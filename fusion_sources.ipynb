{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this file is to merge the information extracted with the different sources such as OpenAlex or OpenCitation together to generate the final output of the process which contains all the association paper-dataset-task to allow further analysis after."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this proceed ?\n",
    "1. Load every generated csv present in extracted_csv folder\n",
    "2. For each line in a csv:\n",
    "    1. Test if the association DOI-Dataset has already been seen\n",
    "    2. If not create a new line in merged.csv with the addition of the information about the task find in dataset.csv \"context\" field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./extracted_csv/paper_poci.csv\n",
      "./extracted_csv/merged.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(csv_path)\n\u001b[1;32m     18\u001b[0m csv_reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mDictReader(\u001b[39mopen\u001b[39m(csv_path))\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m csv_reader:\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m line[\u001b[39m'\u001b[39m\u001b[39mDOI\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m paper_using_dataset[line[\u001b[39m'\u001b[39m\u001b[39mdataset_used\u001b[39m\u001b[39m'\u001b[39m]]:\n\u001b[1;32m     21\u001b[0m         merged\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mline[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mline[\u001b[39m'\u001b[39m\u001b[39mDOI\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mline[\u001b[39m'\u001b[39m\u001b[39mpublication_year\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mline[\u001b[39m'\u001b[39m\u001b[39mdataset_used\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mdatasets_context[line[\u001b[39m'\u001b[39m\u001b[39mdataset_used\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/csv.py:111\u001b[0m, in \u001b[0;36mDictReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_num \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    109\u001b[0m     \u001b[39m# Used only for its side effect.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfieldnames\n\u001b[0;32m--> 111\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreader)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_num \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mline_num\n\u001b[1;32m    114\u001b[0m \u001b[39m# unlike the basic reader, we prefer not to return blanks,\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m# because we will typically wind up with a dict full of None\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# values\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import csv\n",
    "\n",
    "\n",
    "datasets_context = {}\n",
    "ds_reader = csv.DictReader(open('./data/datasets.csv'))\n",
    "for ds in ds_reader:\n",
    "    datasets_context[ds[\"name\"]] = ds[\"context\"]\n",
    "\n",
    "paper_using_dataset = {ds:[] for ds in datasets_context}\n",
    "\n",
    "extracted_csv = glob.glob(\"./extracted_csv/[!merged]*.csv\")\n",
    "\n",
    "with open(\"./extracted_csv/merged.csv\",\"w\") as merged :\n",
    "    merged.write(f\"name,DOI,publication_year,dataset_used,task\")\n",
    "    for csv_path in extracted_csv:\n",
    "        print(csv_path)\n",
    "        csv_reader = csv.DictReader(open(csv_path))\n",
    "        for line in csv_reader:\n",
    "            if line['DOI'] not in paper_using_dataset[line['dataset_used']]:\n",
    "                merged.write(f\"\\n{line['name']},{line['DOI']},{line['publication_year']},{line['dataset_used']},{datasets_context[line['dataset_used']]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
