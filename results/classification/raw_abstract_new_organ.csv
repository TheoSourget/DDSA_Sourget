title,doi,publication_year,abstract,task
DPAFNet: A Residual Dual-Path Attention-Fusion Convolutional Neural Network for Multimodal Brain Tumor Segmentation,https://doi.org/10.1016/j.bspc.2022.104037,2023,"an efficient 3d model dpafnet for brain tumor segmentation based on dualpath dp module and multiscale attention fusion maf module is proposed a novel 3d feature extraction block consisting of dp module and maf module is proposed the maf module is used to aggregate global and local information on channel level a 3d idcm module which is beneficial to dense pixellevel prediction is introduced to merge feature maps with different receptive fields the dice scores of et wt and tc on brats2018 brats2019 and brats2020 datasets all achieve competitive segmentation accuracy brain tumors are highly hazardous and precise automated segmentation of brain tumor subregions has great importance and research significance on the diagnosis and treatment of diseases rapid advances in deep learning make accurate and efficient automatic segmentation more possible but there are challenges in this paper an efficient 3d segmentation model dpafnet based on dualpath dp module and multiscale attention fusion maf module is proposed in dpafnet the dual path convolution is applied to broaden the network scale and residual connection is introduced to avoid network degradation an attention fusion module is proposed to aggregate channel level global and local information in which feature maps of different scales are fused to obtain features that are enriched in semantic information this makes the object information of small tumors get full attention furthermore the 3d iterative dilated convolution merging idcm module expands the receptive field and improves the ability of context awareness ablation experiments verify the optimal combination of dilation rate for the dilated convolution merging module and demonstrate the enhancement of segmentation accuracy due to the postprocessing method comparative experiments of this study on brats2018 brats2019 and brats2020 are promising and provide a promising precision and dice score compared to related work the proposed dpafnet achieves dice score of 795 900 and 839 in the enhancing tumor whole tumor and tumor core on brats2018 respectively on brats2019 it achieves dice score of 782 890 and 812 in the enhancing tumor whole tumor and tumor core respectively",Brain
DPAFNet: A Residual Dual-Path Attention-Fusion Convolutional Neural Network for Multimodal Brain Tumor Segmentation,https://doi.org/10.1016/j.bspc.2022.104037,2023,"an efficient 3d model dpafnet for brain tumor segmentation based on dualpath dp module and multiscale attention fusion maf module is proposed a novel 3d feature extraction block consisting of dp module and maf module is proposed the maf module is used to aggregate global and local information on channel level a 3d idcm module which is beneficial to dense pixellevel prediction is introduced to merge feature maps with different receptive fields the dice scores of et wt and tc on brats2018 brats2019 and brats2020 datasets all achieve competitive segmentation accuracy brain tumors are highly hazardous and precise automated segmentation of brain tumor subregions has great importance and research significance on the diagnosis and treatment of diseases rapid advances in deep learning make accurate and efficient automatic segmentation more possible but there are challenges in this paper an efficient 3d segmentation model dpafnet based on dualpath dp module and multiscale attention fusion maf module is proposed in dpafnet the dual path convolution is applied to broaden the network scale and residual connection is introduced to avoid network degradation an attention fusion module is proposed to aggregate channel level global and local information in which feature maps of different scales are fused to obtain features that are enriched in semantic information this makes the object information of small tumors get full attention furthermore the 3d iterative dilated convolution merging idcm module expands the receptive field and improves the ability of context awareness ablation experiments verify the optimal combination of dilation rate for the dilated convolution merging module and demonstrate the enhancement of segmentation accuracy due to the postprocessing method comparative experiments of this study on brats2018 brats2019 and brats2020 are promising and provide a promising precision and dice score compared to related work the proposed dpafnet achieves dice score of 795 900 and 839 in the enhancing tumor whole tumor and tumor core on brats2018 respectively on brats2019 it achieves dice score of 782 890 and 812 in the enhancing tumor whole tumor and tumor core respectively",Brain
An effective CNN and Transformer complementary network for medical image segmentation,https://doi.org/10.1016/j.patcog.2022.109228,2023,"the transformer network was originally proposed for natural language processing due to its powerful representation ability for longrange dependency it has been extended for vision tasks in recent years to fully utilize the advantages of transformers and convolutional neural networks cnns we propose a cnn and transformer complementary network ctcnet for medical image segmentation we first design two encoders by swin transformers and residual cnns to produce complementary features in transformer and cnn domains respectively then we crosswisely concatenate these complementary features to propose a crossdomain fusion block cfb for effectively blending them in addition we compute the correlation between features from the cnn and transformer domains and apply channel attention to the selfattention features by transformers for capturing dual attention information we incorporate crossdomain fusion feature correlation and dual attention together to propose a feature complementary module fcm for improving the representation ability of features finally we design a swin transformer decoder to further improve the representation ability of longrange dependencies and propose to use skip connections between the transformer decoded features and the complementary features for extracting spatial details contextual semantics and longrange information skip connections are performed in different levels for enhancing multiscale invariance experimental results show that our ctcnet significantly surpasses the stateoftheart image segmentation models based on cnns transformers and even transformer and cnn combined models designed for medical image segmentation it achieves superior performance on different medical applications including multiorgan segmentation and cardiac segmentation",Cardiac
Swin-Unet: Unet-Like Pure Transformer for Medical Image Segmentation,https://doi.org/10.1007/978-3-031-25066-8_9,2023,"abstractin the past few years convolutional neural networks cnns have achieved milestones in medical image analysis in particular deep neural networks based on ushaped architecture and skipconnections have been widely applied in various medical image tasks however although cnn has achieved excellent performance it cannot learn global semantic information interaction well due to the locality of convolution operation in this paper we propose swinunet which is an unetlike pure transformer for medical image segmentation the tokenized image patches are fed into the transformerbased ushaped encoderdecoder architecture with skipconnections for localglobal semantic feature learning specifically we use a hierarchical swin transformer with shifted windows as the encoder to extract context features and a symmetric swin transformerbased decoder with a patch expanding layer is designed to perform the upsampling operation to restore the spatial resolution of the feature maps under the direct downsampling and upsampling of the inputs and outputs by 4times experiments on multiorgan and cardiac segmentation tasks demonstrate that the pure transformerbased ushaped encoderdecoder network outperforms those methods with fullconvolution or the combination of transformer and convolution the codes have been publicly available at the link httpsgithubcomhucaofightingswinunetkeywordstransformerselfattentionmedical image segmentation",Cardiac
Multiscale lightweight 3D segmentation algorithm with attention mechanism: Brain tumor image segmentation,https://doi.org/10.1016/j.eswa.2022.119166,2023,"this study proposes a lightweight automatic 3d algorithm with an attention mechanism for the segmentation of braintumor images to address the challenges accurate segmentation of braintumor regions in medical images is essential in patient diagnosis using the 3d unet however existed 3d networks lack the ability to automatically focus on smaller targets and have low precision on segmenting braintumor regions existed 3d networks use numerous parameters and are difficult to deploy in practice the 3dunet serves as the basic structure of the proposed approach 1 this study replaces the standard convolutions with hierarchical decoupled convolutions to reduce the number of parameters 2 this study adds dilated convolutions to enhance the ability of the network to express multiscale information in the bottom convolution module 3 this study introduces an attention mechanism to the output layer so that the network can automatically focus on the region of the tumor and use the relationships among the enhancing tumor whole tumor and tumor core to increase segmentation precision the results of the proposed network model applied to the brats 2019 test set revealed that the dice coefficients of the proposed adhdcnet for enhancing tumor whole tumor and tumor core were 7791 8994 and 8389 respectively using 030 m parameters and 2581 g floatingpoint operations extensive experiments on the brats 2018 brats 2019 and brats 2020 dadasets show that the proposed model has better potential with regard to the efficient segmentation of small braintumor regions",Brain
Multiscale lightweight 3D segmentation algorithm with attention mechanism: Brain tumor image segmentation,https://doi.org/10.1016/j.eswa.2022.119166,2023,"this study proposes a lightweight automatic 3d algorithm with an attention mechanism for the segmentation of braintumor images to address the challenges accurate segmentation of braintumor regions in medical images is essential in patient diagnosis using the 3d unet however existed 3d networks lack the ability to automatically focus on smaller targets and have low precision on segmenting braintumor regions existed 3d networks use numerous parameters and are difficult to deploy in practice the 3dunet serves as the basic structure of the proposed approach 1 this study replaces the standard convolutions with hierarchical decoupled convolutions to reduce the number of parameters 2 this study adds dilated convolutions to enhance the ability of the network to express multiscale information in the bottom convolution module 3 this study introduces an attention mechanism to the output layer so that the network can automatically focus on the region of the tumor and use the relationships among the enhancing tumor whole tumor and tumor core to increase segmentation precision the results of the proposed network model applied to the brats 2019 test set revealed that the dice coefficients of the proposed adhdcnet for enhancing tumor whole tumor and tumor core were 7791 8994 and 8389 respectively using 030 m parameters and 2581 g floatingpoint operations extensive experiments on the brats 2018 brats 2019 and brats 2020 dadasets show that the proposed model has better potential with regard to the efficient segmentation of small braintumor regions",Brain
Diagnosis of arrhythmias with few abnormal ECG samples using metric-based meta learning,https://doi.org/10.1016/j.compbiomed.2022.106465,2023,"a major challenge in artificial intelligence based ecg diagnosis lies that its difficult to obtain sufficient annotated training samples for each rhythm type especially for rare diseases which makes many approaches fail to achieve the desired performance with limited ecg records in this paper we propose a meta siamese network msn based on metric learning to achieve high accuracy for automatic ecg arrhythmias diagnosis with limited ecg records first the ecg signals from three different ecg datasets are preprocessed through resampling wavelet denoising rwave localization heartbeat segmentation and zscore normalization then an ecg dataset with limited records is constructed to verify the performance of the proposed model and explore variation of model performance with the sample size second a metricbased metalearning framework is proposed to address the challenge of fewshot learning for automatic ecg diagnosis of cardiac arrhythmia and siamese network is employed to achieve arrhythmia diagnosis based on similarity metric finally the nway kshot metatesting strategy is proposed based on the siamese network with double inputs and the experimental results demonstrate that the proposed strategy can effectively improve the robustness of the proposed model",Cardiac
Automated Brain Tumor Diagnosis Using Deep Residual U-Net Segmentation燤odel,https://doi.org/10.32604/cmc.2023.032816,2023,"automated segmentation and classification of biomedical images act as a vital part of the diagnosis of brain tumors bt a primary tumor brain analysis suggests a quicker response from treatment that utilizes for improving patient survival rate the location and classification of bts from huge medicinal images database obtained from routine medical tasks with manual processes are a higher cost together in effort and time an automatic recognition place and classifier process was desired and useful this study introduces an automated deep residual unet segmentation with classification model adruscm for brain tumor diagnosis the presented adruscm model majorly focuses on the segmentation and classification of bt to accomplish this the presented adruscm model involves wiener filtering wf based preprocessing to eradicate the noise that exists in it in addition the adruscm model follows deep residual unet segmentation model to determine the affected brain regions moreover vgg19 model is exploited as a feature extractor finally tunicate swarm optimization tso with gated recurrent unit gru model is applied as a classification model and the tso algorithm effectually tunes the gru hyperparameters the performance validation of the adruscm model was tested utilizing figshare dataset and the outcomes pointed out the better performance of the adruscm approach on recent approaches",Brain
MBANet: A 3D convolutional neural network with multi-branch attention for brain tumor segmentation from MRI images,https://doi.org/10.1016/j.bspc.2022.104296,2023,"a novel network mbanet to segment multimodal brain tumors we propose a 3d shuffle attention sa multibranch attention to focus on tumor regions we add 3d sa attention to skip connections to address the semantic gap problem with spatial and channel aggregation we propose a bu module that not only perfectly integrates with 3d sa attention but also reduces computational resource consumption mbanet increases the segmentation performance on brats 2018 and brats 2019 validation datasets compared with other stateoftheart methods more than half of brain tumors are malignant tumors so there is a need for fast and accurate segmentation of tumor regions in brain magnetic resonance imaging mri images traditional 2d brain tumor segmentation methods seriously ignore the spatial context features of brain tumor mri images so how to achieve accurate segmentation of brain tumor regions with multiple modalities is the main problem the paper proposes a 3d convolutional neural network with 3d multibranch attention mbanet first the optimized shuffle unit is used to form the basic unit bu module of mbanet in the bu module the group convolution is used to perform convolution operation after the input channel is split and the channel shuffle is used to scramble the convolutional channels after fusion then mbanet uses a novel multibranch 3d shuffle attention sa module as the attention layer in the encoder the 3d sa module groups along the channel dimension and divides the feature maps into small features for each small feature the 3d sa module builds both channel attention and spatial attention while adopting the bu module in addition in order to recover the resolution of the upsampling semantic features better a 3d sa module is also used in the skip connection of mbanet experiments on the brats 2018 and brats 2019 show that the dice of et wt and tc reach 8018 8980 8547 and 7821 8979 8304 respectively the excellent segmentation performance shows that mbanet is significantly improved compared with other stateoftheart methods",Brain
MBANet: A 3D convolutional neural network with multi-branch attention for brain tumor segmentation from MRI images,https://doi.org/10.1016/j.bspc.2022.104296,2023,"a novel network mbanet to segment multimodal brain tumors we propose a 3d shuffle attention sa multibranch attention to focus on tumor regions we add 3d sa attention to skip connections to address the semantic gap problem with spatial and channel aggregation we propose a bu module that not only perfectly integrates with 3d sa attention but also reduces computational resource consumption mbanet increases the segmentation performance on brats 2018 and brats 2019 validation datasets compared with other stateoftheart methods more than half of brain tumors are malignant tumors so there is a need for fast and accurate segmentation of tumor regions in brain magnetic resonance imaging mri images traditional 2d brain tumor segmentation methods seriously ignore the spatial context features of brain tumor mri images so how to achieve accurate segmentation of brain tumor regions with multiple modalities is the main problem the paper proposes a 3d convolutional neural network with 3d multibranch attention mbanet first the optimized shuffle unit is used to form the basic unit bu module of mbanet in the bu module the group convolution is used to perform convolution operation after the input channel is split and the channel shuffle is used to scramble the convolutional channels after fusion then mbanet uses a novel multibranch 3d shuffle attention sa module as the attention layer in the encoder the 3d sa module groups along the channel dimension and divides the feature maps into small features for each small feature the 3d sa module builds both channel attention and spatial attention while adopting the bu module in addition in order to recover the resolution of the upsampling semantic features better a 3d sa module is also used in the skip connection of mbanet experiments on the brats 2018 and brats 2019 show that the dice of et wt and tc reach 8018 8980 8547 and 7821 8979 8304 respectively the excellent segmentation performance shows that mbanet is significantly improved compared with other stateoftheart methods",Brain
Brain tumor segmentation of MRI images: A comprehensive review on the application of artificial intelligence tools,https://doi.org/10.1016/j.compbiomed.2022.106405,2023,"brain cancer is a destructive and lifethreatening disease that imposes immense negative effects on patients lives therefore the detection of brain tumors at an early stage improves the impact of treatments and increases the patients survival rates however detecting brain tumors in their initial stages is a demanding task and an unmet needthe present study presents a comprehensive review of the recent artificial intelligence ai methods of diagnosing brain tumors using mri images these ai techniques can be divided into supervised unsupervised and deep learning dl methodsdiagnosing and segmenting brain tumors usually begin with magnetic resonance imaging mri on the brain since mri is a noninvasive imaging technique another existing challenge is that the growth of technology is faster than the rate of increase in the number of medical staff who can employ these technologies it has resulted in an increased risk of diagnostic misinterpretation therefore developing robust automated brain tumor detection techniques has been studied widely over the past yearsthe current review provides an analysis of the performance of modern methods in this area moreover various image segmentation methods in addition to the recent efforts of researchers are summarized finally the paper discusses open questions and suggests directions for future research",Brain
Multi-input Unet model based on the integrated block and the aggregation connection for MRI brain tumor segmentation,https://doi.org/10.1016/j.bspc.2022.104027,2023,"with the growth of data information and the development of computer equipment it is extremely timeconsuming and laborious to rely on the traditional manual segmentation of brain medical images to solve the above problems this paper proposes a multiinput unet model based on the integrated block and the aggregation connection to achieve efficient and accurate segmentation of tumor structure besides this paper solves the lowresolution problem in sagittal and coronal planes which can effectively improve memory efficiency the proposed algorithm is innovative in three aspects firstly by inputting the mask images which can effectively represent the tumor location characteristics it can provide more information about the spatial relationship to alleviate the problems of fuzzy boundary and low contrast between the lesion region and healthy brain tissue then the integrated block extracts the tumor local information in different receptive domains by a multiscale convolution kernel the aggregation connection realizes the implicit deep connection of context information which combines the shallow and deep information of the brain with strong geometric spatial relationships meanwhile to effectively alleviate the waste of memory resources caused by redundant and background information in medical images the amount of calculation in model training is reduced by dimension reduction of the feature map an ablation experiment is used to verify the innovation of the proposed algorithm on the brats dataset which compares with the stateoftheart brain tumor segmentation methods the precision of the proposed multiinput unet model for the whole tumor and core lesion is 092 and 090 respectively",Brain
Multi-input Unet model based on the integrated block and the aggregation connection for MRI brain tumor segmentation,https://doi.org/10.1016/j.bspc.2022.104027,2023,"with the growth of data information and the development of computer equipment it is extremely timeconsuming and laborious to rely on the traditional manual segmentation of brain medical images to solve the above problems this paper proposes a multiinput unet model based on the integrated block and the aggregation connection to achieve efficient and accurate segmentation of tumor structure besides this paper solves the lowresolution problem in sagittal and coronal planes which can effectively improve memory efficiency the proposed algorithm is innovative in three aspects firstly by inputting the mask images which can effectively represent the tumor location characteristics it can provide more information about the spatial relationship to alleviate the problems of fuzzy boundary and low contrast between the lesion region and healthy brain tissue then the integrated block extracts the tumor local information in different receptive domains by a multiscale convolution kernel the aggregation connection realizes the implicit deep connection of context information which combines the shallow and deep information of the brain with strong geometric spatial relationships meanwhile to effectively alleviate the waste of memory resources caused by redundant and background information in medical images the amount of calculation in model training is reduced by dimension reduction of the feature map an ablation experiment is used to verify the innovation of the proposed algorithm on the brats dataset which compares with the stateoftheart brain tumor segmentation methods the precision of the proposed multiinput unet model for the whole tumor and core lesion is 092 and 090 respectively",Brain
Multi-target segmentation of pancreas and pancreatic tumor based on fusion of attention mechanism,https://doi.org/10.1016/j.bspc.2022.104170,2023,"multiobjective segmentation algorithms for pancreatic and pancreatic tumors are relatively scarce the existing pancreas segmentation algorithms are weak in small target feature extraction the existing pancreas segmentation algorithms require too much computation and high equipment requirements therefore clinical application is more difficult we design a novel loss function wml which effectively enhances the networks attention to target samples and the ability to capture edge detail pixels of pancreas and pancreatic tumor so that the weights of the convolution kernel change in the direction favorable to pancreatic and pancreatic tumor feature learning we propose a novel attention module mdag for exploring multidimensional hybrid features of pancreas and pancreatic tumour mdag is able to efficiently learn contextual information within the ushaped network accomplish small target feature localisation in multiple dimensions of space and channels and filter redundant information in shallow feature maps thus enhancing the feature representation of pancreas and pancreatic tumour our proposed mdag performs well on both the task07pancreas dataset as well as the nihpancreas dataset and the mdag is able to achieve higher segmentation performance with a smaller number of parameters existing neural network segmentation schemes perform well in the task of segmenting images of organs with large areas and clear morphology such as the liver and lungs however it is difficult to segment organs with variable morphology and small target area such as pancreas and tumors in order to achieve accurate segmentation of pancreas and its cysts mdagnet multidimensional attention gate network is proposed in this paper combining three attention mechanisms spatial channel and multidimensional feature map input mdagmultidimensional attention gate obtains the global distribution of semantic information in spatial and channel dimensions filters redundant information in shallow feature maps realizes feature response and recalibrates convolution kernel parameters in addition the wmlweighted cross entropy and miou loss function loss can adaptively assign the weight of category loss and count the classification error of global pixels which can increase the error attention of the target area and improving the segmentation accuracy of the network the algorithm is experimented on the task07pancreas dataset compared with unet under the same conditions the dice coefficient precision recall rate and miou mean intersection over union of mdagnet are improved by 53 15 127 and 76 respectively the results show that mdagnet can accurately segment the region of pancreas and its cyst in ctcomputed tomography images which proves that mdag has better segmentation efficiency for such small target regions",Lung
Multi-target segmentation of pancreas and pancreatic tumor based on fusion of attention mechanism,https://doi.org/10.1016/j.bspc.2022.104170,2023,"multiobjective segmentation algorithms for pancreatic and pancreatic tumors are relatively scarce the existing pancreas segmentation algorithms are weak in small target feature extraction the existing pancreas segmentation algorithms require too much computation and high equipment requirements therefore clinical application is more difficult we design a novel loss function wml which effectively enhances the networks attention to target samples and the ability to capture edge detail pixels of pancreas and pancreatic tumor so that the weights of the convolution kernel change in the direction favorable to pancreatic and pancreatic tumor feature learning we propose a novel attention module mdag for exploring multidimensional hybrid features of pancreas and pancreatic tumour mdag is able to efficiently learn contextual information within the ushaped network accomplish small target feature localisation in multiple dimensions of space and channels and filter redundant information in shallow feature maps thus enhancing the feature representation of pancreas and pancreatic tumour our proposed mdag performs well on both the task07pancreas dataset as well as the nihpancreas dataset and the mdag is able to achieve higher segmentation performance with a smaller number of parameters existing neural network segmentation schemes perform well in the task of segmenting images of organs with large areas and clear morphology such as the liver and lungs however it is difficult to segment organs with variable morphology and small target area such as pancreas and tumors in order to achieve accurate segmentation of pancreas and its cysts mdagnet multidimensional attention gate network is proposed in this paper combining three attention mechanisms spatial channel and multidimensional feature map input mdagmultidimensional attention gate obtains the global distribution of semantic information in spatial and channel dimensions filters redundant information in shallow feature maps realizes feature response and recalibrates convolution kernel parameters in addition the wmlweighted cross entropy and miou loss function loss can adaptively assign the weight of category loss and count the classification error of global pixels which can increase the error attention of the target area and improving the segmentation accuracy of the network the algorithm is experimented on the task07pancreas dataset compared with unet under the same conditions the dice coefficient precision recall rate and miou mean intersection over union of mdagnet are improved by 53 15 127 and 76 respectively the results show that mdagnet can accurately segment the region of pancreas and its cyst in ctcomputed tomography images which proves that mdag has better segmentation efficiency for such small target regions",Lung
Brain MRI high resolution image creation and segmentation with the new GAN method,https://doi.org/10.1016/j.bspc.2022.104246,2023,"it provides a better way to analyze images by increasing the image resolution a new and highaccuracy method has been proposed by making the unsupervised ones of the stateofart methods controlled while segmenting the image effective results in brainmri segmentation brain magnetic resonance imaging segmentation is a recent and still popular research area good and accurate segmentation results play an important role in the diagnosis of cancer or other brain diseases in this article a novel generative adversarial network architecture is proposed for brain magnetic resonance imaging segmentation the proposed method is called ssimdcl supervised simdcl four studies were conducted in this article in the first study the ssimdcl method on the twodimensional brain magnetic resonance imaging dataset was compared with the current stateofart architectures cyclegan cut fastcut dclgan and simdcl in the second study the dataset resolution was improved in the third study being measured the efficiency of the newly created dataset and the ssimdcl is trained for both the dataset with increased resolution and the normal dataset and the results are obtained in the fourth study the results of the ssimdcl and the volbrain brain magnetic resonance imaging segmentation results which are widely used today are included when volbrain segmentation and ssimdcl segmentation are compared the results were compared both visually and metrically fréchet inception distance fid kernel inception distance kid peak signal to noise ratio psnr and learned perceptual image patch similarity lpips were used as measurement metrics the jaccard and dice similarity metrics were also used in the analysis it was observed that the ssimdcl give satisfactory results in all four studies this method can be used as an automatic brain mri image segmentation system",Brain
Joint few-shot registration and segmentation self-training of 3D medical images,https://doi.org/10.1016/j.bspc.2022.104294,2023,"joint registration and segmentation selftraining framework for fewshot scenario weakly supervised registration and semisupervised segmentation complement each other qualityassessed and screened pseudolabels ensure a benign dualtask selftraining outperforms fully supervised singletask models on 3d medical images medical image segmentation and registration are very important related steps in clinical medical diagnosis in the past few years deep learning techniques for joint segmentation and registration have achieved good results in both segmentation and registration tasks through oneway assisted learning or mutual utilization however they often rely on large labeled datasets for supervised training or directly use pseudolabels without quality estimation we propose a joint registration and segmentation selftraining framework jrss which aims to use segmentation pseudolabels to promote shared learning between segmentation and registration in scenarios with few manually labeled samples while improving the performance of dual tasks jrss combines weakly supervised registration and semisupervised segmentation learning in a selftraining framework segmentation selftraining generates highquality pseudolabels for unlabeled data by injecting noise pseudolabels screening and uncertainty correction registration utilizes pseudolabels to facilitate weakly supervised learning and as input noise as well as data augmentation to facilitate segmentation selftraining experiments on two public 3d medical image datasets abdominal ct and brain mri demonstrate that our proposed method achieves simultaneous improvements in segmentation and registration accuracy under fewshot scenarios outperforms the singletask fullysupervised training stateoftheart model in the metrics of dice similarity coefficient and standard deviation of the jacobian determinant",Brain
Multi-level threshold segmentation framework for breast cancer images using enhanced differential evolution,https://doi.org/10.1016/j.bspc.2022.104373,2023,"an improved multistrategy based differential evolution algorithm is proposed the proposed method improves solution quality and accelerates convergence the proposed method is embedded in an image segmentation framework the proposed framework can effectively segment breast cancer images breast cancer has replaced lung cancer as the most prevalent malignancy threatening human health early breast screening can help improve treatment success and reduce the risk of death the analysis and diagnosis of breast cancer real images by computeraided technology is the key link to early diagnosis highquality medical segmentation images can improve the accuracy of lesion area detection this study used a multilevel threshold image segmentation framework based on novel differential evolution twodimensional kapurs entropy and the twodimensional histogram to improve the efficiency of subsequent image analysis and diagnosis we proposed an enhanced differential evolution in the framework based on the roundup search the elite lévymutation and the decentralized foraging strategy to explore the optimal thresholds in this study the enhanced differential evolution was compared to stateoftheart methods for benchmark function experiments and breast cancer image segmentation experiments it is shown that the proposed threshold search method accelerates convergence and reduces the problem of premature convergence quantitative results demonstrate that the proposed method can achieve an average peak signaltonoise ratio and feature similarity index of 21231 and 0951 respectively at the 5level threshold which is better than other methods as a result the proposed multilevel threshold image segmentation model can provide quality samples for subsequent image analysis and classification",Lung
A multi-scale interactive U-Net for pulmonary vessel segmentation method based on transfer learning,https://doi.org/10.1016/j.bspc.2022.104407,2023,"pulmonary vessel segmentation is the key application of ai in lung disease diagnosis and surgical planning compared with manual labeling automatic labeling of pulmonary vessels using an aibased medical image segmentation method has the advantages of low cost high accuracy and efficiency which is the development trend of medical images in terms of pulmonary vessel segmentation fcn and unet are the most widely used pulmonary vessel segmentation methods based on deep learning however the precision of pulmonary vessel segmentation especially the small vessels tends to be poor by such methods therefore to solve the above problem multiscale interactive unet msiunet is proposed in msiunet three decoder branches are used to extract smallscale middlescale and largescale vessels respectively which can improve the accuracy of small vessel segmentation by enhancing the representational ability of small vessels in addition to solve the problem of small vessel information loss caused by downsampling we introduce the attention mechanism into the skiplayer connection and propose a crosslayer aggregation module cla among the three decoder branches a multiscale information interaction strategy msiis is proposed based on transfer learning which can effectively enhance the correlation of multiscale vessels in lung ct images in the training stage we propose a scaleinduced supervision strategy siss this strategy uses the idea of fusion first and then supervision which effectively solves the problem of inconsistency in multiscale vessels classification thereby reducing the segmentation errors finally we use feature transmission instead of convolution parameter sharing to realize the multiscale information interaction strategy and propose an extension scheme called multilevel cascade interactive unet mlciunet the experimental results indicate that our msiunet and mlciunet have better performance than other stateoftheart methods on pulmonary vessel segmentation specifically the best dice similarity coefficient dsc sensitivity and precision are obtained by the proposed methods to segment pulmonary vessels we propose msiunet for pulmonary vessel segmentation we construct a novel skiplayer connection module to enhance the encoder features we design a information interaction strategy to enhance the information interaction between the threescale vessels to reduce the errors of segmentation we propose a scaleinduced supervision strategy choose the resunet as the baseline model of pulmonary vessel segmentation",Lung
SSO-RBNN driven brain tumor classification with Saliency-K-means segmentation technique,https://doi.org/10.1016/j.bspc.2022.104356,2023,"earlystage diagnosis of brain tumor leads to better chance of cure from this deadliest disease across the globe existing schemes on brain tumor classification use machine learning convolutional neural networks generative adversarial networks and deep learning schemes however more execution time and uncertain predictions leading additional process to crosscheck the obtained results in this paper a classification model saliencykmeanssorbnn is formulated including a new hybrid saliencekmean segmentation technique along with utilizing the advantage of social spider optimization sso algorithm in radial basis neural network rbnn hybrid saliency map with kmeans clusterbased segmentation approach is formulated to segment the tumor region as saliency map spotlights on eye catching region within target image segmented image is fetched to feature extraction phase by considering multiresolution wavelet transform principal component kurtosis skewness inverse difference moment idm cosine transform feature vector is then processed for an efficient classification using rbnn by optimizing the cluster center through sso rbnn with gaussian kernel depicts a low complex model for classification saliencykmeanssorbnn and new hybrid saliencykmean segmentation are validated on standard datasets and compared with existing schemes with regard to specificity precision sensitivity f1 score mcc kappa coefficient and complexity saliencykmeanssorbnn yielding a classification accuracy in three datasets as 96 92 and 94",Brain
A comparison of diffusion tensor imaging tractography and constrained spherical deconvolution with automatic segmentation in traumatic brain injury,https://doi.org/10.1016/j.nicl.2022.103284,2023,"detection of microstructural white matter injury in traumatic brain injury tbi requires specialised imaging methods of which diffusion tensor imaging dti has been extensively studied newer fibre alignment estimation methods such as constrained spherical deconvolution csd are better than dti in resolving crossing fibres that are ubiquitous in the brain and may improve the ability to detect microstructural injuries furthermore automatic tract segmentation has the potential to improve tractography reliability and accelerate workflow compared to the manual segmentation commonly used in this study we compared the results of deterministic dti based tractography and manual tract segmentation with csd based probabilistic tractography and automatic tract segmentation using tractseg 37 participants with a history of tbi with glasgow coma scale 1315 and persistent symptoms and 41 healthy controls underwent deterministic dtibased tractography with manual tract segmentation and probabilistic csdbased tractography with tractseg automatic segmentationfractional anisotropy fa and mean diffusivity of corpus callosum and three bilateral association tracts were measured fa and md values derived from both tractography methods were generally moderately to strongly correlated csd with tractseg differentiated the groups based on fa while dti did not csd and tractsegbased tractography may be more sensitive in detecting microstructural changes associated with tbi than deterministic dti tractography additionally csd with tractseg was found to be applicable at lower bvalue and number of diffusionencoding gradients data than previously reported",Brain
A modified reptile search algorithm for global optimization and image segmentation: Case study brain MRI images,https://doi.org/10.1016/j.compbiomed.2022.106404,2023,"in this paper we proposed an enhanced reptile search algorithm rsa for global optimization and selected optimal thresholding values for multilevel image segmentation rsa is a recent metaheuristic optimization algorithm depending on the hunting behavior of crocodiles rsa is inclined to inadequate diversity local optima and unbalanced exploitation abilities as other metaheuristic algorithms the runge kutta optimizer run is a novel metaheuristic algorithm that has demonstrated effectiveness in solving realworld optimization problems the enhanced solution quality esq in run utilizes the thusfar best solution to promote the quality of solutions improve the convergence speed and effectively balance the exploration and exploitation steps also the scale factor sf has a randomized adaptation nature which helps run in further improving the exploration and exploitation steps this parameter ensures a smooth transition from exploration to exploitation in order to mitigate the drawbacks of the rsa algorithm this paper proposed a modified rsa mrsa which combines the rsa algorithm with the run the esq mechanism and the scale factor boost the original rsas performance enhance convergence speed bypass local optimum and enhance the balance between exploitation and exploration the validity of mrsa was verified using two experimental sequences first we applied mrsa to cec2020 benchmark functions of various types and dimensions showing that mrsa has more robust search capabilities than the original rsa and popular counterpart algorithms concerning statistical convergence and diversity measurements the second experiment evaluated mrsa for a realworld application to solve magnetic resonance imaging mri brain image segmentation overall experimental results confirm that the mrsa has a strong optimization ability also mrsa method is a more successful multilevel thresholding segmentation and outperforms comparison methods according to different performance measures",Brain
Segmentation and Analysis Emphasizing Neonatal MRI Brain Images Using Machine Learning Techniques,https://doi.org/10.3390/math11020285,2023,"mri scanning has shown significant growth in the detection of brain tumors in the recent decade among various methods such as mra xray ct pet spect etc brain tumor identification requires high exactness because a minor error can be lifethreatening brain tumor disclosure remains a challenging job in medical image processing this paper targets to explicate a method that is more precise and accurate in brain tumor detection and focuses on tumors in neonatal brains the infant brain varies from the adult brain in some aspects and proper preprocessing technique proves to be fruitful to avoid miscues in results this paper is divided into two parts in the first half preprocessing was accomplished using he clahe and bpdfhe enhancement techniques an analysis is the sequel to the above methods to check for the best method based on performance metrics ie mse psnr rmse and ambe the second half deals with the segmentation process we propose a novel arkfcm to use for segmentation finally the trends in the performance metrics dice similarity and jaccard similarity as well as the segmentation results are discussed in comparison with the conventional fcm method",Brain
Lung and Infection CT-Scan-Based Segmentation with 3D UNet Architecture and Its Modification,https://doi.org/10.3390/healthcare11020213,2023,"covid19 is the disease that has spread over the world since december 2019 this disease has a negative impact on individuals governments and even the global economy which has caused the who to declare covid19 as a pheic public health emergency of international concern until now there has been no medicine that can completely cure covid19 therefore to prevent the spread and reduce the negative impact of covid19 an accurate and fast test is needed the use of chest radiography imaging technology such as cxr and ctscan plays a significant role in the diagnosis of covid19 in this study ctscan segmentation will be carried out using the 3d version of the most recommended segmentation algorithm for biomedical images namely 3d unet and three other architectures from the 3d unet modifications namely 3d resunet 3d vggunet and 3d denseunet these four architectures will be used in two cases of segmentation binaryclass segmentation where each architecture will segment the lung area from a ct scan and multiclass segmentation where each architecture will segment the lung and infection area from a ct scan before entering the model the dataset is preprocessed first by applying a minmax scaler to scale the pixel value to a range of zero to one and the clahe method is also applied to eliminate intensity in homogeneity and noise from the data of the four models tested in this study surprisingly the original 3d unet produced the most satisfactory results compared to the other three architectures although it requires more iterations to obtain the maximum results for the binaryclass segmentation case 3d unet produced iou scores dice scores and accuracy of 9432 9705 and 9937 respectively for the case of multiclass segmentation 3d unet produced iou scores dice scores and accuracy of 8158 8861 and 9878 respectively the use of 3d segmentation architecture will be very helpful for medical personnel because apart from helping the process of diagnosing someone with covid19 they can also find out the severity of the disease through 3d infection projections",Lung
Performance evaluation of automated white matter hyperintensity segmentation algorithms in a multicenter cohort on cognitive impairment and dementia,https://doi.org/10.3389/fpsyt.2022.1010273,2023,"white matter hyperintensities wmh a biomarker of small vessel disease are often found in alzheimers disease ad and their advanced detection and quantification can be beneficial for research and clinical applications to investigate wmh in largescale multicenter studies on cognitive impairment and ad appropriate automated wmh segmentation algorithms are required this study aimed to compare the performance of segmentation tools and provide information on their application in multicenter researchwe used a pseudorandomly selected dataset n 50 from the dznemulticenter observational longitudinal cognitive impairment and dementia study delcode that included 3d fluidattenuated inversion recovery flair images from participants across the cognitive continuum performances of toprated algorithms for automated wmh segmentation brain intensity abnormality classification algorithm bianca lesion segmentation toolbox lst lesion growth algorithm lga lst lesion prediction algorithm lpa pgs and sysumedia were compared to manual reference segmentation rsacross tools segmentation performance was moderate for global wmh volume and number of detected lesions after retraining on a delcode subset the deep learning algorithm sysumedia showed the highest performances with an average dices coefficient of 0702 0109 sd for volume and a mean f1score of 0642 0109 sd for the number of lesions the intraclass correlation was excellent for all algorithms 09 but bianca 0835 performance improved with high wmh burden and varied across brain regionsto conclude the deep learning algorithm when retrained performed well in the multicenter context nevertheless the performance was close to traditional methods we provide methodological recommendations for future studies using automated wmh segmentation to quantify and assess wmh along the continuum of cognitive impairment and ad dementia",Brain
Brain Tumor MRI Identification and Classification Using DWT PCA and KSVM,https://doi.org/10.36227/techrxiv.21771329.v2,2023,"ltpgt classification segmentation and the identification of the infection region in mri images of brain tumors are laborintensive and iterative processes numerous anatomical structures of the human body may be envisioned using an image processing theory with basic imaging methods it is challenging to see the aberrant human brains structure the neurological structure of the human brain may be distinguished and made clearer using the magnetic resonance imaging technique the mri approach uses a number of imaging techniques to evaluate and record the human brains interior features in this study we focused on strategies for noise removal graylevel cooccurrence matrix glcm extraction of features and segmentation of brain tumor regions based on discrete wavelet transform dwt to minimize complexity and enhance performance in turn this reduces any noise that could have been left over after segmentation due to morphological filtering brain mri scans were utilized to test the accuracy of the classification and the location of the tumor using probabilistic neural network classifiers the classifiers accuracy and position detection were tested using mri brain imaging the efficiency of the suggested approach is demonstrated by experimental findings which showed that normal and diseased tissues could be distinguished from one another from brain mri scans with about 100 accuracy ltpgt",Brain
A Novel Lightweight CNN Architecture for the Diagnosis of Brain Tumors Using MR Images,https://doi.org/10.3390/diagnostics13020312,2023,"over the last few years brain tumorrelated clinical cases have increased substantially particularly in adults due to environmental and genetic factors if they are unidentified in the early stages there is a risk of severe medical complications including death so early diagnosis of brain tumors plays a vital role in treatment planning and improving a patients condition there are different forms properties and treatments of brain tumors among them manual identification and classification of brain tumors are complex timedemanding and sensitive to error based on these observations we developed an automated methodology for detecting and classifying brain tumors using the magnetic resonance mr imaging modality the proposed work includes three phases preprocessing classification and segmentation in the preprocessing we started with the skullstripping process through morphological and thresholding operations to eliminate nonbrain matters such as skin muscle fat and eyeballs then we employed image data augmentation to improve the model accuracy by minimizing the overfitting later in the classification phase we developed a novel lightweight convolutional neural network lightweight cnn model to extract features from skullfree augmented brain mr images and then classify them as normal and abnormal finally we obtained infected tumor regions from the brain mr images in the segmentation phase using a fastlinking modified spiking cortical model flmscm based on this sequence of operations our framework achieved 9958 classification accuracy and 957 of dice similarity coefficient dsc the experimental results illustrate the efficiency of the proposed framework and its appreciable performance compared to the existing techniques",Brain
A systematic literature review of machine learning application in COVID-19 medical image classification,https://doi.org/10.1016/j.procs.2022.12.192,2023,"detecting covid19 as early as possible and quickly is one way to stop the spread of covid19 machine learning development can help to diagnose covid19 more quickly and accurately this report aims to find out how far research has progressed and what lessons can be learned for future research in this sector by filtering titles abstracts and content in the google scholar database this literature review was able to find 19 related papers to answer two research questions ie what medical images are commonly used for covid19 classification and what are the methods for covid19 classification according to the findings chest xray were the most commonly used data to categorize covid19 and transfer learning techniques were the method used in this study researchers also concluded that lung segmentation and use of multimodal data could improve performance",Lung
Twist-Net: A multi-modality transfer learning network with the hybrid bilateral encoder for hypopharyngeal cancer segmentation,https://doi.org/10.1016/j.compbiomed.2023.106555,2023,"hypopharyngeal cancer hpc is a rare disease therefore it is a challenge to automatically segment hpc tumors and metastatic lymph nodes hpc risk areas from medical images with the smallscale dataset combining lowlevel details and highlevel semantics from feature maps in different scales can improve the accuracy of segmentation herein we propose a multimodality transfer learning network with hybrid bilateral encoder twistnet for hypopharyngeal cancer segmentation specifically we propose a bilateral transition bt block and a bilateral gather bg block to twist fuse highlevel semantic feature maps and lowlevel detailed feature maps we design a block with multireceptive field extraction capabilities m block to capture multiscale information to avoid overfitting caused by the small scale of the dataset we propose a transfer learning method that can transfer priors experience from large computer vision datasets to multimodality medical imaging datasets compared with other methods our method outperforms other methods on hpc dataset achieving the highest dice of 8298 our method is also superior to other methods on two public medical segmentation datasets ie the chasedb1 dataset and brats2018 dataset on these two datasets the dice of our method is 7983 and 8487 respectively the code is available at httpsgithubcomzhongqiu1245twistnet",Brain
Comparing 3D 2.5D and 2D Approaches to Brain Image Auto-Segmentation,https://doi.org/10.3390/bioengineering10020181,2023,"deeplearning methods for autosegmenting brain images either segment one slice of the image 2d five consecutive slices of the image 25d or an entire volume of the image 3d whether one approach is superior for autosegmenting brain images is not known we compared these three approaches 3d 25d and 2d across three autosegmentation models capsule networks unets and nnunets to segment brain structures we used 3430 brain mris acquired in a multiinstitutional study to train and test our models we used the following performance metrics segmentation accuracy performance with limited training data required computational memory and computational speed during training and deployment the 3d 25d and 2d approaches respectively gave the highest to lowest dice scores across all models 3d models maintained higher dice scores when the training set size was decreased from 3199 mris down to 60 mris 3d models converged 20 to 40 faster during training and were 30 to 50 faster during deployment however 3d models require 20 times more computational memory compared to 25d or 2d models this study showed that 3d models are more accurate maintain better performance with limited training data and are faster to train and deploy however 3d models require more computational memory compared to 25d or 2d models",Brain
Self-supervised Pretraining for 2D Medical Image Segmentation,https://doi.org/10.1007/978-3-031-25082-8_31,2023,"abstractsupervised machine learning provides stateoftheart solutions to a wide range of computer vision problems however the need for copious labelled training data limits the capabilities of these algorithms in scenarios where such input is scarce or expensive selfsupervised learning offers a way to lower the need for manually annotated data by pretraining models for a specific domain on unlabelled data in this approach labelled data are solely required to finetune models for downstream tasks medical image segmentation is a field where labelling data requires expert knowledge and collecting large labelled datasets is challenging therefore selfsupervised learning algorithms promise substantial improvements in this field despite this selfsupervised learning algorithms are used rarely to pretrain medical image segmentation networks in this paper we elaborate and analyse the effectiveness of supervised and selfsupervised pretraining approaches on downstream medical image segmentation focusing on convergence and data efficiency we find that selfsupervised pretraining on natural images and targetdomainspecific images leads to the fastest and most stable downstream convergence in our experiments on the acdc cardiac segmentation dataset this pretraining approach achieves 45 times faster finetuning convergence compared to an imagenet pretrained model we also show that this approach requires less than five epochs of pretraining on domainspecific data to achieve such improvement in the downstream convergence time finally we find that in lowdata scenarios supervised imagenet pretraining achieves the best accuracy requiring less than 100 annotated samples to realise close to minimal errorkeywordsselfsupervised learningmedical image segmentationpretrainingdataefficient learningcardiac mri segmentation",Cardiac
Self-supervised Pretraining for 2D Medical Image Segmentation,https://doi.org/10.1007/978-3-031-25082-8_31,2023,"abstractsupervised machine learning provides stateoftheart solutions to a wide range of computer vision problems however the need for copious labelled training data limits the capabilities of these algorithms in scenarios where such input is scarce or expensive selfsupervised learning offers a way to lower the need for manually annotated data by pretraining models for a specific domain on unlabelled data in this approach labelled data are solely required to finetune models for downstream tasks medical image segmentation is a field where labelling data requires expert knowledge and collecting large labelled datasets is challenging therefore selfsupervised learning algorithms promise substantial improvements in this field despite this selfsupervised learning algorithms are used rarely to pretrain medical image segmentation networks in this paper we elaborate and analyse the effectiveness of supervised and selfsupervised pretraining approaches on downstream medical image segmentation focusing on convergence and data efficiency we find that selfsupervised pretraining on natural images and targetdomainspecific images leads to the fastest and most stable downstream convergence in our experiments on the acdc cardiac segmentation dataset this pretraining approach achieves 45 times faster finetuning convergence compared to an imagenet pretrained model we also show that this approach requires less than five epochs of pretraining on domainspecific data to achieve such improvement in the downstream convergence time finally we find that in lowdata scenarios supervised imagenet pretraining achieves the best accuracy requiring less than 100 annotated samples to realise close to minimal errorkeywordsselfsupervised learningmedical image segmentationpretrainingdataefficient learningcardiac mri segmentation",Cardiac
Implementable Deep Learning for Multi‐sequence Proton <scp>MRI</scp> Lung Segmentation: A Multi‐center Multi‐vendor and Multi‐disease Study,https://doi.org/10.1002/jmri.28643,2023,"recently deep learning via convolutional neural networks cnns has largely superseded conventional methods for proton 1 hmri lung segmentation however previous deep learning studies have utilized singlecenter data and limited acquisition parametersdevelop a generalizable cnn for lung segmentation in 1 hmri robust to pathology acquisition protocol vendor and centerretrospectivea total of 809 1 hmri scans from 258 participants with various pulmonary pathologies median age range 57 685 42 females and 31 healthy participants median age range 34 2376 34 females that were split into training 593 scans 74 157 participants 55 testing 50 scans 6 50 participants 17 and external validation 164 scans 20 82 participants 28 sets15t and 3t3d spoiledgradient recalled and ultrashort echotime 1 hmri2d and 3d cnns trained on singlecenter multisequence data and the conventional spatial fuzzy cmeans sfcm method were compared to manually delineated expert segmentations each method was validated on external data originating from several centers dice similarity coefficient dsc average boundary hausdorff distance average hd and relative error xor metrics to assess segmentation performancekruskalwallis tests assessed significances of differences between acquisitions in the testing set friedman tests with post hoc multiple comparisons assessed differences between the 2d cnn 3d cnn and sfcm blandaltman analyses assessed agreement with manually derived lung volumes a p value of 005 was considered statistically significantthe 3d cnn significantly outperformed its 2d analog and sfcm yielding a median range dsc of 0961 08800987 average hd of 163 mm 065545 and xor of 0079 00250240 on the testing set and a dsc of 0973 08660987 average hd of 111 mm 047813 and xor of 0054 00260255 on external validation datathe 3d cnn generated accurate 1 hmri lung segmentations on a heterogenous dataset demonstrating robustness to disease pathology sequence vendor and center4stage 1",Lung
CaraNet: context axial reverse attention network for segmentation of small medical objects,https://doi.org/10.1117/1.jmi.10.1.014005,2023,"segmenting medical images accurately and reliably is important for disease diagnosis and treatment it is a challenging task because of the wide variety of objects sizes shapes and scanning modalities recently many convolutional neural networks cnn have been designed for segmentation tasks and achieved great success few studies however have fully considered the sizes of objects and thus most demonstrate poor performance for small objects segmentation this can have a significant impact on the early detection of diseases this paper proposes a context axial reverse attention network caranet to improve the segmentation performance on small objects compared with several recent stateoftheart models caranet applies axial reserve attention ara and channelwise feature pyramid cfp module to dig feature information of small medical object and we evaluate our model by six different measurement metrics we test our caranet on brain tumor brats 2018 and polyp kvasirseg cvccolondb cvcclinicdb cvc300 and etislaribpolypdb segmentation datasets our caranet achieves the toprank mean dice segmentation accuracy and results show a distinct advantage of caranet in the segmentation of small medical objects",Brain
CaraNet: context axial reverse attention network for segmentation of small medical objects,https://doi.org/10.1117/1.jmi.10.1.014005,2023,"segmenting medical images accurately and reliably is important for disease diagnosis and treatment it is a challenging task because of the wide variety of objects sizes shapes and scanning modalities recently many convolutional neural networks cnn have been designed for segmentation tasks and achieved great success few studies however have fully considered the sizes of objects and thus most demonstrate poor performance for small objects segmentation this can have a significant impact on the early detection of diseases this paper proposes a context axial reverse attention network caranet to improve the segmentation performance on small objects compared with several recent stateoftheart models caranet applies axial reserve attention ara and channelwise feature pyramid cfp module to dig feature information of small medical object and we evaluate our model by six different measurement metrics we test our caranet on brain tumor brats 2018 and polyp kvasirseg cvccolondb cvcclinicdb cvc300 and etislaribpolypdb segmentation datasets our caranet achieves the toprank mean dice segmentation accuracy and results show a distinct advantage of caranet in the segmentation of small medical objects",Brain
Histogram Matched Chest X-Rays Based Tuberculosis Detection Using CNN,https://doi.org/10.32604/csse.2023.025195,2023,"tuberculosis tb is a severe infection that mostly affects the lungs and kills millions of peoples lives every year tuberculosis can be diagnosed using chest xrays cxr and datadriven deep learning dl approaches because of its better automated feature extraction capability convolutional neural networks cnns trained on natural images are particularly effective in image categorization a combination of 3001 normal and 3001 tb cxr images was gathered for this study from different accessible public datasets ten different deep cnns resnet50 resnet101 resnet152 inceptionv3 vgg16 vgg19 densenet121 densenet169 densenet201 mobilenet are trained and tested for identifying tb and normal cases this study presents a deep cnn approach based on histogram matched cxr images that does not require object segmentation of interest and this coupled methodology of histogram matching with the cxrs improves the accuracy and detection performance of cnn models for tb detection furthermore this research contains two separate experiments that used cxr images with and without histogram matching to classify tb and nontb cxrs using deep cnns it was able to accurately detect tb from cxr images using preprocessing data augmentation and deep cnn models without histogram matching the best accuracy sensitivity specificity precision and f1score in the detection of tb using cxr images among ten models are 9925 9948 9952 9948 and 9922 respectively with histogram matching the best accuracy sensitivity specificity precision and f1score are 9958 9982 9967 9965 and 9956 respectively the proposed methodology which has cuttingedge performance will be useful in computerassisted tb diagnosis and aids in minimizing irregularities in tb detection in developing countries",Lung
Histogram Matched Chest X-Rays Based Tuberculosis Detection Using CNN,https://doi.org/10.32604/csse.2023.025195,2023,"tuberculosis tb is a severe infection that mostly affects the lungs and kills millions of peoples lives every year tuberculosis can be diagnosed using chest xrays cxr and datadriven deep learning dl approaches because of its better automated feature extraction capability convolutional neural networks cnns trained on natural images are particularly effective in image categorization a combination of 3001 normal and 3001 tb cxr images was gathered for this study from different accessible public datasets ten different deep cnns resnet50 resnet101 resnet152 inceptionv3 vgg16 vgg19 densenet121 densenet169 densenet201 mobilenet are trained and tested for identifying tb and normal cases this study presents a deep cnn approach based on histogram matched cxr images that does not require object segmentation of interest and this coupled methodology of histogram matching with the cxrs improves the accuracy and detection performance of cnn models for tb detection furthermore this research contains two separate experiments that used cxr images with and without histogram matching to classify tb and nontb cxrs using deep cnns it was able to accurately detect tb from cxr images using preprocessing data augmentation and deep cnn models without histogram matching the best accuracy sensitivity specificity precision and f1score in the detection of tb using cxr images among ten models are 9925 9948 9952 9948 and 9922 respectively with histogram matching the best accuracy sensitivity specificity precision and f1score are 9958 9982 9967 9965 and 9956 respectively the proposed methodology which has cuttingedge performance will be useful in computerassisted tb diagnosis and aids in minimizing irregularities in tb detection in developing countries",Lung
Brain Tumor Segmentation through Level Based Learning Model,https://doi.org/10.32604/csse.2023.024295,2023,"brain tumors are potentially fatal presence of cancer cells over a human brain and they need to be segmented for accurate and reliable planning of diagnosis segmentation process must be carried out in different regions based on which the stages of cancer can be accurately derived glioma patients exhibit a different level of challenge in terms of cancer or tumors detection as the magnetic resonance imaging mri images possess varying sizes shapes positions and modalities the scanner used for sensing the location of tumors cells will be subjected to additional protocols and measures for accuracy in turn increasing the time and affecting the performance of the entire model in this view convolutional neural networks deliver suitable models for efficient segmentation and thus delivered promising results the previous strategies and models failed to adhere to diversity of sizes and shapes proving to be a wellestablished solution for detecting tumors of bigger size tumors tend to be smaller in size and shape during their premature stages and they can easily evade the algorithms of convolutional neural network cnn this proposal intends to furnish a detailed model for sensing early stages of cancer and hence perform segmentation irrespective of the current size and shape of tumors the size of networks and layers will lead to a significant weightage when multiple kernel sizes are involved especially in multiresolution environments on the other hand the proposed model is designed with a novel approach including a dilated convolution and levelbased learning strategy when the convolution process is dilated the process of feature extraction deals with multiscale objective and levelbased learning eliminates the shortcoming of previous models thereby enhancing the quality of smaller tumors cells and shapes the levelbased learning approach also encapsulates the feature reconstruction processes which highlights the sensing of smallscale tumors growth inclusively segmenting the images is performed with better accuracy and hence detection becomes better when compared to that of hierarchical approaches",Brain
A Novel Handcrafted with Deep Features Based Brain Tumor Diagnosis Model,https://doi.org/10.32604/iasc.2023.029602,2023,"in healthcare sector image classification is one of the crucial problems that impact the quality output from image processing domain the purpose of image classification is to categorize different healthcare images under various class labels which in turn helps in the detection and management of diseases magnetic resonance imaging mri is one of the effective noninvasive strategies that generate a huge and distinct number of tissue contrasts in every imaging modality this technique is commonly utilized by healthcare professionals for brain tumor bt diagnosis with recent advancements in machine learning ml and deep learning dl models it is possible to detect the tumor from images automatically using a computeraided design the current study focuses on the design of automated deep learningbased bt detection and classification model using mri images dlbtdcmri the proposed dlbtdcmri technique aims at detecting and classifying different stages of bt the proposed dlbtdcmri technique involves median filtering technique to remove the noise and enhance the quality of mri images besides morphological operationsbased image segmentation approach is also applied to determine the btaffected regions in brain mri image moreover a fusion of handcrafted deep features using vggnet is utilized to derive a valuable set of feature vectors finally artificial fish swarm optimization afso with artificial neural network ann model is utilized as a classifier to decide the presence of bt in order to assess the enhanced bt classification performance of the proposed model a comprehensive set of simulations was performed on benchmark dataset and the results were validated under several measures",Brain
Enhanced Long Short Term Memory for Early Alzheimer's Disease Prediction,https://doi.org/10.32604/iasc.2023.025591,2023,"the most noteworthy neurodegenerative disorder nationwide is apparently the alzheimers disease ad which ha no proven viable treatment till date and despite the clinical trials showing the potential of preclinical therapy a sensitive method for evaluating the ad has to be developed yet due to the correlations between ocular and brain tissue the eye retinal blood vessels has been investigated for predicting the ad hence en enhanced method named enhanced long short term memory elstm has been proposed in this work which aims at finding the severity of ad from ocular biomarkers to find the level of disease severity the new layer named precise layer was introduced in elstm which will help the doctors to provide the apt treatments for the patients rapidly to avoid the problem of overfitting a dropout has been added to lstm in the existing work boundary detection of retinal layers was found to be inaccurate during the segmentation process of optical coherence tomography oct image and to overcome this issue particle swarm optimization pso has been utilized to the best of our understanding this is the first paper to use particle swarm optimization when compared with the existing works the proposed work is found to be performing better in terms of f1 score precision recall training loss and segmentation accuracy and it is found that the prediction accuracy was increased to 10 higher than the existing systems",Brain
A Novel Segment White Matter Hyperintensities Approach for Detecting Alzheimer,https://doi.org/10.32604/csse.2023.026582,2023,"segmentation has been an effective step that needs to be done before the classification or detection of an anomaly like alzheimers on a brain scan segmentation helps detect pixels of the same intensity or volume and group them together as one class or region where in that particular region of interest roi can be concentrated on rather than focusing on the entire image in this paper white matter hyperintensities wmh is taken as a strong biomarker that supports and determines the presence of alzheimers as the first step a proper segmentation of the lesions has to be carried out as pointed out in various other research papers when the wmh area is very small or in places like the septum pellucidum the detection of the lesion is hard to find to overcome such problem areas a very optimized and accurate threshold would be required to have a precise segmentation to detect the area of localization this would help in proper detection and classification of the anomaly in this paper an elaborate comparison of various thresholding techniques has been done for segmentation a novel idea for detection of alzheimers has been presented in this paper which encompasses the effectiveness of an optimized and adaptive technique the unet architecture has been taken as the baseline model with an adaptive kernel model embedded within the architecture various stateoftheart technologies have been used with the dataset and a comparative study has been presented with the current architecture used in the paper the lesion segmentation in narrow areas has accurately been detected compared to the other models and the number of false positives has been reduced to a great extent",Brain
Enhanced Feature Fusion Segmentation for Tumor Detection Using Intelligent Techniques,https://doi.org/10.32604/iasc.2023.030667,2023,"in the field of diagnosis of medical images the challenge lies in tracking and identifying the defective cells and the extent of the defective region within the complex structure of a brain cavity locating the defective cells precisely during the diagnosis phase helps to fight the greatest exterminator of mankind early detection of these defective cells requires an accurate computeraided diagnostic system cad that supports early treatment and promotes survival rates of patients an earlier version of cad systems relies greatly on the expertise of radiologist and it consumed more time to identify the defective region the manuscript takes the efficacy of coalescing features like intensity shape and texture of the magnetic resonance image mri in the enhanced feature fusion segmentation based classification method eefs the image is enhanced and segmented to extract the prominent features to bring out the desired effect the eefs method uses enhanced local binary pattern enlbp partisan gray level cooccurrence matrix histogram of oriented gradients pglcmhog and igrab cut method to segment image these prominent features along with deep features are coalesced to provide a singledimensional feature vector that is effectively used for prediction the coalesced vector is used with the existing classifiers to compare the results of these classifiers with that of the generated vector the generated vector provides promising results with commendably less computatio nal time for preprocessing and classification of mr medical images",Brain
Brain Tumor Classification Using Image Fusion and EFPA-SVM Classifier,https://doi.org/10.32604/iasc.2023.030144,2023,"an accurate and early diagnosis of brain tumors based on medical imaging modalities is of great interest because brain tumors are a harmful threat to a persons health worldwide several medical imaging techniques have been used to analyze brain tumors including computed tomography ct and magnetic resonance imaging mri ct provides information about dense tissues whereas mri gives information about soft tissues however the fusion of ct and mri images has little effect on enhancing the accuracy of the diagnosis of brain tumors therefore machine learning methods have been adopted to diagnose brain tumors in recent years this paper intends to develop a novel scheme to detect and classify brain tumors based on fused ct and mri images the proposed approach starts with preprocessing the images to reduce the noise then fusion rules are applied to get the fused image and a segmentation algorithm is employed to isolate the tumor region from the background to isolate the tumor region finally a machine learning classifier classified the brain images into benign and malignant tumors computing statistical measures evaluate the classification potential of the proposed scheme experimental outcomes are provided and the enhanced flower pollination algorithm efpa system shows that it outperforms other brain tumor classification methods considered for comparison",Brain
Segmentation of lung cancer-caused metastatic lesions in bone scan images using self-defined model with deep supervision,https://doi.org/10.1016/j.bspc.2022.104068,2023,"automated segmentation of lesions metastasized from lung cancer in thorax is first studied with spect bone scan images a view aggregation method is developed to enhance the areas within a spect image that may denote the metastatic lesions a selfdefined endtoend segmentation network is proposed by introducing deep supervision into the encoderdecoder network to automatically identify and delineate metastatic lesions extensive experiments conducted on clinical spect bone scan images show the proposed models feasibility and superiority as compared to the classical image segmentation models to automatically identify and delineate metastatic lesions in lowresolution bone scan images we propose a deep learningbased segmentation method in this paper in particular the view aggregation in this method uses a pixelwise addition to enhance the regions with high uptake of the radiopharmaceutical the operation of view aggregation augments images for the lesion segmentation task by following the structure of the encoderdecoder with deep supervision our model is an endtoend segmentation network that consists of two subnetworks of feature extraction and pixel classification as such the hieratical features of bone scan images can be learned by the feature extraction subnetwork the pixels in metastasis areas within a feature map are then identified and delineated by the pixel classification subnetwork the results of experiments on clinical bone scan images show that the proposed model performs well in segmenting metastatic lesions automatically obtaining a mean score of 06556 on dsc dice similarity coefficient however more bone scan images enable our model to learn better representative features of metastatic lesions for further improving the performance of deep learningbased lesion segmentation",Lung
An efficient R-Transformer network with dual encoders for brain glioma segmentation in MR images,https://doi.org/10.1016/j.bspc.2022.104034,2023,"we propose a rtransformer network to achieve precise brain tumor segmentation by combining rtransformer with unet ertn employs the ranking attention mechanism which helps the model improve training efficiency and reduce computation cost ertn can provide higher brain tumor segmentation accuracy than the cnns or transformers based methods gliomas are the most prevalent and destructive forms of primary brain tumors with a high mortality rate magnetic resonance imaging is extensively employed in the examination of gliomas segmenting brain glioma on magnetic resonance images has significant clinical value however the blur boundary of gliomas variability in the shape location and size make segmentation extremely challenging in this paper we propose a new method to segment gliomas from threedimensional brain magnetic resonance images accurately we propose an efficient rtransformer network with dual encoders ertn to achieve precise segmentation by innovatively combining rtransformer with unet specifically ertn constructs a feature branch and a patch branch capturing complex semantic features and global context information moreover features generated from the feature branch and patch branch are upsampled and combined with low and highresolution cnn features in the decoder to enable precise localization at last ertn employs the ranking attention mechanism in transformer rtransformer which helps the model focus on helpful information to improve training efficiency and reduce computation cost experiments on the 2017 brats dataset prove that ertn achieves satisfactory performance with a dice similarity coefficient of 8320 7793 and 7259 on the whole tumor tumor core and enhanced tumor segmentation for the hausdorff distance index we obtained the scores of 530 460 and 550 for the whole tumor tumor core and enhanced tumor respectively our results suggest that ertn improves the segmentation accuracy and reduces computation cost which performs better than the existing convolution and transformerbased methods",Brain
An efficient R-Transformer network with dual encoders for brain glioma segmentation in MR images,https://doi.org/10.1016/j.bspc.2022.104034,2023,"we propose a rtransformer network to achieve precise brain tumor segmentation by combining rtransformer with unet ertn employs the ranking attention mechanism which helps the model improve training efficiency and reduce computation cost ertn can provide higher brain tumor segmentation accuracy than the cnns or transformers based methods gliomas are the most prevalent and destructive forms of primary brain tumors with a high mortality rate magnetic resonance imaging is extensively employed in the examination of gliomas segmenting brain glioma on magnetic resonance images has significant clinical value however the blur boundary of gliomas variability in the shape location and size make segmentation extremely challenging in this paper we propose a new method to segment gliomas from threedimensional brain magnetic resonance images accurately we propose an efficient rtransformer network with dual encoders ertn to achieve precise segmentation by innovatively combining rtransformer with unet specifically ertn constructs a feature branch and a patch branch capturing complex semantic features and global context information moreover features generated from the feature branch and patch branch are upsampled and combined with low and highresolution cnn features in the decoder to enable precise localization at last ertn employs the ranking attention mechanism in transformer rtransformer which helps the model focus on helpful information to improve training efficiency and reduce computation cost experiments on the 2017 brats dataset prove that ertn achieves satisfactory performance with a dice similarity coefficient of 8320 7793 and 7259 on the whole tumor tumor core and enhanced tumor segmentation for the hausdorff distance index we obtained the scores of 530 460 and 550 for the whole tumor tumor core and enhanced tumor respectively our results suggest that ertn improves the segmentation accuracy and reduces computation cost which performs better than the existing convolution and transformerbased methods",Brain
Inner Cascaded U2-Net: An Improvement to Plain Cascaded U-Net,https://doi.org/10.32604/cmes.2022.020428,2023,"deep neural networks are now widely used in the medical image segmentation field for their performance superiority and no need of manual feature extraction unet has been the baseline model since the very beginning due to a symmetrical ustructure for better feature extraction and fusing and suitable for small datasets to enhance the segmentation performance of unet cascaded unet proposes to put two unets successively to segment targets from coarse to fine however the plain cascaded unet faces the problem of too less between connections so the contextual information learned by the former unet cannot be fully used by the latter one in this article we devise novel inner cascaded unet and inner cascaded u2net as improvements to plain cascaded unet for medical image segmentation the proposed inner cascaded unet adds inner nested connections between two unets to share more contextual information to further boost segmentation performance we propose inner cascaded u2net which applies residual ublock to capture more global contextual information from different scales the proposed models can be trained from scratch in an endtoend fashion and have been evaluated on multimodal brain tumor segmentation challenge brats 2013 and isbi liver tumor segmentation challenge lits dataset in comparison to related unet cascaded unet unet u2net and stateoftheart methods our experiments demonstrate that our proposed inner cascaded unet and inner cascaded u2net achieve better segmentation performance in terms of dice similarity coefficient and hausdorff distance as well as get finer outline segmentation",Brain
Inner Cascaded U2-Net: An Improvement to Plain Cascaded U-Net,https://doi.org/10.32604/cmes.2022.020428,2023,"deep neural networks are now widely used in the medical image segmentation field for their performance superiority and no need of manual feature extraction unet has been the baseline model since the very beginning due to a symmetrical ustructure for better feature extraction and fusing and suitable for small datasets to enhance the segmentation performance of unet cascaded unet proposes to put two unets successively to segment targets from coarse to fine however the plain cascaded unet faces the problem of too less between connections so the contextual information learned by the former unet cannot be fully used by the latter one in this article we devise novel inner cascaded unet and inner cascaded u2net as improvements to plain cascaded unet for medical image segmentation the proposed inner cascaded unet adds inner nested connections between two unets to share more contextual information to further boost segmentation performance we propose inner cascaded u2net which applies residual ublock to capture more global contextual information from different scales the proposed models can be trained from scratch in an endtoend fashion and have been evaluated on multimodal brain tumor segmentation challenge brats 2013 and isbi liver tumor segmentation challenge lits dataset in comparison to related unet cascaded unet unet u2net and stateoftheart methods our experiments demonstrate that our proposed inner cascaded unet and inner cascaded u2net achieve better segmentation performance in terms of dice similarity coefficient and hausdorff distance as well as get finer outline segmentation",Brain
Automatic 3D mitral valve leaflet segmentation and validation of quantitative measurement,https://doi.org/10.1016/j.bspc.2022.104166,2023,"3d transesophageal echocardiography tee is widely used in the diagnosis of mitral valve disease and is also well suited for guiding cardiac interventions the aim of this work is to achieve patientspecific 3d tee mitral valve leaflet segmentation without any user interaction and to assess the feasibility of 3d quantitative measurements on automatic segmentation model we suggested a novel pretraining strategy to better implement automatic segmentation the strategy refers to classify the diastolic and systolic states of the mitral valve through a 3d convolutional neural network architecture and then use the pretrained weights obtained from the classification task to initialize the parameters of the 3d segmentation deep learning framework to determine the accuracy of geometric parameters of segmentation model the measurements of the segmentation model were compared with those obtained by the clinical software statistical analysis was performed by using intraclass correlation coefficient and blandaltman method fourteen 3d volumes were used to evaluate the segmentation performance the results show a dice similarity coefficient dsc of 08770027 and an average surface distance asd of 09250392 mm twentyeight 3d volumes were used for the quantitative measurement the statistical results show that the mitral annular parameters have a good agreement between segmentation model and clinical software except for the annular height we developed a fully automatic methodology to segment the mitral valve leaflet from 3d tee and demonstrated the feasibility of improving segmentation performance with the proposed pretraining strategy the automatic segmentation model was proved to be reliable for performing quantitative measurements of mitral valve annulus dimensions the results indicate that the precision of the automatic segmentation methodology could pave the way for application in quantification modeling and surgical planning tools",Cardiac
Detection of Left Ventricular Cavity from Cardiac MRI Images Using Faster R-CNN,https://doi.org/10.32604/cmc.2023.031900,2023,"the automatic localization of the left ventricle lv in shortaxis magnetic resonance mr images is a required step to process cardiac images using convolutional neural networks for the extraction of a region of interest roi the precise extraction of the lvs roi from cardiac mri images is crucial for detecting heart disorders via cardiac segmentation or registration nevertheless this task appears to be intricate due to the diversities in the size and shape of the lv and the scattering of surrounding tissues across different slices thus this study proposed a regionbased convolutional network faster rcnn for the lv localization from shortaxis cardiac mri images using a region proposal network rpn integrated with deep feature classification and regression the model was trained using images with corresponding bounding boxes labels around the lv and various experiments were applied to select the appropriate layers and set the suitable hyperparameters the experimental findings show that the proposed model was adequate with accuracy precision recall and f1 score values of 091 094 095 and 095 respectively this model also allows the cropping of the detected area of lv which is vital in reducing the computational cost and time during segmentation and classification procedures therefore it would be an ideal model and clinically applicable for diagnosing cardiac diseases",Cardiac
A U-Net-Based CNN Model for Detection and Segmentation of Brain Tumor,https://doi.org/10.32604/cmc.2023.031695,2023,"human brain consists of millions of cells to control the overall structure of the human body when these cells start behaving abnormally then brain tumors occurred precise and initial stage brain tumor detection has always been an issue in the field of medicines for medical experts to handle this issue various deep learning techniques for brain tumor detection and segmentation techniques have been developed which worked on different datasets to obtain fruitful results but the problem still exists for the initial stage of detection of brain tumors to save human lives for this purpose we proposed a novel unetbased convolutional neural network cnn technique to detect and segmentizes the brain tumor for magnetic resonance imaging mri moreover a 2dimensional publicly available multimodal brain tumor image segmentation brats2020 dataset with 1840 mri images of brain tumors has been used having an image size of 240 240 pixels after initial dataset preprocessing the proposed model is trained by dividing the dataset into three parts ie testing training and validation process our model attained an accuracy value of 098 on the brats2020 dataset which is the highest one as compared to the already existing techniques",Brain
A U-Net-Based CNN Model for Detection and Segmentation of Brain Tumor,https://doi.org/10.32604/cmc.2023.031695,2023,"human brain consists of millions of cells to control the overall structure of the human body when these cells start behaving abnormally then brain tumors occurred precise and initial stage brain tumor detection has always been an issue in the field of medicines for medical experts to handle this issue various deep learning techniques for brain tumor detection and segmentation techniques have been developed which worked on different datasets to obtain fruitful results but the problem still exists for the initial stage of detection of brain tumors to save human lives for this purpose we proposed a novel unetbased convolutional neural network cnn technique to detect and segmentizes the brain tumor for magnetic resonance imaging mri moreover a 2dimensional publicly available multimodal brain tumor image segmentation brats2020 dataset with 1840 mri images of brain tumors has been used having an image size of 240 240 pixels after initial dataset preprocessing the proposed model is trained by dividing the dataset into three parts ie testing training and validation process our model attained an accuracy value of 098 on the brats2020 dataset which is the highest one as compared to the already existing techniques",Brain
Precise Multi-Class Classification of Brain Tumor via Optimization Based Relevance Vector Machine,https://doi.org/10.32604/iasc.2023.029959,2023,"the objective of this research is to examine the use of feature selection and classification methods for distinguishing different types of brain tumors the brain tumor is characterized by an anomalous proliferation of brain cells that can either be benign or malignant most tumors are misdiagnosed due to the variability and complexity of lesions which reduces the survival rate in patients diagnosis of brain tumors via computer vision algorithms is a challenging task segmentation and classification of brain tumors are currently one of the most essential surgical and pharmaceutical procedures traditional brain tumor identification techniques require manual segmentation or handcrafted feature extraction that is errorprone and timeconsuming hence the proposed research work is mainly focused on medical image processing which takes magnetic resonance imaging mri images as input and performs preprocessing segmentation feature extraction feature selection similarity measurement and classification steps for identifying brain tumors initially the median filter is practically applied to the input image to reduce the noise the graphcut segmentation technique is used to segment the tumor region the texture feature is extracted from the output of the segmented image the extracted feature is selected by using the ant colony optimization aco algorithm to improve the performance of the classifier this probabilistic approach is used to solve computing issues the euclidean distance is used to calculate the degree of similarity for each extracted feature the selected feature value is given to the relevance vector machine rvm which is a multiclass classification technique finally the tumor is classified as abnormal or normal the experimental result reveals that the proposed rvm technique gives a better accuracy range of 9887 when compared to the traditional support vector machine svm technique",Brain
Enhanced Detection of Cerebral Atherosclerosis Using Hybrid Algorithm of Image Segmentation,https://doi.org/10.32604/iasc.2023.025919,2023,"in medical science for envisaging human bodys phenomenal structure a major part has been driven by image processing techniques major objective of this work is to detect of cerebral atherosclerosis for image segmentation application detection of some abnormal structures in human body has become a difficult task to complete with some simple images for expounding and distinguishing neural architecture of human brain in an effective manner mri magnetic resonance imaging is one of the most suitable and significant technique here we work on detection of cerebral atherosclerosis from mri images of patients cerebral atherosclerosis is a cerebral vascular disease causes narrowing of the arteries due to buildup of fatty plaque inside the blood vessels of the brain it leads to ischemic stroke if not diagnosed early stroke affects majorly old age people and percentage of affected women is more compared to men results preprocessing is done by using alpha trimmed mean filter which is used to remove noise and also it enhances the image segmentation of cerebral atherosclerosis is done by using kmeans clustering contextual clustering and proposed hybrid algorithm various parameters like correlation pixel density energy is determined and from the analysis of parameters it is determined that proposed hybrid algorithm is efficient",Brain
DSCA-Net: A depthwise separable convolutional neural network with attention mechanism for medical image segmentation,https://doi.org/10.3934/mbe.2023017,2023,"accurate segmentation is a basic and crucial step for medical image processing and analysis in the last few years unet and its variants have become widely adopted models in medical image segmentation tasks however the multiple training parameters of these models determines high computation complexity which is impractical for further applications in this paper by introducing depthwise separable convolution and attention mechanism into ushaped architecture we propose a novel lightweight neural network dscanet for medical image segmentation three attention modules are created to improve its segmentation performance firstly pooling attention pa module is utilized to reduce the loss of consecutive downsampling operations secondly for capturing critical context information based on attention mechanism and convolution operation we propose context attention ca module instead of concatenation operations finally multiscale edge attention mea module is used to emphasize multilevel representative scale edge features for final prediction the number of parameters in our network is 22 m which is 716 less than unet experiment results across four public datasets show the potential and the dice coefficients are improved by 549 for isic 2018 428 for thyroid 161 for lung and 931 for nuclei compared with unet",Lung
Lung parenchyma segmentation based on semantic data augmentation and boundary attention consistency,https://doi.org/10.1016/j.bspc.2022.104205,2023,"propose an automatic accurate deep learning segmentation approach applied to the lung parenchyma preprocess the ct image and fill the regions outside thoracic cavity to improve the contrast of the lung parenchyma change the regions of original image inside and outside lung parenchyma to generate new training images propose a novel boundary attention consistency to further enhance the attention to lung boundary and output fine boundary choose the unet network as the baseline model of lung segmentation the paper proposes an automatic accurate deep learning segmentation approach applied to the lung parenchyma in this way we adopt a set of strategies to produce fine and accurate segmentation firstly we preprocess the image and fill the regions outside thoracic cavity to improve the contrast of the lung parenchyma then we use semantic data augmentation to get more effective dataset specially we change the regions of original image inside and outside lung parenchyma except for boundary to generate new training images and preserve the invariance of lung boundary furthermore we propose a novel boundary attention consistency to further enhance the attention to lung boundary and promote network to output fine boundary we choose the unet network as the baseline model of lung segmentation and apply above strategies to train it the effectiveness of every component of proposed segmentation method is confirmed by ablation experiments and the superiority of the proposed segmentation method is fully verified by comparing with other existing segmentation methods",Lung
IHA-Net: An automatic segmentation framework for computer-tomography of tiny intracerebral hemorrhage based on improved attention U-net,https://doi.org/10.1016/j.bspc.2022.104320,2023,"a novel endtoend model is proposed which can work well on tiny ich segmentation configuring rhac modules with different atrous rates at different encoder stages the multiobject function is utilized to handle the imbalance problem of pixels intermediate supervision is employed to facilitate better segmentation performance experiments of ich segmentation on internal testing data and external clinical data intracerebral hemorrhage ich is a serious category of head injury which means bleeding occurs inside the skull and in many cases leads to a high disability or mortality therefore accurate and rapid hematoma region segmentation is of great significance for ich diagnosis and treatment nevertheless even with a powerful deep neural network there are still certain limitations in the case of tiny ich regions in this paper a novel model based on convolutional neural network for the segmentation of hematoma regions in brain computed tomography images of patients with ich is developed specifically in order to prevent the degradation of tiny lesion regions due to repeated downsampling we also proposed a residual hybrid atrous convolution strategy furthermore a multiobject function for joint optimization is introduced to ease the severe pixel imbalanced problem which is of benefit to training procedure in addition to avoid gradient disappearance and slow convergence intermediate supervision with a lightweight head is utilized during the training the performance of developed segmentation algorithm for intracranial hemorrhage is analyzed by using dice coefficient jaccard index sensitivity and accuracy from both quantitative and visual results we found that the proposed model outperformed the previous methods and achieved a satisfying segmentation performance for intracranial hemorrhage test in both internal testing data dice of 0725 jaccard of 0605 and external clinical data dice of 0869 jaccard of 0774 which indicates that proposed model has better segmentation effect and potential clinical prospect",Brain
An Interpretable CNN for the Segmentation of the Left Ventricle in Cardiac MRI by Real-Time Visualization,https://doi.org/10.32604/cmes.2022.023195,2023,"the interpretability of deep learning models has emerged as a compelling area in artificial intelligence research the safety criteria for medical imaging are highly stringent and models are required for an explanation however existing convolutional neural network solutions for left ventricular segmentation are viewed in terms of inputs and outputs thus the interpretability of cnns has come into the spotlight since medical imaging data are limited many methods to finetune medical imaging models that are popular in transfer models have been built using massive public imagenet datasets by the transfer learning method unfortunately this generates many unreliable parameters and makes it difficult to generate plausible explanations from these models in this study we trained from scratch rather than relying on transfer learning creating a novel interpretable approach for autonomously segmenting the left ventricle with a cardiac mri our enhanced gpu training system implemented interpretable global average pooling for graphics using deep learning the deep learning tasks were simplified simplification included data management neural network architecture and training our system monitored and analyzed the gradient changes of different layers with dynamic visualizations in realtime and selected the optimal deployment model our results demonstrated that the proposed method was feasible and efficient the dice coefficient reached 9448 and the accuracy reached 997 it was found that no current transfer learning models could perform comparably to the imagenet transfer learning architectures this model is lightweight and more convenient to deploy on mobile devices than transfer learning models",Cardiac
Fusion Strategy for Improving Medical Image Segmentation,https://doi.org/10.32604/cmc.2023.027606,2023,"in this paper we combine decision fusion methods with four metaheuristic algorithms particle swarm optimization pso algorithm cuckoo search algorithm modification of cuckoo search cs mcculloch algorithm and genetic algorithm in order to improve the image segmentation the proposed technique based on fusing the data from particle swarm optimization pso cuckoo search modification of cuckoo search cs mcculloch and genetic algorithms are obtained for improving magnetic resonance images mris segmentation four algorithms are used to compute the accuracy of each method while the outputs are passed to fusion methods in order to obtain parts of the points that determine similar membership values we apply the different rules of incorporation for these groups the proposed approach is applied to challenging applications mri images gray matterwhite matter of brain segmentations and original blackwhite images behavior of the proposed algorithm is provided by applying to different medical images it is shown that the proposed method gives accurate results due to the decision fusion produces the greatest improvement in classification accuracy",Brain
Two-stage training strategy combined with neural network for segmentation of internal mammary artery graft,https://doi.org/10.1016/j.bspc.2022.104278,2023,"cardiovascular disease is a major health condition affecting the global population leading to 420 million diagnoses and nearly 20 million deaths annually coronary heart disease is one of the most prevalent cardiovascular diseases and its diagnosis and treatment creates a large social and economic burden necessitating a large number of imaging evaluations and repetitive manual assessments by expert radiologists recently deep learningbased methods have demonstrated excellent performance in coronary artery recognition coronary artery segmentation and centerline extraction etc however current research focuses on cta and mri data types and for inexperienced cardiologists even if the neural network gives accurate segmentation results it is impossible to determine its specific location in the heart in response to the above problems we constructed a novel dataset cardiacvessel which contains 2d slices from cta images through 3d reconstruction techniques and performed pixellevel annotations of vessels we then propose a simple and effective twostage training strategy for internal mammary artery graft segmentation we conduct extensive experiments to compare the performance of various cnn and transformerbased network architectures the proposed twostage training strategy can significantly improve network performance we constructed a cardiovascular dataset for internal mammary artery bridge segmentation we propose a twostage training strategy to train the neural network which can significantly improve the segmentation performance of internal mammary artery bridges we conduct extensive experiments including cnnbased and transformerbased networks which can fully demonstrate the effectiveness of the strategy",Cardiac
Brain Tumor: Hybrid Feature Extraction Based on UNet and 3DCNN,https://doi.org/10.32604/csse.2023.032488,2023,"automated segmentation of brain tumors using magnetic resonance imaging mri data is critical in the analysis and monitoring of disease development as a result gliomas are aggressive and diverse tumors that may be split into intratumoral groups by using effective and accurate segmentation methods it is intended to extract characteristics from an image using the gray level cooccurrence glc matrix feature extraction method described in the proposed work using convolutional neural networks cnns which are commonly used in biomedical image segmentation cnns have significantly improved the precision of the stateoftheart segmentation of a brain tumor using two segmentation networks a unet and a 3d cnn we present a major yet easy combinative technique that results in improved and more precise estimates the unet and 3d cnn are used together in this study to get better and more accurate estimates of what is going on using the dataset two models were developed and assessed to provide segmentation maps that differed fundamentally in terms of the segmented tumour subregion then the estimates was made by two separate models that were put together to produce the final prediction in comparison to current stateoftheart designs the precision percentage was 9835 985 and 994 on the validation set for tumor core enhanced tumor and whole tumor respectively",Brain
Improved Model for Genetic Algorithm-Based Accurate Lung Cancer Segmentation and Classification,https://doi.org/10.32604/csse.2023.029169,2023,"lung cancer is one of the hazardous diseases that have to be detected in earlier stages for providing better treatment and clinical support to patients for lung cancer diagnosis the computed tomography ct scan images are to be processed with image processing techniques and effective classification process is required for appropriate cancer diagnosis in present scenario of medical data processing the cancer detection process is very time consuming and exactitude for that this paper develops an improved model for lung cancer segmentation and classification using genetic algorithm in the model the input ct images are preprocessed with the filters called adaptive median filter and average filter the filtered images are enhanced with histogram equalization and the roiregions of interest cancer tissues are segmented using guaranteed convergence particle swarm optimization technique for classification of images probabilistic neural networks pnn based classification is used the experimentation is carried out by simulating the model in matlab with the input ct lung images lidcidri lung image database consortiumimage database resource initiative benchmark dataset the results ensure that the proposed model outperforms existing methods with accurate classification results with minimal processing time",Lung
The multimodal MRI brain tumor segmentation based on AD-Net,https://doi.org/10.1016/j.bspc.2022.104336,2023,"multimodal glioma images provide different features of tumor boundaries based on magnetic resonance imaging mri where multimodal features are often challenging to extract for deep learning segmentation methods disturbance between features of different modes is an important factor restricting multimodal learning to efficiently extract multimodal features we propose an automatic weighted dilated convolutional network adnet to learn multimodal brain tumor features through channel feature separation learning specifically the autoweight dilated convolutional unit ad unit utilizes dualscale convolutional feature maps to acquire channel separation features we employ two learnable parameters to fuse dualscale convolutional feature maps in encoding layers and the two learnable parameters are automatically adjusted with the back propagation of the gradient we adopt the jensenshannon divergence to constrain the distribution of its feature map which in turn regularizes the weights of the entire downsampling in addition we use the training technique of deep supervision to achieve fast fitting our proposed method got dice scores of 090 080 and 076 for the whole tumor wt the tumor core tc and the enhancing tumor et on the brats20 dataset the experimental results showed good performance with the adnet network we apply the dilated convolution with a dualsized kernel to expand the receptive field of convolution and fuse the features to build the autoweight dilated network we use densely stacked grouping convolution to reduce the number of model parameters and speed up training we adopt jensenshannon divergence to constrain the distribution of its feature map which in turn regularizes the weights of the entire downsampling we use the training technique of deep supervision add additional loss calculation and update the weight of the encoding layer with an additional gradient to achieve the purpose of fast fitting",Brain
The multimodal MRI brain tumor segmentation based on AD-Net,https://doi.org/10.1016/j.bspc.2022.104336,2023,"multimodal glioma images provide different features of tumor boundaries based on magnetic resonance imaging mri where multimodal features are often challenging to extract for deep learning segmentation methods disturbance between features of different modes is an important factor restricting multimodal learning to efficiently extract multimodal features we propose an automatic weighted dilated convolutional network adnet to learn multimodal brain tumor features through channel feature separation learning specifically the autoweight dilated convolutional unit ad unit utilizes dualscale convolutional feature maps to acquire channel separation features we employ two learnable parameters to fuse dualscale convolutional feature maps in encoding layers and the two learnable parameters are automatically adjusted with the back propagation of the gradient we adopt the jensenshannon divergence to constrain the distribution of its feature map which in turn regularizes the weights of the entire downsampling in addition we use the training technique of deep supervision to achieve fast fitting our proposed method got dice scores of 090 080 and 076 for the whole tumor wt the tumor core tc and the enhancing tumor et on the brats20 dataset the experimental results showed good performance with the adnet network we apply the dilated convolution with a dualsized kernel to expand the receptive field of convolution and fuse the features to build the autoweight dilated network we use densely stacked grouping convolution to reduce the number of model parameters and speed up training we adopt jensenshannon divergence to constrain the distribution of its feature map which in turn regularizes the weights of the entire downsampling we use the training technique of deep supervision add additional loss calculation and update the weight of the encoding layer with an additional gradient to achieve the purpose of fast fitting",Brain
Lesion detection of chest X-Ray based on scalable attention residual CNN,https://doi.org/10.3934/mbe.2023079,2023,"ltabstractgtltpgtmost of the research on disease recognition in chest xrays is limited to segmentation and classification but the problem of inaccurate recognition in edges and small parts makes doctors spend more time making judgments in this paper we propose a lesion detection method based on a scalable attention residual cnn sarcnn which uses target detection to identify and locate diseases in chest xrays and greatly improves work efficiency we designed a multiconvolution feature fusion block mffb treestructured aggregation module tsam and scalable channel and spatial attention scsa which can effectively alleviate the difficulties in chest xray recognition caused by single resolution weak communication of features of different layers and lack of attention fusion respectively these three modules are embeddable and can be easily combined with other networks through a large number of experiments on the largest public lung chest radiograph detection dataset vindrcxr the mean average precision map of the proposed method was improved from 1283 to 1575 in the case of the pascal voc 2010 standard with iou ampgt 04 which exceeds the existing mainstream deep learning model in addition the proposed model has a lower complexity and faster reasoning speed which is conducive to the implementation of computeraided systems and provides referential solutions for relevant communitiesltpgtltabstractgt",Lung
Improved accuracy of auto-segmentation of organs at risk in radiotherapy planning for nasopharyngeal carcinoma based on fully convolutional neural network deep learning,https://doi.org/10.1016/j.oraloncology.2022.106261,2023,"we examined a modified encoderdecoder architecturebased fully convolutional neural network organnet for simultaneous autosegmentation of 24 organs at risk oars in the head and neck followed by validation tests and evaluation of clinical applicationcomputed tomography ct images from 310 radiotherapy plans were used as the experimental data set of which 260 and 50 were used as the training and test sets respectively an improved unet architecture was established by introducing a batch normalization layer residual squeezeandexcitation layer and unique organspecific loss function for deep learning training the performance of the trained network model was evaluated by comparing the manualdelineation and the staple contour of 10 physicians from different centersour model achieved good segmentation in all 24 oars in nasopharyngeal cancer radiotherapy plan ct images with an average dice similarity coefficient of 8375 specifically the mean dice coefficients in largevolume organs brainstem spinal cord leftright parotid glands leftright temporal lobes and leftright mandibles were 8497 9500 and in smallvolume organs pituitary lens optic nerve and optic chiasma were 5546 9156 respectively using the staple contours as standard contour the organnet achieved comparable or better dice in organ segmentation then that of the manualdelineation as wellthe established organnet enables simultaneous automatic segmentation of multiple targets on ct images of the head and neck radiotherapy plans effectively improves the accuracy of unet based segmentation for oars especially for smallvolume organs",Brain
Integrated approach of brain segmentation using neuro fuzzy k-means,https://doi.org/10.11591/ijeecs.v29.i1.pp270-276,2023,"ltp classabstractgta proposed method using neurofuzzy kmeans for the segmentation process of brain has been developed successfully simulated and assessed the proposed method has been assessed by using clinical brain images of magnetic resonance imaging mri technology to segment the three main tissues of the brain the proposed system is able to segment the three important regions of the brain which are white matter grey matter and cerebrospinal fluid csf more accurately as compared to the benchmarked algorithms furthermore the developed methods misclassification rate mr has been significantly minimized by 88 27 88 82 71 84 and 82 29 83 as compared to kmeans fuzzy logic and radial basis function rbf for white matter grey matter and csf respectively also from the visual interpretation it is observed that the brains edges are well preserved and the tissues are clearly segmented from these measures the proposed integrated approach is shown to be accurate in segmenting the mri brain tissue with reduced misclassified pixelsltpgt",Brain
EB-LG Module for 3D Point Cloud Classification and Segmentation,https://doi.org/10.1109/lra.2022.3223558,2023,"thanks to the development of deep learning technology and computer science 3d point cloud analysis is becoming a research hotspot based on convolution operator local feature learning is fundamental but far from perfect regarding point cloud analysis task actually when people see a winglike part local features our brain immediately associates it with a plane model global features and then we further trust that its a wing based on the feedback from our brain such hidden features between local features and global features are commonlyexisted but ignored by existing methods to this end we propose error feature backprojection based localglobal eblg feature learning module for better representations of point clouds specifically eblg module adequately captures the hidden features firstly and then borrowing from the successful idea of errorfeedback mechanism the learned hidden features will be backprojected to original local features so that the enhanced local features are obtained serving as a plugandplay eblg module is lightweight and can be easily integrated into existing stateoftheart networks to boost their performance extensive evaluations on both synthetic and realworld 3d point cloud benchmarks demonstrate the effectiveness and the generalization ability of our method",Brain
Application of IVOCT to coronary atherosclerotic plaque,https://doi.org/10.1117/12.2654764,2023,"coronary atherosclerotic heart disease is one of the main causes of death from cardiovascular diseases early detection of atherosclerotic lesions can help clinicians understand the condition of cardiovascular patients and provide reference for better treatment measures compared with other detection technologies intravascular optical coherence tomography ivoct has the advantages of no radiation high resolution and high imaging speed therefore it plays an important role in the detection and evaluation of atherosclerotic plaque although ivoct has been widely used in the detection of plaque in coronary vessels the imaging system could not directly provide effective plaque feature identification information and clinicians can only judge the characteristics of plaque according to their own experience based on a brief introduction of the application of ivoct in detecting coronary atherosclerotic plaque this paper introduces the method of eliminating the vascular motion artifact caused by cardiac pulsation the automatic segmentation and classification of ivoct images are studied by using machine learning method and the plaque features of calcified plaque lipid plaque and fibrous plaque in ivoct images are extracted the deep learning algorithm is used to analyze the characteristics of vulnerable plaque and put forward quantitative evaluation indicators it is very important to develop the intelligent recognition system of ivoct in plaque type that provide objective intuitive and accurate plaque classification marks display and rupture risk assessment for the clinic so that clinicians can get rid of the current situation of relying solely on experience for lesion recognition and save patients lives in time",Cardiac
Lung CT image synthesis using GANs,https://doi.org/10.1016/j.eswa.2022.119350,2023,"biomedical engineering has been targeted as a potential research candidate for machine learning applications with the purpose of detecting or diagnosing pathologies however acquiring relevant highquality and heterogeneous medical datasets is challenging due to privacy and security issues and the effort required to annotate the data generative models have recently gained a growing interest in the computer vision field due to their ability to increase dataset size by generating new highquality samples from the initial set which can be used as data augmentation of a training dataset this study aimed to synthesize artificial lung images from corresponding positional and semantic annotations using two generative adversarial networks and databases of real computed tomography scans the pix2pix approach that generates lung images from the lung segmentation maps and the conditional generative adversarial network ccgan approach that was implemented with additional semantic labels in the generation process to evaluate the quality of the generated images two quantitative measures were used the domainspecific fréchet inception distance and structural similarity index additionally an expert assessment was performed to measure the capability to distinguish between real and generated images the assessment performed shows the high quality of synthesized images which was confirmed by the expert evaluation this work represents an innovative application of gan approaches for medical application taking into consideration the pathological findings in the ct images and the clinical evaluation to assess the realism of these features in the generated images",Lung
Deep learning approach for detecting and localizing brain tumor from magnetic resonance imaging images,https://doi.org/10.11591/ijeecs.v29.i3.pp1729-1737,2023,"ltspan langenusgtbrain is the most important part of the nervous system brain tumor is mainly a mass or growth of abnormal tissues in a brain early detection of brain tumor can reduce complex treatment process magnetic resonance images mri are used to detect brain tumor in this paper we have introduced a deep convolutional neural network cnn to automatic brain tumor segmentation using mri medical images which can solve the vanishing gradient problem classifying the brain mri images with resnet50 and inceptionv3 in order to identify whether there is tumor or not after this step we have compared the accuracy level of both of the cnn models thereafter applied unet architecture individually with encoder resnet50 and inceptionv3 to avieved promising results the publicly available low grade gliomas lgg segmentation dataset has been utilized to test the model before applying the model on the mri images preprocessing and several augmentation techniques have been done to obtain quality a dataset unet architecture with inceptionv3 provided 9955 accuracy on the other hand our proposed method unet with encoder resnet50 showed 9977 accuracyltspangt",Brain
Deep and statistical learning in biomedical imaging: State of the art in 3D MRI brain tumor segmentation,https://doi.org/10.1016/j.inffus.2022.12.013,2023,"clinical diagnostic and treatment decisions rely upon the integration of patientspecific data with clinical reasoning cancer presents a unique context that influence treatment decisions given its diverse forms of disease evolution biomedical imaging allows noninvasive assessment of disease based on visual evaluations leading to better clinical outcome prediction and therapeutic planning early methods of brain cancer characterization predominantly relied upon statistical modeling of neuroimaging data driven by the breakthroughs in computer vision deep learning became the de facto standard in the domain of medical imaging integrated statistical and deep learning methods have recently emerged as a new direction in the automation of the medical practice unifying multidisciplinary knowledge in medicine statistics and artificial intelligence in this study we critically review major statistical and deep learning models and their applications in brain imaging research with a focus on mribased brain tumor segmentation the results do highlight that modeldriven classical statistics and datadriven deep learning is a potent combination for developing automated systems in clinical oncology",Brain
RAAGR2-Net: A brain tumor segmentation network using parallel processing of multiple spatial frames,https://doi.org/10.1016/j.compbiomed.2022.106426,2023,"brain tumors are one of the most fatal cancers magnetic resonance imaging mri is a noninvasive method that provides multimodal images containing important information regarding the tumor many contemporary techniques employ four modalities t1weighted t1 t1weighted with contrast t1c t2weighted t2 and fluidattenuationinversionrecovery flair each of which provides unique and important characteristics for the location of each tumor although several modern procedures provide decent segmentation results on the multimodal brain tumor image segmentation benchmark brats dataset they lack performance when evaluated simultaneously on all the regions of mri images furthermore there is still room for improvement due to parameter limitations and computational complexity therefore in this work a novel encoderdecoderbased architecture is proposed for the effective segmentation of brain tumor regions data preprocessing is performed by applying n4 bias field correction zscore and 0 to 1 resampling to facilitate model training to minimize the loss of location information in different modules a residual spatial pyramid pooling raspp module is proposed raspp is a set of parallel layers using dilated convolution in addition an attention gate ag module is used to efficiently emphasize and restore the segmented output from extracted feature maps the proposed modules attempt to acquire rich feature representations by combining knowledge from diverse feature maps and retaining their local information the performance of the proposed deep network based on raspp ag and recursive residual r2 block termed raagr2net is evaluated on the brats benchmarks the experimental results show that the suggested network outperforms existing networks that exhibit the usefulness of the proposed modules for fine segmentation the code for this work is made available online at httpsgithubcomrehman1995raagr2net",Brain
RAAGR2-Net: A brain tumor segmentation network using parallel processing of multiple spatial frames,https://doi.org/10.1016/j.compbiomed.2022.106426,2023,"brain tumors are one of the most fatal cancers magnetic resonance imaging mri is a noninvasive method that provides multimodal images containing important information regarding the tumor many contemporary techniques employ four modalities t1weighted t1 t1weighted with contrast t1c t2weighted t2 and fluidattenuationinversionrecovery flair each of which provides unique and important characteristics for the location of each tumor although several modern procedures provide decent segmentation results on the multimodal brain tumor image segmentation benchmark brats dataset they lack performance when evaluated simultaneously on all the regions of mri images furthermore there is still room for improvement due to parameter limitations and computational complexity therefore in this work a novel encoderdecoderbased architecture is proposed for the effective segmentation of brain tumor regions data preprocessing is performed by applying n4 bias field correction zscore and 0 to 1 resampling to facilitate model training to minimize the loss of location information in different modules a residual spatial pyramid pooling raspp module is proposed raspp is a set of parallel layers using dilated convolution in addition an attention gate ag module is used to efficiently emphasize and restore the segmented output from extracted feature maps the proposed modules attempt to acquire rich feature representations by combining knowledge from diverse feature maps and retaining their local information the performance of the proposed deep network based on raspp ag and recursive residual r2 block termed raagr2net is evaluated on the brats benchmarks the experimental results show that the suggested network outperforms existing networks that exhibit the usefulness of the proposed modules for fine segmentation the code for this work is made available online at httpsgithubcomrehman1995raagr2net",Brain
Towards fully automated deep-learning-based brain tumor segmentation: Is brain extraction still necessary?,https://doi.org/10.1016/j.bspc.2022.104514,2023,"stateoftheart brain tumor segmentation is based on deep learning models applied to multimodal mris currently these models are trained on images after a preprocessing stage that involves registration interpolation brain extraction be also known as skullstripping and manual correction by an expert however for clinical practice this last step is tedious and timeconsuming and therefore not always feasible resulting in skullstripping faults that can negatively impact the tumor segmentation quality still the extent of this impact has never been measured for any of the many different be methods available in this work we propose an automatic brain tumor segmentation pipeline and evaluate its performance with multiple be methods our experiments show that the choice of a be method can compromise up to 157 of the tumor segmentation performance moreover we propose training and testing tumor segmentation models on nonskullstripped images effectively discarding the be step from the pipeline our results show that this approach leads to a competitive performance at a fraction of the time we conclude that in contrast to the current paradigm training tumor segmentation models on nonskullstripped images can be the best option when high performance in clinical practice is desired",Brain
Brain Tumor Segmentation in Multimodal MRI Using U-Net Layered Structure,https://doi.org/10.32604/cmc.2023.033024,2023,"the brain tumour is the mass where some tissues become old or damaged but they do not die or not leave their space mainly brain tumour masses occur due to malignant masses these tissues must die so that new tissues are allowed to be born and take their place tumour segmentation is a complex and timetaking problem due to the tumours size shape and appearance variation manually finding such masses in the brain by analyzing magnetic resonance images mri is a crucial task for experts and radiologists radiologists could not work for large volume images simultaneously and many errors occurred due to overwhelming image analysis the main objective of this research study is the segmentation of tumors in brain mri images with the help of digital image processing and deep learning approaches this research study proposed an automatic model for tumor segmentation in mri images the proposed model has a few significant steps which first apply the preprocessing method for the whole dataset to convert neuroimaging informatics technology initiative nifti volumes into the 3d numpy array in the second step the proposed model adopts unet deep learning segmentation algorithm with an improved layered structure and sets the updated parameters in the third step the proposed model uses stateoftheart medical image computing and computerassisted intervention miccai brats 2018 dataset with mri modalities such as t1 t1gd t2 and fluidattenuated inversion recovery flair tumour types in mri images are classified according to the tumour masses labelling of these masses carried by stateoftheart approaches such that the first is enhancing tumour label 4 edema label 2 necrotic and nonenhancing tumour core label 1 and the remaining region is label 0 such that edema whole tumour necrosis and active the proposed model is evaluated and gets the dice coefficient dsc value for highgrade glioma hgg volumes for their test seta test setb and test setc 09795 09855 and 09793 respectively dsc value for the lowgrade glioma lgg volumes for the test set is 09950 which shows the proposed model has achieved significant results in segmenting the tumour in mri using deep learning approaches the proposed model is fully automatic that can implement in clinics where human experts consume maximum time to identify the tumorous region of the brain mri the proposed model can help in a way it can proceed rapidly by treating the tumor segmentation in mri",Brain
Brain Tumor Segmentation in Multimodal MRI Using U-Net Layered Structure,https://doi.org/10.32604/cmc.2023.033024,2023,"the brain tumour is the mass where some tissues become old or damaged but they do not die or not leave their space mainly brain tumour masses occur due to malignant masses these tissues must die so that new tissues are allowed to be born and take their place tumour segmentation is a complex and timetaking problem due to the tumours size shape and appearance variation manually finding such masses in the brain by analyzing magnetic resonance images mri is a crucial task for experts and radiologists radiologists could not work for large volume images simultaneously and many errors occurred due to overwhelming image analysis the main objective of this research study is the segmentation of tumors in brain mri images with the help of digital image processing and deep learning approaches this research study proposed an automatic model for tumor segmentation in mri images the proposed model has a few significant steps which first apply the preprocessing method for the whole dataset to convert neuroimaging informatics technology initiative nifti volumes into the 3d numpy array in the second step the proposed model adopts unet deep learning segmentation algorithm with an improved layered structure and sets the updated parameters in the third step the proposed model uses stateoftheart medical image computing and computerassisted intervention miccai brats 2018 dataset with mri modalities such as t1 t1gd t2 and fluidattenuated inversion recovery flair tumour types in mri images are classified according to the tumour masses labelling of these masses carried by stateoftheart approaches such that the first is enhancing tumour label 4 edema label 2 necrotic and nonenhancing tumour core label 1 and the remaining region is label 0 such that edema whole tumour necrosis and active the proposed model is evaluated and gets the dice coefficient dsc value for highgrade glioma hgg volumes for their test seta test setb and test setc 09795 09855 and 09793 respectively dsc value for the lowgrade glioma lgg volumes for the test set is 09950 which shows the proposed model has achieved significant results in segmenting the tumour in mri using deep learning approaches the proposed model is fully automatic that can implement in clinics where human experts consume maximum time to identify the tumorous region of the brain mri the proposed model can help in a way it can proceed rapidly by treating the tumor segmentation in mri",Brain
Salp Swarm Algorithm with Multilevel Thresholding Based Brain Tumor Segmentation Model,https://doi.org/10.32604/cmc.2023.030814,2023,"biomedical image processing acts as an essential part of several medical applications in supporting computer aided disease diagnosis magnetic resonance image mri is a commonly utilized imaging tool used to save glioma for clinical examination biomedical image segmentation plays a vital role in healthcare decision making process which also helps to identify the affected regions in the mri though numerous segmentation models are available in the literature it is still needed to develop effective segmentation models for bt this study develops a salp swarm algorithm with multilevel thresholding based brain tumor segmentation ssamltbts model the presented ssamltbts model initially employs bilateral filtering based on noise removal and skull stripping as a preprocessing phase in addition otsu thresholding approach is applied to segment the biomedical images and the optimum threshold values are chosen by the use of ssa finally active contour ac technique is used to identify the suspicious regions in the medical image a comprehensive experimental analysis of the ssamltbts model is performed using benchmark dataset and the outcomes are inspected in many aspects the simulation outcomes reported the improved outcomes of the ssamltbts model over recent approaches with maximum accuracy of 9595",Brain
A literature survey of MR-based brain tumor segmentation with missing modalities,https://doi.org/10.1016/j.compmedimag.2022.102167,2023,"multimodal mr brain tumor segmentation is one of the hottest issues in the community of medical image processing however acquiring the complete set of mr modalities is not always possible in clinical practice due to the acquisition protocols image corruption scanner availability scanning cost or allergies to certain contrast materials the missing information can cause some restraints to brain tumor diagnosis monitoring treatment planning and prognosis thus it is highly desirable to develop brain tumor segmentation methods to address the missing modalities problem based on the recent advancements in this review we provide a detailed analysis of the missing modality issue in mrbased brain tumor segmentation first we briefly introduce the biomedical background concerning brain tumor mr imaging techniques and the current challenges in brain tumor segmentation then we provide a taxonomy of the stateoftheart methods with five categories namely image synthesisbased method latent feature spacebased model multisource correlationbased method knowledge distillationbased method and domain adaptationbased method in addition the principles architectures benefits and limitations are elaborated in each method following that the corresponding datasets and widely used evaluation metrics are described finally we analyze the current challenges and provide a prospect for future development trends this review aims to provide readers with a thorough knowledge of the recent contributions in the field of brain tumor segmentation with missing modalities and suggest potential future directions",Brain
Brain Tumor Segmentation Using U-Net,https://doi.org/10.1007/978-981-19-6880-8_16,2023,"abstractbrain tumor segmenting from the noninvasive magnetic resonance imaging mri is hard and the most vital task for several applications in the area of medical science analysisin current days surgical operations are usually done on handoperated ways in the hospital that takes excess time manually segmenting the brain tumor is really a very overlong job and it much more depends on the individual person and we found that gliomas are the hardest tumor to be found out having irregular shape and vague boundaries mri images are the mostly used for the segmentation of the brain affected portion segmentation method for mri images of brain is one of the ways that radioscopy performs on the brain image for finding the tumor tissue from the normal tissue in this paper we present this proposed approach depending on fully convolutional network fcn and we are making use of unet as the model this model can be used as a vital essential on prearranged surgical operations to accomplish the successful operations of human brainkeywordsbrain tumor segmentationmagnetic resonance imagefully convolutional networkdeep learningmachine learning",Brain
Multi-task deep learning for medical image computing and analysis: A review,https://doi.org/10.1016/j.compbiomed.2022.106496,2023,"the renaissance of deep learning has provided promising solutions to various tasks while conventional deep learning models are constructed for a single specific task multitask deep learning mtdl that is capable to simultaneously accomplish at least two tasks has attracted research attention mtdl is a joint learning paradigm that harnesses the inherent correlation of multiple related tasks to achieve reciprocal benefits in improving performance enhancing generalizability and reducing the overall computational cost this review focuses on the advanced applications of mtdl for medical image computing and analysis with the references of 251 literatures we first summarize four popular mtdl network architectures ie cascaded parallel interacted and hybrid then we review the representative mtdlbased networks for eight application areas including the brain eye chest cardiac abdomen musculoskeletal pathology and other human body regions while mtdlbased medical image processing has been flourishing and demonstrating outstanding performance in many tasks in the meanwhile there are performance gaps in some tasks and accordingly we perceive the open challenges and the perspective trends for instance in the 2018 ischemic stroke lesion segmentation challenge the reported top dice score of 051 and top recall of 055 achieved by the cascaded mtdl model indicate further research efforts in high demand to escalate the performance of current models",Cardiac
Multi-task deep learning for medical image computing and analysis: A review,https://doi.org/10.1016/j.compbiomed.2022.106496,2023,"the renaissance of deep learning has provided promising solutions to various tasks while conventional deep learning models are constructed for a single specific task multitask deep learning mtdl that is capable to simultaneously accomplish at least two tasks has attracted research attention mtdl is a joint learning paradigm that harnesses the inherent correlation of multiple related tasks to achieve reciprocal benefits in improving performance enhancing generalizability and reducing the overall computational cost this review focuses on the advanced applications of mtdl for medical image computing and analysis with the references of 251 literatures we first summarize four popular mtdl network architectures ie cascaded parallel interacted and hybrid then we review the representative mtdlbased networks for eight application areas including the brain eye chest cardiac abdomen musculoskeletal pathology and other human body regions while mtdlbased medical image processing has been flourishing and demonstrating outstanding performance in many tasks in the meanwhile there are performance gaps in some tasks and accordingly we perceive the open challenges and the perspective trends for instance in the 2018 ischemic stroke lesion segmentation challenge the reported top dice score of 051 and top recall of 055 achieved by the cascaded mtdl model indicate further research efforts in high demand to escalate the performance of current models",Brain
Prostate Cancer Grading Using Multistage Deep Neural Networks,https://doi.org/10.1007/978-981-19-5868-7_21,2023,"abstractprostate cancer is the second most commonly occurring cancer in men with a high incidence to mortality ratio accurate prostate cancer grading is the foremost step in determining the precise treatment process for the patient in preventing mortality of the patient currently the grading is carried out by pathologists which has limitation of availability super specialist doctors across world to grade it at affordable price and nonsuper specialist doctor grading is error prone this paper evades the need for an expert pathologist by proposing a novel deep learning method for automatic screening of prostate images to detect and assign a grade severity of cancer based on the images the explainability of classification model imbibed using gradientweighted class activation mapping gradcam visualization which generate heatmap of image which influenced the decision of the model the proposed method has three stages with ensemble deep neural networks to grade the prostate cancer firstly a unet is used for the segmentation of the histopathological image subsequently the segmented image is overlaid on the original image which helps underscore the most critical regions determining the grade of cancer finally the overlaid image is used by an ensemble model consisting of xception resnet50 efficientnetb7 to predict the final grade of the histopathological image the dataset containing 10000 histopathological images obtained from karolinska and radboud that are made publicly available through the prostate cancer grade assessment challenge hosted in kaggle is used for training and evaluation this method achieves a classification accuracy of 9238 and outperforms many stateoftheart methodskeywordsprostate cancergleason gradeisup gradesegmentationclassificationmedical image analysis",Prostate
The Role of Bioinformatics and Imaging Models in Tumorigenesis and Treatment Response of Brain and Spinal Cord Neoplasm,https://doi.org/10.1007/978-3-031-14732-6_7,2023,"abstractthis chapter focuses on the division and location of brain deformities such as tumors in magnetic resonance imaging mri through chanvese active contour segmentation brain tumor division and identification is a major test in the area of biomedical picture processing to detect the size and location of the tumor various techniques are available but active contour gives accurate knowledge of the region for segmentation chanvese active contour method provides independent robust and more flexible segmentation in this chapter firstly we used preprocessing technique in which noise and unused parts of the brain and skull are removed for this we proposed the skull stripping method then we applied feature extraction to enhance the image intensity and quality and lastly used chanvese active contour with a level set image segmentation technique to detect the tumor the tumor area was calculated after tumor detectionkeywordsbrain tumormripreprocessingskull strippingfeature extractionactive contour segmentation",Brain
Tensor image registration library: Deformable registration of stand‐alone histology images to whole‐brain post‐mortem MRI data,https://doi.org/10.1016/j.neuroimage.2022.119792,2023,"accurate registration between microscopy and mri data is necessary for validating imaging biomarkers against neuropathology and to disentangle complex signal dependencies in microstructural mri existing registration methods often rely on serial histological sampling or significant manual input providing limited scope to work with a large number of standalone histology sections here we present a customisable pipeline to assist the registration of standalone histology sections to wholebrain mri dataour pipeline registers stained histology sections to wholebrain postmortem mri in 4 stages with the help of two photographic intermediaries a block face image to undistort histology sections and coronal brain slab photographs to insert them into mri space each registration stage is implemented as a configurable standalone python script using our novel platform tensor image registration library tirl which provides flexibility for wider adaptation we report our experience of registering 87 plpstained histology sections from 14 subjects and perform various experiments to assess the accuracy and robustness of each stage of the pipelineall 87 histology sections were successfully registered to mri histologytoblock registration stage 1 achieved 0204 mm accuracy better than commonly used existing methods blocktoslice matching stage 2 showed great robustness in automatically identifying and inserting small tissue blocks into whole brain slices with 02 mm accuracy simulations demonstrated subvoxel level accuracy 013 mm of the slicetovolume registration stage 3 algorithm which was observed in over 200 actual brain slice registrations compensating 3d slice deformations up to 65 mm stage 4 combined the previous stages and generated refined pixelwise aligned multimodal histologymri stacksour opensource pipeline provides robust automation tools for registering standalone histology sections to mri data with subvoxel level precision and the underlying framework makes it readily adaptable to a diverse range of microscopymri studies",Brain
3D SAACNet with GBM for the classification of benign and malignant lung nodules,https://doi.org/10.1016/j.compbiomed.2022.106532,2023,"in view of the low diagnostic accuracy of the current classification methods of benign and malignant pulmonary nodules this paper proposes a 3d segmentation attention network integrating asymmetric convolution saacnet classification model combined with a gradient boosting machine gbm this can make full use of the spatial information of pulmonary nodules first the asymmetric convolution ac designed in saacnet can not only strengthen feature extraction but also improve the networks robustness to object flip and rotation detection and improve network performance second the segmentation attention network integrating ac saac block can effectively extract more finegrained multiscale spatial information while adaptively recalibrating multidimensional channel attention weights the saacnet also uses a dualpath connection for feature reuse where the model makes full use of features in addition this article makes the loss function pay more attention to difficult and misclassified samples by adding adjustment factors third the gbm is used to splice the nodule size originally cropped nodule pixels and the depth features learned by saacnet to improve the prediction accuracy of the overall model a comprehensive ablation experiment is carried out on the public dataset luna16 and compared with other lung nodule classification models the classification accuracy acc is 9518 and the area under the curve auc is 0977 the results show that this method effectively improves the classification performance of pulmonary nodules the proposed method has advantages in the classification of benign and malignant pulmonary nodules and it can effectively assist radiologists in pulmonary nodule classification",Lung
Hippocampus Segmentation-Based Alzheimer’s Disease Diagnosis and Classification of MRI Images,https://doi.org/10.1007/s13369-022-07538-2,2023,"alzheimers disease represents a neurological condition characterized by steady cognitive decline and eventual memory loss due to the death of brain cells it is one of the most prominent dementia types observed in patients and which hence underlines the imminent need for potential methods to diagnose the disease early on this work considers a novel approach by utilizing a reduced version of one of the datasets used in this work to achieve a considerably accurate prediction while also enabling quicker training it leverages image segmentation to isolate the hippocampus region from brain mri images and then strikes a comparison between models trained on the segmented portions and models trained on complete images this research uses two datasets4 classes of images from kaggle and a popular oasis 2 mri and demographic dataset a deep learningbased approach was adopted to train the kaggle dataset to perform severity classification and the hippocampus region segmented from a reduced version of the oasis dataset was trained on supervised and ensemble learning algorithms to detect alzheimers disease the metric used for the assessment of model performance is classification accuracy a comparative analysis between the proposed approach and existing work was also performed and it was observed that the proposed approach is effective in the early diagnosis of alzheimers disease",Brain
AimSeg: a machine-learning-aided tool for axon inner tongue and myelin segmentation,https://doi.org/10.1101/2023.01.02.522533,2023,"abstract electron microscopy em images of axons and their ensheathing myelin from both the central and peripheral nervous system are used for assessing myelin formation degeneration demyelination and regeneration remyelination the gratio is the gold standard measure of assessing myelin thickness and quality and traditionally is determined from measurements done manually from em images a timeconsuming endeavour with limited reproducibility these measurements have also historically neglected the innermost uncompacted myelin sheath known as the inner myelin tongue nonetheless the inner tongue has been shown to be important for myelin growth and some studies have reported that certain conditions can elicit its enlargement ignoring this fact may bias the standard gratio analysis whereas quantifying the uncompacted myelin has the potential to provide novel insights in the myelin field in this regard we have developed aimseg a bioimage analysis tool for axon inner tongue and myelin segmentation aided by machine learning classifiers trained on tissue undergoing remyelination aimseg can be used either as an automated workflow or as a userassisted segmentation tool validation results show good performance segmenting all three fibre components with the assisted segmentation showing the potential for further improvement with minimal user intervention this results in a considerable reduction in time for analysis compared with manual annotation aimseg could also be used to build larger high quality ground truth datasets to train novel deep learning models implemented in fiji aimseg can use machine learning classifiers trained in ilastik this combined with a userfriendly interface and the ability to quantify uncompacted myelin makes aimseg a unique tool to assess myelin growth author summary myelin is formed by specialised cells that wrap themselves around axons and has a major role in the function protection and maintenance of nerves these functions are disturbed by demyelinating diseases such as multiple sclerosis in this work we present aimseg a new tool based on artificial intelligence algorithms machine learning to assess myelin growth on electron microscopy images whereas standard metrics and previous computational methods focus on quantifying compact myelin aimseg also quantifies the inner myelin tongue uncompacted myelin this structure has been largely overlooked despite the fact that it has an important role in the process of myelin growth both during development and in the adult brain and recent studies have reported morphological changes associated with some diseases we report the performance of aimseg both as a fully automated approach and in an assisted segmentation workflow that enables the user to curate the results onthefly while reducing human intervention to the minimum therefore aimseg stands as a novel bioimage analysis tool that meets the challenges of assessing myelin growth by supporting both standard metrics for myelin evaluation and the quantification of the uncompacted myelin in different conditions",Brain
Brain Tumor Segmentation Utilizing MRI Multimodal Images with Deep Learning,https://doi.org/10.1201/9781003277002-5,2023,"brain malignancy labeling and delineation via magnetic resonance imaging mri remain difficult but critical activities for a variety of clinical diagnostic purposes several contemporary studies employed three methodologies flair t1c and t2 considering every brain visualization paradigm providing distinct and essential facts relevant to specific areas of the lesion in this work a preprocessing strategy for the operation of just on a limited section of the data instead of the entire image is suggested for the production of a versatile yet robust brain tumor segmentation method this strategy helps in reduction in processing duration and fixes the concern of overfitting in a cascade deep learning network in the subsequent stage an effortless and coherent cascade convolutional neural network ccnn is suggested considering the employment of typically coping with a reduced portion of brain data in every layer the ccnn model harvests all regional and universal characteristics in dual independent ways in addition unique extensive evaluations are carried out on the brats 2018 dataset demonstrating that the suggested model gains fair performance the suggested methodology yields average total tumor score of 0934 0925 and 0908 for the intensification of the lesions and central scale score of the lesions respectively",Brain
Brain Tumor Segmentation Utilizing MRI Multimodal Images with Deep Learning,https://doi.org/10.1201/9781003277002-5,2023,"brain malignancy labeling and delineation via magnetic resonance imaging mri remain difficult but critical activities for a variety of clinical diagnostic purposes several contemporary studies employed three methodologies flair t1c and t2 considering every brain visualization paradigm providing distinct and essential facts relevant to specific areas of the lesion in this work a preprocessing strategy for the operation of just on a limited section of the data instead of the entire image is suggested for the production of a versatile yet robust brain tumor segmentation method this strategy helps in reduction in processing duration and fixes the concern of overfitting in a cascade deep learning network in the subsequent stage an effortless and coherent cascade convolutional neural network ccnn is suggested considering the employment of typically coping with a reduced portion of brain data in every layer the ccnn model harvests all regional and universal characteristics in dual independent ways in addition unique extensive evaluations are carried out on the brats 2018 dataset demonstrating that the suggested model gains fair performance the suggested methodology yields average total tumor score of 0934 0925 and 0908 for the intensification of the lesions and central scale score of the lesions respectively",Brain
Learning to segment fetal brain tissue from noisy annotations,https://doi.org/10.1016/j.media.2022.102731,2023,"automatic fetal brain tissue segmentation can enhance the quantitative assessment of brain development at this critical stage deep learning methods represent the state of the art in medical image segmentation and have also achieved impressive results in brain segmentation however effective training of a deep learning model to perform this task requires a large number of training images to represent the rapid development of the transient fetal brain structures on the other hand manual multilabel segmentation of a large number of 3d images is prohibitive to address this challenge we segmented 272 training images covering 1939 gestational weeks using an automatic multiatlas segmentation strategy based on deformable registration and probabilistic atlas fusion and manually corrected large errors in those segmentations since this process generated a large training dataset with noisy segmentations we developed a novel label smoothing procedure and a loss function to train a deep learning model with smoothed noisy segmentations our proposed methods properly account for the uncertainty in tissue boundaries we evaluated our method on 23 manuallysegmented test images of a separate set of fetuses results show that our method achieves an average dice similarity coefficient of 0893 and 0916 for the transient structures of younger and older fetuses respectively our method generated results that were significantly more accurate than several stateoftheart methods including nnunet that achieved the closest results to our method our trained model can serve as a valuable tool to enhance the accuracy and reproducibility of fetal brain analysis in mri",Brain
PCRLv2: A Unified Visual Information Preservation Framework for  Self-supervised Pre-training in Medical Image Analysis,https://doi.org/10.48550/arxiv.2301.00772,2023,"recent advances in selfsupervised learning ssl in computer vision are primarily comparative whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views however the preserved highlevel semantics do not contain enough local information which is vital in medical image analysis eg imagebased diagnosis and tumor segmentation to mitigate the locality problem of comparative ssl we propose to incorporate the task of pixel restoration for explicitly encoding more pixellevel information into highlevel semantics we also address the preservation of scale information a powerful tool in aiding image understanding but has not drawn much attention in ssl the resulting framework can be formulated as a multitask optimization problem on the feature pyramid specifically we conduct multiscale pixel restoration and siamese feature comparison in the pyramid in addition we propose nonskip unet to build the feature pyramid and develop subcrop to replace multicrop in 3d medical imaging the proposed unified ssl framework pcrlv2 surpasses its selfsupervised counterparts on various tasks including brain tumor segmentation brats 2018 chest pathology identification chestxray chexpert pulmonary nodule detection luna and abdominal organ segmentation lits sometimes outperforming them by large margins with limited annotations",Brain
PCRLv2: A Unified Visual Information Preservation Framework for  Self-supervised Pre-training in Medical Image Analysis,https://doi.org/10.48550/arxiv.2301.00772,2023,"recent advances in selfsupervised learning ssl in computer vision are primarily comparative whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views however the preserved highlevel semantics do not contain enough local information which is vital in medical image analysis eg imagebased diagnosis and tumor segmentation to mitigate the locality problem of comparative ssl we propose to incorporate the task of pixel restoration for explicitly encoding more pixellevel information into highlevel semantics we also address the preservation of scale information a powerful tool in aiding image understanding but has not drawn much attention in ssl the resulting framework can be formulated as a multitask optimization problem on the feature pyramid specifically we conduct multiscale pixel restoration and siamese feature comparison in the pyramid in addition we propose nonskip unet to build the feature pyramid and develop subcrop to replace multicrop in 3d medical imaging the proposed unified ssl framework pcrlv2 surpasses its selfsupervised counterparts on various tasks including brain tumor segmentation brats 2018 chest pathology identification chestxray chexpert pulmonary nodule detection luna and abdominal organ segmentation lits sometimes outperforming them by large margins with limited annotations",Brain
A radiographic deep transfer learning framework adapted to estimate lung opacities from chest x-rays,https://doi.org/10.1186/s42234-022-00103-0,2023,"abstract chest radiographs cxrs are the most widely available radiographic imaging modality used to detect respiratory diseases that result in lung opacities cxr reports often use nonstandardized language that result in subjective qualitative and nonreproducible opacity estimates our goal was to develop a robust deep transfer learning framework and adapt it to estimate the degree of lung opacity from cxrs following cxr data selection based on exclusion criteria segmentation schemes were used for roi region of interest extraction and all combinations of segmentation data balancing and classification methods were tested to pick the top performing models multifold cross validation was used to determine the best model from the initial selected top models based on appropriate performance metrics as well as a novel macroaveraged heatmap concordance score ma hcs performance of the best model is compared against that of expert physician annotators and heatmaps were produced finally model performance sensitivity analysis across patient populations of interest was performed the proposed framework was adapted to the specific use case of estimation of degree of cxr lung opacity using ordinal multiclass classification acquired between march 24 2020 and may 22 2020 38365 prospectively annotated cxrs from 17418 patients were used we tested three neural network architectures resnet50 vgg16 and chexnet three segmentation schemes no segmentation lung segmentation and lateral segmentation based on spine detection and three data balancing strategies undersampling doublestage sampling and synthetic minority oversampling using 38079 cxr images for training and validation with 286 images as the outofthebox dataset that underwent expert radiologist adjudication based on the results of these experiments the resnet50 model with undersampling and no roi segmentation is recommended for lung opacity classification based on optimal values for the mae metric and hcs heatmap concordance score the degree of agreement between the opacity scores predicted by this model with respect to the two sets of radiologist scores or or original reader and oobtr or out of box reader in terms of performance metrics is superior to the interradiologist opacity score agreement",Lung
Fine-grained brain tissue segmentation for brain modeling of stroke patient,https://doi.org/10.1016/j.compbiomed.2022.106472,2023,"brain segmentation of stroke patients can facilitate brain modeling for electrical noninvasive brain stimulation a therapy for stimulating brain function using an electric current however it remains challenging owing to its timeconsuming labordependent and complicated pipeline in addition conventional tools that define lesions into one region rather than distinguishing between the strokeaffected regions and cerebrospinal fluid can lead to inaccurate treatment results in this study we first define a novel strokeaffected region as a detailed subregion of the conventionally defined lesion subsequently a novel comprehensive framework is proposed to segment headbrain and finelevel strokeaffected regions for normal controls and chronic stroke patients the proposed framework consists of a timeefficient and precise deep learningbased segmentation model the experiment results indicate that the proposed method perform better than the conventional deep learningbased segmentation model in terms of the evaluation metrics the proposed method would be a valuable addition to brain modeling for noninvasive neuromodulation",Brain
Finding the Most Transferable Tasks for Brain Image Segmentation,https://doi.org/10.48550/arxiv.2301.00934,2023,"although many studies have successfully applied transfer learning to medical image segmentation very few of them have investigated the selection strategy when multiple source tasks are available for transfer in this paper we propose a prior knowledge guided and transferability based framework to select the best source tasks among a collection of brain image segmentation tasks to improve the transfer learning performance on the given target task the framework consists of modality analysis roi region of interest analysis and transferability estimation such that the source task selection can be refined step by step specifically we adapt the stateoftheart analytical transferability estimation metrics to medical image segmentation tasks and further show that their performance can be significantly boosted by filtering candidate source tasks based on modality and roi characteristics our experiments on brain matter brain tumor and white matter hyperintensities segmentation datasets reveal that transferring from different tasks under the same modality is often more successful than transferring from the same task under different modalities furthermore within the same modality transferring from the source task that has stronger roi shape similarity with the target task can significantly improve the final transfer performance and such similarity can be captured using the structural similarity index in the label space",Brain
An automatic pipeline for atlas-based fetal and neonatal brain segmentation and analysis,https://doi.org/10.1016/j.cmpb.2023.107334,2023,"the automatic segmentation of perinatal brain structures in magnetic resonance imaging mri is of utmost importance for the study of brain growth and related complications while different methods exist for adult and pediatric mri data there is a lack for automatic tools for the analysis of perinatal imagingin this work a new pipeline for fetal and neonatal segmentation has been developed we also report the creation of two new fetal atlases and their use within the pipeline for atlasbased segmentation based on novel registration methods the pipeline is also able to extract cortical and pial surfaces and compute features such as curvature local gyrification index sulcal depth and thicknessresults show that the introduction of the new templates together with our segmentation strategy leads to accurate results when compared to expert annotations as well as better performances when compared to a reference pipeline developing human connectome project dhcp for both early and lateonset fetal brainsthese findings show the potential of the presented atlases and the whole pipeline for application in both fetal neonatal and longitudinal studies which could lead to dramatic improvements in the understanding of perinatal brain development",Brain
A multi-output network with U-net enhanced class activation map and robust classification performance for medical imaging analysis,https://doi.org/10.1007/s44163-022-00045-1,2023,"abstract computer vision in medical diagnosis has achieved a high level of success in diagnosing diseases with high accuracy however conventional classifiers that produce an imagetolabel result provide insufficient information for medical professionals to judge and raise concerns over the trust and reliability of a model with results that cannot be explained to gain local insight of cancerous regions separate tasks such as imaging segmentation needs to be implemented to aid the doctors in treating patients which doubles the training time and costs which renders the diagnosis system inefficient and difficult to be accepted by the public to tackle this issue and drive the aifirst medical solutions further this paper proposes a multioutput network which follows a unet architecture for image segmentation output and features an additional cnn module for auxiliary classification output class activation maps or cams are a method of providing insight into a convolutional neural networks feature maps that lead to its classification but in the case of lung diseases the region of interest is enhanced by unet assisted class activation mapping cam visualization therefore our proposed model combines image segmentation models and classifiers to crop out only the lung region of a chest xrays class activation map to provide a visualization that improves the explainability and can generate classification results simultaneously which builds trust for ailed diagnosis system the proposed unet model achieves 9772 accuracy and a dice coefficient of 09691 on a testing data from the covidquex dataset which includes both diseased and healthy lungs",Lung
A multi-output network with U-net enhanced class activation map and robust classification performance for medical imaging analysis,https://doi.org/10.1007/s44163-022-00045-1,2023,"abstract computer vision in medical diagnosis has achieved a high level of success in diagnosing diseases with high accuracy however conventional classifiers that produce an imagetolabel result provide insufficient information for medical professionals to judge and raise concerns over the trust and reliability of a model with results that cannot be explained to gain local insight of cancerous regions separate tasks such as imaging segmentation needs to be implemented to aid the doctors in treating patients which doubles the training time and costs which renders the diagnosis system inefficient and difficult to be accepted by the public to tackle this issue and drive the aifirst medical solutions further this paper proposes a multioutput network which follows a unet architecture for image segmentation output and features an additional cnn module for auxiliary classification output class activation maps or cams are a method of providing insight into a convolutional neural networks feature maps that lead to its classification but in the case of lung diseases the region of interest is enhanced by unet assisted class activation mapping cam visualization therefore our proposed model combines image segmentation models and classifiers to crop out only the lung region of a chest xrays class activation map to provide a visualization that improves the explainability and can generate classification results simultaneously which builds trust for ailed diagnosis system the proposed unet model achieves 9772 accuracy and a dice coefficient of 09691 on a testing data from the covidquex dataset which includes both diseased and healthy lungs",Lung
A Novel 3D-to-3D Diffeomorphic Registration Algorithm With Applications to Left Ventricle Segmentation in MR and Ultrasound Sequences,https://doi.org/10.1109/access.2023.3234241,2023,"left ventricular segmentation is a difficult and timeconsuming task performed by clinicians requiring the use of manual contours we propose a novel threedimensional diffeomorphic registration algorithm for endocardial segmentation of the left ventricle in magnetic resonance images and ultrasound temporal sequences the proposed diffeomorphic registration method computes a voxeltovoxel correspondence in threedimensional space and is parameterized by one radial and three curl components to emulate the cardiac deformations in addition the proposed method allows for enforcing constraints to control the amount of deformation the method was evaluated on 521 temporal frames from 20 patients from the automated cardiac diagnosis challenge magnetic resonance imaging dataset and 213 frames from 10 patients undergoing ultrasound scans from the mazankowski alberta heart institute the algorithm was compared against six other registration methods the symmetric normalization algorithm from the dipy package two variants of the demons algorithm from the insight toolkit software package two versions of realtitracker and elastix the proposed method yielded overall dice scores of 9810 090 for the mri dataset and 9290 242 for the ultrasound dataset the robustness of the algorithm is demonstrated by the high performance on multiple imaging modalities and various patient abnormalities",Cardiac
Improving performance robustness of subject-based brain segmentation software,https://doi.org/10.47936/encephalitis.2022.00108,2023,"purposeartificial intelligence aibased image analysis tools to quantify the brain have become commercialized however insufficient data for learning and scanner specificity is a limitation for achieving high quality in the present study the performance of personalized brain segmentation software when applied to multicenter data using an ai model trained on data from a single institution was improvedmethodspreindicators of brain white matter wm information from the training dataset were utilized for preprocessing during learning data of cognitively normal cn individuals from a single center were utilized and data of cn individuals and alzheimer disease ad patients enrolled in multiple centers were considered the test setresultsthe preprocessing based on the preindicator dice similarity coefficient dsc 08567 resulted in a better performance than without dsc 07921 the standard deviation sd of the wm region intensity dsc 08303 had a more substantial influence on the performance than the average intensity dsc 06591 when the sd of the test data wm intensity was smaller than the learning data the performance improved 003 increase in lower sd 005 decrease in higher sd furthermore preindicatorbased pretreatment increased the correlation of mean cortical thickness of the entire gray matter between atroscan and freesurfer and data augmentation without preprocessing did notboth preindicator processing and data augmentation improved the correlation coefficient from 07584 to 08165conclusiondata augmentation and preindicatorbased preprocessing of training data can improve the performance of aibased brain segmentation software both increasing the generalizability and stability of brain segmentation software",Brain
Signal Thresholding Segmentation of Ventricular Volumes in Young Patients with Various Diseases—Can We Trust the Numbers?,https://doi.org/10.3390/diagnostics13020180,2023,"in many cardiac diseases right and left ventricular volumes in systole and diastole are diagnostically and prognostically relevant measurements are made by segmentation of the myocardial borders on cardiac magnetic resonance cmr images automatic detection of myocardial contours is possible by signal thresholding techniques but must be validated before use in clinical settings biventricular volumes were measured in enddiastole edvi and in endsystole esvi both manually and with the massk application with signal thresholds at 30 50 and 70 stroke volumes sv and cardiac indices ci were calculated from volumetric measurements and from flow measured in the ascending aorta and the main pulmonary artery and both methods were compared reproducibility of volumetric measurements was tested in 20 patients measurements were acquired in 94 patients aged 15 9 years referred for various conditions edvi and esvi of both ventricles were largest with manual segmentation and inversely proportional to the massk threshold manual and k30 sv and ci corresponded best to flow measurements interobserver variability was low for all volumes manually and with massk in conclusion manual and 30 thresholdbased biventricular volume segmentation agree best with twodimensional phantomcorrected phase contrast flow measurements in a young cardiac referral population and are well reproducible",Cardiac
Spiking neural P system with synaptic vesicles and applications in multiple brain metastasis segmentation,https://doi.org/10.1016/j.ins.2023.01.016,2023,"spiking neural sn p systems performing operations by a series of spikes and rules are a kind of membrane computing models and have been applied in various fields however in the model only one set of spikes is computed in a neuron resulting in too many spikes and neurons being consumed in solving a problem to solve this issue we propose sn p systems with synaptic vesicles snsv p system where each neuron contains multiple synaptic vesicles to deal with different sets of spikes simultaneously three kinds of rules are also designed for communications in the new p system based on the snsv p system several multifusion attention mechanismbased singleshot deep learning models with different initializations are implemented simultaneously to perform ensemble learning on brain metastasis bms segmentation the experimental results demonstrate that the snsv p system outperforms stateoftheart methods and performs well on bms with various phenotypes",Brain
RNN-combined graph convolutional network with multi-feature fusion for tuberculosis cavity segmentation,https://doi.org/10.1007/s11760-022-02446-2,2023,"tuberculosis is a common infectious disease in the world tuberculosis cavities are common and an important imaging signs in tuberculosis accurate segmentation of tuberculosis cavities has practical significance for indicating the activity of lesions and guiding clinical treatment however this task faces challenges such as blurred boundaries irregular shapes different location and size of lesions and similar structures on computed tomography ct to other lung diseases or tissues to overcome these problems we propose a novel rnncombined graph convolutional network r2gcn method which integrates the bidirectional recurrent network brn and graph convolution network gcn modules first feature extraction is performed on the input image by vgg16 or resnet50 to obtain the feature map the feature map is then used as the input of the two modules on the one hand we adopt the brn to retrieve contextual information from the feature map on the other hand we take the vector for each location in the feature map as input nodes and utilize gcn to extract node topology information finally two types of features obtained fuse together our strategy can not only make full use of node correlations and differences but also obtain more precise segmentation boundaries extensive experiments on ct images of cavitary patients with tuberculosis show that our proposed method achieves the best segmentation accuracy than compared segmentation methods our method can be used for the diagnosis of tuberculosis cavity and the evaluation of tuberculosis cavity treatment",Lung
Comparison of In-Vivo and Ex-Vivo Ascending Aorta Elastic Properties through Automatic Deep Learning Segmentation of Cine-MRI and Biomechanical Testing,https://doi.org/10.3390/jcm12020402,2023,"ascending aortic aneurysm is a pathology that is important to be supervised and treated during the years the aorta dilates it becomes stiff and its elastic properties decrease in some cases the aortic wall can rupture leading to aortic dissection with a high mortality rate the main reference standard to measure when the patient needs to undertake surgery is the aortic diameter however the aortic diameter was shown not to be sufficient to predict aortic dissection implying other characteristics should be considered therefore the main objective of this work is to assess invivo the elastic properties of four different quadrants of the ascending aorta and compare the results with equivalent properties obtained exvivo the database consists of 73 cinemri sequences of thoracic aorta acquired in axial orientation at the level of the pulmonary trunk all the patients have dilated aorta and surgery is required the exams were acquired just prior to surgery each consisting of 30 slices on average across the cardiac cycle multiple deep learning architectures have been explored with different hyperparameters and settings to automatically segment the contour of the aorta on each image and then automatically calculate the aortic compliance a semantic segmentation unet network outperforms the rest explored networks with a dice score of 9809 096 and a hausdorff distance of 488 mm 170 mm local aortic compliance and local aortic wall strain were calculated from the segmented surfaces for each quadrant and then compared with elastic properties obtained exvivo good agreement was observed between youngs modulus and invivo strain our results suggest that the lateral and posterior quadrants are the stiffest in contrast the medial and anterior quadrants have the lowest aortic stiffness the invivo stiffness tendency agrees with the values obtained exvivo we can conclude that our automatic segmentation method is robust and compatible with clinical practice thanks to a graphical user interface while the invivo elastic properties are reliable and compatible with the exvivo ones",Cardiac
Deep belief network-based image processing for local directional segmentation in brain tumor detection,https://doi.org/10.1117/1.jei.32.6.062502,2023,"brain tumor data have recently been analyzed using deep learning techniques segmentation and classification of brain tumors and distinguishing tumorous and nontumorous cells are fascinating when it comes to distinguishing brain cell with tumorous and without tumorous and differentiate the tumorous cells to find their class label for this purpose segmentation is an appropriate method for classifying the brain image and it is commonly employed by researchers to achieve accurate classification it is necessary to begin with the extraction of relevant features in this work the probabilistic fuzzy cmeans fcm algorithm is utilized to further refine the segmentation process this analysis makes it possible to distinguish the regions of interest for magnetic resonance imaging mri scan of the brain revealed which provides a framework for reducing the dimensionality of mri brain image local directional pattern ldp is applied to the segments after they have been segmented to extract the significant regions of features that have been identified by the segmentation method next to deep belief network the features are provided which determines whether the images are normal or abnormal and whether mri can be used to detect or rule out the presence of tumors experimentation is conducted with the help of the proposed method and brain tumor segmentation database the accuracy has been assessed in relation to the highest percentage of 9578 is obtained",Brain
A Unified Visual Information Preservation Framework for Self-supervised Pre-training in Medical Image Analysis,https://doi.org/10.1109/tpami.2023.3234002,2023,"recent advances in selfsupervised learning ssl in computer vision are primarily comparative whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views however the preserved highlevel semantics do not contain enough local information which is vital in medical image analysis eg imagebased diagnosis and tumor segmentation to mitigate the locality problem of comparative ssl we propose to incorporate the task of pixel restoration for explicitly encoding more pixellevel information into highlevel semantics we also address the preservation of scale information a powerful tool in aiding image understanding but has not drawn much attention in ssl the resulting framework can be formulated as a multitask optimization problem on the feature pyramid specifically we conduct multiscale pixel restoration and siamese feature comparison in the pyramid in addition we propose nonskip unet to build the feature pyramid and develop subcrop to replace multicrop in 3d medical imaging the proposed unified ssl framework pcrlv2 surpasses its selfsupervised counterparts on various tasks including brain tumor segmentation brats 2018 chest pathology identification chestxray chexpert pulmonary nodule detection luna and abdominal organ segmentation lits sometimes outperforming them by large margins with limited annotations codes and models are available at httpsgithubcomrl4mpcrlv2",Brain
A Unified Visual Information Preservation Framework for Self-supervised Pre-training in Medical Image Analysis,https://doi.org/10.1109/tpami.2023.3234002,2023,"recent advances in selfsupervised learning ssl in computer vision are primarily comparative whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views however the preserved highlevel semantics do not contain enough local information which is vital in medical image analysis eg imagebased diagnosis and tumor segmentation to mitigate the locality problem of comparative ssl we propose to incorporate the task of pixel restoration for explicitly encoding more pixellevel information into highlevel semantics we also address the preservation of scale information a powerful tool in aiding image understanding but has not drawn much attention in ssl the resulting framework can be formulated as a multitask optimization problem on the feature pyramid specifically we conduct multiscale pixel restoration and siamese feature comparison in the pyramid in addition we propose nonskip unet to build the feature pyramid and develop subcrop to replace multicrop in 3d medical imaging the proposed unified ssl framework pcrlv2 surpasses its selfsupervised counterparts on various tasks including brain tumor segmentation brats 2018 chest pathology identification chestxray chexpert pulmonary nodule detection luna and abdominal organ segmentation lits sometimes outperforming them by large margins with limited annotations codes and models are available at httpsgithubcomrl4mpcrlv2",Brain
Segmentation of MRI Images of Gliomas using Convolutional Neural Networks,https://doi.org/10.1201/9781003373261-4,2023,"the need for accurate and intuitive diagnostic tools in the field of biomedical science has incited many researchers to focus on integrating the various models offered by deep learning to suit therapeutic utility neural networks in particular have been exhaustively worked upon to aid in image segmentation and classification operations this project aims to address the need for automatic segmentation of mri images of gliomas in cancer patients the densenet architectural variant of convolutional neural networks has been utilized to build a highly accurate 3d segmentation tool our program also functions to perform preliminary classification of the tumors into highgrade tumors and lowgrade tumors to afford the medical community an initial insight into the severity of the gliomas we have utilized the opensource python library function to build our architecture the training and testing of this architecture were performed on the benchmark miccai brats dataset our model showed high segmentation precision where we obtained accuracy close to 100 9994 with enhancements the same values were obtained for sensitivity and positive predictive values ppvs this level of segmentation accuracy can be considered ideal for practical medical use",Brain
Brain Tissue Segmentation Across the Human Lifespan via Supervised  Contrastive Learning,https://doi.org/10.48550/arxiv.2301.01369,2023,"automatic segmentation of brain mr images into white matter wm gray matter gm and cerebrospinal fluid csf is critical for tissue volumetric analysis and cortical surface reconstruction due to dramatic structural and appearance changes associated with developmental and aging processes existing brain tissue segmentation methods are only viable for specific age groups consequently methods developed for one age group may fail for another in this paper we make the first attempt to segment brain tissues across the entire human lifespan 0100 years of age using a unified deep learning model to overcome the challenges related to structural variability underpinned by biological processes intensity inhomogeneity motion artifacts scannerinduced differences and acquisition protocols we propose to use contrastive learning to improve the quality of feature representations in a latent space for effective lifespan tissue segmentation we compared our approach with commonly used segmentation methods on a largescale dataset of 2464 mr images experimental results show that our model accurately segments brain tissues across the lifespan and outperforms existing methods",Brain
Deep Learning-Based Multiclass Brain Tissue Segmentation in Fetal MRIs,https://doi.org/10.3390/s23020655,2023,"fetal brain tissue segmentation is essential for quantifying the presence of congenital disorders in the developing fetus manual segmentation of fetal brain tissue is cumbersome and timeconsuming so using an automatic segmentation method can greatly simplify the process in addition the fetal brain undergoes a variety of changes throughout pregnancy such as increased brain volume neuronal migration and synaptogenesis in this case the contrast between tissues especially between gray matter and white matter constantly changes throughout pregnancy increasing the complexity and difficulty of our segmentation to reduce the burden of manual refinement of segmentation we proposed a new deep learningbased segmentation method our approach utilized a novel attentional structural block the contextual transformer block cotblock which was applied in the backbone network model of the encoderdecoder to guide the learning of dynamic attentional matrices and enhance image feature extraction additionally in the last layer of the decoder we introduced a hybrid dilated convolution module which can expand the receptive field and retain detailed spatial information effectively extracting the global contextual information in fetal brain mri we quantitatively evaluated our method according to several performance measures dice precision sensitivity and specificity in 80 fetal brain mri scans with gestational ages ranging from 20 to 35 weeks we obtained an average dice similarity coefficient dsc of 8379 an average volume similarity vs of 8484 and an average hausdorff95 distance hd95 of 3566 mm we also used several advanced deep learning segmentation models for comparison under equivalent conditions and the results showed that our method was superior to other methods and exhibited an excellent segmentation performance",Brain
Research on the Application of Artificial Intelligence in Public Health Management: Leveraging Artificial Intelligence to Improve COVID-19 CT Image Diagnosis,https://doi.org/10.3390/ijerph20021158,2023,"since the start of 2020 the outbreak of the coronavirus disease covid19 has been a global public health emergency and it has caused unprecedented economic and social disaster in order to improve the diagnosis efficiency of covid19 patients a number of researchers have conducted extensive studies on applying artificial intelligence techniques to the analysis of covid19related medical images the automatic segmentation of lesions from computed tomography ct images using deep learning provides an important basis for the quantification and diagnosis of covid19 cases for a deep learningbased ct diagnostic method a few of accurate pixellevel labels are essential for the training process of a model however the translucent groundglass area of the lesion usually leads to mislabeling while performing the manual labeling operation which weakens the accuracy of the model in this work we propose a method for correcting rough labels that is to hierarchize these rough labels into precise ones by performing an analysis on the pixel distribution of the infected and normal areas in the lung the proposed method corrects the incorrectly labeled pixels and enables the deep learning model to learn the infected degree of each infected pixel with which an aiding system named dlshelper for covid19 ct image diagnosis using the hierarchical labels is also proposed the dlshelper targets lesion segmentation from ct images as well as the severity grading the dlshelper assists medical staff in efficient diagnosis by providing rich auxiliary diagnostic information including the severity grade the proportions of the lesion and the visualization of the lesion area a comprehensive experiment based on a public covid19 ct image dataset is also conducted and the experimental results show that the dlshelper significantly improves the accuracy of segmentation for the lesion areas and also achieves a promising accuracy for the severity grading task",Lung
A Novel Generative Adversarial Network-Based Approach for Automated Brain Tumour Segmentation,https://doi.org/10.3390/medicina59010119,2023,"background medical image segmentation is more complicated and demanding than ordinary image segmentation due to the density of medical pictures a brain tumour is the most common cause of high mortality objectives extraction of tumorous cells is particularly difficult due to the differences between tumorous and nontumorous cells in ordinary convolutional neural networks local background information is restricted as a result previous deep learning algorithms in medical imaging have struggled to detect anomalies in diverse cells methods as a solution to this challenge a deep convolutional generative adversarial network for tumour segmentation from brain magnetic resonance imaging mri images is proposed a generator and a discriminator are the two networks that make up the proposed model this network focuses on tumour localisation noiserelated issues and social class disparities results dice score coefficient dsc peak signal to noise ratio psnr and structural index similarity ssim are all generally 0894 62084 db and 088912 respectively the models accuracy has improved to 97 percent and its loss has reduced to 0012 conclusions experiments reveal that the proposed approach may successfully segment tumorous and benign tissues as a result a novel brain tumour segmentation approach has been created",Brain
Automatic Assessment of Stereotactic Radiation Therapy Outcome in Brain Metastasis using Longitudinal Segmentation on Serial MRI,https://doi.org/10.1109/jbhi.2023.3235304,2023,"the standard clinical approach to assess the radiotherapy outcome in brain metastasis is through monitoring the changes in tumour size on longitudinal mri this assessment requires contouring the tumour on many volumetric images acquired before and at several followup scans after the treatment that is routinely done manually by oncologists with a substantial burden on the clinical workflow in this work we introduce a novel system for automatic assessment of stereotactic radiation therapy srt outcome in brain metastasis using standard serial mri at the heart of the proposed system is a deep learningbased segmentation framework to delineate tumours longitudinally on serial mri with high precision longitudinal changes in tumour size are then analyzed automatically to assess the local response and detect possible adverse radiation effects are after srt the system was trained and optimized using the data acquired from 96 patients 130 tumours and evaluated on an independent test set of 20 patients 22 tumours 95 mri scans the comparison between automatic therapy outcome evaluation and manual assessments by expert oncologists demonstrates a good agreement with an accuracy sensitivity and specificity of 91 89 and 92 respectively in detecting local controlfailure and 91 100 and 89 in detecting are on the independent test set this study is a step forward towards automatic monitoring and evaluation of radiotherapy outcome in brain tumours that can streamline the radiooncology workflow substantially",Brain
Cross-convolutional transformer for automated multi-organs segmentation in a variety of medical images,https://doi.org/10.1088/1361-6560/acb19a,2023,"objectiveit is a huge challenge for multiorgans segmentation in various medical images based on a consistent algorithm with the development of deep learning methods we therefore develop a deep learning method based on crossconvolutional transformer for these automated segmentation to obtain better generalization and accuracyapproachwe propose a crossconvolutional transformer network c2former to solve the segmentation problem specifically we first redesign a novel crossconvolutional selfattention mechanism in terms of the algorithm to integrate local and global contexts and model longdistance and shortdistance dependencies to enhance the semantic feature understanding of images then multiscale feature edge fusion module is proposed to combine the image edge features which effectively form multiscale feature streams and establish reliable relational connections in the global context finally we use three different modalities imaging three different anatomical regions to train and test multi organs and evaluate segmentation performancemain resultswe use the evaluation metrics of dice similarity coefficient dsc and 95 hausdorff distance hd95 for each dataset experiments showed the average dsc of 8322 and hd95 of 1755 mm on the synapse dataset ct images of abdominal multiorgan the average dsc of 9142 and hd95 of 106 mm on the acdc dataset mri of cardiac substructures and the average dsc of 8678 and hd95 of 1685 mm on the isic 2017 dataset skin cancer images in each dataset our proposed method consistently outperforms the compared networkssignificancethe proposed deep learning network provides a generalized and accurate solution method for multiorgan segmentation in the three different datasets it has the potential to be applied to a variety of medical datasets for structural segmentation",Cardiac
Cross-convolutional transformer for automated multi-organs segmentation in a variety of medical images,https://doi.org/10.1088/1361-6560/acb19a,2023,"objectiveit is a huge challenge for multiorgans segmentation in various medical images based on a consistent algorithm with the development of deep learning methods we therefore develop a deep learning method based on crossconvolutional transformer for these automated segmentation to obtain better generalization and accuracyapproachwe propose a crossconvolutional transformer network c2former to solve the segmentation problem specifically we first redesign a novel crossconvolutional selfattention mechanism in terms of the algorithm to integrate local and global contexts and model longdistance and shortdistance dependencies to enhance the semantic feature understanding of images then multiscale feature edge fusion module is proposed to combine the image edge features which effectively form multiscale feature streams and establish reliable relational connections in the global context finally we use three different modalities imaging three different anatomical regions to train and test multi organs and evaluate segmentation performancemain resultswe use the evaluation metrics of dice similarity coefficient dsc and 95 hausdorff distance hd95 for each dataset experiments showed the average dsc of 8322 and hd95 of 1755 mm on the synapse dataset ct images of abdominal multiorgan the average dsc of 9142 and hd95 of 106 mm on the acdc dataset mri of cardiac substructures and the average dsc of 8678 and hd95 of 1685 mm on the isic 2017 dataset skin cancer images in each dataset our proposed method consistently outperforms the compared networkssignificancethe proposed deep learning network provides a generalized and accurate solution method for multiorgan segmentation in the three different datasets it has the potential to be applied to a variety of medical datasets for structural segmentation",Cardiac
Early Lung Cancer Detection by Using Artificial Intelligence System,https://doi.org/10.1007/978-3-031-15816-2_19,2023,"abstractlung cancer is by far the primary cause of cancer deaths globally computeraided diagnosis cad system is used for the prediction of lung cancer which helps to attain a high detection rate and reduces the time consumed for analyzing the sample in this paper cad system based on sputum color images is proposed which consists of four main processing steps it starts with the preprocessing step using a heuristic rulebased and a bayesian classification method using the histogram analysis in this step the region of interest roi representing the sputum cell is detected and extracted in order to segment the nuclei from the cytoplasm mean shift segmentation is used the next step is feature analysis finally the diagnosis is done using a rulebased algorithm alongside the artificial neural network ann and support vector machine svm for identifying cancerous and noncancerous cells the performance evaluation was done based on the sensitivity specificity and accuracy our methods are validating by using a set of experiments conducted with a data set of 100 images the final results showed that the techniques used outperformed conventional methods the proposed cad system achieved a reasonable accuracy above 95 with high true positive rates that can basically meet the requirement of clinical diagnosiskeywordslung cancerbayesianartificial neural network",Lung
HMNet: Hierarchical Multi-Scale Brain Tumor Segmentation Network,https://doi.org/10.3390/jcm12020538,2023,"an accurate and efficient automatic brain tumor segmentation algorithm is important for clinical practice in recent years there has been much interest in automatic segmentation algorithms that use convolutional neural networks in this paper we propose a novel hierarchical multiscale segmentation network hmnet which contains a highresolution branch and parallel multiresolution branches the highresolution branch can keep track of the brain tumors spatial details and the multiresolution feature exchange and fusion allow the networks receptive fields to adapt to brain tumors of different shapes and sizes in particular to overcome the large computational overhead caused by expensive 3d convolution we propose a lightweight conditional channel weighting block to reduce gpu memory and improve the efficiency of hmnet we also propose a lightweight multiresolution feature fusion lmrf module to further reduce model complexity and reduce the redundancy of the feature maps we run tests on the brats 2020 dataset to determine how well the proposed network would work the dice similarity coefficients of hmnet for et wt and tc are 0781 0901 and 0823 respectively many comparative experiments on the brats 2020 dataset and other two datasets show that our proposed hmnet has achieved satisfactory performance compared with the sota approaches",Brain
HMNet: Hierarchical Multi-Scale Brain Tumor Segmentation Network,https://doi.org/10.3390/jcm12020538,2023,"an accurate and efficient automatic brain tumor segmentation algorithm is important for clinical practice in recent years there has been much interest in automatic segmentation algorithms that use convolutional neural networks in this paper we propose a novel hierarchical multiscale segmentation network hmnet which contains a highresolution branch and parallel multiresolution branches the highresolution branch can keep track of the brain tumors spatial details and the multiresolution feature exchange and fusion allow the networks receptive fields to adapt to brain tumors of different shapes and sizes in particular to overcome the large computational overhead caused by expensive 3d convolution we propose a lightweight conditional channel weighting block to reduce gpu memory and improve the efficiency of hmnet we also propose a lightweight multiresolution feature fusion lmrf module to further reduce model complexity and reduce the redundancy of the feature maps we run tests on the brats 2020 dataset to determine how well the proposed network would work the dice similarity coefficients of hmnet for et wt and tc are 0781 0901 and 0823 respectively many comparative experiments on the brats 2020 dataset and other two datasets show that our proposed hmnet has achieved satisfactory performance compared with the sota approaches",Brain
Cardiac Magnetic Resonance Image Segmentation Method Based on Multi-Scale Feature Fusion and Sequence Relationship Learning,https://doi.org/10.3390/s23020690,2023,"accurate segmentation of the left atrial structure using magnetic resonance images provides an important basis for the diagnosis of atrial fibrillation af and its treatment using robotic surgery in this study an image segmentation method based on sequence relationship learning and multiscale feature fusion is proposed for 3d to 2d sequence conversion in cardiac magnetic resonance images and the varying scales of left atrial structures within different slices firstly a convolutional neural network layer with an attention module was designed to extract and fuse contextual information at different scales in the image to strengthen the target features using the correlation between features in different regions within the image and to improve the networks ability to distinguish the left atrial structure secondly a recurrent neural network layer oriented to twodimensional images was designed to capture the correlation of left atrial structures in adjacent slices by simulating the continuous relationship between sequential image slices finally a combined loss function was constructed to reduce the effect of positive and negative sample imbalance and improve model stability the dice iou and hausdorff distance values reached 9073 8937 and 4803 mm respectively based on the lasc2013 left atrial segmentation challenge in 2013 dataset the corresponding values reached 9205 8941 and 9056 mm respectively based on the asc2018 atrial segmentation challenge at 2018 dataset",Cardiac
Deep learning-based semantic vessel graph extraction for intracranial aneurysm rupture risk management,https://doi.org/10.1007/s11548-022-02818-6,2023,"intracranial aneurysms are vascular deformations in the brain which are complicated to treat in clinical routines the risk assessment of intracranial aneurysm rupture is simplified and might be unreliable especially for patients with multiple aneurysms clinical research proposed more advanced analysis of intracranial aneurysm but requires many complex preprocessing steps advanced tools for automatic aneurysm analysis are needed to transfer current research into clinical routinewe propose a pipeline for intracranial aneurysm analysis using deep learningbased mesh segmentation automatic centerline and outlet detection and automatic generation of a semantic vessel graph we use the semantic vessel graph for morphological analysis and an automatic rupture state classificationthe deep learningbased mesh segmentation can be successfully applied to aneurysm surface meshes with the subsequent semantic graph extraction additional morphological parameters can be extracted that take the whole vascular domain into account the vessels near ruptured aneurysms had a slightly higher average torsion and curvature compared to vessels near unruptured aneurysms the 3d surface models can be further employed for rupture state classification which achieves an accuracy of 833the presented pipeline addresses several aspects of current research and can be used for aneurysm analysis with minimal user effort the semantic graph representation with automatic separation of the aneurysm from the parent vessel is advantageous for morphological and hemodynamical parameter extraction and has great potential for deep learningbased rupture state classification",Brain
A standardized protocol for manually segmenting stroke lesions on high-resolution T1-weighted MR images,https://doi.org/10.3389/fnimg.2022.1098604,2023,"although automated methods for stroke lesion segmentation exist many researchers still rely on manual segmentation as the gold standard our detailed standardized protocol for stroke lesion tracing on highresolution 3d t1weighted t1w magnetic resonance imaging mri has been used to trace over 1300 stroke mri in the current study we describe the protocol including a stepbystep method utilized for training multiple individuals to trace lesions tracers in a consistent manner and suggestions for distinguishing between lesioned and nonlesioned areas in stroke brains interrater and intrarater reliability were calculated across six tracers trained using our protocol resulting in an average intraclass correlation of 098 and 099 respectively as well as a dice similarity coefficient of 0727 and 0839 respectively this protocol provides a standardized guideline for researchers performing manual lesion segmentation in stroke t1weighted mri with detailed methods to promote reproducibility in stroke research",Brain
MITEA: A dataset for machine learning segmentation of the left ventricle in 3D echocardiography using subject-specific labels from cardiac magnetic resonance imaging,https://doi.org/10.3389/fcvm.2022.1016703,2023,"segmentation of the left ventricle lv in echocardiography is an important task for the quantification of volume and mass in heart disease continuing advances in echocardiography have extended imaging capabilities into the 3d domain subsequently overcoming the geometric assumptions associated with conventional 2d acquisitions nevertheless the analysis of 3d echocardiography 3de poses several challenges associated with limited spatial resolution poor contrasttonoise ratio complex noise characteristics and image anisotropy to develop automated methods for 3de analysis a sufficiently large labeled dataset is typically required however ground truth segmentations have historically been difficult to obtain due to the high interobserver variability associated with manual analysis we address this lack of expert consensus by registering labels derived from higherresolution subjectspecific cardiac magnetic resonance cmr images producing 536 annotated 3de images from 143 human subjects 10 of which were excluded this heterogeneous population consists of healthy controls and patients with cardiac disease across a range of demographics to demonstrate the utility of such a dataset a stateoftheart selfconfiguring deep learning network for semantic segmentation was employed for automated 3de analysis using the proposed dataset for training the network produced measurement biases of 9 16 ml 1 10 ml 2 5 and 5 23 g for enddiastolic volume endsystolic volume ejection fraction and mass respectively outperforming an expert human observer in terms of accuracy as well as scanrescan reproducibility as part of the cardiac atlas project we present here a large publicly available 3de dataset with ground truth labels that leverage the higher resolution and contrast of cmr to provide a new benchmark for automated 3de analysis such an approach not only reduces the effect of observerspecific bias present in manual 3de annotations but also enables the development of analysis techniques which exhibit better agreement with cmr compared to conventional methods this represents an important step for enabling more efficient and accurate diagnostic and prognostic information to be obtained from echocardiography",Cardiac
Automated lung cancer assessment on 18F-PET/CT using Retina U-Net and anatomical region segmentation,https://doi.org/10.1007/s00330-022-09332-y,2023,"abstract objectives to develop and test a retina unet algorithm for the detection of primary lung tumors and associated metastases of all stages on fdgpetct methods a data set consisting of 364 fdgpetcts of patients with histologically confirmed lung cancer was used for algorithm development and internal testing the data set comprised tumors of all stages all lung tumors t lymphatic metastases n and distant metastases m were manually segmented as 3d volumes using wholebody petct series the data set was split into a training n 216 validation n 74 and internal test data set n 74 detection performance for all lesion types at multiple classifier thresholds was evaluated and falsepositivefindingspercase fpc calculated next detected lesions were assigned to categories t n or m using an automated anatomical region segmentation furthermore reasons for fps were visually assessed and analyzed finally performance was tested on 20 petcts from another institution results sensitivity for t lesions was 862 95 ci 772927 at a fpc of 20 on the internal test set the anatomical correlate to most fps was the physiological activity of bone marrow 168 tnm categorization based on the anatomical region approach was correct in 943 of lesions performance on the external test set confirmed the good performance of the algorithm overall detection rate 888 95 ci 825935 and fpc 27 conclusions retina unets are a valuable tool for tumor detection tasks on petct and can form the backbone of reading assistance tools in this field fps have anatomical correlates that can lead the way to further algorithm improvements the code is publicly available key points detection of malignant lesions in petct with retina unet is feasible all falsepositive findings had anatomical correlates physiological bone marrow activity being the most prevalent retina unets can build the backbone for tools assisting imaging professionals in lung tumor staging",Lung
Topological structure and global features enhanced graph reasoning model for non-small cell lung cancer segmentation from CT,https://doi.org/10.1088/1361-6560/acabff,2023,"abstract objective accurate and automated segmentation of lung tumors from computed tomography ct images is critical yet challenging lung tumors are of various sizes and locations and have indistinct boundaries adjacent to other normal tissues approach we propose a new segmentation model that can integrate the topological structure and global features of image region nodes to address the challenges firstly we construct a weighted graph with image region nodes the graph topology reflects the complex spatial relationships among these nodes and each node has its specific attributes secondly we propose a nodewise topological feature learning module based on a new graph convolutional autoencoder gca meanwhile a node information supplementation gnis module is established by integrating specific features of each node extracted by a convolutional neural network cnn into each encoding layer of gca afterwards we construct a global feature extraction model based on multilayer perceptron mlp to encode the features learnt from all the image region nodes which are crucial complementary information for tumor segmentation main results ablation study results over the public lung tumor segmentation dataset demonstrate the contributions of our major technical innovations compared with other segmentation methods our new model improves the segmentation performance and has generalization ability on different 3d image segmentation backbones our model achieved dice of 07827 iou of 06981 and hd of 321743 mm on the public dataset 2018 medical segmentation decathlon challenge and dice of 07004 iou of 05704 and hd of 644661 mm on lung tumor dataset from shandong cancer hospital significance the novel model improves automated lung tumor segmentation performance especially the challenging and complex cases using topological structure and global features of image region nodes it is of great potential to apply the model to other ct segmentation tasks",Lung
Automated Pneumonia Based Lung Diseases Classification with Robust Technique Based on a Customized Deep Learning Approach,https://doi.org/10.3390/diagnostics13020260,2023,"many people have been affected by infectious lung diseases ild with the outbreak of the covid19 disease in the last few years many people have waited for weeks to recover in the intensive care wards of hospitals therefore early diagnosis of ild is of great importance to reduce the occupancy rates of health institutions and the treatment time of patients many artificial intelligencebased studies have been carried out in detecting and classifying diseases from medical images using imaging applications the most important goal of these studies was to increase classification performance and model reliability in this approach a powerful algorithm based on a new customized deep learning model acl model which trained synchronously with the attention and lstm model with cnn models was proposed to classify healthy covid19 and pneumonia the important stains and traces in the chest xray cxr image were emphasized with the markercontrolled watershed mcw segmentation algorithm the acl model was trained for different trainingtest ratios 9010 8020 and 7030 for 9010 8020 and 7030 trainingtest ratios accuracy scores were 100 96 and 96 respectively the best performance results were obtained compared to the existing methods in addition the contribution of the strategies utilized in the proposed model to classification performance was analyzed in detail deep learningbased applications can be used as a useful decision support tool for physicians in the early diagnosis of ild diseases however for the reliability of these applications it is necessary to undertake verification with many datasets",Lung
Multiclass Semantic Segmentation to Identify Anatomical Sub-Regions of  Brain and Measure Neuronal Health in Parkinson's Disease,https://doi.org/10.48550/arxiv.2301.02925,2023,"automated segmentation of anatomical subregions with high precision has become a necessity to enable the quantification and characterization of cells tissues in histology images currently a machine learning model to analyze subanatomical regions of the brain to analyze 2d histological images is not available the scientists rely on manually segmenting anatomical subregions of the brain which is extremely timeconsuming and prone to labelerdependent bias one of the major challenges in accomplishing such a task is the lack of highquality annotated images that can be used to train a generic artificial intelligence model in this study we employed a unetbased architecture compared model performance with various combinations of encoders image sizes and sample selection techniques additionally to increase the sample set we resorted to data augmentation which provided data diversity and robust learning in this study we trained our best fit model on approximately one thousand annotated 2d brain images stained with nissl haematoxylin and tyrosine hydroxylase enzyme th indicator of dopaminergic neuron viability the dataset comprises of different animal studies enabling the model to be trained on different datasets the model effectively is able to detect two subregions compacta sncd and reticulata snr in all the images in spite of limited training data our best model achieves a mean intersection over union iou of 79 and a mean dice coefficient of 87 in conclusion the unetbased model with effiecientnet as an encoder outperforms all other encoders resulting in a first of its kind robust model for multiclass segmentation of subbrain regions in 2d images",Brain
Weakly Supervised Joint Whole-Slide Segmentation and Classification in  Prostate Cancer,https://doi.org/10.48550/arxiv.2301.02933,2023,"the segmentation and automatic identification of histological regions of diagnostic interest offer a valuable aid to pathologists however segmentation methods are hampered by the difficulty of obtaining pixellevel annotations which are tedious and expensive to obtain for wholeslide images wsi to remedy this weakly supervised methods have been developed to exploit the annotations directly available at the image level however to our knowledge none of these techniques is adapted to deal with wsis in this paper we propose wholesight a weaklysupervised method to simultaneously segment and classify wsis of arbitrary shapes and sizes formally wholesight first constructs a tissuegraph representation of the wsi where the nodes and edges depict tissue regions and their interactions respectively during training a graph classification head classifies the wsi and produces nodelevel pseudo labels via posthoc feature attribution these pseudo labels are then used to train a node classification head for wsi segmentation during testing both heads simultaneously render class prediction and segmentation for an input wsi we evaluated wholesight on three public prostate cancer wsi datasets our method achieved stateoftheart weaklysupervised segmentation performance on all datasets while resulting in better or comparable classification with respect to stateoftheart weaklysupervised wsi classification methods additionally we quantify the generalization capability of our method in terms of segmentation and classification performance uncertainty estimation and model calibration",Prostate
Statistical shape modeling of multi-organ anatomies with shared boundaries,https://doi.org/10.3389/fbioe.2022.1078800,2023,"introduction statistical shape modeling ssm is a valuable and powerful tool to generate a detailed representation of complex anatomy that enables quantitative analysis of shapes and their variations ssm applies mathematics statistics and computing to parse the shape into some quantitative representation such as correspondence points or landmarks which can be used to study the covariance patterns of the shapes and answer various questions about the anatomical variations across the population complex anatomical structures have many diverse parts with varying interactions or intricate architecture for example the heart is a fourchambered organ with several shared boundaries between chambers subtle shape changes within the shared boundaries of the heart can indicate potential pathologic changes such as right ventricular overload early detection and robust quantification could provide insight into ideal treatment techniques and intervention timing however existing ssm methods do not explicitly handle shared boundaries which aid in a better understanding of the anatomy of interest if shared boundaries are not explicitly modeled it restricts the capability of the shape model to identify the pathological shape changes occurring at the shared boundary hence this paper presents a general and flexible datadriven approach for building statistical shape models of multiorgan anatomies with shared boundaries that explicitly model contact surfaces methods this work focuses on particlebased shape modeling psm a stateofart ssm approach for building shape models by optimizing the position of correspondence particles the proposed psm strategy for handling shared boundaries entails a detecting and extracting the shared boundary surface and contour outline of the surface meshisoline of the meshes of the two organs b followed by a formulation for a correspondencebased optimization algorithm to build a multiorgan anatomy statistical shape model that captures morphological and alignment changes of individual organs and their shared boundary surfaces throughout the population results we demonstrate the shared boundary pipeline using a toy dataset of parameterized shapes and a clinical dataset of the biventricular heart models the shared boundary model for the cardiac biventricular data achieves consistent parameterization of the shared surface interventricular septum and identifies the curvature of the interventricular septum as pathological shape differences",Cardiac
Automated Tumor Segmentation and Brain Tissue Extraction from Multiparametric MRI of Pediatric Brain Tumors: A Multi-Institutional Study,https://doi.org/10.1101/2023.01.02.22284037,2023,"abstract background brain tumors are the most common solid tumors and the leading cause of cancerrelated death among all childhood cancers tumor segmentation is essential in surgical and treatment planning and response assessment and monitoring however manual segmentation is timeconsuming and has high interoperator variability we present a multiinstitutional deep learningbased method for automated brain extraction and segmentation of pediatric brain tumors based on multiparametric mri scans methods multiparametric scans t1w t1wce t2 and t2flair of 244 pediatric patients n215 internal and n29 external cohorts with de novo brain tumors including a variety of tumor subtypes were preprocessed and manually segmented to identify the brain tissue and tumor subregions into four tumor subregions ie enhancing tumor et nonenhancing tumor net cystic components cc and peritumoral edema ed the internal cohort was split into training n151 validation n43 and withheld internal test n21 subsets deepmedic a threedimensional convolutional neural network was trained and the model parameters were tuned finally the network was evaluated on the withheld internal and external test cohorts results dice similarity score mediansd was 091010088016 for the whole tumor 073027084029 for et 07919074027 for union of all nonenhancing components ie net cc ed and 098002 for brain tissue in both internalexternal test sets conclusions our proposed automated brain extraction and tumor subregion segmentation models demonstrated accurate performance on segmentation of the brain tissue and whole tumor regions in pediatric brain tumors and can facilitate detection of abnormal regions for further clinical measurements key points we proposed automated tumor segmentation and brain extraction on pediatric mri the volumetric measurements using our models agree with ground truth segmentations importance of the study the current response assessment in pediatric brain tumors pbts is currently based on bidirectional or 2d measurements which underestimate the size of nonspherical and complex pbts in children compared to volumetric or 3d methods there is a need for development of automated methods to reduce manual burden and intra and interrater variability to segment tumor subregions and assess volumetric changes most currently available automated segmentation tools are developed on adult brain tumors and therefore do not generalize well to pbts that have different radiological appearances to address this we propose a deep learning dl autosegmentation method that shows promising results in pbts collected from a publicly available largescale imaging dataset childrens brain tumor network cbtn that comprises multiparametric mri scans of multiple pbt types acquired across multiple institutions on different scanners and protocols as a complementary to tumor segmentation we propose an automated dl model for brain tissue extraction",Brain
Longitudinal deep neural networks for assessing metastatic brain cancer on a massive open benchmark.,https://doi.org/10.21203/rs.3.rs-2444113/v1,2023,"abstract the detection and tracking of metastatic cancer over the lifetime of a patient remains a major challenge in clinical trials and realworld care 13 recent advances in deep learning combined with massive realworld datasets may enable the development of tools that can address this challenge we present our work with the nyumets project to develop nyumetsbrain and a novel longitudinal deep neural network dnn segmentationthroughtime stt nyumetsbrain is the worlds largest longitudinal realworld dataset of cancer consisting of the imaging clinical followup and medical management of 1429 patients with an average of six mri studies obtained over 17 months per patient the dataset includes over 2367 expert segmentations of metastatic brain tumors and 81562 medical prescriptions using this dataset we developed segmentation through time stt a deep neural network dnn which explicitly utilizes the longitudinal structure of the data and obtained state of the art results at tumor segmentation and detection of small lt 10 mm 3 metastases we also demonstrate that longitudinal measurements to assess the monthly rate of change of brain metastases over time are strongly predictive of overall survival hr 127 95ci 118138 we are releasing the entire dataset codebase trained model weights and an interface for dataset access for other cancer researchers to build upon these results and to serve as a public benchmark massive realworld datasets and public benchmarks such as nyumetsbrain may enable the tracking and detection of metastatic brain cancer and be broadly applicable to advancing the development of ai models in other types of metastatic cancer as well",Brain
Clustering based image segmentation for optimal image fusion using CT and MRI images,https://doi.org/10.1142/s1793962324410010,2023,"as opposed to using many unrelated photographs to depict the same scene image fusions combine multiple similar images to generate a single unified image with greater detail imaging sensors and the need for a wideband signal to transmit most source images limit their resolution this study suggests new methods of fusing medical pictures from different modalities in order to increase image quality and by extension the accuracy with which brain tumors can be detected and identified improved convolutional neural network icnn and region growthbased formula see textmeans clustering rkmc are used in the suggested strategy to boost the quality of brain image fusions obtained from computed tomography scanned image ctsi and magnetic resonance imaging mri in this study the first stages of this task consist of eliminating noise segmenting images extracting and selecting features and fusing images amf adaptive median filtering are first used to eliminate noise from mri images and ctsi of the brain improving the image quality with the help of the rkmc algorithm mri image and ctsi scans can be segmented into their constituent pieces which can then be seen either as grayscale images or as pictures of objects the rkmc algorithm is able to adequately account for the possibility of tumors in white images more useful image features can be extracted with the use of mpca modified principal component analysis afterward features with the highest fitness values are chosen by using afo adaptive firefly optimization image fusions of multimodal images are carried out using icnn which generates the images lower middle and higherlevel contents incorporating important and relevant image characteristics from all viewpoints and perspectives improves feature training and testing the results show that the proposed rkmcicnns outperform the stateoftheart approaches in terms of accuracy psnr rmse and runtime",Brain
Does image resolution impact chest X-ray based fine-grained  Tuberculosis-consistent lesion segmentation?,https://doi.org/10.48550/arxiv.2301.04032,2023,"deep learning dl models are stateoftheart in segmenting anatomical and disease regions of interest rois in medical images particularly a large number of dlbased techniques have been reported using chest xrays cxrs however these models are reportedly trained on reduced image resolutions for reasons related to the lack of computational resources literature is sparse in discussing the optimal image resolution to train these models for segmenting the tuberculosis tbconsistent lesions in cxrs in this study we investigated the performance variations using an inceptionv3 unet model using various image resolutions withwithout lung roi cropping and aspect ratio adjustments and ii identified the optimal image resolution through extensive empirical evaluations to improve tbconsistent lesion segmentation performance we used the shenzhen cxr dataset for the study which includes 326 normal patients and 336 tb patients we proposed a combinatorial approach consisting of storing model snapshots optimizing segmentation threshold and testtime augmentation tta and averaging the snapshot predictions to further improve performance with the optimal resolution our experimental results demonstrate that higher image resolutions are not always necessary however identifying the optimal image resolution is critical to achieving superior performance",Lung
A Novel Interval Iterative Multi-Thresholding Algorithm Based on Hybrid Spatial Filter and Region Growing for Medical Brain MR Images,https://doi.org/10.3390/app13021087,2023,"medical image segmentation is widely used in clinical medicine and the accuracy of the segmentation algorithm will affect the diagnosis results and treatment plans however manual segmentation of medical images requires extensive experience and knowledge and it is both timeconsuming and laborintensive to overcome the problems above we propose a novel interval iterative multithresholding segmentation algorithm based on hybrid spatial filter and region growing for medical brain mr images first a hybrid spatial filter is designed to perform on the original image which can make full use of the spatial information while denoising second the interval iterative otsu method based on region growing is proposed to segment the original image and its filtering layer the initial thresholds can be quickly obtained by region growing algorithm which can reduce the time complexity the interval iterative algorithm is used to optimize the thresholds finally a weighted strategy is used to refine the segmentation results the segmentation results of our proposed algorithm outperform other comparison algorithms in both subjective and objective evaluations subjectively the obtained segmentation results have clear edges complete and consistent regions we use the uniformity measure u for objective evaluation and the u value is significantly higher than other comparison algorithms the proposed algorithm achieved an average u value of 09854 across all test images the proposed algorithm can segment medical images well and expand the doctors ability to utilize medical images",Brain
Region-adaptive magnetic resonance image enhancement for improving CNN-based segmentation of the prostate and prostatic zones,https://doi.org/10.1038/s41598-023-27671-8,2023,"abstract automatic segmentation of the prostate of and the prostatic zones on mri remains one of the most compelling research areas while different image enhancement techniques are emerging as powerful tools for improving the performance of segmentation algorithms their application still lacks consensus due to contrasting evidence regarding performance improvement and crossmodel stability further hampered by the inability to explain models predictions particularly for prostate segmentation the effectiveness of image enhancement on different convolutional neural networks cnn remains largely unexplored the present work introduces a novel image enhancement method named raclahe to enhance the performance of cnn models for segmenting the prostates gland and the prostatic zones the improvement in performance and consistency across five cnn models unet unet unet3 resunet and usenet is compared against four popular image enhancement methods additionally a methodology is proposed to explain both quantitatively and qualitatively the relation between saliency maps and ground truth probability maps overall raclahe was the most consistent image enhancement algorithm in terms of performance improvement across cnn models with the mean increase in dice score ranging from 3 to 9 for the different prostatic regions while achieving minimal intermodel variability the integration of a feature driven methodology to explain the predictions after applying image enhancement methods enables the development of a concrete trustworthy automated pipeline for prostate segmentation on mr images",Prostate
An atrium segmentation network with location guidance and siamese  adjustment,https://doi.org/10.48550/arxiv.2301.04401,2023,"the segmentation of atrial scan images is of great significance for the threedimensional reconstruction of the atrium and the surgical positioning most of the existing segmentation networks adopt a 2d structure and only take original images as input ignoring the context information of 3d images and the role of prior information in this paper we propose an atrium segmentation network lgsanet with location guidance and siamese adjustment which takes adjacent three slices of images as input and adopts an endtoend approach to achieve coarsetofine atrial segmentation the location guidancelg block uses the prior information of the localization map to guide the encoding features of the fine segmentation stage and the siamese adjustmentsa block uses the context information to adjust the segmentation edges on the atrium datasets of acdc and asc sufficient experiments prove that our method can adapt to many classic 2d segmentation networks so that it can obtain significant performance improvements",Cardiac
pyssam -- a Python library for statistical modelling of biomedical shape  and appearance,https://doi.org/10.48550/arxiv.2301.04416,2023,"pyssam is a python library for creating statistical shape and appearance models ssams for biological and other shapes such as bones lungs or other organs a point cloud best describing the anatomical landmarks of the organ are required from each sample in a small population as an input additional information such as landmark grayvalue can be included to incorporate joint correlations of shape and appearance into the model our library performs alignment and scaling of the input data and creates a ssam based on covariance across the population the output ssam can be used to parameterise and quantify shape change across a population pyssam is a small and low dependency codebase with examples included as jupyter notebooks for several common ssam computations the given examples can easily be extended to alternative datasets and also alternative tasks such as medical image segmentation by incorporating a ssam as a constraint for segmented organs",Lung
pyssam -- a Python library for statistical modelling of biomedical shape  and appearance,https://doi.org/10.48550/arxiv.2301.04416,2023,"pyssam is a python library for creating statistical shape and appearance models ssams for biological and other shapes such as bones lungs or other organs a point cloud best describing the anatomical landmarks of the organ are required from each sample in a small population as an input additional information such as landmark grayvalue can be included to incorporate joint correlations of shape and appearance into the model our library performs alignment and scaling of the input data and creates a ssam based on covariance across the population the output ssam can be used to parameterise and quantify shape change across a population pyssam is a small and low dependency codebase with examples included as jupyter notebooks for several common ssam computations the given examples can easily be extended to alternative datasets and also alternative tasks such as medical image segmentation by incorporating a ssam as a constraint for segmented organs",Lung
PerfU-Net: Baseline infarct estimation from CT perfusion source data for acute ischemic stroke,https://doi.org/10.1016/j.media.2023.102749,2023,"ct perfusion imaging is commonly used for infarct core quantification in acute ischemic stroke patients the outcomes and perfusion maps of ct perfusion software however show many discrepancies between vendors we aim to perform infarct core segmentation directly from ct perfusion source data using machine learning excluding the need to use the perfusion maps from standard ct perfusion software to this end we present a symmetryaware spatiotemporal segmentation model that encodes the microperfusion dynamics in the brain while decoding a static segmentation map for infarct core assessment our proposed spatiotemporal perfunet employs an attention module on the skipconnections to match the dimensions of the encoder and decoder we train and evaluate the method on 94 and 62 scans respectively using the ischemic stroke lesion segmentation isles 2018 challenge data we achieve stateoftheart results compared to methods that only use ct perfusion source imaging with a dice score of 046 we are almost on par with methods that use perfusion maps from third party software whilst it is known that there is a large variation in these perfusion maps from various vendors moreover we achieve improved performance compared to simple perfusion map analysis which is used in clinical practice",Brain
Comparison of EEG source localization using simplified and anatomically accurate head models in younger and older adults,https://doi.org/10.36227/techrxiv.21867834.v1,2023,"ltpgtaccuracy of electroencephalography eeg source localization relies on the volume conduction head model a previous analysis of young adults has shown that simplified head models have larger source localization errors when compared with head models based on magnetic resonance images mris as obtaining individual mris may not always be feasible researchers often use generic head models based on template mris it is unclear how much error would be introduced using template mri head models in older adults that likely have differences in brain structure compared to young adults the primary goal of this study was to determine the error caused by using simplified head models without individualspecific mris in both younger and older adults we collected highdensity eeg during uneven terrain walking and motor imagery for 15 younger 223 years and 21 older adults 745 years and obtained t1weighted mri for each individual we performed equivalent dipole fitting after independent component analysis to obtain brain source locations using four forward modeling pipelines with increasing complexity these pipelines included 1 a generic head model with template electrode positions or 2 digitized electrode positions 3 individualspecific head models with digitized electrode positions using simplified tissue segmentation or 4 anatomically accurate segmentation we found that when compared to the anatomically accurate individualspecific head models performing dipole fitting with generic head models led to similar source localization discrepancies up to 2 cm for younger and older adults coregistering digitized electrode locations to the generic head models reduced source localization discrepancies by 6 mm additionally we found that source depths generally increased with skull conductivity for the representative young adult but not as much for the older adult our results can help inform a more accurate interpretation of brain areas in eeg studies when individual mris are unavailable ltpgt",Brain
Comparison of EEG source localization using simplified and anatomically accurate head models in younger and older adults,https://doi.org/10.36227/techrxiv.21867834,2023,"ltpgtaccuracy of electroencephalography eeg source localization relies on the volume conduction head model a previous analysis of young adults has shown that simplified head models have larger source localization errors when compared with head models based on magnetic resonance images mris as obtaining individual mris may not always be feasible researchers often use generic head models based on template mris it is unclear how much error would be introduced using template mri head models in older adults that likely have differences in brain structure compared to young adults the primary goal of this study was to determine the error caused by using simplified head models without individualspecific mris in both younger and older adults we collected highdensity eeg during uneven terrain walking and motor imagery for 15 younger 223 years and 21 older adults 745 years and obtained t1weighted mri for each individual we performed equivalent dipole fitting after independent component analysis to obtain brain source locations using four forward modeling pipelines with increasing complexity these pipelines included 1 a generic head model with template electrode positions or 2 digitized electrode positions 3 individualspecific head models with digitized electrode positions using simplified tissue segmentation or 4 anatomically accurate segmentation we found that when compared to the anatomically accurate individualspecific head models performing dipole fitting with generic head models led to similar source localization discrepancies up to 2 cm for younger and older adults coregistering digitized electrode locations to the generic head models reduced source localization discrepancies by 6 mm additionally we found that source depths generally increased with skull conductivity for the representative young adult but not as much for the older adult our results can help inform a more accurate interpretation of brain areas in eeg studies when individual mris are unavailable ltpgt",Brain
Detecting COVID-19 From Lung Computed Tomography Images: A Swarm Optimized Artificial Neural Network Approach,https://doi.org/10.1109/access.2023.3236812,2023,"covid19 has affected many people across the globe though vaccines are available now early detection of the disease plays a vital role in the better management of covid19 patients an artificial neural network ann powered computer aided diagnosis cad system can automate the detection pipeline accounting for accurate diagnosis overcoming the limitations of manual methods this work proposes a cad system for covid19 that detects and classifies abnormalities in lung ct images using artificial bee colony abc optimised ann abcnn the proposed abcnn approach works by segmenting the suspicious regions from the ct images of noncovid and covid patients using an abc optimised region growing process and extracting the texture and intensity features from those suspicious regions further an optimised ann model whose input features initial weights and hidden nodes are optimised using abc optimisation classifies those abnormal regions into covid and noncovid classes the proposed abcnn approach is evaluated using the lung ct images collected from the public datasets in comparison to other available techniques the proposed abcnn approach achieved a high classification accuracy of 9237 when evaluated using a set of 470 lung ct images",Lung
Reverse-Net: Few-Shot Learning with Reverse Teaching for Deformable Medical Image Registration,https://doi.org/10.3390/app13021040,2023,"multimodal medical image registration has an important role in monitoring tumor growth radiotherapy and disease diagnosis deeplearningbased methods have made great progress in the past few years however its success depends on large training datasets and the performance of the model decreases due to overfitting and poor generalization when only limited data are available in this paper a multimodal medical image registration framework based on fewshot learning is proposed named reversenet which can improve the accuracy and generalization ability of the network by using a few segmentation labels firstly we used the border enhancement network to enhance the roi region of interest boundaries of t1 images to provide highquality data for the subsequent pixel alignment stage secondly through a coarse registration network the t1 image and t2 image were roughly aligned then the pixel alignment network generated more smooth deformation fields finally the reverse teaching network used the warped t1 segmentation labels and warped images generated by the deformation field to teach the border enhancement network more structural knowledge the performance and generalizability of our model have been evaluated on publicly available brain datasets including the mrbrains13dataniipro sri24 cit168 and oasis datasets compared with voxelmorph the reversenet obtained performance improvements of 436 in dsc on the publicly available mrbrains13dataniipro dataset on the unseen dataset oasis the reversenet obtained performance improvements of 42 in dsc compared with voxelmorph which shows that the model can obtain better generalizability the promising performance on dataset cit168 indicates that the model is practicable",Brain
AI-based MRI auto-segmentation of brain tumor in rodents a multicenter study,https://doi.org/10.1186/s40478-023-01509-w,2023,"abstract automatic segmentation of rodent brain tumor on magnetic resonance imaging mri may facilitate biomedical research the current study aims to prove the feasibility for automatic segmentation by artificial intelligence ai and practicability of aiassisted segmentation mri images including t2wi t1wi and cet1wi of brain tumor from 57 wagrij rats in ku leuven and 46 mice from the cancer imaging archive tcia were collected a 3d unet architecture was adopted for segmentation of tumor bearing brain and brain tumor after training these models were tested with both datasets after gaussian noise addition reduction of interobserver disparity by aiassisted segmentation was also evaluated the ai model segmented tumorbearing brain well for both leuven and tcia datasets with dice similarity coefficients dscs of 087 and 085 respectively after noise addition the performance remained unchanged when the signalnoise ratio snr was higher than two or eight respectively for the segmentation of tumor lesions aibased model yielded dscs of 070 and 061 for leuven and tcia datasets respectively similarly the performance is uncompromised when the snr was over two and eight respectively aiassisted segmentation could significantly reduce the interobserver disparities and segmentation time in both rats and mice both ai models for segmenting brain or tumor lesions could improve interobserver agreement and therefore contributed to the standardization of the following biomedical studies",Brain
ZScribbleSeg: Zen and the Art of Scribble Supervised Medical Image  Segmentation,https://doi.org/10.48550/arxiv.2301.04882,2023,"curating a large scale fullyannotated dataset can be both labourintensive and expertisedemanding especially for medical images to alleviate this problem we propose to utilize solely scribble annotations for weakly supervised segmentation existing solutions mainly leverage selective losses computed solely on annotated areas and generate pseudo gold standard segmentation by propagating labels to adjacent areas however these methods could suffer from the inaccurate and sometimes unrealistic pseudo segmentation due to the insufficient supervision and incomplete shape features different from previous efforts we first investigate the principle of good scribble annotations which leads to efficient scribble forms via supervision maximization and randomness simulation furthermore we introduce regularization terms to encode the spatial relationship and shape prior where a new formulation is developed to estimate the mixture ratios of label classes these ratios are critical in identifying the unlabeled pixels for each class and correcting erroneous predictions thus the accurate estimation lays the foundation for the incorporation of spatial prior finally we integrate the efficient scribble supervision with the prior into a unified framework denoted as zscribbleseg and apply the method to multiple scenarios leveraging only scribble annotations zscribbleseg set new stateofthearts on four segmentation tasks using acdc mscmrseg myops and ppss datasets",Cardiac
ZScribbleSeg: Zen and the Art of Scribble Supervised Medical Image  Segmentation,https://doi.org/10.48550/arxiv.2301.04882,2023,"curating a large scale fullyannotated dataset can be both labourintensive and expertisedemanding especially for medical images to alleviate this problem we propose to utilize solely scribble annotations for weakly supervised segmentation existing solutions mainly leverage selective losses computed solely on annotated areas and generate pseudo gold standard segmentation by propagating labels to adjacent areas however these methods could suffer from the inaccurate and sometimes unrealistic pseudo segmentation due to the insufficient supervision and incomplete shape features different from previous efforts we first investigate the principle of good scribble annotations which leads to efficient scribble forms via supervision maximization and randomness simulation furthermore we introduce regularization terms to encode the spatial relationship and shape prior where a new formulation is developed to estimate the mixture ratios of label classes these ratios are critical in identifying the unlabeled pixels for each class and correcting erroneous predictions thus the accurate estimation lays the foundation for the incorporation of spatial prior finally we integrate the efficient scribble supervision with the prior into a unified framework denoted as zscribbleseg and apply the method to multiple scenarios leveraging only scribble annotations zscribbleseg set new stateofthearts on four segmentation tasks using acdc mscmrseg myops and ppss datasets",Cardiac
High-throughput 3DRA segmentation of brain vasculature and aneurysms using deep learning,https://doi.org/10.1016/j.cmpb.2023.107355,2023,"automatic segmentation of the cerebral vasculature and aneurysms facilitates incidental detection of aneurysms the assessment of aneurysm rupture risk assists with preoperative treatment planning and enables insilico investigation of cerebral hemodynamics within and in the vicinity of aneurysms however ensuring precise and robust segmentation of cerebral vessels and aneurysms in neuroimaging modalities such as threedimensional rotational angiography 3dra is challenging the vasculature constitutes a small proportion of the image volume resulting in a large class imbalance relative to surrounding brain tissue additionally aneurysms and vessels have similar imageappearance characteristics making it challenging to distinguish the aneurysm sac from the vessel lumenwe propose a novel multiclass convolutional neural network to tackle these challenges and facilitate the automatic segmentation of cerebral vessels and aneurysms in 3dra images the proposed model is trained and evaluated on an internal multicenter dataset and an external publicly available challenge dataseton the internal clinical dataset our method consistently outperformed several stateoftheart approaches for vessel and aneurysm segmentation achieving an average dice score of 081 015 higher than nnunet and an average surfacetosurface error of 020 mm less than the inplane resolution 035 mmpixel for aneurysm segmentation and an average dice score of 091 and average surfacetosurface error of 025 mm for vessel segmentation in 223 cases of a clinical dataset our method accurately segmented 190 aneurysm casesthe proposed approach can help address class imbalance problems and interclass interference problems in multiclass segmentation besides this method performs consistently on clinical datasets from four different sources and the generated results are qualified for hemodynamic simulation code available at httpsgithubcomcistibvesselaneurysmsegmentation",Brain
A deep learning based dual encoder–decoder framework for anatomical structure segmentation in chest X-ray images,https://doi.org/10.1038/s41598-023-27815-w,2023,"automated multiorgan segmentation plays an essential part in the computeraided diagnostic cad of chest xray fluoroscopy however developing a cad system for the anatomical structure segmentation remains challenging due to several indistinct structures variations in the anatomical structure shape among different individuals the presence of medical tools such as pacemakers and catheters and various artifacts in the chest radiographic images in this paper we propose a robust deep learning segmentation framework for the anatomical structure in chest radiographs that utilizes a dual encoderdecoder convolutional neural network cnn the first network in the dual encoderdecoder structure effectively utilizes a pretrained vgg19 as an encoder for the segmentation task the pretrained encoder output is fed into the squeezeandexcitation se to boost the networks representation power which enables it to perform dynamic channelwise feature calibrations the calibrated features are efficiently passed into the first decoder to generate the mask we integrated the generated mask with the input image and passed it through a second encoderdecoder network with the recurrent residual blocks and an attention the gate module to capture the additional contextual features and improve the segmentation of the smaller regions three public chest xray datasets are used to evaluate the proposed method for multiorgans segmentation such as the heart lungs and clavicles and singleorgan segmentation which include only lungs the results from the experiment show that our proposed technique outperformed the existing multiclass and singleclass segmentation methods",Lung
A deep learning based dual encoder–decoder framework for anatomical structure segmentation in chest X-ray images,https://doi.org/10.1038/s41598-023-27815-w,2023,"automated multiorgan segmentation plays an essential part in the computeraided diagnostic cad of chest xray fluoroscopy however developing a cad system for the anatomical structure segmentation remains challenging due to several indistinct structures variations in the anatomical structure shape among different individuals the presence of medical tools such as pacemakers and catheters and various artifacts in the chest radiographic images in this paper we propose a robust deep learning segmentation framework for the anatomical structure in chest radiographs that utilizes a dual encoderdecoder convolutional neural network cnn the first network in the dual encoderdecoder structure effectively utilizes a pretrained vgg19 as an encoder for the segmentation task the pretrained encoder output is fed into the squeezeandexcitation se to boost the networks representation power which enables it to perform dynamic channelwise feature calibrations the calibrated features are efficiently passed into the first decoder to generate the mask we integrated the generated mask with the input image and passed it through a second encoderdecoder network with the recurrent residual blocks and an attention the gate module to capture the additional contextual features and improve the segmentation of the smaller regions three public chest xray datasets are used to evaluate the proposed method for multiorgans segmentation such as the heart lungs and clavicles and singleorgan segmentation which include only lungs the results from the experiment show that our proposed technique outperformed the existing multiclass and singleclass segmentation methods",Lung
Preoperative visualization of congenital lung abnormalities: hybridizing artificial intelligence and virtual reality,https://doi.org/10.1093/ejcts/ezad014,2023,"when surgical resection is indicated for a congenital lung abnormality cla lobectomy is often preferred over segmentectomy mostly because the latter is associated with more residual disease presumably this occurs in children because sublobar surgery often does not adhere to anatomical borders wedge resection instead of segmentectomy thus increasing the risk of residual disease this study investigated the feasibility of identifying eligible cases for anatomical segmentectomy by combining virtual reality vr and artificial intelligence aisemiautomated segmentation of bronchovascular structures and lesions were visualized with vr and ai technology two specialists independently evaluated via a questionnaire the informative value of regular computed tomography versus threedimensional 3d vr imagesfive asymptomatic nonoperated cases were selected bronchovascular segmentation volume calculation and image visualization in the vr environment were successful in all cases based on the computed tomography images assignment of the cla lesion to specific lung segments matched between the consulted specialists in only 1 out of the cases based on the three 3d vr images however the localization matched in 3 of the 5 cases if the patients would have been operated adding the 3d vr tool to the preoperative workup would have resulted in changing the surgical strategy ie lobectomy versus segmentectomy in 4 casesthis study demonstrated the technical feasibility of a hybridized aivr visualization of segmentlevel lung anatomy in patients with cla further exploration of the value of 3d vr in identifying eligible cases for anatomical segmentectomy is therefore warranted",Lung
A novel cascade machine learning pipeline for Alzheimer’s disease identification and prediction,https://doi.org/10.3389/fnagi.2022.1073909,2023,"introduction alzheimers disease ad is a progressive and irreversible brain degenerative disorder early among all diagnostic strategies hippocampal atrophy is considered a promising diagnostic method in order to proactively detect patients with early alzheimers disease we built an alzheimers segmentation and classification alscf pipeline based on machine learning methods in our study we collected coronal t1 weighted images that include 187 patients with ad and 230 normal controls ncs our pipeline began with the segmentation of the hippocampus by using a modified u2net subsequently we extracted 851 radiomics features and selected 37 features most relevant to ad by the hierarchical clustering method and least absolute shrinkage and selection operator lasso algorithm at last four classifiers were implemented to distinguish ad from ncs and the performance of the models was evaluated by accuracy specificity sensitivity and area under the curve results our proposed pipeline showed excellent discriminative performance of classification with ad vs nc in the training set auc097 95 ci 096098 the model was also verified in the validation set with dice093 for segmentation and accuracy095 for classification discussion the alscf pipeline can automate the process from segmentation to classification which may assist doctors with ad diagnosis and develop individualized medical plans for ad in clinical practice",Brain
DPC-MSGATNet: dual-path chain multi-scale gated axial-transformer network for four-chamber view segmentation in fetal echocardiography,https://doi.org/10.1007/s40747-023-00968-x,2023,"abstract echocardiography is essential in evaluating fetal cardiac anatomical structures and functions when clinicians conduct early treatment and screening for congenital heart defects a common and intricate fetal malformation nevertheless the prenatal detection rate of fetal chd remains low since the peculiarities of fetal cardiac structures and the variousness of fetal chd precisely segmenting four cardiac chambers can assist clinicians in analyzing cardiac morphology and further facilitate chd diagnosis hence we design a dualpath chain multiscale gated axialtransformer network dpcmsgatnet that simultaneously models global dependencies and local visual cues for fetal ultrasound us fourchamber fc views and further accurately segments four chambers our dpcmsgatnet includes a global and a local branch that simultaneously operates on an entire fc view and image patches to learn multiscale representations we design a plugandplay module interactive dualpath chain gated axialtransformer idpcgat to enhance the interactions between global and local branches in idpcgat the multiscale representations from the two branches can complement each other capturing the same regions salient features and suppressing feature responses to maintain only the activations associated with specific targets extensive experiments demonstrate that the dpcmsgatnet exceeds seven stateoftheart convolution and transformerbased methods by a large margin in terms of f1 and iou scores on our fetal fc view dataset achieving a f1 score of 9687 mmlmath xmlnsmmlhttpwwww3org1998mathmathml mmlmommlmo mmlmath and an iou score of 9399 mmlmath xmlnsmmlhttpwwww3org1998mathmathml mmlmommlmo mmlmath the codes and datasets can be available at httpsgithubcomqiaosibodpcmsgatnet",Cardiac
Semiautomated pelvic lymph node treatment response evaluation for patients with advanced prostate cancer: based on MET-RADS-P guidelines,https://doi.org/10.1186/s40644-023-00523-4,2023,"abstract background the evaluation of treatment response according to metastasis reporting and data system for prostate cancer metradsp criteria is an important but timeconsuming task for patients with advanced prostate cancer apc a deep learningbased algorithm has the potential to assist with this assessment objective to develop and evaluate a deep learningbased algorithm for semiautomated treatment response assessment of pelvic lymph nodes methods a total of 162 patients who had undergone at least two scans for followup assessment after apc metastasis treatment were enrolled a previously reported deep learning model was used to perform automated segmentation of pelvic lymph nodes the performance of the deep learning algorithm was evaluated using the dice similarity coefficient dsc and volumetric similarity vs the consistency of the short diameter measurement with the radiologist was evaluated using blandaltman plotting based on the segmentation of lymph nodes the treatment response was assessed automatically with a rulebased program according to the metradsp criteria kappa statistics were used to assess the accuracy and consistency of the treatment response assessment by the deep learning model and two radiologists attending radiologist r1 and fellow radiologist r2 results the mean dsc and vs of the pelvic lymph node segmentation were 082 009 and 088 012 respectively blandaltman plotting showed that most of the lymph node measurements were within the upper and lower limits of agreement loa the accuracies of automated segmentationbased assessment were 092 95 ci 085096 091 95 ci 086095 and 75 95 ci 046092 for target lesions nontarget lesions and nonpathological lesions respectively the consistency of treatment response assessment based on automated segmentation and manual segmentation was excellent for target lesions k value 092 086098 good for nontarget lesions 082 074090 and moderate for nonpathological lesions 071 050092 conclusion the deep learningbased semiautomated algorithm showed high accuracy for the treatment response assessment of pelvic lymph nodes and demonstrated comparable performance with radiologists",Prostate
K-mean clustering and local binary pattern techniques for automatic brain tumor detection,https://doi.org/10.11591/eei.v12i3.4404,2023,"tumors in brains are caused by the unregulated emergence of tissue cells inside the brain the early diagnosis and determining the precise location of the tumor in magnetic resonance imaging mri and its size are essential for the teams of physicians image segmentation is often considered a preliminary step in medical image analyses kmeans clustering has been widely adopted for brain tumor detection the result of this technique is a list of cluster images the challenge of this method is the difficulty of selecting the appropriate cluster section that depicts the tumor in this work we analyze the influence of different image clusters each cluster is then split into the left and right parts after that the texture features are depicted in each part furthermore the bilateral symmetry measure is applied to estimate the cluster that contains the tumor finally the connected component labeling is employed to determine the target cluster for brain tumor detection the developed technique is applied to 30 mri images the encouraging accuracy of 87 is obtained",Brain
PigSNIPE: Scalable Neuroimaging Processing Engine for Minipig MRI,https://doi.org/10.20944/preprints202301.0313.v1,2023,"translation of basic animal research to find effective methods of diagnosing and treating human neurological disorders requires parallel analysis infrastructures small animals such as mice provide exploratory animal disease models however many interventions developed using small animal models fail to translate to human use due to physical or biological differences recently largeanimal minipigs have emerged in neuroscience due to both brain similarity and economic advantages medical image processing is a crucial part of research as it allows researchers to monitor their experiments and understand disease development however although many algorithms are created and optimized for mr analysis of human data those tools are not directly applicable or sufficiently sensitive to measure minipig data in this work we propose pigsnipe a pipeline for the automated handling processing and analyzing of largescale data sets of minipig mr images the pipeline allows for image registration acpc alignment landmark detection skull stripping brainmasks and intracranial volume segmentation dice 098 tissue segmentation dice 082 and caudateputamen brain segmentation dice 08 in under two minutes to the best of our knowledge this is the first automated pipeline tool aimed at large animal images",Brain
HUMAN INTELLIGENCE BASED DEEP LEARNING TECHNIQUE FOR IMAGE SEGMENATION OF BRAIN MRI,https://doi.org/10.46647/ijetms.2023.v07i01.021,2023,"in this work a fully automated system for brain region segmentation by using human intelligence based deep learning technique is proposed deep learning technique is most popular state of the art method in recent applications there are two stages involved the preprocessing and segmentation via convolutional neural network cnnthe mri image with noise is used as an input image mri images are collected from publicly available database open access series of image studies oasis three layers are used in this network which is used to segment the brain region the mr images are first given to preprocessing step to enhance the quality of image for segmentation in this work non local mean filter is used for image denoising which calculates weighted average of pixels and finding similarity with the target pixel the denoised image is given as an input of cnn brain region segmentation by deep learning involves feature extraction cnn learns features directly from an image and no handcrafted features are needed the method consists of three steps such as input data generation construction of model and learning the parameter so a compact representation from the image as image patches are given as input data to the multilayer convolutional neural network the supervised deep network consists of three layers input image is given to the input layer it predict the label from input layer in every hidden layer one convolutional layer and one pooling layer is present convolutional layer compute a dot product of the weights input and add a bias term in this work 4 training images and 1 testing images in ages from the database are used cnn is trained iteratively with representative input patterns along with target label the execution of the cnn gives high exactness in the scope of 94 to 96",Brain
Developing a hybrid algorithm to detect brain tumors from MRI images,https://doi.org/10.1186/s43055-023-00962-w,2023,"abstract background image processing technologies have been developed in the past two decades to help clinicians diagnose tumors using medical images computeraided diagnosis systems cads have proven their ability to increase clinicians detection rate of positive cases by 10 and have become integrated with many medical imaging systems and technologies the study aimed to develop a hybrid algorithm to help doctors detect brain tumors from magnetic resonance imaging images results we were able to reach a detection accuracy of 966 and design a computer application that allows the user to enter the image and identify the location of the tumor in it if it exists with many additional features conclusions this approach can be improved by using different segmentation techniques extracting additional features or using other classifiers",Brain
NVTrans‐UNet: Neighborhood vision transformer based U‐Net for multi‐modal cardiac MR image segmentation,https://doi.org/10.1002/acm2.13908,2023,"with the rapid development of artificial intelligence and image processing technology medical imaging technology has turned into a critical tool for clinical diagnosis and disease treatment the extraction and segmentation of the regions of interest in cardiac images are crucial to the diagnosis of cardiovascular diseases due to the erratically diastolic and systolic cardiac the boundaries of magnetic resonance mr images are quite fuzzy moreover it is hard to provide complete information using a single modality due to the complex structure of the cardiac image furthermore conventional cnnbased segmentation methods are weak in feature extraction to overcome these challenges we propose a multimodal method for cardiac image segmentation called nvtransunet firstly we employ the neighborhood vision transformer nvt module which takes advantage of neighborhood attention na and inductive biases it can better extract the local information of the cardiac image as well as reduce the computational cost secondly we introduce a multimodal gated fusion mgf network which can automatically adjust the contributions of different modal feature maps and make full use of multimodal information thirdly the bottleneck layer with atrous spatial pyramid pooling aspp is proposed to expand the feature receptive field finally the mixed loss is added to the cardiac image to focus the fuzzy boundary and realize accurate segmentation we evaluated our model on myops 2020 dataset the dice score of myocardial infarction mi was 0642 0171 and the dice score of myocardial infarction edema mi me was 0574 0110 compared with the baseline the mi increases by 112 and the mi me increases by 125 the results show the effectiveness of the proposed nvtransunet in the segmentation of mi and me",Cardiac
Infant’s MRI Brain Tissue Segmentation using Integrated CNN Feature Extractor and Random Forest,https://doi.org/10.17762/ijritcc.v11i1s.6002,2023,"infant mri brain soft tissue segmentation become more difficult task compare with adult mri brain tissue segmentation due to infants brain have a very low signal to noise ratio among the white matterwm and the gray matter gm due the fast improvement of the overall brain at this time the overall shape and appearance of the brain differs significantly manual segmentation of anomalous tissues is timeconsuming and unpleasant essential feature extraction in traditional machine algorithm is based on experts required prior knowledge and also system sensitivity has change recently biomedical image segmentation based on deep learning has presented significant potential in becoming an important element of the clinical assessment process inspired by the mentioned objective we introduce a methodology for analysing infant image in order to appropriately segment tissue of infant mri images in this paper we integrated random forest classifier along with deep convolutional neural networks cnn for segmentation of infants mri of iseg 2017 dataset we segmented infants mri brain images into such as wm white matter gmgray matter and csfcerebrospinal fluid tissues the obtained result show that the recommended integrated cnnrf method outperforms and archives a superior dscdice similarity coefficient mhdmodified hausdorff distance and asdaverage surface distance for respective segmented tissue of infants brain mri",Brain
Is the generalizability of a developed artificial intelligence algorithm for COVID-19 on chest CT sufficient for clinical use? Results from the International Consortium for COVID-19 Imaging AI (ICOVAI),https://doi.org/10.1007/s00330-022-09303-3,2023,"only few published artificial intelligence ai studies for covid19 imaging have been externally validated assessing the generalizability of developed models is essential especially when considering clinical implementation we report the development of the international consortium for covid19 imaging ai icovai model and perform independent external validationthe icovai model was developed using multicenter data n 1286 ct scans to quantify disease extent and assess covid19 likelihood using the covid19 reporting and data system corads a resunet model was modified to automatically delineate lung contours and infectious lung opacities on ct scans after which a random forest predicted the corads score after internal testing the model was externally validated on a multicenter dataset n 400 by independent researchers corads classification performance was calculated using linearly weighted cohens kappa and segmentation performance using dice similarity coefficient dscregarding internal versus external testing segmentation performance of lung contours was equally excellent dsc 097 vs dsc 097 p 097 lung opacities segmentation performance was adequate internally dsc 076 but significantly worse on external validation dsc 059 p 00001 for corads classification agreement with radiologists on the internal set was substantial kappa 078 but significantly lower on the external set kappa 062 p 00001in this multicenter study a model developed for corads score prediction and quantification of covid19 disease extent was found to have a significant reduction in performance on independent external validation versus internal testing the limited reproducibility of the model restricted its potential for clinical use the study demonstrates the importance of independent external validation of ai models the icovai model for prediction of corads and quantification of disease extent on chest ct of covid19 patients was developed using a large sample of multicenter data there was substantial performance on internal testing however performance was significantly reduced on external validation performed by independent researchers the limited generalizability of the model restricts its potential for clinical use results of ai models for covid19 imaging on internal tests may not generalize well to external data demonstrating the importance of independent external validation",Lung
Mixed Attention with Deep Supervision for Delineation of COVID Infection in Lung CT,https://doi.org/10.1101/2023.01.17.23284673,2023,"abstract the covid19 pandemic with its multiple variants has placed immense pressure on the global healthcare system an early effective screening and grading become imperative towards optimizing the limited available resources of the medical facilities computed tomography ct provides a significant noninvasive screening mechanism for covid19 infection an automated segmentation of the infected volumes in lung ct is expected to significantly aid in the diagnosis and care of patients however an accurate demarcation of lesions remains problematic due to their irregular structure and locations within the lung a novel deep learning architecture mixed attention deeply supervised network miadsnet is proposed for delineating the infected regions of the lung from ct images incorporating dilated convolutions with varying dilation rates into a mixed attention framework allows capture of multiscale features towards improved segmentation of lesions having different sizes and textures mixed attention helps prioritise relevant feature maps to be probed along with those regions containing crucial information within these maps deep supervision facilitates discovery of robust and discriminatory characteristics in the hidden layers at shallower levels while overcoming the vanishing gradient this is followed by estimating the severity of the disease based on the ratio of the area of infected region in each lung with respect to its entire volume experimental results on three publicly available datasets indicate that the miadsnet outperforms several stateoftheart architectures in the covid19 lesion segmentation task particularly in defining structures involving complex geometries",Lung
2.5D and 3D segmentation of brain metastases with deep learning on multinational MRI data,https://doi.org/10.3389/fninf.2022.1056068,2023,"introduction management of patients with brain metastases is often based on manual lesion detection and segmentation by an expert reader this is a time and laborintensive process and to that end this work proposes an endtoend deep learning segmentation network for a varying number of available mri available sequences methods we adapt and evaluate a 25d and a 3d convolution neural network trained and tested on a retrospective multinational study from two independent centers in addition nnunet was adapted as a comparative benchmark segmentation and detection performance was evaluated by 1 the dice similarity coefficient 2 a permetastases and the average detection sensitivity and 3 the number of false positives results the 25d and 3d models achieved similar results albeit the 25d model had better detection rate whereas the 3d model had fewer false positive predictions and nnunet had fewest false positives but with the lowest detection rate on mri data from center 1 the 25d 3d and nnunet detected 79 71 and 65 of all metastases had an average per patient sensitivity of 088 084 and 076 and had on average 62 32 and 17 false positive predictions per patient respectively for center 2 the 25d 3d and nnunet detected 88 86 and 78 of all metastases had an average per patient sensitivity of 092 091 and 085 and had on average 10 04 and 01 false positive predictions per patient respectively discussionconclusion our results show that deep learning can yield highly accurate segmentations of brain metastases with few false positives in multinational data but the accuracy degrades for metastases with an area smaller than 04 cm 2",Brain
Weakly supervised learning analysis of Aβ plaque distribution in the whole rat brain,https://doi.org/10.3389/fnins.2022.1097019,2023,"alzheimers disease ad is a great challenge for the world and hardly to be cured partly because of the lack of animal models that fully mimic pathological progress recently a rat model exhibiting the most pathological symptoms of ad has been reported however highresolution imaging and accurate quantification of betaamyloid aβ plaques in the whole rat brain have not been fulfilled due to substantial technical challenges in this paper a highefficiency data analysis pipeline is proposed to quantify aβ plaques in whole rat brain through several terabytes of image data acquired by a highspeed volumetric imaging approach we have developed previously a novel segmentation framework applying a highperformance weakly supervised learning method which can dramatically reduce the human labeling consumption is described in this study the effectiveness of our segmentation framework is validated with different metrics the segmented aβ plaques were mapped to a standard rat brain atlas for quantitative analysis of the aβ distribution in each brain area this pipeline may also be applied to the segmentation and accurate quantification of other nonspecific morphology objects",Brain
A novel deep learning-based brain tumor detection using the Bagging ensemble with K-nearest neighbor,https://doi.org/10.1515/jisys-2022-0206,2023,"abstract in the case of magnetic resonance imaging mri imaging image processing is crucial in the medical industry mri images are commonly used to analyze and diagnose tumor growth in the body a number of successful brain tumor identification and classification procedures have been developed by various experts existing approaches face a number of obstacles including detection time accuracy and tumor size early detection of brain tumors improves options for treatment and patient survival rates manually segmenting brain tumors from a significant number of mri data for brain tumor diagnosis is a tough and timeconsuming task automatic image segmentation of brain tumors is required the objective of this study is to evaluate the degree of accuracy and simplify the medical picture segmentation procedure used to identify the type of brain tumor from mri results additionally this work suggests a novel method for identifying brain malignancies utilizing the bagging ensemble with knearest neighbor bknn in order to raise the knns accuracy and quality rate for image segmentation a unet architecture is utilized first followed by a baggingbased knn prediction algorithm for classification the goal of employing unet is to improve the accuracy and uniformity of parameter distribution in the layers each decision tree is fitted on a little different training dataset during classification and the bagged decision trees are effective since each tree has minor differences and generates slightly different skilled predictions the overall classification accuracy was up to 977 percent confirming the efficiency of the suggested strategy for distinguishing normal and pathological tissues from brain mr images this is greater than the methods that are already in use",Brain
Segmentation of Lung Lobes and Lesions in Chest CT for the Classification of COVID-19 Severity,https://doi.org/10.21203/rs.3.rs-2466037/v1,2023,"abstract to precisely determine the severity of covid19related pneumonia computed tomography ct is an imaging modality beneficial for patient monitoring and therapy planning thus we aimed to develop a deep learningbased image segmentation model to automatically assess lung lesions related to covid19 infection and calculate the total severity score tss the entire dataset consists of 100 covid19 patients acquired from chulabhorn hospital divided into 25 cases without lung lesions and 75 cases with lung lesions categorized severity by radiologists regarding tss the model combines a 3dunet with pretrained densenet and resnet models for lung lobe segmentation and calculation of the percentage of lung involvement related to covid19 infection as well as tss measured by the dice similarity coefficient dsc our final model consisting of 3dunet integrated with densenet169 achieved segmentation of lung lobes and lesions with dice similarity coefficients of 0929 and 0842 respectively the calculated tsss are similar to those evaluated by radiologists with an r2 of 0833 the correlation between the groundtruth tss and model prediction was greater than that of the radiologist which was 0993 and 0836 respectively",Lung
Partial Unbalanced Feature Transport for Cross-Modality Cardiac Image Segmentation,https://doi.org/10.1109/tmi.2023.3238067,2023,"deep learning based approaches have achieved great success on the automatic cardiac image segmentation task however the achieved segmentation performance remains limited due to the significant difference across image domains which is referred to as domain shift unsupervised domain adaptation uda as a promising method to mitigate this effect trains a model to reduce the domain discrepancy between the source with labels and the target without labels domains in a common latent feature space in this work we propose a novel framework named partial unbalanced feature transport puft for crossmodality cardiac image segmentation our model facilities uda leveraging two continuous normalizing flowbased variational autoencoders cnfvae and a partial unbalanced optimal transport puot strategy instead of directly using vae for uda in previous works where the latent features from both domains are approximated by a parameterized variational form we introduce continuous normalizing flows cnf into the extended vae to estimate the probabilistic posterior and alleviate the inference bias to remove the remaining domain shift puot exploits the label information in the source domain to constrain the ot plan and extracts structural information of both domains which are often neglected in classical ot for uda we evaluate our proposed model on two cardiac datasets and an abdominal dataset the experimental results demonstrate that puft achieves superior performance compared with stateoftheart segmentation methods for most structural segmentation",Cardiac
Unsupervised Cardiac Segmentation Utilizing Synthesized Images from  Anatomical Labels,https://doi.org/10.48550/arxiv.2301.06043,2023,"cardiac segmentation is in great demand for clinical practice due to the enormous labor of manual delineation unsupervised segmentation is desired the illposed optimization problem of this task is inherently challenging requiring welldesigned constraints in this work we propose an unsupervised framework for multiclass segmentation with both intensity and shape constraints firstly we extend a conventional nonconvex energy function as an intensity constraint and implement it with unet for shape constraint synthetic images are generated from anatomical labels via imagetoimage translation as shape supervision for the segmentation network moreover augmentation invariance is applied to facilitate the segmentation network to learn the latent features in terms of shape we evaluated the proposed framework using the public datasets from miccai2019 mscmr challenge and achieved promising results on cardiac mris with dice scores of 05737 07796 and 06287 in myo lv and rv respectively",Cardiac
Unsupervised Cardiac Segmentation Utilizing Synthesized Images from  Anatomical Labels,https://doi.org/10.48550/arxiv.2301.06043,2023,"cardiac segmentation is in great demand for clinical practice due to the enormous labor of manual delineation unsupervised segmentation is desired the illposed optimization problem of this task is inherently challenging requiring welldesigned constraints in this work we propose an unsupervised framework for multiclass segmentation with both intensity and shape constraints firstly we extend a conventional nonconvex energy function as an intensity constraint and implement it with unet for shape constraint synthetic images are generated from anatomical labels via imagetoimage translation as shape supervision for the segmentation network moreover augmentation invariance is applied to facilitate the segmentation network to learn the latent features in terms of shape we evaluated the proposed framework using the public datasets from miccai2019 mscmr challenge and achieved promising results on cardiac mris with dice scores of 05737 07796 and 06287 in myo lv and rv respectively",Cardiac
Segmenting thalamic nuclei from manifold projections of multi-contrast  MRI,https://doi.org/10.48550/arxiv.2301.06114,2023,"the thalamus is a subcortical gray matter structure that plays a key role in relaying sensory and motor signals within the brain its nuclei can atrophy or otherwise be affected by neurological disease and injuries including mild traumatic brain injury segmenting both the thalamus and its nuclei is challenging because of the relatively low contrast within and around the thalamus in conventional magnetic resonance mr images this paper explores imaging features to determine key tissue signatures that naturally cluster from which we can parcellate thalamic nuclei tissue contrasts include t1weighted and t2weighted images mr diffusion measurements including fa mean diffusivity knutsson coefficients that represent fiber orientation and synthetic multiti images derived from fgatir and t1weighted images after registration of these contrasts and isolation of the thalamus we use the uniform manifold approximation and projection umap method for dimensionality reduction to produce a lowdimensional representation of the data within the thalamus manual labeling of the thalamus provides labels for our umap embedding from which k nearest neighbors can be used to label new unseen voxels in that same umap embedding n fold crossvalidation of the method reveals comparable performance to stateoftheart methods for thalamic parcellation",Brain
TAAL: Test-time Augmentation for Active Learning in Medical Image  Segmentation,https://doi.org/10.48550/arxiv.2301.06624,2023,"deep learning methods typically depend on the availability of labeled data which is expensive and timeconsuming to obtain active learning addresses such effort by prioritizing which samples are best to annotate in order to maximize the performance of the task model while frameworks for active learning have been widely explored in the context of classification of natural images they have been only sparsely used in medical image segmentation the challenge resides in obtaining an uncertainty measure that reveals the best candidate data for annotation this paper proposes testtime augmentation for active learning taal a novel semisupervised active learning approach for segmentation that exploits the uncertainty information offered by data transformations our method applies crossaugmentation consistency during training and inference to both improve model learning in a semisupervised fashion and identify the most relevant unlabeled samples to annotate next in addition our consistency loss uses a modified version of the jsd to further improve model performance by relying on data transformations rather than on external modules or simple heuristics typically used in uncertaintybased strategies taal emerges as a simple yet powerful taskagnostic semisupervised active learning approach applicable to the medical domain our results on a publiclyavailable dataset of cardiac images show that taal outperforms existing baseline methods in both fullysupervised and semisupervised settings our implementation is publicly available on httpsgithubcommelinphdtaal",Cardiac
Composite Deep Network with Feature Weighting for Improved Delineation  of COVID Infection in Lung CT,https://doi.org/10.48550/arxiv.2301.06961,2023,"an early effective screening and grading of covid19 has become imperative towards optimizing the limited available resources of the medical facilities an automated segmentation of the infected volumes in lung ct is expected to significantly aid in the diagnosis and care of patients however an accurate demarcation of lesions remains problematic due to their irregular structure and locations within the lung a novel deep learning architecture composite deep network with feature weighting cdnetfw is proposed for efficient delineation of infected regions from lung ct images initially a coarsersegmentation is performed directly at shallower levels thereby facilitating discovery of robust and discriminatory characteristics in the hidden layers the novel feature weighting module helps prioritise relevant feature maps to be probed along with those regions containing crucial information within these maps this is followed by estimating the severity of the diseasethe deep network cdnetfw has been shown to outperform several stateoftheart architectures in the covid19 lesion segmentation task as measured by experimental results on ct slices from publicly available datasets especially when it comes to defining structures involving complex geometries",Lung
Diffusion MRI data analysis assisted by deep learning synthesized anatomical images (DeepAnat),https://doi.org/10.1016/j.media.2023.102744,2023,"diffusion mri is a useful neuroimaging tool for noninvasive mapping of human brain microstructure and structural connections the analysis of diffusion mri data often requires brain segmentation including volumetric segmentation and cerebral cortical surfaces from additional highresolution t1weighted t1w anatomical mri data which may be unacquired corrupted by subject motion or hardware failure or cannot be accurately coregistered to the diffusion data that are not corrected for susceptibilityinduced geometric distortion to address these challenges this study proposes to synthesize highquality t1w anatomical images directly from diffusion data using convolutional neural networks cnns entitled deepanat including a unet and a hybrid generative adversarial network gan and perform brain segmentation on synthesized t1w images or assist the coregistration using synthesized t1w images the quantitative and systematic evaluations using data of 60 young subjects provided by the human connectome project hcp show that the synthesized t1w images and results for brain segmentation and comprehensive diffusion analysis tasks are highly similar to those from native t1w data the brain segmentation accuracy is slightly higher for the unet than the gan the efficacy of deepanat is further validated on a larger dataset of 300 more elderly subjects provided by the uk biobank moreover the unets trained and validated on the hcp and uk biobank data are shown to be highly generalizable to the diffusion data from massachusetts general hospital connectome diffusion microstructure dataset mgh cdmd acquired with different hardware systems and imaging protocols and therefore can be used directly without retraining or with finetuning for further improved performance finally it is quantitatively demonstrated that the alignment between native t1w images and diffusion images uncorrected for geometric distortion assisted by synthesized t1w images substantially improves upon that by directly coregistering the diffusion and t1w images using the data of 20 subjects from mgh cdmd in summary our study demonstrates the benefits and practical feasibility of deepanat for assisting various diffusion mri data analyses and supports its use in neuroscientific applications",Brain
Unsupervised Cross-modality Adaptation via Dual Structural-Oriented Guidance for 3D Medical Image Segmentation,https://doi.org/10.1109/tmi.2023.3238114,2023,"deep convolutional neural networks cnns have achieved impressive performance in medical image segmentation however their performance could degrade significantly when being deployed to unseen data with heterogeneous characteristics unsupervised domain adaptation uda is a promising solution to tackle this problem in this work we present a novel uda method named dual adaptationguiding network dagnet which incorporates two highly effective and complementary structuraloriented guidance in training to collaboratively adapt a segmentation model from a labelled source domain to an unlabeled target domain specifically our dagnet consists of two core modules 1 fourierbased contrastive style augmentation fcsa which implicitly guides the segmentation network to focus on learning modalityinsensitive and structuralrelevant features and 2 residual space alignment rsa which provides explicit guidance to enhance the geometric continuity of the prediction in the target modality based on a 3d prior of interslice correlation we have extensively evaluated our method with cardiac substructure and abdominal multiorgan segmentation for bidirectional crossmodality adaptation between mri and ct images experimental results on two different tasks demonstrate that our dagnet greatly outperforms the stateoftheart uda approaches for 3d medical image segmentation on unlabeled target images",Cardiac
Medical-Network (Med-Net): A Neural Network for Breast Cancer Segmentation in Ultrasound Image,https://doi.org/10.1007/978-981-19-7742-8_12,2023,"abstractbreast tumor segmentation is an important image processing technique for cancer diagnosis and treatment recently deep learning models have shown significant advances toward computeraided diagnosis systems cad we proposed a novel neural networkbased attention modules to segment tumors from breast ultrasound bus images inspired by the human brain function of interpreting the scene in this contribution we focused only on the salient areas of the image while suppressing other details this was built on a residual encoder and dense blocks decoder the generated feature map comprises spatial as well as channel details and fused the maps producing more meaningful feature map and gives better discriminative characteristics the results show that the proposed model outperformed several recent models and has potential for clinical practiceskeywordsconvolutional neural networkbus imagesbreast tumor segmentationdeep learning",Brain
Evaluation of the HD-GLIO Deep Learning Algorithm for Brain Tumour Segmentation on Postoperative MRI,https://doi.org/10.3390/diagnostics13030363,2023,"in the context of brain tumour response assessment deep learningbased threedimensional 3d tumour segmentation has shown potential to enter the routine radiological workflow the purpose of the present study was to perform an external evaluation of a stateoftheart deep learning 3d brain tumour segmentation algorithm hdglio on an independent cohort of consecutive postoperative patients for 66 consecutive magnetic resonance imaging examinations we compared delineations of contrastenhancing ce tumour lesions and nonenhancing t2flair hyperintense abnormality ne lesions by the hdglio algorithm and radiologists using dice similarity coefficients dice volume agreement was assessed using concordance correlation coefficients cccs and blandaltman plots the algorithm performed very well regarding the segmentation of ne volumes median dice 079 and ce tumour volumes larger than 10 cm3 median dice 086 if considering all cases with ce tumour lesions the performance dropped significantly median dice 040 volume agreement was excellent with cccs of 0997 ce tumour volumes and 0922 ne volumes the findings have implications for the application of the hdglio algorithm in the routine radiological workflow where small contrastenhancing tumours will constitute a considerable share of the followup cases our study underlines that independent validations on clinical datasets are key to asserting the robustness of deep learning algorithms",Brain
Model-based inexact graph matching on top of CNNs for semantic scene  understanding,https://doi.org/10.48550/arxiv.2301.07468,2023,"deep learning based pipelines for semantic segmentation often ignore structural information available on annotated images used for training we propose a novel postprocessing module enforcing structural knowledge about the objects of interest to improve segmentation results provided by deep learning this module corresponds to a manytooneornone inexact graph matching approach and is formulated as a quadratic assignment problem our approach is compared to a cnnbased segmentation for various cnn backbones on two public datasets one for face segmentation from 2d rgb images fasseg and the other for brain segmentation from 3d mris ibsr evaluations are performed using two types of structural information distances and directional relations this choice being a hyperparameter of our generic framework on fasseg data results show that our module improves accuracy of the cnn by about 63 the hausdorff distance decreases from 2211 to 2071 on ibsr data the improvement is of 51 the hausdorff distance decreases from 1101 to 54 in addition our approach is shown to be resilient to small training datasets that often limit the performance of deep learning methods the improvement increases as the size of the training dataset decreases",Brain
Active learning for medical image segmentation with stochastic batches,https://doi.org/10.48550/arxiv.2301.07670,2023,"the performance of learningbased algorithms improves with the amount of labelled data used for training yet manually annotating data can be tedious and expensive especially in medical image segmentation to reduce manual labelling active learning al targets the most informative samples from the unlabelled set to annotate and add to the labelled training set on one hand most active learning works have focused on the classification or limited segmentation of natural images despite active learning being highly desirable in the difficult task of medical image segmentation on the other hand uncertaintybased al approaches notoriously offer suboptimal batchquery strategies while diversitybased methods tend to be computationally expensive over and above methodological hurdles random sampling has proven an extremely difficult baseline to outperform when varying learning and sampling conditions this work aims to take advantage of the diversity and speed offered by random sampling to improve the selection of uncertaintybased al methods for segmenting medical images more specifically we propose to compute uncertainty at the level of batches instead of samples through an original use of stochastic batches during sampling in al exhaustive experiments on medical image segmentation with an illustration on mri prostate imaging show that the benefits of stochastic batches during sample selection are robust to a variety of changes in the training and sampling procedures",Prostate
Left ventricle segmentation in transesophageal echocardiography images using a deep neural network,https://doi.org/10.1371/journal.pone.0280485,2023,"there has been little progress in research on the best anatomical position for effective chest compressions and cardiac function during cardiopulmonary resuscitation cpr this study aimed to divide the left ventricle lv into segments to determine the best position for effective chest compressions using the lv systolic function seen during cprwe used transesophageal echocardiography images acquired during cpr a deep neural network with an attention mechanism and a residual feature aggregation module were applied to the images to segment the lv the results were compared between the proposed model and unetthe results of the proposed model showed higher performance in most metrics when compared to unet dice coefficient 08990017 vs 07920027 p005 intersection of union 08220026 vs 06680034 p005 recall 09040023 vs 07570037 p005 precision 09010021 vs 08590034 p005 there was a significant difference between the proposed model and unetcompared to unet the proposed model showed better performance for all metrics this model would allow us to evaluate the systolic function of the heart during cpr in greater detail by segmenting the lv more accurately",Cardiac
Evaluation of generalization ability for deep learning‐based auto‐segmentation accuracy in limited field of view CBCT of male pelvic region,https://doi.org/10.1002/acm2.13912,2023,"the aim of this study was to evaluate generalization ability of segmentation accuracy for limited fov cbct in the male pelvic region using a fullimage cnn autosegmentation accuracy was evaluated using various datasets with different intensity distributions and fov sizesa total of 171 cbct datasets from patients with prostate cancer were enrolled there were 151 10 and 10 cbct datasets acquired from vero4drt truebeam stx and clinacix respectively the fov for vero4drt truebeam stx and clinacix was 20 26 and 25 cm respectively the rois including the bladder prostate rectum and seminal vesicles were manually delineated the u2 net cnn network architecture was used to train the segmentation model a total of 131 limited fov cbct datasets from vero4drt were used for training 104 datasets and validation 27 datasets thereafter the rest were for testing the training routine was set to save the best weight values when the dsc in the validation set was maximized segmentation accuracy was qualitatively and quantitatively evaluated between the ground truth and predicted rois in the different testing datasetsthe mean scores standard deviation of visual evaluation for bladder prostate rectum and seminal vesicle in all treatment machines were 10 07 15 06 14 06 and 21 08 points respectively the median dsc values for all imaging devices were 094 for the bladder 084087 for the prostate and rectum and 048069 for the seminal vesicles although the dsc values for the bladder and seminal vesicles were significantly different among the three imaging devices the dsc value of the bladder changed by less than 1 point the median msd values for all imaging devices were 12 mm for the bladder and 1422 mm for the prostate rectum and seminal vesicles the msd values for the seminal vesicles were significantly different between the three imaging devicesthe proposed method is effective for testing datasets with different intensity distributions and fov from training datasets",Prostate
Modulatory feedback explain object segmentation by attention,https://doi.org/10.1101/2023.01.19.524712,2023,"studies in neuroscience inspired progress in the design of artificial neural networks anns and vice versa anns have also started to provide new insights into the functioning of brain circuits so far the focus has been on how anns can help to explain the tuning of neurons at various stages of the visual cortical hierarchy however the role of modulatory feedback connections which play a role in attention and perceptual organization has not been tested yet here we present a biologically plausible neural network that performs scene segmentation and can shift attention using modulatory feedback connections from higher to lower brain areas the model replicates several neurophysiological signatures of recurrent processing specifically figural regions elicit more neuronal activity in model units than the background the modulation of neuronal activity by figure and ground occurs at a delay after the first feedforward response because it depends on a loop through the higher model areas importantly the enhancement of the figural response is controlled by objectbased attention which stays focused on the figural regions and does not spill over to the adjacent background as observed in the visual cortex our results indicate how progress in deep learning can be used to garner insight into the recurrent cortical processing for scene segmentation and objectbased attention",Brain
Artificial intelligence-based identification of brain CT medical images,https://doi.org/10.1117/12.2652045,2023,"stroke is a group of diseases with severe brain tissue damage which are caused by either the sudden rupture of brain blood vessels cerebral hemorrhage or brain blood vessel obstruction leading to rapid changes and high mortality the diagnosis of stroke mainly relies on medical imaging techniques including computed tomography ct and magnetic resonance imaging mri which require experienced radiologists to guarantee suitable accuracy however the amount of brain ct image data is extremely large usually exceeding the technical capabilities of radiologists currently artificial intelligence has been applied into ct image analysis in order to achieve high sensitivity and specific diagnosis results for clinical examinations in this work we obtained ct images from a database cq500 including epidural hemorrhage cerebral parenchymal hemorrhage and intraventricular hemorrhage then we introduced a deeplearning algorithm based on unet model which was trained to generate image segmentation providing a calculated accuracy of prediction yield the results showed that the average intersection ratio of the final model on the test set could reach the value of 096 briefly artificial intelligence in this work can efficiently improve the analysis of brain ct images suggesting an important development direction for future medical imaging auxiliary diagnosis",Brain
Transcranial magnetic stimulation (TMS) localization by co-registration of facial point clouds,https://doi.org/10.1016/j.brs.2023.01.837,2023,"the effectiveness of transcranial magnetic stimulation tms is crucially dependent upon accurate localization to ensure treatment of the correct brain region the development of tms navigation systems represented a major advance upon the use of caps to subjectively position the tms coil on the scalp in particular after computer based coregistration of anatomical landmarks pinpointed on the patients head with corresponding landmarks pinpointed on a segmentation produced from a 3d magnetic resonance imaging mri scan the distance and angle between the stimulation coil and the relevant brain region in mri scan can be precisely and elegantly controlled 1",Brain
Prostate lesion segmentation based on a 3D end-to-end convolution neural network with deep multi-scale attention,https://doi.org/10.1016/j.mri.2023.01.015,2023,"prostate cancer is one of the deadest cancers among human beings to better diagnose the prostate cancer prostate lesion segmentation becomes a very important work but its progress is very slow due to the prostate lesions small in size irregular in shape and blurred in contour therefore automatic prostate lesion segmentation from mpmri is a great significant work and a challenging task however the most existing multistep segmentation methods based on voxellevel classification are timeconsuming may introduce errors in different steps and lead to error accumulation to decrease the computation time harness richer 3d spatial features and fuse the multilevel contextual information of mpmri we present an automatic segmentation method in which all steps are optimized conjointly as one step to form our endtoend convolutional neural network the proposed endtoend network dmsavnet consists of two parts 1 a 3d vnet is used as the backbone network it is the first attempt in employing 3d convolutional neural network for cs prostate lesion segmentation 2 a deep multiscale attention mechanism is introduced into the 3d vnet which can highly focus on the roi while suppressing the redundant background as a merit the attention can adaptively realign the context information between the feature maps at different scales and the saliency maps in highlevels we performed experiments based on five crossfold validation with data including 97 patients the results show that the dice and sensitivity are 07014 and 08652 respectively which demonstrates that our segmentation approach is more significant and accurate compared to other methods",Prostate
A General Bayesian Functional Spatial Partitioning Method for Multiple Region Discovery Applied to Prostate Cancer MRI,https://doi.org/10.1214/23-ba1366,2023,"current protocols to estimate the number size and location of cancerous lesions in the prostate using multiparametric magnetic resonance imaging mpmri are highly dependent on reader experience and expertise automatic voxelwise cancer classifiers do not directly provide estimates of number location and size of cancerous lesions that are clinically important existing spatial partitioning methods estimate linear or piecewiselinear boundaries separating regions of local stationarity in spatially registered data and are inadequate for the application of lesion detection frequentist segmentation and clustering methods often require prespecification of the number of clusters and do not quantify uncertainty previously we developed a novel bayesian functional spatial partitioning method to estimate the boundary surrounding a single cancerous lesion using data derived from mpmri we propose a bayesian functional spatial partitioning method for multiple lesion detection with an unknown number of lesions our method utilizes functional estimation to model the smooth boundary curves surrounding each cancerous lesion in a reversible jump markov chain monte carlo rjmcmc framework we develop novel jump steps to jointly estimate and quantify uncertainty in the number of lesions their boundaries and the spatial parameters in each lesion through simulation we show that our method is robust to the shape of the lesions number of lesions and regionspecific spatial processes we illustrate our method through the detection of prostate cancer lesions using mri",Prostate
Research on Segmentation Technology in Lung Cancer Radiotherapy Based on Deep Learning,https://doi.org/10.2174/1573405619666230123104243,2023,"lung cancer has the highest mortality rate among cancers radiation therapy rt is one of the most effective therapies for lung cancer the correct segmentation of lung tumors lts and organs at risk oars is the cornerstone of successful rtwe searched four databases for relevant material published in the last 10 years web of science pubmed science direct and google scholar the advancement of deep learningbased segmentation technology for lung cancer radiotherapy dslc research was examined from the perspectives of lts and oarsin this paper most of the dice similarity coefficient dsc values of lt segmentation in the surveyed literature were above 07 whereas the dsc indicators of oar segmentation were all over 08the contribution of this review is to summarize dslc research methods and the issues that dslc faces are discussed as well as possible viable solutions the purpose of this review is to encourage collaboration among experts in lung cancer radiotherapy and dl and to promote more research into the use of dl in lung cancer radiotherapy",Lung
Reducing Annotator's Burden: Cross-Pseudo Supervision for Brain Tumor Segmentation,https://doi.org/10.7557/18.6815,2023,"deep learning is proven to help with common medical image processing procedures namely segmentation labeling data is a core requirement for training a deep learning model this is timeconsuming and expert annotators are in short supply strategies that lower data annotation requirements are highly desirable in this study we adapt crosspseudo supervision cps for 3d medical segmentation a stateofart semisupervised deeplearning method where labeled and unlabeled data are used in conjunction to further improve the resulting model using the 2021 brats dataset a fully labeled publicly available brain tumor dataset we train cpsbased networks using a varying number of labeled and unlabeled samples and compare the resulting models against the fullysupervised baseline the results show that cps improves performance scores across all combinations of dataset sizes with an increase in the dice similarity coefficient dsc of 2642 and a decrease in the 95th percentile hausdorff distance 95 hd of 2427",Brain
Reducing Annotator's Burden: Cross-Pseudo Supervision for Brain Tumor Segmentation,https://doi.org/10.7557/18.6815,2023,"deep learning is proven to help with common medical image processing procedures namely segmentation labeling data is a core requirement for training a deep learning model this is timeconsuming and expert annotators are in short supply strategies that lower data annotation requirements are highly desirable in this study we adapt crosspseudo supervision cps for 3d medical segmentation a stateofart semisupervised deeplearning method where labeled and unlabeled data are used in conjunction to further improve the resulting model using the 2021 brats dataset a fully labeled publicly available brain tumor dataset we train cpsbased networks using a varying number of labeled and unlabeled samples and compare the resulting models against the fullysupervised baseline the results show that cps improves performance scores across all combinations of dataset sizes with an increase in the dice similarity coefficient dsc of 2642 and a decrease in the 95th percentile hausdorff distance 95 hd of 2427",Brain
3D Quantum-inspired Self-supervised Tensor Network for Volumetric Segmentation of Medical Images,https://doi.org/10.36227/techrxiv.12909860.v4,2023,"ltdivgtthis paper introduces a novel shallow 3d selfsupervised tensor neural network for volumetric segmentation of medical images with merits of obviating training and supervision the proposed network is referred to as 3d quantuminspired selfsupervised tensor neural network 3dqnet the underlying architecture of 3dqnet is composed of a trinity of volumetric layers viz input intermediate and output layers interconnected using an sconnected thirdorder neighborhoodbased topology for voxelwise processing of 3d medical image data suitable for semantic segmentation each of the volumetric layers contains quantum neurons designated by qubits or quantum bits the incorporation of tensor decomposition in quantum formalism leads to faster convergence of the network operations to preclude the inherent slow convergence problems faced by the classical supervised and selfsupervised networks the segmented volumes are obtained once the network converges the suggested 3dqnet is tailored and tested on the brats 2019 brain mr image data set and liver tumor segmentation challenge lits17 data set extensively in our experiments 3dqnet has achieved promising dice similarity as compared to the intensively supervised convolutional networkbased models like 3dunet voxresnet drinet and 3despnet showing a potential advantage of our selfsupervised shallow network on facilitating semantic segmentationltdivgt",Brain
3D Quantum-inspired Self-supervised Tensor Network for Volumetric Segmentation of Medical Images,https://doi.org/10.36227/techrxiv.12909860.v4,2023,"ltdivgtthis paper introduces a novel shallow 3d selfsupervised tensor neural network for volumetric segmentation of medical images with merits of obviating training and supervision the proposed network is referred to as 3d quantuminspired selfsupervised tensor neural network 3dqnet the underlying architecture of 3dqnet is composed of a trinity of volumetric layers viz input intermediate and output layers interconnected using an sconnected thirdorder neighborhoodbased topology for voxelwise processing of 3d medical image data suitable for semantic segmentation each of the volumetric layers contains quantum neurons designated by qubits or quantum bits the incorporation of tensor decomposition in quantum formalism leads to faster convergence of the network operations to preclude the inherent slow convergence problems faced by the classical supervised and selfsupervised networks the segmented volumes are obtained once the network converges the suggested 3dqnet is tailored and tested on the brats 2019 brain mr image data set and liver tumor segmentation challenge lits17 data set extensively in our experiments 3dqnet has achieved promising dice similarity as compared to the intensively supervised convolutional networkbased models like 3dunet voxresnet drinet and 3despnet showing a potential advantage of our selfsupervised shallow network on facilitating semantic segmentationltdivgt",Brain
Automatic Postoperative Brain Tumor Segmentation with Limited Data using Transfer Learning and Triplet Attention,https://doi.org/10.7557/18.6826,2023,"accurate brain tumor segmentation is clinically important for diagnosis and treatment planning convolutional neural networks cnns have achieved promising performance in various visual recognition tasks training such networks usually requires large amount of labeled data which is often challenging for medical applications in this work we address the segmentation problem by applying transfer learning to downstream segmentation tasks specifically we explore how knowledge acquired from a large preoperative dataset can be transferred to postoperative tumor segmentation on a smaller dataset to this end we have developed a 3d cnn for brain tumor segmentation and finetuned the pretrained models on the target domain data to better exploit the interchannel and spatial information triplet attention has been incorporated and extended into existing segmentation network extensive experiments on our dataset demonstrate the effectiveness of transfer learning and attention modules for improved postoperative tumor segmentation performance when only limited amount of annotated data is available",Brain
Error-Correcting Mean-Teacher: Corrections instead of consistency-targets applied to semi-supervised medical image segmentation,https://doi.org/10.1016/j.compbiomed.2023.106585,2023,"semantic segmentation is an essential task in medical imaging research many powerful deeplearningbased approaches can be employed for this problem but they are dependent on the availability of an expansive labeled dataset in this work we augment such supervised segmentation models to be suitable for learning from unlabeled data our semisupervised approach termed errorcorrecting meanteacher uses an exponential moving average model like the original mean teacher but introduces our new paradigm of error correction the original segmentation network is augmented to handle this secondary correction task both tasks build upon the core feature extraction layers of the model for the correction task features detected in the input image are fused with features detected in the predicted segmentation and further processed with taskspecific decoder layers the combination of image and segmentation features allows the model to correct present mistakes in the given input pair the correction task is trained jointly on the labeled data on unlabeled data the exponential moving average of the original network corrects the students prediction the combined outputs of the students prediction with the teachers correction form the basis for the semisupervised update we evaluate our method with the 2017 and 2018 robotic scene segmentation data the isic 2017 and the brats 2020 challenges a proprietary endoscopic submucosal dissection dataset cityscapes and pascal voc 2012 additionally we analyze the impact of the individual components and examine the behavior when the amount of labeled data varies with experiments performed on two distinct segmentation architectures our method shows improvements in terms of the mean intersection over union over the supervised baseline and competing methods code is available at httpsgithubcomclonerobecmt",Brain
WS-LungNet: A two-stage weakly-supervised lung cancer detection and diagnosis network,https://doi.org/10.1016/j.compbiomed.2023.106587,2023,"computeraided lung cancer diagnosis cad system on computed tomography ct helps radiologists guide preoperative planning and prognosis assessment the flexibility and scalability of deep learning methods are limited in lung cad in essence two significant challenges to be solved are 1 label scarcity due to cost annotations of ct images by experienced domain experts and 2 label inconsistency between the observed nodule malignancy and the patients pathology evaluation these two issues can be considered weak label problems we address these issues in this paper by introducing a weaklysupervised lung cancer detection and diagnosis network wslungnet consisting of a semisupervised computeraided detection semicade that can segment 3d pulmonary nodules based on unlabeled data through adversarial learning to reduce label scarcity as well as a crossnodule attention computeraided diagnosis cnacadx for evaluating malignancy at the patient level by modeling correlations between nodules via crossattention mechanisms and thereby eliminating label inconsistency through extensive evaluations on the lidcidri public database we show that our proposed method achieves 8299 competition performance metric cpm on pulmonary nodule detection and 8863 area under the curve auc on lung cancer diagnosis extensive experiments demonstrate the advantage of wslungnet on nodule detection and malignancy evaluation tasks our promising results demonstrate the benefits and flexibility of the semisupervised segmentation with adversarial learning and the nodule instance correlation learning with the attention mechanism the results also suggest that making use of the unlabeled data and taking the relationship among nodules in a case into account are essential for lung cancer detection and diagnosis",Lung
Segmenting lung parenchyma from CT images with gray correlation‐based clustering,https://doi.org/10.1049/ipr2.12744,2023,"lung segmentation a prerequisite step of lung disease detection in computeraided diagnosis system is a challenging task because of noises complex structures as well as large individual differences of lung ct scans here an automatic algorithm for segmenting lungs from thoracic ct images accurately is presented this scheme consists of three principal steps image preprocessing lung extracting and contour correcting to cope with inhomogeneous intensities of ct images a novel preprocessing approach based on empirical mode decomposition and bilateral filter is proposed which has abilities of denoising smoothing and edge keeping lung region is then extracted with a novel gray correlationbased clustering approach a new lung contour correction technology is finally employed to repair the concave regions caused by pulmonary nodules vessels and so on experimental results show that the preprocessing approach outperforms other methods on image denoising and smoothing meanwhile the lung segmentation algorithm is tested on a group of lung ct images affected with interstitial lung diseases and achieves a high segmentation accuracy compared with several existing lung segmentation methods this algorithm exhibits a better performance on lung segmentation",Lung
Segmenting lung parenchyma from CT images with gray correlation‐based clustering,https://doi.org/10.1049/ipr2.12744,2023,"lung segmentation a prerequisite step of lung disease detection in computeraided diagnosis system is a challenging task because of noises complex structures as well as large individual differences of lung ct scans here an automatic algorithm for segmenting lungs from thoracic ct images accurately is presented this scheme consists of three principal steps image preprocessing lung extracting and contour correcting to cope with inhomogeneous intensities of ct images a novel preprocessing approach based on empirical mode decomposition and bilateral filter is proposed which has abilities of denoising smoothing and edge keeping lung region is then extracted with a novel gray correlationbased clustering approach a new lung contour correction technology is finally employed to repair the concave regions caused by pulmonary nodules vessels and so on experimental results show that the preprocessing approach outperforms other methods on image denoising and smoothing meanwhile the lung segmentation algorithm is tested on a group of lung ct images affected with interstitial lung diseases and achieves a high segmentation accuracy compared with several existing lung segmentation methods this algorithm exhibits a better performance on lung segmentation",Lung
Analysis of High-Resolution CT Images of COVID-19 Patients,https://doi.org/10.1007/978-3-031-15542-0_12,2023,"abstractthis research work is carried out to quantify the covid19 disease and to explore whether the quantitative can be used to analyze the survivability of the patient during admission in this method a novel percentage split distribution psd thresholdingbased image segmentation method is proposed to quantify normal and lesion regions by analyzing the benign ggos the method segments the lungct image based on pixel distribution the segmented regions are quantified as a fraction of region of interest with total number of pixels the study is also extended to analyze the left and right lungs separately with some common findings on lesion distribution involved with covid19 disease the performance of psd method has been compared with two traditional image segmentationbased methods from the results it has been observed that the segments created by the psd method are better than experimental methods and clearly identify the margins of lesion and normal regionskeywordscovid19sarskmeansadaptive thresholdingggopsdlesion region",Lung
Analysis of High-Resolution CT Images of COVID-19 Patients,https://doi.org/10.1007/978-3-031-15542-0_12,2023,"abstractthis research work is carried out to quantify the covid19 disease and to explore whether the quantitative can be used to analyze the survivability of the patient during admission in this method a novel percentage split distribution psd thresholdingbased image segmentation method is proposed to quantify normal and lesion regions by analyzing the benign ggos the method segments the lungct image based on pixel distribution the segmented regions are quantified as a fraction of region of interest with total number of pixels the study is also extended to analyze the left and right lungs separately with some common findings on lesion distribution involved with covid19 disease the performance of psd method has been compared with two traditional image segmentationbased methods from the results it has been observed that the segments created by the psd method are better than experimental methods and clearly identify the margins of lesion and normal regionskeywordscovid19sarskmeansadaptive thresholdingggopsdlesion region",Lung
Unsupervised anomaly detection in brain MRI: Learning abstract distribution from massive healthy brains,https://doi.org/10.1016/j.compbiomed.2023.106610,2023,"to develop a general unsupervised anomaly detection method based only on mr images of normal brains to automatically detect various brain abnormalitiesin this study a novel method based on threedimensional deep autoencoder network is proposed to automatically detect and segment various brain abnormalities without being trained on any abnormal samples a total of 578 normal t2w mr volumes without obvious abnormalities were used for model training and validation the proposed 3d autoencoder was evaluated on two different datasets brats dataset and inhouse dataset containing t2w volumes from patients with glioblastoma multiple sclerosis and cerebral infarction lesions detection and segmentation performance were reported as auc precisionrecall curve sensitivity and dice scorein anomaly detection aucs for three typical lesions were as follows glioblastoma 0844 multiple sclerosis 0858 cerebral infarction 0807 in anomaly segmentation the mean dice for glioblastomas was 0462 the proposed network also has the ability to generate an anomaly heatmap for visualization purposeour proposed method was able to automatically detect various brain anomalies such as glioblastoma multiple sclerosis and cerebral infarction this work suggests that unsupervised anomaly detection is a powerful approach to detect arbitrary brain abnormalities without labeled samples it has the potential to support diagnostic workflow in radiology as an automated tool for computeraided image analysis",Brain
Unsupervised anomaly detection in brain MRI: Learning abstract distribution from massive healthy brains,https://doi.org/10.1016/j.compbiomed.2023.106610,2023,"to develop a general unsupervised anomaly detection method based only on mr images of normal brains to automatically detect various brain abnormalitiesin this study a novel method based on threedimensional deep autoencoder network is proposed to automatically detect and segment various brain abnormalities without being trained on any abnormal samples a total of 578 normal t2w mr volumes without obvious abnormalities were used for model training and validation the proposed 3d autoencoder was evaluated on two different datasets brats dataset and inhouse dataset containing t2w volumes from patients with glioblastoma multiple sclerosis and cerebral infarction lesions detection and segmentation performance were reported as auc precisionrecall curve sensitivity and dice scorein anomaly detection aucs for three typical lesions were as follows glioblastoma 0844 multiple sclerosis 0858 cerebral infarction 0807 in anomaly segmentation the mean dice for glioblastomas was 0462 the proposed network also has the ability to generate an anomaly heatmap for visualization purposeour proposed method was able to automatically detect various brain anomalies such as glioblastoma multiple sclerosis and cerebral infarction this work suggests that unsupervised anomaly detection is a powerful approach to detect arbitrary brain abnormalities without labeled samples it has the potential to support diagnostic workflow in radiology as an automated tool for computeraided image analysis",Brain
Dilated convolution network with edge fusion block and directional feature maps for cardiac MRI segmentation,https://doi.org/10.3389/fphys.2023.1027076,2023,"cardiac magnetic resonance imaging mri segmentation task refers to the accurate segmentation of ventricle and myocardium which is a prerequisite for evaluating the soundness of cardiac function with the development of deep learning in medical imaging more and more heart segmentation methods based on deep learning have been proposed due to the fuzzy boundary and uneven intensity distribution of cardiac mri some existing methods do not make full use of multiscale characteristic information and have the problem of ambiguity between classes in this paper we propose a dilated convolution network with edge fusion block and directional feature maps for cardiac mri segmentation the network uses feature fusion module to preserve boundary information and adopts the direction field module to obtain the feature maps to improve the original segmentation features firstly multiscale feature information is obtained and fused through dilated convolutional layers of different scales while downsampling secondly in the decoding stage the edge fusion block integrates the edge features into the side output of the encoder and concatenates them with the upsampled features finally the concatenated features utilize the direction field to improve the original segmentation features and generate the final result our propose method conducts comprehensive comparative experiments on the automated cardiac diagnosis challenge acdc and myocardial pathological segmentation myops datasets the results show that the proposed cardiac mri segmentation method has better performance compared to other existing methods",Cardiac
Dilated convolution network with edge fusion block and directional feature maps for cardiac MRI segmentation,https://doi.org/10.3389/fphys.2023.1027076,2023,"cardiac magnetic resonance imaging mri segmentation task refers to the accurate segmentation of ventricle and myocardium which is a prerequisite for evaluating the soundness of cardiac function with the development of deep learning in medical imaging more and more heart segmentation methods based on deep learning have been proposed due to the fuzzy boundary and uneven intensity distribution of cardiac mri some existing methods do not make full use of multiscale characteristic information and have the problem of ambiguity between classes in this paper we propose a dilated convolution network with edge fusion block and directional feature maps for cardiac mri segmentation the network uses feature fusion module to preserve boundary information and adopts the direction field module to obtain the feature maps to improve the original segmentation features firstly multiscale feature information is obtained and fused through dilated convolutional layers of different scales while downsampling secondly in the decoding stage the edge fusion block integrates the edge features into the side output of the encoder and concatenates them with the upsampled features finally the concatenated features utilize the direction field to improve the original segmentation features and generate the final result our propose method conducts comprehensive comparative experiments on the automated cardiac diagnosis challenge acdc and myocardial pathological segmentation myops datasets the results show that the proposed cardiac mri segmentation method has better performance compared to other existing methods",Cardiac
Brain Tumor Detection in Image Processing,https://doi.org/10.22214/ijraset.2023.48799,2023,"abstract mri plays a significant role in brain tumor analysis diagnosis and treatment planning its useful to doctor to determine the preceding steps of a brain tumor brain tumor detection and analysis by using mri images is a challenging task because of the complex structure of the brain abnormal growth of tissues in the brain which affect proper brain functions is considered as a brain tumor ctscan is not always preferred method for detection mri images provide greater result than ctscan and xrays in this numerous preprocessing postprocessing and methods like contrast enhancement filtering edge detection and postprocessing techniques like threshold segmentation histogram morphological operation through image processing ip tool and image segmentation techniques is available in matlab for detection of brain tumor images mriimages are discussed",Brain
GREnet: Gradually REcurrent Network With Curriculum Learning for 2-D Medical Image Segmentation,https://doi.org/10.1109/tnnls.2023.3238381,2023,"medical image segmentation is a vital stage in medical image analysis numerous deeplearning methods are booming to improve the performance of 2d medical image segmentation owing to the fast growth of the convolutional neural network generally the manually defined ground truth is utilized directly to supervise models in the training phase however direct supervision of the ground truth often results in ambiguity and distractors as complex challenges appear simultaneously to alleviate this issue we propose a gradually recurrent network with curriculum learning which is supervised by gradual information of the ground truth the whole model is composed of two independent networks one is the segmentation network denoted as grenet which formulates 2d medical image segmentation as a temporal task supervised by pixellevel gradual curricula in the training phase the other is a curriculummining network to a certain degree the curriculummining network provides curricula with an increasing difficulty in the ground truth of the training set by progressively uncovering hardtosegmentation pixels via a datadriven manner given that segmentation is a pixellevel denseprediction challenge to the best of our knowledge this is the first work to function 2d medical image segmentation as a temporal task with pixellevel curriculum learning in grenet the naive unet is adopted as the backbone while convlstm is used to establish the temporal link between gradual curricula in the curriculummining network unet inlineformula xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink texmath notationlatextexmath inlineformula supplemented by transformer is designed to deliver curricula through the outputs of the modified unet inlineformula xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink texmath notationlatextexmath inlineformula at different layers experimental results have demonstrated the effectiveness of grenet on seven datasets ie three lesion segmentation datasets in dermoscopic images an optic disc and cup segmentation dataset and a blood vessel segmentation dataset in retinal images a breast lesion segmentation dataset in ultrasound images and a lung segmentation dataset in computed tomography ct",Lung
Region Segmentation of Whole-Slide Images for Analyzing Histological Differentiation of Prostate Adenocarcinoma Using Ensemble EfficientNetB2 U-Net with Transfer Learning Mechanism,https://doi.org/10.3390/cancers15030762,2023,"recent advances in computeraided detection via deep learning dl now allow for prostate cancer to be detected automatically and recognized with extremely high accuracy much like other medical diagnoses and prognoses however researchers are still limited by the gleason scoring system the histopathological analysis involved in assigning the appropriate score is a rigorous timeconsuming manual process that is constrained by the quality of the material and the pathologists level of expertise in this research we implemented a dl model using transfer learning on a set of histopathological images to segment cancerous and noncancerous areas in wholeslide images wsis in this approach the proposed ensemble unet model was applied for the segmentation of stroma cancerous and benign areas the wsi dataset of prostate cancer was collected from the kaggle repository which is publicly available online a total of 1000 wsis were used for region segmentation from this 8100 patch images were used for training and 900 for testing the proposed model demonstrated an average dice coefficient dc intersection over union iou and hausdorff distance of 0891 0811 and 159 respectively on the test set with corresponding masks of patch images the manipulation of the proposed segmentation model improves the ability of the pathologist to predict disease outcomes thus enhancing treatment efficacy by isolating the cancerous regions in wsis",Prostate
A survey of machine learning-based methods for COVID-19 medical image analysis,https://doi.org/10.1007/s11517-022-02758-y,2023,"the ongoing covid19 pandemic caused by the sarscov2 virus has already resulted in 66 million deaths with more than 637 million people infected after only 30 months since the first occurrences of the disease in december 2019 hence rapid and accurate detection and diagnosis of the disease is the first priority all over the world researchers have been working on various methods for covid19 detection and as the disease infects lungs lung image analysis has become a popular research area for detecting the presence of the disease medical images from chest xrays cxr computed tomography ct images and lung ultrasound images have been used by automated image analysis systems in artificial intelligence ai and machine learning mlbased approaches various existing and novel ml deep learning dl transfer learning tl and hybrid models have been applied for detecting and classifying covid19 segmentation of infected regions assessing the severity and tracking patient progress from medical images of covid19 patients in this paper a comprehensive review of some recent approaches on covid19based image analyses is provided surveying the contributions of existing research efforts the available image datasets and the performance metrics used in recent works the challenges and future research scopes to address the progress of the fight against covid19 from the ai perspective are also discussed the main objective of this paper is therefore to provide a summary of the research works done in covid detection and analysis from medical image datasets using ml dl and tl models by analyzing their novelty and efficiency while mentioning other covid19based reviewsurvey researches to deliver a brief overview on the maximum amount of information on covid19based existing researches",Lung
A survey of machine learning-based methods for COVID-19 medical image analysis,https://doi.org/10.1007/s11517-022-02758-y,2023,"the ongoing covid19 pandemic caused by the sarscov2 virus has already resulted in 66 million deaths with more than 637 million people infected after only 30 months since the first occurrences of the disease in december 2019 hence rapid and accurate detection and diagnosis of the disease is the first priority all over the world researchers have been working on various methods for covid19 detection and as the disease infects lungs lung image analysis has become a popular research area for detecting the presence of the disease medical images from chest xrays cxr computed tomography ct images and lung ultrasound images have been used by automated image analysis systems in artificial intelligence ai and machine learning mlbased approaches various existing and novel ml deep learning dl transfer learning tl and hybrid models have been applied for detecting and classifying covid19 segmentation of infected regions assessing the severity and tracking patient progress from medical images of covid19 patients in this paper a comprehensive review of some recent approaches on covid19based image analyses is provided surveying the contributions of existing research efforts the available image datasets and the performance metrics used in recent works the challenges and future research scopes to address the progress of the fight against covid19 from the ai perspective are also discussed the main objective of this paper is therefore to provide a summary of the research works done in covid detection and analysis from medical image datasets using ml dl and tl models by analyzing their novelty and efficiency while mentioning other covid19based reviewsurvey researches to deliver a brief overview on the maximum amount of information on covid19based existing researches",Lung
Region‐related focal loss for 3D brain tumor MRI segmentation,https://doi.org/10.1002/mp.16244,2023,"in the brain tumor magnetic resonance image mri segmentation although the 3d convolution networks cnns has achieved stateoftheart results the class and hardvoxel imbalances in the 3d images have not been well addressed voxel independent losses are dependent on the setting of class weights for the class imbalance issue and are hard to assign each class equally regionrelated losses cannot correctly focus on hard voxels dynamically and not be robust to misclassification of small structures meanwhile repeatedly training on the additional hard samples augmented by existing methods would bring more class imbalance overfitting and incorrect knowledge learning to the modela novel regionrelated loss with balanced dynamic weighting while alleviating the sensitivity to small structures is necessary in addition we need to increase the diversity of hard samples in the training to improve the performance of modelthe proposed regionrelated focal loss rfl reshapes standard dice loss dl by upweighting the loss assigned to hardclassified voxels compared to dl rfl adaptively modulate its gradient with an invariant focalized point that voxels with lowerconfidence than it would achieve a larger gradient and higherconfidence voxels would get a smaller gradient meanwhile rfl can adjust the parameters to set where and how much the network is focused in addition an intraclassly transformed augmentation network itanet is proposed to increase the diversity of hard samples in which the 3d registration network and intraclass transfer layer are used to transform the shape and intensity respectively a selective hard sample miningshsm strategy is used to train the itanet for avoiding excessive class imbalance source code in tensorflow is available at httpsgithubcomlbwhurflitathe experiments are carried out on public data set brain tumor segmentation challenge 2020 brats2020 experiments with brats2020 online validation set show that proposed methods achieve an average dice scores of 0905 0821 and 0806 for whole tumor wt tumor core tc and enhancing tumor et respectively compared with dl baseline the proposed rfl significantly improves the dice scores by an average of 1 and for the small region et it can even increase by 3 and the proposed method combined with itanet improves the dice scores of et and tc by 5 and 3 respectivelythe proposed rfl can converge with a invariant focalized point in the training of segmentation network thus effectively alleviating the hardvoxel imbalance in brain tumor mri segmentation the negative region term of rfl can effectively reduce the sensitivity of the segmentation model to the misclassification of small structures the proposed itanet can increase the diversity of hard samples by transforming their shape and transfer their intraclass intensity thereby effectively improving the robustness of the segmentation network to hard samples",Brain
Region‐related focal loss for 3D brain tumor MRI segmentation,https://doi.org/10.1002/mp.16244,2023,"in the brain tumor magnetic resonance image mri segmentation although the 3d convolution networks cnns has achieved stateoftheart results the class and hardvoxel imbalances in the 3d images have not been well addressed voxel independent losses are dependent on the setting of class weights for the class imbalance issue and are hard to assign each class equally regionrelated losses cannot correctly focus on hard voxels dynamically and not be robust to misclassification of small structures meanwhile repeatedly training on the additional hard samples augmented by existing methods would bring more class imbalance overfitting and incorrect knowledge learning to the modela novel regionrelated loss with balanced dynamic weighting while alleviating the sensitivity to small structures is necessary in addition we need to increase the diversity of hard samples in the training to improve the performance of modelthe proposed regionrelated focal loss rfl reshapes standard dice loss dl by upweighting the loss assigned to hardclassified voxels compared to dl rfl adaptively modulate its gradient with an invariant focalized point that voxels with lowerconfidence than it would achieve a larger gradient and higherconfidence voxels would get a smaller gradient meanwhile rfl can adjust the parameters to set where and how much the network is focused in addition an intraclassly transformed augmentation network itanet is proposed to increase the diversity of hard samples in which the 3d registration network and intraclass transfer layer are used to transform the shape and intensity respectively a selective hard sample miningshsm strategy is used to train the itanet for avoiding excessive class imbalance source code in tensorflow is available at httpsgithubcomlbwhurflitathe experiments are carried out on public data set brain tumor segmentation challenge 2020 brats2020 experiments with brats2020 online validation set show that proposed methods achieve an average dice scores of 0905 0821 and 0806 for whole tumor wt tumor core tc and enhancing tumor et respectively compared with dl baseline the proposed rfl significantly improves the dice scores by an average of 1 and for the small region et it can even increase by 3 and the proposed method combined with itanet improves the dice scores of et and tc by 5 and 3 respectivelythe proposed rfl can converge with a invariant focalized point in the training of segmentation network thus effectively alleviating the hardvoxel imbalance in brain tumor mri segmentation the negative region term of rfl can effectively reduce the sensitivity of the segmentation model to the misclassification of small structures the proposed itanet can increase the diversity of hard samples by transforming their shape and transfer their intraclass intensity thereby effectively improving the robustness of the segmentation network to hard samples",Brain
A comparison of manual and automated neural architecture search for white matter tract segmentation,https://doi.org/10.1038/s41598-023-28210-1,2023,"abstract segmentation of white matter tracts in diffusion magnetic resonance images is an important first step in many imaging studies of the brain in health and disease similar to medical image segmentation in general a popular approach to white matter tract segmentation is to use unet based artificial neural network architectures despite many suggested improvements to the unet architecture in recent years there is a lack of systematic comparison of architectural variants for white matter tract segmentation in this paper we evaluate multiple unet based architectures specifically for this purpose we compare the results of these networks to those achieved by our own various architecture changes as well as to new unet architectures designed automatically via neural architecture search nas to the best of our knowledge this is the first study to systematically compare multiple unet based architectures for white matter tract segmentation and the first to use nas we find that the recently proposed medical imaging segmentation network unet3 slightly outperforms the current state of the art for white matter tract segmentation and achieves a notably better mean dice score for segmentation of the fornix 001 and 0006 mean dice increase for left and right fornix respectively a tract that the current state of the art model struggles to segment unet3 also outperforms the current state of the art when little training data is available additionally manual architecture search found that a minor segmentation improvement is observed when an additional deeper layer is added to the ushape of unet3 however all networks including those designed via nas achieve similar results suggesting that there may be benefit in exploring networks that deviate from the general unet paradigm",Brain
Myocardial Segmentation of Tagged Magnetic Resonance Images with Transfer Learning Using Generative Cine-To-Tagged Dataset Transformation,https://doi.org/10.3390/bioengineering10020166,2023,"the use of deep learning dl segmentation in cardiac mri has the potential to streamline the radiology workflow particularly for the measurement of myocardial strain recent efforts in dl motion tracking models have drastically reduced the time needed to measure the hearts displacement field and the subsequent myocardial strain estimation however the selection of initial myocardial reference points is not automated and still requires manual input from domain experts segmentation of the myocardium is a key step for initializing reference points while highperforming myocardial segmentation models exist for cine images this is not the case for tagged images in this work we developed and compared two novel dl models nnunet and segmentation resnet vae for the segmentation of myocardium from tagged cmr images we implemented two methods to transform cardiac cine images into tagged images allowing us to leverage large public annotated cine datasets the cinetotagged methods included i a novel physicsdriven transformation model and ii a generative adversarial network gan style transfer model we show that pretrained models perform better 28 dice coefficient percentage points and converge faster 6 than models trained from scratch the bestperforming method relies on a pretraining with an unpaired unlabeled and structurepreserving generative model trained to transform cine images into their taggedappearing equivalents our stateoftheart myocardium segmentation network reached a dice coefficient of 0828 and 95th percentile hausdorff distance of 4745 mm on a heldout test set this performance is comparable to existing stateoftheart segmentation networks for cine images",Cardiac
Automatic Detection and Segmentation of Postoperative Cerebellar Damage Based on Normalization,https://doi.org/10.1093/noajnl/vdad006,2023,"abstract background surgical resection is the gold standard in the treatment of pediatric posterior fossa tumors however surgical damage is often unavoidable and its association with postoperative complications is not well understood a reliable localization and measure of cerebellar damage is fundamental to study the relationship between the damaged cerebellar regions and postoperative neurological outcomes existing cerebellum normalization methods are likely to fail on postoperative scans therefore current approaches to measure postoperative damage rely on manual labelling in this work we develop a robust algorithm to automatically detect and measure cerebellum damage in postoperative 3d t1 magnetic resonance imaging mri methods in our approach normal brain tissues are first segmented using a bayesian algorithm customized for postoperative scans next the cerebellum is isolated by nonlinear registration of a wholebrain template to the native space the isolated cerebellum is then normalized into the spatially unbiased atlas suit space using anatomical information derived from the previous step finally the damage is detected in the atlas space by comparing the normalized cerebellum and the suit template results we evaluated our damage detection tool on postoperative scans of 153 patients with medulloblastoma based on inspection by human experts we also designed a simulation to evaluate performance without human intervention and with an explicitly controlled and defined ground truth our results show that the approach performs adequately under various realistic conditions conclusions we develop an accurate robust and fully automatic localization and measurement of cerebellar damage in the atlas space using postoperative mri",Brain
Attention Mechanism Trained with Small Datasets for Biomedical Image Segmentation,https://doi.org/10.3390/electronics12030682,2023,"the understanding of longrange pixelpixel dependencies plays a vital role in image segmentation the use of a cnn plus an attention mechanism still has room for improvement since existing transformerbased architectures require many thousands of annotated training samples to model longrange spatial dependencies this paper presents a smooth attention branch sab a novel architecture that simplifies the understanding of longrange pixelpixel dependencies for biomedical image segmentation in small datasets the sab is essentially a modified attention operation that implements a subnetwork via reshaped feature maps instead of directly calculating a softmax value over the attention score for each input the sab fuses multilayer attentive feature maps to learn visual attention in multilevel features we also introduce position blurring and inner cropping specifically for smallscale datasets to prevent overfitting furthermore we redesign the skip pathway for the reduction of the semantic gap between every captured feature of the contracting and expansive path we evaluate the architecture of unet with the sab sabnet by comparing it with the original unet and widely used transformerbased models across multiple biomedical image segmentation tasks related to the brain mri heart mri liver ct spleen ct and colonoscopy datasets our training set was made of random 100 images of the original training set since our goal was to adopt attention mechanisms for biomedical image segmentation tasks with smallscale labeled data an ablation study conducted on the brain mri test set demonstrated that every proposed method achieved an improvement in biomedical image segmentation integrating the proposed methods helped the resulting models consistently achieve outstanding performance on the above five biomedical segmentation tasks in particular the proposed method with unet improved its segmentation performance over that of the original unet by 1376 on the brain mri dataset we proposed several novel methods to address the need for modeling longrange pixelpixel dependencies in smallscale biomedical image segmentation the experimental results illustrated that each method could improve the medical image segmentation accuracy to various degrees moreover sabnet which integrated all proposed methods consistently achieved outstanding performance on the five biomedical segmentation tasks",Brain
Brain MRI Image Active Contour Segmentation for Healthcare Systems,https://doi.org/10.1201/9781003248750-8,2023,"the segmentation and identification of neoplasm from brain mr images have gotten enormous consideration in the zone of biomedical research analysis segmentation is the way toward parting an image into various sections called segments the precise segmentation of brain mr images into different units assumes a significant job in the early analysis and treatment of carcinoma in this chapter an active contour chanvese segmentation algorithm is used this algorithm comprises two energies of which one power diminishes the form and the other expansion of the shape these two energies get adjusted when the chapter arrives at the furthest point of our ideal item which brings about total segmentation the proposed design comprises five fundamental steps preprocessing creation of an introductory mask giving the most extreme number of cyclesiterations application of chanvese active contour approach for the finding of the tumor and extraction of its region the competence of the proposed design has been tested on various brain mr images we have found that the proposed methodology can detect and extract the tumor and its area",Brain
Mapping Resection Progress by Tool-Tip Tracking during Brain Tumor Surgery for Real-Time Estimation of Residual Tumor,https://doi.org/10.3390/cancers15030825,2023,"surgical resection continues to be the primary initial therapeutic strategy in the treatment of patients with brain tumors computerized cranial neuronavigation based on preoperative imaging offers precision guidance during craniotomy and early tumor resection but progressively loses validity with brain shift intraoperative mri imri and intraoperative ultrasound ius can update the imaging used for guidance and navigation but are limited in terms of temporal and spatial resolution respectively we present a system that uses timestamped tooltip positions of surgical instruments to generate a map of resection progress with high spatial and temporal accuracy we evaluate this system and present results from 80 cranial tumor resections regions of the preoperative tumor segmentation that are covered by the resection map true positive tracking and regions of the preoperative tumor segmentation not covered by the resection map true negative tracking are determined for each case we compare true negative tracking which estimates the residual tumor with the actual residual tumor identified using imri we discuss factors that can cause false positive tracking and false negative tracking which underestimate and overestimate the residual tumor respectively our method provides good estimates of the residual tumor when there is minimal brain shift and lineofsight is maintained when these conditions are not met surgeons report that it is still useful for identifying regions of potential residual",Brain
An Overview of Deep Learning Methods for Left Ventricle Segmentation,https://doi.org/10.1155/2023/4208231,2023,"cardiac health diseases are one of the key causes of death around the globe the number of heart patients has considerably increased during the pandemic therefore it is crucial to assess and analyze the medical and cardiac images deep learning architectures specifically convolutional neural networks have profoundly become the primary choice for the assessment of cardiac medical images the left ventricle is a vital part of the cardiovascular system where the boundary and size perform a significant role in the evaluation of cardiac function due to automatic segmentation and good promising results the left ventricle segmentation using deep learning has attracted a lot of attention this article presents a critical review of deep learning methods used for the left ventricle segmentation from frequently used imaging modalities including magnetic resonance images ultrasound and computer tomography this study also demonstrates the details of the network architecture software and hardware used for training along with publicly available cardiac image datasets and selfprepared dataset details incorporated the summary of the evaluation matrices with results used by different researchers is also presented in this study finally all this information is summarized and comprehended in order to assist the readers to understand the motivation and methodology of various deep learning models as well as exploring potential solutions to future challenges in lv segmentation",Cardiac
Improved UNet Deep Learning Model for Automatic Detection of Lung Cancer Nodules,https://doi.org/10.1155/2023/9739264,2023,"uncontrolled cell growth in the two spongy lung organs in the chest is the most prevalent kind of cancer when cells from the lungs spread to other tissues and organs this is referred to as metastasis this work uses image processing deep learning and metaheuristics to identify cancer in its early stages at this point a new convolutional neural network is constructed the predator technique has the potential to increase network architecture and accuracy deep learning identified lung cancer spinal metastases in as energy consumption increased ct readings for lung cancer bone metastases decreased qualified physicians on the other hand discovered 7114 and 7460 percent of targets with energies of 140 and 60 kev respectively whereas the proposed model gives 7651 and 8158 percent respectively expert physicians detection rate was 7460 percent lower than deep learnings detection rate of 8158 percent the proposed method has the highest accuracy sensitivity and specificity 934 984 and 971 percent respectively as well as the lowest error rate 16 percent finally in lung segmentation the proposed model outperforms the cnn model highintensity energyspectral ct images are more difficult to segment than lowintensity energyspectral ct images",Lung
Improved UNet Deep Learning Model for Automatic Detection of Lung Cancer Nodules,https://doi.org/10.1155/2023/9739264,2023,"uncontrolled cell growth in the two spongy lung organs in the chest is the most prevalent kind of cancer when cells from the lungs spread to other tissues and organs this is referred to as metastasis this work uses image processing deep learning and metaheuristics to identify cancer in its early stages at this point a new convolutional neural network is constructed the predator technique has the potential to increase network architecture and accuracy deep learning identified lung cancer spinal metastases in as energy consumption increased ct readings for lung cancer bone metastases decreased qualified physicians on the other hand discovered 7114 and 7460 percent of targets with energies of 140 and 60 kev respectively whereas the proposed model gives 7651 and 8158 percent respectively expert physicians detection rate was 7460 percent lower than deep learnings detection rate of 8158 percent the proposed method has the highest accuracy sensitivity and specificity 934 984 and 971 percent respectively as well as the lowest error rate 16 percent finally in lung segmentation the proposed model outperforms the cnn model highintensity energyspectral ct images are more difficult to segment than lowintensity energyspectral ct images",Lung
Simulating Federated Transfer Learning for Lung Segmentation using Modified UNet Model,https://doi.org/10.1016/j.procs.2023.01.127,2023,"lung segmentation helps doctors in analyzing and diagnosing lung diseases effectively covid 19 pandemic highlighted the need for such artificial intelligence ai model to segment lung xray images and diagnose patient covid conditions in a short time which was not possible due to huge number of patient influx at hospitals with the limited radiologist to diagnose based on test report in short time ai models developed to assist doctors to diagnose faster faces another challenge of data privacy such ai models for better performance need huge data collected from multiple hospitalsdiagnostic centres across the globe into single place to train the ai models federated learning fl framework using transfer learning approach addresses these concerns as fl framework doesnt need data to be shared to outside hospital ecosystem as ai model get trained on local system and ai model get trained on distributed data fl with transfer learning doesnt need the parallel training of the model at all participants nodes like other fl paper simulates federated transfer learning for image segmentation using transfer learning technique with few participating nodes and each nodes having different size dataset the proposed method also leverages other healthcare data available at local system to train the proposed model to overcome lack of more data paper uses pretrained weights of unet segmentation model trained for mri image segmentation to lung segmentation model paper demonstrates using such similar healthcare data available at local system helps improving the performance of the model the paper uses explainable ai approach to explain the result using above three techniques lung segmentation ai model gets near perfect segmentation accuracy",Lung
How should studies using AI be reported? lessons from a systematic review in cardiac MRI,https://doi.org/10.3389/fradi.2023.1112841,2023,"recent years have seen a dramatic increase in studies presenting artificial intelligence ai tools for cardiac imaging amongst these are ai tools that undertake segmentation of structures on cardiac mri cmr an essential step in obtaining clinically relevant functional information the quality of reporting of these studies carries significant implications for advancement of the field and the translation of ai tools to clinical practice we recently undertook a systematic review to evaluate the quality of reporting of studies presenting automated approaches to segmentation in cardiac mri alabed et al 2022 quality of reporting in ai cardiac mri segmentation studiesa systematic review and recommendations for future studies frontiers in cardiovascular medicine 9956811 209 studies were assessed for compliance with the checklist for ai in medical imaging claim a framework for reporting we found variableand sometimes poorquality of reporting and identified significant and frequently missing information in publications compliance with claim was high for descriptions of models 100 iqr 80100 but lower than expected for descriptions of study design 71 iqr 6386 datasets used in training and testing 63 iqr 5067 and model performance 60 iqr 5070 here we present a summary of our key findings aimed at general readers who may not be experts in ai and use them as a framework to discuss the factors determining quality of reporting making recommendations for improving the reporting of research in this field we aim to assist researchers in presenting their work and readers in their appraisal of evidence finally we emphasise the need for close scrutiny of studies presenting ai tools even in the face of the excitement surrounding ai in cardiac imaging",Cardiac
Detection &amp; Quantification of Lung Nodules Using 3D CT images,https://doi.org/10.33411/ijist/2023050105,2023,"in computer vision image detection and quantification play an important role image detection and quantification is the process of identifying nodule position and the amount of covered area the dataset which we have used for this research contains 3d ct lung images in our proposed work we have taken 3d images and those are highresolution images we have compared the accuracy of the existing mask and our segmented images the segmentation method that we have applied to these images is sparse field method localized regionbased segmentation and for nodule detection i have used ray projection the ray projection method is efficient for making the point more visible by its x y and z components like a parametric equation where the line crossing through a targeted point by that nodule is more dominated the frangi filter was to give a geometric shape to the nodule and we got 90 accurate detection the high mortality rate associated with lung cancer makes it imperative that it be detected at an early stage the application of computerized image processing methods has the potential to improve both the efficiency and reliability of lung cancer screening computerized tomography ct pictures are frequently used in medical image processing because of their excellent resolution and low noise computeraided detection systems including preprocessing and segmentation methods as well as data analysis approaches have been investigated in this research for their potential use in the detection and diagnosis of lung cancer the primary objective was to research cuttingedge methods for creating computational diagnostic tools to aid in the collection processing and interpretation of medical imaging data nonetheless there are still areas that need more work such as improving sensitivity decreasing false positives and optimizing the identification of each type of nodule even those of varying size and form",Lung
Harmonizing Flows: Unsupervised MR harmonization based on normalizing  flows,https://doi.org/10.48550/arxiv.2301.11551,2023,"in this paper we propose an unsupervised framework based on normalizing flows that harmonizes mr images to mimic the distribution of the source domain the proposed framework consists of three steps first a shallow harmonizer network is trained to recover images of the source domain from their augmented versions a normalizing flow network is then trained to learn the distribution of the source domain finally at test time a harmonizer network is modified so that the output images match the source domains distribution learned by the normalizing flow model our unsupervised sourcefree and taskindependent approach is evaluated on crossdomain brain mri segmentation using data from four different sites results demonstrate its superior performance compared to existing methods",Brain
CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac  Anatomy,https://doi.org/10.48550/arxiv.2301.13098,2023,"two key questions in cardiac image analysis are to assess the anatomy and motion of the heart from images and to understand how they are associated with nonimaging clinical factors such as gender age and diseases while the first question can often be addressed by image segmentation and motion tracking algorithms our capability to model and to answer the second question is still limited in this work we propose a novel conditional generative model to describe the 4d spatiotemporal anatomy of the heart and its interaction with nonimaging clinical factors the clinical factors are integrated as the conditions of the generative modelling which allows us to investigate how these factors influence the cardiac anatomy we evaluate the model performance in mainly two tasks anatomical sequence completion and sequence generation the model achieves a high performance in anatomical sequence completion comparable to or outperforming other stateoftheart generative models in terms of sequence generation given clinical conditions the model can generate realistic synthetic 4d sequential anatomies that share similar distributions with the real data",Cardiac
Neural Gas Network Image Features and Segmentation for Brain Tumor  Detection Using Magnetic Resonance Imaging Data,https://doi.org/10.48550/arxiv.2301.12176,2023,"accurate detection of brain tumors could save lots of lives and increasing the accuracy of this binary classification even as much as a few percent has high importance neural gas networks ngn is a fast unsupervised algorithm that could be used in data clustering image pattern recognition and image segmentation in this research we used the metaheuristic firefly algorithm fa for image contrast enhancement as preprocessing and ngn weights for feature extraction and segmentation of magnetic resonance imaging mri data on two brain tumor datasets from the kaggle platform also tumor classification is conducted by support vector machine svm classification algorithms and compared with a deep learning technique plus other features in train and test phases additionally ngn tumor segmentation is evaluated by famous performance metrics such as accuracy fmeasure jaccard and more versus ground truth data and compared with traditional segmentation techniques the proposed method is fast and precise in both tasks of tumor classification and segmentation compared with other methods a classification accuracy of 9514 and segmentation accuracy of 0977 is achieved by the proposed method",Brain
MRI brain tumor segmentation using residual Spatial Pyramid Pooling-powered 3D U-Net,https://doi.org/10.3389/fpubh.2023.1091850,2023,"brain tumor diagnosis has been a lengthy process and automation of a process such as brain tumor segmentation speeds up the timeline unets have been a commonly used solution for semantic segmentation and it uses a downsamplingupsampling approach to segment tumors unets rely on residual connections to pass information during upsampling however an upsampling block only receives information from one downsampling block this restricts the context and scope of an upsampling block in this paper we propose sppunet where the residual connections are replaced with a combination of spatial pyramid pooling spp and attention blocks here spp provides information from various downsampling blocks which will increase the scope of reconstruction while attention provides the necessary context by incorporating local characteristics with their corresponding global dependencies existing literature uses heavy approaches such as the usage of nested and dense skip connections and transformers these approaches increase the training parameters within the model which therefore increase the training time and complexity of the model the proposed approach on the other hand attains comparable results to existing literature without changing the number of trainable parameters over larger dimensions such as 160 192 192 all in all the proposed model scores an average dice score of 0883 and a hausdorff distance of 784 on brats 2021 cross validation",Brain
MRI brain tumor segmentation using residual Spatial Pyramid Pooling-powered 3D U-Net,https://doi.org/10.3389/fpubh.2023.1091850,2023,"brain tumor diagnosis has been a lengthy process and automation of a process such as brain tumor segmentation speeds up the timeline unets have been a commonly used solution for semantic segmentation and it uses a downsamplingupsampling approach to segment tumors unets rely on residual connections to pass information during upsampling however an upsampling block only receives information from one downsampling block this restricts the context and scope of an upsampling block in this paper we propose sppunet where the residual connections are replaced with a combination of spatial pyramid pooling spp and attention blocks here spp provides information from various downsampling blocks which will increase the scope of reconstruction while attention provides the necessary context by incorporating local characteristics with their corresponding global dependencies existing literature uses heavy approaches such as the usage of nested and dense skip connections and transformers these approaches increase the training parameters within the model which therefore increase the training time and complexity of the model the proposed approach on the other hand attains comparable results to existing literature without changing the number of trainable parameters over larger dimensions such as 160 192 192 all in all the proposed model scores an average dice score of 0883 and a hausdorff distance of 784 on brats 2021 cross validation",Brain
SynthSR: A public AI tool to turn heterogeneous clinical brain scans into high-resolution T1-weighted images for 3D morphometry,https://doi.org/10.1126/sciadv.add3607,2023,"every year millions of brain magnetic resonance imaging mri scans are acquired in hospitals across the world these have the potential to revolutionize our understanding of many neurological diseases but their morphometric analysis has not yet been possible due to their anisotropic resolution we present an artificial intelligence technique synthsr that takes clinical brain mri scans with any mr contrast t1 t2 etc orientation axialcoronalsagittal and resolution and turns them into highresolution t1 scans that are usable by virtually all existing human neuroimaging tools we present results on segmentation registration and atlasing of 10000 scans of controls and patients with brain tumors strokes and alzheimers disease synthsr yields morphometric results that are very highly correlated with what one would have obtained with highresolution t1 scans synthsr allows sample sizes that have the potential to overcome the power limitations of prospective research studies and shed new light on the healthy and diseased human brain",Brain
ANN: Concept and Application in Brain Tumor Segmentation,https://doi.org/10.1007/978-981-19-5723-9_12,2023,"medical expert analyses brain mr images to segment the tumor area the report may vary according to the machines or the experience of operators automating the process of brain tumor segmentation based on mris is a greater need to maintain uniformity in addition provide a report to the doctor with high accuracy to proceed with the diagnosis of the patient many researchers have applied ann in training the model to segment the tumorous cells in the mr images using ann multiple stateofart methods have been proposed with promising results motivated with architecture and performance of neural network in this chapter we discussed the working of ann artificial neural network and its application in brain tumor segmentation",Brain
CaraNet: Context Axial Reverse Attention Network for Segmentation of  Small Medical Objects,https://doi.org/10.48550/arxiv.2301.13366,2023,"segmenting medical images accurately and reliably is important for disease diagnosis and treatment it is a challenging task because of the wide variety of objects sizes shapes and scanning modalities recently many convolutional neural networks cnn have been designed for segmentation tasks and achieved great success few studies however have fully considered the sizes of objects and thus most demonstrate poor performance for small objects segmentation this can have a significant impact on the early detection of diseases this paper proposes a context axial reverse attention network caranet to improve the segmentation performance on small objects compared with several recent stateoftheart models caranet applies axial reserve attention ara and channelwise feature pyramid cfp module to dig feature information of small medical object and we evaluate our model by six different measurement metrics we test our caranet on brain tumor brats 2018 and polyp kvasirseg cvccolondb cvcclinicdb cvc300 and etislaribpolypdb segmentation datasets our caranet achieves the toprank mean dice segmentation accuracy and results show a distinct advantage of caranet in the segmentation of small medical objects",Brain
CaraNet: Context Axial Reverse Attention Network for Segmentation of  Small Medical Objects,https://doi.org/10.48550/arxiv.2301.13366,2023,"segmenting medical images accurately and reliably is important for disease diagnosis and treatment it is a challenging task because of the wide variety of objects sizes shapes and scanning modalities recently many convolutional neural networks cnn have been designed for segmentation tasks and achieved great success few studies however have fully considered the sizes of objects and thus most demonstrate poor performance for small objects segmentation this can have a significant impact on the early detection of diseases this paper proposes a context axial reverse attention network caranet to improve the segmentation performance on small objects compared with several recent stateoftheart models caranet applies axial reserve attention ara and channelwise feature pyramid cfp module to dig feature information of small medical object and we evaluate our model by six different measurement metrics we test our caranet on brain tumor brats 2018 and polyp kvasirseg cvccolondb cvcclinicdb cvc300 and etislaribpolypdb segmentation datasets our caranet achieves the toprank mean dice segmentation accuracy and results show a distinct advantage of caranet in the segmentation of small medical objects",Brain
Deep learning estimation of three-dimensional left atrial shape from two-chamber and four-chamber cardiac long axis views,https://doi.org/10.1093/ehjci/jead010,2023,"abstract aims left atrial volume is commonly estimated using the biplane arealength method from twochamber 2ch and fourchamber 4ch long axes views however this can be inaccurate due to a violation of geometric assumptions we aimed to develop a deep learning neural network to infer 3d left atrial shape volume and surface area from 2ch and 4ch views methods and results a 3d unet was trained and tested using 2ch and 4ch segmentations generated from 3d coronary computed tomography angiography ccta segmentations n 1700 with 1400100200 cases for trainingvalidatingtesting an independent test dataset from another institution was also evaluated using cardiac magnetic resonance cmr 2ch and 4ch segmentations as input and 3d ccta segmentations as the ground truth n 20 for the 200 test cases generated from ccta the network achieved a mean dice score value of 937 showing excellent 3d shape reconstruction from two views compared with the 3d segmentation dice of 974 the network also showed significantly lower mean absolute error values of 35 ml49 cm2 for la volumesurface area respectively compared to the arealength method errors of 130 ml341 cm2 respectively p amplt 005 for both for the independent cmr test set the network achieved accurate 3d shape estimation mean dice score value of 874 and a mean absolute error values of 60 ml57 cm2 for left atrial volumesurface area respectively significantly less than the arealength method errors of 142 ml193 cm2 respectively p amplt 005 for both conclusions compared to the biplane arealength method the network showed higher accuracy and robustness for both volume and surface area",Cardiac
Segmentation of beating embryonic heart structures from 4-D OCT images using deep learning,https://doi.org/10.1364/opticaopen.21973721.v1,2023,"optical coherence tomography oct has been used to investigate heart development because of its capability to image both structure and function of beating embryonic hearts cardiac structure segmentation is a prerequisite for quantification of embryonic heart motion and function using oct since manual segmentation is timeconsuming and laborintensive an automatic method is needed to facilitate highthroughput studies the purpose of this study is to develop an image processing pipeline to facilitate the segmentation of beating embryonic heart structures from a 4d oct dataset sequential oct images were obtained at multiple planes of a beating quail embryonic heart and reassembled to a 4d dataset using imagebased retrospective gating multiple image volumes at different time points were selected as keyvolumes and their cardiac structures including myocardium cardiac jelly and lumen were manually labeled registrationbased data augmentation was used to synthesize additional labeled image volumes by learning transformations between keyvolumes and other unlabeled volumes the synthesized labeled images were then used to train a fully convolutional network unet for heart structure segmentation the proposed deep learningbased pipeline achieved high segmentation accuracy with only two labeled image volumes and reduced the time cost of segmenting one 4d oct dataset from a week to two hours using this method one could carry out cohort studies that quantify complex cardiac motion and function in developing hearts",Cardiac
Segmentation of beating embryonic heart structures from 4-D OCT images using deep learning,https://doi.org/10.1364/opticaopen.21973721,2023,"optical coherence tomography oct has been used to investigate heart development because of its capability to image both structure and function of beating embryonic hearts cardiac structure segmentation is a prerequisite for quantification of embryonic heart motion and function using oct since manual segmentation is timeconsuming and laborintensive an automatic method is needed to facilitate highthroughput studies the purpose of this study is to develop an image processing pipeline to facilitate the segmentation of beating embryonic heart structures from a 4d oct dataset sequential oct images were obtained at multiple planes of a beating quail embryonic heart and reassembled to a 4d dataset using imagebased retrospective gating multiple image volumes at different time points were selected as keyvolumes and their cardiac structures including myocardium cardiac jelly and lumen were manually labeled registrationbased data augmentation was used to synthesize additional labeled image volumes by learning transformations between keyvolumes and other unlabeled volumes the synthesized labeled images were then used to train a fully convolutional network unet for heart structure segmentation the proposed deep learningbased pipeline achieved high segmentation accuracy with only two labeled image volumes and reduced the time cost of segmenting one 4d oct dataset from a week to two hours using this method one could carry out cohort studies that quantify complex cardiac motion and function in developing hearts",Cardiac
Abstract TMP69: Random Rater Sampling For Deep Learning Algorithm To Segment Acute Ischemic Stroke On Non-contrast Computed Tomography,https://doi.org/10.1161/str.54.suppl_1.tmp69,2023,"introduction the delineation of volume and location of acute ischemic brain tissue aibt on noncontrast ct ncct increases the efficiency of endovascular treatment decisions however the manual segmentation of the aibt on ncct is a challenging task and suffers from low interexpert agreement whether supervised deep convolutional neural networks cnn are more accurate than expert raters remain to be determined and the optimal ground truth segmentation of aibt is unclear given the low interexpert agreement we hypothesized that randomly sampling ground truth segmentations of expert raters would enable the cnn to better approximate an accurate ground truth and increase performance methods the data set consisted of 200 ncct images figure 1a of acute ischemic stroke patients presenting within 616h and consenting to the defuse3 trial three experienced neuroradiologists manually segmented the aibt figure 1b13 the aggregated validation sets of 5foldcrossvalidation were used to compare the i average interexpert agreement the average performance of ii three individual cnns trained on each rater and iii one cnn trained with random rater sampling results iii random rater sampling figure 1c lead to a cnn performance superior to ii the average performance of individually trained cnns the reliability of a cnn goes beyond the human interexpert agreement i surface dice at tolerance 5mm 088 versus 068 and 067 respectively table 1 conclusions the volume and location of aibt on ncct can reliably be segmented by a cnn the agreement between a randomly chosen rater and the cnn predictions surpasses the interexpert agreement table 1",Brain
Abstract TP100: Transfer Learning Based Cerebral Microbleed Detection As An Mri Biomarker For Cerebral Amyloid Angiopathy Spectrum Diseases,https://doi.org/10.1161/str.54.suppl_1.tp100,2023,"objectives quantifying cerebral microbleeds cmbs in cerebral amyloid angiopathy caa is important however manual counting of cmbs on brain mri is laborious this work aims to develop a novel automatic deep learning segmentation algorithm for fast and accurate quantification of cmbs on brain mris method we used a internal dataset susceptibilityweighted imaging swi clinical scans from 83 patients with caa with heterogeneous protocols on 15t and 3t scanners and manual cmb segmentation by 2 readers and b public dataset 57 swi scans from 30 patients with alzheimers and cmb locations the data was split into training validation and testing subsets internal 502013 public 38910 preprocessing included n3 bias field correction brain extraction and upsampling to a fixed inplane resolution 02mm model used multichannel 2d input fig1b and mimicked manual cmb segmentation we trained basemodel initially using the public dataset and then applied transfer learning using the internal dataset to segment cmbs in clinical scans we evaluated models performance by sensitivity s precision p number of false positives per scan fpc and f1score f1 results on 10 public test scans base model performed well s 081 p 074 fpc 060 f1 077 but had high fpc for 13 internal test scans s 100 p 015 fpc 431 f1 026 after transfer learning the precision fpc and f1score were improved for internal scans s 080 p 080 fpc 015 f1 080 conclusion refined deeplearning based cmb counting algorithms could quantify cmbs for heterogeneous clinical mri dataset with good sensitivity precision and false positivity this method may accelerate further caa clinical diagnosis and research",Brain
Abstract 106: Novel Imaging-based Morphological Markers For Improved Prediction Of Stroke Outcomes: A Machine Learning Approach,https://doi.org/10.1161/str.54.suppl_1.106,2023,"patient selection for acute reperfusion therapies of acute ischemic stroke is based on assessment of the core and tissueatrisk and the time from stroke onset response to treatment and clinical outcomes however vary significantly since patientspecific cerebrovascular anatomy plays a vital role in governing flow and reperfusion we developed an endtoend automated machine learning approach to extract advanced cerebrovascular morphological features including tortuosity and collateral index to improve outcome prediction and patient selection methods using our validated automatic cerebrovascular segmentation and feature extraction algorithm we obtained the morphological properties of the brain vasculature including vessel tortuosity length diameter and bifurcation patterns in mr angiography scans of 100 anonymized stroke patients each patients collateral index was also automatically graded using a previously established probabilistic atlas of healthy cerebrovasculature to predict 90day functional outcomes mrs a statistical model was trained using patients clinical features demographics comorbidities and baseline nihss imaging features initial aspects perfusion mismatch volume and collateral index and the extracted morphologic features length diameter number of branches vessel tortuosity fractal dimension and total volume the predictions were compared against ground truth mrs to assess model accuracy we also compared the models performance against conventional outcome predictors with only the clinical and imaging features results the conventional model including the common clinical and imaging features excluding the collateral index gave an area under the curve auc of 063 which is comparable to previously published results including the automatically scored collateral index improved the accuracy to 074 we found that further including the morphological features to the predictor model significantly improved auc accuracy to 083 conclusion including automatically extracted cerebrovascular morphologic features in traditional clinical and imaging markers significantly improves outcome prediction and response to treatment in stroke patients",Brain
Development of a compressed FCN architecture for semantic segmentation using Particle Swarm Optimization,https://doi.org/10.1007/s00521-023-08324-3,2023,"researchers have adapted the conventional deep learning classification networks to generate fully conventional networks fcn for carrying out accurate semantic segmentation however such models are expensive both in terms of storage and inference time and not readily employable on edge devices in this paper a compressed version of vgg16based fully convolution network fcn has been developed using particle swarm optimization it has been shown that the developed model can offer tremendous saving in storage space and also faster inference time and can be implemented on edge devices the efficacy of the proposed approach has been tested using potato late blight leaf images from publicly available plantvillage dataset street scene image dataset and lungs xray dataset and it has been shown that it approaches the accuracies offered by standard fcn even after 851 compression",Lung
Development of a compressed FCN architecture for semantic segmentation using Particle Swarm Optimization,https://doi.org/10.1007/s00521-023-08324-3,2023,"researchers have adapted the conventional deep learning classification networks to generate fully conventional networks fcn for carrying out accurate semantic segmentation however such models are expensive both in terms of storage and inference time and not readily employable on edge devices in this paper a compressed version of vgg16based fully convolution network fcn has been developed using particle swarm optimization it has been shown that the developed model can offer tremendous saving in storage space and also faster inference time and can be implemented on edge devices the efficacy of the proposed approach has been tested using potato late blight leaf images from publicly available plantvillage dataset street scene image dataset and lungs xray dataset and it has been shown that it approaches the accuracies offered by standard fcn even after 851 compression",Lung
Deep Learning-Based Segmentation of Cellular Membranes in Colorectal Immunohistochemical Images,https://doi.org/10.5772/intechopen.108589,2023,"the segmentation of cellular membranes is essential for getting crucial information in diagnosing several cancers including lung breast colon gastric cancer etc manual segmentation of cellular membranes is a tedious timeconsuming routine and prone to error and interobserver variation so it is one of the challenges that pathologists face in immunohistochemical ihc tissue images although automated segmentation of cellular membranes has recently gained considerable attention in digital pathology applications little research is based on machine learning approaches therefore this study proposes a deep framework for semantic segmenting cellular membranes using an endtoend trainable convolutional neural network cnn based on encoder and decoder architecture with atreus spatial pyramid pooling aspp the backbone of the encoder depends on the residual architecture the performance of the proposed framework was evalu ated and compared to other benchmark methods as a result we show that the proposed framework exhibits significant potential for cellular membranes segmentation in ihc images",Lung
Lung nodule pre-diagnosis and insertion path planning for chest CT images,https://doi.org/10.1186/s12880-023-00973-z,2023,"abstract medical image processing has proven to be effective and feasible for assisting oncologists in diagnosing lung thyroid and other cancers especially at early stage however there is no reliable method for the recognition screening classification and detection of nodules and even deep learningbased methods have limitations in this study we mainly explored the automatic prediagnosis of lung nodules with the aim of accurately identifying nodules in chest ct images regardless of the benign and malignant nodules and the insertion path planning of suspected malignant nodules used for further diagnosis by roboticbased biopsy puncture the overall process included lung parenchyma segmentation classification and prediagnosis 3d reconstruction and path planning and experimental verification first accurate lung parenchyma segmentation in chest ct images was achieved using digital image processing technologies such as adaptive gray threshold connected area labeling and mathematical morphological boundary repair multifeature weight assignment was then adopted to establish a multilevel classification criterion to complete the classification and prediagnosis of pulmonary nodules next 3d reconstruction of lung regions was performed using voxelization and on its basis a feasible local optimal insertion path with an insertion point could be found by avoiding sternums andor key tissues in terms of the needleinserting path finally ct images of 900 patients from lung image database consortium and image database resource initiative were chosen to verify the validity of pulmonary nodule diagnosis our previously designed surgical robotic system and a custom thoracic model were used to validate the effectiveness of the insertion path this work can not only assist doctors in completing the prediagnosis of pulmonary nodules but also provide a reference for clinical biopsy puncture of suspected malignant nodules considered by doctors",Lung
An Ensemble Model for the Diagnosis of Brain Tumors through MRIs,https://doi.org/10.3390/diagnostics13030561,2023,"automatic brain tumor detection in mr images is one of the basic applications of machine vision in medical image processing which despite much research still needs further development using multiple machine learning techniques as an ensemble system is one of the solutions that can be effective in achieving this goal in this paper a novel method for diagnosing brain tumors by combining data mining and machine learning techniques has been proposed in the proposed method each image is initially preprocessed to eliminate its background region and identify brain tissue the social spider optimization sso algorithm is then utilized to segment the mri images the mri images segmentation allows for a more precise identification of the tumor region in the image in the next step the distinctive features of the image are extracted using the svd technique in addition to removing redundant information this strategy boosts the speed of the processing at the classification stage finally a combination of the algorithms naïve bayes support vector machine and knearest neighbor is used to classify the extracted features and detect brain tumors each of the three algorithms performs feature classification individually and the final output of the proposed model is created by integrating the three independent outputs and voting the results the results indicate that the proposed method can diagnose brain tumors in the brats 2014 dataset with an average accuracy of 9861 sensitivity of 9579 and specificity of 9971 additionally the proposed method could diagnose brain tumors in the btd20 database with an average accuracy of 9913 sensitivity of 99 and specificity of 9926 these results show a significant improvement compared to previous efforts the findings confirm that using the image segmentation technique as well as the ensemble learning is effective in improving the efficiency of the proposed method",Brain
An Ensemble Model for the Diagnosis of Brain Tumors through MRIs,https://doi.org/10.3390/diagnostics13030561,2023,"automatic brain tumor detection in mr images is one of the basic applications of machine vision in medical image processing which despite much research still needs further development using multiple machine learning techniques as an ensemble system is one of the solutions that can be effective in achieving this goal in this paper a novel method for diagnosing brain tumors by combining data mining and machine learning techniques has been proposed in the proposed method each image is initially preprocessed to eliminate its background region and identify brain tissue the social spider optimization sso algorithm is then utilized to segment the mri images the mri images segmentation allows for a more precise identification of the tumor region in the image in the next step the distinctive features of the image are extracted using the svd technique in addition to removing redundant information this strategy boosts the speed of the processing at the classification stage finally a combination of the algorithms naïve bayes support vector machine and knearest neighbor is used to classify the extracted features and detect brain tumors each of the three algorithms performs feature classification individually and the final output of the proposed model is created by integrating the three independent outputs and voting the results the results indicate that the proposed method can diagnose brain tumors in the brats 2014 dataset with an average accuracy of 9861 sensitivity of 9579 and specificity of 9971 additionally the proposed method could diagnose brain tumors in the btd20 database with an average accuracy of 9913 sensitivity of 99 and specificity of 9926 these results show a significant improvement compared to previous efforts the findings confirm that using the image segmentation technique as well as the ensemble learning is effective in improving the efficiency of the proposed method",Brain
Medical Images Segmentation for Lung Cancer Diagnosis Based on Deep Learning Architectures,https://doi.org/10.3390/diagnostics13030546,2023,"lung cancer presents one of the leading causes of mortalities for people around the world lung image analysis and segmentation are one of the primary steps used for early diagnosis of cancer handcrafted medical imaging segmentation presents a very timeconsuming task for radiation oncologists to address this problem we propose in this work to develop a full and entire system used for early diagnosis of lung cancer in ct scan imaging the proposed lung cancer diagnosis system is composed of two main parts the first part is used for segmentation developed on top of the unetr network and the second part is a classification part used to classify the output segmentation part either benign or malignant developed on top of the selfsupervised network the proposed system presents a powerful tool for early diagnosing and combatting lung cancer using 3dinput ct scan data extensive experiments have been performed to contribute to better segmentation and classification results training and testing experiments have been performed using the decathlon dataset experimental results have been conducted to new stateoftheart performances segmentation accuracy of 9783 and 9877 as classification accuracy the proposed system presents a new powerful tool to use for early diagnosing and combatting lung cancer using 3dinput ct scan data",Lung
Improvised light weight deep CNN based U-Net for the semantic segmentation of lungs from chest X-rays,https://doi.org/10.1016/j.rineng.2023.100929,2023,"in the last decade neural networks and deep learning techniques are widely adopted in the field of medical imaging for image detection classification and segmentation tasks and has achieved exceptional results deep models have immensely contributed in this sector thus making it easier for quick diagnosis early and effective treatment xrays are most commonly used radiological medical imaging tool and radiologists medical practitioners face huge difficulty to classify and segment different organs by looking at the chest xrays for the possible detection of any abnormalities in thoracic cavity which includes lungs heart diaphragm sternum and clavicles specifically we presented a modified unet architecture for the semantic segmentation of lungs from the chest xrays images the proposed model is lighter counterpart of unet architecture consisting multiple dropouts in all the deconvolutional layers this efficiently resolving the problem of overfitting and outperforms the original unet model the light weight proposed architecture outperforms on the combination of three different datasets by producing 9271 training accuracy and a marvelous generalization accuracy of 9387 with adam optimizer and underlying loss function is dice coefficient the clubbed dataset comprised of over 900 chest xrays images along with corresponding truth segmentation masks provided by the professionals conclusively we offer improved performance better model generalization with relatively lighter model for the semantic segmentation of lungs from the chest xrays images",Lung
Improvised light weight deep CNN based U-Net for the semantic segmentation of lungs from chest X-rays,https://doi.org/10.1016/j.rineng.2023.100929,2023,"in the last decade neural networks and deep learning techniques are widely adopted in the field of medical imaging for image detection classification and segmentation tasks and has achieved exceptional results deep models have immensely contributed in this sector thus making it easier for quick diagnosis early and effective treatment xrays are most commonly used radiological medical imaging tool and radiologists medical practitioners face huge difficulty to classify and segment different organs by looking at the chest xrays for the possible detection of any abnormalities in thoracic cavity which includes lungs heart diaphragm sternum and clavicles specifically we presented a modified unet architecture for the semantic segmentation of lungs from the chest xrays images the proposed model is lighter counterpart of unet architecture consisting multiple dropouts in all the deconvolutional layers this efficiently resolving the problem of overfitting and outperforms the original unet model the light weight proposed architecture outperforms on the combination of three different datasets by producing 9271 training accuracy and a marvelous generalization accuracy of 9387 with adam optimizer and underlying loss function is dice coefficient the clubbed dataset comprised of over 900 chest xrays images along with corresponding truth segmentation masks provided by the professionals conclusively we offer improved performance better model generalization with relatively lighter model for the semantic segmentation of lungs from the chest xrays images",Lung
Radiomic phenotyping of the lung parenchyma in a lung cancer screening cohort,https://doi.org/10.1038/s41598-023-29058-1,2023,"abstract highthroughput extraction of radiomic features from lowdose ct scans can characterize the heterogeneity of the lung parenchyma and potentially aid in identifying subpopulations that may have higher risk of lung diseases such as copd and lung cancer due to inflammation or obstruction of the airways we aim to determine the feasibility of a lung radiomics phenotyping approach in a lung cancer screening cohort while quantifying the effect of different ct reconstruction algorithms on phenotype robustness we identified lowdose ct scans n 308 acquired with siemens healthineers scanners from patients who completed lowdose ct within our lung cancer screening program between 2015 and 2018 and had two different sets of image reconstructions kernel available ie medium i30f sharp i50f for the same acquisition following segmentation of the lung field a total of 26 radiomic features were extracted from the entire 3d lungfield using a previously validated fullyautomated latticebased software pipeline adapted for lowdose ct scans the lattice inhouse software was used to extract features including graylevel histogram cooccurrence and runlength descriptors the lattice approach uses nonoverlapping windows for traversing along pixels of images and calculates different features each feature was averaged for each scan within a range of lattice window sizes w of 4 8 and 20 mm the extracted imaging features from both datasets were harmonized to correct for differences in image acquisition parameters subsequently unsupervised hierarchical clustering was applied on the extracted features to identify distinct phenotypic patterns of the lung parenchyma where consensus clustering was used to identify the optimal number of clusters k 2 differences between phenotypes for demographic and clinical covariates including sex age bmi packyears of smoking lungrads and cancer diagnosis were assessed for each phenotype cluster and then compared across clusters for the two different ct reconstruction algorithms using the cluster entanglement metric where a lower entanglement coefficient corresponds to good cluster alignment furthermore an independent set of lowdose ct scans n 88 from patients with available pulmonary function data on lung obstruction were analyzed using the identified optimal clusters to assess associations to lung obstruction and validate the lung phenotyping paradigm heatmaps generated by radiomic features identified two distinct lung parenchymal phenotype patterns across different feature extraction window sizes for both reconstruction algorithms p lt 005 with k 2 associations of radiomicbased clusters with clinical covariates showed significant differences for bmi and packyears of smoking p lt 005 for both reconstruction kernels radiomic phenotype patterns were more similar across the two reconstructed kernels when smaller window sizes w 4 and 8 mm were used for radiomic feature extraction as deemed by their entanglement coefficient validation of clustering approaches using cluster mapping for the independent sample with lung obstruction also showed two statistically significant phenotypes p lt 005 with significant difference for bmi and smoking packyears radiomic analysis can be used to characterize lung parenchymal phenotypes from lowdose ct scans which appear reproducible for different reconstruction kernels further work should seek to evaluate the effect of additional ct acquisition parameters and validate these phenotypes in characterizing lung cancer screening populations to potentially better stratify disease patterns and cancer risk",Lung
Surface‐GCN: Learning interaction experience for organ segmentation in 3D medical images,https://doi.org/10.1002/mp.16280,2023,"accurate segmentation of organs has a great significance for clinical diagnosis but it is still hard work due to the obscure imaging boundaries caused by tissue adhesion on medical images based on the image continuity in medical image volumes segmentation on these slices could be inferred from adjacent slices with a clear organ boundary radiologists can delineate a clear organ boundary by observing adjacent slicesinspired by the radiologists delineating procedure we design an organ segmentation model based on boundary information of adjacent slices and a humanmachine interactive learning strategy to introduce clinical experiencewe propose an interactive organ segmentation method for medical image volume based on graph convolution network gcn called surfacegcn first we propose a surface feature extraction network sfenet to capture surface features of a target organ and supervise it by a minibatch adaptive surface matching mbasm module then to predict organ boundaries precisely we design an automatic segmentation module based on a surface convolution unit scu which propagates information on organ surfaces to refine the generated boundaries in addition an interactive segmentation module is proposed to learn radiologists experience of interactive corrections on organ surfaces to reduce interaction clickswe evaluate the proposed method on one prostate mr image dataset and two abdominal multiorgan ct datasets the experimental results show that our method outperforms other stateoftheart methods for prostate segmentation the proposed method conducts a dsc score of 9449 on promise12 test dataset for abdominal multiorgan segmentation the proposed method achieves dsc scores of 95 91 95 and 88 for the left kidney gallbladder spleen and esophagus respectively for interactive segmentation the proposed method reduces 510 interaction clicks to reach the same accuracyto overcome the medical organ segmentation challenge we propose a graph convolutional network called surfacegcn by imitating radiologist interactions and learning clinical experience on single and multiple organ segmentation tasks the proposed method could obtain more accurate segmentation boundaries compared with other stateoftheart methods",Prostate
Surface‐GCN: Learning interaction experience for organ segmentation in 3D medical images,https://doi.org/10.1002/mp.16280,2023,"accurate segmentation of organs has a great significance for clinical diagnosis but it is still hard work due to the obscure imaging boundaries caused by tissue adhesion on medical images based on the image continuity in medical image volumes segmentation on these slices could be inferred from adjacent slices with a clear organ boundary radiologists can delineate a clear organ boundary by observing adjacent slicesinspired by the radiologists delineating procedure we design an organ segmentation model based on boundary information of adjacent slices and a humanmachine interactive learning strategy to introduce clinical experiencewe propose an interactive organ segmentation method for medical image volume based on graph convolution network gcn called surfacegcn first we propose a surface feature extraction network sfenet to capture surface features of a target organ and supervise it by a minibatch adaptive surface matching mbasm module then to predict organ boundaries precisely we design an automatic segmentation module based on a surface convolution unit scu which propagates information on organ surfaces to refine the generated boundaries in addition an interactive segmentation module is proposed to learn radiologists experience of interactive corrections on organ surfaces to reduce interaction clickswe evaluate the proposed method on one prostate mr image dataset and two abdominal multiorgan ct datasets the experimental results show that our method outperforms other stateoftheart methods for prostate segmentation the proposed method conducts a dsc score of 9449 on promise12 test dataset for abdominal multiorgan segmentation the proposed method achieves dsc scores of 95 91 95 and 88 for the left kidney gallbladder spleen and esophagus respectively for interactive segmentation the proposed method reduces 510 interaction clicks to reach the same accuracyto overcome the medical organ segmentation challenge we propose a graph convolutional network called surfacegcn by imitating radiologist interactions and learning clinical experience on single and multiple organ segmentation tasks the proposed method could obtain more accurate segmentation boundaries compared with other stateoftheart methods",Prostate
DCSAU-Net: A deeper and more compact split-attention U-Net for medical image segmentation,https://doi.org/10.1016/j.compbiomed.2023.106626,2023,"deep learning architecture with convolutional neural network achieves outstanding success in the field of computer vision where unet has made a great breakthrough in biomedical image segmentation and has been widely applied in a wide range of practical scenarios however the equal design of every downsampling layer in the encoder part and simply stacked convolutions do not allow unet to extract sufficient information of features from different depths the increasing complexity of medical images brings new challenges to the existing methods in this paper we propose a deeper and more compact splitattention ushape network which efficiently utilises lowlevel and highlevel semantic information based on two frameworks primary feature conservation and compact splitattention block we evaluate the proposed model on cvcclinicdb 2018 data science bowl isic2018 segpc2021 and brats2021 datasets as a result our proposed model displays better performance than other stateoftheart methods in terms of the mean intersection over union and dice coefficient more significantly the proposed model demonstrates excellent segmentation performance on challenging images the code for our work and more technical details can be found at httpsgithubcomxq141839dcsaunet",Brain
An Attention-based Context-informed Deep Framework for Infant Brain Subcortical Segmentation,https://doi.org/10.1016/j.neuroimage.2023.119931,2023,"precise segmentation of subcortical structures from infant brain magnetic resonance mr images plays an essential role in studying early subcortical structural and functional developmental patterns and diagnosis of related brain disorders however due to the dynamic appearance changes low tissue contrast and tiny subcortical size in infant brain mr images infant subcortical segmentation is a challenging task in this paper we propose a contextguided attentionbased coarsetofine deep framework to precisely segment the infant subcortical structures at the coarse stage we aim to directly predict the signed distance maps sdms from multimodal intensity images including t1w t2w and the ratio of t1w and t2w images with an sdmunet which can leverage the spatial context information including the structural position information and the shape information of the target structure to generate highquality sdms at the fine stage the predicted sdms which encode spatialcontext information of each subcortical structure are integrated with the multimodal intensity images as the input to a multisource and multipath attention unet m2aunet for achieving refined segmentation both the 3d spatial and channel attention blocks are added to guide the m2aunet to focus more on the important subregions and channels we additionally incorporate the inner and outer subcortical boundaries as extra labels to help precisely estimate the ambiguous boundaries we validate our method on an infant mr image dataset and on an unrelated neonatal mr image dataset compared to eleven stateoftheart methods the proposed framework consistently achieves higher segmentation accuracy in both qualitative and quantitative evaluations of infant mr images and also exhibits good generalizability in the neonatal dataset",Brain
Classification of COVID-19 from community-acquired pneumonia: Boosting the performance with capsule network and maximum intensity projection image of CT scans,https://doi.org/10.1016/j.compbiomed.2023.106567,2023,"the coronavirus disease 2019 covid19 and communityacquired pneumonia cap present a high degree of similarity in chest computed tomography ct images therefore a procedure for accurately and automatically distinguishing between them is cruciala deep learning method for distinguishing covid19 from cap is developed using maximum intensity projection mip images from ct scans linknet is employed for lung segmentation of chest ct images mip images are produced by superposing the maximum gray of intrapulmonary ct values the mip images are input into a capsule network for patientlevel pred iction and diagnosis of covid19 the network is trained using 333 ct scans 168 covid19165 cap and validated on three external datasets containing 3581 ct scans 2110 covid191471 caplinknet achieves the highest dice coefficient of 0983 for lung segmentation for the classification of covid19 and cap the capsule network with the densenet121 feature extractor outperforms resnet50 and inceptionv3 achieving an accuracy of 0970 on the training dataset without mip or the capsule network the accuracy decreases to 0857 and 0818 respectively accuracy scores of 0961 0997 and 0949 are achieved on the external validation datasets the proposed method has higher or comparable sensitivity compared with ten stateoftheart methodsthe proposed method illustrates the feasibility of applying mip images from ct scans to distinguish covid19 from cap using capsule networks mip images provide conspicuous benefits when exploiting deep learning to detect covid19 lesions from ct scans and the capsule network improves covid19 diagnosis",Lung
Performance Analysis of Classification and Detection of Brain Tumor MRI Images Using Resnet50 Deep Residual U-Net,https://doi.org/10.18502/jimc.v6i1.11848,2023,"background this research adds to the growing body of work demonstrating the vital role of image categorization in the medical sector the efficiency of illness diagnosis is being greatly enhanced using image classification a brain tumor is a collection of abnormal cells in the brain diagnostic precision is required when looking for a tumor in the brain because even the smallest error in human judgement can have disastrous results to get around this problem the medical community has implemented an automated brain tumor segmentation system a variety of methods are employed to segment a brain tumor but the results are inconsistent to improve the quality of mri images we present our findings in this paper deep learning methods for image segmentation and classification are discussed in this paperx0d methods in this paper we a very robust deep learning method for image segmentation and classification for image classification we are employing the enhanced faster rcnn method the resnet50 model is used to differentiate between tumor and nontumor images the next step in this framework is to use deep residual unet for segmentation resunet is an fcnn that maximizes efficiency the proposed method works well in terms of its ability to find and classify things accuratelyx0d results the accuracy rate for identifying tumours in mri scans using the proposed technique is 9423 using transfer learning with resnet50 as the base model and the use of discriminative learning rates our model achieved superior results than other recent modelsx0d conclusion within the scope of this study we have integrated the residual networks with the unet to make the network stronger this strategy improves the efficiency of classification and segmentation tools to achieve a higher level of accuracy the model may be trained further or additional data may be applied in the training process",Brain
A Medical Image Segmentation Method Based on Improved UNet 3+ Network,https://doi.org/10.3390/diagnostics13030576,2023,"in recent years segmentation details and computing efficiency have become more important in medical image segmentation for clinical applications in deep learning unet based on a convolutional neural network is one of the most commonly used models unet 3 was designed as a modified unet by adopting the architecture of fullscale skip connections however fullscale feature fusion can result in excessively redundant computations this study aimed to reduce the network parameters of unet 3 while further improving the feature extraction capability first to eliminate redundancy and improve computational efficiency we prune the fullscale skip connections of unet 3 in addition we use the attention module called convolutional block attention module cbam to capture more essential features and thus improve the feature expression capabilities the performance of the proposed model was validated by three different types of datasets skin cancer segmentation breast cancer segmentation and lung segmentation the parameters are reduced by about 36 and 18 compared to unet and unet 3 respectively the results show that the proposed method not only outperformed the comparison models in a variety of evaluation metrics but also achieved more accurate segmentation results the proposed models have lower network parameters that enhance feature extraction and improve segmentation performance efficiently furthermore the models have great potential for application in medical imaging computeraided diagnosis",Lung
COVID-19 Lung CT image segmentation using localization and enhancement methods with U-Net,https://doi.org/10.1016/j.procs.2023.01.144,2023,"segmentation of pneumonia lesions from lung ct images has become vital for diagnosing the disease and evaluating the severity of the patients during the covid19 pandemic several aibased systems have been proposed for this task however some lowcontrast abnormal zones in ct images make the task challenging the researchers investigated image preprocessing techniques to accomplish this problem and to enable more accurate segmentation by the aibased systems this study proposes a covid19 lungct segmentation system based on histogrambased nonparametric region localization and enhancement le methods prior to the unet architecture the covid19infected lung ct images were initially processed by the le method and the infected regions were detected and enhanced to provide more discriminative features to the deep learning segmentation methods the unet is trained using the enhanced images to segment the regions affected by covid19 the proposed system achieved 9775 085 and 074 accuracy dice score and jaccard index respectively the comparison results suggested that the use of le methods as a preprocessing step in ct lung images significantly improved the feature extraction and segmentation abilities of the unet model by a 021 dice score the results might lead to implementing the le method in segmenting varied medical images",Lung
PointNeuron: 3D Neuron Reconstruction via Geometry and Topology Learning of Point Clouds,https://doi.org/10.1109/wacv56688.2023.00574,2023,"digital neuron reconstruction from 3d microscopy images is an essential technique for investigating brain connectomics and neuron morphology existing reconstruction frameworks use convolutionbased segmentation networks to partition the neuron from noisy backgrounds before applying the tracing algorithm the tracing results are sensitive to the raw image quality and segmentation accuracy in this paper we propose a novel framework for 3d neuron reconstruction our key idea is to use the geometric representation power of the point cloud to better explore the intrinsic structural information of neurons our proposed framework adopts one graph convolutional network to predict the neural skeleton points and another one to produce the connectivity of these points we finally generate the target swc file through the interpretation of the predicted point coordinates radius and connections evaluated on the janeliafly dataset from the bigneuron project we show that our framework achieves competitive neuron reconstruction performance our geometry and topology learning of point clouds could further benefit 3d medical image analysis such as cardiac surface reconstruction our code is available at httpsgithubcomrunkaizhaopointneuron",Cardiac
PointNeuron: 3D Neuron Reconstruction via Geometry and Topology Learning of Point Clouds,https://doi.org/10.1109/wacv56688.2023.00574,2023,"digital neuron reconstruction from 3d microscopy images is an essential technique for investigating brain connectomics and neuron morphology existing reconstruction frameworks use convolutionbased segmentation networks to partition the neuron from noisy backgrounds before applying the tracing algorithm the tracing results are sensitive to the raw image quality and segmentation accuracy in this paper we propose a novel framework for 3d neuron reconstruction our key idea is to use the geometric representation power of the point cloud to better explore the intrinsic structural information of neurons our proposed framework adopts one graph convolutional network to predict the neural skeleton points and another one to produce the connectivity of these points we finally generate the target swc file through the interpretation of the predicted point coordinates radius and connections evaluated on the janeliafly dataset from the bigneuron project we show that our framework achieves competitive neuron reconstruction performance our geometry and topology learning of point clouds could further benefit 3d medical image analysis such as cardiac surface reconstruction our code is available at httpsgithubcomrunkaizhaopointneuron",Brain
Cut-Paste Consistency Learning for Semi-Supervised Lesion Segmentation,https://doi.org/10.1109/wacv56688.2023.00610,2023,"semisupervised learning has the potential to improve the dataefficiency of training datahungry deep neural networks which is especially important for medical image analysis tasks where labeled data is scarce in this work we present a simple semisupervised learning method for lesion segmentation tasks based on the ideas of cutpaste augmentation and consistency regularization by exploiting the mask information available in the labeled data we synthesize partially labeled samples from the unlabeled images so that the usual supervised learning objective eg binary cross entropy can be applied additionally we introduce a background consistency term to regularize the training on the unlabeled background regions of the synthetic images we empirically verify the effectiveness of the proposed method on two public lesion segmentation datasets including an eye fundus photograph dataset and a brain ct scan dataset the experiment results indicate that our method achieves consistent and superior performance over other selftraining and consistencybased methods without introducing sophisticated network components",Brain
CYBORG: Blending Human Saliency Into the Loss Improves Deep Learning-Based Synthetic Face Detection,https://doi.org/10.1109/wacv56688.2023.00605,2023,"can deep learning models achieve greater generalization if their training is guided by reference to human perceptual abilities and how can we implement this in a practical manner this paper proposes a training strategy to convey brain oversight to raise generalization cyborg this new approach incorporates humanannotated saliency maps into a loss function that guides the models learning to focus on image regions that humans deem salient for the task the class activation mapping cam mechanism is used to probe the models current saliency in each training batch juxtapose this model saliency with human saliency and penalize large differences results on the task of synthetic face detection selected to illustrate the effectiveness of the approach show that cyborg leads to significant improvement in accuracy on unseen samples consisting of face images generated from six generative adversarial networks across multiple classification network architectures we also show that scaling to even seven times the training data or using nonhumansaliency auxiliary information such as segmentation masks and standard loss cannot beat the performance of cyborgtrained models as a side effect of this work we observe that the addition of explicit region annotation to the task of synthetic face detection increased human classification accuracy this work opens a new area of research on how to incorporate human visual saliency into loss functions in practice all data code and trained models used in this work are offered with this paper",Brain
The Fully Convolutional Transformer for Medical Image Segmentation,https://doi.org/10.1109/wacv56688.2023.00365,2023,"we propose a novel transformer capable of segmenting medical images of varying modalities challenges posed by the finegrained nature of medical image analysis mean that the adaptation of the transformer for their analysis is still at nascent stages the overwhelming success of the unet lay in its ability to appreciate the finegrained nature of the segmentation task an ability which existing transformer based models do not currently posses to address this shortcoming we propose the fully convolutional transformer fct which builds on the proven ability of convolutional neural networks to learn effective image representations and combines them with the ability of transformers to effectively capture longterm dependencies in its inputs the fct is the first fully convolutional transformer model in medical imaging literature it processes its input in two stages where first it learns to extract long range semantic dependencies from the input image and then learns to capture hierarchical global attributes from the features fct is compact accurate and robust our results show that it outperforms all existing transformer architectures by large margins across multiple medical image segmentation datasets of varying data modalities without the need for any pretraining fct outperforms its immediate competitor on the acdc dataset by 13 on the synapse dataset by 44 on the spleen dataset by 12 and on isic 2017 dataset by 11 on the dice metric with up to five times fewer parameters on the acdc post2017miccaichallenge online test set our model sets a new stateoftheart on unseen mri test cases outperforming large ensemble models as well as nnunet with considerably fewer parameters our code environments and models will be available via github sup xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinksup",Cardiac
Lung Cancer Segmentation with Three-Parameter Logistic Type Distribution燤odel,https://doi.org/10.32604/cmc.2023.031878,2023,"lung cancer is the leading cause of mortality in the world affecting both men and women equally when a radiologist just focuses on the patients body it increases the amount of strain on the radiologist and the likelihood of missing pathological information such as abnormalities are increased one of the primary objectives of this research work is to develop computerassisted diagnosis and detection of lung cancer it also intends to make it easier for radiologists to identify and diagnose lung cancer accurately the proposed strategy which was based on a unique image feature took into consideration the spatial interaction of voxels that were next to one another using the unetthree parameter logistic distributionbased technique we were able to replicate the situation the proposed technique had an average dice coefficient dsc of 973 a sensitivity of 965 and a specificity of 941 when tested on the luna16 dataset this research investigates how diverse lung segmentation juxta pleural nodule inclusion and pulmonary nodule segmentation approaches may be applied to create computer aided diagnosis cad systems when we compared our approach to four other lung segmentation methods we discovered that ours was the most successful we employed 40 patients from luna16 datasets to evaluate this in terms of dsc performance the findings demonstrate that the suggested technique outperforms the other strategies by a significant margin",Lung
Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions,https://doi.org/10.1109/wacv56688.2023.00319,2023,"due to the scarcity of dense pixellevel semantic annotations for images recorded in adverse visual conditions there has been a keen interest in unsupervised domain adaptation uda for the semantic segmentation of such images uda adapts models trained on normal conditions to the target adversecondition domains meanwhile multiple datasets with driving scenes provide corresponding images of the same scenes across multiple conditions which can serve as a form of weak supervision for domain adaptation we propose refign a generic extension to selftrainingbased uda methods which leverages these crossdomain correspondences refign consists of two steps 1 aligning the normalcondition image to the corresponding adversecondition image using an uncertaintyaware dense matching network and 2 refining the adverse prediction with the normal prediction using an adaptive label correction mechanism we design custom modules to streamline both steps and set the new state of the art for domainadaptive semantic segmentation on several adversecondition benchmarks including acdc and dark zurich the approach introduces no extra training parameters minimal computational overheadduring training onlyand can be used as a dropin extension to improve any given selftrainingbased uda method code is available at httpsgithubcombrdavrefign",Cardiac
CNN based pulmonary nodule segmentation using lung-range-standardization,https://doi.org/10.21203/rs.3.rs-2541317/v1,2023,"abstract lung cancer is one of the most fatal disease with high lethality in general lung cancers are diagnosed by radiologists but checking radiological image is a very toilsome work for radiologists because it requires long time practice and high concentration so many computeraided diagnosis cad systems were introduced to cooperate with radiologists and nowadays lots of cad systems based upon deep learning exceed human experts in diagnosing accuracy and the remarkable thing is that the much of progress has been made in designing architectures but in this paper a new preprocessing method lungrangestandardization is proposed in order to improve the general accuracy of lungrelated diagnosis systems and to increase the utility of lidc dataset and the efficiency of the proposed preprocessing method is validated through comparison between the nodule segmentation model trained using lungrangestandardization and the nodule segmentation model which is trained without lungrangestandardization",Lung
Concurrent 3D super resolution on intensity and segmentation maps improves detection of structural effects in neurodegenerative disease,https://doi.org/10.1101/2023.02.02.23285376,2023,"abstract we propose a new perceptual super resolution psr method for 3d neuroimaging and evaluate its performance in detecting brain changes due to neurodegenerative disease the method concurrent super resolution and segmentation csrs is trained on volumetric brain data to consistently upsample both an image intensity channel and associated segmentation labels the simultaneous nature of the method improves not only the resolution of the images but also the resolution of associated segmentations thereby making the approach directly applicable to existing labeled datasets one challenge to real world evaluation of sr methods such as csrs is the lack of high resolution ground truth in the target application data clinical neuroimages we therefore evaluate csrs effectiveness in an adjacent clinically relevant signal detection problem quantifying crosssectional and longitudinal change across a set of phenotypically heterogeneous but related disorders that exhibit known and differentiable patterns of brain atrophy we contrast several 3d psr loss functions in this paradigm and show that csrs consistently increases the ability to detect regional atrophy both longitudinally and crosssectionally in each of five related diseases",Brain
Spectral Clustering to Detect Malignant Prostate Using Multimodal Images,https://doi.org/10.1007/978-981-19-5936-3_51,2023,"abstractglobally the prostate is a second most frequent cancer in men and is the fifth leading cause of death at early state prostates are asymptomatic and do not require any care however if screened at early state it can be removed immediately the screening is done either with most widely used transrectal trus imaging or with magnetic imaging the paper introduces a novel approach to demark the prostate boundary using spectral clustering approach with gaussian similarity the multimodal image database is obtained with the ethically approved collaboration the algorithm is tested on 217 mri images and 402 trus images the competency of the approach was evaluated with respect to five quality metrics in both the modalities the results showed that the proposed approach is robust in demarking the prostate region with segmentation accuracy of 9202 and 9378 for mri and trus database the highest average sensitivity and specificity of 957 in segmenting mri and trus images shows the robustness of the proposed sc approach in accurate delineation of prostate boundarieskeywordsprostate segmentationtransrectal imagingmagnetic resonance imagingspectral clusteringgaussian similarity",Prostate
An Effective CNN Method Using Multi-SVM Process for Brain Tumor Segmentation and Detection from MR Images,https://doi.org/10.1007/978-981-19-5936-3_71,2023,"abstractin most of the medical applications the accuracy of detecting and diagnosing the disease in a proper procedure is always a challenging issue one of the most searched research works is brain tumor detection with most effective way here deep learningbased algorithms yield better outcomes brain tumor segmentation algorithms have been more investigated in the recent times with varied algorithms for accurate segmentation and detection in this work brain tumor detection from the mr scan images is mainly based on convolution neural network cnn amalgamated with multisvm classifier with various preprocessing and intermediate steps involved to bring out optimal results in preprocessing stage image filtering and intensity normalization of input images are carried out at later stages cnn along with multisvm classifier is utilized for training testing along with classification process finally the classification tends to display the presence of brain tumor or not the implementation is processed by means of matlab computing language with necessary prerequisiteskeywordsbrain tumorsegmentationclassificationcnnsvm",Brain
Brain Tumor Detection and Classification using Intelligence Techniques: An Overview,https://doi.org/10.1109/access.2023.3242666,2023,"a tumor is carried on by rapid and uncontrolled cell growth in the brain if it is not treated in the initial phases it could prove fatal despite numerous significant efforts and encouraging outcomes accurate segmentation and classification continue to be a challenge detection of brain tumors is significantly complicated by the distinctions in tumor position structure and proportions the main disinterest of this study stays to offer investigators comprehensive literature on magnetic resonance mr imagings ability to identify brain tumors using computational intelligence and statistical image processing techniques this research paper proposed several ways to detect brain cancer and tumors this study also shows an assessment matrix for a specific system using particular systems and dataset types this paper also explains the morphology of brain tumors accessible data sets augmentation methods component extraction and categorization among deep learning dl transfer learning tl and machine learning ml models finally our study compiles all relevant material for the identification of understanding tumors including their benefits drawbacks advancements and upcoming trends",Brain
3-D Quantum-Inspired Self-Supervised Tensor Network for Volumetric Segmentation of Medical Images,https://doi.org/10.1109/tnnls.2023.3240238,2023,"this article introduces a novel shallow 3d selfsupervised tensor neural network in quantum formalism for volumetric segmentation of medical images with merits of obviating training and supervision the proposed network is referred to as the 3d quantuminspired selfsupervised tensor neural network 3dqnet the underlying architecture of 3dqnet is composed of a trinity of volumetric layers viz input intermediate and output layers interconnected using an inlineformula xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink texmath notationlatexmathcalstexmath inlineformula connected thirdorder neighborhoodbased topology for voxelwise processing of 3d medical image data suitable for semantic segmentation each of the volumetric layers contains quantum neurons designated by qubits or quantum bits the incorporation of tensor decomposition in quantum formalism leads to faster convergence of network operations to preclude the inherent slow convergence problems faced by the classical supervised and selfsupervised networks the segmented volumes are obtained once the network converges the suggested 3dqnet is tailored and tested on the brats 2019 brain mr image dataset and the liver tumor segmentation challenge lits17 dataset extensively in our experiments the 3dqnet has achieved promising dice similarity ds as compared with the timeintensive supervised convolutional neural network cnnbased models such as 3dunet voxelwise residual network voxresnet denseresinception net drinet and 3despnet thereby showing a potential advantage of our selfsupervised shallow network on facilitating semantic segmentation",Brain
3-D Quantum-Inspired Self-Supervised Tensor Network for Volumetric Segmentation of Medical Images,https://doi.org/10.1109/tnnls.2023.3240238,2023,"this article introduces a novel shallow 3d selfsupervised tensor neural network in quantum formalism for volumetric segmentation of medical images with merits of obviating training and supervision the proposed network is referred to as the 3d quantuminspired selfsupervised tensor neural network 3dqnet the underlying architecture of 3dqnet is composed of a trinity of volumetric layers viz input intermediate and output layers interconnected using an inlineformula xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink texmath notationlatexmathcalstexmath inlineformula connected thirdorder neighborhoodbased topology for voxelwise processing of 3d medical image data suitable for semantic segmentation each of the volumetric layers contains quantum neurons designated by qubits or quantum bits the incorporation of tensor decomposition in quantum formalism leads to faster convergence of network operations to preclude the inherent slow convergence problems faced by the classical supervised and selfsupervised networks the segmented volumes are obtained once the network converges the suggested 3dqnet is tailored and tested on the brats 2019 brain mr image dataset and the liver tumor segmentation challenge lits17 dataset extensively in our experiments the 3dqnet has achieved promising dice similarity ds as compared with the timeintensive supervised convolutional neural network cnnbased models such as 3dunet voxelwise residual network voxresnet denseresinception net drinet and 3despnet thereby showing a potential advantage of our selfsupervised shallow network on facilitating semantic segmentation",Brain
Application of Artificial Intelligence Methods in Carotid Artery Segmentation: A Review,https://doi.org/10.1109/access.2023.3243162,2023,"the carotid artery is one of the most important blood vessels that supply blood to the brain if thrombus occurs it may cause cerebral ischemic stroke and endanger life carotid intimamedia thickness and stability of carotid plaque are essential indicators for predicting stroke which can be measured through medical image segmentation therefore automatic and accurate carotid artery image segmentation and measurement of carotid intimamedia thickness and the area and volume of carotid plaque are of great significance for stroke risk prediction and treatment however due to the complex shape of the carotid artery and the characteristics of carotid artery imaging the traditional methods such as threshold methods region growth methods can not segment the carotid artery very well in recent years researchers have taken artificial intelligence traditional machine learning and deep learning as a critical research method for carotid artery segmentation and extensive research has been performed with satisfactory results in this paper we present a comprehensive review of carotid artery segmentation using artificial intelligence methods we first briefly introduce medical image processing methods and artificial intelligence methods and then review and summarize the application of artificial intelligence segmentation methods in carotid artery segmentation including carotid lumen mediaadventitia lumenintima and plaques finally the challenges of current artificial intelligence methods in carotid artery segmentation are analyzed",Brain
A multi-object deep neural network architecture to detect prostate anatomy in T2-weighted MRI: Performance evaluation,https://doi.org/10.3389/fnume.2022.1083245,2023,"prostate gland segmentation is the primary step to estimate gland volume which aids in the prostate disease management in this study we present a 2d3d convolutional neural network cnn ensemble that automatically segments the whole prostate gland along with the peripheral zone pz ppzsegnet using a t2weighted sequence t2w of magnetic resonance imaging mri the study used 4 different public data sets organized as train 1 and test 1 independently derived from the same cohort test 2 test 3 and test 4 the prostate gland and the peripheral zone pz anatomy were manually delineated with consensus read by a radiologist except for test 4 cohorts that had premarked glandular anatomy a bayesian hyperparameter optimization method was applied to construct the network model ppzsegnet with a training cohort train 1 n 150 using a fivefold cross validation the model evaluation was performed on an independent cohort of 283 t2w mri prostate cases test 1 to 4 without any additional tuning the data cohorts were derived from the cancer imaging archives tcia prostatex challenge prostatectomy repeatability studies and promise12challenge the segmentation performance was evaluated by computing the dice similarity coefficient and hausdorff distance between the estimateddeepnetwork identified regions and the radiologistdrawn annotations the deep network architecture was able to segment the prostate gland anatomy with an average dice score of 086 in test 1 n 192 079 in test 2 n 26 081 in test 3 n 15 and 062 in test 4 n 50 we also found the dice coefficient improved with larger prostate volumes in 3 of the 4 test cohorts the variation of the dice scores from different cohorts of test images suggests the necessity of more diverse models that are inclusive of dependencies such as the gland sizes and others which will enable us to develop a universal network for prostate and pz segmentation our training and evaluation code can be accessed through the link httpsgithubcommariabaldeonppzsegnetgit",Prostate
A multi-object deep neural network architecture to detect prostate anatomy in T2-weighted MRI: Performance evaluation,https://doi.org/10.3389/fnume.2022.1083245,2023,"prostate gland segmentation is the primary step to estimate gland volume which aids in the prostate disease management in this study we present a 2d3d convolutional neural network cnn ensemble that automatically segments the whole prostate gland along with the peripheral zone pz ppzsegnet using a t2weighted sequence t2w of magnetic resonance imaging mri the study used 4 different public data sets organized as train 1 and test 1 independently derived from the same cohort test 2 test 3 and test 4 the prostate gland and the peripheral zone pz anatomy were manually delineated with consensus read by a radiologist except for test 4 cohorts that had premarked glandular anatomy a bayesian hyperparameter optimization method was applied to construct the network model ppzsegnet with a training cohort train 1 n 150 using a fivefold cross validation the model evaluation was performed on an independent cohort of 283 t2w mri prostate cases test 1 to 4 without any additional tuning the data cohorts were derived from the cancer imaging archives tcia prostatex challenge prostatectomy repeatability studies and promise12challenge the segmentation performance was evaluated by computing the dice similarity coefficient and hausdorff distance between the estimateddeepnetwork identified regions and the radiologistdrawn annotations the deep network architecture was able to segment the prostate gland anatomy with an average dice score of 086 in test 1 n 192 079 in test 2 n 26 081 in test 3 n 15 and 062 in test 4 n 50 we also found the dice coefficient improved with larger prostate volumes in 3 of the 4 test cohorts the variation of the dice scores from different cohorts of test images suggests the necessity of more diverse models that are inclusive of dependencies such as the gland sizes and others which will enable us to develop a universal network for prostate and pz segmentation our training and evaluation code can be accessed through the link httpsgithubcommariabaldeonppzsegnetgit",Prostate
A multi-object deep neural network architecture to detect prostate anatomy in T2-weighted MRI: Performance evaluation,https://doi.org/10.3389/fnume.2022.1083245,2023,"prostate gland segmentation is the primary step to estimate gland volume which aids in the prostate disease management in this study we present a 2d3d convolutional neural network cnn ensemble that automatically segments the whole prostate gland along with the peripheral zone pz ppzsegnet using a t2weighted sequence t2w of magnetic resonance imaging mri the study used 4 different public data sets organized as train 1 and test 1 independently derived from the same cohort test 2 test 3 and test 4 the prostate gland and the peripheral zone pz anatomy were manually delineated with consensus read by a radiologist except for test 4 cohorts that had premarked glandular anatomy a bayesian hyperparameter optimization method was applied to construct the network model ppzsegnet with a training cohort train 1 n 150 using a fivefold cross validation the model evaluation was performed on an independent cohort of 283 t2w mri prostate cases test 1 to 4 without any additional tuning the data cohorts were derived from the cancer imaging archives tcia prostatex challenge prostatectomy repeatability studies and promise12challenge the segmentation performance was evaluated by computing the dice similarity coefficient and hausdorff distance between the estimateddeepnetwork identified regions and the radiologistdrawn annotations the deep network architecture was able to segment the prostate gland anatomy with an average dice score of 086 in test 1 n 192 079 in test 2 n 26 081 in test 3 n 15 and 062 in test 4 n 50 we also found the dice coefficient improved with larger prostate volumes in 3 of the 4 test cohorts the variation of the dice scores from different cohorts of test images suggests the necessity of more diverse models that are inclusive of dependencies such as the gland sizes and others which will enable us to develop a universal network for prostate and pz segmentation our training and evaluation code can be accessed through the link httpsgithubcommariabaldeonppzsegnetgit",Prostate
Deep Learning (DL)-based Automatic Segmentation of the Internal Pudendal  Artery (IPA) for Reduction of Erectile Dysfunction in Definitive Radiotherapy  of Localized Prostate Cancer,https://doi.org/10.48550/arxiv.2302.01493,2023,"background and purpose radiationinduced erectile dysfunction ried is commonly seen in prostate cancer patients clinical trials have been developed in multiple institutions to investigate whether dosesparing to the internalpudendalarteries ipa will improve retention of sexual potency the ipa is usually not considered a conventional organatrisk oar due to segmentation difficulty in this work we propose a deep learning dlbased autosegmentation model for the ipa that utilizes ct and mri or ct alone as the input image modality to accommodate variation in clinical practice materials and methods 86 patients with ct and mri images and noisy ipa labels were recruited in this study we split the data into 421430 for model training testing and a clinical observer study respectively there were three major innovations in this model 1 we designed an architecture with squeezeandexcite blocks and modality attention for effective feature extraction and production of accurate segmentation 2 a novel loss function was used for training the model effectively with noisy labels and 3 modality dropout strategy was used for making the model capable of segmentation in the absence of mri results the dsc asd and hd95 values for the test dataset were 622 254mm and 7mm respectively ai segmented contours were dosimetrically equivalent to the expert physicians contours the observer study showed that expert physicians scored ai contours mean37 higher than inexperienced physicians contours mean31 when inexperienced physicians started with ai contours the score improved to 37 conclusion the proposed model achieved good quality ipa contours to improve uniformity of segmentation and to facilitate introduction of standardized ipa segmentation into clinical trials and practice",Prostate
Efficient MRI Segmentation and Detection of Brain Tumour using CNN,https://doi.org/10.48175/ijarsct-8088,2023,"in many fields including medical imaging aerial surveillance the best manipulation and analysis surgical microscopes etc object detection is crucial the goal of this system is to create a standard for the detection and classification of brain tumors specifically to identify whether a tumour is cancerous or not using the svm algorithm many people have already used anns that employ empirical risk minimization to detect things to categorize the photos we are utilizing the support vector machine technique which relies on structural risk minimization medical images are subjected to the svm algorithm for tumour extraction and a system using python is constructed for the tumour classification function as well cnn techniques were employed for the training dataset this system exhibits a cnn and svmbased object detection prototype",Brain
Fully automated clinical target volume segmentation for glioblastoma radiotherapy using a deep convolutional neural network,https://doi.org/10.5114/pjr.2023.124434,2023,"target volume delineation is a crucial step prior to radiotherapy planning in radiotherapy for glioblastoma this step is performed manually which is timeconsuming and prone to intra and interrater variabilities therefore the purpose of this study is to evaluate a deep convolutional neural network cnn model for automatic segmentation of clinical target volume ctv in glioblastoma patientsin this study the modified segmentationnet segnet model with deep supervision and residualbased skip connection mechanism was trained on 259 glioblastoma patients from the multimodal brain tumour image segmentation benchmark brats 2019 challenge dataset for segmentation of gross tumour volume gtv then the pretrained cnn model was finetuned with an independent clinical dataset n 37 to perform the ctv segmentation in the process of finetuning to generate a ct segmentation mask both ct and mri scans were simultaneously used as input data the performance of the cnn model in terms of segmentation accuracy was evaluated on an independent clinical test dataset n 15 using the dice similarity coefficient dsc and hausdorff distance the impact of autosegmented ctv definition on dosimetry was also analysedthe proposed model achieved the segmentation results with a dsc of 8960 356 and hausdorff distance of 149 065 mm a statistically significant difference was found for the dmin and dmax of the ctv between manually and automatically planned dosesthe results of our study suggest that our cnnbased autocontouring system can be used for segmentation of ctvs to facilitate the brain tumour radiotherapy workflow",Brain
Fully automated clinical target volume segmentation for glioblastoma radiotherapy using a deep convolutional neural network,https://doi.org/10.5114/pjr.2023.124434,2023,"target volume delineation is a crucial step prior to radiotherapy planning in radiotherapy for glioblastoma this step is performed manually which is timeconsuming and prone to intra and interrater variabilities therefore the purpose of this study is to evaluate a deep convolutional neural network cnn model for automatic segmentation of clinical target volume ctv in glioblastoma patientsin this study the modified segmentationnet segnet model with deep supervision and residualbased skip connection mechanism was trained on 259 glioblastoma patients from the multimodal brain tumour image segmentation benchmark brats 2019 challenge dataset for segmentation of gross tumour volume gtv then the pretrained cnn model was finetuned with an independent clinical dataset n 37 to perform the ctv segmentation in the process of finetuning to generate a ct segmentation mask both ct and mri scans were simultaneously used as input data the performance of the cnn model in terms of segmentation accuracy was evaluated on an independent clinical test dataset n 15 using the dice similarity coefficient dsc and hausdorff distance the impact of autosegmented ctv definition on dosimetry was also analysedthe proposed model achieved the segmentation results with a dsc of 8960 356 and hausdorff distance of 149 065 mm a statistically significant difference was found for the dmin and dmax of the ctv between manually and automatically planned dosesthe results of our study suggest that our cnnbased autocontouring system can be used for segmentation of ctvs to facilitate the brain tumour radiotherapy workflow",Brain
Selecting the Best Optimizers for Deep Learning based Medical Image  Segmentation,https://doi.org/10.48550/arxiv.2302.02289,2023,"the goal of this work is to identify the best optimizers for deep learning in the context of cardiac image segmentation and to provide guidance on how to design segmentation networks with effective optimization strategies adaptive learning helps with fast convergence by starting with a larger learning rate lr and gradually decreasing it momentum optimizers are particularly effective at quickly optimizing neural networks within the accelerated schemes category by revealing the potential interplay between these two types of algorithms lr and momentum optimizers or momentum rate mr in short in this article we explore the two variants of sgd algorithms in a single setting we suggest using cyclic learning as the base optimizer and integrating optimal values of learning rate and momentum rate we investigated the relationship of lr and mr under an important problem of medical image segmentation of cardiac structures from mri and ct scans we conducted experiments using the cardiac imaging dataset from the acdc challenge of miccai 2017 and four different architectures shown to be successful for cardiac image segmentation problems our comprehensive evaluations demonstrated that the proposed optimizer achieved better results over a 2 improvement in the dice metric than other optimizers in deep learning literature with similar or lower computational cost in both single and multiobject segmentation settings we hypothesized that combination of accelerated and adaptive optimization methods can have a drastic effect in medical image segmentation performances to this end we proposed a new cyclic optimization method textitclmr to address the efficiency and accuracy problems in deep learning based medical image segmentation the proposed strategy yielded better generalization in comparison to adaptive optimizers",Cardiac
Selecting the Best Optimizers for Deep Learning based Medical Image  Segmentation,https://doi.org/10.48550/arxiv.2302.02289,2023,"the goal of this work is to identify the best optimizers for deep learning in the context of cardiac image segmentation and to provide guidance on how to design segmentation networks with effective optimization strategies adaptive learning helps with fast convergence by starting with a larger learning rate lr and gradually decreasing it momentum optimizers are particularly effective at quickly optimizing neural networks within the accelerated schemes category by revealing the potential interplay between these two types of algorithms lr and momentum optimizers or momentum rate mr in short in this article we explore the two variants of sgd algorithms in a single setting we suggest using cyclic learning as the base optimizer and integrating optimal values of learning rate and momentum rate we investigated the relationship of lr and mr under an important problem of medical image segmentation of cardiac structures from mri and ct scans we conducted experiments using the cardiac imaging dataset from the acdc challenge of miccai 2017 and four different architectures shown to be successful for cardiac image segmentation problems our comprehensive evaluations demonstrated that the proposed optimizer achieved better results over a 2 improvement in the dice metric than other optimizers in deep learning literature with similar or lower computational cost in both single and multiobject segmentation settings we hypothesized that combination of accelerated and adaptive optimization methods can have a drastic effect in medical image segmentation performances to this end we proposed a new cyclic optimization method textitclmr to address the efficiency and accuracy problems in deep learning based medical image segmentation the proposed strategy yielded better generalization in comparison to adaptive optimizers",Cardiac
Exploiting Partial Common Information Microstructure for Multi-Modal  Brain Tumor Segmentation,https://doi.org/10.48550/arxiv.2302.02521,2023,"learning with multiple modalities is crucial for automated brain tumor segmentation from magnetic resonance imaging data explicitly optimizing the common information shared among all modalities eg by maximizing the total correlation has been shown to achieve better feature representations and thus enhance the segmentation performance however existing approaches are oblivious to partial common information shared by subsets of the modalities in this paper we show that identifying such partial common information can significantly boost the discriminative power of image segmentation models in particular we introduce a novel concept of partial common information mask pcimask to provide a finegrained characterization of what partial common information is shared by which subsets of the modalities by solving a masked correlation maximization and simultaneously learning an optimal pcimask we identify the latent microstructure of partial common information and leverage it in a selfattention module to selectively weight different feature representations in multimodal data we implement our proposed framework on the standard unet our experimental results on the multimodal brain tumor segmentation challenge brats datasets consistently outperform those of stateoftheart segmentation baselines with validation dice similarity coefficients of 0920 0897 0837 for the whole tumor tumor core and enhancing tumor on brats2020",Brain
Exploiting Partial Common Information Microstructure for Multi-Modal  Brain Tumor Segmentation,https://doi.org/10.48550/arxiv.2302.02521,2023,"learning with multiple modalities is crucial for automated brain tumor segmentation from magnetic resonance imaging data explicitly optimizing the common information shared among all modalities eg by maximizing the total correlation has been shown to achieve better feature representations and thus enhance the segmentation performance however existing approaches are oblivious to partial common information shared by subsets of the modalities in this paper we show that identifying such partial common information can significantly boost the discriminative power of image segmentation models in particular we introduce a novel concept of partial common information mask pcimask to provide a finegrained characterization of what partial common information is shared by which subsets of the modalities by solving a masked correlation maximization and simultaneously learning an optimal pcimask we identify the latent microstructure of partial common information and leverage it in a selfattention module to selectively weight different feature representations in multimodal data we implement our proposed framework on the standard unet our experimental results on the multimodal brain tumor segmentation challenge brats datasets consistently outperform those of stateoftheart segmentation baselines with validation dice similarity coefficients of 0920 0897 0837 for the whole tumor tumor core and enhancing tumor on brats2020",Brain
Joint Cancer Segmentation and PI-RADS Classification on Multiparametric MRI Using MiniSegCaps Network,https://doi.org/10.3390/diagnostics13040615,2023,"mri is the primary imaging approach for diagnosing prostate cancer prostate imaging reporting and data system pirads on multiparametric mri mpmri provides fundamental mri interpretation guidelines but suffers from interreader variability deep learning networks show great promise in automatic lesion segmentation and classification which help to ease the burden on radiologists and reduce interreader variability in this study we proposed a novel multibranch network minisegcaps for prostate cancer segmentation and pirads classification on mpmri miniseg branch outputted the segmentation in conjunction with pirads prediction guided by the attention map from the capsulenet capsulenet branch exploited the relative spatial information of prostate cancer to anatomical structures such as the zonal location of the lesion which also reduced the sample size requirement in training due to its equivariance properties in addition a gated recurrent unit gru is adopted to exploit spatial knowledge across slices improving throughplane consistency based on the clinical reports we established a prostate mpmri database from 462 patients paired with radiologically estimated annotations minisegcaps was trained and evaluated with fivefold crossvalidation on 93 testing cases our model achieved a 0712 dice coefficient on lesion segmentation 8918 accuracy and 9252 sensitivity on pirads classification pirads 4 in patientlevel evaluation significantly outperforming existing methods in addition a graphical user interface gui integrated into the clinical workflow can automatically produce diagnosis reports based on the results from minisegcaps",Prostate
Semi-Supervised Medical Image Segmentation Guided by Bi-Directional Constrained Dual-Task Consistency,https://doi.org/10.3390/bioengineering10020225,2023,"medical image processing tasks represented by multiobject segmentation are of great significance for surgical planning robotassisted surgery and surgical safety however the exceptionally low contrast among tissues and limited available annotated data makes developing an automatic segmentation algorithm for pelvic ct challenginga bidirection constrained dualtask consistency model named pict is proposed to improve segmentation quality by leveraging free unlabeled data first to learn more unmarked data features it encourages the model prediction of the interpolated image to be consistent with the interpolation of the model prediction at the pixel model and data levels moreover to constrain the error prediction of interpolation interference pict designs an auxiliary pseudosupervision task that focuses on the underlying information of noninterpolation data finally an effective loss algorithm for both consistency tasks is designed to ensure the complementary manner and produce more reliable predictionsquantitative experiments show that the proposed pict achieves 8718 9642 and 7941 mean dsc score on acdc ctpelvic1k and the individual multitissue pelvis dataset with gains of around 08 05 and 1 compared to the stateoftheart semisupervised method compared to the baseline supervised method the pict brings over 39 improvementsthe developed pict model can effectively leverage unlabeled data to improve segmentation quality of low contrast medical images the segmentation result could improve the precision of surgical path planning and provide input for robotassisted surgery",Cardiac
Deep learning-based algorithm improves radiologists’ performance in lung cancer bone metastases detection on computed tomography,https://doi.org/10.3389/fonc.2023.1125637,2023,"to develop and assess a deep convolutional neural network dcnn model for the automatic detection of bone metastases from lung cancer on computed tomography ctin this retrospective study ct scans acquired from a single institution from june 2012 to may 2022 were included in total 126 patients were assigned to a training cohort n 76 a validation cohort n 12 and a testing cohort n 38 we trained and developed a dcnn model based on positive scans with bone metastases and negative scans without bone metastases to detect and segment the bone metastases of lung cancer on ct we evaluated the clinical efficacy of the dcnn model in an observer study with five boardcertified radiologists and three junior radiologists the receiver operator characteristic curve was used to assess the sensitivity and false positives of the detection performance the intersectionoverunion and dice coefficient were used to evaluate the segmentation performance of predicted lung cancer bone metastasesthe dcnn model achieved a detection sensitivity of 0894 with 524 average false positives per case and a segmentation dice coefficient of 0856 in the testing cohort through the radiologistsdcnn model collaboration the detection accuracy of the three junior radiologists improved from 0617 to 0879 and the sensitivity from 0680 to 0902 furthermore the mean interpretation time per case of the junior radiologists was reduced by 228 s p 0045the proposed dcnn model for automatic lung cancer bone metastases detection can improve diagnostic efficiency and reduce the diagnosis time and workload of junior radiologists",Lung
Med-NCA: Robust and Lightweight Segmentation with Neural Cellular  Automata,https://doi.org/10.48550/arxiv.2302.03473,2023,"access to the proper infrastructure is critical when performing medical image segmentation with deep learning this requirement makes it difficult to run stateoftheart segmentation models in resourceconstrained scenarios like primary care facilities in rural areas and during crises the recently emerging field of neural cellular automata nca has shown that locally interacting onecell models can achieve competitive results in tasks such as image generation or segmentations in lowresolution inputs however they are constrained by high vram requirements and the difficulty of reaching convergence for highresolution images to counteract these limitations we propose mednca an endtoend nca training pipeline for highresolution image segmentation our method follows a twostep process global knowledge is first communicated between cells across the downscaled image following that patchbased segmentation is performed our proposed mednca outperforms the classic unet by 2 and 3 dice for hippocampus and prostate segmentation respectively while also being 500 times smaller we also show that mednca is by design invariant with respect to image scale shape and translation experiencing only slight performance degradation even with strong shifts and is robust against mri acquisition artefacts mednca enables highresolution medical image segmentation even on a raspberry pi b arguably the smallest device able to run pytorch and that can be powered by a standard power bank",Prostate
Aligning Multi-Sequence CMR Towards Fully Automated Myocardial Pathology  Segmentation,https://doi.org/10.48550/arxiv.2302.03537,2023,"myocardial pathology segmentation myops is critical for the risk stratification and treatment planning of myocardial infarction mi multisequence cardiac magnetic resonance mscmr images can provide valuable information for instance balanced steadystate free precession cine sequences present clear anatomical boundaries while late gadolinium enhancement and t2weighted cmr sequences visualize myocardial scar and edema of mi respectively existing methods usually fuse anatomical and pathological information from different cmr sequences for myops but assume that these images have been spatially aligned however mscmr images are usually unaligned due to the respiratory motions in clinical practices which poses additional challenges for myops this work presents an automatic myops framework for unaligned mscmr images specifically we design a combined computing model for simultaneous image registration and information fusion which aggregates multisequence features into a common space to extract anatomical structures ie myocardium consequently we can highlight the informative regions in the common space via the extracted myocardium to improve myops performance considering the spatial relationship between myocardial pathologies and myocardium experiments on a private mscmr dataset and a public dataset from the myops2020 challenge show that our framework could achieve promising performance for fully automatic myops",Cardiac
Aligning Multi-Sequence CMR Towards Fully Automated Myocardial Pathology  Segmentation,https://doi.org/10.48550/arxiv.2302.03537,2023,"myocardial pathology segmentation myops is critical for the risk stratification and treatment planning of myocardial infarction mi multisequence cardiac magnetic resonance mscmr images can provide valuable information for instance balanced steadystate free precession cine sequences present clear anatomical boundaries while late gadolinium enhancement and t2weighted cmr sequences visualize myocardial scar and edema of mi respectively existing methods usually fuse anatomical and pathological information from different cmr sequences for myops but assume that these images have been spatially aligned however mscmr images are usually unaligned due to the respiratory motions in clinical practices which poses additional challenges for myops this work presents an automatic myops framework for unaligned mscmr images specifically we design a combined computing model for simultaneous image registration and information fusion which aggregates multisequence features into a common space to extract anatomical structures ie myocardium consequently we can highlight the informative regions in the common space via the extracted myocardium to improve myops performance considering the spatial relationship between myocardial pathologies and myocardium experiments on a private mscmr dataset and a public dataset from the myops2020 challenge show that our framework could achieve promising performance for fully automatic myops",Cardiac
Application-specific approaches to MicroCT for evaluation of mouse models of pulmonary disease,https://doi.org/10.1371/journal.pone.0281452,2023,"the advent of microcomputed tomography microct has provided significant advancement in our ability to generate clinically relevant assessments of lung health and disease in small animal models as microct use to generate outcomes analysis in pulmonary preclinical models has increased there have been substantial improvements in image quality and resolution and data analysis software however there are limited published methods for standardized imaging and automated analysis available for investigators manual quantitative analysis of microct images is complicated by the presence of inflammation and parenchymal disease to improve the efficiency and limit userassociated bias we have developed an automated pulmonary air and tissue segmentation pats task list to segment lung air volume and lung tissue volume for quantitative analysis we demonstrate the effective use of the pats task list using four distinct methods for imaging 1 in vivo respiration controlled scanning using a flexivent 2 longitudinal breathgated in vivo scanning in resolving and nonresolving pulmonary disease initiated by lipopolysaccharide bleomycin and silicaexposure 3 postmortem imaging and 4 ex vivo highresolution scanning the accuracy of the pats task list was compared to manual segmentation the use of these imaging techniques and automated quantification methodology across multiple models of lung injury and fibrosis demonstrates the broad applicability and adaptability of microct to various lung diseases and small animal models and presents a significant advance in efficiency and standardization of preclinical microct imaging and analysis for the field of pulmonary research",Lung
Computer-Aided Diagnosis Model Using Machine Learning for Brain Tumor Detection and Classification,https://doi.org/10.32604/csse.2023.035455,2023,"the brain tumor bt is created by an uncontrollable rise of anomalous cells in brain tissue and it consists of 2 types of cancers they are malignant and benign tumors the benevolent bt does not affect the neighbouring healthy and normal tissue however the malignant could affect the adjacent brain tissues which results in death initial recognition of bt is highly significant to protecting the patients life generally the bt can be identified through the magnetic resonance imaging mri scanning technique but the radiotherapists are not offering effective tumor segmentation in mri images because of the position and unequal shape of the tumor in the brain recently ml has prevailed against standard image processing techniques several studies denote the superiority of machine learning ml techniques over standard techniques therefore this study develops novel brain tumor detection and classification model using met heuristic optimization with machine learning btdcmoml model to accomplish the detection of brain tumor effectively a computeraided design cad model using machine learning ml technique is proposed in this research manuscript initially the input image preprocessing is performed using gaborfiltering gf based noise removal contrast enhancement and skull stripping next mayfly optimization with the kapurs thresholding based segmentation process takes place for feature extraction proposes local diagonal extreme patterns ldep are exploited at last the extreme gradient boosting xgboost model can be used for the bt classification process the accuracy analysis is performed in terms of learning accuracy and the validation accuracy is performed to determine the efficiency of the proposed research work the experimental validation of the proposed model demonstrates its promising performance over other existing methods",Brain
Classification of Multi-view Digital Mammogram Images Using SMO-WkNN,https://doi.org/10.32604/csse.2023.035185,2023,"breast cancer bca is a leading cause of death in the female population across the globe approximately 23 million new bca cases are recorded globally in females overtaking lung cancer as the most prevalent form of cancer to be diagnosed however the mortality rates for cervical and bca are significantly higher in developing nations than in developed countries early diagnosis is the only option to minimize the risks of bca deep learning dlbased models have performed well in image processing in recent years particularly convolutional neural network cnn hence this research proposes a dlbased cnn model to diagnose bca from digitized mammogram images the main objective of this research is to develop an accurate and efficient early diagnosis model for bca detection this proposed model is a multiviewbased computeraided diagnosis cad model which performs the diagnosis of bca on multiviews of mammogram images like mediolateraloblique mlo and craniocaudal cc the digital mammogram images are collected from the digital database for screening mammography ddsm dataset in preprocessing median filter and contrast limited adaptive histogram equalization clahe techniques are utilized for image enhancement after preprocessing the segmentation is performed using the region growing rg algorithm the feature extraction is carried out from the segmented images using a pyramidal histogram of oriented gradients phog and the alextnet model finally the classification is performed using the weighted knearest neighbor wknn optimized with sequential minimal optimization smo the classified images are evaluated based on accuracy recall precision specificity f1score and mathews correlation coefficient mcc additionally the false positive and error rates are evaluated the proposed model obtained 9857 accuracy 9861 recall 9925 specificity 9863 precision 9793 f1score 9626 mcc 00143 error rate and 00075 false positive rate fpr compared to the existing models the research model has obtained better performances and outperformed the other models",Lung
Cardiac CT Image Segmentation for Deep Learning–Based Coronary Calcium Detection Using K-Means Clustering and Grabcut Algorithm,https://doi.org/10.32604/csse.2023.037055,2023,"specific medical data has limitations in that there are not many numbers and it is not standardized to solve these limitations it is necessary to study how to efficiently process these limited amounts of data in this paper deep learning methods for automatically determining cardiovascular diseases are described and an effective preprocessing method for ct images that can be applied to improve the performance of deep learning was conducted the cardiac ct images include several parts of the body such as the heart lungs spine and ribs the preprocessing step proposed in this paper divided ct image data into regions of interest and other regions using kmeans clustering and the grabcut algorithm we compared the deep learning performance results of original data data using only kmeans clustering and data using both kmeans clustering and the grabcut algorithm all data used in this paper were collected at soonchunhyang university cheonan hospital in korea and the experimental test proceeded with irb approval the training was conducted using resnet 50 vgg and inception resnet v2 models and resnet 50 had the best accuracy in validation and testing through the preprocessing process proposed in this paper the accuracy of deep learning models was significantly improved by at least 10 and up to 40",Cardiac
Cardiac CT Image Segmentation for Deep Learning–Based Coronary Calcium Detection Using K-Means Clustering and Grabcut Algorithm,https://doi.org/10.32604/csse.2023.037055,2023,"specific medical data has limitations in that there are not many numbers and it is not standardized to solve these limitations it is necessary to study how to efficiently process these limited amounts of data in this paper deep learning methods for automatically determining cardiovascular diseases are described and an effective preprocessing method for ct images that can be applied to improve the performance of deep learning was conducted the cardiac ct images include several parts of the body such as the heart lungs spine and ribs the preprocessing step proposed in this paper divided ct image data into regions of interest and other regions using kmeans clustering and the grabcut algorithm we compared the deep learning performance results of original data data using only kmeans clustering and data using both kmeans clustering and the grabcut algorithm all data used in this paper were collected at soonchunhyang university cheonan hospital in korea and the experimental test proceeded with irb approval the training was conducted using resnet 50 vgg and inception resnet v2 models and resnet 50 had the best accuracy in validation and testing through the preprocessing process proposed in this paper the accuracy of deep learning models was significantly improved by at least 10 and up to 40",Lung
Cardiac CT Image Segmentation for Deep Learning–Based Coronary Calcium Detection Using K-Means Clustering and Grabcut Algorithm,https://doi.org/10.32604/csse.2023.037055,2023,"specific medical data has limitations in that there are not many numbers and it is not standardized to solve these limitations it is necessary to study how to efficiently process these limited amounts of data in this paper deep learning methods for automatically determining cardiovascular diseases are described and an effective preprocessing method for ct images that can be applied to improve the performance of deep learning was conducted the cardiac ct images include several parts of the body such as the heart lungs spine and ribs the preprocessing step proposed in this paper divided ct image data into regions of interest and other regions using kmeans clustering and the grabcut algorithm we compared the deep learning performance results of original data data using only kmeans clustering and data using both kmeans clustering and the grabcut algorithm all data used in this paper were collected at soonchunhyang university cheonan hospital in korea and the experimental test proceeded with irb approval the training was conducted using resnet 50 vgg and inception resnet v2 models and resnet 50 had the best accuracy in validation and testing through the preprocessing process proposed in this paper the accuracy of deep learning models was significantly improved by at least 10 and up to 40",Lung
Nonlinear Teager-Kaiser Infomax Boost Clustering Algorithm for Brain Tumor Detection Technique,https://doi.org/10.32604/csse.2023.028542,2023,"brain tumor detection and division is a difficult tedious undertaking in clinical image preparation when it comes to the new technology that enables accurate identification of the mysterious tissues of the brain magnetic resonance imaging mri is a great tool it is possible to alter the tumors size and shape at any time for any number of patients by using the brain picture radiologists have a difficult time sorting and classifying tumors from multiple images brain tumors may be accurately detected using a new approach called nonlinear teagerkaiser iterative infomax boost clusteringbased image segmentation ntkfibcis teagerkaiser filtering is used to reduce noise artifacts and improve the quality of images before they are processed different clinical characteristics are then retrieved and analyzed statistically to identify brain tumors the use of a brats2015 database enables the proposed approach to be used for both qualitative and quantitative research this dataset was used to do experimental evaluations on several metrics such as peak signaltonoise ratios illness detection accuracy and falsepositive rates as well as disease detection time as a function of a picture count this segmentation delivers greater accuracy in detecting brain tumors with minimal time consumption and falsepositive rates than current stateoftheart approaches",Brain
Nonlinear Teager-Kaiser Infomax Boost Clustering Algorithm for Brain Tumor Detection Technique,https://doi.org/10.32604/csse.2023.028542,2023,"brain tumor detection and division is a difficult tedious undertaking in clinical image preparation when it comes to the new technology that enables accurate identification of the mysterious tissues of the brain magnetic resonance imaging mri is a great tool it is possible to alter the tumors size and shape at any time for any number of patients by using the brain picture radiologists have a difficult time sorting and classifying tumors from multiple images brain tumors may be accurately detected using a new approach called nonlinear teagerkaiser iterative infomax boost clusteringbased image segmentation ntkfibcis teagerkaiser filtering is used to reduce noise artifacts and improve the quality of images before they are processed different clinical characteristics are then retrieved and analyzed statistically to identify brain tumors the use of a brats2015 database enables the proposed approach to be used for both qualitative and quantitative research this dataset was used to do experimental evaluations on several metrics such as peak signaltonoise ratios illness detection accuracy and falsepositive rates as well as disease detection time as a function of a picture count this segmentation delivers greater accuracy in detecting brain tumors with minimal time consumption and falsepositive rates than current stateoftheart approaches",Brain
An Effective Diagnosis System for Brain Tumor Detection and Classification,https://doi.org/10.32604/csse.2023.036107,2023,"a brain tumor is an excessive development of abnormal and uncontrolled cells in the brain this growth is considered deadly since it may cause death the brain controls numerous functions such as memory vision and emotions due to the location size and shape of these tumors their detection is a challenging and complex task several efforts have been conducted toward improved detection and yielded promising results and outcomes however the accuracy should be higher than what has been reached this paper presents a method to detect brain tumors with high accuracy the method works using an image segmentation technique and a classifier in matlab the utilized classifier is a support vector machine svm discrete wavelet transform dwt and principal component analysis pca are also involved a dataset from the kaggle website is used to test the developed approach the obtained results reached nearly 992 of accuracy the paper provides a confusion matrix of applying the proposed approach to testing images and a comparative evaluation between the developed method and some works in the literature this evaluation shows that the presented system outperforms other approaches regarding the accuracy precision and recall this research discovered that the developed method is extremely useful in detecting brain tumors given the high accuracy precision and recall results the proposed system directs us to believe that bringing this kind of technology to physicians diagnosing brain tumors is crucial",Brain
Brain Tumor MRI Identification and Classification Using DWT PCA and KSVM,https://doi.org/10.21203/rs.3.rs-2562932/v1,2023,"abstract background classification segmentation and the identification of the infection region in mri images of brain tumors are laborintensive and iterative processes the optimum classification technique helps make the proper choice and delivers the best therapy despite several significant efforts and encouraging discoveries in this subject precise segmentation and classification remain challenging tasks method in this study we proposed a new method for the exact segmentation and classification of brain tumors from mr images initially the tumor image is preprocessed and segmented by using the threshold function for removing image noises to minimize complexity and enhance performance used discrete wavelet transformation dwt for getting the accurate in mr images principal component analysis pca are used to condense the feature vector dimensions of magnetic resonance imagesfinally for differentiate between benign and malignant tumor types the classification stage employs a pretrained support vector machine with several kernels also known as a kernel support vector machine ksvm result the efficacy of the suggested approach is also compared to that of other existing frameworks for segmentation and classification results demonstrated that developed approach is effective and quick where as we obtained excellent accuracy and recognized the brain mr images as normal and pathological tissues",Brain
Optimized CNN-based Brain Tumor Segmentation and Classification using Artificial Bee Colony and Thresholding,https://doi.org/10.15837/ijccc.2023.1.4577,2023,"one of the most important tasks used by the medical profession for disease identification and recovery preparation is automatic medical image processing statistical approaches are the most commonly used algorithms and they consist several important step brain tumors are the foremost causes of death of cancerous diseases all over the world the hippocampus is the human bodys primary control structure since a tumor attacks the brain it can kill the patient if it is not detected early among the various imaging modalities available magnetic resonance image mri is a better implement for calculating area and classifying tumors based on their grade mri does not emit any toxic radiation there is currently no automated method for detecting and identifying the grade of a tumor this study mainly focusses on classifying and segmenting brain tumors from mri scan data it aids physicians in the planning of future care or surgery this procedure consists of four steps image denoising tumor extraction attribute extraction and hybrid classification in the first step of image denoising the curvelet transformation ct is used then in the next stage artificial bee colony abc optimization is used in conjunction with the thresholding process to remove tumors from brain mri scans another optimization approach is used to recover the learning rate of the convolutional neural network for the final hybrid classification the experiment model is assessed by using the multimodal brain tumor brats 2013 and 2015 challenge datasets from medical image computing the outcomes of the experiment presented that the method achieved the segmentation 9523 and 94 of accuracy where the proposed optimized cnn achieved classification accuracy of 985 and 99 for both datasets",Brain
Optimized CNN-based Brain Tumor Segmentation and Classification using Artificial Bee Colony and Thresholding,https://doi.org/10.15837/ijccc.2023.1.4577,2023,"one of the most important tasks used by the medical profession for disease identification and recovery preparation is automatic medical image processing statistical approaches are the most commonly used algorithms and they consist several important step brain tumors are the foremost causes of death of cancerous diseases all over the world the hippocampus is the human bodys primary control structure since a tumor attacks the brain it can kill the patient if it is not detected early among the various imaging modalities available magnetic resonance image mri is a better implement for calculating area and classifying tumors based on their grade mri does not emit any toxic radiation there is currently no automated method for detecting and identifying the grade of a tumor this study mainly focusses on classifying and segmenting brain tumors from mri scan data it aids physicians in the planning of future care or surgery this procedure consists of four steps image denoising tumor extraction attribute extraction and hybrid classification in the first step of image denoising the curvelet transformation ct is used then in the next stage artificial bee colony abc optimization is used in conjunction with the thresholding process to remove tumors from brain mri scans another optimization approach is used to recover the learning rate of the convolutional neural network for the final hybrid classification the experiment model is assessed by using the multimodal brain tumor brats 2013 and 2015 challenge datasets from medical image computing the outcomes of the experiment presented that the method achieved the segmentation 9523 and 94 of accuracy where the proposed optimized cnn achieved classification accuracy of 985 and 99 for both datasets",Brain
Brain Tumor Classification using SLIC Segmentation with Superpixel Fusion GoogleNet and Linear Neighborhood Semantic Segmentation,https://doi.org/10.56042/jsir.v82i2.70214,2023,"brain tumor is an abnormal tissue mass resultant of uncontrolled growth of cells brain tumors often reduce life expectancy and cause death in the later stages automatic detection of brain tumors is a challenging and important task in computeraided disease diagnosis systems this paper presents a deep learningbased approach to the classification of brain tumors the noise in the brain mri image is removed using edge directional total variation denoising the brain mri image is segmented using slic segmentation with superpixel fusion the segments are given to a trained googlenet model which identifies the tumor parts in the image once the tumor is identified a convolution neural network cnn based modified semantic segmentation model is used to classify the pixels along the edges of the tumor segments the modified sematic segmentation uses a linear neighborhood of the pixel for better classification the final tumor identified is accurate as pixels at the border are classified precisely the experimental results show that the proposed method has produced an accuracy of 973 with googlenet classification model and the linear neighborhood semantic segmentation has delivered an accuracy of 98",Brain
HC-Net: A hybrid convolutional network for non-human primate brain extraction,https://doi.org/10.3389/fncom.2023.1113381,2023,"brain extraction skull stripping is an essential step in the magnetic resonance imaging mri analysis of brain sciences however most of the current brain extraction methods that achieve satisfactory results for human brains are often challenged by nonhuman primate brains due to the small sample characteristics and the nature of thickslice scanning of macaque mri data traditional deep convolutional neural networks dcnns are unable to obtain excellent results to overcome this challenge this study proposed a symmetrical endtoend trainable hybrid convolutional neural network hcnet it makes full use of the spatial information between adjacent slices of the mri image sequence and combines three consecutive slices from three axes for 3d convolutions which reduces the calculation consumption and promotes accuracy the hcnet consists of encoding and decoding structures of 3d convolutions and 2d convolutions in series the effective use of 2d convolutions and 3d convolutions relieves the underfitting of 2d convolutions to spatial features and the overfitting of 3d convolutions to small samples after evaluating macaque brain data from different sites the results showed that hcnet performed better in inference time approximately 13 s per volume and accuracy mean dice coefficient reached 9546 the hcnet model also had good generalization ability and stability in different modes of brain extraction tasks",Brain
An adaptively weighted ensemble of multiple CNNs for carotid ultrasound image segmentation,https://doi.org/10.1016/j.bspc.2023.104673,2023,"carotid atherosclerotic plaques cause stroke when plaques rupture and clog the blood vessels that deliver blood to brain ultrasound measurements ie totalplaquearea and intimamediathickness are mainly used to monitor the progression and regression of plaques recently deep learning has provided powerful tools for ultrasound carotid image segmentation however the performances of deep learning models vary on different network architectures in this paper we report on the development of an adaptively weighted ensemble of multiple convolutional neural networks cnns for carotid ultrasound image segmentation aiming at combining the advantages of different cnn models to achieve higher accuracy and better generalization performance during the joint training of the ensemble networks the model weights and sample weights were combined to improve the segmentation performance this adaptively weighted ensemble algorithm was applied to three unet models with different backbones resnet152 densenet169 and vgg19 and evaluated on 510 carotid ultrasound images from 144 subjects who were followed in the stroke prevention and atherosclerosis research centre sparc london canada the experimental results show that our method increases the segmentation accuracy and reduces the distance errors as compared to using a single classifier three ensemble algorithms average weighting majority voting and segnetunet and a published carotid segmentation algorithm with high accuracy and low variance the proposed adaptively weighted ensemble model could be used to measure carotid plaques in clinical practice and clinical trials",Brain
The XPRESS Challenge: Xray Projectomic Reconstruction -- Extracting  Segmentation with Skeletons,https://doi.org/10.48550/arxiv.2302.03819,2023,"the wiring and connectivity of neurons form a structural basis for the function of the nervous system advances in volume electron microscopy em and image segmentation have enabled mapping of circuit diagrams connectomics within local regions of the mouse brain however applying volume em over the whole brain is not currently feasible due to technological challenges as a result comprehensive maps of longrange connections between brain regions are lacking recently we demonstrated that xray holographic nanotomography xnh can provide highresolution images of brain tissue at a much larger scale than em in particular xnh is wellsuited to resolve large myelinated axon tracts white matter that make up the bulk of longrange connections projections and are critical for interregion communication thus xnh provides an imaging solution for brainwide projectomics however because xnh data is typically collected at lower resolutions and larger fieldsofview than em accurate segmentation of xnh images remains an important challenge that we present here in this task we provide volumetric xnh images of cortical white matter axons from the mouse brain along with ground truth annotations for axon trajectories manual voxelwise annotation of ground truth is a timeconsuming bottleneck for training segmentation networks on the other hand skeletonbased ground truth is much faster to annotate and sufficient to determine connectivity therefore we encourage participants to develop methods to leverage skeletonbased training to this end we provide two types of groundtruth annotations a small volume of voxelwise annotations and a larger volume with skeletonbased annotations entries will be evaluated on how accurately the submitted segmentations agree with the groundtruth skeleton annotations",Brain
A Weighted Normalized Boundary Loss for Reducing the Hausdorff Distance  in Medical Imaging Segmentation,https://doi.org/10.48550/arxiv.2302.03868,2023,"within medical imaging segmentation the dice coefficient and hausdorffbased metrics are standard measures of success for deep learning models however modern loss functions for medical image segmentation often only consider the dice coefficient or similar regionbased metrics during training as a result segmentation architectures trained over such loss functions run the risk of achieving high accuracy for the dice coefficient but low accuracy for hausdorffbased metrics low accuracy on hausdorffbased metrics can be problematic for applications such as tumor segmentation where such benchmarks are crucial for example high dice scores accompanied by significant hausdorff errors could indicate that the predictions fail to detect small tumors we propose the weighted normalized boundary loss a novel loss function to minimize hausdorffbased metrics with more desirable numerical properties than current methods and with weighting terms for class imbalance our loss function outperforms other losses when tested on the brats dataset using a standard 3d unet and the stateoftheart nnunet architectures these results suggest we can improve segmentation accuracy with our novel loss function",Brain
Segmentation of multiple Organs‐at‐Risk associated with brain tumors based on coarse‐to‐fine stratified networks,https://doi.org/10.1002/mp.16247,2023,"delineation of organsatrisks oars is an important step in radiotherapy treatment planning as manual delineation is timeconsuming laborintensive and affected by inter and intraobserver variability a robust and efficient automatic segmentation algorithm is highly desirable for improving the efficiency and repeatability of oar delineationautomatic segmentation of oars in medical images is challenged by low contrast various shapes and imbalanced sizes of different organs we aim to overcome these challenges and develop a highperformance method for automatic segmentation of 10 oars required in radiotherapy planning for brain tumorsa novel twostage segmentation framework is proposed where a coarse and simultaneous localization of all the target organs is obtained in the first stage and a fine segmentation is achieved for each organ respectively in the second stage to deal with organs with various sizes and shapes a stratified segmentation strategy is proposed where a high and lowresolution residual network hlrnet that consists of a multiresolution branch and a highresolution branch is introduced to segment mediumsized organs and a highresolution residual network hrrnet is used to segment small organs in addition a label fusion strategy is proposed to better deal with symmetric pairs of organs like the left and right cochleas and lacrimal glandsour method was validated on the dataset of miccai abcs 2020 challenge for oar segmentation it obtained an average dice of 758 for 10 oars and significantly outperformed several stateoftheart models including nnunet 716 and focusnet 724 our proposed hlrnet and hrrnet improved the segmentation accuracy for mediumsized and small organs respectively the label fusion strategy led to higher accuracy for symmetric pairs of organsour proposed method is effective for the segmentation of oars of brain tumors with a better performance than existing methods especially on mediumsized and small organs it has a potential for improving the efficiency of radiotherapy planning with high segmentation accuracy",Brain
Hypergraph-based Numerical Neural-like P Systems for Medical Image Segmentation,https://doi.org/10.1109/tpds.2023.3240174,2023,"neurallike p systems are membrane computing models inspired by natural computing and are viewed as thirdgeneration neural network models although real neurons have complex structures classical neurallike p systems simplify the structures and corresponding mechanisms to twodimensional graphs or treebased firing and forgetting communications which limit the real applications of these models in this paper we propose a hypergraphbased numerical neurallike hnn p system containing five types of neurons to describe the highorder correlations among neuron structures three new kinds of communication mechanisms among neurons are also proposed to address numerical variables and functions based on the new neurallike p system a tumororgan segmentation model for medical images is developed the experimental results indicate that the proposed models outperform the stateoftheart methods based on two hippocampal datasets and a multiple brain metastases dataset thus verifying the effectiveness of the hnn p system in correctly segmenting tumorsorgans",Brain
An Efficient Model for Lungs Nodule Classification Using Supervised Learning Technique,https://doi.org/10.1155/2023/8262741,2023,"lung cancer has the highest death rate of any other cancer in the world detecting lung cancer early can increase a patients survival rate the corresponding work presents the method for improving the computeraided detection cad of nodules present in the lung area in computed tomography ct images the main aim was to get an overview of the latest tools and technologies used acquisition storage segmentation classification processing and analysis of biomedical data after the analysis a model is proposed consisting of three main steps in the first step threshold values and component labeling of 3d components were used to segment the lung volume in the second step candidate nodules are identified and segmented with an optimal threshold value and rulebased trimming it also selects 2d and 3d features from the candidate segmented node in the final step the selected features are used to train the svm and classify the nodes and classify the nonnodes to assess the performance of the proposed framework experiments were performed on the lidc data set as a result it was observed that the number of false positives in the nodule candidate was reduced to 4 fp per scan with a sensitivity of 95",Lung
Ensembled EfficientNetB3 architecture for multi-class classification of tumours in MRI images,https://doi.org/10.3233/idt-220150,2023,"healthcare informatics is one of the major concern domains in the processing of medical imaging for the diagnosis and treatment of brain tumours all over the world timely diagnosis of abnormal structures in brain tumours helps the clinical applications medicines doctors etc in processing and analysing the medical imaging the multiclass image classification of brain tumours faces challenges such as the scaling of large dataset training of image datasets efficiency accuracy etc efficientnetb3 neural network scales the images in three dimensions resulting in improved accuracy the novel neural network framework utilizes the optimization of an ensembled architecture of efficientnetb3 with unet for mri images which applies a semantic segmentation model for pretrained backbone networks the proposed neural model operates on a substantial network which will adapt the robustness by capturing the extraction of features in the unet encoder the decoder will be enabling pixellevel localization at the definite precision level by an average ensemble of segmentation models the ensembled pretrained models will provide better training and prediction of abnormal structures in mri images and thresholds for multiclassification of medical image visualization the proposed model results in mean accuracy of 9924 on the kaggle dataset with 3064 images with a mean dice score coefficient dsc of 09124 which is being compared with two stateofart neural models",Brain
Self-supervised Tumor Segmentation with Sim2Real Adaptation,https://doi.org/10.1109/jbhi.2023.3240844,2023,"this paper targets on selfsupervised tumor segmentation we make the following contributions i we take inspiration from the observation that tumors are often characterised independently of their contexts we propose a novel proxy task layerdecomposition that closely matches the goal of the downstream task and design a scalable pipeline for generating synthetic tumor data for pretraining ii we propose a twostage sim2real training regime for unsupervised tumor segmentation where we first pretrain a model with simulated tumors and then adopt a selftraining strategy for downstream data adaptation iii when evaluating on different tumor segmentation benchmarks italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkegi brats2018 for brain tumor segmentation and lits2017 for liver tumor segmentation our approach achieves stateoftheart segmentation performance under the unsupervised setting while transferring the model for tumor segmentation under a lowannotation regime the proposed approach also outperforms all existing selfsupervised approaches iv we conduct extensive ablation studies to analyse the critical components in data simulation and validate the necessity of different proxy tasks we demonstrate that with sufficient texture randomization in simulation model trained on synthetic data can effortlessly generalise to datasets with real tumors",Brain
Self-supervised Tumor Segmentation with Sim2Real Adaptation,https://doi.org/10.1109/jbhi.2023.3240844,2023,"this paper targets on selfsupervised tumor segmentation we make the following contributions i we take inspiration from the observation that tumors are often characterised independently of their contexts we propose a novel proxy task layerdecomposition that closely matches the goal of the downstream task and design a scalable pipeline for generating synthetic tumor data for pretraining ii we propose a twostage sim2real training regime for unsupervised tumor segmentation where we first pretrain a model with simulated tumors and then adopt a selftraining strategy for downstream data adaptation iii when evaluating on different tumor segmentation benchmarks italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkegi brats2018 for brain tumor segmentation and lits2017 for liver tumor segmentation our approach achieves stateoftheart segmentation performance under the unsupervised setting while transferring the model for tumor segmentation under a lowannotation regime the proposed approach also outperforms all existing selfsupervised approaches iv we conduct extensive ablation studies to analyse the critical components in data simulation and validate the necessity of different proxy tasks we demonstrate that with sufficient texture randomization in simulation model trained on synthetic data can effortlessly generalise to datasets with real tumors",Brain
SS-TBN: A Semi-Supervised Tri-Branch Network for COVID-19 Screening and Lesion Segmentation,https://doi.org/10.1109/tpami.2023.3240886,2023,"insufficient annotated data and minor lung lesions pose big challenges for computed tomography ctaided automatic covid19 diagnosis at an early outbreak stage to address this issue we propose a semisupervised tribranch network sstbn first we develop a joint tbn model for dualtask application scenarios of image segmentation and classification such as ctbased covid19 diagnosis in which pixellevel lesion segmentation and slicelevel infection classification branches are simultaneously trained via lesion attention and individuallevel diagnosis branch aggregates slicelevel outputs for covid19 screening second we propose a novel hybrid semisupervised learning method to make full use of unlabeled data combining a new doublethreshold pseudo labeling method specifically designed to the joint model and a new interslice consistency regularization method specifically tailored to ct images besides two publicly available external datasets we collect internal and our own external datasets including 210395 images 1420 cases vs 498 controls from ten hospitals experimental results show that the proposed method achieves stateoftheart performance in covid19 classification with limited annotated data even if lesions are subtle and that segmentation results promote interpretability for diagnosis suggesting the potential of the sstbn in early screening in insufficient labeled data situations at the early stage of a pandemic outbreak like covid19",Lung
LDANet: Automatic lung parenchyma segmentation from CT images,https://doi.org/10.1016/j.compbiomed.2023.106659,2023,"automatic segmentation of the lung parenchyma from computed tomography ct images is helpful for the subsequent diagnosis and treatment of patients in this paper based on a deep learning algorithm a lung dense attention network ldanet is proposed with two mechanisms residual spatial attention rsa and gated channel attention gca rsa is utilized to weight the spatial information of the lung parenchyma and suppress feature activation in irrelevant regions while the weights of each channel are adaptively calibrated using gca to implicitly predict potential key features then a dual attention guidance module dagm is designed to maximize the integration of the advantages of both mechanisms in addition ldanet introduces a lightweight dense block ldb that reuses feature information and a positioned transpose block ptb that realizes accurate positioning and gradually restores the image resolution until the predicted segmentation map is generated experiments are conducted on two public datasets lidcidri and covid19 ct segmentation on which ldanet achieves dice similarity coefficient values of 098430 and 098319 respectively outperforming a stateoftheart lung segmentation model additionally the effectiveness of the main components of ldanet is demonstrated through ablation experiments",Lung
A High-Speed Architecture for Lung Cancer Diagnosis,https://doi.org/10.4018/978-1-6684-6523-3.ch001,2023,"here the authors propose a simplified technique and its architecture for blind segmentation of histopathological images of lung cancer combining the kmeans and histogram analysis an improved version of otsus algorithm is introduced for performing histogram analysis to determine the number of clusters for executing the automatic segmentation of histopathological images the architecture is input with biopsy images of cancer patients suffering from different stages of lung cancer procured from standard hospital databases to evaluate the performance the results obtained are compared with the existing works from the literature showing considerable improvement in the overall efficiency of the image segmentation process segmentation output in terms of quantitative parameters like psnr ssim time of execution etc as well as qualitative analysis clearly reveals the usefulness of this technique in highspeed cytological evaluation the proposed architecture gives promising results in terms of its performance with a time of execution of 19225ms",Lung
Brain Tumor Segmentation Using Deep Learning Technique,https://doi.org/10.4018/978-1-6684-6434-2.ch003,2023,"cancer is one of the most lethal diseases in the world a brain tumor is a form of cancer that develops in the brains glial cells magnetic resonance imaging mri is a prominent imaging tool for detecting brain tumors it includes four different modalities that neurologists use to determine the location and kind of tumor the suggested approach uses a 2d unet model to separate the brain tumors sub regions to prevent excessive preprocessing and gpu utilization the authors utilize the patching approach to partition the picture slices into distinct patches in this study second they leverage the squeeze and excitation blocks to more effectively map lowlevel features to highlevel features than a basic unet the suggested technique yields dice scores of 085 087 and 090 for the three tumor categories of enhancing tumor whole tumor and tumor core respectively the results outperform the most recent approaches including the major papers from the brats 2019 competition",Brain
Brain Tumor Segmentation Using Deep Learning Technique,https://doi.org/10.4018/978-1-6684-6434-2.ch003,2023,"cancer is one of the most lethal diseases in the world a brain tumor is a form of cancer that develops in the brains glial cells magnetic resonance imaging mri is a prominent imaging tool for detecting brain tumors it includes four different modalities that neurologists use to determine the location and kind of tumor the suggested approach uses a 2d unet model to separate the brain tumors sub regions to prevent excessive preprocessing and gpu utilization the authors utilize the patching approach to partition the picture slices into distinct patches in this study second they leverage the squeeze and excitation blocks to more effectively map lowlevel features to highlevel features than a basic unet the suggested technique yields dice scores of 085 087 and 090 for the three tumor categories of enhancing tumor whole tumor and tumor core respectively the results outperform the most recent approaches including the major papers from the brats 2019 competition",Brain
Automation of Brain Tumor Segmentation Using Deep Learning,https://doi.org/10.1007/978-981-19-5723-9_13,2023,"today also radiologist analyze the mr images manually based on their experience and knowledge for segmenting the tumor use some graphical software to make the report about the presence of the tumor its size and other features based on this report doctors diagnose the patient it is the main source for any doctor to start the treatment of the patient however as the mri reports are based on the experience of the radiologist so it is a big challenge to maintain uniformity in the reports generated from the different mr imaging centers therefore automation in this particular field is very much required for better precision and to maintain uniformity in the report therefore doctor can diagnose the patient in much better way deep learning playing a vital role in automating the process of brain tumor and other organ segmentation using mr images many researchers developed various stateofart methods to automate the process of brain tumor segmentation in mr images there are multiple deep learning methods such as stacked auto encoder artificial neural network convolutional neural network and unet used for the process of segmenting the medial images where cnn is the most successful method for segmenting in this chapter the importance of automatic brain tumor segmentation approach cnn and process of convolution max pooling discussed in detail moreover application of cnn for automatically segmenting brain tumor also discussed with some stateofart methods",Brain
Investigating the Impact of Two Major Programming Environments on the Accuracy of Deep Learning-Based Glioma Detection from MRI Images,https://doi.org/10.3390/diagnostics13040651,2023,"brain tumors have been the subject of research for many years brain tumors are typically classified into two main groups benign and malignant tumors the most common tumor type among malignant brain tumors is known as glioma in the diagnosis of glioma different imaging technologies could be used among these techniques mri is the most preferred imaging technology due to its highresolution image data however the detection of gliomas from a huge set of mri data could be challenging for the practitioners in order to solve this concern many deep learning dl models based on convolutional neural networks cnns have been proposed to be used in detecting glioma however understanding which cnn architecture would work efficiently under various conditions including development environment or programming aspects as well as performance analysis has not been studied so far in this research work therefore the purpose is to investigate the impact of two major programming environments namely matlab and python on the accuracy of cnnbased glioma detection from magnetic resonance imaging mri images to this end experiments on the brain tumor segmentation brats dataset 2016 and 2017 consisting of multiparametric magnetic mri images are performed by implementing two popular cnn architectures the threedimensional 3d unet and the vnet in the programming environments from the results it is concluded that the use of python with google colaboratory colab might be highly useful in the implementation of cnnbased models for glioma detection moreover the 3d unet model is found to perform better attaining a high accuracy on the dataset the authors believe that the results achieved from this study would provide useful information to the research community in their appropriate implementation of dl approaches for brain tumor detection",Brain
Investigating the Impact of Two Major Programming Environments on the Accuracy of Deep Learning-Based Glioma Detection from MRI Images,https://doi.org/10.3390/diagnostics13040651,2023,"brain tumors have been the subject of research for many years brain tumors are typically classified into two main groups benign and malignant tumors the most common tumor type among malignant brain tumors is known as glioma in the diagnosis of glioma different imaging technologies could be used among these techniques mri is the most preferred imaging technology due to its highresolution image data however the detection of gliomas from a huge set of mri data could be challenging for the practitioners in order to solve this concern many deep learning dl models based on convolutional neural networks cnns have been proposed to be used in detecting glioma however understanding which cnn architecture would work efficiently under various conditions including development environment or programming aspects as well as performance analysis has not been studied so far in this research work therefore the purpose is to investigate the impact of two major programming environments namely matlab and python on the accuracy of cnnbased glioma detection from magnetic resonance imaging mri images to this end experiments on the brain tumor segmentation brats dataset 2016 and 2017 consisting of multiparametric magnetic mri images are performed by implementing two popular cnn architectures the threedimensional 3d unet and the vnet in the programming environments from the results it is concluded that the use of python with google colaboratory colab might be highly useful in the implementation of cnnbased models for glioma detection moreover the 3d unet model is found to perform better attaining a high accuracy on the dataset the authors believe that the results achieved from this study would provide useful information to the research community in their appropriate implementation of dl approaches for brain tumor detection",Brain
Feature Extraction Using a Residual Deep Convolutional Neural Network (ResNet-152) and Optimized Feature Dimension Reduction for MRI Brain Tumor Classification,https://doi.org/10.3390/diagnostics13040668,2023,"one of the top causes of mortality in people globally is a brain tumor today biopsy is regarded as the cornerstone of cancer diagnosis however it faces difficulties including low sensitivity hazards during biopsy treatment and a protracted waiting period for findings in this context developing noninvasive and computational methods for identifying and treating brain cancers is crucial the classification of tumors obtained from an mri is crucial for making a variety of medical diagnoses however mri analysis typically requires much time the primary challenge is that the tissues of the brain are comparable numerous scientists have created new techniques for identifying and categorizing cancers however due to their limitations the majority of them eventually fail in that context this work presents a novel way of classifying multiple types of brain tumors this work also introduces a segmentation algorithm known as canny mayfly enhanced chimpanzee optimization algorithm echoa is used to select the features by minimizing the dimension of the retrieved features resnet152 and the softmax classifier are then used to perform the feature classification process python is used to carry out the proposed method on the figshare dataset the accuracy specificity and sensitivity of the proposed cancer classification system are just a few of the characteristics that are used to evaluate its overall performance according to the final evaluation results our proposed strategy outperformed with an accuracy of 9885",Brain
DEHA-Net: A Dual-Encoder-Based Hard Attention Network with an Adaptive ROI Mechanism for Lung Nodule Segmentation,https://doi.org/10.3390/s23041989,2023,"measuring pulmonary nodules accurately can help the early diagnosis of lung cancer which can increase the survival rate among patients numerous techniques for lung nodule segmentation have been developed however most of them either rely on the 3d volumetric region of interest voi input by radiologists or use the 2d fixed region of interest roi for all the slices of computed tomography ct scan these methods only consider the presence of nodules within the given voi which limits the networks ability to detect nodules outside the voi and can also encompass unnecessary structures in the voi leading to potentially inaccurate segmentation in this work we propose a novel approach for 3d lung nodule segmentation that utilizes the 2d region of interest roi inputted from a radiologist or computeraided detection cade system concretely we developed a twostage lung nodule segmentation technique firstly we designed a dualencoderbased hard attention network dehanet in which the full axial slice of thoracic computed tomography ct scan along with an roi mask were considered as input to segment the lung nodule in the given slice the output of dehanet the segmentation mask of the lung nodule was inputted to the adaptive region of interest aroi algorithm to automatically generate the roi masks for the surrounding slices which eliminated the need for any further inputs from radiologists after extracting the segmentation along the axial axis at the second stage we further investigated the lung nodule along sagittal and coronal views by employing dehanet all the estimated masks were inputted into the consensus module to obtain the final volumetric segmentation of the nodule the proposed scheme was rigorously evaluated on the lung image database consortium and image database resource initiative lidcidri dataset and an extensive analysis of the results was performed the quantitative analysis showed that the proposed method not only improved the existing stateoftheart methods in terms of dice score but also showed significant robustness against different types shapes and dimensions of the lung nodules the proposed framework achieved the average dice score sensitivity and positive predictive value of 8791 9084 and 8956 respectively",Lung
A Novel Method of Thresholding for Brain Tumor Segmentation and Detection,https://doi.org/10.1007/978-981-19-7528-8_22,2023,"abstracthumanassisted manual categorization of brain tumors is one of the most difficult tasks in medical image processing because incorrect prognosis and diagnosis might occur brain tumors vary in appearance and there is a strong relationship between tumors and normal tissues in this study a thresholding approach was used to eliminate brain malignancies from 2d magnetic resonance brain images mri we suggested an hofilter for preprocessing mri images that eliminates unnecessary noise and prepares the picture for tumor segmentation we also compared our findings to those of other researchers on segmentation and detection and discovered that ours were better for a variety of methodologies we got better results after using the highlighted object filter hofilter to extract the appropriately segmented tumor from mri images edge detection segmentation and morphological techniques were applied in our proposed model we obtained an accuracy rate of 9646 and a precision rate of 9619keywordsmrithresholdingsegmentationhofilterbrain tumor detection",Brain
Clinical Validation of Siemens’ Syngo.via Automatic Contouring System,https://doi.org/10.1016/j.adro.2023.101177,2023,"the manual delineation of organs at risk is a process that requires a great deal of time both for the technician and for the physician availability of validated software tools assisted by artificial intelligence would be of great benefit as it would significantly improve the radiation therapy workflow reducing the time required for segmentation the purpose of this article is to validate the deep learningbased autocontouring solution integrated in syngovia rt image suite vb40 siemens healthineers forchheim germanyfor this purpose we have used our own specific qualitative classification system rank to evaluate more than 600 contours corresponding to 18 different automatically delineated organs at risk computed tomography data sets of 95 different patients were included 30 patients with lung 30 patients with breast and 35 male patients with pelvic cancer the automatically generated structures were reviewed in the eclipse contouring module independently by 3 observers an expert physician an expert technician and a junior physicianthere is a statistically significant difference between the dice coefficient associated with rank 4 compared with the coefficient associated with ranks 2 and 3 p 001 in total 64 of the evaluated structures received the maximum score 4 only 1 of the structures were classified with the lowest score 1 the time savings for breast thorax and pelvis were 876 935 and 822 respectivelysiemens syngovia rt image suite offers good autocontouring results and significant time savings",Lung
Classification and Segmentation on Multi-regional Brain Tumors Using Volumetric Images of MRI with Customized 3D U-Net Framework,https://doi.org/10.1007/978-981-19-7528-8_18,2023,"abstractautomated segmentation is a computerized technique that helps to find tumor location size and shape human segmentation is error prone time consuming and needs an expert radiologist in our study we developed a customized 3d unet model that processes 3d volumetric images for multiclass tumor segmentation this framework is modified in such a way that the gradient flow is better for finding accurate output the brats 2020 dataset is used to train this network with endtoend learning strategy followed by defining the proper skip connection from encoder to decoder in model evaluation binary crossentropy with dice loss functions is utilized testing samples are predicted and classified into three regions whole tumor wt tumor core tc and enhancing tumor et model performance is evaluated through dice and jaccard coefficient metrics for each class furthermore in the testing dataset the dice scores are found at 0753 0799 and 0887 for the et tc and wt classeskeywordsdeep learningmedical imagingmrisemantic segmentation3d unetbrats 2020",Brain
Lumen and nuclei detection in histopathology of prostate cancer based on morphological feature extraction,https://doi.org/10.1063/5.0106231,2023,"prostate cancer is the most common cancer in men the results of a fast and precise classification can be a fundamental objective of reference histological assessment is valuable information for doctors the most common assessment for histological assessment of prostate cancer is the gleason grading system gleason pattern detection was done by extracting morphological features in the form of line length area fraction and the comparison between line length and area fraction all morphological features become the input of backpropagation based on the results of backpropagation testing this method can classify gleason pattern images with an accuracy of 9167 the threshold of segmentation in determining the lumen and nucleus did not have a specific range in its threshold due to the lack of uniform contrast in each image",Prostate
Reliable Mutual Distillation for Medical Image Segmentation under Imperfect Annotations,https://doi.org/10.1109/tmi.2023.3237183,2023,"convolutional neural networks cnns have made enormous progress in medical image segmentation the learning of cnns is dependent on a large amount of training data with fine annotations the workload of data labeling can be significantly relieved via collecting imperfect annotations which only match the underlying ground truths coarsely however label noises which are systematically introduced by the annotation protocols severely hinders the learning of cnnbased segmentation models hence we devise a novel collaborative learning framework in which two segmentation models cooperate to combat label noises in coarse annotations first the complementary knowledge of two models is explored by making one model clean training data for the other model secondly to further alleviate the negative impact of label noises and make sufficient usage of the training data the specific reliable knowledge of each model is distilled into the other model with augmentationbased consistency constraints a reliabilityaware sample selection strategy is incorporated for guaranteeing the quality of the distilled knowledge moreover we employ joint data and model augmentations to expand the usage of reliable knowledge extensive experiments on two benchmarks showcase the superiority of our proposed method against existing methods under annotations with different noise levels for example our approach can improve existing methods by nearly 3 dsc on the lung lesion segmentation dataset lidcidri under annotations with 80 noise ratio",Lung
Scaling and Cutout Data Augmentation for Cardiac Segmentation,https://doi.org/10.1007/978-981-19-6634-7_42,2023,"abstractconvolutional neural network cnn has a compelling learning capability especially on spatial data representation crucial in dealing with complex learning tasks however it requires extensive training data to optimally fit the model making it susceptible to overfitting problems when the data is scarce thus limiting its generalization ability therefore it is essential to collect enough data or supplement the dataset with artificial data to improve the performance of the cnn model in this paper simple data augmentation through the geometry transformations of scaling and cutting is explored to augment the training dataset for cardiac segmentation the generated images and labels are combined with the original dataset to double the training data size three stateoftheart semantic segmentation models which are unet ternausnet and dabnet were used to validate the performance improvement of the proposed data augmentation method the best performance improvement is returned by dabnet with an increment of 024 and 514 for mean accuracy and mean intersection over union respectively hence a better segmentation performance will enable medical practitioners to localize the organs effectively and efficientlykeywordssemantic segmentationdata augmentationcardiac analysismagnetic resonance imaging",Cardiac
A deep learning model based on the attention mechanism for automatic segmentation of abdominal muscle and fat for body composition assessment,https://doi.org/10.21037/qims-22-330,2023,"quantitative muscle and fat data obtained through body composition analysis are expected to be a new stable biomarker for the early and accurate prediction of treatmentrelated toxicity treatment response and prognosis in patients with lung cancer the use of these biomarkers can enable the adjustment of individualized treatment regimens in a timely manner which is critical to further improving patient prognosis and quality of life we aimed to develop a deep learning model based on attention for fully automated segmentation of the abdomen from computed tomography ct to quantify body compositiona fully automatic segmentation deep learning model was designed based on the attention mechanism and using unet as the framework subcutaneous fat skeletal muscle and visceral fat were manually segmented by two experts to serve as ground truth labels the performance of the model was evaluated using dice similarity coefficients dscs and hausdorff distance at 95th percentile hd95the mean dsc for subcutaneous fat and skeletal muscle were high for both the enhanced ct test set 093006 and 096002 respectively and the plain ct test set 090009 and 095001 respectively nevertheless the model did not perform well in the segmentation performance of visceral fat especially for the enhanced ct test set the mean dsc for the enhanced ct test set was 087011 while the mean dsc for the plain ct test set was 092003 we discuss the reasons for this resultthis work demonstrates a method for the automatic outlining of subcutaneous fat skeletal muscle and visceral fat areas at l3",Lung
Learning from multiple annotators for medical image segmentation,https://doi.org/10.1016/j.patcog.2023.109400,2023,"supervised machine learning methods have been widely developed for segmentation tasks in recent years however the quality of labels has high impact on the predictive performance of these algorithms this issue is particularly acute in the medical image domain where both the cost of annotation and the interobserver variability are high different human experts contribute estimates of the actual segmentation labels in a typical label acquisition process influenced by their personal biases and competency levels the performance of automatic segmentation algorithms is limited when these noisy labels are used as the expert consensus label in this work we use two coupled cnns to jointly learn from purely noisy observations alone the reliability of individual annotators and the expert consensus label distributions the separation of the two is achieved by maximally describing the annotators unreliable behavior we call it maximally unreliable while achieving high fidelity with the noisy training data we first create a toy segmentation dataset using mnist and investigate the properties of the proposed algorithm we then use three public medical imaging segmentation datasets to demonstrate our methods efficacy including both simulated where necessary and realworld annotations 1 isbi2015 multiplesclerosis lesions 2 brats brain tumors 3 lidcidri lung abnormalities finally we create a realworld multiple sclerosis lesion dataset qsmsc at ucl queen square multiple sclerosis center at ucl uk with manual segmentations from 4 different annotators 3 radiologists with different level skills and 1 expert to generate the expert consensus label in all datasets our method consistently outperforms competing methods and relevant baselines especially when the number of annotations is small and the amount of disagreement is large the studies also reveal that the system is capable of capturing the complicated spatial characteristics of annotators mistakes",Brain
Learning from multiple annotators for medical image segmentation,https://doi.org/10.1016/j.patcog.2023.109400,2023,"supervised machine learning methods have been widely developed for segmentation tasks in recent years however the quality of labels has high impact on the predictive performance of these algorithms this issue is particularly acute in the medical image domain where both the cost of annotation and the interobserver variability are high different human experts contribute estimates of the actual segmentation labels in a typical label acquisition process influenced by their personal biases and competency levels the performance of automatic segmentation algorithms is limited when these noisy labels are used as the expert consensus label in this work we use two coupled cnns to jointly learn from purely noisy observations alone the reliability of individual annotators and the expert consensus label distributions the separation of the two is achieved by maximally describing the annotators unreliable behavior we call it maximally unreliable while achieving high fidelity with the noisy training data we first create a toy segmentation dataset using mnist and investigate the properties of the proposed algorithm we then use three public medical imaging segmentation datasets to demonstrate our methods efficacy including both simulated where necessary and realworld annotations 1 isbi2015 multiplesclerosis lesions 2 brats brain tumors 3 lidcidri lung abnormalities finally we create a realworld multiple sclerosis lesion dataset qsmsc at ucl queen square multiple sclerosis center at ucl uk with manual segmentations from 4 different annotators 3 radiologists with different level skills and 1 expert to generate the expert consensus label in all datasets our method consistently outperforms competing methods and relevant baselines especially when the number of annotations is small and the amount of disagreement is large the studies also reveal that the system is capable of capturing the complicated spatial characteristics of annotators mistakes",Brain
Learning from multiple annotators for medical image segmentation,https://doi.org/10.1016/j.patcog.2023.109400,2023,"supervised machine learning methods have been widely developed for segmentation tasks in recent years however the quality of labels has high impact on the predictive performance of these algorithms this issue is particularly acute in the medical image domain where both the cost of annotation and the interobserver variability are high different human experts contribute estimates of the actual segmentation labels in a typical label acquisition process influenced by their personal biases and competency levels the performance of automatic segmentation algorithms is limited when these noisy labels are used as the expert consensus label in this work we use two coupled cnns to jointly learn from purely noisy observations alone the reliability of individual annotators and the expert consensus label distributions the separation of the two is achieved by maximally describing the annotators unreliable behavior we call it maximally unreliable while achieving high fidelity with the noisy training data we first create a toy segmentation dataset using mnist and investigate the properties of the proposed algorithm we then use three public medical imaging segmentation datasets to demonstrate our methods efficacy including both simulated where necessary and realworld annotations 1 isbi2015 multiplesclerosis lesions 2 brats brain tumors 3 lidcidri lung abnormalities finally we create a realworld multiple sclerosis lesion dataset qsmsc at ucl queen square multiple sclerosis center at ucl uk with manual segmentations from 4 different annotators 3 radiologists with different level skills and 1 expert to generate the expert consensus label in all datasets our method consistently outperforms competing methods and relevant baselines especially when the number of annotations is small and the amount of disagreement is large the studies also reveal that the system is capable of capturing the complicated spatial characteristics of annotators mistakes",Lung
Boosting COVID-19 Severity Detection with Infection-Aware Contrastive Mixup Classification,https://doi.org/10.1007/978-3-031-25082-8_36,2023,"abstractthis paper presents our solution for the 2nd covid19 severity detection competition this task aims to distinguish the mild moderate severe and critical grades in covid19 chest ct images in our approach we devise a novel infectionaware 3d contrastive mixup classification network for severity grading specifically we train two segmentation networks to first extract the lung region and then the inner lesion region the lesion segmentation mask serves as complementary information for the original ct slices to relieve the issue of imbalanced data distribution we further improve the advanced contrastive mixup classification network by weighted crossentropy loss on the covid19 severity detection leaderboard our approach won the first place with a macro f1 score of 5176 it significantly outperforms the baseline method by over 1146keywordscovid19 severity detectionchest ct imagesinfectionaware contrastive mixup classification",Lung
Comparison of automated segmentation techniques for magnetic resonance images of the prostate,https://doi.org/10.1186/s12880-023-00974-y,2023,"contouring of anatomical regions is a crucial step in the medical workflow and is both timeconsuming and prone to intra and interobserver variability this study compares different strategies for automatic segmentation of the prostate in t2weighted mristhis study included 100 patients diagnosed with prostate adenocarcinoma who had undergone multiparametric mri and prostatectomy from the t2weighted mr images ground truth segmentation masks were established by consensus from two expert radiologists the prostate was then automatically contoured with six different methods 1 a multiatlas algorithm 2 a proprietary algorithm in the syngovia medical imaging software and four deep learning models 3 a vnet trained from scratch 4 a pretrained 2d unet 5 a gan extension of the 2d unet and 6 a segmentationadapted efficientdet architecture the resulting segmentations were compared and scored against the ground truth masks with one 7030 and one 5050 traintest data split we also analyzed the association between segmentation performance and clinical variablesthe best performing method was the adapted efficientdet model 6 achieving a mean dice coefficient of 0914 a mean absolute volume difference of 59 a mean surface distance msd of 193 pixels and a mean 95th percentile hausdorff distance of 377 pixels the deep learning models were less prone to serious errors 0854 minimum dice and 402 maximum msd and no significant relationship was found between segmentation performance and clinical variablesdeep learningbased segmentation techniques can consistently achieve dice coefficients of 09 or above with as few as 50 training patients regardless of architectural archetype the atlasbased and syngovia methods found in commercial clinical software performed significantly worse 0855formula see text0887 dice",Prostate
Enhancing Modality-Agnostic Representations via Meta-Learning for Brain  Tumor Segmentation,https://doi.org/10.48550/arxiv.2302.04308,2023,"in the medical vision domain different imaging modalities provide complementary information however in practice not all modalities may be available during inference previous approaches eg knowledge distillation or image synthesis often assume the availability of full modalities for all patients during training this is unrealistic and impractical owing to the variability in data collection across sites we propose a novel approach to learn enhanced modalityagnostic representations by employing a novel metalearning strategy in training even when only a fraction of full modality patients are available metalearning enhances partial modality representations to full modality representations by metatraining on partial modality data and metatesting on limited full modality samples additionally we cosupervise this feature enrichment by introducing an auxiliary adversarial learning branch more specifically a missing modality detector is used as a discriminator to mimic the full modality setting our segmentation framework significantly outperforms stateoftheart brain tumor segmentation techniques in missing modality scenarios as demonstrated on two brain tumor mri datasets",Brain
Complex Network for Complex Problems: A comparative study of CNN and  Complex-valued CNN,https://doi.org/10.48550/arxiv.2302.04584,2023,"neural networks especially convolutional neural networks cnn are one of the most common tools these days used in computer vision most of these networks work with realvalued data using realvalued features complexvalued convolutional neural networks cvcnn can preserve the algebraic structure of complexvalued input data and have the potential to learn more complex relationships between the input and the groundtruth although some comparisons of cnns and cvcnns for different tasks have been performed in the past a largescale investigation comparing different models operating on different tasks has not been conducted furthermore because complex features contain both real and imaginary components cvcnns have double the number of trainable parameters as realvalued cnns in terms of the actual number of trainable parameters whether or not the improvements in performance with cvcnn observed in the past have been because of the complex features or just because of having double the number of trainable parameters has not yet been explored this paper presents a comparative study of cnn cnnx2 cnn with double the number of trainable parameters as the cnn and cvcnn the experiments were performed using seven models for two different tasks brain tumour classification and segmentation in brain mris the results have revealed that the cvcnn models outperformed the cnn and cnnx2 models",Brain
Brain Tumor Detection and Localization: An Inception V3 - Based Classification Followed By RESUNET-Based Segmentation Approach,https://doi.org/10.33889/ijmems.2023.8.2.020,2023,"adults and children alike are at risk from brain tumors accurate and prompt detection on the other hand can save lives this research focuses on the identification and localization of brain tumors many research has been available on the analysis and classification of brain tumors but only a few have addressed the issue of feature engineering to address the difficulties of manual diagnostics and traditional featureengineering procedures new methods are required to reliably segment and identify brain tumors an automated diagnostic method is required while progress is being made automated brain tumor diagnosis still confront hurdles such as low accuracy and a high rate of falsepositive outcomes deep learning is used to analyse brain tumors in the model described in this work which improves classification and segmentation using inceptionv3 and resunet deep learning is pragmatic for tumor classification and segmentation on the inception v3 model add one extra layer as a head for classifying the outcomes of these procedures are compared to those of existing methods the test accuracy of the inceptionv3 with extra classification layer model is 09996 while the loss value is 00025 the model tversky value for localization and detection is 09688 while the model accuracy is 09700",Brain
Proposed Methodology for Reducing Bias in Structural MRI Analysis in the Presence of Lesions: Data from a Pediatric Traumatic Brain Injury Cohort,https://doi.org/10.1101/2023.02.12.528180,2023,"abstract traumatic brain injury can lead to multiple pathologic features including brain lesions which are visible on magnetic resonance imaging mri these resulting heterogenous lesions can present a difficulty for several standard approaches to neuroimaging resulting in bias and error in subsequent quantitative measurements thus cases presenting with lesions on mri may be excluded from analyses biasing samples across the research field we outline a potential solution to this issue in the case of freesurfer a popular neuroimaging tool for surfacebased segmentation of brain tissue from structural mri the proposed solution involves twosteps a preprocessing enantiomorphic lesionfilling and b postprocessing lesion labelling we applied this methodology to 14 pediatric tbi cases which presented with lesions on t1w mri following qualitative inspection of these cases after implementation of the approach 8 out of 14 cases were retained as being of sufficient quality in brief we have presented here an adapted pipeline for processing structural mri smri of patients who have experienced a tbi using the freesurfer software package this approach aims to mitigate potential lesioninduced biases that exist beyond the locality of the pathological tissue even in the contralesioned hemisphere",Brain
Open-source fully-automated hybrid cardiac substructure segmentation: development and optimisation,https://doi.org/10.1007/s13246-023-01231-w,2023,"abstract radiotherapy for thoracic and breast tumours is associated with a range of cardiotoxicities emerging evidence suggests cardiac substructure doses may be more predictive of specific outcomes however quantitative data necessary to develop clinical planning constraints is lacking retrospective analysis of patient data is required which relies on accurate segmentation of cardiac substructures in this study a novel model was designed to deliver reliable accurate and anatomically consistent segmentation of 18 cardiac substructures on computed tomography ct scans thirty manually contoured ct scans were included the proposed multistage method leverages deep learning dl multiatlas mapping and geometric modelling to automatically segment the whole heart cardiac chambers great vessels heart valves coronary arteries and conduction nodes segmentation performance was evaluated using the dice similarity coefficient dsc mean distance to agreement mda hausdorff distance hd and volume ratio performance was reliable with no errors observed and acceptable variation in accuracy between cases including in challenging cases with imaging artefacts and atypical patient anatomy the median dsc range was 081093 for whole heart and cardiac chambers 043076 for great vessels and conduction nodes and 022053 for heart valves for all structures the median mda was below 6 mm median hd ranged 77197 mm and median volume ratio was close to one 095149 for all structures except the left main coronary artery 207 the fully automatic algorithm takes between 9 and 23 min per case the proposed fullyautomatic method accurately delineates cardiac substructures on radiotherapy planning ct scans robust and anatomically consistent segmentations particularly for smaller structures represents a major advantage of the proposed segmentation approach the opensource software will facilitate more precise evaluation of cardiac doses and risks from available clinical datasets graphical abstract",Cardiac
Learning multi-view and centerline topology connectivity information for pulmonary artery–vein separation,https://doi.org/10.1016/j.compbiomed.2023.106669,2023,"automatic pulmonary arteryvein separation has considerable importance in the diagnosis and treatment of lung diseases however insufficient connectivity and spatial inconsistency have always been the problems of arteryvein separationa novel automatic method for arteryvein separation in ct images is presented in this work specifically a multiscale information aggregated network msianet including multiscale fusion blocks and deep supervision is proposed to learn the features of arteryvein and aggregate additional semantic information respectively the proposed method integrates nine msianet models for arteryvein separation vessel segmentation and centerline separation tasks along with axial coronal and sagittal multiview slices first the preliminary arteryvein separation results are obtained by the proposed multiview fusion strategy mvfs then centerline correction algorithm cca is used to correct the preliminary results of arteryvein separation by the centerline separation results finally the vessel segmentation results are utilized to reconstruct the arteryvein morphology in addition weighted crossentropy and dice loss are employed to solve the class imbalance problemwe constructed 50 manually labeled contrastenhanced computed ct scans for fivefold crossvalidation and experimental results demonstrated that our method achieves superior segmentation performance of 977 851 and 849 on acc pre and dsc respectively additionally a series of ablation studies demonstrate the effectiveness of the proposed componentsthe proposed method can effectively solve the problem of insufficient vascular connectivity and correct the spatial inconsistency of arteryvein",Lung
Edge Detection of MRI Brain Images Based on Segmentation and Classification Using Support Vector Machines and Neural Networks Pattern Recognition,https://doi.org/10.1007/978-3-031-21216-1_11,2023,"abstractbrain tumor brain cancer is a mass of abnormal cells that grow in the brain in an uncontrolled way brain ct and brain mri are the most frequently performed examinations the objective of this paper is to develop a method for the classification of brain mri images of healthy cases and tumor cases mri brain database is obtained by preprocessing segmentation feature extraction feature extraction based on support vector machines clustering is used in this research the objective of this method is to create several vectors and each vector contains a number of features of each image so that we can make the classification by these featureskeywordsneural networks pattern recognitionsupport vector machinesegmentationbrain image",Brain
Study and Implementation of U-Net Encoder-Decoder Neural Network for Brain Tumors Segmentation,https://doi.org/10.1007/978-3-031-21216-1_47,2023,"abstractemerging advanced technologies have seen a revolution of applications into medical field in all its aspects and sides this has helped healthcare practitioners and empowered them in achieving accurate diagnosis and treatment specifically with the evolution of computer aided diagnosis systems which use image processing techniques computer visionand deep learning applied on different medical images in order to diagnose the image or sections of the image with particular diseases or illnesses medical images of multiples organs or parts of the body liver brain kidney skin etc can today be visualized thanks to the advanced medical imaging techniques that exists in the market mri ct etc these technologies uses high energy in order to acquire high quality images but high energy can harm human cells this is why we us low energy and with this used we get slightly low quality medical images and here technology intervenes where we can use preprocessing techniques in order to increase image resolution prior to perform diagnosis either by doctor or cad system we present in this paper a computer aided diagnosis system that provides an automated brain tissue segmentation applied on 3d mri images with its four different modalities t1 t1c t2 t2 weighted of brats 2020 challenge dataset by implementing a unet like deep neural network which provides information about classification of brain tissue into healthy tissue edema enhancing tumour non enhancing tumour the model achieved an accuracy of 9901 and dice coefficient of 4795 after 35 epochs of trainingkeywordssegmentationdeep learningbrain tumorsmedical image segmentationmedical image analysis",Brain
Study and Implementation of U-Net Encoder-Decoder Neural Network for Brain Tumors Segmentation,https://doi.org/10.1007/978-3-031-21216-1_47,2023,"abstractemerging advanced technologies have seen a revolution of applications into medical field in all its aspects and sides this has helped healthcare practitioners and empowered them in achieving accurate diagnosis and treatment specifically with the evolution of computer aided diagnosis systems which use image processing techniques computer visionand deep learning applied on different medical images in order to diagnose the image or sections of the image with particular diseases or illnesses medical images of multiples organs or parts of the body liver brain kidney skin etc can today be visualized thanks to the advanced medical imaging techniques that exists in the market mri ct etc these technologies uses high energy in order to acquire high quality images but high energy can harm human cells this is why we us low energy and with this used we get slightly low quality medical images and here technology intervenes where we can use preprocessing techniques in order to increase image resolution prior to perform diagnosis either by doctor or cad system we present in this paper a computer aided diagnosis system that provides an automated brain tissue segmentation applied on 3d mri images with its four different modalities t1 t1c t2 t2 weighted of brats 2020 challenge dataset by implementing a unet like deep neural network which provides information about classification of brain tissue into healthy tissue edema enhancing tumour non enhancing tumour the model achieved an accuracy of 9901 and dice coefficient of 4795 after 35 epochs of trainingkeywordssegmentationdeep learningbrain tumorsmedical image segmentationmedical image analysis",Brain
Acute ischemic stroke lesion segmentation in non-contrast CT images  using 3D convolutional neural networks,https://doi.org/10.48550/arxiv.2301.06793,2023,"in this paper an automatic algorithm aimed at volumetric segmentation of acute ischemic stroke lesion in noncontrast computed tomography brain 3d images is proposed our deeplearning approach is based on the popular 3d unet convolutional neural network architecture which was modified by adding the squeezeandexcitation blocks and residual connections robust preprocessing methods were implemented to improve the segmentation accuracy moreover a specific patches sampling strategy was used to address the large size of medical images to smooth out the effect of the class imbalance problem and to stabilize neural network training all experiments were performed using fivefold crossvalidation on the dataset containing noncontrast computed tomography volumetric brain scans of 81 patients diagnosed with acute ischemic stroke two radiology experts manually segmented images independently and then verified the labeling results for inconsistencies the quantitative results of the proposed algorithm and obtained segmentation were measured by the dice similarity coefficient sensitivity specificity and precision metrics our proposed model achieves an average dice of 0628pm0033 sensitivity of 0699pm0039 specificity of 09965pm00016 and precision of 0619pm0036 showing promising segmentation results",Brain
Automated Brain Tumor Segmentation for MR Brain Images using Artificial Bee Colony Combined with Interval Type-II Fuzzy Technique,https://doi.org/10.1109/tii.2023.3244344,2023,"accurate prediction of brain tumors is vital while getting to the forum of medical image analysis where precision in decisionmaking is of paramount importance and the problems are to be addressed forthwith for over a decade innumerable medical imaging techniques using artificial intelligence and machine learning have been promulgated the present research is intended to develop an algorithm that forges the working principles of the artificial bee colony abc and interval typeii fuzzy logic system it2fls algorithm to delineate the tumor region which has been encompassed by complex brain tissues the crux of any therapeutic sequences to be accomplished lies in the decisiveness of the oncologists where the algorithm presented in this study significantly leverages decisionmaking through technological intervention the algorithm proposed has versatility in handling a wide range of image sequences available in the brats challenge datasets 2015 2017 and 2018 that have various levels of barriers setbacks and hardships in identifying the aberrant regions and it provides better segmentation outcomes that have been qualitatively validated and justified with metrics such as doi specificity and sensitivity augmentation of the visual perception for oncologists is the insignia of this study which in turn provides better insight and understanding regarding the ailment of the patient",Brain
Automated Brain Tumor Segmentation for MR Brain Images using Artificial Bee Colony Combined with Interval Type-II Fuzzy Technique,https://doi.org/10.1109/tii.2023.3244344,2023,"accurate prediction of brain tumors is vital while getting to the forum of medical image analysis where precision in decisionmaking is of paramount importance and the problems are to be addressed forthwith for over a decade innumerable medical imaging techniques using artificial intelligence and machine learning have been promulgated the present research is intended to develop an algorithm that forges the working principles of the artificial bee colony abc and interval typeii fuzzy logic system it2fls algorithm to delineate the tumor region which has been encompassed by complex brain tissues the crux of any therapeutic sequences to be accomplished lies in the decisiveness of the oncologists where the algorithm presented in this study significantly leverages decisionmaking through technological intervention the algorithm proposed has versatility in handling a wide range of image sequences available in the brats challenge datasets 2015 2017 and 2018 that have various levels of barriers setbacks and hardships in identifying the aberrant regions and it provides better segmentation outcomes that have been qualitatively validated and justified with metrics such as doi specificity and sensitivity augmentation of the visual perception for oncologists is the insignia of this study which in turn provides better insight and understanding regarding the ailment of the patient",Brain
PA-Seg: Learning from Point Annotations for 3D Medical Image Segmentation using Contextual Regularization and Cross Knowledge Distillation,https://doi.org/10.1109/tmi.2023.3245068,2023,"the success of convolutional neural networks cnns in 3d medical image segmentation relies on massive fully annotated 3d volumes for training that are timeconsuming and laborintensive to acquire in this paper we propose to annotate a segmentation target with only seven points in 3d medical images and design a twostage weakly supervised learning framework paseg in the first stage we employ geodesic distance transform to expand the seed points to provide more supervision signal to further deal with unannotated image regions during training we propose two contextual regularization strategies ie multiview conditional random field mcrf loss and variance minimization vm loss where the first one encourages pixels with similar features to have consistent labels and the second one minimizes the intensity variance for the segmented foreground and background respectively in the second stage we use predictions obtained by the model pretrained in the first stage as pseudo labels to overcome noises in the pseudo labels we introduce a self and cross monitoring scm strategy which combines selftraining with cross knowledge distillation ckd between a primary model and an auxiliary model that learn from soft labels generated by each other experiments on public datasets for vestibular schwannoma vs segmentation and brain tumor segmentation brats demonstrated that our model trained in the first stage outperformed existing stateoftheart weakly supervised approaches by a large margin and after using scm for additional training the models performance was close to its fully supervised counterpart on the brats dataset",Brain
PA-Seg: Learning from Point Annotations for 3D Medical Image Segmentation using Contextual Regularization and Cross Knowledge Distillation,https://doi.org/10.1109/tmi.2023.3245068,2023,"the success of convolutional neural networks cnns in 3d medical image segmentation relies on massive fully annotated 3d volumes for training that are timeconsuming and laborintensive to acquire in this paper we propose to annotate a segmentation target with only seven points in 3d medical images and design a twostage weakly supervised learning framework paseg in the first stage we employ geodesic distance transform to expand the seed points to provide more supervision signal to further deal with unannotated image regions during training we propose two contextual regularization strategies ie multiview conditional random field mcrf loss and variance minimization vm loss where the first one encourages pixels with similar features to have consistent labels and the second one minimizes the intensity variance for the segmented foreground and background respectively in the second stage we use predictions obtained by the model pretrained in the first stage as pseudo labels to overcome noises in the pseudo labels we introduce a self and cross monitoring scm strategy which combines selftraining with cross knowledge distillation ckd between a primary model and an auxiliary model that learn from soft labels generated by each other experiments on public datasets for vestibular schwannoma vs segmentation and brain tumor segmentation brats demonstrated that our model trained in the first stage outperformed existing stateoftheart weakly supervised approaches by a large margin and after using scm for additional training the models performance was close to its fully supervised counterpart on the brats dataset",Brain
SELDNet: Sequenced encoder and lightweight decoder network for COVID-19 infection region segmentation,https://doi.org/10.1016/j.displa.2023.102395,2023,"segmenting regions of lung infection from computed tomography ct images shows excellent potential for rapid and accurate quantifying of coronavirus disease 2019 covid19 infection and determining disease development and treatment approaches however a number of challenges remain including the complexity of imaging features and their variability with disease progression as well as the high similarity to other lung diseases which makes feature extraction difficult to answer the above challenges we propose a new sequence encoder and lightweight decoder network for medical image segmentation model seldnet i construct sequence encoders and lightweight decoders based on transformer and deep separable convolution respectively to achieve different finegrained feature extraction ii design a semantic association module based on crossattention mechanism between encoder and decoder to enhance the fusion of different levels of semantics the experimental results showed that the network can effectively achieve segmentation of covid19 infected regions the dice of the segmentation result was 791 the sensitivity was 763 and the specificity was 967 compared with several stateoftheart image segmentation models our proposed seldnet model achieves better results in the segmentation task of covid19 infected regions",Lung
Optimizing Xenium In Situ data utility by quality assessment and best practice analysis workflows,https://doi.org/10.1101/2023.02.13.528102,2023,"abstract the xenium in situ platform is a new spatial transcriptomics product commercialized by 10x genomics capable of mapping hundreds of transcripts in situ at a subcellular resolution given the multitude of commercially available spatial transcriptomics technologies recommendations in choice of platform and analysis guidelines are increasingly important herein we explore eight preview xenium datasets of the mouse brain and two of human breast cancer by comparing scalability resolution data quality capacities and limitations with eight other spatially resolved transcriptomics technologies in addition we benchmarked the performance of multiple open source computational tools when applied to xenium datasets in tasks including cell segmentation segmentationfree analysis selection of spatially variable genes and domain identification among others this study serves as the first independent analysis of the performance of xenium and provides bestpractices and recommendations for analysis of such datasets",Brain
Novel Light Convolutional Neural Network for COVID Detection with Watershed Based Region Growing Segmentation,https://doi.org/10.3390/jimaging9020042,2023,"a rapidly spreading epidemic covid19 had a serious effect on millions and took many lives therefore for individuals with covid19 early discovery is essential for halting the infections progress to quickly and accurately diagnose covid19 imaging modalities including computed tomography ct scans and chest xray radiographs are frequently employed the potential of artificial intelligence ai approaches further explored the creation of automated and precise covid19 detection systems scientists widely use deep learning techniques to identify coronavirus infection in lung imaging in our paper we developed a novel light cnn model architecture with watershedbased regiongrowing segmentation on chest xrays both ct scans and xray radiographs were employed along with 5fold crossvalidation compared to earlier stateoftheart models our model is lighter and outperformed the previous methods by achieving a mean accuracy of 988 on xray images and 986 on ct scans predicting the rate of 099 and 097 for ppv positive predicted value and npv negative predicted value rate of 098 and 099 respectively",Lung
Automated Quantification of Pneumonia Infected Volume in Lung CT Images: A Comparison With Subjective Assessment of Radiologists,https://doi.org/10.20944/preprints202302.0198.v1,2023,"assessment of the percentage of disease infected lung volume using computed tomography ct images can play an important role to detect lung diseases and predict disease severity however manual segmentation of disease infected regions from many ct image slices is tedious and not feasible in clinical practice to help solve this clinical challenge this study aims to investigate a new strategy to automatically segment disease infected regions and predict disease severity we employed a public dataset acquired from 20 covid19 patients which includes manually annotated lung and infections masks to train a new ensembled deep learning dl model that combines the five customized residual attention unet models to segment disease infected regions followed by a feature pyramid network fpn model to classify severity stage of covid19 infection to test potentially clinical utility of new model we first gathered and processed another set of ct images acquired from 80 covid19 patients next we asked two chest radiologists to read ct images of each patient and report the estimated percentage of infected lung volume and disease severity level additionally we asked radiologists to rate acceptance of dl modelgenerated segmentation results using a 5scale rating method data analysis results show that agreement between disease severity classification is ampampgt90 in 45 testing cases furthermore ampampgt73 of cases received the high rating score from two radiologists scored more than 4 this study demonstrates feasibility of developing a new dlmodel to efficiently provide quantitative assessment of disease severity based on the automated segmentation of the disease infected regions to support improving efficacy of radiologists in disease diagnosis",Lung
Performance of HMRF-Based Unsupervised Segmentation and Random Walk Segmentation Algorithms for Gallbladder MRI,https://doi.org/10.1007/978-981-19-7982-8_7,2023,"abstractthis article represents performance of segmentation algorithm of an unsupervised image based on hidden markov random field hmrf model and random walk segmentation algorithms for gallbladder mri detection of lesions in human brain is an important task aimed at saving precious lives the novelty of the method of segmentation is the use of random walk algorithm together with entropy maximization we employ entropy maximization to automatically identify the seed points that are to be used in random walk algorithm detected early diseases can be healed by eliminating slices of human organs specific symptoms of the disease are missing and the cancer remains undetected until it has spread to all the organs hidden markov random field model is used to segment gallbladder lesions expert medical opinion is required to determine whether the lesions have cancer here we analysis the performance of both the algorithm hmrfbased unsupervised segmentation and random walk segmentationkeywordsentropy maximizationrandom walkwavelet mutationprecisionrecallhidden markov random field model",Brain
Mangrove forest identification using object-based approach classification,https://doi.org/10.1063/5.0114997,2023,"as an essential indicator of coastal ecosystem mangrove forest has unique characteristics making it different from terrestrial vegetation mangrove forest identification is essential to support the inventory and monitoring of mangrove diversity this study was aimed to identify 1 the characteristics of mangrove and nonmangrove objects based on image classification 2 mangrove forest mapping from remote sensing imagery and 3 accuracy assessment this study applied a geographic objectbased image analysis geobia approach for highresolution imagery of worldview2 2 m at clungup mangrove conservation cmc malang regency east java indonesia ruleset for mangrove object detection was built from the segmentation of the algorithm and image classification a multiresolution segmentation algorithm in worldview2 was applied to make a segmented object all multispectral bands of worldview2 and some vegetation indexes were used as input variables for the segmentation and classification object in the classification process a threshold for a particular variable representing a significant object difference was used this process resulted in two classes which are identified as mangrove and nonmangrove the results showed that the use of the geobia method for highresolution imagery has the potential to identify and plot a mangrove forest with high accuracy of up to 90 this study contributes to the development of an objectbased approach using remote sensing imagery and is very potential to be applied in a more detailed mapping",Lung
Multi-class Brain Tumor Segmentation using Graph Attention Network,https://doi.org/10.48550/arxiv.2302.05598,2023,"brain tumor segmentation from magnetic resonance imaging mri plays an important role in diagnostic radiology to overcome the practical issues in manual approaches there is a huge demand for building automatic tumor segmentation algorithms this work introduces an efficient brain tumor summation model by exploiting the advancement in mri and graph neural networks gnns the model represents the volumetric mri as a region adjacency graph rag and learns to identify the type of tumors through a graph attention network gat a variant of gnns the ablation analysis conducted on two benchmark datasets proves that the proposed model can produce competitive results compared to the leadingedge solutions it achieves mean dice scores of 091 086 079 and mean hausdorff distances in the 95th percentile hd95 of 591 608 and 952 mm respectively for whole tumor core tumor and enhancing tumor segmentation on brats2021 validation dataset on average these performances are 6 and 50 compared to a gnnbased baseline model respectively on dice score and hd95 evaluation metrics",Brain
Multi-class Brain Tumor Segmentation using Graph Attention Network,https://doi.org/10.48550/arxiv.2302.05598,2023,"brain tumor segmentation from magnetic resonance imaging mri plays an important role in diagnostic radiology to overcome the practical issues in manual approaches there is a huge demand for building automatic tumor segmentation algorithms this work introduces an efficient brain tumor summation model by exploiting the advancement in mri and graph neural networks gnns the model represents the volumetric mri as a region adjacency graph rag and learns to identify the type of tumors through a graph attention network gat a variant of gnns the ablation analysis conducted on two benchmark datasets proves that the proposed model can produce competitive results compared to the leadingedge solutions it achieves mean dice scores of 091 086 079 and mean hausdorff distances in the 95th percentile hd95 of 591 608 and 952 mm respectively for whole tumor core tumor and enhancing tumor segmentation on brats2021 validation dataset on average these performances are 6 and 50 compared to a gnnbased baseline model respectively on dice score and hd95 evaluation metrics",Brain
Between Generating Noise and Generating Images: Noise in the Correct  Frequency Improves the Quality of Synthetic Histopathology Images for Digital  Pathology,https://doi.org/10.48550/arxiv.2302.06549,2023,"artificial intelligence and machine learning techniques have the promise to revolutionize the field of digital pathology however these models demand considerable amounts of data while the availability of unbiased training data is limited synthetic images can augment existing datasets to improve and validate ai algorithms yet controlling the exact distribution of cellular features within them is still challenging one of the solutions is harnessing conditional generative adversarial networks that take a semantic mask as an input rather than a random noise unlike other domains outlining the exact cellular structure of tissues is hard and most of the input masks depict regions of cell types however using polygonbased masks introduce inherent artifacts within the synthetic images due to the mismatch between the polygon size and the singlecell size in this work we show that introducing random singlepixel noise with the appropriate spatial frequency into a polygon semantic mask can dramatically improve the quality of the synthetic images we used our platform to generate synthetic images of immunohistochemistrytreated lung biopsies we test the quality of the images using a threefold validation procedure first we show that adding the appropriate noise frequency yields 87 of the similarity metrics improvement that is obtained by adding the actual singlecell features second we show that the synthetic images pass the turing test finally we show that adding these synthetic images to the train set improves ai performance in terms of pdl1 semantic segmentation performances our work suggests a simple and powerful approach for generating synthetic data on demand to unbias limited datasets to improve the algorithms accuracy and validate their robustness",Lung
Contouring quality assurance methodology based on multiple geometric features against deep learning auto‐segmentation,https://doi.org/10.1002/mp.16299,2023,"contouring error is one of the top failure modes in radiation treatment multiple efforts have been made to develop tools to automatically detect segmentation errors deep learningbased autosegmentation dlas has been used as a baseline for flagging manual segmentation errors but those efforts are limited to using only one or two contour comparison metricsthe purpose of this research is to develop an improved contouring quality assurance system to identify and flag manual contouring errorsdlas contours were used as a reference to compare with manually segmented contours a total of 27 geometric agreement metrics were determined from the comparisons between the two segmentation approaches feature selection was performed to optimize the training of a machine learning classification model to identify potential contouring errors a public dataset with 339 cases was used to train and test the classifier four independent classifiers were trained using fivefold cross validation and the predictions from each classifier were ensembled using soft voting the trained model was validated on a heldout testing dataset an additional independent clinical dataset with 60 cases was used to test the generalizability of the model model predictions were reviewed by an expert to confirm or reject the findingsthe proposed machine learning multiple features mlmf approach outperformed traditional nonmachinelearningbased approaches that are based on only one or two geometric agreement metrics the machine learning model achieved recall precision values of 0842 0899 0762 0762 0727 0842 and 0773 0773 for brainstem parotidl parotidr and mandible contours respectively compared to 0526 0909 0619 0765 0682 0882 0773 0568 for an approach based solely on dice similarity coefficient values in the external validation dataset 667 933 941 and 588 of flagged cases were confirmed to have contouring errors by an expert for brainstem parotidl parotidr and mandible contours respectivelythe proposed mlmf approach which includes multiple geometric agreement metrics to flag manual contouring errors demonstrated superior performance in comparison to traditional methods this method is easy to implement in clinical practice and can help to reduce the significant time and labor costs associated with manual segmentation and review",Brain
Does image resolution impact chest X-ray based fine-grained Tuberculosis-consistent lesion segmentation?,None,2023,"deep learning dl models are stateoftheart in segmenting anatomical and disease regions of interest rois in medical images particularly a large number of dlbased techniques have been reported using chest xrays cxrs however these models are reportedly trained on reduced image resolutions for reasons related to the lack of computational resources literature is sparse in discussing the optimal image resolution to train these models for segmenting the tuberculosis tbconsistent lesions in cxrs in this study we investigated the performance variations using an inceptionv3 unet model using various image resolutions withwithout lung roi cropping and aspect ratio adjustments and ii identified the optimal image resolution through extensive empirical evaluations to improve tbconsistent lesion segmentation performance we used the shenzhen cxr dataset for the study which includes 326 normal patients and 336 tb patients we proposed a combinatorial approach consisting of storing model snapshots optimizing segmentation threshold and testtime augmentation tta and averaging the snapshot predictions to further improve performance with the optimal resolution our experimental results demonstrate that higher image resolutions are not always necessary however identifying the optimal image resolution is critical to achieving superior performance",Lung
Automatic uncertainty-based quality controlled T1 mapping and ECV analysis from native and post-contrast cardiac T1 mapping images using Bayesian vision transformer,https://doi.org/10.1016/j.media.2023.102773,2023,"deep learningbased methods for cardiac mr segmentation have achieved stateoftheart results however these methods can generate incorrect segmentation results which can lead to wrong clinical decisions in the downstream tasks automatic and accurate analysis of downstream tasks such as myocardial tissue characterization is highly dependent on the quality of the segmentation results therefore it is of paramount importance to use quality control methods to detect the failed segmentations before further analysis in this work we propose a fully automatic uncertaintybased quality control framework for t1 mapping and extracellular volume ecv analysis the framework consists of three parts the first one focuses on segmentation of cardiac structures from a native and postcontrast t1 mapping dataset n295 using a bayesian swin transformerbased unet in the second part we propose a novel uncertaintybased quality control qc to detect inaccurate segmentation results the qc method utilizes imagelevel uncertainty features as input to a random forestbased classifierregressor to determine the quality of the segmentation outputs the experimental results from four different types of segmentation results show that the proposed qc method achieves a mean area under the roc curve auc of 0927 on binary classification and a mean absolute error mae of 0021 on dice score regression significantly outperforming other stateoftheart uncertainty based qc methods the performance gap is notably higher in predicting the segmentation quality from poorperforming models which shows the robustness of our method in detecting failed segmentations after the inaccurate segmentation results are detected and rejected by the qc method in the third part t1 mapping and ecv values are computed automatically to characterize the myocardial tissues of healthy and cardiac pathological cases the native myocardial t1 and ecv values computed from automatic and manual segmentations show an excellent agreement yielding pearson coefficients of 0990 and 0975 on the combined validation and test sets respectively from the results we observe that the automatically computed myocardial t1 and ecv values have the ability to characterize myocardial tissues of healthy and cardiac diseases like myocardial infarction amyloidosis takotsubo syndrome dilated cardiomyopathy and hypertrophic cardiomyopathy",Cardiac
PigSNIPE: Scalable Neuroimaging Processing Engine for Minipig MRI,https://doi.org/10.3390/a16020116,2023,"translation of basic animal research to find effective methods of diagnosing and treating human neurological disorders requires parallel analysis infrastructures small animals such as mice provide exploratory animal disease models however many interventions developed using small animal models fail to translate to human use due to physical or biological differences recently largeanimal minipigs have emerged in neuroscience due to both their brain similarity and economic advantages medical image processing is a crucial part of research as it allows researchers to monitor their experiments and understand disease development by pairing four reinforcement learning models and five deep learning unet segmentation models with existing algorithms we developed pigsnipe a pipeline for the automated handling processing and analyzing of largescale data sets of minipig mr images pigsnipe allows for image registration acpc alignment detection of 19 anatomical landmarks skull stripping brainmask and intracranial volume segmentation dice 098 tissue segmentation dice 082 and caudateputamen brain segmentation dice 08 in under two minutes to the best of our knowledge this is the first automated pipeline tool aimed at large animal images which can significantly reduce the time and resources needed for analyzing minipig neuroimages",Brain
Sooty Tern Optimization Algorithm-Based Deep Learning Model for Diagnosing NSCLC Tumours,https://doi.org/10.3390/s23042147,2023,"lung cancer is one of the most common causes of cancer deaths in the modern world screening of lung nodules is essential for early recognition to facilitate treatment that improves the rate of patient rehabilitation an increase in accuracy during lung cancer detection is vital for sustaining the rate of patient persistence even though several research works have been conducted in this research domain moreover the classical system fails to segment cancer cells of different sizes accurately and with excellent reliability this paper proposes a sooty tern optimization algorithmbased deep learning dl model for diagnosing nonsmall cell lung cancer nsclc tumours with increased accuracy we discuss various algorithms for diagnosing models that adopt the otsu segmentation method to perfectly isolate the lung nodules then the sooty tern optimization algorithm shoa is adopted for partitioning the cancer nodules by defining the best characteristics which aids in improving diagnostic accuracy it further utilizes a local binary pattern lbp for determining appropriate feature retrieval from the lung nodules in addition it adopts cnn and grubased classifiers for identifying whether the lung nodules are malignant or nonmalignant depending on the features retrieved during the diagnosing process the experimental results of this shoaoptimized dnn model achieved an accuracy of 9832 better than the baseline schemes used for comparison",Lung
Automatic Deep Learning-Based Pleural Effusion Segmentation in Lung Ultrasound Images,https://doi.org/10.21203/rs.3.rs-2486425/v1,2023,"abstract pointofcare lung ultrasound lus allows realtime patient scanning to help diagnose pleural effusion pe and plan further investigation and treatment lus typically requires training and experience from the clinician to accurately interpret the images to address this limitation we previously demonstrated a deeplearning model capable of detecting the presence of pe on lus at an accuracy greater than 90 when compared to an experienced lus operator this followup study aimed to develop a deeplearning model to provide segmentations for pe in lus three thousand and fortyone lus images from twenty four patients diagnosed with pe were selected for this study two lus experts provided the ground truth for training by reviewing and segmenting the images the algorithm was then trained using tenfold crossvalidation once training was completed the algorithm segmented a separate subset of patients comparing the segmentations we demonstrated an average dice similarity coefficient dsc of 070 between the algorithm and experts in contrast an average dsc of 061 was observed between the experts in summary we showed that the trained algorithm achieved a comparable average dsc at pe segmentation this represents a promising step toward developing a computational tool for accurately augmenting pe diagnosis and treatment",Lung
Improving the Accuracy of Brain Tumor Identification in Magnetic Resonanceaging using Super-pixel and Fast Primal Dual Algorithm,https://doi.org/10.5829/ije.2023.36.03c.10,2023,"brain tumors are one of the most common causes of death that have been widely investigated by scholars in research areas including care and prevention despite various empirical studies on the brain tumor segmentatin there is still a need for further investigation this fact is more needed in the automatic methods of brain tumors detection in the present study a new method for improving brain tumor segmentation accuracy based on superpixel and fast primal dual pd algorithms has been proposed the proposed method detects brain tumor tissue in flairmri imaging in brats2012 dataset this method detects the primary borders of tumors using a superpixel algorithm and improves brain tumor borders using fast pd in markov random field optimization then postprocessing processes are used to delete white brain areas finally an active contour algorithm was employed to display tumor area different experiments were carried on the proposed method and qualitative and quantitative criteria such as dice similarity measure accuracy and fmeasure were used for evaluation the obtained results showed the efficiency of the proposed method such that in the accuracy and sensitivity of 8659 and 8857 and f1measure 8637 were obtained respectively",Brain
Improving the Accuracy of Brain Tumor Identification in Magnetic Resonanceaging using Super-pixel and Fast Primal Dual Algorithm,https://doi.org/10.5829/ije.2023.36.03c.10,2023,"brain tumors are one of the most common causes of death that have been widely investigated by scholars in research areas including care and prevention despite various empirical studies on the brain tumor segmentatin there is still a need for further investigation this fact is more needed in the automatic methods of brain tumors detection in the present study a new method for improving brain tumor segmentation accuracy based on superpixel and fast primal dual pd algorithms has been proposed the proposed method detects brain tumor tissue in flairmri imaging in brats2012 dataset this method detects the primary borders of tumors using a superpixel algorithm and improves brain tumor borders using fast pd in markov random field optimization then postprocessing processes are used to delete white brain areas finally an active contour algorithm was employed to display tumor area different experiments were carried on the proposed method and qualitative and quantitative criteria such as dice similarity measure accuracy and fmeasure were used for evaluation the obtained results showed the efficiency of the proposed method such that in the accuracy and sensitivity of 8659 and 8857 and f1measure 8637 were obtained respectively",Brain
Cell Segmentation of Histopathological Images of Glioma Using Voronoi Tessellation and Quadtree Representation,https://doi.org/10.1007/978-981-19-7346-8_33,2023,"abstractautomatic cell segmentation is a challenging task in histopathological image analysis which is responsible for examining tissues and cells for diagnosing the severity of cancer in patients cell segmentation is the technique of breaking down a microscopic image area into sections that reflect individual cell occurrences finding the high density of cells and finer edge detection of cells is complicated due to the overlapping regions to overcome this difficulty a novel method of segmenting whole slide images wsi of low grade glioma lgg and high grade glioma hgg using voronoi tessellation of polygon approximation is proposed the suggested approach consistently segments images of distinct cell types growing in dense cultures that were captured using various morphological techniques the edge detection of the cells obtained from voronoi is finer compared to other existing edge detection methods quadtree image representation is implemented using proposed approach which is utilized to calculate the cell count and density estimate of tumor from voronoi tessellation in olog4n the factors gleaned from the histopathological analysis helps the pathologist in finding the densely populated brain tumors cells in wsi and treating the patient accordinglykeywordshistopathologywsiquadtreevoronoigliomalgghgg",Brain
Lowering the computational barrier: Partially Bayesian neural networks for transparency in medical imaging AI,https://doi.org/10.3389/fcomp.2023.1071174,2023,"deep neural networks dnns can provide clinicians with fast and accurate predictions that are highly valuable for highstakes medical decisionmaking such as in brain tumor segmentation and treatment planning however these models largely lack transparency about the uncertainty in their predictions potentially giving clinicians a false sense of reliability that may lead to grave consequences in patient care growing calls for transparent and responsible ai have promoted uncertainty quantification uq to capture and communicate uncertainty in a systematic and principled manner however traditional bayesian uq methods remain prohibitively costly for large milliondimensional tumor segmentation dnns such as the unet in this work we discuss a computationallyefficient uq approach via the partially bayesian neural networks pbnn in pbnn only a single layer strategically selected based on gradientbased sensitivity analysis is targeted for bayesian inference we illustrate the effectiveness of pbnn in capturing the full uncertainty for a 78million parameter unet we also demonstrate how practitioners and model developers can use the pbnns predictions to better understand the models capabilities and behavior",Brain
Diagnosis of Chronic Brain Syndrome Using Deep Learning,https://doi.org/10.22214/ijraset.2023.49110,2023,"abstract brain tumours which grow within the brain or spread from other secondary tumours elsewhere in the body have been one of the top causes of death in both adults and children in recent years patients can benefit from more effective treatment options if cancers are diagnosed early traditional feature extraction approaches concentrate on either lowlevel or highlevel features with some hand crafted features used to bridge the gap by encodingcombining lowlevel and highlevel features a feature extraction framework can be designed to close this gap without employing handcrafted features deep learning is extremely powerful for feature representation because it can completely describe lowlevel and highlevel information while also embedding the feature extraction phase in the selflearning process a computerised technique for locating and segmenting brain tumours could help doctors make faster and more accurate diagnoses in this paper we propose a deep learning model that uses the vgg16 and vgg19 architectures to detect and localise cancers in mribased pictures the transfer learning model was able to learn froma small number of photos and achieve a test accuracy of 92 percent for detection and a mean average precision score of 9014 percent for segmentation",Brain
MSCAF-Net: A General Framework for Camouflaged Object Detection via Learning Multi-Scale Context-Aware Features,https://doi.org/10.1109/tcsvt.2023.3245883,2023,"the aim of camouflaged object detection cod is to find objects that are hidden in their surrounding environment due to the factors like low illumination occlusion small size and high similarity to the background cod is recognized to be a very challenging task in this paper we propose a general cod framework termed as mscafnet focusing on learning multiscale contextaware features to achieve this target we first adopt the improved pyramid vision transformer pvtv2 model as the backbone to extract global contextual information at multiple scales an enhanced receptive field erf module is then designed to refine the features at each scale further a crossscale feature fusion csff module is introduced to achieve sufficient interaction of multiscale information aiming to enrich the scale diversity of extracted features in addition inspired the mechanism of the human visual system a dense interactive decoder did module is devised to output a rough localization map which is used to modulate the fused features obtained in the csff module for more accurate detection the effectiveness of our mscafnet is validated on four benchmark datasets the results show that the proposed method significantly outperforms stateoftheart sota cod models by a large margin besides we also investigate the potential of our mscafnet on some other vision tasks that are highly related to cod such as polyp segmentation covid19 lung infection segmentation transparent object detection and defect detection experimental results demonstrate the high versatility of the proposed mscafnet the source code and results of our method are available at httpsgithubcomyuliu316316mscafcod",Lung
Dense regression activation maps for lesion segmentation in CT scans of COVID-19 patients,https://doi.org/10.1016/j.media.2023.102771,2023,"automatic lesion segmentation on thoracic ct enables rapid quantitative analysis of lung involvement in covid19 infections however obtaining a large amount of voxellevel annotations for training segmentation networks is prohibitively expensive therefore we propose a weaklysupervised segmentation method based on dense regression activation maps drams most weaklysupervised segmentation approaches exploit class activation maps cams to localize objects however because cams were trained for classification they do not align precisely with the object segmentations instead we produce highresolution activation maps using dense features from a segmentation network that was trained to estimate a perlobe lesion percentage in this way the network can exploit knowledge regarding the required lesion volume in addition we propose an attention neural network module to refine drams optimized together with the main regression task we evaluated our algorithm on 90 subjects results show our method achieved 702 dice coefficient substantially outperforming the cambased baseline at 486 we published our source code at httpsgithubcomdiagnijmegenbodyctdram",Lung
Convolutional Neural Network Model to Segment Myocardial Infarction from MRI Images,https://doi.org/10.3991/ijoe.v19i02.36607,2023,"cardiovascular diseases cvds are considered one of the leading causes of death worldwide myocardial infarction mi is one of the deadliest cardiac diseases that require more consideration recently cardiac magnetic resonance imaging mri has been applied as a standard technique for assessing such diseases the segmentation of the left ventricle lv and myocardium from mri images is vital in detecting mi disease at its early stages the automatic segmentation of lv is still challenging due to the complex structures of mri images inhomogeneous lv shape and moving organs around the lv such as the lungs and diaphragm thus this study proposed a convolutional neural network cnn model for lv and myocardium segmentation to detect mi the layers selection and hyperparameters finetuning were applied before the training phase the model showed robust performance based on the evaluation metrics such as accuracy sensitivity specificity dice score coefficient dsc jaccard index and intersection over union iou with values of 086 091 084 081 069 and 083 respectively",Cardiac
Convolutional Neural Network Model to Segment Myocardial Infarction from MRI Images,https://doi.org/10.3991/ijoe.v19i02.36607,2023,"cardiovascular diseases cvds are considered one of the leading causes of death worldwide myocardial infarction mi is one of the deadliest cardiac diseases that require more consideration recently cardiac magnetic resonance imaging mri has been applied as a standard technique for assessing such diseases the segmentation of the left ventricle lv and myocardium from mri images is vital in detecting mi disease at its early stages the automatic segmentation of lv is still challenging due to the complex structures of mri images inhomogeneous lv shape and moving organs around the lv such as the lungs and diaphragm thus this study proposed a convolutional neural network cnn model for lv and myocardium segmentation to detect mi the layers selection and hyperparameters finetuning were applied before the training phase the model showed robust performance based on the evaluation metrics such as accuracy sensitivity specificity dice score coefficient dsc jaccard index and intersection over union iou with values of 086 091 084 081 069 and 083 respectively",Lung
Convolutional Neural Network Model to Segment Myocardial Infarction from MRI Images,https://doi.org/10.3991/ijoe.v19i02.36607,2023,"cardiovascular diseases cvds are considered one of the leading causes of death worldwide myocardial infarction mi is one of the deadliest cardiac diseases that require more consideration recently cardiac magnetic resonance imaging mri has been applied as a standard technique for assessing such diseases the segmentation of the left ventricle lv and myocardium from mri images is vital in detecting mi disease at its early stages the automatic segmentation of lv is still challenging due to the complex structures of mri images inhomogeneous lv shape and moving organs around the lv such as the lungs and diaphragm thus this study proposed a convolutional neural network cnn model for lv and myocardium segmentation to detect mi the layers selection and hyperparameters finetuning were applied before the training phase the model showed robust performance based on the evaluation metrics such as accuracy sensitivity specificity dice score coefficient dsc jaccard index and intersection over union iou with values of 086 091 084 081 069 and 083 respectively",Lung
A <scp>CNN</scp> transfer learning‐based approach for segmentation and classification of brain stroke from <scp>noncontrast CT</scp> images,https://doi.org/10.1002/ima.22864,2023,"imaging is needed in stroke cases in order to understand what the type of stroke ischemic hemorrhagic is to rule out bleeding to determine the infarct area and to plan treatment noncontrast ct is the primary imaging protocol used in the initial evaluation of patients with suspected stroke as apart from studies in the literature this paper proposes novel automated classification and segmentation approaches which are capable of extracting hemorrhage and ischemic lesions infarcts simultaneously from the noncontrasts brain ct images during the treatment of brain stroke patients it is aimed to automate the detection of stroke lesions with a high accuracy rate using the unet model for segmentation in the experiments performed on the real data set a precision value of 9506 is obtained for the classification model for segmentation the iou coefficient values from the experiments are 9201 for hemorrhagic and 8222 for ischemic respectively",Brain
Assessing the Impact of Image Resolution on Deep Learning for TB Lesion Segmentation on Frontal Chest X-rays,https://doi.org/10.3390/diagnostics13040747,2023,"deep learning dl models are stateoftheart in segmenting anatomical and disease regions of interest rois in medical images particularly a large number of dlbased techniques have been reported using chest xrays cxrs however these models are reportedly trained on reduced image resolutions for reasons related to the lack of computational resources literature is sparse in discussing the optimal image resolution to train these models for segmenting the tuberculosis tbconsistent lesions in cxrs in this study we investigated the performance variations with an inceptionv3 unet model using various image resolutions withwithout lung roi cropping and aspect ratio adjustments and identified the optimal image resolution through extensive empirical evaluations to improve tbconsistent lesion segmentation performance we used the shenzhen cxr dataset for the study which includes 326 normal patients and 336 tb patients we proposed a combinatorial approach consisting of storing model snapshots optimizing segmentation threshold and testtime augmentation tta and averaging the snapshot predictions to further improve performance with the optimal resolution our experimental results demonstrate that higher image resolutions are not always necessary however identifying the optimal image resolution is critical to achieving superior performance",Lung
Brain Tumor Detection Using Transfer Learning,https://doi.org/10.46610/josp.2023.v09i01.004,2023,"the main objective of the proposed work is to encounter the most serious condition of brain tumors however if caught early enough a brain tumor can be cured mri scans and ct scans are used to diagnose brain tumors in most cases it is far too difficult to accurately detect a tumors location and size it is often difficult for doctors and patients to comprehend the outcomes this paper targets to frame automated segmentation and classification of brain tumors in this work around 3000 mri images both tumors and nontumors are collected to identify the images with tumors otsus segmentation method is used following this process the feature extraction technique is carried out using the vantage point tree algorithm which employs the modification features of the vp tree algorithm grayscale images and removal of duplicate images to increase accuracy but the present vp tree algorithm is used for color images next otsus segmentation algorithm accuracy is obtained before and after the segmentation using four classification algorithms namely efficient net b0 efficient net v2b0 res net 50 res net 101 and vgg 19 following this severity classification is carried out to categorize the datasets depending on their severity ie grade i grade ii grade iii and grade iv comparing the obtained results the efficientnetb0 and efficientnetv2b0 outperform in terms of accuracy precision and f1 score compared to the other classification algorithms",Brain
Nodule Detection and Prediction of Lung Carcinoma in CT Images: A Relative Study of Enhancement and Segmentation Methods,https://doi.org/10.1007/978-981-19-6631-6_29,2023,"abstractimage enhancement and segmentation plays an indispensable role in the accurate analysis of affected nodules in lung computed tomography ct images computeraided detection or diagnosis has become very crucial in the healthcare system for fast detection of lung cancer the radiologist has a difficult time in correctly identifying the cancerous lung nodules because of the vast number of patients radiologists frequently overlook malignant nodules in imaging many recent studies in the field of automated lung nodule diagnosis have revealed significant improvements in radiologist performance when detecting pulmonary nodules imaging quality must be taken into account this has prompted us to investigate the preprocessing stage of lung ct images which includes a contrast enhancement and segmentation stage in this paper different lung nodule enhancement and segmentation methods are compared the different enhancement methods compared are histogram equalization he contrast limited adaptive histogram equalization clahe image complement ic gamma correction gc and balanced contrast enhancement technique bcet the five different segmentation methods compared are adaptive image thresholding ait flood fill technique fft fast marching method fmm grayscale intensity difference gsid and watershed segmentation wskeywordsimage enhancementsegmentationct imageslung nodule",Lung
Edge-weighted pFISTA-Net for MRI Reconstruction,https://doi.org/10.48550/arxiv.2302.07468,2023,"deep learning based on unrolled algorithm has served as an effective method for accelerated magnetic resonance imaging mri however many methods ignore the direct use of edge information to assist mri reconstruction in this work we present the edgeweighted pfistanet that directly applies the detected edge map to the softthresholding part of pfistanet the softthresholding value of different regions will be adjusted according to the edge map experimental results of a public brain dataset show that the proposed yields reconstructions with lower error and better artifact suppression compared with the stateoftheart deep learningbased methods the edgeweighted pfistanet also shows robustness for different undersampling masks and edge detection operators in addition we extend the edge weighted structure to joint reconstruction and segmentation network and obtain improved reconstruction performance and more accurate segmentation results",Brain
PDRF-Net: a progressive dense residual fusion network for COVID-19 lung CT image segmentation,https://doi.org/10.1007/s12530-023-09489-x,2023,"the lungs of patients with covid19 exhibit distinctive lesion features in chest ct images fast and accurate segmentation of lesion sites from ct images of patients lungs is significant for the diagnosis and monitoring of covid19 patients to this end we propose a progressive dense residual fusion network named pdrfnet for covid19 lung ct segmentation dense skip connections are introduced to capture multilevel contextual information and compensate for the feature loss problem in network delivery the efficient aggregated residual module is designed for the encodingdecoding structure which combines a visual transformer and the residual block to enable the network to extract richer and minutedetail features from ct images furthermore we introduce a bilateral channel pixel weighted module to progressively fuse the feature maps obtained from multiple branches the proposed pdrfnet obtains good segmentation results on two covid19 datasets its segmentation performance is superior to baseline by 116 and 111 and outperforming other comparative mainstream methods thus pdrfnet serves as an easytotrain highperformance deep learning model that can realize effective segmentation of the covid19 lung ct images",Lung
PDRF-Net: a progressive dense residual fusion network for COVID-19 lung CT image segmentation,https://doi.org/10.1007/s12530-023-09489-x,2023,"the lungs of patients with covid19 exhibit distinctive lesion features in chest ct images fast and accurate segmentation of lesion sites from ct images of patients lungs is significant for the diagnosis and monitoring of covid19 patients to this end we propose a progressive dense residual fusion network named pdrfnet for covid19 lung ct segmentation dense skip connections are introduced to capture multilevel contextual information and compensate for the feature loss problem in network delivery the efficient aggregated residual module is designed for the encodingdecoding structure which combines a visual transformer and the residual block to enable the network to extract richer and minutedetail features from ct images furthermore we introduce a bilateral channel pixel weighted module to progressively fuse the feature maps obtained from multiple branches the proposed pdrfnet obtains good segmentation results on two covid19 datasets its segmentation performance is superior to baseline by 116 and 111 and outperforming other comparative mainstream methods thus pdrfnet serves as an easytotrain highperformance deep learning model that can realize effective segmentation of the covid19 lung ct images",Lung
Segmentation of Brain Tissues from MRI Images Using Multitask Fuzzy Clustering Algorithm,https://doi.org/10.1155/2023/4387134,2023,"in recent years brain magnetic resonance imaging mri image segmentation has drawn considerable attention mri image segmentation result provides a basis for medical diagnosis the segmentation result influences the clinical treatment directly nevertheless mri images have shortcomings such as noise and the inhomogeneity of grayscale the performance of traditional segmentation algorithms still needs further improvement in this paper we propose a novel brain mri image segmentation algorithm based on fuzzy cmeans fcm clustering algorithm to improve the segmentation accuracy first we introduce multitask learning strategy into fcm to extract public information among different segmentation tasks it combines the advantages of the two algorithms the algorithm enables to utilize both public information among different tasks and individual information within tasks then we design an adaptive task weight learning mechanism and a weighted multitask fuzzy cmeans wmtfcm clustering algorithm is proposed under the adaptive task weight learning mechanism each task obtains the optimal weight and achieves better clustering performance simulated mri images from mcconnell brainweb have been used to evaluate the proposed algorithm experimental results demonstrate that the proposed method provides more accurate and stable segmentation results than its competitors on the mri images with various noise and intensity inhomogeneity",Brain
State-of-the-Art in Lung Ultrasound Processing - Brief Review,https://doi.org/10.1109/sami58000.2023.10044483,2023,"this paper explains the basic principles of ultrasound and its use in the medical examination mainly in chest ultrasound we provide an overview of methods that address various aspects of classification and semantic segmentation of pathological symptoms in ultrasound videos also we review the availability of the lung ultrasound data for the development of the machine learning models finally we introduce our ongoing research in the field this article serves as a theoretical basis for the introduction to lung ultrasound and the processing of ultrasonography data mainly with convolutional neural networks",Lung
COVID-19 Diagnosis-Based Deep Learning Approaches for COVIDx Dataset: A Preliminary Survey,https://doi.org/10.1201/9781003251903-6,2023,"this chapter presents a comprehensive review of the utilization of deep learning dl approaches to covid19 identification and lung segmentation it also presents a review of articles using dl approaches to classify the enrolled images using covidx dataset this dataset is commonly used recently to classify infected or normal patients in supervised learning convolutional neural networks and recurrent neural networks are preferred to achieve precise diagnosis and classification in real time for medical images abbasi et al 29 proposed an independent covid19 diagnosis and severity prediction method which uses deep feature maps from chest xray cxr imaging to diagnose covid19 and predict its severity the results of covid19 image retrieval and diagnosis tasks show that the proposed model can serve as a robust solution for cxr analysis the availability of a large public database is one of the problems in developing a reliable and accurate covid19 diagnosis system",Lung
Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement,https://doi.org/10.1007/978-3-031-25066-8_17,2023,"abstracta stroke occurs when an artery in the brain ruptures and bleeds or when the blood supply to the brain is cut off blood and oxygen cannot reach the brains tissues due to the rupture or obstruction resulting in tissue death the middle cerebral artery mca is the largest cerebral artery and the most commonly damaged vessel in stroke the quick onset of a focused neurological deficit caused by interruption of blood flow in the territory supplied by the mca is known as an mca stroke alberta stroke programme early ct score aspects is used to estimate the extent of early ischemic changes in patients with mca stroke this study proposes a deep learningbased method to score the ct scan for aspects our work has three highlights first we propose a novel method for medical image segmentation for stroke detection second we show the effectiveness of ai solution for fullyautomated aspect scoring with reduced diagnosis time for a given noncontrast ct ncct scan our algorithms show a dice similarity coefficient of 064 for the mca anatomy segmentation and 072 for the infarcts segmentation lastly we show that our models performance is inline with interreader variability between radiologistskeywordsstrokeinfarctautomated aspects scoring frameworksegmentation",Brain
Neural Registration and Segmentation of White Matter Tracts in Multi-modal Brain MRI,https://doi.org/10.1007/978-3-031-25066-8_12,2023,"abstractpresurgical mapping of white matter wm tracts requires specific neuroanatomical knowledge and a significant amount of time currently presurgical tractography workflows rely on classical registration tools that prospectively align the multiple brain mri modalities required for the task brain lesions and patient motion may challenge the robustness and accuracy of these tool eventually requiring additional manual intervention we present a novel neural workflow for 3d registration and segmentation of wm tracts in multiple brain mri sequences the method is applied to pairs of t1weighted t1w and directionally encoded color dec maps validation is provided on two different datasets the human connectome project hcp dataset and a real presurgical dataset the proposed method outperforms the stateoftheart tractseg and agynet algorithms on both datasets quantitatively and qualitatively suggesting its applicability to automatic wm tract mapping in neurosurgical mrikeywordsconvolutional neural networkstractographyregistrationmultimodal segmentationbrain mrineurosurgical planning",Brain
Contour Dice Loss for Structures with Fuzzy and Complex Boundaries in Fetal MRI,https://doi.org/10.1007/978-3-031-25066-8_19,2023,"abstractvolumetric measurements of fetal structures in mri are time consuming and error prone and therefore require automatic segmentation placenta segmentation and accurate fetal brain segmentation for gyrification assessment are particularly challenging because of the placenta fuzzy boundaries and the fetal brain cortex complex foldings in this paper we study the use of the contour dice loss for both problems and compare it to other boundary losses and to the combined dice and crossentropy loss the loss is computed efficiently for each slice via erosion dilation and xor operators we describe a new formulation of the loss akin to the contour dice metric the combination of the dice loss and the contour dice yielded the best performance for placenta segmentation for fetal brain segmentation the best performing loss was the combined dice with crossentropy loss followed by the dice with contour dice loss which performed better than other boundary losseskeywordsdeep learning segmentationfetal mrisegmentation contour",Brain
ExSwin-Unet: An Unbalanced Weighted Unet with Shifted Window and External Attentions for Fetal Brain MRI Image Segmentation,https://doi.org/10.1007/978-3-031-25066-8_18,2023,"abstractaccurate fetal brain mri image segmentation is essential for fetal disease diagnosis and treatment while manual segmentation is laborious timeconsuming and errorprone automated segmentation is a challenging task owing to 1 the variations in shape and size of brain structures among patients 2 the subtle changes caused by congenital diseases and 3 the complicated anatomy of brain it is critical to effectively capture the longrange dependencies and correlations among training samples to yield satisfactory results recently some transformerbased models have been proposed and achieved good performance in segmentation tasks however the selfattention blocks embedded in transformers often neglect the latent relationships among different samples model may have biased results due to the unbalanced data distribution in the training dataset we propose a novel unbalanced weighted unet equipped with a new exswin transformer block to comprehensively address the above concerns by effectively capturing longrange dependencies and correlations among different samples we design a deeper encoder to facilitate features extracting and preserving more semantic details in addition an adaptive weight adjusting method is implemented to dynamically adjust the loss weight of different classes to optimize learning direction and extract more features from underlearning classes extensive experiments on a feta dataset demonstrate the effectiveness of our model achieving better results than stateoftheart approacheskeywordsfetal brain mri imagestransformermedical image segmentation",Brain
Unsupervised Domain Adaptation for MRI Volume Segmentation and  Classification Using Image-to-Image Translation,https://doi.org/10.48550/arxiv.2302.08016,2023,"unsupervised domain adaptation is a type of domain adaptation and exploits labeled data from the source domain and unlabeled data from the target one in the crossmodality domain adaptation for medical image segmentation challenge crossmoda2022 contrast enhanced t1 mri volumes for brain are provided as the source domain data and highresolution t2 mri volumes are provided as the target domain data the crossmoda2022 challenge contains two tasks segmentation of vestibular schwannoma vs and cochlea and classification of vs with koos grade in this report we presented our solution for the crossmoda2022 challenge we employ an imagetoimage translation method for unsupervised domain adaptation and residual unet the segmentation task we use svm for the classification task the experimental results show that the mean dsc and assd are 0614 and 2936 for the segmentation task and mamae is 084 for the classification task",Brain
FriendlyClearMap: An optimized toolkit for mouse brain mapping and analysis,https://doi.org/10.1101/2023.02.16.528882,2023,"abstract tissue clearing is currently revolutionizing neuroanatomy by enabling organlevel imaging with cellular resolution however currently available tools for data analysis require a significant time investment for training and adaptation to each laboratorys use case which limits productivity here we present friendlyclearmap an integrated toolset that makes clearmap1 and clearmap2s cellmap pipeline easier to use extends its functions and provides docker images from which it can be run with minimal time investment we also provide detailed tutorials for each step of the pipeline for more precise alignment we add a landmarkbased atlas registration to clearmaps functions as well as include young mouse reference atlases for developmental studies we provide alternative cell segmentation method besides clearmaps thresholdbased approach ilastiks pixel classification importing segmentations from commercial image analysis packages and even manual annotations finally we integrate brainrender a recently released visualization tool for advanced 3d visualization of the annotated cells as a proofofprinciple we use friendlyclearmap to quantify the distribution of the three main gabaergic interneuron subclasses parvalbumin somatostatin and vip in the mouse fore and midbrain for pv neurons we provide an additional dataset with adolescent vs adult pv neuron density showcasing the use for developmental studies when combined with the analysis pipeline outlined above our toolkit improves on the stateoftheart packages by extending their function and making them easier to deploy at scale",Brain
Deep Structural Causal Shape Models,https://doi.org/10.1007/978-3-031-25075-0_28,2023,"abstractcausal reasoning provides a language to ask important interventional and counterfactual questions beyond purely statistical association in medical imaging for example we may want to study the causal effect of genetic environmental or lifestyle factors on the normal and pathological variation of anatomical phenotypes however while anatomical shape models of 3d surface meshes extracted from automated image segmentation can be reliably constructed there is a lack of computational tooling to enable causal reasoning about morphological variations to tackle this problem we propose deep structural causal shape models csms which utilise highquality mesh generation techniques from geometric deep learning within the expressive framework of deep structural causal models csms enable subjectspecific prognoses through counterfactual mesh generation how would this patients brain structure change if they were ten years older which is in contrast to most current works on purely populationlevel statistical shape modelling we demonstrate the capabilities of csms at all levels of pearls causal hierarchy through a number of qualitative and quantitative experiments leveraging a large dataset of 3d brain structureskeywordscausalitygeometric deep learning3d shape modelscounterfactualsmedical imaging",Brain
An Atrous Convolved Hybrid Seg-Net Model with residual and attention mechanism for gland detection and segmentation in histopathological images,https://doi.org/10.1016/j.compbiomed.2023.106690,2023,"a clinically compatible computerized segmentation model is presented here that aspires to supply clinical gland informative details by seizing every small and intricate variation in medical images integrate second opinions and reduce human errorsit comprises of enhanced learning capability that extracts denser multiscale glandspecific features recover semantic gap during concatenation and effectively handle resolutiondegradation and vanishing gradient problems it is having three proposed modules namely atrous convolved residual learning module in the encoder as well as decoder residual attention module in the skip connection paths and atrous convolved transitional module as the transitional and output layer also preprocessing techniques like patchsampling stainnormalization augmentation etc are employed to develop its generalization capability to verify its robustness and invigorate network invariance against digital variability extensive experiments are carried out employing three different public datasets ie glas gland segmentation challenge crag colorectal adenocarcinoma gland and lc25000 lung colon25000 dataset and a private hosc hospital colon datasetthe presented model accomplished combative gland detection outcomes having f1score glastest a0957 test b0926 crag0935 lc 250000922 hosc0963 and gland segmentation results having objectdice index glastest a0961 test b0933 crag0961 lc250000940 hosc0929 and objecthausdorff distance glastest a2177 and test b6974 crag8763 lc250009585 hosc8329 in addition validation score glas test a0945 test b0937 crag0934 lc250000911 hosc0928 supplied by the proficient pathologists is integrated for the end segmentation results to corroborate the applicability and appropriateness for assistance at the clinical level applicationsthe proposed system will assist pathologists in devising precise diagnoses by offering a referential perspective during morphology assessment of colon histopathology images",Lung
Machine Learning in Lung Cancer Radiomics,https://doi.org/10.1007/s11633-022-1364-x,2023,"lung cancer is the leading cause of cancerrelated deaths worldwide medical imaging technologies such as computed tomography ct and positron emission tomography pet are routinely used for noninvasive lung cancer diagnosis in clinical practice physicians investigate the characteristics of tumors such as the size shape and location from ct and pet images to make decisions recently scientists have proposed various computational image features that can capture more information than that directly perceivable by human eyes which promotes the rise of radiomics radiomics is a research field on the conversion of medical images into highdimensional features with datadriven methods to help subsequent data mining for better clinical decision support radiomic analysis has four major steps image preprocessing tumor segmentation feature extraction and clinical prediction machine learning including the highprofile deep learning facilitates the development and application of radiomic methods various radiomic methods have been proposed recently such as the construction of radiomic signatures tumor habitat analysis cluster pattern characterization and endtoend prediction of tumor properties these methods have been applied in many studies aiming at lung cancer diagnosis treatment and monitoring shedding light on future noninvasive evaluations of the nodule malignancy histological subtypes genomic properties and treatment responses in this review we summarized and categorized the studies on the general workflow methods for clinical prediction and clinical applications of machine learning in lung cancer radiomic studies introduced some commonlyused software tools and discussed the limitations of current methods and possible future directions",Lung
Lung Cancer Detection Using CT Scan Images,https://doi.org/10.1007/978-981-19-6383-4_36,2023,"abstractearly diagnosis and treatment of lung cancer which is a life taking disease can save many human lives doctors use ct scan images to detect the presence of lung cancer in any patient but it is almost impossible for doctors to check every ct scan and accurately predict the presence of cancer cells computer aided detection or diagnosis will be helpful for the accurate identification of cancer cells in the past machine learning and image processing techniques have assisted computer aided detection this work will explore various computerassisted procedures methods identifying the best methodology now in use describing its benefits and limitations hence a new model is proposed which is more effective in terms of accuracy it outperforms existing techniques in this work google colaboratory is used to execute this work it provides free gpu and cpu in order to detect the cancer nodules segmentation is done based on area in order to avoid oversegmentation a markercontrolled watershed algorithm is used in order to deploy segmentation the ct scan is first converted into a grayscale image then noise is removed using gaussian and median filters followed by segmentation further morphological transformations are done to remove white noises features such as area center and radius of the cancer nodules are extracted from the experimental results proposed technique is outperforming in detection of the cancer and stage of the cancerkeywordsgaussian filtermedian filterwatershed algorithmmorphological transformationslung cancer",Lung
Multi-stage stacked temporal convolution neural networks (MS-S-TCNs) for biosignal segmentation and anomaly localization,https://doi.org/10.1016/j.patcog.2023.109440,2023,"in the computer vision domain temporal convolution networks tcn have gained traction due to their lightweight robust architectures for sequencetosequence prediction tasks with that insight in this study we propose a novel deep learning architecture for biosignal segmentation and anomaly localization based on tcns named the multistage stacked tcn which employs multiple tcn modules with varying dilation factors more precisely for each stage our architecture uses tcn modules with multiple dilation factors and we use convolutionbased fusion to combine predictions returned from each stage furthermore aiming smoothed predictions we introduce a novel loss function based on the firstorder derivative to demonstrate the robustness of our architecture we evaluate our model on five different tasks related to three 1d biosignal modalities heart sounds lung sounds and electrocardiogram our proposed framework achieves stateoftheart performance for all tasks significantly outperforming the respective stateoftheart models having f1 score gains up to 9 furthermore the framework demonstrates competitive performance gains compared to traditional multistage tcn models with similar configurations yielding f1 score gains up to 5 our model is also interpretable using neural conductance we demonstrate the effectiveness of having tcns with varying dilation factors our visualizations show that the model benefits from feature maps captured at multiple dilation factors and the information is effectively propagated through the network such that the final stage produces the most accurate result",Lung
Selective Deeply Supervised Multi-Scale Attention Network for Brain Tumor Segmentation,https://doi.org/10.3390/s23042346,2023,"brain tumors are among the deadliest forms of cancer characterized by abnormal proliferation of brain cells while early identification of brain tumors can greatly aid in their therapy the process of manual segmentation performed by expert doctors which is often timeconsuming tedious and prone to human error can act as a bottleneck in the diagnostic process this motivates the development of automated algorithms for brain tumor segmentation however accurately segmenting the enhanced and core tumor regions is complicated due to high levels of inter and intratumor heterogeneity in terms of texture morphology and shape this study proposes a fully automatic method called the selective deeply supervised multiscale attention network sdsmsanet for segmenting brain tumor regions using a multiscale attention network with novel selective deep supervision sds mechanisms for training the method utilizes a 3d input composed of five consecutive slices in addition to a 2d slice to maintain sequential information the proposed multiscale architecture includes two encoding units to extract meaningful global and local features from the 3d and 2d inputs respectively these coarse features are then passed through attention units to filter out redundant information by assigning lower weights the refined features are fed into a decoder block which upscales the features at various levels while learning patterns relevant to all tumor regions the sds block is introduced to immediately upscale features from intermediate layers of the decoder with the aim of producing segmentations of the whole enhanced and core tumor regions the proposed framework was evaluated on the brats2020 dataset and showed improved performance in brain tumor region segmentation particularly in the segmentation of the core and enhancing tumor regions demonstrating the effectiveness of the proposed approach our code is publicly available",Brain
Selective Deeply Supervised Multi-Scale Attention Network for Brain Tumor Segmentation,https://doi.org/10.3390/s23042346,2023,"brain tumors are among the deadliest forms of cancer characterized by abnormal proliferation of brain cells while early identification of brain tumors can greatly aid in their therapy the process of manual segmentation performed by expert doctors which is often timeconsuming tedious and prone to human error can act as a bottleneck in the diagnostic process this motivates the development of automated algorithms for brain tumor segmentation however accurately segmenting the enhanced and core tumor regions is complicated due to high levels of inter and intratumor heterogeneity in terms of texture morphology and shape this study proposes a fully automatic method called the selective deeply supervised multiscale attention network sdsmsanet for segmenting brain tumor regions using a multiscale attention network with novel selective deep supervision sds mechanisms for training the method utilizes a 3d input composed of five consecutive slices in addition to a 2d slice to maintain sequential information the proposed multiscale architecture includes two encoding units to extract meaningful global and local features from the 3d and 2d inputs respectively these coarse features are then passed through attention units to filter out redundant information by assigning lower weights the refined features are fed into a decoder block which upscales the features at various levels while learning patterns relevant to all tumor regions the sds block is introduced to immediately upscale features from intermediate layers of the decoder with the aim of producing segmentations of the whole enhanced and core tumor regions the proposed framework was evaluated on the brats2020 dataset and showed improved performance in brain tumor region segmentation particularly in the segmentation of the core and enhancing tumor regions demonstrating the effectiveness of the proposed approach our code is publicly available",Brain
Efficient Lung Cancer Image Classification and Segmentation Algorithm Based on an Improved Swin Transformer,https://doi.org/10.3390/electronics12041024,2023,"with the advancement of computer technology transformer models have been applied to the field of computer vision cv after their success in natural language processing nlp in todays rapidly evolving medical field radiologists continue to face multiple challenges such as increased workload and increased diagnostic demands the accuracy of traditional lung cancer detection methods still needs to be improved especially in realistic diagnostic scenarios in this study we evaluated the performance of the swin transformer model in the classification and segmentation of lung cancer the results showed that the pretrained swinb model achieved a top1 accuracy of 8226 in the classification mission outperforming vit by 2529 in the segmentation mission the swins model demonstrated improvement over other methods in terms of mean intersection over union miou these results suggest that pretraining can be an effective approach for improving the accuracy of the swin transformer model in these tasks",Lung
LUNG CANCER DETECTION USING MORPHOLOGICAL WATERSHED OPERATIONS,https://doi.org/10.55041/ijsrem17781,2023,"cancer is one of the most serious and widespread disease across the world accounting for a large number of deaths every year lung cancer is the leading cause of cancer deaths in the world having high mortality rate the main problem in lung cancer is that most of these cases are diagnosed at the later stages of cancer making treatments more problematic and reducing the survival chances the survival rate of cancer patients increment from 1449 if the illness is recognized in time early discovery of lung cancer can expand the possibility of survival among individuals a ct scan is more likely to show lung tumors than routine chest xrays as it can show the size shape and position of any lung tumor and can help find enlarged lymph nodes that might contain cancer that has spread visual interpretation of ct scan can be difficult and error prone hence image processing techniques are used to detect the cancer nodules at an early stage this paper deals with an automated approach for early detection of lung cancer this algorithm is proposed using methods such as median filtering for image smoothing contrast adjustment for enhancing the image segmentation using morphological watershed operations and otsus thresholding key words ct median filtering contrast adjustment morphological watershed operations otsu thresholding",Lung
GMetaNet: Multi-scale ghost convolutional neural network with auxiliary MetaFormer decoding path for brain tumor segmentation,https://doi.org/10.1016/j.bspc.2023.104694,2023,"automatic segmentation of brain tumors from multimodal mr images plays an important role in treatment decision and operation planning thus we propose a novel 3d multiscale ghost convolution neural network with auxiliary metaformer decoding path gmetanet by combining the local modeling of cnn and the longrange representation of transformer we can achieve efficient semantic information extraction first based on ghost module three novel modules are proposed namely the lightweight ghost spatial pyramid gsp module the ghost selfattention gsa module and the dense residual ghost drg module second the gsp module learns features under different receptive fields at a low computational cost to improve the multiscale representation the proposed gsa module enables the model to capture longrange dependencies as a local decoder the drg module is used to refine information and avoid degradation moreover a global decoder including metaformer is designed which can achieve the effective aggregation of local and global features finally deep supervision is introduced to ensemble three outputs and improve the convergence experiments are conducted on brats datasets to evaluate the proposed model the dice scores are 901 841 and 820 for whole tumor tumor core and enhancing tumor on the brats 2018 validation set and 902 825 and 784 on the brats 2019 validation set network parameters and flops are 61 m and 692g respectively experimental results show that gmetanet is comparable to the stateoftheart methods in segmentation performance moreover the proposed model has better potential in computational efficiency",Brain
GMetaNet: Multi-scale ghost convolutional neural network with auxiliary MetaFormer decoding path for brain tumor segmentation,https://doi.org/10.1016/j.bspc.2023.104694,2023,"automatic segmentation of brain tumors from multimodal mr images plays an important role in treatment decision and operation planning thus we propose a novel 3d multiscale ghost convolution neural network with auxiliary metaformer decoding path gmetanet by combining the local modeling of cnn and the longrange representation of transformer we can achieve efficient semantic information extraction first based on ghost module three novel modules are proposed namely the lightweight ghost spatial pyramid gsp module the ghost selfattention gsa module and the dense residual ghost drg module second the gsp module learns features under different receptive fields at a low computational cost to improve the multiscale representation the proposed gsa module enables the model to capture longrange dependencies as a local decoder the drg module is used to refine information and avoid degradation moreover a global decoder including metaformer is designed which can achieve the effective aggregation of local and global features finally deep supervision is introduced to ensemble three outputs and improve the convergence experiments are conducted on brats datasets to evaluate the proposed model the dice scores are 901 841 and 820 for whole tumor tumor core and enhancing tumor on the brats 2018 validation set and 902 825 and 784 on the brats 2019 validation set network parameters and flops are 61 m and 692g respectively experimental results show that gmetanet is comparable to the stateoftheart methods in segmentation performance moreover the proposed model has better potential in computational efficiency",Brain
Evaluation of EfficientNet models for COVID-19 detection using lung parenchyma,https://doi.org/10.1007/s00521-023-08344-z,2023,"when the covid19 pandemic broke out in the beginning of 2020 it became crucial to enhance early diagnosis with efficient means to reduce dangers and future spread of the viruses as soon as possible finding effective treatments and lowering mortality rates is now more important than ever scanning with a computer tomography ct scanner is a helpful method for detecting covid19 in this regard the present paper as such is an attempt to contribute to this process by generating an opensource ctbased image dataset this dataset contains the ct scans of lung parenchyma regions of 180 covid19positive and 86 covid19negative patients taken at the bursa yuksek ihtisas training and research hospital the experimental studies show that the modified efficientnetapnish method uses this dataset effectively for diagnostic purposes firstly a smart segmentation mechanism based on the kmeans algorithm is applied to this dataset as a preprocessing stage then performance pretrained models are analyzed using different cnn architectures and with our nish activation function the statistical rates are obtained by the various efficientnet models and the highest detection score is obtained with the efficientnetb4apnish version which provides a 9793 accuracy rate and a 9733 f1score the implications of the proposed method are immense both for presentday applications and future developments",Lung
Optimization of Standard Reference Cerebral Ventricular Volumes Measuring Protocol using Magnetic Resonance Imaging Techniques for Clinical Applications,https://doi.org/10.21203/rs.3.rs-2547159/v1,2023,"abstract introduction cerebral ventricular morphology and morphometric changes in response to some ensuing cerebral pathological processes these changes may be use as an indication to detect pathological processes thus it is imperative to establish a measuring procedure to measure very vital organ dimensions to aid clinal diagnoses and to optimize these procedures for clinical application in addition to establishing baseline data of ventricular volumes to enable research and clinical comparison and adopting an easytouse graphical user interface for the computation of organ dimensions aim the study aimed at establishing standard measuring protocol in addition to baseline reference data using normal magnetic resonance images of the brains and developing a userfriendly graphical user interface for the estimation of ventricular volume for clinical applications methodology a retrospective study design approach was adopted and a convenient sampling technique was used to collect a total of 200 magnetic resonance images and 112 of that met the inclusion criteria were analysed at two imaging facilities in ghana data samples were processed using mevislab mvl dicom image analysis and processing software application tools for segmentation and measurements of the images minitab statistical tool was used for statistical modeling of ventricular volume models and script writing coding was done using python application programme and was also used to design and developed a gui for the ventricular volume calculator results the overall mean age for the study is 54 years and ranged between 2089yrs the overall mean and sd of the ventricular volume calculated in the study was 3360 1207 cm 3 the mean total ventricular volume tvv per each age group that is for 2029 yrs 3039 yrs 4049 yrs 5059 yrs 6069 yrs 7079 yrs and 8089 yrs were 1549 209cm 3 2347 230cm 3 2941 293cm 3 3214 183cm 3 3554 148cm 3 4754 201cm 3 and 5160 366cm 3 respectively regression linear equations modeled per ventricle were as follows for left lateral ventricle volume llvv cm 3 095 189lwt for right lateral ventricle volume rlvv cm 3 241 151lwt for the third ventricle volume 3 rd vv cm 3 081 077lwt and for the fourth ventricle volume 4 th vv cm 3 088 095lwt conclusion optimized standard reference dataset of ventricular volumes and sizes of normal brains are crucial baseline determinants for early detection of cerebral diseases and mathematical modeling and gui holds high prospects in the computation of these organ dimensions in medical imaging",Brain
A convolutional neural network with pixel-wise sparse graph reasoning for COVID-19 lesion segmentation in CT images,https://doi.org/10.1016/j.compbiomed.2023.106698,2023,"the covid19 pandemic has extremely threatened human health and automated algorithms are needed to segment infected regions in the lung using computed tomography ct although several deep convolutional neural networks dcnns have proposed for this purpose their performance on this task is suppressed due to the limited local receptive field and deficient global reasoning ability to address these issues we propose a segmentation network with a novel pixelwise sparse graph reasoning psgr module for the segmentation of covid19 infected regions in ct images the psgr module which is inserted between the encoder and decoder of the network can improve the modeling of global contextual information in the psgr module a graph is first constructed by projecting each pixel on a node based on the features produced by the encoder then we convert the graph into a sparselyconnected one by keeping k strongest connections to each uncertainly segmented pixel finally the global reasoning is performed on the sparselyconnected graph our segmentation network was evaluated on three publicly available datasets and compared with a variety of widelyused segmentation models our results demonstrate that 1 the proposed psgr module can capture the longrange dependencies effectively and 2 the segmentation model equipped with this psgr module can accurately segment covid19 infected regions in ct images and outperform all other competing models",Lung
RSU-Net: U-net based on residual and self-attention mechanism in the segmentation of cardiac magnetic resonance images,https://doi.org/10.1016/j.cmpb.2023.107437,2023,"automated segmentation techniques for cardiac magnetic resonance imaging mri are beneficial for evaluating cardiac functional parameters in clinical diagnosis however due to the characteristics of unclear image boundaries and anisotropic resolution anisotropy produced by cardiac magnetic resonance imaging technology most of the existing methods still have the problems of intraclass uncertainty and interclass uncertainty however due to the irregularity of the anatomical shape of the heart and the inhomogeneity of tissue density the boundaries of its anatomical structures become uncertain and discontinuous therefore fast and accurate segmentation of cardiac tissue remains a challenging problem in medical image processing",Cardiac
Robust machine learning segmentation for large-scale analysis of heterogeneous clinical brain MRI datasets,https://doi.org/10.1073/pnas.2216399120,2023,"every year millions of brain mri scans are acquired in hospitals which is a figure considerably larger than the size of any research dataset therefore the ability to analyze such scans could transform neuroimaging research yet their potential remains untapped since no automated algorithm is robust enough to cope with the high variability in clinical acquisitions mr contrasts resolutions orientations artifacts and subject populations here we present synthseg an ai segmentation suite that enables robust analysis of heterogeneous clinical datasets in addition to wholebrain segmentation synthseg also performs cortical parcellation intracranial volume estimation and automated detection of faulty segmentations mainly caused by scans of very low quality we demonstrate synthseg in seven experiments including an aging study on 14000 scans where it accurately replicates atrophy patterns observed on data of much higher quality synthseg is publicly released as a readytouse tool to unlock the potential of quantitative morphometry",Brain
Comparison of conventional edge detection methods performance in lung segmentation of COVID19 patients,https://doi.org/10.1063/5.0111683,2023,"digital image processing techniques have been widely used in the medical field including in medical image analysis one part of the image processing technique that plays an essential role in medical image analysis is image segmentation this paper will discuss the performance of conventional edge detection which consists of the sobel canny prewitt and robert methods in segmenting the lungs especially covid19 patients based on the conventional edge detection method we conducted a trial of measuring the lung area and the white patches contained therein in addition we compared the area between the lungs of normal patients and the lungs of covid patients the experimental results show that of the four types of conventional edge detection methods used all of them have almost the same performance both in processing time and the results of the calculation of lung area obtained based on the experimental results the conventional edge detection method can be considered for further development",Lung
Comparison of conventional edge detection methods performance in lung segmentation of COVID19 patients,https://doi.org/10.1063/5.0111683,2023,"digital image processing techniques have been widely used in the medical field including in medical image analysis one part of the image processing technique that plays an essential role in medical image analysis is image segmentation this paper will discuss the performance of conventional edge detection which consists of the sobel canny prewitt and robert methods in segmenting the lungs especially covid19 patients based on the conventional edge detection method we conducted a trial of measuring the lung area and the white patches contained therein in addition we compared the area between the lungs of normal patients and the lungs of covid patients the experimental results show that of the four types of conventional edge detection methods used all of them have almost the same performance both in processing time and the results of the calculation of lung area obtained based on the experimental results the conventional edge detection method can be considered for further development",Lung
An anisotropically diffusible fuzzy clustering based image segmentation methodology for intracranial cyst detection,https://doi.org/10.3233/jifs-221947,2023,"an intracranial cyst is an abnormal growth of mass in the brain that affects functioning of the nervous system and so an early detection of the lesion enables to avoid adverse effects the processing unit in the magnetic resonance imaging mri system performs reading the images followed by primary image enhancement to suppress distortions thereby enhancing the feature quality in terms of its intensity augmenting the resolution by image segmentation postprocessing by thresholding based on grayscale values and performing several morphological operations with the existing methodologies extracting the region of interest roi with the overlapping intensity values lead to inaccurate results a novel method in which the input image that is anisotropically diffused and blurred is converted into a sharp image further fuzzy partitioning of pixels deployed on global thresholding clustering methodology gtcm based segmentation takes 4 clusters into account hence forth seperating the exterior portion of the skull the border region of the skull the ventricles which may include the lesion and the noise statistical results based on several metrics such as sensitivity specificity f measure jaccord index dice coefficient and precision show that the proposed method is far more effective an accuracy of 9926 is obtained in exactly locating and extracting the lesion along with its attributes",Brain
Alzheimer Disease Classification through Transfer Learning Approach,https://doi.org/10.3390/diagnostics13040801,2023,"alzheimers disease ad is a slow neurological disorder that destroys the thought process and consciousness of a human it directly affects the development of mental ability and neurocognitive functionality the number of patients with alzheimers disease is increasing day by day especially in old aged people who are above 60 years of age and gradually it becomes cause of their death in this research we discuss the segmentation and classification of the magnetic resonance imaging mri of alzheimers disease through the concept of transfer learning and customizing of the convolutional neural network cnn by specifically using images that are segmented by the gray matter gm of the brain instead of training and computing the proposed model accuracy from the start we used a pretrained deep learning model as our base model and after that transfer learning was applied the accuracy of the proposed model was tested over a different number of epochs 10 25 and 50 the overall accuracy of the proposed model was 9784",Brain
Prostate Ultrasound Image Segmentation Based on DSU-Net,https://doi.org/10.3390/biomedicines11030646,2023,"in recent years the incidence of prostate cancer in the male population has been increasing year by year transrectal ultrasound trus is an important means of prostate cancer diagnosis the accurate segmentation of the prostate in trus images can assist doctors in needle biopsy and surgery and is also the basis for the accurate identification of prostate cancer due to the asymmetric shape and blurred boundary line of the prostate in trus images it is difficult to obtain accurate segmentation results with existing segmentation methods therefore a prostate segmentation method called dsunet is proposed in this paper this proposed method replaces the basic convolution in the unet model with the improved convolution combining shear transformation and deformable convolution making the network more sensitive to border features and more suitable for prostate segmentation tasks experiments show that dsunet has higher accuracy than other existing traditional segmentation methods",Prostate
CUTS: A Fully Unsupervised Framework for Medical Image Segmentation,https://doi.org/10.21203/rs.3.rs-2535268/v1,2023,"abstract in this work we introduce cuts contrastive and unsupervised training for segmentation the first fully unsupervised deep learning framework for medical image segmentation to better utilize the vast majority of imaging data that is not labeled or annotated segmenting medical images into regions of interest is a critical task for facilitating both patient diagnoses and quantitative research a major limiting factor is the lack of labeled data as obtaining expert annotations for each new set of imaging data or task can be expensive labor intensive and inconsistent across annotators thus we utilize selfsupervision from pixels and their local neighborhoods in the images themselves our unsupervised approach optimizes a training objective that leverages concepts from contrastive learning and autoencoding previous contrastive learning approaches either focused on imagelevel contrastive training and therefore lacked sufficient patchlevel information necessary for segmentation or framed themselves as pretraining steps that require further supervised finetuning in contrast our framework segments medical images with a novel twostage approach without relying on any labeled data at any stage the first stage involves the creation of a pixelcentered patch that embeds every pixel along with its surrounding patch using a vector representation in a highdimensional latent embedding space the second stage utilizes diffusion condensation a multiscale topological data analysis approach to dynamically coarsegrain these embedding vectors at all levels of granularity the final outcome is a series of coarsetofine segmentations that highlight image structures at various scales in this work we show successful multiscale segmentation on natural images retinal fundus images and brain mri images our framework delineates structures and patterns at different scales which in the cases of medical images may carry distinct information relevant to clinical interpretation quantitatively our framework demonstrates beyond 100 improvement on dice coefficient and hausdorff distance compared to existing unsupervised methods on geographic atrophy segmentation in retinal fundus images when segmenting ventricles in the brain mri images our framework outperforms existing unsupervised methods by a factor between 2 to 300 on dice coefficient and between 14 and 77 on hausdorff distance as we tackle the problem of segmenting medical images at multiple meaningful granularities without relying on any label we hope to demonstrate the possibility to circumvent tedious and repetitive manual annotations in future practice",Brain
iU-Net: a hybrid structured network with a novel feature fusion approach for medical image segmentation,https://doi.org/10.1186/s13040-023-00320-6,2023,"abstract in recent years convolutional neural networks cnns have made great achievements in the field of medical image segmentation especially full convolutional neural networks based on ushaped structures and skip connections however limited by the inherent limitations of convolution cnnsbased methods usually exhibit limitations in modeling longrange dependencies and are unable to extract large amounts of global contextual information which deprives neural networks of the ability to adapt to different visual modalities in this paper we propose our own model which is called iunet bacause its structure closely resembles the combination of i and u iunet is a multiple encoderdecoder structure combining swin transformer and cnn we use a hierarchical swin transformer structure with shifted windows as the primary encoder and convolution as the secondary encoder to complement the context information extracted by the primary encoder to sufficiently fuse the feature information extracted from multiple encoders we design a feature fusion module wffm based on wave function representation besides a three branch up sampling methodtriupsample has developed to replace the patch expand in the swin transformer which can effectively avoid the checkerboard artifacts caused by the patch expand on the skin lesion region segmentation task the segmentation performance of iunet is optimal with dice and iou reaching 9012 and 8306 respectively to verify the generalization of iunet we used the model trained on isic2018 dataset to test on ph2 dataset and achieved 9380 dice and 8874 iou on the lung feild segmentation task the iunet achieved optimal results on iou and precision reaching 9854 and 9435 respectively extensive experiments demonstrate the segmentation performance and generalization ability of iunet",Lung
A Bibliography of Multiple Sclerosis Lesions Detection Methods using  Brain MRIs,https://doi.org/10.48550/arxiv.2302.09516,2023,"introduction multiple sclerosis ms is a chronic disease that affects millions of people across the globe ms can critically affect different organs of the central nervous system such as the eyes the spinal cord and the brain background to help physicians in diagnosing ms lesions computeraided methods are widely used in this regard a considerable research has been carried out in the area of automatic detection and segmentation of ms lesions in magnetic resonance images mris methodology in this study we review the different approaches that have been used in computeraided detection and segmentation of ms lesions our review resulted in categorizing ms lesion segmentation approaches into six broad categories datadriven statistical supervised machine learning unsupervised machine learning fuzzy and deep learningbased techniques we critically analyze the different techniques under these approaches and highlight their strengths and weaknesses results from the study we observe that a considerable amount of work around 25 of related literature is focused on statisticalbased ms lesion segmentation techniques followed by 2115 for datadriven based methods 1923 for deep learning and 1538 for supervised methods implication the study points out the challengesgaps to be addressed in future research the study shows the work which has been done in last one decade in detection and segmentation of ms lesions the results show that in recent years deep learning methods are outperforming all the others methods",Brain
Evaluation of eight registration algorithms applied to the insula and insular gyri,https://doi.org/10.1111/jon.13091,2023,"spatial registration is crucial in establishing correspondence between anatomic brain regions for research and clinical purposes the insular cortex ic and gyri ig are implicated in various functions and pathologies including epilepsy optimizing registration of the insula to a common atlas can improve the accuracy of grouplevel analyses here we compared six nonlinear one linear and one semiautomated registration algorithms ras for registering the ic and ig to the montreal neurologic institute standard space mni1523t images acquired from 20 controls and 20 temporal lobe epilepsy patients with mesial temporal sclerosis underwent automated segmentation of the insula this was followed by manual segmentation of the entire ic and six individual igs consensus segmentations were created at 75 agreement for ic and ig before undergoing registration to mni152 space with eight ras dice similarity coefficients dscs were calculated between segmentations after registration and the ic and ig in mni152 space statistical analysis involved the kruskalwallace test with dunns test for ic and twoway analysis of variance with tukeys honest significant difference test for igdscs were significantly different between ras based on multiple pairwise comparisons we report that certain ras performed better than others across population groups additionally registration performance differed according to specific igwe compared different methods for registering the ic and ig to mni152 space we found differences in performance between ras which suggests that algorithm choice is important factor in analyses involving the insula",Brain
GEOMETRICAL FEATURE OF LUNG LESION IDENTIFICATION USING COMPUTED TOMOGRAPHY SCAN IMAGES,https://doi.org/10.11113/jurnalteknologi.v85.18828,2023,"lung lesion identification is an important aspect of an early lung cancer diagnosis early identification of lung cancer may assist physicians in treating patients this paper uses computed tomography scan images to present a lung lesion identification geometrical feature from the previous studies lung segmentation is particularly challenging because differences in pulmonary inflation with an elastic chest wall can result in significant variability in volumes and margins when attempting to automate lung segmentation besides the features used to describe a lung lesion focus on image features which are geometric appearance texture and others this study develops an image processing technique that uses image segmentation algorithms to segment lung lesions in computed tomography images the suggested approach includes the following stages which require image processing techniques data collection image segmentation and performance evaluation the computed tomography scan images were collected from advanced medical and dental institute amdi universiti sains malaysia database as a contribution to biomedical engineering this study has successfully calculated the performance of the image processing method for lung segmentation which gets an average accuracy of 9938 recall is 9945 and fscore is 996 the lung lesion segmentation approach based on the objects size could help investigate image abnormality for medical analysis from the study 80 of the total lesion identification using the proposed method was correctly predicted when compared with the radiologists lesion mark the experiment results found clear support for the next stage of this research",Lung
Multi-Modal Remote Sensing Image Segmentation with Intuition-Inspired Hypergraph Modeling,https://doi.org/10.1109/tip.2023.3245324,2023,"multimodal remote sensing rs image segmentation aims to comprehensively utilize multiple rs modalities to assign pixellevel semantics to the studied scenes which can provide a new perspective for global city understanding multimodal segmentation inevitably encounters the challenge of modeling intra and intermodal relationships italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkiei object diversity and modal gaps however the previous methods are usually designed for a single rs modality limited by the noisy collection environment and poor discrimination information neuropsychology and neuroanatomy confirm that the human brain performs the guiding perception and integrative cognition of multimodal semantics through intuitive reasoning therefore establishing a semantic understanding framework inspired by intuition to realize multimodal rs segmentation becomes the main motivation of this work drived by the superiority of hypergraphs in modeling highorder relationships we propose an intuitioninspired hypergraph network italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkii sup xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink2sup italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkhni for multimodal rs segmentation specifically we present a hypergraph parser to imitate guiding perception to learn intramodal objectwise relationships it parses the input modality into irregular hypergraphs to mine semantic clues and generate robust monomodal representations in addition we also design a hypergraph matcher to dynamically update the hypergraph structure from the explicit correspondence of visual concepts similar to integrative cognition to improve crossmodal compatibility when fusing multimodal features extensive experiments on two multimodal rs datasets show that the proposed italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkii sup xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink2sup italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkhni outperforms the stateoftheart models achieving f sub xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink1sub miou accuracy 914829 on the isprs vaihingen dataset and 921842 on the msaw dataset the complete algorithm and benchmark results will be available online",Brain
Shape-aware Joint Distribution Alignment for Cross-domain Image Segmentation,https://doi.org/10.1109/tmi.2023.3247941,2023,"we present an unsupervised domain adaptation method for image segmentation which aligns highorder statistics computed for the source and target domains encoding domaininvariant spatial relationships between segmentation classes our method first estimates the joint distribution of predictions for pair of pixels whose relative position corresponds to a given spatial displacement domain adaptation is then achieved by aligning the joint distributions of source and target images computed for a set of displacements two enhancements of this method are proposed the first one uses an efficient multiscale strategy that enables capturing longrange relationships in the statistics the second one extends the joint distribution alignment loss to features in intermediate layers of the network by computing their crosscorrelation we test our method on the task of unpaired multimodal cardiac segmentation using the multimodality whole heart segmentation challenge dataset and prostate segmentation task where images from two datasets are taken as data in different domains our results show the advantages of our method compared to recent approaches for crossdomain image segmentation code is available at httpsgithubcomwangping521domainadaptationshapeprior",Cardiac
Shape-aware Joint Distribution Alignment for Cross-domain Image Segmentation,https://doi.org/10.1109/tmi.2023.3247941,2023,"we present an unsupervised domain adaptation method for image segmentation which aligns highorder statistics computed for the source and target domains encoding domaininvariant spatial relationships between segmentation classes our method first estimates the joint distribution of predictions for pair of pixels whose relative position corresponds to a given spatial displacement domain adaptation is then achieved by aligning the joint distributions of source and target images computed for a set of displacements two enhancements of this method are proposed the first one uses an efficient multiscale strategy that enables capturing longrange relationships in the statistics the second one extends the joint distribution alignment loss to features in intermediate layers of the network by computing their crosscorrelation we test our method on the task of unpaired multimodal cardiac segmentation using the multimodality whole heart segmentation challenge dataset and prostate segmentation task where images from two datasets are taken as data in different domains our results show the advantages of our method compared to recent approaches for crossdomain image segmentation code is available at httpsgithubcomwangping521domainadaptationshapeprior",Prostate
Heart disease prediction using image segmentation Through the CNN model,https://doi.org/10.1109/confluence56041.2023.10048835,2023,"one of the most fatal diseases is heart disease this is a condition that affects a big portion of the worlds population when we examine the death rate and the enormous number of people who suffer from heart disease it becomes clear how critical early detection of heart disease is there are numerous established approaches for predicting such sickness but they do not appear to be adequate there is an immediate need for a medical diagnosis system that can anticipate heart disease early on and provide a more accurate diagnosis than standard approaches such as logistic regularization lasso elastic network and group lasso regularisation nowadays machine learning approaches are gaining a lot of traction convolutional neural networks cnns are utilised in this paper to create a system for early stage prediction and medical diagnosis cnn receives 13 clinical features as input the cnn is trained using a modified back propagation training approach during testing it was discovered that cnn predicts the absence and presence of cardiac disease with greater than 95 percent accuracy in this investigation we present cardiohelp a method that uses a deep learning algorithm known as convolutional neural networks to predict whether or not a patient will have cardiovascular disease cnn in order to model temporal data the suggested technique makes use of cnn for early hf prediction we compiled a dataset on heart disease and used cuttingedge algorithms to compare our findings the results were promising",Cardiac
New Approach to Image Segmentation: U-Net Convolutional Network for Multiresolution CT Image Lung Segmentation,https://doi.org/10.28991/esj-2023-07-02-014,2023,"image processing is the main topic of discussion in the field of computer vision technology with the increase in the number of images used over time the types of images with different resolution qualities are becoming more diverse low image resolution leads to uncertainty in the task of image processing therefore a method with high performance is needed for image processing in image processing there is a convolutional neural networks cnn architecture for semantic segmentation of pixels called unet unet is formed by an encoder network and decoder network that will later produce segmented images in this paper researchers applied the unet architecture to the lung ct image dataset which has different resolutions in each image to segment the image that produces a segmented lung image in this study we conducted experiments for many training and testing data ratios while also comparing the model performances between the single resolution dataset and the multiresolution dataset the results showed that the segmentation accuracy using a single resolution dataset is as follows 5 to 5 ratio is 6600 8 to 2 ratio is 8896 and 9 to 1 ratio is 9447 for the multiresolution dataset the application is 5 to 5 ratio is 8242 8 to 2 ratio is 9012 and 9 to 1 ratio is 9366 and for the result the training time using single resolution dataset are 5 to 5 ratio is 5994 seconds 8 to 2 ratio is 8716 seconds and 9 to 1 ratio is 19534 seconds as for multiresolution data application are 5 to 5 ratio is 4960 seconds 8 to 2 ratio is 10208 seconds and 9 to 1 ratio is 19979 seconds based on those results we obtained the best accuracy for single resolution at a 91 ratio and the best training time for multiresolution at a 55 ratio doi 1028991esj20230702014 full text pdf",Lung
Brain Tumor Segmentation and Classification from Sensor-Based Portable Microwave Brain Imaging System Using Lightweight Deep Learning Models,https://doi.org/10.3390/bios13030302,2023,"automated brain tumor segmentation from reconstructed microwave rmw brain images and image classification is essential for the investigation and monitoring of the progression of brain disease the manual detection classification and segmentation of tumors are extremely timeconsuming but crucial tasks due to the tumors pattern in this paper we propose a new lightweight segmentation model called microwavesegnet msegnet which segments the brain tumor and a new classifier called the brainimagenet binet model to classify the rmw images initially three hundred 300 rmw brain image samples were obtained from our sensorsbased microwave brain imaging smbi system to create an original dataset then image preprocessing and augmentation techniques were applied to make 6000 training images per fold for a 5fold crossvalidation later the msegnet and binet were compared to stateoftheart segmentation and classification models to verify their performance the msegnet has achieved an intersectionoverunion iou and dice score of 8692 and 9310 respectively for tumor segmentation the binet has achieved an accuracy precision recall f1score and specificity of 8933 8874 8867 8861 and 9433 respectively for threeclass classification using raw rmw images whereas it achieved 9833 9835 9833 9833 and 9917 respectively for segmented rmw images therefore the proposed cascaded model can be used in the smbi system",Brain
A Comprehensive Exploration of Brain Tumor Segmentation Using Deep Learning Techniques,https://doi.org/10.1201/9781003320340-7,2023,"cancer is one of the most lethal diseases in this world ontime detection and clear identification of brain tumors will improve the survival percentage of patients nowadays the segmentation processes using magnetic resonance imaging mri play a major role to detect and predict a brain tumor traditional image segmentation was a difficult task because it requires more time so to overcome these types of limitations we are using an automatic image segmentation process many algorithms are available for automatic segmentation and out of that deep learning technique there is an efficient algorithm because we may determine the exact size and position of cancer using a large number of training datasets many review papers on mribased image segmentation have been published in order to raise awareness this review chapter mainly discusses various convolutional neural network cnnbased deep learning algorithms as it provides better accuracy in image recognition problems in this chapter we reviewed metrics like accuracy specificity sensitivity and the predicted error percentage values using different techniques from this survey we conclude that the use of the cascaded cnn technique with maximum accuracy will be produced and also by comparing the performance analysis of different cnn techniques every cnn model has different values and its own merits and demerits have been discussed in this chapter",Brain
Brain Tissue Segmentation Using Transfer Learning,https://doi.org/10.1007/978-981-19-7874-6_34,2023,"abstracta brain tumour bt is a lifethreatening condition produced by aberrant brain cell proliferation that affects human blood cells and nerves detecting bts in a timely and exact manner is critical to preventing complex and unpleasant treatment methods as it can aid surgeons in preoperative planning manually bt detection takes a long time and is extremely reliant on the presence of local experts as a result accurate automated techniques for identifying and categorizing diverse forms of brain tumours are urgently needed however due to wide differences in size position and structure precise localization and classification of brain tumours is a difficult task weve proposed an innovative approach to dealing with the problemskeywordsbrain tumourdeep learningtransfer learningmagnetic resonance imagingunet convolutional neural network",Brain
Noisy Brain MR Image Segmentation Using Modified Adaptively Regularized Kernel Fuzzy C-Means Clustering Algorithm,https://doi.org/10.1007/978-981-19-7874-6_45,2023,"abstractimage segmentation is one of the most crucial steps in the field of biomedical image analysis magnetic resonance mr imaging plays a vital role in diagnosing several neurological diseases over the past three decades clustering algorithms are widely employed in the field of biomedical image segmentation adaptively regularized kernelbased fuzzy cmeans clustering arkfcm algorithm is the most popular algorithm for segmenting abnormal tissues like cerebrospinal fluid gray matter and white matter the original arkfcm is noise sensitive noisy image analysis leads to the wrong diagnosis and reduces accuracy in this paper an adaptive weighted mean filtering algorithm is proposed this proposed algorithm is tested on the brain web database the obtained average accuracy based on jaccard similarity was 8533 7909 and 7685 for gray matter white matter and cerebrospinal fluid respectively the result shows that the modified arkfcm algorithm segments noisy mr images efficiently with better accuracykeywordsimage segmentationmagnetic resonancebrain imagefuzzy cmeans clusteringand clustering algorithm",Brain
Active Learning in Brain Tumor Segmentation with Uncertainty Sampling  Annotation Redundancy Restriction and Data Initialization,https://doi.org/10.48550/arxiv.2302.10185,2023,"deep learning models have demonstrated great potential in medical 3d imaging but their development is limited by the expensive large volume of annotated data required active learning al addresses this by training a model on a subset of the most informative data samples without compromising performance we compared different al strategies and propose a framework that minimizes the amount of data needed for stateoftheart performance 638 multiinstitutional brain tumor mri images were used to train a 3d unet model and compare al strategies we investigated uncertainty sampling annotation redundancy restriction and initial dataset selection techniques uncertainty estimation techniques including bayesian estimation with dropout bootstrapping and margins sampling were compared to random query strategies to avoid annotation redundancy by removing similar images within the tobeannotated subset were considered as well we determined the minimum amount of data necessary to achieve similar performance to the model trained on the full dataset alpha 01 a variancebased selection strategy using radiomics to identify the initial training dataset is also proposed bayesian approximation with dropout at training and testing showed similar results to that of the full data model with less than 20 of the training data p0293 compared to random query achieving similar performance at 565 of the training data p0814 annotation redundancy restriction techniques achieved stateoftheart performance at approximately 4050 of the training data radiomics dataset initialization had higher dice with initial dataset sizes of 20 and 80 images but improvements were not significant in conclusion we investigated various al strategies with dropout uncertainty estimation achieving stateoftheart performance with the least annotated data",Brain
Is Autoencoder Truly Applicable for 3D CT Super-Resolution?,https://doi.org/10.48550/arxiv.2302.10272,2023,"featured by a bottleneck structure autoencoder ae and its variants have been largely applied in various medical image analysis tasks such as segmentation reconstruction and denoising despite of their promising performances in aforementioned tasks in this paper we claim that ae models are not applicable to single image superresolution sisr for 3d ct data our hypothesis is that the bottleneck architecture that resizes feature maps in ae models degrades the details of input images thus can sabotage the performance of superresolution although unet proposed skip connections that merge information from different levels we claim that the degrading impact of feature resizing operations could hardly be removed by skip connections by conducting largescale ablation experiments and comparing the performance between models with and without the bottleneck design on a public ct lung dataset we have discovered that ae models including unet have failed to achieve a compatible sisr result p005 by students ttest compared to the baseline model our work is the first comparative study investigating the suitability of ae architecture for 3d ct sisr tasks and brings a rationale for researchers to rethink the choice of model architectures especially for 3d ct sisr tasks the full implementation and trained models can be found at httpsgithubcomroldbachautoencoder3dctsisr",Lung
DrasCLR: A Self-supervised Framework of Learning Disease-related and  Anatomy-specific Representation for 3D Medical Images,https://doi.org/10.48550/arxiv.2302.10390,2023,"largescale volumetric medical images with annotation are rare costly and time prohibitive to acquire selfsupervised learning ssl offers a promising pretraining and feature extraction solution for many downstream tasks as it only uses unlabeled data recently ssl methods based on instance discrimination have gained popularity in the medical imaging domain however ssl pretrained encoders may use many clues in the image to discriminate an instance that are not necessarily diseaserelated moreover pathological patterns are often subtle and heterogeneous requiring the ability of the desired method to represent anatomyspecific features that are sensitive to abnormal changes in different body parts in this work we present a novel ssl framework named drasclr for 3d medical imaging to overcome these challenges we propose two domainspecific contrastive learning strategies one aims to capture subtle disease patterns inside a local anatomical region and the other aims to represent severe disease patterns that span larger regions we formulate the encoder using conditional hyperparameterized network in which the parameters are dependant on the anatomical location to extract anatomically sensitive features extensive experiments on largescale computer tomography ct datasets of lung images show that our method improves the performance of many downstream prediction and segmentation tasks the patientlevel representation improves the performance of the patient survival prediction task we show how our method can detect emphysema subtypes via dense prediction we demonstrate that finetuning the pretrained model can significantly reduce annotation efforts without sacrificing emphysema detection accuracy our ablation study highlights the importance of incorporating anatomical context into the ssl framework",Lung
A Review of Left Ventricle Segmentation Techniques,https://doi.org/10.22214/ijraset.2023.49169,2023,"abstract the creation of automated techniques for the identification and segmentation the left ventricle lv in medical pictures has received more attention in recent years this is partly caused by the rising incidence of cardiovascular disease and the demand for more precise and effective lv evaluation techniques the considerable variation in lv form and size as well as the presence of other structures like the right ventricle rv and left atrium in the same pictures provide a number of obstacles for lv recognition and segmentation in addition other surrounding structures such as the ribs frequently block the view of the lv myocardium the muscular wall of the heart despite these difficulties several automated techniques have been put out lately with varied degrees of effectiveness we evaluate the current status of automated lv detection and segmentation in this research and provide an improved method for lv detection and segmentation we test our strategy using a sizable datasets of cardiac mri images and we contrast the outcomes with those of other approaches",Cardiac
Automated Lung Cancer Segmentation in Tissue Micro Array Analysis Histopathological Images Using a Prototype of Computer-Assisted Diagnosis,https://doi.org/10.3390/jpm13030388,2023,"background lung cancer is a fatal disease that kills approximately 85 of those diagnosed with it in recent years advances in medical imaging have greatly improved the acquisition storage and visualization of various pathologies making it a necessary component in medicine today objective develop a computeraided diagnostic system to detect lung cancer early by segmenting tumor and nontumor tissue on tissue micro array analysis tma histopathological images method the prototype computeraided diagnostic system was developed to segment tumor areas nontumor areas and fundus on tma histopathological images results the system achieved an average accuracy of 834 and an fmeasurement of 844 in segmenting tumor and nontumor tissue conclusion the computeraided diagnostic system provides a second diagnostic opinion to specialists allowing for more precise diagnoses and more appropriate treatments for lung cancer",Lung
External validation of a convolutional neural network for the automatic segmentation of intraprostatic tumor lesions on 68Ga-PSMA PET images,https://doi.org/10.3389/fmed.2023.1133269,2023,"introduction state of the art artificial intelligence ai models have the potential to become a onestop shop to improve diagnosis and prognosis in several oncological settings the external validation of ai models on independent cohorts is essential to evaluate their generalization ability hence their potential utility in clinical practice in this study we tested on a large separate cohort a recently proposed stateoftheart convolutional neural network for the automatic segmentation of intraprostatic cancer lesions on psma pet images methods eightyfive biopsy proven prostate cancer patients who underwent 68 ga psma pet for staging purposes were enrolled in this study images were acquired with either fully hybrid petmri n 46 or petct n 39 all participants showed at least one intraprostatic pathological finding on pet images that was independently segmented by two nuclear medicine physicians the trained model was available at httpsgitlabcomdejankostyszynprostategtvsegmentation and data processing has been done in agreement with the reference work results when compared to the manual contouring the ai model yielded a median dice score 074 therefore showing a moderately good performance results were robust to the modality used to acquire images petct or petmri and to the ground truth labels no significant difference between the models performance when compared to reader 1 or reader 2 manual contouring discussion in conclusion this ai model could be used to automatically segment intraprostatic cancer lesions for research purposes as instance to define the volume of interest for radiomics or deep learning analysis however more robust performance is needed for the generation of aibased decision support technologies to be proposed in clinical practice",Prostate
Establishing the Validity of Compressed Sensing Diffusion Spectrum Imaging,https://doi.org/10.1101/2023.02.22.529546,2023,"diffusion spectrum imaging dsi using dense cartesian sampling of q space has been shown to provide important advantages for modeling complex white matter architecture however its adoption has been limited by the lengthy acquisition time required sparser sampling of q space combined with compressed sensing cs reconstruction techniques has been proposed as a way to reduce the scan time of dsi acquisitions however prior studies have mainly evaluated csdsi in postmortem or nonhuman data at present the capacity for csdsi to provide accurate and reliable measures of white matter anatomy and microstructure in the living human brain remains unclear we evaluated the accuracy and interscan reliability of 6 different csdsi schemes that provided up to 80 reductions in scan time compared to a full dsi scheme we capitalized on a dataset of twentysix participants who were scanned over eight independent sessions using a full dsi scheme from this full dsi scheme we subsampled images to create a range of csdsi images this allowed us to compare the accuracy and interscan reliability of derived measures of white matter structure bundle segmentation voxelwise scalar maps produced by the csdsi and the full dsi schemes we found that csdsi estimates of both bundle segmentations and voxelwise scalars were nearly as accurate and reliable as those generated by the full dsi scheme moreover we found that the accuracy and reliability of csdsi was higher in white matter bundles that were more reliably segmented by the full dsi scheme as a final step we replicated the accuracy of csdsi in a prospectively acquired dataset n20 scanned once together these results illustrate the utility of csdsi for reliably delineating in vivo white matter architecture in a fraction of the scan time underscoring its promise for both clinical and research applications",Brain
A Novel 18-Convolutional Layered Deep U-Net Architecture for COVID-19 Infection Diagnosis Through Object Detection on Lung CT Scan Segmentation,https://doi.org/10.1007/978-981-19-6088-8_58,2023,"abstractwith the advancement of digital technology a large number of medical images are created in the field of digital medicine object detection is a critical field of study in medical image analysis detection and processing object detection is the categorization of the pixels in an image that determines where the objects in the image are located image classification is the global classification of an images pixels the objects are identified but not located from all of the pixels in the image the intelligent identification process for the adjuvant diagnosis to assist medical doctors of various disciplines is in high demand the need for the high accurate object detection method for the medical images remains a major challenge toward disease detection in the health care with this summary overview a novel model is proposed for lung ct scan image detection as 18convolutional layered deep unet architecture for diagnosis of covid19 detection through object detection model fitting is done with 18convolutional layered deep unet architecture and the model design is formed with four contraction path and four expansive path layers the customized model design is finetuned with the parameter optimization the object detection is done and the performance is analyzed the dataset is also fitted with existing deep convolution neural network models like regionbased threshold edgebased and clusteringbased method and the performance is analyzed and compared with proposed model with metrics like pixel accuracy intersection over union and dice coefficient implementation results show that the proposed models have pixel accuracy of 9832 intersection over union of 487 and dice coefficient of 9756 compared to existing object detection modelskeywordscnnpixel accuracyobject detectiondropoutdice coefficient",Lung
Vital Role of 2D CNN in Brain Malignancy,https://doi.org/10.1007/978-981-19-6088-8_10,2023,"abstractmalignancy is abnormal cell proliferation in body tissues in brain if proliferation happens uncontrollably then it is brain malignancy it has to be detected at an early stage to improve the patients scope for survival carcinomas tumors are to be treated and removed surgically whereas benign ones do not cause much damage to the brain tissues a cancerous tumor grows aggressively or recursively damaging the entire structure an magnetic resonance image mri is the most prevalent way of detecting them manual tumor identification procedure is timeconsuming and is more prone to human mistakes computer technologies assist more than humans in identifying microchanges in brain tissues nowadays machine learning algorithms are playing an important role in evaluating medical images and data segmentation and classification of tumor region identified from mris assist professionals by extracting and detecting specific locations of infected regions in the brain convolution neural networks cnns are the best source to identify tumors from mris which will be observed in this work our findings are based on rectified linear unit relu hyperbolic tangent tanh sigmoid added with elu exponential linear unit functions resulting in mean and fscore accuracy of 9944keywordsbraincarcinomaconvolution neural networkmalignancyproliferationtumor",Brain
SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining,https://doi.org/10.1016/j.media.2023.102789,2023,"despite advances in data augmentation and transfer learning convolutional neural networks cnns difficultly generalise to unseen domains when segmenting brain scans cnns are highly sensitive to changes in resolution and contrast even within the same mri modality performance can decrease across datasets here we introduce synthseg the first segmentation cnn robust against changes in contrast and resolution synthseg is trained with synthetic data sampled from a generative model conditioned on segmentations crucially we adopt a domain randomisation strategy where we fully randomise the contrast and resolution of the synthetic training data consequently synthseg can segment real scans from a wide range of target domains without retraining or finetuning which enables straightforward analysis of huge amounts of heterogeneous clinical data because synthseg only requires segmentations to be trained no images it can learn from labels obtained by automated methods on diverse populations eg ageing and diseased thus achieving robustness to a wide range of morphological variability we demonstrate synthseg on 5000 scans of six modalities including ct and ten resolutions where it exhibits unparallelled generalisation compared with supervised cnns stateoftheart domain adaptation and bayesian segmentation finally we demonstrate the generalisability of synthseg by applying it to cardiac mri and ct scans",Cardiac
SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining,https://doi.org/10.1016/j.media.2023.102789,2023,"despite advances in data augmentation and transfer learning convolutional neural networks cnns difficultly generalise to unseen domains when segmenting brain scans cnns are highly sensitive to changes in resolution and contrast even within the same mri modality performance can decrease across datasets here we introduce synthseg the first segmentation cnn robust against changes in contrast and resolution synthseg is trained with synthetic data sampled from a generative model conditioned on segmentations crucially we adopt a domain randomisation strategy where we fully randomise the contrast and resolution of the synthetic training data consequently synthseg can segment real scans from a wide range of target domains without retraining or finetuning which enables straightforward analysis of huge amounts of heterogeneous clinical data because synthseg only requires segmentations to be trained no images it can learn from labels obtained by automated methods on diverse populations eg ageing and diseased thus achieving robustness to a wide range of morphological variability we demonstrate synthseg on 5000 scans of six modalities including ct and ten resolutions where it exhibits unparallelled generalisation compared with supervised cnns stateoftheart domain adaptation and bayesian segmentation finally we demonstrate the generalisability of synthseg by applying it to cardiac mri and ct scans",Brain
Semi-Supervised Segmentation of Multi-vendor and Multi-center Cardiac  MRI using Histogram Matching,https://doi.org/10.48550/arxiv.2302.11200,2023,"automatic segmentation of the heart cavity is an essential task for the diagnosis of cardiac diseases in this paper we propose a semisupervised segmentation setup for leveraging unlabeled data to segment leftventricle rightventricle and myocardium we utilize an enhanced version of residual unet architecture on a largescale cardiac mri dataset handling the class imbalanced data issue using dice loss the enhanced supervised model is able to achieve better dice scores in comparison with a vanilla unet model we applied several augmentation techniques including histogram matching to increase the performance of our model in other domains also we introduce a simple but efficient semisupervised segmentation method to improve segmentation results without the need for large labeled data finally we applied our method on two benchmark datasets stacom2018 and mms 2020 challenges to show the potency of the proposed model the effectiveness of our proposed model is demonstrated by the quantitative results the model achieves average dice scores of 0921 0926 and 0891 for leftventricle rightventricle and myocardium respectively",Cardiac
Personalized and privacy-preserving federated heterogeneous medical image analysis with PPPML-HMI,https://doi.org/10.1101/2023.02.19.22279631,2023,"abstract heterogeneous data is endemic due to the use of diverse models and settings of devices by hospitals in the field of medical imaging however there are few opensource frameworks for federated heterogeneous medical image analysis with personalization and privacy protection simultaneously without the demand to modify the existing model structures or to share any private data in this paper we proposed pppmlhmi an opensource learning paradigm for personalized and privacypreserving federated heterogeneous medical image analysis to our best knowledge personalization and privacy protection were achieved simultaneously for the first time under the federated scenario by integrating the perfedavg algorithm and designing our novel cyclic secure aggregation with the homomorphic encryption algorithm to show the utility of pppmlhmi we applied it to a simulated classification task namely the classification of healthy people and patients from the radchestct dataset and one realworld segmentation task namely the segmentation of lung infections from covid19 ct scans for the realworld task pppmlhmi achieved 5 higher dice score on average compared to conventional fl under the heterogeneous scenario meanwhile we applied the improved deep leakage from gradients to simulate adversarial attacks and showed the solid privacypreserving capability of pppmlhmi by applying pppmlhmi to both tasks with different neural networks a varied number of users and sample sizes we further demonstrated the strong robustness of pppmlhmi",Lung
A framework for Brain tumor detection based on segmentation and features fusion using MRI images,https://doi.org/10.1016/j.brainres.2023.148300,2023,"irregular growth of cells in the skull is recognized as a brain tumor that can have two types such as benign and malignant there exist various methods which are used by oncologists to assess the existence of brain tumors such as blood tests or visual assessments moreover the noninvasive magnetic resonance imaging mri technique without ionizing radiation has been commonly utilized for diagnosis however the segmentation in 3dimensional mri is timeconsuming and the outcomes mainly depend on the operators experience therefore a novel and robust automated brain tumor detector has been suggested based on segmentation and fusion of features to improve the localization results we preprocessed the images using gaussian filter gf and synthstrip a tool for brain skull stripping we utilized two known benchmarks for training and testing ie figshare and harvard the proposed methodology attained 998 accuracy 993 recall 994 precision 995 f1 score and 0989 auc we performed the comparative analysis of our approach with prevailing dl classical and segmentationbased approaches additionally we also performed the crossvalidation using harvard dataset attaining 993 identification accuracy the outcomes exhibit that our approach offers significant outcomes than existing methods and outperforms them",Brain
Personalized and privacy-preserving federated heterogeneous medical  image analysis with PPPML-HMI,https://doi.org/10.48550/arxiv.2302.11571,2023,"heterogeneous data is endemic due to the use of diverse models and settings of devices by hospitals in the field of medical imaging however there are few opensource frameworks for federated heterogeneous medical image analysis with personalization and privacy protection simultaneously without the demand to modify the existing model structures or to share any private data in this paper we proposed pppmlhmi an opensource learning paradigm for personalized and privacypreserving federated heterogeneous medical image analysis to our best knowledge personalization and privacy protection were achieved simultaneously for the first time under the federated scenario by integrating the perfedavg algorithm and designing our novel cyclic secure aggregation with the homomorphic encryption algorithm to show the utility of pppmlhmi we applied it to a simulated classification task namely the classification of healthy people and patients from the radchestct dataset and one realworld segmentation task namely the segmentation of lung infections from covid19 ct scans for the realworld task pppmlhmi achieved sim5 higher dice score on average compared to conventional fl under the heterogeneous scenario meanwhile we applied the improved deep leakage from gradients to simulate adversarial attacks and showed the solid privacypreserving capability of pppmlhmi by applying pppmlhmi to both tasks with different neural networks a varied number of users and sample sizes we further demonstrated the strong robustness of pppmlhmi",Lung
Incorporating Training Data Uncertainty in Machine Learning Models for Satellite Imagery,https://doi.org/10.5194/egusphere-egu23-10528,2023,"ampltpampgtsupervised machine learning ml models rely on labels in the training data to learn the patterns of interest in earth science applications these labels are usually collected by humans either as labels annotated on imagery such as land cover class or as in situ measurements such as soil moisture both annotations and in situ measurements contain uncertainties resulting from factors such as class misinterpretation and device error these training data uncertainties propagate through the ml model training and result in uncertainties in the model outputs therefore it is essential to quantify these uncertainties and incorporate them in the model 1ampltpampgt ampltpampgtin this research we will present results of inputting semantic segmentation label uncertainties into the model training and show that it improves model performance the experiment is run using the landcovernet training dataset which contains global land cover labels based on timeseries of sentinel2 multispectral imagery 2 these labels are human annotations derived using a consensus algorithm based on the input labels from three independent annotators the training dataset contains the consensus label and consensus score and we treat the latter as a measure of uncertainty for each labeled pixel in the data our model architecture is a convolutional neural network cnn trained on a subset of landcovernet with the rest of the dataset used for validation we compare the results of this experiment with the same model trained on the dataset without the uncertainty information and show the improvement in the accuracy of the modelampltpampgt ampltpampgtampamp160ampltpampgt ampltpampgt1 elmes a alemohammad h avery r caylor k eastman j fishgold l friedl m jain m kohli d laso bayas j lunga d mccarty j pontius r reinmann a rogan j song l stoynova h ye s yi zf estes l 2020 accounting for training data error in machine learning applied to earth observations ampltemampgtremote sensingampltemampgt 126 1034 httpsdoiorg103390rs12061034ampltpampgt ampltpampgt2 alemohammad h booth k 2020 landcovernet a global benchmark land cover classification training dataset ampltemampgtneurips 2020 workshop on ai for earth sciencesampltemampgt httparxivorgabs201203111ampltpampgt",Lung
Cardiovascular Imaging using Machine Learning: A Review,https://doi.org/10.35940/ijrte.f7480.0311623,2023,"cardiovascular diseases are a major cause of death worldwide making early detection and diagnosis critical for reducing mortality and morbidity the interpretation of complex medical images can be made easier with the use of machine learning algorithms which could result in more precise cardiovascular imaging diagnosis in this review paper we give an overview of the stateoftheart in machine learningbased cardiovascular imaging including the datasets imaging modalities and algorithms that are currently accessible we also discuss the major challenges and opportunities in the field and highlight recent advances in machine learning algorithms for automated cardiac image analysis specifically we focus on the use of deep learning and convolutional neural networks for cardiac image segmentation and classification of cardiac conditions such as heart failure myocardial infarction and arrhythmias we explore the potential of these algorithms to improve the accuracy and efficiency of cardiovascular imaging and discuss the need for standardized datasets and evaluation metrics to enable better comparison of different algorithms we also discuss the importance of interpretability in machine learning algorithms to enhance trust and transparency in their predictions overall this review provides a comprehensive overview of the current state and future potential of machine learning in cardiovascular imaging highlighting its significant impact on improving the diagnosis and treatment of cardiovascular diseases",Cardiac
Region-of-interest Attentive Heteromodal Variational Encoder-Decoder for Segmentation with Missing Modalities,https://doi.org/10.1007/978-3-031-26351-4_9,2023,"abstractthe use of multimodal images generally improves segmentation however complete multimodal datasets are often unavailable due to clinical constraints to address this problem we propose a novel multimodal segmentation framework that is robust to missing modalities by using a regionofinterest roi attentive modality completion we use roi attentive skip connection to focus on segmentationrelated regions and a joint discriminator that combines tumor roi attentive images and segmentation probability maps to learn segmentationrelevant shared latent representations our method is validated in the brain tumor segmentation challenge dataset of 285 cases for the three regions of the complete tumor tumor core and enhancing tumor it is also validated on the ischemic stroke lesion segmentation challenge dataset with 28 cases of infarction lesions our method outperforms stateoftheart methods in robust multimodal segmentation achieving an average dice of 8415 7559 and 5490 for the three types of brain tumor regions respectively and 4829 for stroke lesions our method can improve the clinical workflow that requires multimodal images keywordssegmentationmissing modalitiesmultimodal learningadversarial learning",Brain
Slice-Mask Based 3D Cardiac Shape Reconstruction from CT Volume,https://doi.org/10.1007/978-3-031-26351-4_5,2023,"abstractan accurate 3d ventricular model is essential for diagnosing and analyzing cardiovascular disease it is challenging to obtain accurate patientspecific models on scarce data via widely accepted deeplearning methods to fully use the characteristics of medical volumebased images we present a slicemask representation to better regress the parameters of the 3d model a data synthesis strategy is proposed to alleviate the lack of training data by sampling in the constructed statistical shape model space and obtaining the corresponding slicemasks we train the endtoend structure by combining the segmentation and parametric regression modules furthermore we establish a larger left ventricular ct dataset than before which fills the gap in relevant data of the healthy population our method is evaluated on both synthetic data and real cardiac scans experiments demonstrate that our method can achieve advanced results in shape reconstruction and segmentation tasks code is publicly available at httpsgithubcomyuanxiaohanslicemaskbased3dcardiacshapereconstructionkeywords3d reconstructionsegmentationcardiac ct",Cardiac
Towards Explainable AI on Chest X-Ray Diagnosis Using Image Segmentation and CAM Visualization,https://doi.org/10.1007/978-3-031-28076-4_48,2023,"abstractcomputer vision in medical diagnosis has achieved a high level of success in diagnosing diseases with high accuracy however conventional classifiers that produce an imagetolabel result provide insufficient information for medical professionals to judge and raise concerns over the trust and reliability of a model with results that cannot be explained class activation maps are a method of providing insight into a convolutional neural networks feature maps that lead to its classification but in the case of lung diseases the region of concern is only the lungs therefore the proposed model combines image segmentation models and classifiers to crop out only the lung region of a chest xrays class activation map to provide a visualization that improves the explainability and trust of an ais diagnosis by focusing on a models weights within the region of concern the proposed unet model achieves 9772 accuracy and a dice coefficient of 09691 on testing data from the covidquex dataset which includes both diseased and healthy lungskeywordsdeep learningimage processingneural networksmedical diagnosissegmentation techniquesexplainable ai",Lung
Towards Explainable AI on Chest X-Ray Diagnosis Using Image Segmentation and CAM Visualization,https://doi.org/10.1007/978-3-031-28076-4_48,2023,"abstractcomputer vision in medical diagnosis has achieved a high level of success in diagnosing diseases with high accuracy however conventional classifiers that produce an imagetolabel result provide insufficient information for medical professionals to judge and raise concerns over the trust and reliability of a model with results that cannot be explained class activation maps are a method of providing insight into a convolutional neural networks feature maps that lead to its classification but in the case of lung diseases the region of concern is only the lungs therefore the proposed model combines image segmentation models and classifiers to crop out only the lung region of a chest xrays class activation map to provide a visualization that improves the explainability and trust of an ais diagnosis by focusing on a models weights within the region of concern the proposed unet model achieves 9772 accuracy and a dice coefficient of 09691 on testing data from the covidquex dataset which includes both diseased and healthy lungskeywordsdeep learningimage processingneural networksmedical diagnosissegmentation techniquesexplainable ai",Lung
Variational Autoencoders for Generating Synthetic Tractography-Based Bundle Templates in a Low-Data Setting,https://doi.org/10.1101/2023.02.24.529954,2023,"abstract white matter tracts generated from whole brain tractography are often processed using automatic segmentation methods with standard atlases atlases are generated from hundreds of subjects which becomes timeconsuming to create and difficult to apply to all populations in this study we extended our prior work on using a deep generative model convolutional variational autoencoder to map complex and dataintensive streamlines to a lowdimensional latent space given a limited sample size of 50 subjects from the adni3 dataset to generate synthetic populationspecific bundle templates using kernel density estimation kde on streamline embeddings we conducted a quantitative shape analysis by calculating bundle shape metrics and found that our bundle templates better capture the shape distribution of the bundles than the atlas data used in the original segmentation derived from young healthy adults we further demonstrated the use of our framework for direct bundle segmentation from wholebrain tractograms",Brain
Brain Tumor Segmentation Using Modified Double U-Net Architecture,https://doi.org/10.4028/p-52096g,2023,"children and the elderly are most susceptible to brain tumors its deadly cancer caused by uncontrollable brain cell proliferation inside the skull the heterogeneity of tumor cells makes classification extremely difficult image segmentation has been revolutionized because of the convolution neural network cnn which is especially useful for medical images not only does the unet succeed in segmenting a wide range of medical pictures in general but also in some particularly difficult instances however we uncovered severe problems in the standard models that have been used for medical image segmentation as a result we applied modification and created an efficient unetbased deep learning architecture which was examined on the brain tumor dataset from the kaggle repository which consists of over 1500 images of brain tumors together with their ground truth after comparing our model to comparable cuttingedge approaches we determined that our design resulted in at least a 10 improvement showing that it generates more efficient better and robust results",Brain
Clinical capability of modern brain tumor segmentation models,https://doi.org/10.1002/mp.16321,2023,"stateoftheart automated segmentation methods achieve exceptionally high performance on the brain tumor segmentation brats challenge a dataset of uniformly processed and standardized magnetic resonance generated images mris of gliomas however a reasonable concern is that these models may not fare well on clinical mris that do not belong to the specially curated brats dataset research using the previous generation of deep learning models indicates significant performance loss on crossinstitutional predictions here we evaluate the crossinstitutional applicability and generalisability of stateoftheart deep learning models on new clinical data methods we train a stateoftheart 3d unet model on the conventional brats dataset comprising low and highgrade gliomas we then evaluate the performance of this model for automatic tumor segmentation of brain tumors on inhouse clinical data this dataset contains mris of different tumor types resolutions and standardization than those found in the brats dataset ground truth segmentations to validate the automated segmentation for inhouse clinical data were obtained from expert radiation oncologistswe report average dice scores of 0764 0648 and 061 for the whole tumor tumor core and enhancing tumor respectively in the clinical mris these means are higher than numbers reported previously on the same institution and crossinstitution datasets of different origin using different methods there is no statistical difference p 01 when comparing the dice scores to the interannotation variability between two expert clinical radiation oncologists though the clinical data performance is lower than the brats dataset these numbers indicate that models trained on the brats dataset have impressive segmentation performance on previously unseen images obtained at a separate clinical institution these images differ in the imaging resolutions standardization pipelines and tumor types from the brats datastateoftheart deep learning models demonstrate promising performance on crossinstitutional predictions they significantly improve on previous models and can transfer knowledge to new types of brain tumors without additional modeling this article is protected by copyright all rights reserved",Brain
Clinical capability of modern brain tumor segmentation models,https://doi.org/10.1002/mp.16321,2023,"stateoftheart automated segmentation methods achieve exceptionally high performance on the brain tumor segmentation brats challenge a dataset of uniformly processed and standardized magnetic resonance generated images mris of gliomas however a reasonable concern is that these models may not fare well on clinical mris that do not belong to the specially curated brats dataset research using the previous generation of deep learning models indicates significant performance loss on crossinstitutional predictions here we evaluate the crossinstitutional applicability and generalisability of stateoftheart deep learning models on new clinical data methods we train a stateoftheart 3d unet model on the conventional brats dataset comprising low and highgrade gliomas we then evaluate the performance of this model for automatic tumor segmentation of brain tumors on inhouse clinical data this dataset contains mris of different tumor types resolutions and standardization than those found in the brats dataset ground truth segmentations to validate the automated segmentation for inhouse clinical data were obtained from expert radiation oncologistswe report average dice scores of 0764 0648 and 061 for the whole tumor tumor core and enhancing tumor respectively in the clinical mris these means are higher than numbers reported previously on the same institution and crossinstitution datasets of different origin using different methods there is no statistical difference p 01 when comparing the dice scores to the interannotation variability between two expert clinical radiation oncologists though the clinical data performance is lower than the brats dataset these numbers indicate that models trained on the brats dataset have impressive segmentation performance on previously unseen images obtained at a separate clinical institution these images differ in the imaging resolutions standardization pipelines and tumor types from the brats datastateoftheart deep learning models demonstrate promising performance on crossinstitutional predictions they significantly improve on previous models and can transfer knowledge to new types of brain tumors without additional modeling this article is protected by copyright all rights reserved",Brain
Large-Kernel Attention for 3D Medical Image Segmentation,https://doi.org/10.1007/s12559-023-10126-7,2023,"abstract automated segmentation of multiple organs and tumors from 3d medical images such as magnetic resonance imaging mri and computed tomography ct scans using deep learning methods can aid in diagnosing and treating cancer however organs often overlap and are complexly connected characterized by extensive anatomical variation and low contrast in addition the diversity of tumor shape location and appearance coupled with the dominance of background voxels makes accurate 3d medical image segmentation difficult in this paper a novel 3d largekernel lk attention module is proposed to address these problems to achieve accurate multiorgan segmentation and tumor segmentation the advantages of biologically inspired selfattention and convolution are combined in the proposed lk attention module including local contextual information longrange dependencies and channel adaptation the module also decomposes the lk convolution to optimize the computational cost and can be easily incorporated into cnns such as unet comprehensive ablation experiments demonstrated the feasibility of convolutional decomposition and explored the most efficient and effective network design among them the best midtype 3d lk attentionbased unet network was evaluated on ctorg and brats 2020 datasets achieving stateoftheart segmentation performance when compared to avantgarde cnn and transformerbased methods for medical image segmentation the performance improvement due to the proposed 3d lk attention module was statistically validated",Brain
Efficient U-Net Architecture with Multiple Encoders and Attention Mechanism Decoders for Brain Tumor Segmentation,https://doi.org/10.3390/diagnostics13050872,2023,"the brain is the center of human control and communication hence it is very important to protect it and provide ideal conditions for it to function brain cancer remains one of the leading causes of death in the world and the detection of malignant brain tumors is a priority in medical image segmentation the brain tumor segmentation task aims to identify the pixels that belong to the abnormal areas when compared to normal tissue deep learning has shown in recent years its power to solve this problem especially the unetlike architectures in this paper we proposed an efficient unet architecture with three different encoders vgg19 resnet50 and mobilenetv2 this is based on transfer learning followed by a bidirectional features pyramid network applied to each encoder to obtain more spatial pertinent features then we fused the feature maps extracted from the output of each network and merged them into our decoder with an attention mechanism the method was evaluated on the brats 2020 dataset to segment the different types of tumors and the results show a good performance in terms of dice similarity with coefficients of 08741 08069 and 07033 for the whole tumor core tumor and enhancing tumor respectively",Brain
Efficient U-Net Architecture with Multiple Encoders and Attention Mechanism Decoders for Brain Tumor Segmentation,https://doi.org/10.3390/diagnostics13050872,2023,"the brain is the center of human control and communication hence it is very important to protect it and provide ideal conditions for it to function brain cancer remains one of the leading causes of death in the world and the detection of malignant brain tumors is a priority in medical image segmentation the brain tumor segmentation task aims to identify the pixels that belong to the abnormal areas when compared to normal tissue deep learning has shown in recent years its power to solve this problem especially the unetlike architectures in this paper we proposed an efficient unet architecture with three different encoders vgg19 resnet50 and mobilenetv2 this is based on transfer learning followed by a bidirectional features pyramid network applied to each encoder to obtain more spatial pertinent features then we fused the feature maps extracted from the output of each network and merged them into our decoder with an attention mechanism the method was evaluated on the brats 2020 dataset to segment the different types of tumors and the results show a good performance in terms of dice similarity with coefficients of 08741 08069 and 07033 for the whole tumor core tumor and enhancing tumor respectively",Brain
A deep learning approach for fully automated cardiac shape modeling in tetralogy of Fallot,https://doi.org/10.1186/s12968-023-00924-1,2023,"abstract background cardiac shape modeling is a useful computational tool that has provided quantitative insights into the mechanisms underlying dysfunction in heart disease the manual input and time required to make cardiac shape models however limits their clinical utility here we present an endtoend pipeline that uses deep learning for automated view classification slice selection phase selection anatomical landmark localization and myocardial image segmentation for the automated generation of threedimensional biventricular shape models with this approach we aim to make cardiac shape modeling a more robust and broadly applicable tool that has processing times consistent with clinical workflows methods cardiovascular magnetic resonance cmr images from a cohort of 123 patients with repaired tetralogy of fallot rtof from two internal sites were used to train and validate each step in the automated pipeline the complete automated pipeline was tested using cmr images from a cohort of 12 rtof patients from an internal site and 18 rtof patients from an external site manually and automatically generated shape models from the test set were compared using euclidean projection distances global ventricular measurements and atlasbased shape mode scores results the mean absolute error mae between manually and automatically generated shape models in the test set was similar to the voxel resolution of the original cmr images for enddiastolic models mae 19 05 mm and endsystolic models mae 21 07 mm global ventricular measurements computed from automated models were in good agreement with those computed from manual models the average mean absolute difference in shape mode zscore between manually and automatically generated models was 05 standard deviations for the first 20 modes of a reference statistical shape atlas conclusions using deep learning accurate threedimensional biventricular shape models can be reliably created this fully automated endtoend approach dramatically reduces the manual input required to create shape models thereby enabling the rapid analysis of largescale datasets and the potential to deploy statistical atlasbased analyses in pointofcare clinical settings training data and networks are available from cardiacatlasorg",Cardiac
Simple and Powerful PCG Classification Method Based on Selection and Transfer Learning for Precision Medicine Application,https://doi.org/10.3390/bioengineering10030294,2023,"the world health organization who highlights that cardiovascular diseases cvds are one of the leading causes of death globally with an estimated rise to over 236 million deaths by 2030 this alarming trend can be attributed to our unhealthy lifestyles and lack of attention towards early cvd diagnosis traditional cardiac auscultation where a highly qualified cardiologist listens to the heart sounds is a crucial diagnostic method but not always feasible or affordable therefore developing accessible and userfriendly cvd recognition solutions can encourage individuals to integrate regular heart screenings into their routine although many automatic cvd screening methods have been proposed most of them rely on complex prepocessing steps and heart cycle segmentation processes in this work we introduce a simple and efficient approach for recognizing normal and abnormal pcg signals using physionet data we employ data selection techniques such as kernel density estimation kde for signal duration extraction signaltonoise ratio snr and gmm clustering to improve the performance of 17 pretrained keras cnn models our results indicate that using kde to select the appropriate signal duration and finetuning the vgg19 model results in excellent classification performance with an overall accuracy of 097 sensitivity of 0946 precision of 0944 and specificity of 0946",Cardiac
Hybrid Whale and Gray Wolf Deep Learning Optimization Algorithm for Prediction of Alzheimer’s Disease,https://doi.org/10.3390/math11051136,2023,"in recent years finding the optimal solution for image segmentation has become more important in many applications the whale optimization algorithm woa is a metaheuristic optimization technique that has the advantage of achieving the global optimal solution while also being simple to implement and solving many realtime problems if the complexity of the problem increases the woa may stick to local optima rather than global optima this could be an issue in obtaining a better optimal solution for this reason this paper recommends a hybrid algorithm that is based on a mixture of the woa and gray wolf optimization gwo for segmenting the brain sub regions such as the gray matter gm white matter wm ventricle corpus callosum cc and hippocampus hc this hybrid mixture consists of two steps ie the woa and gwo the proposed method helps in diagnosing alzheimers disease ad by segmenting the brain sub regions srs by using a hybrid of the woa and gwo hwoagwo which is represented as hwgo the segmented region was validated with different measures and it shows better accuracy results of 92 following segmentation the deep learning classifier was utilized to categorize normal and ad images the combination of woa and gwo yields an accuracy of 90 as a result it was discovered that the suggested method is a highly successful technique for identifying the ideal solution and it is paired with a deep learning algorithm for classification",Brain
Multi-Attention Segmentation Networks Combined with the Sobel Operator for Medical Images,https://doi.org/10.3390/s23052546,2023,"medical images are used as an important basis for diagnosing diseases among which ct images are seen as an important tool for diagnosing lung lesions however manual segmentation of infected areas in ct images is timeconsuming and laborious with its excellent feature extraction capabilities a deep learningbased method has been widely used for automatic lesion segmentation of covid19 ct images however the segmentation accuracy of these methods is still limited to effectively quantify the severity of lung infections we propose a sobel operator combined with multiattention networks for covid19 lesion segmentation smanet in our smanet method an edge feature fusion module uses the sobel operator to add edge detail information to the input image to guide the network to focus on key regions smanet introduces a selfattentive channel attention mechanism and a spatial linear attention mechanism in addition the tversky loss function is adopted for the segmentation network for small lesions comparative experiments on covid19 public datasets show that the average dice similarity coefficient dsc and joint intersection over union iou of the proposed smanet model are 861 and 778 respectively which are better than those in most existing segmentation networks",Lung
A Comparative Study of Automated Deep Learning Segmentation Models for Prostate MRI,https://doi.org/10.3390/cancers15051467,2023,"prostate cancer is one of the most common forms of cancer globally affecting roughly one in every eight men according to the american cancer society although the survival rate for prostate cancer is significantly high given the very high incidence rate there is an urgent need to improve and develop new clinical aid systems to help detect and treat prostate cancer in a timely manner in this retrospective study our contributions are twofold first we perform a comparative unified study of different commonly used segmentation models for prostate gland and zone peripheral and transition segmentation second we present and evaluate an additional research question regarding the effectiveness of using an object detector as a preprocessing step to aid in the segmentation process we perform a thorough evaluation of the deep learning models on two public datasets where one is used for crossvalidation and the other as an external test set overall the results reveal that the choice of model is relatively inconsequential as the majority produce nonsignificantly different scores apart from nnunet which consistently outperforms others and that the models trained on data cropped by the object detector often generalize better despite performing worse during crossvalidation",Prostate
Dual-Branch TransV-Net for 3D Echocardiography Segmentation,https://doi.org/10.1109/tii.2023.3249904,2023,"segmentation of left and right ventricles from 3d echocardiographic images is premised and key for quantitative analysis of cardiac function which is important for pediatric cardiac diagnosis compared with 2d echocardiography 3d echocardiography can fully represent ventricular structure without geometric inference however it usually takes experts several hours to obtain a 3d segmentation mask of the left and right ventricles therefore a fast and automatic segmentation method is highly desired unfortunately 3d echocardiography suffers from low contrast unclear left and right ventricles borders and blind zone existing segmentation methods usually have poor performance at ventricular boundaries to deal with these problems we propose a novel dualbranch transvnet dbtv dbtv comprises two parallel interleaved and relatively independent vshaped encoderdecoder branches the main branch acts on the original data to extract image features and the auxiliary branch acts on edge maps to extract the additional edge features to suppress noise and enhance the edge information extra concatenations are added to bridge the features from the main and auxiliary branches to reduce object missing caused by blind zone a 3d transformerbased module is proposed in the bottom layer of the dualbranch structure to extract the global contexts we do experiments on a selfcollected dataset with 120 3d echocardiographic images from 60 cardiac sequences and the dice score of 0913 and 0880 are obtained in the left and right ventricle segments respectively each inference takes about twothirds of a second for a single 3d frame",Cardiac
3D PETCT Tumor Lesion Segmentation via GCN Refinement,https://doi.org/10.48550/arxiv.2302.12571,2023,"wholebody petct scan is an important tool for diagnosing various malignancies eg malignant melanoma lymphoma or lung cancer and accurate segmentation of tumors is a key part for subsequent treatment in recent years cnnbased segmentation methods have been extensively investigated however these methods often give inaccurate segmentation results such as oversegmentation and undersegmentation therefore to address such issues we propose a postprocessing method based on a graph convolutional neural network gcn to refine inaccurate segmentation parts and improve the overall segmentation accuracy firstly nnunet is used as an initial segmentation framework and the uncertainty in the segmentation results is analyzed certainty and uncertainty nodes establish the nodes of a graph neural network each node and its 6 neighbors form an edge and 32 nodes are randomly selected for uncertain nodes to form edges the highly uncertain nodes are taken as the subsequent refinement targets secondly the nnunet result of the certainty nodes is used as label to form a semisupervised graph network problem and the uncertainty part is optimized through training the gcn network to improve the segmentation performance this describes our proposed nnunetgcn segmentation framework we perform tumor segmentation experiments on the petct dataset in the miccia2022 autopet challenge among them 30 cases are randomly selected for testing and the experimental results show that the false positive rate is effectively reduced with nnunetgcn refinement in quantitative analysis there is an improvement of 212 on the average dice score 634 on 95 hausdorff distance hd95 and 172 on average symmetric surface distance assd the quantitative and qualitative evaluation results show that gcn postprocessing methods can effectively improve tumor segmentation performance",Lung
SIFT-GVF-based lung edge correction method for correcting the lung region in CT images,https://doi.org/10.1371/journal.pone.0282107,2023,"juxtapleural nodules were excluded from the segmented lung region in the hounsfield unit thresholdbased segmentation method to reinclude those regions in the lung region a new approach was presented using scaleinvariant feature transform and gradient vector flow models in this study first the scaleinvariant feature transform method was utilized to detect all scaleinvariant points in the binary lung region the boundary points in the neighborhood of a scaleinvariant point were collected to form the supportive boundary lines then we utilized a fourier descriptor to obtain a character representation of each supportive boundary line spectrum energy recognizes supportive boundaries that must be corrected third the gradient vector flowsnake method was presented to correct the recognized supportive borders with a smooth profile curve giving an ideal correction edge in those regions finally the performance of the proposed method was evaluated through experiments on multiple authentic computed tomography images the perfect results and robustness proved that the proposed method could correct the juxtapleural region precisely",Lung
A computer vision pipeline for fully automated echocardiogram interpretation,https://doi.org/10.36828/szxf7275,2023,"cardiovascular disease is the leading cause of global mortality and continues to place a significant burden in economic and resource terms upon health services a 2dimensional transthoracic echocardiogram captures high spatial and temporal images and videos of the heart and is the modality of choice for the rapid assessment of heart function and structure due to its noninvasive nature and lack of ionising radiation the challenging process of analysing echocardiographic images is currently manually performed by trained experts though this process is vulnerable to intra and interobserver variability and is highly timeconsuming additionally echocardiographic images suffer from varying degrees of noise and vary drastically in terms of image quality exponential advancements in the fields of artificial intelligence deep learning and computer vision have enabled the rapid development of automated systems capable of highprecision tasks often outperforming human experts this thesis aims to investigate the applicability of applying deep learning methods to automate key processes in the modern echocardiographic laboratory namely view classification quality assessment cardiac phase detection segmentation of the left ventricle and keypoint detection on tissue doppler imaging strips stateoftheart deep learning architectures were applied to each task and evaluated against groundtruth annotations provided by trained experts the datasets used throughout each chapter are diverse and in some cases have been made public for the benefit of the research community to encourage transparency and openness all code and model weights have been published should automated deep learning systems both online in terms of providing realtime feedback and offline behind the scenes become integrated within clinical practice there is great potential for improved accuracy and efficiency thus improving patient outcomes furthermore health services could save valuable resources such as time and money",Cardiac
An efficient Berkeley’s wavelet convolutional transfer learning and local binary Gabor fuzzy C-means clustering for brain tumour detection,https://doi.org/10.1080/13682199.2023.2166805,2023,"manual diagnosis of brain tumour tissues is particularly labourintensive as well as operatordependent due to the intricacy of brain tissue traditional approaches are ineffective in the presence of these effects necessitating the assessment of the photographs by professionals who can identify them this research proposes a novel technique in brain tumour detection based on segmentation with classification utilizing dl architectures here input has been collected as various brain slice image datasets initially this image has been processed for resizing and smoothening and this image has been segmented the segmentation has been carried out using local binary gabor fuzzy cmeans clustering then the segmented image has been classified for spotting the tumour using berkeleys wavelet convolutional transfer learning based on the accuracy sensitivity specificity jaccards coefficient spatial overlap avme and fom the creative outcome of the approach used was evaluated",Brain
CXLSeg Dataset: Chest X-ray with Lung Segmentation,https://doi.org/10.1109/cymaen57228.2023.10050951,2023,"with the advancement of robust deep learning techniques a significant number of applications pertaining to biomedical research and clinical practice can be noticed within the computer vision domain radiologists use chest xray cxr images prominent among medical imaging to diagnose and treat diseases proper anatomical segmentation of cxr images is increasingly valuable as a critical image preprocessing step as well as in interpreting the deep learning models since it isolates the necessary area by extracting the region of interest this paper proposes a cxrsegmented dataset based on the mimiccxr dataset a total of 243324 frontal views of cxr images with segmented masks for each image are available in the dataset a unet model with spatial attention saunet architecture is utilized for segmenting the cxr images after a comparative analysis of different unet variants the saunet model achieved a 9680 in dice similarity coefficient and 9197 in iou for lung segmentation this study has shown that the visual feature extraction process is optimized using segmented cxr radiographs of cxlseg instead of original mimiccxr images by a significant margin",Lung
MCSC-Net: COVID-19 detection using deep-Q-neural network classification with RFNN-based hybrid whale optimization,https://doi.org/10.3233/xst-221360,2023,"background covid19 is the most dangerous virus and its accurate diagnosis saves lives and slows its spread however covid19 diagnosis takes time and requires trained professionals therefore developing a deep learning dl model on lowradiated imaging modalities like chest xrays cxrs is needed objective the existing dl models failed to diagnose covid19 and other lung diseases accurately this study implements a multiclass cxr segmentation and classification network mcscnet to detect covid19 using cxr images methods initially a hybrid median bilateral filter hmbf is applied to cxr images to reduce image noise and enhance the covid19 infected regions then a skip connectionbased residual network50 scresnet50 is used to segment localize covid19 regions the features from cxrs are further extracted using a robust feature neural network rfnn since the initial features contain joint covid19 normal pneumonia bacterial and viral properties the conventional methods fail to separate the class of each diseasebased feature to extract the distinct features of each class rfnn includes a diseasespecific feature separate attention mechanism dsfsam furthermore the hunting nature of the hybrid whale optimization algorithm hwoa is used to select the best features in each class finally the deepqneural network dqnn classifies cxrs into multiple disease classes results the proposed mcscnet shows the enhanced accuracy of 9909 for 2class 9916 for 3class and 9925 for 4class classification of cxr images compared to other stateofart approaches conclusion the proposed mcscnet enables to conduct multiclass segmentation and classification tasks applying to cxr images with high accuracy thus together with goldstandard clinical and laboratory tests this new method is promising to be used in future clinical practice to evaluate patients",Lung
Segmentation of brain tumor subregions with depthwise separable dense U‐NET (DSDU‐NET),https://doi.org/10.1002/ima.22861,2023,"brain tumors are one of the most dangerous medical conditions the dispersed extremities and nonuniform structure of the tumors are the basis of why techniques of traditional segmentation have grown to be inefficient magnetic resonance imaging mri is one of the most widely used scanning procedures for tumors however to ameliorate the survival rate the detection of tumors alone does not suffice and there are other effective procedures one of the most pivotal procedures for diagnosing the condition is the process of the brain tumor segmentation is a laborious and cumbersome process as a result a deep learning dl based solution is used to extract tumor subregions like enhancing tumor et tumor core tc and whole tumor wt the proposed model involves novel dsdunet depthwise separable dense unet dsdunet that precise outputs are acquired by retaining the lowlevel features in the preprocessing stage a methodology called multiscale patch extraction is used to segregate tumor regions and a grouping of gaussian filter unsharp masking and histogram equalization is carried out on the data set to get significantly better performance the proposed dsdunet network performed better in terms of performance specificity sensitivity dice similarity index and hausdorff distance for segmented image subregions when validated on brats 2018 and 2019 data sources when particularly in comparison to other models",Brain
Segmentation of brain tumor subregions with depthwise separable dense U‐NET (DSDU‐NET),https://doi.org/10.1002/ima.22861,2023,"brain tumors are one of the most dangerous medical conditions the dispersed extremities and nonuniform structure of the tumors are the basis of why techniques of traditional segmentation have grown to be inefficient magnetic resonance imaging mri is one of the most widely used scanning procedures for tumors however to ameliorate the survival rate the detection of tumors alone does not suffice and there are other effective procedures one of the most pivotal procedures for diagnosing the condition is the process of the brain tumor segmentation is a laborious and cumbersome process as a result a deep learning dl based solution is used to extract tumor subregions like enhancing tumor et tumor core tc and whole tumor wt the proposed model involves novel dsdunet depthwise separable dense unet dsdunet that precise outputs are acquired by retaining the lowlevel features in the preprocessing stage a methodology called multiscale patch extraction is used to segregate tumor regions and a grouping of gaussian filter unsharp masking and histogram equalization is carried out on the data set to get significantly better performance the proposed dsdunet network performed better in terms of performance specificity sensitivity dice similarity index and hausdorff distance for segmented image subregions when validated on brats 2018 and 2019 data sources when particularly in comparison to other models",Brain
SAN-Net: Learning generalization to unseen sites for stroke lesion segmentation with self-adaptive normalization,https://doi.org/10.1016/j.compbiomed.2023.106717,2023,"there are considerable interests in automatic stroke lesion segmentation on magnetic resonance mr images in the medical imaging field as stroke is an important cerebrovascular disease although deep learningbased models have been proposed for this task generalizing these models to unseen sites is difficult due to not only the large intersite discrepancy among different scanners imaging protocols and populations but also the variations in stroke lesion shape size and location to tackle this issue we introduce a selfadaptive normalization network termed sannet to achieve adaptive generalization on unseen sites for stroke lesion segmentation motivated by traditional zscore normalization and dynamic network we devise a masked adaptive instance normalization main to minimize intersite discrepancies which standardizes input mr images from different sites into a siteunrelated style by dynamically learning affine parameters from the input ie main can affinely transform the intensity values then we leverage a gradient reversal layer to force the unet encoder to learn siteinvariant representation with a site classifier which further improves the model generalization in conjunction with main finally inspired by the pseudosymmetry of the human brain we introduce a simple yet effective data augmentation technique termed symmetryinspired data augmentation sida that can be embedded within sannet to double the sample size while halving memory consumption experimental results on the benchmark anatomical tracings of lesions after stroke atlas v12 dataset which includes mr images from 9 different sites demonstrate that under the leaveonesiteout setting the proposed sannet outperforms recently published methods in terms of quantitative metrics and qualitative comparisons",Brain
Deep Learning Algorithms with LIME and Similarity Distance Analysis on COVID-19 Chest X-ray Dataset,https://doi.org/10.3390/ijerph20054330,2023,"in the last few years many types of research have been conducted on the most harmful pandemic covid19 machine learning approaches have been applied to investigate chest xrays of covid19 patients in many respects this study focuses on the deep learning algorithm from the standpoint of feature space and similarity analysis firstly we utilized local interpretable modelagnostic explanations lime to justify the necessity of the region of interest roi process and further prepared roi via unet segmentation that masked out nonlung areas of images to prevent the classifier from being distracted by irrelevant features the experimental results were promising with detection performance reaching an overall accuracy of 955 a sensitivity of 984 a precision of 947 and an f1 score of 965 on the covid19 category secondly we applied similarity analysis to identify outliers and further provided an objective confidence reference specific to the similarity distance to centers or boundaries of clusters while inferring finally the experimental results suggested putting more effort into enhancing the lowaccuracy subspace locally which is identified by the similarity distance to the centers the experimental results were promising and based on those perspectives our approach could be more flexible to deploy dedicated classifiers specific to different subspaces instead of one rigid endtoend black box model for all feature space",Lung
Prediction of the Topography of the Corticospinal Tract on T1-Weighted MR Images Using Deep-Learning-Based Segmentation,https://doi.org/10.3390/diagnostics13050911,2023,"introduction tractography is an invaluable tool in the planning of tumor surgery in the vicinity of functionally eloquent areas of the brain as well as in the research of normal development or of various diseases the aim of our study was to compare the performance of a deeplearningbased image segmentation for the prediction of the topography of white matter tracts on t1weighted mr images to the performance of a manual segmentation methods t1weighted mr images of 190 healthy subjects from 6 different datasets were utilized in this study using deterministic diffusion tensor imaging we first reconstructed the corticospinal tract on both sides after training a segmentation model on 90 subjects of the piop2 dataset using the nnunet in a cloudbased environment with graphical processing unit google colab we evaluated its performance using 100 subjects from 6 different datasets results our algorithm created a segmentation model that predicted the topography of the corticospinal pathway on t1weighted images in healthy subjects the average dice score was 05479 0351307184 on the validation dataset conclusions deeplearningbased segmentation could be applicable in the future to predict the location of white matter pathways in t1weighted scans",Brain
CKD-TransBTS: Clinical Knowledge-Driven Hybrid Transformer with Modality-Correlated Cross-Attention for Brain Tumor Segmentation,https://doi.org/10.1109/tmi.2023.3250474,2023,"brain tumor segmentation bts in magnetic resonance image mri is crucial for brain tumor diagnosis cancer management and research purposes with the great success of the tenyear brats challenges as well as the advances of cnn and transformer algorithms a lot of outstanding bts models have been proposed to tackle the difficulties of bts in different technical aspects however existing studies hardly consider how to fuse the multimodality images in a reasonable manner in this paper we leverage the clinical knowledge of how radiologists diagnose brain tumors from multiple mri modalities and propose a clinical knowledgedriven brain tumor segmentation model called ckdtransbts instead of directly concatenating all the modalities we reorganize the input modalities by separating them into two groups according to the imaging principle of mri a dualbranch hybrid encoder with the proposed modalitycorrelated crossattention block mcca is designed to extract the multimodality image features the proposed model inherits the strengths from both transformer and cnn with the local feature representation ability for precise lesion boundaries and longrange feature extraction for 3d volumetric images to bridge the gap between transformer and cnn features we propose a transcnn feature calibration block tcfc in the decoder we compare the proposed model with six cnnbased models and six transformerbased models on the brats 2021 challenge dataset extensive experiments demonstrate that the proposed model achieves stateoftheart brain tumor segmentation performance compared with all the competitors",Brain
CKD-TransBTS: Clinical Knowledge-Driven Hybrid Transformer with Modality-Correlated Cross-Attention for Brain Tumor Segmentation,https://doi.org/10.1109/tmi.2023.3250474,2023,"brain tumor segmentation bts in magnetic resonance image mri is crucial for brain tumor diagnosis cancer management and research purposes with the great success of the tenyear brats challenges as well as the advances of cnn and transformer algorithms a lot of outstanding bts models have been proposed to tackle the difficulties of bts in different technical aspects however existing studies hardly consider how to fuse the multimodality images in a reasonable manner in this paper we leverage the clinical knowledge of how radiologists diagnose brain tumors from multiple mri modalities and propose a clinical knowledgedriven brain tumor segmentation model called ckdtransbts instead of directly concatenating all the modalities we reorganize the input modalities by separating them into two groups according to the imaging principle of mri a dualbranch hybrid encoder with the proposed modalitycorrelated crossattention block mcca is designed to extract the multimodality image features the proposed model inherits the strengths from both transformer and cnn with the local feature representation ability for precise lesion boundaries and longrange feature extraction for 3d volumetric images to bridge the gap between transformer and cnn features we propose a transcnn feature calibration block tcfc in the decoder we compare the proposed model with six cnnbased models and six transformerbased models on the brats 2021 challenge dataset extensive experiments demonstrate that the proposed model achieves stateoftheart brain tumor segmentation performance compared with all the competitors",Brain
Deep Learning-based Multi-Organ CT Segmentation with Adversarial Data  Augmentation,https://doi.org/10.48550/arxiv.2302.13172,2023,"in this work we propose an adversarial attackbased data augmentation method to improve the deeplearningbased segmentation algorithm for the delineation of organsatrisk oar in abdominal computed tomography ct to facilitate radiation therapy we introduce adversarial feature attack for medical image afami augmentation which forces the segmentation network to learn outofdistribution statistics and improve generalization and robustness to noises afami augmentation consists of three steps 1 generate adversarial noises by fast gradient sign method fgsm on the intermediate features of the segmentation networks encoder 2 inject the generated adversarial noises into the network intentionally compromising performance 3 optimize the network with both clean and adversarial features experiments are conducted segmenting the heart left and right kidney liver left and right lung spinal cord and stomach we first evaluate the afami augmentation using nnunet and ttvnet on the test data from a public abdominal dataset and an institutional dataset in addition we validate how afami affects the networks robustness to the noisy data by evaluating the networks with added gaussian noises of varying magnitudes to the institutional dataset network performance is quantitatively evaluated using dice similarity coefficient dsc for volumebased accuracy also hausdorff distance hd is applied for surfacebased accuracy on the public dataset nnunet with afami achieves dsc 085 and hd 616 millimeters mm and ttvnet achieves dsc 086 and hd 562 mm afami augmentation further improves all contour accuracies up to 0217 dsc score when tested on images with gaussian noises afami augmentation is therefore demonstrated to improve segmentation performance and robustness in ct multiorgan segmentation",Lung
MPS-AMS: Masked Patches Selection and Adaptive Masking Strategy Based  Self-Supervised Medical Image Segmentation,https://doi.org/10.48550/arxiv.2302.13699,2023,"existing selfsupervised learning methods based on contrastive learning and masked image modeling have demonstrated impressive performances however current masked image modeling methods are mainly utilized in natural images and their applications in medical images are relatively lacking besides their fixed high masking strategy limits the upper bound of conditional mutual information and the gradient noise is considerable making less the learned representation information motivated by these limitations in this paper we propose masked patches selection and adaptive masking strategy based selfsupervised medical image segmentation method named mpsams we leverage the masked patches selection strategy to choose masked patches with lesions to obtain more lesion representation information and the adaptive masking strategy is utilized to help learn more mutual information and improve performance further extensive experiments on three public medical image segmentation datasets busi hecktor and brats2018 show that our proposed method greatly outperforms the stateoftheart selfsupervised baselines",Brain
EDMAE: An Efficient Decoupled Masked Autoencoder for Standard View  Identification in Pediatric Echocardiography,https://doi.org/10.48550/arxiv.2302.13869,2023,"an efficient decoupled masked autoencoder edmae which is a novel selfsupervised method is proposed for standard view recognition in pediatric echocardiography in this paper the proposed edmae based on the encoderdecoder structure forms a new proxy task the decoder of edmae consists of a teacher encoder and a student encoder in which the teacher encoder extracts the latent representation of the masked image blocks while the student encoder extracts the latent representation of the visible image blocks a loss is calculated between the feature maps output from two encoders to ensure consistency in the latent representations they extracted edmae replaces the vit structure in the encoder of traditional mae with pure convolution operation to improve training efficiency edmae is pretrained in a selfsupervised manner on a largescale private dataset of pediatric echocardiography and then finetuned on the downstream task of standard view recognition the high classification accuracy is achieved in 27 standard views of pediatric echocardiography to further validate the effectiveness of the proposed method another downstream task of cardiac ultrasound segmentation is performed on a public dataset camus the experiments show that the proposed method not only can surpass some recent supervised methods but also has more competitiveness on different downstream tasks",Cardiac
Deep learning based dominant index lesion segmentation for mr‐guided radiation therapy of prostate cancer,https://doi.org/10.1002/mp.16320,2023,"background dose escalation radiotherapy enables increased control of prostate cancer pca but requires segmentation of dominant index lesions dil this motivates the development of automated methods for fast accurate and consistent segmentation of pca dil purpose to construct and validate a model for deeplearningbased automatic segmentation of pca dil defined by gleason score gs 34 from mr images applied to mrguided radiation therapy validate generalizability of constructed models across scanner and acquisition differences methods five deeplearning networks were evaluated on apparent diffusion coefficient adc mri from 500 lesions in 365 patients arising from internal training dataset 1 156 lesions in 125 patients 15tesla ge mr with endorectal coil testing using dataset 1 35 lesions in 26 patients external prostatex dataset 2 299 lesions in 204 patients 3tesla siemens mr and internal interrater dataset 3 10 lesions in 10 patients 3tesla philips mr the five networks include multiple resolution residually connected network mrrn and mrrn regularized in training with deep supervision implemented into the last convolutional block mrrnds unet unet resunet and fast panoptic segmentation fpsnet as well as fast panoptic segmentation with smoothed labels fpsnetsl models were evaluated by volumetric dil segmentation accuracy using dice similarity coefficient dsc and the balanced f1 measure of detection accuracy as a function of lesion aggressiveness and size dataset 1 and 2 and accuracy with respect to tworaters on dataset 3 upon acceptance for publication segmentation models will be made available in an opensource github repository results in general mrrnds more accurately segmented tumors than other methods on the testing datasets mrrnds significantly outperformed resunet in dataset2 dsc of 054 vs 044 p0001 and the unet in dataset3 dsc of 045 vs p 004 fpsnetsl was similarly accurate as mrrnds in dataset2 p 030 but mrrnds significantly outperformed fpsnet and fpsnetsl in both dataset1 060 vs 051 p 001 and 054 p 0049 respectively and dataset3 045 vs 006 p 0002 and 024 p 0004 respectively finally mrrnds produced slightly higher agreement with experienced radiologist than two radiologists in dataset 3 dsc of 045 vs 041 conclusions mrrnds was generalizable to different mr testing datasets acquired using different scanners it produced slightly higher agreement with an experienced radiologist than that between two radiologists finally mrrnds more accurately segmented aggressive lesions which are generally candidates for radiative dose ablation this article is protected by copyright all rights reserved",Prostate
Deep learning based dominant index lesion segmentation for mr‐guided radiation therapy of prostate cancer,https://doi.org/10.1002/mp.16320,2023,"background dose escalation radiotherapy enables increased control of prostate cancer pca but requires segmentation of dominant index lesions dil this motivates the development of automated methods for fast accurate and consistent segmentation of pca dil purpose to construct and validate a model for deeplearningbased automatic segmentation of pca dil defined by gleason score gs 34 from mr images applied to mrguided radiation therapy validate generalizability of constructed models across scanner and acquisition differences methods five deeplearning networks were evaluated on apparent diffusion coefficient adc mri from 500 lesions in 365 patients arising from internal training dataset 1 156 lesions in 125 patients 15tesla ge mr with endorectal coil testing using dataset 1 35 lesions in 26 patients external prostatex dataset 2 299 lesions in 204 patients 3tesla siemens mr and internal interrater dataset 3 10 lesions in 10 patients 3tesla philips mr the five networks include multiple resolution residually connected network mrrn and mrrn regularized in training with deep supervision implemented into the last convolutional block mrrnds unet unet resunet and fast panoptic segmentation fpsnet as well as fast panoptic segmentation with smoothed labels fpsnetsl models were evaluated by volumetric dil segmentation accuracy using dice similarity coefficient dsc and the balanced f1 measure of detection accuracy as a function of lesion aggressiveness and size dataset 1 and 2 and accuracy with respect to tworaters on dataset 3 upon acceptance for publication segmentation models will be made available in an opensource github repository results in general mrrnds more accurately segmented tumors than other methods on the testing datasets mrrnds significantly outperformed resunet in dataset2 dsc of 054 vs 044 p0001 and the unet in dataset3 dsc of 045 vs p 004 fpsnetsl was similarly accurate as mrrnds in dataset2 p 030 but mrrnds significantly outperformed fpsnet and fpsnetsl in both dataset1 060 vs 051 p 001 and 054 p 0049 respectively and dataset3 045 vs 006 p 0002 and 024 p 0004 respectively finally mrrnds produced slightly higher agreement with experienced radiologist than two radiologists in dataset 3 dsc of 045 vs 041 conclusions mrrnds was generalizable to different mr testing datasets acquired using different scanners it produced slightly higher agreement with an experienced radiologist than that between two radiologists finally mrrnds more accurately segmented aggressive lesions which are generally candidates for radiative dose ablation this article is protected by copyright all rights reserved",Prostate
A task-unified network with transformer and spatial-temporal convolution for left ventricular quantification,https://doi.org/10.21203/rs.3.rs-2590069/v1,2023,"abstract quantification of the cardiac function is vital for diagnosing and curing the cardiovascular diseases left ventricular function measurement is the most commonly used measure to evaluate the function of cardiac in clinical practice how to improve the accuracy of left ventricular quantitative assessment results has always been the subject of research by medical researchers although considerable efforts have been put forward to measure the left ventricle lv automatically using deep learning methods the accurate quantification is yet a challenge work as a result of the changeable anatomy structure of heart in the systolic diastolic cycle besides most methods used direct regression method which lacks of visual based analysis in this work a deep learning segmentation and regression taskunified network with transformer and spatialtemporal convolution was proposed to segment and quantify the lv simultaneously the segmentation module leveraged a unet like 3d transformer model to predict the contour of three anatomy structures while the regression module learned spatialtemporal representations from the original images and the reconstruct feature maps from segmentation path to estimate the fifinally desired quantification metrics furthermore we employed a joint task loss function to train the two module networks our framework is evaluated on the miccai 2017 left ventricle full quantification challenge dataset the results of experiments demonstrate the effectiveness of our framework which achieves competitive cardiac quantification metric results and at the same time produces visualized segmentation results that are conducive to later analysis",Cardiac
Self-Supervised Wavelet-Based Attention Network for Semantic Segmentation of MRI Brain Tumor,https://doi.org/10.3390/s23052719,2023,"to determine the appropriate treatment plan for patients radiologists must reliably detect brain tumors despite the fact that manual segmentation involves a great deal of knowledge and ability it may sometimes be inaccurate by evaluating the size location structure and grade of the tumor automatic tumor segmentation in mri images aids in a more thorough analysis of pathological conditions due to the intensity differences in mri images gliomas may spread out have low contrast and are therefore difficult to detect as a result segmenting brain tumors is a challenging process in the past several methods for segmenting brain tumors in mri scans were created however because of their susceptibility to noise and distortions the usefulness of these approaches is limited selfsupervised wavele based attention network sswan a new attention module with adjustable selfsupervised activation functions and dynamic weights is what we suggest as a way to collect global context information in particular this networks input and labels are made up of four parameters produced by the twodimensional 2d wavelet transform which makes the training process simpler by neatly segmenting the data into lowfrequency and highfrequency channels to be more precise we make use of the channel attention and spatial attention modules of the selfsupervised attention block ssab as a result this method may more easily zero in on crucial underlying channels and spatial patterns the suggested sswan has been shown to outperform the current stateoftheart algorithms in medical image segmentation tasks with more accuracy more promising dependability and less unnecessary redundancy",Brain
An Open-Source Tool for Longitudinal Whole-Brain and White Matter Lesion Segmentation,https://doi.org/10.1016/j.nicl.2023.103354,2023,"in this paper we describe and validate a longitudinal method for wholebrain segmentation of longitudinal mri scans it builds upon an existing wholebrain segmentation method that can handle multicontrast data and robustly analyze images with white matter lesions this method is here extended with subjectspecific latent variables that encourage temporal consistency between its segmentation results enabling it to better track subtle morphological changes in dozens of neuroanatomical structures and white matter lesions we validate the proposed method on multiple datasets of control subjects and patients suffering from alzheimers disease and multiple sclerosis and compare its results against those obtained with its original crosssectional formulation and two benchmark longitudinal methods the results indicate that the method attains a higher testretest reliability while being more sensitive to longitudinal disease effect differences between patient groups an implementation is publicly available as part of the opensource neuroimaging package freesurfer",Brain
Hybrid Multilevel Thresholding Image Segmentation Approach for Brain MRI,https://doi.org/10.3390/diagnostics13050925,2023,"a brain tumor is an abnormal growth of tissues inside the skull that can interfere with the normal functioning of the neurological system and the body and it is responsible for the deaths of many individuals every year magnetic resonance imaging mri techniques are widely used for detection of brain cancers segmentation of brain mri is a foundational process with numerous clinical applications in neurology including quantitative analysis operational planning and functional imaging the segmentation process classifies the pixel values of the image into different groups based on the intensity levels of the pixels and a selected threshold value the quality of the medical image segmentation extensively depends on the method which selects the threshold values of the image for the segmentation process the traditional multilevel thresholding methods are computationally expensive since these methods thoroughly search for the best threshold values to maximize the accuracy of the segmentation process metaheuristic optimization algorithms are widely used for solving such problems however these algorithms suffer from the problem of local optima stagnation and slow convergence speed in this work the original bald eagle search bes algorithm problems are resolved in the proposed dynamic opposite bald eagle search dobes algorithm by employing dynamic opposition learning dol at the initial as well as exploitation phases using the dobes algorithm a hybrid multilevel thresholding image segmentation approach has been developed for mri image segmentation the hybrid approach is divided into two phases in the first phase the proposed dobes optimization algorithm is used for the multilevel thresholding after the selection of the thresholds for the image segmentation the morphological operations have been utilized in the second phase to remove the unwanted area present in the segmented image the performance efficiency of the proposed dobes based multilevel thresholding algorithm with respect to bes has been verified using the five benchmark images the proposed dobes based multilevel thresholding algorithm attains higher peak signaltonoise ratio psnr and structured similarity index measure ssim value in comparison to the bes algorithm for the benchmark images additionally the proposed hybrid multilevel thresholding segmentation approach has been compared with the existing segmentation algorithms to validate its significance the results show that the proposed algorithm performs better for tumor segmentation in mri images as the ssim value attained using the proposed hybrid segmentation approach is nearer to 1 when compared with ground truth images",Brain
Unsupervised Pathology Detection: A Deep Dive Into the State of the Art,https://doi.org/10.48550/arxiv.2303.00609,2023,"deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology as the unsupervised anomaly detection uad literature continuously grows and new paradigms emerge it is vital to continuously evaluate and benchmark new methods in a common framework in order to reassess the stateoftheart sota and identify promising research directions to this end we evaluate a diverse selection of cuttingedge uad methods on multiple medical datasets comparing them against the established sota in uad for brain mri our experiments demonstrate that newly developed featuremodeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new sota in a variety of modalities and datasets additionally we show that such methods are capable of benefiting from recently developed selfsupervised pretraining algorithms further increasing their performance finally we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets our code can be found under httpsgithubcomiolagupdstudy",Brain
Need for objective task-based evaluation of AI-based segmentation methods for quantitative PET.,None,2023,"artificial intelligence aibased methods are showing substantial promise in segmenting oncologic positron emission tomography pet images for clinical translation of these methods assessing their performance on clinically relevant tasks is important however these methods are typically evaluated using metrics that may not correlate with the task performance one such widely used metric is the dice score a figure of merit that measures the spatial overlap between the estimated segmentation and a reference standard eg manual segmentation in this work we investigated whether evaluating aibased segmentation methods using dice scores yields a similar interpretation as evaluation on the clinical tasks of quantifying metabolic tumor volume mtv and total lesion glycolysis tlg of primary tumor from pet images of patients with nonsmall cell lung cancer the investigation was conducted via a retrospective analysis with the ecogacrin 6668rtog 0235 multicenter clinical trial data specifically we evaluated different structures of a commonly used aibased segmentation method using both dice scores and the accuracy in quantifying mtvtlg our results show that evaluation using dice scores can lead to findings that are inconsistent with evaluation using the taskbased figure of merit thus our study motivates the need for objective taskbased evaluation of aibased segmentation methods for quantitative pet",Lung
Clinically Relevant Myocardium Segmentation in Cardiac Magnetic Resonance Images,https://doi.org/10.1109/jbhi.2023.3250429,2023,"deep learning approaches have shown great success in myocardium region segmentation in cardiac mr cmr images however most of these often ignore irregularities such as protrusions breaks in contour etc as a result the common practice by clinicians is to manually correct the obtained outputs for the evaluation of myocardium condition this paper aims to make the deep learning systems capable of handling the aforementioned irregularities and satisfy desired clinical constraints necessary for various downstream clinical analysis we propose a refinement model which imposes structural constraints on the outputs of the existing deep learningbased myocardium segmentation methods the complete system is a pipeline of deep neural networks where an initial network performs myocardium segmentation as accurate as possible and the refinement network removes defects from the initial output to make it suitable for clinical decision support systems we experiment with datasets collected from four different sources and observe consistent final segmentation outputs with improvement up to 8 in dice coefficient and up to 18 pixels in hausdorff distance due to the proposed refinement model the proposed refinement strategy leads to qualitative and quantitative improvements in the performances of all the considered segmentation networks our work is an important step towards the development of a fully automatic myocardium segmentation system it can also be generalized for other tasks where the object of interest has regular structure and the defects can be modelled statistically",Cardiac
Segmentation of Pericardial Adipose Tissue in CMR Images: a Benchmark Dataset MRPEAT and a Triple-Stage Network 3SUnet,https://doi.org/10.1109/tmi.2023.3251368,2023,"increased pericardial adipose tissue peat is associated with a series of cardiovascular diseases cvds and metabolic syndromes quantitative analysis of peat by means of image segmentation is of great significance although cardiovascular magnetic resonance cmr has been utilized as a routine method for noninvasive and nonradioactive cvd diagnosis segmentation of peat in cmr images is challenging and laborious in practice no public cmr datasets are available for validating peat automatic segmentation therefore we first release a benchmark cmr dataset mrpeat which consists of cardiac short axis sa cmr images from 50 hypertrophic cardiomyopathy hcm 50 acute myocardial infarction ami and 50 normal control nc subjects we then propose a deep learning model named as 3sunet to segment peat on mrpeat to tackle the challenges that peat is relatively small and diverse and its intensities are hard to distinguish from the background the 3sunet is a triplestage network of which the backbones are all unet one unet is used to extract a region of interest roi for any given image with ventricles and peat being contained completely using a multitask continual learning strategy another unet is adopted to segment peat in roicropped images the third unet is utilized to refine peat segmentation accuracy guided by an image adaptive probability map the proposed model is qualitatively and quantitatively compared with the stateoftheart models on the dataset we obtain the peat segmentation results through 3sunet assess the robustness of 3sunet under different pathological conditions and identify the imaging indications of peat in cvds italic xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkthe dataset and all source codes are available ati httpsdflagneugithubiomembercszresearch",Cardiac
BrainLine: An Open Pipeline for Connectivity Analysis of Heterogeneous Whole-Brain Fluorescence Volumes,https://doi.org/10.1101/2023.02.28.530429,2023,"wholebrain fluorescence images require several stages of computational processing to fully reveal the neuron morphology and connectivity information they contain however these computational tools are rarely part of an integrated pipeline here we present brainline an opensource pipeline that interfaces with existing software to provide registration axon segmentation soma detection visualization and analysis of results by implementing a feedback based training paradigm with brainline we were able to use a single learning algorithm to accurately process a diverse set of wholebrain images generated by lightsheet microscopy brainline is available as part of our python package brainlit httpbrainlitneurodataio",Brain
A modality‐collaborative convolution and transformer hybrid network for unpaired multi‐modal medical image segmentation with limited annotations,https://doi.org/10.1002/mp.16338,2023,"multimodal learning is widely adopted to learn the latent complementary information between different modalities in multimodal medical image segmentation tasks nevertheless the traditional multimodal learning methods require spatially wellaligned and paired multimodal images for supervised training which cannot leverage unpaired multimodal images with spatial misalignment and modality discrepancy for training accurate multimodal segmentation networks using easily accessible and lowcost unpaired multimodal images in clinical practice unpaired multimodal learning has received comprehensive attention recentlyexisting unpaired multimodal learning methods usually focus on the intensity distribution gap but ignore the scale variation problem between different modalities besides within existing methods shared convolutional kernels are frequently employed to capture common patterns in all modalities but they are typically inefficient at learning global contextual information on the other hand existing methods highly rely on a large number of labeled unpaired multimodal scans for training which ignores the practical scenario when labeled data is limited to solve the above problems we propose a modalitycollaborative convolution and transformer hybrid network mcthnet using semisupervised learning for unpaired multimodal segmentation with limited annotations which not only collaboratively learns modalityspecific and modalityinvariant representations but also could automatically leverage extensive unlabeled scans for improving performancewe make three main contributions to the proposed method first to alleviate the intensity distribution gap and scale variation problems across modalities we develop a modalityspecific scaleaware convolution mssc module that can adaptively adjust the receptive field sizes and feature normalization parameters according to the input secondly we propose a modalityinvariant vision transformer mivit module as the shared bottleneck layer for all modalities which implicitly incorporates convolutionlike local operations with the global processing of transformers for learning generalizable modalityinvariant representations third we design a multimodal cross pseudo supervision mcps method for semisupervised learning which enforces the consistency between the pseudo segmentation maps generated by two perturbed networks to acquire abundant annotation information from unlabeled unpaired multimodal scansextensive experiments are performed on two unpaired ct and mr segmentation datasets including a cardiac substructure dataset derived from the mmwhs2017 dataset and an abdominal multiorgan dataset consisting of the btcv and chaos datasets experiment results show that our proposed method significantly outperforms other existing stateoftheart methods under various labeling ratios and achieves a comparable segmentation performance close to singlemodal methods with fully labeled data by only leveraging a small portion of labeled data specifically when the labeling ratio is 25 our proposed method achieves overall mean dsc values of 7856 and 7618 in cardiac and abdominal segmentation respectively which significantly improves the average dsc value of two tasks by 1284 compared to singlemodal unet modelsour proposed method is beneficial for reducing the annotation burden of unpaired multimodal medical images in clinical applications",Cardiac
Application of Automatic Segmentation on Super-Resolution Reconstruction MR Images of the Abnormal Fetal Brain,https://doi.org/10.3174/ajnr.a7808,2023,"h3background and purposeh3 fetal brain mr imaging is clinically used to characterize fetal brain abnormalities recently algorithms have been proposed to reconstruct highresolution 3d fetal brain volumes from 2d slices by means of these reconstructions convolutional neural networks have been developed for automatic image segmentation to avoid laborintensive manual annotations usually trained on data of normal fetal brains herein we tested the performance of an algorithm specifically developed for segmentation of abnormal fetal brains h3materials and methodsh3 this was a singlecenter retrospective study on mr images of 16 fetuses with severe cns anomalies gestation 2139 weeks t2weighted 2d slices were converted to 3d volumes using a superresolution reconstruction algorithm the acquired volumetric data were then processed by a novel convolutional neural network to perform segmentations of white matter and the ventricular system and cerebellum these were compared with manual segmentation using the dice coefficient hausdorff distance 95th percentile and volume difference using interquartile ranges we identified outliers of these metrics and further analyzed them in detail h3resultsh3 the mean dice coefficient was 962 937 and 947 for white matter and the ventricular system and cerebellum respectively the hausdorff distance was 11 23 and 16 mm respectively the volume difference was 16 14 and 03 ml respectively of the 126 measurements there were 16 outliers among 5 fetuses discussed on a casebycase basis h3conclusionsh3 our novel segmentation algorithm obtained excellent results on mr images of fetuses with severe brain abnormalities analysis of the outliers shows the need to include pathologies underrepresented in the current data set quality control to prevent occasional errors is still needed",Brain
StereoCell enables high accuracy single cell segmentation for spatial transcriptomic dataset,https://doi.org/10.1101/2023.02.28.530414,2023,"abstract with recent advances in resolution and fieldofview spatially resolved sequencing has emerged as a cuttingedge technology that provides a technical foundation for interpreting large tissues at the spatial singlecell level to handle the highresolution spatial omics dataset with associated images and generate spatial singlecell level gene expression a powerful onestop toolbox is required here we propose stereocell an imagefacilitated cell segmentation framework for highresolution and large fieldofview spatial omics stereocell offers a comprehensive and systematic solution to generating highconfidence spatial singlecell data including image stitching registration nuclei segmentation and molecule labeling in image stitching and molecule labeling stereocell delivers the bestperforming algorithms to reduce stitching error and improve the signaltonoise ratio of singlecell gene expression compared to existing methods meanwhile as demonstrated using mouse brain stereocell has been shown to obtain highaccuracy spatial singlecell data which facilitates clustering and annotation",Brain
Edge-enhancement cascaded network for lung lobe segmentation based on CT images,https://doi.org/10.3389/fphy.2023.1098756,2023,"in order to reduce postoperative complications it is required that the puncture needle should not pass through the lung lobe without tumor as far as possible in lung biopsy surgery therefore it is necessary to accurately segment the lung lobe on the lung ct images this paper proposed an automatic lung lobe segmentation method on lung ct images considering the boundary of the lung lobe is difficult to be identified our lung lobe segmentation network is designed to be a multistage cascade network based on edge enhancement in the first stage the anatomical features of the lung lobe are extracted based on the generative adversarial network gan and the lung lobe boundary is gaussian smoothed to generate the boundary response map in the second stage the ct images and the boundary response map are used as input and the dense connection blocks are used to realize deep feature extraction and finally five lung lobes are segmented the experiments indicated that the average value of dice coefficient is 09741 which meets the clinical needs",Lung
Automated Quantification of Pneumonia Infected Volume in Lung CT Images: A Comparison with Subjective Assessment of Radiologists,https://doi.org/10.3390/bioengineering10030321,2023,"objective to help improve radiologists efficacy of disease diagnosis in reading computed tomography ct images this study aims to investigate the feasibility of applying a modified deep learning dl method as a new strategy to automatically segment diseaseinfected regions and predict disease severity methods we employed a public dataset acquired from 20 covid19 patients which includes manually annotated lung and infections masks to train a new ensembled dl model that combines five customized residual attention unet models to segment disease infected regions followed by a feature pyramid network model to predict disease severity stage to test the potential clinical utility of the new dl model we conducted an observer comparison study first we collected another set of ct images acquired from 80 covid19 patients and process images using the new dl model second we asked two chest radiologists to read images of each ct scan and report the estimated percentage of the diseaseinfected lung volume and disease severity level third we also asked radiologists to rate acceptance of dl modelgenerated segmentation results using a 5scale rating method results data analysis results show that agreement of disease severity classification between the dl model and radiologists is gt90 in 45 testing cases furthermore gt73 of cases received a high rating score 4 from two radiologists conclusion this study demonstrates the feasibility of developing a new dl model to automatically segment diseaseinfected regions and quantitatively predict disease severity which may help avoid tedious effort and interreader variability in subjective assessment of disease severity in future clinical practice",Lung
Computed tomography–based COVID–19 triage through a deep neural network using mask–weighted global average pooling,https://doi.org/10.3389/fcimb.2023.1116285,2023,"background there is an urgent need to find an effective and accurate method for triaging coronavirus disease 2019 covid19 patients from millions or billions of people therefore this study aimed to develop a novel deeplearning approach for covid19 triage based on chest computed tomography ct images including normal pneumonia and covid19 cases methods a total of 2809 chest ct scans 1105 covid19 854 normal and 850 non3covid19 pneumonia cases were acquired for this study and classified into the training set n 2329 and test set n 480 a unetbased convolutional neural network was used for lung segmentation and a maskweighted global average pooling gap method was proposed for the deep neural network to improve the performance of covid19 classification between covid19 and normal or common pneumonia cases results the results for lung segmentation reached a dice value of 965 on 30 independent ct scans the performance of the maskweighted gap method achieved the covid19 triage with a sensitivity of 965 and specificity of 878 using the testing dataset the maskweighted gap method demonstrated 09 and 2 improvements in sensitivity and specificity respectively compared with the normal gap in addition fusion images between the ct images and the highlighted area from the deep learning model using the gradcam method indicating the lesion region detected using the deep learning method were drawn and could also be confirmed by radiologists conclusions this study proposed a maskweighted gapbased deep learning method and obtained promising results for covid19 triage based on chest ct images furthermore it can be considered a convenient tool to assist doctors in diagnosing covid19",Lung
CT-Based Automatic Spine Segmentation Using Patch-Based Deep Learning,https://doi.org/10.1155/2023/2345835,2023,"ct vertebral segmentation plays an essential role in various clinical applications such as computerassisted surgical interventions assessment of spinal abnormalities and vertebral compression fractures automatic ct vertebral segmentation is challenging due to the overlapping shadows of thoracoabdominal structures such as the lungs bony structures such as the ribs and other issues such as ambiguous object borders complicated spine architecture patient variability and fluctuations in image contrast deep learning is an emerging technique for disease diagnosis in the medical field this study proposes a patchbased deep learning approach to extract the discriminative features from unlabeled data using a stacked sparse autoencoder ssae 2d slices from a ct volume are divided into overlapping patches fed into the model for training a random under sampling rusmodule is applied to balance the training data by selecting a subset of the majority class ssae uses pixel intensities alone to learn highlevel features to recognize distinctive features from image patches each image is subjected to a sliding window operation to express image patches using autoencoder highlevel features which are then fed into a sigmoid layer to classify whether each patch is a vertebra or not we validate our approach on three diverse publicly available datasets verse csiseg and the lumbar ct dataset our proposed method outperformed other models after configuration optimization by achieving 899 in precision 902 in recall 989 in accuracy 904 in fscore 826 in intersection over union iou and 902 in dice coefficient dc the results of this study demonstrate that our models performance consistency using a variety of validation strategies is flexible fast and generalizable making it suited for clinical application",Lung
CT-Based Automatic Spine Segmentation Using Patch-Based Deep Learning,https://doi.org/10.1155/2023/2345835,2023,"ct vertebral segmentation plays an essential role in various clinical applications such as computerassisted surgical interventions assessment of spinal abnormalities and vertebral compression fractures automatic ct vertebral segmentation is challenging due to the overlapping shadows of thoracoabdominal structures such as the lungs bony structures such as the ribs and other issues such as ambiguous object borders complicated spine architecture patient variability and fluctuations in image contrast deep learning is an emerging technique for disease diagnosis in the medical field this study proposes a patchbased deep learning approach to extract the discriminative features from unlabeled data using a stacked sparse autoencoder ssae 2d slices from a ct volume are divided into overlapping patches fed into the model for training a random under sampling rusmodule is applied to balance the training data by selecting a subset of the majority class ssae uses pixel intensities alone to learn highlevel features to recognize distinctive features from image patches each image is subjected to a sliding window operation to express image patches using autoencoder highlevel features which are then fed into a sigmoid layer to classify whether each patch is a vertebra or not we validate our approach on three diverse publicly available datasets verse csiseg and the lumbar ct dataset our proposed method outperformed other models after configuration optimization by achieving 899 in precision 902 in recall 989 in accuracy 904 in fscore 826 in intersection over union iou and 902 in dice coefficient dc the results of this study demonstrate that our models performance consistency using a variety of validation strategies is flexible fast and generalizable making it suited for clinical application",Lung
An end-to-end SE(3)-equivariant segmentation network,https://doi.org/10.48550/arxiv.2303.00351,2023,"convolutional neural networks cnns allow for parameter sharing and translational equivariance by using convolutional kernels in their linear layers by restricting these kernels to be so3steerable cnns can further improve parameter sharing and equivariance these equivariant convolutional layers have several advantages over standard convolutional layers including increased robustness to unseen poses smaller network size and improved sample efficiency despite this most segmentation networks used in medical image analysis continue to rely on standard convolutional kernels in this paper we present a new family of segmentation networks that use equivariant voxel convolutions based on spherical harmonics as well as equivariant pooling and normalization operations these se3equivariant volumetric segmentation networks which are robust to data poses not seen during training do not require rotationbased data augmentation during training in addition we demonstrate improved segmentation performance in mri brain tumor and healthy brain structure segmentation tasks with enhanced robustness to reduced amounts of training data and improved parameter efficiency code to reproduce our results and to implement the equivariant segmentation networks for other tasks is available at httpgithubcomscannrade3nnunet",Brain
X-Ray2EM: Uncertainty-Aware Cross-Modality Image Reconstruction from X-Ray to Electron Microscopy in Connectomics.,None,2023,"comprehensive synapseresolution imaging of the brain will be crucial for understanding neuronal computations and function in connectomics this has been the sole purview of volume electron microscopy em which entails an excruciatingly difficult process because it requires cutting tissue into many thin fragile slices that then need to be imaged aligned and reconstructed unlike em hard xray imaging is compatible with thick tissues eliminating the need for thin sectioning and delivering fast acquisition intrinsic alignment and isotropic resolution unfortunately current stateoftheart xray microscopy provides much lower resolution to the extent that segmenting membranes is very challenging we propose an uncertaintyaware 3d reconstruction model that translates xray images to emlike images with enhanced membrane segmentation quality showing its potential for developing simpler faster and more accurate xray based connectomics pipelines",Brain
GeoLab: Geometry-based Tractography Parcellation of Superficial White  Matter,https://doi.org/10.48550/arxiv.2303.01147,2023,"superficial white matter swm has been less studied than longrange connections despite being of interest to clinical research andfew tractography parcellation methods have been adapted to swm here we propose an efficient geometrybased parcellation method geolab that allows highperformance segmentation of hundreds of short white matter bundles from a subject this method has been designed for the swm atlas of ebrains european infrastructure which is composed of 657 bundles the atlas projection relies on the precomputed statistics of six bundlespecific geometrical properties of atlas streamlines in the spirit of recobundles a global and local streamlinebased registration sbr is used to align the subject to the atlas space then the streamlines are labeled taking into account the six geometrical parameters describing the similarity to the streamlines in the model bundle compared to other stateoftheart methods geolab allows the extraction of more bundles with a higher number of streamlines",Brain
Adversarial co-training for semantic segmentation over medical images,https://doi.org/10.1016/j.compbiomed.2023.106736,2023,"abundant labeled data drives the model training for better performance but collecting sufficient labels is still challenging to alleviate the pressure of label collection semisupervised learning merges unlabeled data into training process however the joining of unlabeled data eg data from different hospitals with different acquisition parameters will change the original distribution such a distribution shift leads to a perturbation in the training process potentially leading to a confirmation bias in this paper we investigate distribution shift and develop methods to increase the robustness of our models with the goal of improving performance in semisupervised semantic segmentation of medical images we study distribution shift and increase model robustness to it for improving practical performance in semisupervised segmentation over medical images to alleviate the issue of distribution shift we introduce adversarial training into the cotraining process we simulate perturbations caused by the distribution shift via adversarial perturbations and introduce the adversarial perturbation to attack the supervised training to improve the robustness against the distribution shift benefiting from label guidance supervised training does not collapse under adversarial attacks for cotraining two submodels are trained from two views over two disjoint subsets of the dataset to extract different kinds of knowledge independently cotraining outperforms singlemodel by integrating both views of knowledge to avoid confirmation bias for practicality we conduct extensive experiments on challenging medical datasets experimental results show desirable improvements to stateoftheart counterparts yu and wang 2019 peng et al 2020 perone et al 2019 we achieve a dsc score of 8737 with only 20 of labels on the acdc dataset almost same to using 100 of labels on the scgm dataset with more distribution shift we achieve a dsc score of 7865 with 65 of labels surpassing 1030 over peng et al 2020 our evaluative results show superior robustness against distribution shifts in medical scenarios empirical results show the effectiveness of our work for handling distribution shift in medical scenarios",Cardiac
HARDC : A novel ECG-based heartbeat classification method to detect arrhythmia using hierarchical attention based dual structured RNN with dilated CNN,https://doi.org/10.1016/j.neunet.2023.03.004,2023,"deep learningbased models have achieved significant success in detecting cardiac arrhythmia by analyzing ecg signals to categorize patient heartbeats to improve the performance of such models we have developed a novel hybrid hierarchical attentionbased bidirectional recurrent neural network with dilated cnn hardc method for arrhythmia classification this solves problems that arise when traditional dilated convolutional neural network cnn models disregard the correlation between contexts and gradient dispersion the proposed hardc fully exploits the dilated cnn and bidirectional recurrent neural network unit bigrubilstm architecture to generate fusion features as a result of incorporating both local and global feature information and an attention mechanism the models performance for prediction is improved by combining the fusion features with a dilated cnn and a hierarchical attention mechanism the trained hardc model showed significantly improved classification results and interpretability of feature extraction on the physionet 2017 challenge dataset sequential zscore normalization filtering denoising and segmentation are used to prepare the raw data for analysis cgan conditional generative adversarial network is then used to generate synthetic signals from the processed data the experimental results demonstrate that the proposed hardc model significantly outperforms other existing models achieving an accuracy of 9960 f1 score of 9821 a precision of 9766 and recall of 9960 using mitbih generated ecg in addition this approach significantly reduces run time when using dilated cnn compared to normal convolution overall this hybrid model demonstrates an innovative and costeffective strategy for ecg signal compression and highperformance ecg recognition our results indicate that an automated and highly computed method to classify multiple types of arrhythmia signals holds considerable promise",Cardiac
Quantification of Liver-Lung Shunt Fraction on 3D SPECT/CT Images for Selective Internal Radiation Therapy of Liver Cancer using CNN-based Segmentations and Non-rigid Registration,https://doi.org/10.1016/j.cmpb.2023.107453,2023,"selective internal radiation therapy sirt has been proven to be an effective treatment for hepatocellular carcinoma hcc patients in clinical practice the treatment planning for sirt using 90y microspheres requires estimation of the liverlung shunt fraction lsf to avoid radiation pneumonitis currently the manual segmentation method to draw a region of interest roi of the liver and lung in 2d planar imaging of 99mtcmaa and 3d spectct images is inconvenient timeconsuming and observerdependent in this study we propose and evaluate a nearly automatic method for lsf quantification using 3d spectct images offering improved performance compared with the current manual segmentation methodwe retrospectively acquired 3d spect with noncontrastenhanced ct images ncect of 60 hcc patients from a spectct scanning machine along with the corresponding diagnostic contrastenhanced ct images cect our approach for lsf quantification is to use cnnbased methods for liver and lung segmentations in the ncect image we first apply 3d resunet to coarsely segment the liver if the liver segmentation contains a large error we dilate the coarse liver segmentation into the liver mask as a roi in the ncect image subsequently nonrigid registration is applied to deform the liver in the cect image to fit that obtained in the ncect image the final liver segmentation is obtained by segmenting the liver in the deformed cect image using nnunet in addition the lung segmentations are obtained using 2d resunet finally lsf quantitation is performed based on the number of counts in the spect image inside the segmentations evaluations and results to evaluate the liver segmentation accuracy we used dice similarity coefficient dsc asymmetric surface distance assd and max surface distance msd and compared the proposed method to five wellknown cnnbased methods for liver segmentation furthermore the lsf error obtained by the proposed method was compared to a stateoftheart method modified deepmedic and the lsf quantifications obtained by manual segmentation the results show that the proposed method achieved a dsc score for the liver segmentation that is comparable to other stateoftheart methods with an average of 093 and the highest consistency in segmentation accuracy yielding a standard deviation of the dsc score of 001 the proposed method also obtains the lowest assd and msd scores on average 26 mm and 315 mm respectively moreover for the proposed method a median lsf error of 014 is obtained which is a statically significant improvement to the stateoftheartmethod p0004 and is much smaller than the median error in lsf manual determination by the medical experts using 2d planar image 174 and p0001a method for lsf quantification using 3d spectct images based on cnns and nonrigid registration was proposed evaluated and compared to stateoftheart techniques the proposed method can quantitatively determine the lsf with high accuracy and has the potential to be applied in clinical practice",Lung
Fiber bundles simulator using exponential curves to validate fiber clustering algorithms,https://doi.org/10.1117/12.2669811,2023,"currently there are many methods for processing diffusion mri dmri tractography data with the aim to identify the main white matter connections however methods like fiber clustering lack ground truth making the evaluation of the effectiveness of different clustering algorithms problematic an alternative to evaluate the performance and test the efficacy of these algorithms is to use simulated fiber datasets nevertheless the simulation of this data is not trivial due to brain fibers irregular and complex shape although many fiber bundle simulators exist they have been developed for other purposes such as validating tractography algorithms or local diffusion models in addition these simulators usually use simple fiber bundle configurations without considering complex bundle shapes with this in mind the main goal of this work is to implement a simulator of brain fiber bundles based on exponential curves for validating fiber clustering methods this representation uses bundle centroids and shape parameters to obtain a more realistic appearance of the fascicles the simulator was validated using a deep white matter fiber bundle atlas obtaining a good percentage of intersection between the original and simulated bundles of up to 82 furthermore we used groups of simulated bundles for the whole brain to evaluate the performance of a fiber clustering algorithm quickbundles when using different distance thresholds showing the utility of the proposed simulator",Brain
Building brain tumor segmentation networks with user-assisted filter estimation and selection,https://doi.org/10.1117/12.2669770,2023,"brain tumor image segmentation is a challenging research topic in which deeplearning models have presented the best results however the traditional way of training those models from many preannotated images leaves several unanswered questions hence methodologies such as feature learning from image markers flim have involved an expert in the learning loop to reduce human effort in data annotation and build models sufficiently deep for a given problem flim has been successfully used to create encoders estimating the filters of all convolutional layers from patches centered at marker voxels in this work we present multistep ms flim a userassisted approach to estimating and selecting the most relevant filters from multiple flim executions msflim is used only for the first convolutional layer and the results already indicate improvement over flim for evaluation we build a simple ushaped encoderdecoder network named sunet for glioblastoma segmentation using t1gd and flair mri scans varying the encoders training method using flim msflim and backpropagation algorithm also we compared these sunets with two stateoftheart sota deeplearning models using two datasets the results show that the sunet based on msflim outperforms the other training methods and achieves effectiveness within the standard deviations of the sota models",Brain
NEC-NET: segmentation and feature extraction network for the neurocranium in early childhood,https://doi.org/10.1117/12.2670281,2023,"in early life the neurocranium undergoes rapid changes to accommodate the expanding brain neurocranial maturation can be disrupted by developmental abnormalities and environmental factors such as sleep position to establish a baseline for the early detection of anomalies it is important to understand how this structure typically grows in healthy children here we designed a deep neural network pipeline necnet including segmentation and classification to analyze the normative development of the neurocranium in t1 mr images from healthy children aged 12 to 60 months old the pipeline optimizes the segmentation of the neurocranium and shows the preliminary results of agebased regional differences among infants",Brain
A deep learning model for brain vessel segmentation in 3DRA with arteriovenous malformations,https://doi.org/10.1117/12.2669916,2023,"segmentation of brain arteriovenous malformations bavms in 3d rotational angiographies 3dra is still an open problem in the literature with high relevance for clinical practice while deep learning models have been applied for segmenting the brain vasculature in these images they have never been used in cases with bavms this is likely caused by the difficulty to obtain sufficiently annotated data to train these approaches in this paper we introduce a first deep learning model for blood vessel segmentation in 3dra images of patients with bavms to this end we densely annotated 5 3dra volumes of bavm cases and used these to train two alternative 3dunetbased architectures with different segmentation objectives our results show that the networks reach a comprehensive coverage of relevant structures for bavm analysis much better than what is obtained using standard methods this is promising for achieving a better topological and morphological characterisation of the bavm structures of interest furthermore the models have the ability to segment venous structures even when missing in the ground truth labelling which is relevant for planning interventional treatments ultimately these results could be used as more reliable first initial guesses alleviating the cumbersome task of creating manual labels",Brain
Automatic segmentation of brain tumor in multi-contrast magnetic resonance using deep neural network,https://doi.org/10.1117/12.2670375,2023,"among all the tumors that can affect the brain gliomas are the most frequent thus is important to get a correct characterization and delimitation of this malformation to provide the best diagnosis and treatment possible nevertheless there are some issues when dealing with segmenting tumors it can be a long and tedious labor which makes it prone to mistakes to solve those problems several techniques were proposed including automatic and semiautomatic segmentation in this work we propose the use of a unet architecturebased deep neural network to automatically realize segmentations of tumors on magnetic resonance brain images obtained from the brats 2020 database which provides t1 t1 contrast enhancement t1ce t2 and flair images for each subject the database has a total of 1476 images distributed in 369 patients that were shuffled into the training set with 70 of the subjects and the test set with a percentage of 30 our results got a 916 dice value for the validation from a 916 for necrotic core net 917 for peritumoral edema pe and a 914 for enhancing tumor et after the training we got 555665 and 686 dice values for net pe and et respectively we also calculated the whole tumor wt segmentation performance reaching a 788 precision and the tumor core tc segmentation which reach 755 precision",Brain
Automatic segmentation of brain tumor in multi-contrast magnetic resonance using deep neural network,https://doi.org/10.1117/12.2670375,2023,"among all the tumors that can affect the brain gliomas are the most frequent thus is important to get a correct characterization and delimitation of this malformation to provide the best diagnosis and treatment possible nevertheless there are some issues when dealing with segmenting tumors it can be a long and tedious labor which makes it prone to mistakes to solve those problems several techniques were proposed including automatic and semiautomatic segmentation in this work we propose the use of a unet architecturebased deep neural network to automatically realize segmentations of tumors on magnetic resonance brain images obtained from the brats 2020 database which provides t1 t1 contrast enhancement t1ce t2 and flair images for each subject the database has a total of 1476 images distributed in 369 patients that were shuffled into the training set with 70 of the subjects and the test set with a percentage of 30 our results got a 916 dice value for the validation from a 916 for necrotic core net 917 for peritumoral edema pe and a 914 for enhancing tumor et after the training we got 555665 and 686 dice values for net pe and et respectively we also calculated the whole tumor wt segmentation performance reaching a 788 precision and the tumor core tc segmentation which reach 755 precision",Brain
Superficial white matter shape characterization using hierarchical clustering and a multi-subject bundle atlas,https://doi.org/10.1117/12.2669738,2023,"the description of the superficial white matter swm functional and structural organization is still an unachieved task in particular their shape has not been assessed in detail using diffusion magnetic resonance imaging dmri tractography this work aims to characterize the different shapes of the shortrange association connections present in an swm multisubject bundle atlas derived from probabilistic dmri tractography datasets first we calculated a representative centroid shape for each atlas bundle next we computed a distance matrix that encodes the similarity between every pair of centroids for the distance matrix computation centroids were first aligned using a streamlinebased registration reducing the 3d spatial separation effect and allowing us to focus only on shape differences then we applied a hierarchical clustering algorithm over the affinity graph derived from the distance matrix as a result we obtained ten classes with distinctive shapes ranging from a straight line form to u and c arrangements the most predominant shapes were i short open u ii short closed u and iii short c moreover we used the shape information to filter out noisy streamlines in the atlas bundles and applied an automatic segmentation algorithm to 25 subjects of the hcp database our results show that the filtering steps help to segment more dense bundles with fewer outliers improving the identification of the brains short fibers",Brain
VENTSEG: efficient open source framework for ventricular segmentation,https://doi.org/10.1117/12.2669932,2023,"despite advances in deep learning methods aimed at cardiac ventricular segmentation most algorithms have drawbacks due to low prediction accuracy with images from different mr scans to those trained it leads to a process that requires timeconsuming correction by technicians or specialists the time in this process is significant mainly due to the large number of image sets to be processed the lack of description of the algorithms has not allowed repeatability while commercial software is difficult to access for clinical use or research however in cardiac segmentation research several solutions have already been proposed this paper presents an opensource cardiac functionality segmentation and evaluation framework which contemplates a diverse database for network training a multi domain network architecture that allows model generalization and preand postprocessing algorithms that improve prediction results the prediction evaluation of the framework shows that ventseg is 366 superior to the trained model and the similarity percentages in the tested mr scores are over 84 on the other hand the interobserver variability analysis with anonymized data shows in the different metrics that ventseg is on par with cardiac segmentation specialists finally the efficiency calculated in an intraobserver test indicates that our framework reduces manual segmentation time by approximately 80",Cardiac
Self-Configuring Capsule Networks for Brain Image Segmentation,https://doi.org/10.1101/2023.02.28.23286596,2023,"abstract when an autosegmentation model needs to be applied to a new segmentation task multiple decisions should be made about the preprocessing steps and training hyperparameters these decisions are cumbersome and require a high level of expertise to remedy this problem i developed selfconfiguring capsnets sccapsnets that can scan the training data as well as the computational resources that are available and then selfconfigure most of their design options in this study we developed a selfconfiguring capsule network that can configure its design options with minimal user input we showed that our selfconfiguring capsule netwrok can segment brain tumor components namely edema and enhancing core of brain tumors with high accuracy out model outperforms unetbased models in the absence of data augmentation is faster to train and is computationally more efficient compared to unetbased models",Brain
A Fast and Efficient Semi-Unsupervised Segmentation and Feature-Extraction Methodology for Artificial Intelligence and Radiomics Applications: A Preliminary Study Applied to Glioblastoma,https://doi.org/10.3390/electronics12051230,2023,"brain tumors are pathologies characterized by a high degree of mortality an early diagnosis of these pathologies could reduce mortality and limit the adverse effects of brain surgery computeraided tomography ct and magnetic resonance imaging mri are fundamental diagnostic methods they offer lots of helpful information that help medical operators to make an early and effective diagnosis however a human operator must analyze and classify the enormous amount of data provided this process is timeconsuming and sometimes the information is not directly visible to the human eye leading to lost essential information that could be useful for obtaining a correct and early diagnosis in such a scenario the development of suitable tools aimed at helping the human operator is essential in particular artificial intelligence ai methodologies could help the clinical operator correctly classify different tumoral pathologies suggest more appropriate therapy and support the surgeon in reducing invasiveness all ai systems require a socalled training phase and suitable feature identification to work properly in this work we propose a tool to speed up brain tumor segmentation and feature extraction in particular we focus on glioblastoma gbm a brain tumor characterized by high tissue heterogeneity and difficult segmentation the method has been assessed by considering an experimental dataset belonging to the radiomic laboratory of the university of trento the obtained results are encouraging and demonstrate that the proposed method can be very useful to speed up the pathologies segmentation and features extraction compared to other wellknown methods",Brain
Deep learning-based technique for lesions segmentation in CT scan images for COVID-19 prediction,https://doi.org/10.1007/s11042-023-14941-w,2023,"since 2019 covid19 disease caused significant damage and it has become a serious health issue in the worldwide the number of infected and confirmed cases is increasing day by day different hospitals and countries around the world to this day are not equipped enough to treat these cases and stop this pandemic evolution lung and chest xray images eg radiography images and chest ct images are the most effective imaging techniques to analyze and diagnose the covid19 related problems deep learningbased techniques have recently shown good performance in computer vision and healthcare fields we propose developing a new deep learningbased application for covid19 segmentation and analysis in this work the proposed system is developed based on the context aggregation neural network this network consists of three main modules the context fuse model cfm attention mix module amm and a residual convolutional module rcm the developed system can detect two main covid19related regions ground glass opacity and consolidation area in ct images generally these lesions are often related to common pneumonia and covid 19 cases training and testing experiments have been conducted using the covidxct dataset based on the obtained results the developed system demonstrated better and more competitive results compared to stateoftheart performances the numerical findings demonstrate the effectiveness of the proposed work by outperforming other works in terms of accuracy by a factor of over 9623",Lung
Brain Tumor Detection Through Modified Optimization Algorithm by Region-based Image Fusion,https://doi.org/10.37936/ecti-cit.2023171.249604,2023,"this article is about the fusion of brain images which are having different features this article addresses the problems raised in pixellevel image fusionsuch as blurring and artifacts caused by the unwanted addition of noise components in fused images we extracted the regions of the brain image with the proposed tested optimal thresholdingbased segmentation by optimizing thresholds with the proposed sine function adapted improved whale optimization algorithm siwoa algorithm we named the proposed fusion as siwoafusion these optimal segmented regions and discrete wavelet coefficients of images are fused based on interval type 2 fuzzy rules finally combined image visual quality is optimized with siwoa by assuming the amount of the correlation of differences acd as an objective function experiments are tested on standard benchmark databases and proved better than existing methods",Brain
BayeSeg: Bayesian Modeling for Medical Image Segmentation with  Interpretable Generalizability,https://doi.org/10.48550/arxiv.2303.01710,2023,"due to the crossdomain distribution shift aroused from diverse medical imaging systems many deep learning segmentation methods fail to perform well on unseen data which limits their realworld applicability recent works have shown the benefits of extracting domaininvariant representations on domain generalization however the interpretability of domaininvariant features remains a great challenge to address this problem we propose an interpretable bayesian framework bayeseg through bayesian modeling of image and label statistics to enhance model generalizability for medical image segmentation specifically we first decompose an image into a spatialcorrelated variable and a spatialvariant variable assigning hierarchical bayesian priors to explicitly force them to model the domainstable shape and domainspecific appearance information respectively then we model the segmentation as a locally smooth variable only related to the shape finally we develop a variational bayesian framework to infer the posterior distributions of these explainable variables the framework is implemented with neural networks and thus is referred to as deep bayesian segmentation quantitative and qualitative experimental results on prostate segmentation and cardiac segmentation tasks have shown the effectiveness of our proposed method moreover we investigated the interpretability of bayeseg by explaining the posteriors and analyzed certain factors that affect the generalization ability through further ablation studies our code will be released via httpszmiclabgithubioprojectshtml once the manuscript is accepted for publication",Cardiac
BayeSeg: Bayesian Modeling for Medical Image Segmentation with  Interpretable Generalizability,https://doi.org/10.48550/arxiv.2303.01710,2023,"due to the crossdomain distribution shift aroused from diverse medical imaging systems many deep learning segmentation methods fail to perform well on unseen data which limits their realworld applicability recent works have shown the benefits of extracting domaininvariant representations on domain generalization however the interpretability of domaininvariant features remains a great challenge to address this problem we propose an interpretable bayesian framework bayeseg through bayesian modeling of image and label statistics to enhance model generalizability for medical image segmentation specifically we first decompose an image into a spatialcorrelated variable and a spatialvariant variable assigning hierarchical bayesian priors to explicitly force them to model the domainstable shape and domainspecific appearance information respectively then we model the segmentation as a locally smooth variable only related to the shape finally we develop a variational bayesian framework to infer the posterior distributions of these explainable variables the framework is implemented with neural networks and thus is referred to as deep bayesian segmentation quantitative and qualitative experimental results on prostate segmentation and cardiac segmentation tasks have shown the effectiveness of our proposed method moreover we investigated the interpretability of bayeseg by explaining the posteriors and analyzed certain factors that affect the generalization ability through further ablation studies our code will be released via httpszmiclabgithubioprojectshtml once the manuscript is accepted for publication",Prostate
Deep Learning based Analysis of MRI Images for Brain Tumor Diagnosis,https://doi.org/10.14569/ijacsa.2023.0140234,2023,"this identification and examination of brain tumour are critical components of any indication system as evidenced by extensive research and methodological advancement over the years as part of this approach an efficient automated system must be put in place to enhance the rate of tumor identification today manually examining thousands of mri images to locate a brain tumor is arduous and imprecise it may impair patient care since it incorporates several picture datasets it might be timeconsuming tumor cells present in the brain look a lot like healthy tissue making it hard to distinguish between the two while doing segmentation in this study we present an approach for classification and prediction of mri images of the brain using a convolutional neural network conventional classifiers and deep learning here we have proposed a new method for the automatic and exact categorization of brain tumour utilizing a twostage feature composition of deep convolutional neural networks cnns we used a deep learning approach to categorize mri scans into several pathologies including gliomas meningiomas benign lesions and pituitary tumour after first extracting characteristics from the scans additionally the most accurate classifier is selected from a pool of five possible classifiers the principal components analysis pca is used to identify the most important characteristics from the retrieved features which are then used to train the classifier we develop our proposed model in python utilizing tensorflow and keras since it is an effective language for programming and performing work quickly in our work cnn got a 986 accuracy rate which is better than what has been done so far",Brain
A Local Linear Wavelet Artificial Neural Network-based Automated Tumor Detection System with Hybrid Optimization,https://doi.org/10.58599/ijsmien.2023.1202,2023,"the human brain which contains billions of neurons and regulates the central nervous system is the most intricate and convoluted organ the human brain contains neuron and nonneuron cells aberrant and uncontrolled proliferation of these cells implies tumours to get images of the human brain for the radiologists study and classification of the tumour that is present magnetic resonance imaging mri is used the detection of the tumors in brain by the radiologist with mr imaging is careful and time consuming process for the purpose of performing tumour removal operations an artificial neural network makes it easier to automatically detect segment classify and extract the tumour region in this study we proposed a local linear wavelet artificial neural networkbased automated tumor detection system with hybrid optimization which can automatically detect human brain tumours using ann it consists of an mri dataset preprocessing segmentation box bounding glcmlbp feature extraction hybrid firefly optimization local",Brain
Deep learning based brain MRI registration driven by local‐signed‐distance fields of segmentation maps,https://doi.org/10.1002/mp.16291,2023,"background deep learning based unsupervised registration utilizes the intensity information to align images to avoid the influence of intensity variation and improve the registration accuracy unsupervised and weaklysupervised registration are combined namely duallysupervised registration however the estimated dense deformation fields ddfs will focus on the edges among adjacent tissues when the segmentation labels are directly used to drive the registration progress which will decrease the plausibility of brain mri registration purpose in order to increase the accuracy of registration and ensure the plausibility of registration at the same time we combine the localsigneddistance fields lsdfs and intensity images to dually supervise the registration progress the proposed method not only uses the intensity and segmentation information but also uses the voxelwise geometric distance information to the edges hence the accurate voxelwise correspondence relationships are guaranteed both inside and outside the edges methods the proposed duallysupervised registration method mainly includes three enhancement strategies firstly we leverage the segmentation labels to construct their lsdfs to provide more geometrical information for guiding the registration process secondly to calculate lsdfs we construct an lsdfnet which is composed of 3d dilation layers and erosion layers finally we design the duallysupervised registration network vmlsdf by combining the unsupervised voxelmorph vm registration network and the weaklysupervised lsdfnet to utilize intensity and lsdf information respectively results in this paper experiments were then carried out on four public brain image datasets lpba40 hbn oasis1 and oasis3 the experimental results show that the dice similarity coefficient dsc and 95 hausdorff distance hd of vmlsdf are higher than those of the original unsupervised vm and the duallysupervised registration network vmseg using intensity images and segmentation labels at the same time the percentage of negative jacobian determinant njd of vmlsdf is lower than vmseg our code is freely available at httpsgithubcom1209684549lsdf conclusions the experimental results show that lsdfs can improve the registration accuracy compared with vm and vmseg and enhance the plausibility of the ddfs compared with vmseg this article is protected by copyright all rights reserved",Brain
Automatic Segmentation of Parkinson Disease Therapeutic Targets Using Nonlinear Registration and Clinical MR Imaging: Comparison of Methodology Presence of Disease and Quality Control,https://doi.org/10.1159/000526719,2023,"accurate and precise delineation of the globus pallidus pars interna gpi and subthalamic nucleus stn is critical for the clinical treatment and research of parkinsons disease pd automated segmentation is a developing technology which addresses limitations of visualizing deep nuclei on mr imaging and standardizing their definition in research applications we sought to compare manual segmentation with three workflows for templatetopatient nonlinear registration providing atlasbased automatic segmentation of deep nucleibilateral gpi stn and red nucleus rn were segmented for 20 pd and 20 healthy control hc subjects using 3t mris acquired for clinical purposes the automated workflows used were an option available in clinical practice and two common research protocols quality control qc was performed on registered templates via visual inspection of readily discernible brain structures manual segmentation using t1 proton density and t2 sequences was used as ground truth data for comparison dice similarity coefficient dsc was used to assess agreement between segmented nuclei further analysis was done to compare the influences of disease state and qc classifications on dscautomated segmentation workflows cits crvab and dists had the highest dsc for the rn and lowest for the stn manual segmentations outperformed automated segmentation for all workflows and nuclei however for 39 workflows cits stn crvab stn and crvab gpi the differences were not statically significant hc and pd only showed significant differences in 19 comparisons dists gpi qc classification only demonstrated significantly higher dsc in 29 comparisons crvab rn and gpimanual segmentations generally performed better than automated segmentations disease state does not appear to have a significant effect on the quality of automated segmentations via nonlinear templatetopatient registration notably visual inspection of template registration is a poor indicator of the accuracy of deep nuclei segmentation as automatic segmentation methods continue to evolve efficient and reliable qc methods will be necessary to support safe and effective integration into clinical workflows",Brain
Identification and Segmentation of Medical Images by Using Marker-Controlled Watershed Transformation Algorithm XAI and ML,https://doi.org/10.4018/978-1-6684-7524-9.ch003,2023,"to make human life easy and compact xai has developed a lot with more innovations and contributed its own share to make a suitable treatment while diagnosed with brain tumour one needs to classify the tumour and detect it in a proper way where the explained result is most important with the help of different analysis processes where markerbased approaches can help in proper segmentation and noise reduction analysis numerous imaging modalities exist for tumour detection that are utilized to identify tumours in the brain one of the most important issues of xai system is medical diagnosis through ml in medical image processing in this chapter the authors present a modified markercontrolled watershed transformation approach to detect brain tumour with xai and machine learning approaches they include cnn and data augmentation algorithms image preprocessing takes the main area to detect and diagnose disease and diagnose properly the statistical measurements have been introduced to get the mathematical abstractions of different approaches for result analysis",Brain
DACov: a deeper analysis of data augmentation on the computed tomography segmentation problem,https://doi.org/10.1080/21681163.2023.2183807,2023,"due to the covid19 global pandemic computerassisted diagnoses of medical images have gained much attention and robust methods of semantic segmentation of computed tomography ct images have become highly desirable in this work we present a deeper analysis of how data augmentation techniques improve segmentation performance on this problem we evaluate 20 traditional augmentation techniques on five public datasets six different probabilities of applying each augmentation technique on an image were evaluated we also assess a different training methodology where the training subsets are combined into a single larger set all networks were evaluated through a 5fold crossvalidation strategy resulting in over 4600 experiments we also propose a novel data augmentation technique based on generative adversarial networks gans to create new healthy and unhealthy lung ct images evaluating four variations of our approach with the same six probabilities of the traditional methods our findings show that ganbased techniques and spatiallevel transformations are the most promising for improving the learning of deep models on this problem with the stargan v2 f with a probability of 03 achieving the highest fscore value on the ricord1a dataset in the unified training strategy our code is publicly available at httpsgithubcomvriufprdacov2022",Lung
Orvosi jel- és képfeldolgozás transzformációs módszerekkel,https://doi.org/10.15476/elte.2019.240,2023,"in this dissertation i address some specific problems of biomedical signal and image processing my motivations were to develop reliable automatic methods by means of mathematical modelling and transformation methods i developed a novel ecg heartbeat classification method based on a patientspecific modelling of the heartbeats the proposed method outperforms the previous ones an adaptive rational transformation a patientbased pole optimisation method is introduced for the modelling of the heartbeats i introduced an adaptive segmentation and initial value selection method extended the feature vector with the system parameters and discussed multiple fusions for the classification i suggested a novel modelling segmentation and reconstruction of the ecg waveforms the proposed fiducial point detector method outperforms the previous ones with respect to the localization of the p wave geometric interpretation of the qrs complex is given based on rational model curves in order to extract fiducial points and medical descriptors i discussed reconstruction techniques to restore signals based on the medical descriptors this concept serves as a heartbeat synthesizer and alternative pole identification method as well finally i developed a deterministic method to segment the ecg waveforms and to detect fiducial points based on an adaptive rational transformation related to approximation problems with respect to rational systems i gave a sufficient upper limit for the perturbation of the magnitude of the inverse poles depending on the acceptable approximation error these results may have a direct impact in ecg signal processing by means of rational transform namely quantization of the inverse poles and control conditions for the optimization can be provided i introduced a novel image quality measurement method to characterize the objective quality of low dose human lung ct scans in addition i developed a ct simulation framework based on an adapted noise model and a newly constructed lung phantom the proposed simulation technique allows the synthesization of ct images for testing reasons and the proposed metric is found to be acceptable for both low and normal dose ct scans the results were published in 9 scientific papers",Lung
Global Thresholding Technique for Basal Ganglia Segmentation from Positron Emission Tomography Images,https://doi.org/10.1007/978-3-031-27609-5_7,2023,"the basal ganglia is a small brain structure in the brainstem that plays a crucial role in the pathogenesis of parkinsons disease pd it processes the different signals coming from the cortex enabling the right execution of voluntary movements the decrease of dopaminergic neurons of the substantia nigra provokes multiple changes affecting the whole basal ganglia network this leads systematically to patients disability and affects their quality of life progressively positron emission tomography pet is an ideal tool to detect the amount of changes in the brain as it produces detailed quantitative information of the pd progression in this regard artificial intelligence ai proved notable and fundamental changes in the way we detect and treat abnormalities in medical images image segmentation techniques part of ai are significant in detecting changes in medical images thus accurate pet image segmentation is necessary for followups and treatment planning to enhance the health status of different patients for this reason in this paper we aim to improve the detection of pd progression by using intelligent technique such as global thresholding segmentation this technique has been tested onto 110 different pet images and evaluated with the corresponding ground truth which were segmented manually we tested three multiple threshold values and evaluated the segmentation performance in each case using dice similarity coefficient dsc and mean intersection over union miou metrics the results obtained indicate that global thresholding technique have reached higher performance using 150 as threshold with 07701 of dsc and 06394 of miou",Brain
Interobserver Variability in Target Definition for Stereotactic Arrhythmia Radioablation,https://doi.org/10.1101/2023.03.01.23286657,2023,"abstract background stereotactic arrhythmia radioablation star is emerging as a potential new therapy for patients with refractory ventricular tachycardia vt the arrhythmogenic substrate target is synthesized from clinical and electroanatomical information this study was designed to evaluate the baseline interobserver variability in target delineation for star methods delineation software designed for research purposes was used the study was split into three phases firstly electrophysiologists observers delineated a welldefined structure in three patients spinal canal secondly observers delineated the arrhythmogenic cardiac vt target in three patients previously treated with star based on case descriptions to evaluate baseline performance a basic workflow approach was used no advanced techniques were allowed eg image integration thirdly observers delineated three predefined segments from the cardiac 17segment model interobserver variability was evaluated by assessing volumes variation in distance to the median volume as expressed by the rootmeansquare of the observer standard deviation rms sd over the target volume and the dice coefficient results ten electrophysiologists completed the study for the first phase spinal canal delineation interobserver variability was low as indicated by low variation in distance to the median volume rms sd range 002002cm and high dice coefficients mean 097001 in the second phase vttarget delineation distance to the median volume was large rms sd range 052102cm and the dice coefficients low mean 040015 in the third phase segment delineation similar results were observed rms sd range 051155cm dice coefficient mean 031021 conclusions interobserver variability is high for manual delineation of the vttarget and ventricular segments difficulties in cardiac anatomical orientation on traditional radiation oncology ct scans appear to be an important driver of variability this evaluation of the baseline observer variation shows that there is a need for methods and tools to improve variability and allows for future comparison of interventions aiming to reduce observer variation",Cardiac
Automated Ventricle Parcellation and Evan's Ratio Computation in Pre-  and Post-Surgical Ventriculomegaly,https://doi.org/10.48550/arxiv.2303.01922,2023,"normal pressure hydrocephalusnph is a brain disorder associated with enlarged ventricles and multiple cognitive and motor symptoms the degree of ventricular enlargement can be measured using magnetic resonance imagesmris and characterized quantitatively using the evans ratio er automatic computation of er is desired to avoid the extra time and variations associated with manual measurements on mri because shunt surgery is often used to treat nph it is necessary that this process be robust to image artifacts caused by the shunt and related implants in this paper we propose a 3d regionsofinterest aware roiaware network for segmenting the ventricles the method achieves stateoftheart performance on both presurgery mris and postsurgery mris with artifacts based on our segmentation results we also describe an automated approach to compute er from these results experimental results on multiple datasets demonstrate the potential of the proposed method to assist clinicians in the diagnosis and management of nph",Brain
CBCT-Based Synthetic CT Image Generation Using Conditional Denoising  Diffusion Probabilistic Model,https://doi.org/10.48550/arxiv.2303.02649,2023,"background daily or weekly conebeam computed tomography cbct scans are commonly used for accurate patient positioning during the imageguided radiotherapy igrt process making it an ideal option for adaptive radiotherapy art replanning however the presence of severe artifacts and inaccurate hounsfield unit hu values prevent its use for quantitative applications such as organ segmentation and dose calculation to enable the clinical practice of online art it is crucial to obtain cbct scans with a quality comparable to that of a ct scan purpose this work aims to develop a conditional diffusion model to perform image translation from the cbct to the ct domain for the image quality improvement of cbct methods the proposed method is a conditional denoising diffusion probabilistic model ddpm that utilizes a timeembedded unet architecture with residual and attention blocks to gradually transform standard gaussian noise to the target ct distribution conditioned on the cbct the model was trained on deformed planning ct dpct and cbct image pairs and its feasibility was verified in brain patient study and headandneck hn patient study the performance of the proposed algorithm was evaluated using mean absolute error mae peak signaltonoise ratio psnr and normalized crosscorrelation ncc metrics on generated synthetic ct sct samples the proposed method was also compared to four other diffusion modelbased sct generation methods conclusions the proposed conditional ddpm method can generate sct from cbct with accurate hu numbers and reduced artifacts enabling accurate cbctbased organ segmentation and dose calculation for online art",Brain
Evaluating the Fairness of Deep Learning Uncertainty Estimates in  Medical Image Analysis,https://doi.org/10.48550/arxiv.2303.03242,2023,"although deep learning dl models have shown great success in many medical image analysis tasks deployment of the resulting models into real clinical contexts requires 1 that they exhibit robustness and fairness across different subpopulations and 2 that the confidence in dl model predictions be accurately expressed in the form of uncertainties unfortunately recent studies have indeed shown significant biases in dl models across demographic subgroups eg race sex age in the context of medical image analysis indicating a lack of fairness in the models although several methods have been proposed in the ml literature to mitigate a lack of fairness in dl models they focus entirely on the absolute performance between groups without considering their effect on uncertainty estimation in this work we present the first exploration of the effect of popular fairness models on overcoming biases across subgroups in medical image analysis in terms of bottomline performance and their effects on uncertainty quantification we perform extensive experiments on three different clinically relevant tasks i skin lesion classification ii brain tumour segmentation and iii alzheimers disease clinical score regression our results indicate that popular ml methods such as databalancing and distributionally robust optimization succeed in mitigating fairness issues in terms of the model performances for some of the tasks however this can come at the cost of poor uncertainty estimates associated with the model predictions this tradeoff must be mitigated if fairness models are to be adopted in medical image analysis",Brain
Toward Automated Right Ventricle Segmentation via Edge Feature-induced Self-attention Multi-scale Feature Aggregation Full Convolution Network,https://doi.org/10.1109/tim.2022.3206810,2023,"in the field of cardiac magnetic resonance mr image analysis the accurate segmentation of right ventricle rv regions plays an important role in the quantitative examination and medical diagnosis of various cardiovascular diseases however the automated rv segmentation in cardiac mr images is still challenging due to its obscure and illdefined boundaries variably crescentshaped structures and extremelyunbalanced area ratio between the rv region and the background in this work an edge featureinduced selfattention multiscale feature aggregation full convolutional neural network called efisamsfafunet is proposed to address the rv segmentation tasks specifically efisamsfafunet introduces an edge feature extraction module efem to mine the crescentshaped boundary features of the rv area and a kind of selfattention multiscale feature expansion block samsfeb is proposed to mine the internal structure characteristics of the crescentshaped rv internal regions in addition a kind of composite loss function is used to address the problem of model degradation caused by the proportion imbalance between rv region and background the proposed efisamsfafunet was evaluated on the miccai2017 automatic cardiac diagnosis challenge acdc dataset extensive confirmatory and comparative experiments show that the efisamsfafunet can achieve better segmentation results than the representatively stateoftheart methods and it can achieve comparable or the closest segmentation results to the manual segmentation of clinical specialist",Cardiac
Toward Automated Right Ventricle Segmentation via Edge Feature-induced Self-attention Multi-scale Feature Aggregation Full Convolution Network,https://doi.org/10.1109/tim.2022.3206810,2023,"in the field of cardiac magnetic resonance mr image analysis the accurate segmentation of right ventricle rv regions plays an important role in the quantitative examination and medical diagnosis of various cardiovascular diseases however the automated rv segmentation in cardiac mr images is still challenging due to its obscure and illdefined boundaries variably crescentshaped structures and extremelyunbalanced area ratio between the rv region and the background in this work an edge featureinduced selfattention multiscale feature aggregation full convolutional neural network called efisamsfafunet is proposed to address the rv segmentation tasks specifically efisamsfafunet introduces an edge feature extraction module efem to mine the crescentshaped boundary features of the rv area and a kind of selfattention multiscale feature expansion block samsfeb is proposed to mine the internal structure characteristics of the crescentshaped rv internal regions in addition a kind of composite loss function is used to address the problem of model degradation caused by the proportion imbalance between rv region and background the proposed efisamsfafunet was evaluated on the miccai2017 automatic cardiac diagnosis challenge acdc dataset extensive confirmatory and comparative experiments show that the efisamsfafunet can achieve better segmentation results than the representatively stateoftheart methods and it can achieve comparable or the closest segmentation results to the manual segmentation of clinical specialist",Cardiac
Prostate cancer classification with MRI using Taylor-Bird Squirrel Optimization based Deep Recurrent Neural Network,https://doi.org/10.1080/13682199.2023.2165242,2023,"prostate cancer is a type of cancer that develops in the prostate the prostate is a little gland in men that resembles a walnut and secretes seminal fluid which nourishes and transports sperm a taylorbird squirrel optimization based deep recurrent neural network taylorbso based deep rnn is created to determine the severity degree of prostate cancer classificationstart the diagnosis process the taylor series is combined with the bird swarm algorithm bsa and squirrel search algorithm ssa respectively to create the taylorbso by filtering the mr image using the hybrid local and nonlocal means hlnlm filtering model the noise that was present in the input image is successfully eliminated the procedure of cancer classification is designed for determining the existence or absence of a tumour using the features that were collected in the segmentation findings the threshold number however categorizes the tumour severity level as either a highgrade or lowgrade tumour",Prostate
COVID-19 chest X-ray image analysis by threshold-based segmentation,https://doi.org/10.1016/j.heliyon.2023.e14453,2023,"covid19 is a severe acute respiratory syndrome that has caused a major ongoing pandemic worldwide imaging systems such as conventional chest xray cxr and computed tomography ct were proven essential for patients due to the lack of information about the complications that could result from this disease in this study the aim was to develop and evaluate a method for automatic diagnosis of covid19 using binary segmentation of chest xray images the study used frontal chest xray images of 27 infected and 19 uninfected individuals from kaggle covid19 radiography database and applied binary segmentation and quartering in matlab to analyze the images the binary images of the lung were split into four quarters q1 right upper quarter q2 left upper quarter q3 right lower and q4 left lower the results showed that covid19 patients had a higher percentage of attenuation in the lower lobes of the lungs pvalue 000001 compared to healthy individuals which is likely due to groundglass opacities and consolidations caused by the infection the ratios of white pixels in the four quarters of the xray images were calculated and it was found that the left lower quarter had the highest number of white pixels but without a statistical significance compared to right lower quarter pvalue 0102792 this supports the theory that covid19 primarily affects the lower and lateral fields of the lungs and suggests that the virus is accumulated mostly in the lower left quarter of the lungs overall this study contributes to the understanding of the impact of covid19 on the respiratory system and can help in the development of accurate diagnostic methods",Lung
COVID-19 chest X-ray image analysis by threshold-based segmentation,https://doi.org/10.1016/j.heliyon.2023.e14453,2023,"covid19 is a severe acute respiratory syndrome that has caused a major ongoing pandemic worldwide imaging systems such as conventional chest xray cxr and computed tomography ct were proven essential for patients due to the lack of information about the complications that could result from this disease in this study the aim was to develop and evaluate a method for automatic diagnosis of covid19 using binary segmentation of chest xray images the study used frontal chest xray images of 27 infected and 19 uninfected individuals from kaggle covid19 radiography database and applied binary segmentation and quartering in matlab to analyze the images the binary images of the lung were split into four quarters q1 right upper quarter q2 left upper quarter q3 right lower and q4 left lower the results showed that covid19 patients had a higher percentage of attenuation in the lower lobes of the lungs pvalue 000001 compared to healthy individuals which is likely due to groundglass opacities and consolidations caused by the infection the ratios of white pixels in the four quarters of the xray images were calculated and it was found that the left lower quarter had the highest number of white pixels but without a statistical significance compared to right lower quarter pvalue 0102792 this supports the theory that covid19 primarily affects the lower and lateral fields of the lungs and suggests that the virus is accumulated mostly in the lower left quarter of the lungs overall this study contributes to the understanding of the impact of covid19 on the respiratory system and can help in the development of accurate diagnostic methods",Lung
An advanced perceptual U-Net segmentation based DDO-SDN classification system for lung pulmonary cancer detection,https://doi.org/10.1556/1647.2023.00106,2023,"abstract developing an automated lung disease diagnosis framework is still remains one of the most challenging and demanding tasks in recent days most of the medical experts highly preferring the computed tomography ct lung images for an accurate disease detection for this purpose various segmentation optimization and classification techniques are developed in the conventional works for lung pulmonary disease detection however the existing techniques have the major problems of over segmentation inaccurate roi extraction reduced accuracy computational complexity and high false positives thus this research work intends to a simple and efficient segmentation based classification framework for an accurate lung nodules detection and pulmonary disease classification here the tanh normalization technique is applied for preprocessing the input lung ct image with reduced noise and increased quality after that the perceptual unet segmentation algorithm is employed to accurately segment the lung nodules from the preprocessed ct images with simple computational operations moreover the decked dragonfly optimization ddo technique is used for choosing the relevant features based on the best optimal solution which supports to obtain an increased detection accuracy and reduced classification error rate finally the speculative deceptive network sdn based classification algorithm is deployed to exactly detect the pulmonary lung cancer according to the optimal features during evaluation the performance of the proposed segmentation based ddosdn mechanism is validated and compared by using various evaluation parameters",Lung
An Explainable Brain Tumor Detection Framework for MRI Analysis,https://doi.org/10.3390/app13063438,2023,"explainability in medical images analysis plays an important role in the accurate diagnosis and treatment of tumors which can help medical professionals better understand the images analysis results based on deep models this paper proposes an explainable brain tumor detection framework that can complete the tasks of segmentation classification and explainability the reparameterization method is applied to our classification network and the effect of explainable heatmaps is improved by modifying the network architecture our classification model also has the advantage of posthoc explainability we used the brats2018 dataset for training and verification experimental results show that our simplified framework has excellent performance and high calculation speed the comparison of results by segmentation and explainable neural networks helps researchers better understand the process of the black box method increase the trust of the deep model output and make more accurate judgments in disease identification and diagnosis",Brain
An Explainable Brain Tumor Detection Framework for MRI Analysis,https://doi.org/10.3390/app13063438,2023,"explainability in medical images analysis plays an important role in the accurate diagnosis and treatment of tumors which can help medical professionals better understand the images analysis results based on deep models this paper proposes an explainable brain tumor detection framework that can complete the tasks of segmentation classification and explainability the reparameterization method is applied to our classification network and the effect of explainable heatmaps is improved by modifying the network architecture our classification model also has the advantage of posthoc explainability we used the brats2018 dataset for training and verification experimental results show that our simplified framework has excellent performance and high calculation speed the comparison of results by segmentation and explainable neural networks helps researchers better understand the process of the black box method increase the trust of the deep model output and make more accurate judgments in disease identification and diagnosis",Brain
SMA-Net: Sobel Operator Combined with Multi-attention Networks for COVID-19 Lesion Segmentation,https://doi.org/10.1007/978-981-99-0856-1_28,2023,"coronavirus disease 2019 covid19 has been spreading since late 2019 leading the world into a serious health crisis to control the spread rate of infection identifying patients accurately and quickly is the most crucial step computed tomography ct images of the chest are an important basis for diagnosing covid19 they also allow doctors to understand the details of the lung infection however manual segmentation of infected areas in ct images is timeconsuming and laborious with its excellent feature extraction capabilities deep learningbased method has been widely used for automatic lesion segmentation of covid19 ct images but the segmentation accuracy of these methods is still limited to effectively quantify the severity of lung infections we propose a sobel operator combined with multiattention networks for covid19 lesion segmentation smanet in our smanet an edge feature fusion module uses sobel operator to add edge detail information to the input image to guide the network to focus on key regions the smanet introduces a selfattentive channel attention mechanism and a spatial linear attention mechanism in addition tversky loss function is adopted for the segmentation network for small size of lesions comparative experiments on covid19 public datasets show that the average dice similarity coefficient dsc and joint intersection over union iou of proposed smanet are 861 and 778 respectively which are better than most existing neural networks used for covid19 lesion segmentation",Lung
Age Related Changes in Left Ventricular Vortex and Energy Loss Patterns: From Newborns to Adults,https://doi.org/10.1152/ajpheart.00002.2023,2023,"left ventricular vortex formation optimizes the effective transport of blood volume while minimizing energy loss el vector flow mapping vfm derived el patterns have not been described in children lt 1 year a prospective cohort of 66 0 days 22 years 14 patients 2 months cardiovascularly normal children was used to determine lv vortex number size mm2 strength m2sec and energy loss mwmm2 in systole and diastole and compared across age groups one early diastolic ed vortex at the anterior mitral leaflet amp one late diastolic ld vortex at the lv outflow tract lvot were seen in all newborns 2 months at gt 2 months two ed vortices and one ld vortex were seen with 95 of subjects gt 2 years demonstrating this vortex pattern peak and average diastolic el acutely increased in the same 2 months 2 years period and then decreased within the adolescent and young adult age groups overall these findings suggest that the growing heart undergoes a transition to adult vortex flow patterns over the first two years of life with a corresponding acute increase in diastolic el these findings offer an initial insight into the dynamic changes of lv flow patterns in pediatric patients and can serve to expand our understanding of cardiac efficiency and physiology in children",Cardiac
Validation of a Fully Automated Hybrid Deep Learning Cardiac Substructure Segmentation Tool for Contouring and Dose Evaluation in Lung Cancer Radiotherapy,https://doi.org/10.1016/j.clon.2023.03.005,2023,"accurate and consistent delineation of cardiac substructures is challenging the aim of this work was to validate a novel segmentation tool for automatic delineation of cardiac structures and subsequent dose evaluation with potential application in clinical settings and largescale radiationrelated cardiotoxicity studiesa recently developed hybrid method for automatic segmentation of 18 cardiac structures combining deep learning multiatlas mapping and geometric segmentation of small challenging substructures was independently validated on 30 lung cancer cases these included anatomical and imaging variations such as tumour abutting heart lung collapse and metal artefacts automatic segmentations were compared with manual contours of the 18 structures using quantitative metrics including dice similarity coefficient dsc mean distance to agreement mda and dose comparisonsa comparison of manual and automatic contours across all cases showed a median dsc of 075093 and a median mda of 209334 mm for whole heart and chambers the median mda for great vessels coronary arteries cardiac valves sinoatrial and atrioventricular conduction nodes was 301854 mm for the 27 cases treated with curative intent planned target volume dose 50 gy the median dose difference was 112 to 057 gy absolute difference of 113325 for the mean dose to heart and chambers and 225 to 445 gy absolute difference of 094679 for the mean dose to substructuresthe novel hybrid automatic segmentation tool reported high accuracy and consistency over a validation set with challenging anatomical and imaging variations this has promising applications in substructure dose calculations of largescale datasets and for future studies on longterm cardiac toxicity",Cardiac
Validation of a Fully Automated Hybrid Deep Learning Cardiac Substructure Segmentation Tool for Contouring and Dose Evaluation in Lung Cancer Radiotherapy,https://doi.org/10.1016/j.clon.2023.03.005,2023,"accurate and consistent delineation of cardiac substructures is challenging the aim of this work was to validate a novel segmentation tool for automatic delineation of cardiac structures and subsequent dose evaluation with potential application in clinical settings and largescale radiationrelated cardiotoxicity studiesa recently developed hybrid method for automatic segmentation of 18 cardiac structures combining deep learning multiatlas mapping and geometric segmentation of small challenging substructures was independently validated on 30 lung cancer cases these included anatomical and imaging variations such as tumour abutting heart lung collapse and metal artefacts automatic segmentations were compared with manual contours of the 18 structures using quantitative metrics including dice similarity coefficient dsc mean distance to agreement mda and dose comparisonsa comparison of manual and automatic contours across all cases showed a median dsc of 075093 and a median mda of 209334 mm for whole heart and chambers the median mda for great vessels coronary arteries cardiac valves sinoatrial and atrioventricular conduction nodes was 301854 mm for the 27 cases treated with curative intent planned target volume dose 50 gy the median dose difference was 112 to 057 gy absolute difference of 113325 for the mean dose to heart and chambers and 225 to 445 gy absolute difference of 094679 for the mean dose to substructuresthe novel hybrid automatic segmentation tool reported high accuracy and consistency over a validation set with challenging anatomical and imaging variations this has promising applications in substructure dose calculations of largescale datasets and for future studies on longterm cardiac toxicity",Lung
An approach for classification of lung nodules,https://doi.org/10.36922/td.317,2023,"the main objective of the proposed work is to develop an automated computeraided detection cad system to classify lung nodules using various classifiers from computed tomography ct images one of the most important steps in lung nodule detection is the classification of nodule and nonnodule patterns in ct the early detection of the condition helps lower the mortality rate the developed cad systems consist of segmentation feature extraction and classification in this work a filter method is used to segment the infected region later we extracted features through and fed into classifiers such as decision stump ds random forest rf and back propagation neural network bpnn the experimentation was conducted on lidcidri dataset and the results with bpnn outperformed those with ds and rf classifiers",Lung
Classification and Segmentation of Brain Tumor Using EfficientNet-B7 and U-Net,https://doi.org/10.9734/ajrcos/2023/v15i3320,2023,"tumors are caused by uncontrolled growth of abnormal cells magnetic resonance imaging mri is modality that is widely used to produce highly detailed brain images in addition a surgical biopsy of the suspected tissue tumor is required to obtain more information about the type of tumor biopsy takes 10 to 15 days for laboratory testing based on a study conducted by brady in 2016 errors in radiology practice are common with an estimated daily error rate of 35 therefore using the application of artificial intelligence is expected to simplify and improve the accuracy of doctors diagnose",Brain
A Method of Chest Film Segmentation Based on Minimum Error Threshold Method,https://doi.org/10.25236/ajmhs.2023.040210,2023,"in recent years due to irregular life schedule and environmental pollution the incidence rate and mortality of lung cancer have greatly increased however early detection and treatment can significantly reduce mortality in the diagnosis of lung cancer xray plays a key role with the wide application of artificial intelligence intelligent analysis of medical images has also ushered in a new breakthrough in the intelligent analysis of medical images image segmentation is an extremely critical link this paper mainly introduces an image segmentation method about minimum error threshold segmentation which provides an efficient and convenient method for medical image segmentation this method can effectively extract the target lung region avoid obvious oversegmentation and interference of stomach air region and eliminate cavities and noise points to obtain more accurate lung segmentation effect various reasons have led to the rapid rise of the incidence rate and mortality of lung cancer lung cancer will become one of the most threatening diseases to mankind in the 21st century people should pay more attention to lung cancer related issues realizing the advantages of intelligent analysis of medical images and pay more attention to this field",Lung
Mutually communicated model based on multi‐parametric MRI for automated segmentation and classification of prostate cancer,https://doi.org/10.1002/mp.16343,2023,"backgroud multiparametric magnetic resonance imaging mpmri is introduced and established as a noninvasive alternative for prostate cancer pca detection and characterization purpose to develop and evaluate a mutually communicated deep learning segmentation and classification network mcdscn based on mpmri for prostate segmentation and prostate cancer pca diagnosis methods the proposed mcdscn can transfer mutual information between segmentation and classification components and facilitate each other in a bootstrapping way for classification task the mcdscn can transfer the masks produced by the coarse segmentation component to the classification component to exclude irrelevant regions and facilitate classification for segmentation task this model can transfer the highquality localization information learned by the classification component to the fine segmentation component to mitigate the impact of inaccurate localization on segmentation results consecutive mri exams of patients were retrospectively collected from two medical centers referred to as center a and b two experienced radiologists segmented the prostate regions and the ground truth of the classification refers to the prostate biopsy results mcdscn was designed trained and validated using different combinations of distinct mri sequences as input eg t2weighted and apparent diffusion coefficient and the effect of different architectures on the networks performance was tested and discussed data from center a was used for training validation and internal testing while another centers data was used for external testing the statistical analysis is performed to evaluate the performance of the mcdscn the delong test and paired ttest were used to assess the performance of classification and segmentation respectively results in total 134 patients were included the proposed mcdscn outperforms the networks that were designed solely for segmentation or classification regarding the segmentation task the classification localization information helped to improve the iou in center a from 845 to 878 p 001 and in center b from 838 to 871 p 001 while the auc of pca classification was improved in center a from 0946 to 0991 p 002 and in center b from 0926 to 0955 p 001 as a result of the additional information provided by the prostate segmentation conclusion the proposed architecture could effectively transfer mutual information between segmentation and classification components and facilitate each other in a bootstrapping way thus outperforming the networks designed to perform only one task this article is protected by copyright all rights reserved",Prostate
MetaMorph: Learning Metamorphic Image Transformation With Appearance  Changes,https://doi.org/10.48550/arxiv.2303.04849,2023,"this paper presents a novel predictive model metamorph for metamorphic registration of images with appearance changes ie caused by brain tumors in contrast to previous learningbased registration methods that have little or no control over appearancechanges our model introduces a new regularization that can effectively suppress the negative effects of appearance changing areas in particular we develop a piecewise regularization on the tangent space of diffeomorphic transformations also known as initial velocity fields via learned segmentation maps of abnormal regions the geometric transformation and appearance changes are treated as joint tasks that are mutually beneficial our model metamorph is more robust and accurate when searching for an optimal registration solution under the guidance of segmentation which in turn improves the segmentation performance by providing appropriately augmented training labels we validate metamorph on real 3d human brain tumor magnetic resonance imaging mri scans experimental results show that our model outperforms the stateoftheart learningbased registration models the proposed metamorph has great potential in various imageguided clinical interventions eg realtime imageguided navigation systems for tumor removal surgery",Brain
Contrastive Model Adaptation for Cross-Condition Robustness in Semantic  Segmentation,https://doi.org/10.48550/arxiv.2303.05194,2023,"standard unsupervised domain adaptation methods adapt models from a source to a target domain using labeled source data and unlabeled target data jointly in model adaptation on the other hand access to the labeled source data is prohibited ie only the sourcetrained model and unlabeled target data are available we investigate normaltoadverse condition model adaptation for semantic segmentation whereby imagelevel correspondences are available in the target domain the target set consists of unlabeled pairs of adverse and normalcondition street images taken at gpsmatched locations our method cma leverages such image pairs to learn conditioninvariant features via contrastive learning in particular cma encourages features in the embedding space to be grouped according to their conditioninvariant semantic content and not according to the condition under which respective inputs are captured to obtain accurate crossdomain semantic correspondences we warp the normal image to the viewpoint of the adverse image and leverage warpconfidence scores to create robust aggregated features with this approach we achieve stateoftheart semantic segmentation performance for model adaptation on several normaltoadverse adaptation benchmarks such as acdc and dark zurich we also evaluate cma on a newly procured adversecondition generalization benchmark and report favorable results compared to standard unsupervised domain adaptation methods despite the comparative handicap of cma due to source data inaccessibility code is available at httpsgithubcombrdavcma",Cardiac
M3AE: Multimodal Representation Learning for Brain Tumor Segmentation  with Missing Modalities,https://doi.org/10.48550/arxiv.2303.05302,2023,"multimodal magnetic resonance imaging mri provides complementary information for subregion analysis of brain tumors plenty of methods have been proposed for automatic brain tumor segmentation using four common mri modalities and achieved remarkable performance in practice however it is common to have one or more modalities missing due to image corruption artifacts acquisition protocols allergy to contrast agents or simply cost in this work we propose a novel twostage framework for brain tumor segmentation with missing modalities in the first stage a multimodal masked autoencoder m3ae is proposed where both random modalities ie modality dropout and random patches of the remaining modalities are masked for a reconstruction task for selfsupervised learning of robust multimodal representations against missing modalities to this end we name our framework m3ae meanwhile we employ model inversion to optimize a representative fullmodal image at marginal extra cost which will be used to substitute for the missing modalities and boost performance during inference then in the second stage a memoryefficient self distillation is proposed to distill knowledge between heterogenous missingmodal situations while finetuning the model for supervised segmentation our m3ae belongs to the catchall genre where a single model can be applied to all possible subsets of modalities thus is economic for both training and deployment extensive experiments on brats 2018 and 2020 datasets demonstrate its superior performance to existing stateoftheart methods with missing modalities as well as the efficacy of its components our code is available at httpsgithubcomccarlium3ae",Brain
M3AE: Multimodal Representation Learning for Brain Tumor Segmentation  with Missing Modalities,https://doi.org/10.48550/arxiv.2303.05302,2023,"multimodal magnetic resonance imaging mri provides complementary information for subregion analysis of brain tumors plenty of methods have been proposed for automatic brain tumor segmentation using four common mri modalities and achieved remarkable performance in practice however it is common to have one or more modalities missing due to image corruption artifacts acquisition protocols allergy to contrast agents or simply cost in this work we propose a novel twostage framework for brain tumor segmentation with missing modalities in the first stage a multimodal masked autoencoder m3ae is proposed where both random modalities ie modality dropout and random patches of the remaining modalities are masked for a reconstruction task for selfsupervised learning of robust multimodal representations against missing modalities to this end we name our framework m3ae meanwhile we employ model inversion to optimize a representative fullmodal image at marginal extra cost which will be used to substitute for the missing modalities and boost performance during inference then in the second stage a memoryefficient self distillation is proposed to distill knowledge between heterogenous missingmodal situations while finetuning the model for supervised segmentation our m3ae belongs to the catchall genre where a single model can be applied to all possible subsets of modalities thus is economic for both training and deployment extensive experiments on brats 2018 and 2020 datasets demonstrate its superior performance to existing stateoftheart methods with missing modalities as well as the efficacy of its components our code is available at httpsgithubcomccarlium3ae",Brain
Penalized Deep Partially Linear Cox Models with Application to CT Scans  of Lung Cancer Patients,https://doi.org/10.48550/arxiv.2303.05341,2023,"lung cancer is a leading cause of cancer mortality globally highlighting the importance of understanding its mortality risks to design effective patientcentered therapies the national lung screening trial nlst was a nationwide study aimed at investigating risk factors for lung cancer the study employed computed tomography texture analysis ctta which provides objective measurements of texture patterns on ct scans to quantify the mortality risks of lung cancer patients partially linear cox models are becoming a popular tool for modeling survival outcomes as they effectively handle both established risk factors such as age and other clinical factors and new risk factors such as image features in a single framework the challenge in identifying the texture features that impact cancer survival is due to their sensitivity to factors such as scanner type segmentation and organ motion to overcome this challenge we propose a novel penalized deep partially linear cox model penalized dplc which incorporates the scad penalty to select significant texture features and employs a deep neural network to estimate the nonparametric component of the model accurately we prove the convergence and asymptotic properties of the estimator and compare it to other methods through extensive simulation studies evaluating its performance in risk prediction and feature selection the proposed method is applied to the nlst study dataset to uncover the effects of key clinical and imaging risk factors on patients survival our findings provide valuable insights into the relationship between these factors and survival outcomes",Lung
Federated Learning with Research Prototypes: Application to Multi-Center MRI-based Detection of Prostate Cancer with Diverse Histopathology,https://doi.org/10.1016/j.acra.2023.02.012,2023,"early prostate cancer detection and staging from mri is extremely challenging for both radiologists and deep learning algorithms but the potential to learn from large and diverse datasets remains a promising avenue to increase their performance within and across institutions to enable this for prototypestage algorithms where the majority of existing research remains we introduce a flexible federated learning framework for crosssite training validation and evaluation of custom deep learning prostate cancer detection algorithmswe introduce an abstraction of prostate cancer groundtruth that represents diverse annotation and histopathology data we maximize use of this groundtruth if and when they are available using ucnet a custom 3d unet that enables simultaneous supervision of pixelwise regionwise and glandwise classification we leverage these modules to perform crosssite federated training using 1400 heterogeneous multiparameteric prostate mri exams from two university hospitalswe observe a positive result with significant improvements in crosssite generalization performance with negligible intrasite performance degradation for both lesion segmentation and perlesion binary classification of clinicallysignificant prostate cancer crosssite lesion segmentation performance intersectionoverunion iou improved by 100 while crosssite lesion classification performance overall accuracy improved by 95148 depending on the optimal checkpoint selected by each sitefederated learning can improve the generalization performance of prostate cancer detection models across institutions while protecting patient health information and institutionspecific code and data however even more data and participating institutions are likely required to improve the absolute performance of prostate cancer classification models to enable adoption of federated learning with limited reengineering of federated components we opensource our fltools system at httpsfederateducsfedu including examples that can be easily adapted to other medical imaging deep learning projects",Prostate
Application of Medical Image 3D Visualization Web Platform in Auxiliary Diagnosis and Preoperative Planning,https://doi.org/10.18178/joig.11.1.32-39,2023,"threedimensional visualization of medical image data can enable doctors to observe images from more angles and higher dimensions it is of great significance for doctors to assist in diagnosis and preoperative planning most 3d visualization systems are based on desktop applications which are too dependent on hardware and operating system this makes it difficult to use across platforms and maintain webbased systems tend to have limited capabilities to this end we developed a web application which not only provides dicom digital imaging and communications in medicine image browsing and annotation functions but also provides threedimensional postprocessing functions of multiplanar reconstruction volume rendering lung parenchyma segmentation and brain mri magnetic resonance imaging analysis in order to improve the rendering speed we use the marching cube algorithm for 3d reconstruction in the background in an asynchronous way and save the reconstructed model as gltf gl transmission format at the same time draco compression algorithm is used to optimize the gltf model to achieve more efficient rendering after performance evaluation the system reconstructed a ct computed tomography series of 242 slices and the optimized model was only 637mb with a rendering time of less than 25s threedimensional visualization of the lung parenchyma clearly shows the volume location and shape of pulmonary nodules the segmentation and reconstruction of different brain tissues can reveal the spatial threedimensional structure and adjacent relationship of glioma in the brain which has great application value in auxiliary diagnosis and preoperative planning",Brain
Application of Medical Image 3D Visualization Web Platform in Auxiliary Diagnosis and Preoperative Planning,https://doi.org/10.18178/joig.11.1.32-39,2023,"threedimensional visualization of medical image data can enable doctors to observe images from more angles and higher dimensions it is of great significance for doctors to assist in diagnosis and preoperative planning most 3d visualization systems are based on desktop applications which are too dependent on hardware and operating system this makes it difficult to use across platforms and maintain webbased systems tend to have limited capabilities to this end we developed a web application which not only provides dicom digital imaging and communications in medicine image browsing and annotation functions but also provides threedimensional postprocessing functions of multiplanar reconstruction volume rendering lung parenchyma segmentation and brain mri magnetic resonance imaging analysis in order to improve the rendering speed we use the marching cube algorithm for 3d reconstruction in the background in an asynchronous way and save the reconstructed model as gltf gl transmission format at the same time draco compression algorithm is used to optimize the gltf model to achieve more efficient rendering after performance evaluation the system reconstructed a ct computed tomography series of 242 slices and the optimized model was only 637mb with a rendering time of less than 25s threedimensional visualization of the lung parenchyma clearly shows the volume location and shape of pulmonary nodules the segmentation and reconstruction of different brain tissues can reveal the spatial threedimensional structure and adjacent relationship of glioma in the brain which has great application value in auxiliary diagnosis and preoperative planning",Lung
Classification of brain tumor using a multistage approach based on RELM and MLBP,https://doi.org/10.4108/eetpht.v8i4.3082,2023,"introduction automatic segmentation and classification of brain tumors help in improvement of treatment which will increase the life of the patient tumor may be noncancerous benign or cancerous malignant precancerous cells may also form into cancerobjectives hough cnn is applied for selected section which applies hough casting technique in segmentation methods a multistage methodof extracting features with multistage neighbouring is done for emerging an exact brain tumor classifying methodologyresults in this dataset three types of brain tumors are available they are meningioma glioma and pituitary conclusion this paperpresented an efficient brain tumor classification approach which involves multiscale preprocessing multiscale feature extraction and classification",Brain
Lung Nodule CT Image Segmentation Model Based on Multiscale Dense Residual Neural Network,https://doi.org/10.3390/math11061363,2023,"to solve the problem of the low segmentation accuracy of lung nodule ct images using unet an improved method for segmentation of lung nodules by unet was proposed initially the dense network connection and sawtooth expanded convolution design was added to the feature extraction part and a local residual design was adopted in the upsampling process finally the effectiveness of the proposed algorithm was evaluated using the lidcidri lung nodule public dataset the results showed that the improved algorithm had 703 1405 and 1043 higher performance than the unet segmentation algorithm under the three loss functions of dc miou and se and the accuracy was 245 higher compared with that of unet thus the proposed method had an effective network structure",Lung
Importance of Aligning Training Strategy with Evaluation for Diffusion  Models in 3D Multiclass Segmentation,https://doi.org/10.48550/arxiv.2303.06040,2023,"recently denoising diffusion probabilistic models ddpm have been applied to image segmentation by generating segmentation masks conditioned on images while the applications were mainly limited to 2d networks without exploiting potential benefits from the 3d formulation in this work for the first time ddpms are used for 3d multiclass image segmentation we make three key contributions that all focus on aligning the training strategy with the evaluation methodology and improving efficiency firstly the model predicts segmentation masks instead of sampled noise and is optimised directly via dice loss secondly the predicted mask in the previous time step is recycled to generate noisecorrupted masks to reduce information leakage finally the diffusion process during training was reduced to five steps the same as the evaluation through studies on two large multiclass data sets prostate mr and abdominal ct we demonstrated significantly improved performance compared to existing ddpms and reached competitive performance with nondiffusion segmentation models based on unet within the same compute budget the jaxbased diffusion framework has been released on httpsgithubcommathpluscodeimgxdiffseg",Prostate
Semi-supervised Medical Image Segmentation with Low-Confidence Consistency and Class Separation,https://doi.org/10.1109/isbp57705.2023.10061306,2023,"deep learning has achieved a great success in various fields such as image classification semantic segmentation and so on but its excellent performance tends to rely on a large amount of data annotations that are hard to collect especially in dense prediction tasks like medical image segmentation semisupervised learning ssl as a popular solution relieves the burden of labeling however most of current semisupervised medical image segmentation methods treat each pixel equally and underestimate the importance of indistinguishable and lowproportion pixels which are drowned in easily distinguishable but highproportion pixels we believe that these regions with less attention tend to contain crucial and indispensable information to obtain better segmentation performance therefore we propose a simple but effective method for semisupervised medical image segmentation task via enforcing lowconfidence consistency and applying lowconfidence class separation concretely we separate low and highconfidence pixels via the maximum probability values of models predictions and only lowconfidence pixels are kept for these remaining pixels in the mean teacher framework consistency is enforced for invariant predictions between student and teacher in the output level and class separation is applied for promoting representations close to corresponding class prototypes in the feature level we evaluated the proposed approach on two public datasets of cardiac achieving a higher performance than the stateoftheart semisupervised methods on both datasets",Cardiac
U-Net multi-modality glioma MRIs segmentation combined with attention,https://doi.org/10.1109/isbp57705.2023.10061312,2023,"glioma the most common primary intracranial tumor is known as the brain killer accounting for 27 of all central nervous system tumors and 80 of malignant tumors and is one of the most difficult and refractory tumors to treat in neurosurgery the development of medical imaging technology has simplified the diagnosis of the disease and in order to avoid or reduce the errors of manual segmentation deep learning based segmentation of glioma has become the hope of radiologists and clinicians accurate segmentation of gliomas is an important prerequisite for making glioma diagnosis providing treatment plans and evaluating treatment outcomes to effectively target the characteristics of multimodal glioma mri and the shortcomings of cnnsbased unetbased glioma segmentation methods a method of 2dcnns segmentation results based on attention mechanism is proposed in this study the datasets of brats2018 and brats2019 were included and the segmentation results were evaluated using three metrics dice coefficient positive predictive value and sensitivity the experimental results show that the proposed segmentation method can accurately segment gliomas",Brain
U-Net multi-modality glioma MRIs segmentation combined with attention,https://doi.org/10.1109/isbp57705.2023.10061312,2023,"glioma the most common primary intracranial tumor is known as the brain killer accounting for 27 of all central nervous system tumors and 80 of malignant tumors and is one of the most difficult and refractory tumors to treat in neurosurgery the development of medical imaging technology has simplified the diagnosis of the disease and in order to avoid or reduce the errors of manual segmentation deep learning based segmentation of glioma has become the hope of radiologists and clinicians accurate segmentation of gliomas is an important prerequisite for making glioma diagnosis providing treatment plans and evaluating treatment outcomes to effectively target the characteristics of multimodal glioma mri and the shortcomings of cnnsbased unetbased glioma segmentation methods a method of 2dcnns segmentation results based on attention mechanism is proposed in this study the datasets of brats2018 and brats2019 were included and the segmentation results were evaluated using three metrics dice coefficient positive predictive value and sensitivity the experimental results show that the proposed segmentation method can accurately segment gliomas",Brain
A Comparative Study on Subdural Brain Hemorrhage Segmentation,https://doi.org/10.1007/978-3-031-27099-4_24,2023,"brain hemorrhages are one of the most dangerous disease groups if not detected early it can lead to death or severe disability the most common method used to detect bleeding is the evaluation of computed tomography ct images belonging to the bleeding area by specialist physicians considering the difficulty of access to neurosurgery specialists and the lack of expertise of other doctors in emergency intervention on the subject there is a need for decision support mechanisms to assist physicians in the diagnosis and treatment process artificial intelligencebased systems to be used for this purpose can accelerate the diagnosis and treatment process while reducing the burden on physicians in this study the suitability of mask regionbased convolutional neural network mask rcnn cascade regionbased convolutional neural network cascade rcnn mask scoring regionbased convolutional neural network ms rcnn hybrid task cascade htc you only look at coefficients yolact instances as queries queryinst and sample consistency network scnet methods investigated for the problem of detection and segmentation of subdural brain hemorrhages the performance of the methods was determined over the images in the cq500 dataset this is one of the few studies that perform segmentation of subdural cerebral hemorrhages using ct images from an open dataset the results were evaluated according to intersection over union iou and mean average precision map metrics experimental results showed that two methods could detect and segment subdural hemorrhages more accurately than the others",Brain
Ultrasound Segmentation Using a 2D UNet with Bayesian Volumetric Support,https://doi.org/10.1007/978-3-031-27324-7_8,2023,"we present a novel 2d segmentation neural network design for the segmentation of tumour tissue in intraoperative ultrasound ius due to issues with brain shift and tissue deformation preoperative imaging for tumour resection has limited reliability within the operating room or ius serves as a tool for improving tumour localisation and boundary delineation our proposed method takes inspiration from bayesian networks rather than using a conventional 3d unet we develop a technique which samples from the volume around the query slice and perform multiple segmentations which provides volumetric support to improve the accuracy of the segmentation of the query slice our results show that our proposed architecture achieves an 004 increase in the validation dice score compared to the benchmark network",Brain
Segmentation of Intra-operative Ultrasound Using Self-supervised Learning Based 3D-ResUnet Model with Deep Supervision,https://doi.org/10.1007/978-3-031-27324-7_7,2023,"intraoperative ultrasound ius is a robust and relatively inexpensive technique to track intraoperative tissue shift and surgical tools automatic algorithms for brain tissue segmentation in ius especially brain tumors and resection cavity can greatly facilitate the robustness and accuracy of brain shift correction through image registration and allow easy interpretation of the ius this has the potential to improve surgical outcomes and patient survival rates in this paper we have proposed a selfsupervised twostage model for the intraoperative ultrasound ius task in the first stage we trained the encoder of our proposed 3dresunet model using the selfsupervised contrastive learning the selfsupervised learning offers the promise of utilizing unlabeled data the training samples are used in selfsupervision to train the encoder of the proposed 3dresunet model and utilized this encoder as a pretrained weight for the intraoperative ultrasound ius segmentation in the second stage the pretrained weightedbased 3dresunet proposed model was used to train on the training dataset for ius segmentation experiment on curious 22 challenge showed that our proposed solution showed significantly better performance before during and after intraoperative ultrasound ius segmentation the code is publicly available httpsgithubcomrespectknowledgessresunetintraoperativeultrasoundiustumorsegmentation",Brain
Domain-aware Dual Attention for Generalized Medical Image Segmentation on Unseen Domains,https://doi.org/10.1109/jbhi.2023.3251380,2023,"recently there has been significant progress in medical image segmentation utilizing deep learning techniques however these achievements largely rely on the supposition that the source and target domain data are identically distributed and the direct application of related methods without addressing the distribution shift results in dramatic degradation in realistic clinical environments current approaches concerning the distribution shift either require the target domain data in advance for adaptation or focus only on the distribution shift across domains while ignoring the intradomain data variation this paper proposes a domainaware dual attention network for the generalized medical image segmentation task on unseen target domains to alleviate the severe distribution shift between the source and target domains an extrinsic attention ea module is designed to learn image features with knowledge originating from multisource domains moreover an intrinsic attention ia module is also proposed to handle the intradomain variation by individually modeling the pixelregion relations derived from an image the ea and ia modules complement each other well in terms of modeling the extrinsic and intrinsic domain relationships respectively to validate the model effectiveness comprehensive experiments are conducted on various benchmark datasets including the prostate segmentation in magnetic resonance imaging mri scans and the optic cupdisc segmentation in fundus images the experimental results demonstrate that our proposed model effectively generalizes to unseen domains and exceeds the existing advanced approaches",Prostate
Performance Analysis of Ischemic Stroke Lesion Segmentation in Brain MR Images using Histogram based Filter Enhanced FCM,https://doi.org/10.1109/icssit55814.2023.10061114,2023,"a medical condition which threatens life by blocking brains blood supplying arteries is called ischemic stroke an early and accurate diagnosis of brain stroke is possible through evaluation of different modalities dwi flair tl t2 of medical image format available in magnetic resonance imaging mrd delineation of stroke lesion from whole brain mri manually by expert radiologists and neurologist consumes larger proportion of time and subject to intra and interobserver variation hence there is a demanding need of computer based automated algorithm which extracts out the stroke lesions from the whole brain mri and accelerate the process of early stroke diagnosis with the above objective this work proposes histogram based filter enhanced fuzzy c means that brings in the pro role played by histogram unique grey level wise clustering rather than pixel wise clustering as followed in classical fcm the objective function of histogram based fcm is smoothened further by filtering through the median filter which incorporates spatial information into the fcm clustering technique where local information alone is considered above changes in classical fuzzy c means clustering technique through histogram and median filters provides a greater improvement with maximum value of 99 accuracy in dwi and flair 79 dice in dwi 9s precision in dwi ss sensitivity in dwi when compared with available state of art methods standard fcm fcm s1 fcm s2 and enfcm",Brain
Brain Metastasis Tumor Detection using Image Segmentation and VGG16 Architecture,https://doi.org/10.1109/icssit55814.2023.10061029,2023,"in recent years brain tumors have risen to the position of top cause of mortality around the globe a brain tumor is defined as abnormal cell growth in the brain tumors may be categorized into two broad categories benign and cancerous tumors the brain may develop cancerous tumors and there are additional diseases known as brain metastasis tumors that spread from other places the prompt detection and categorization of this tumor are critical as they may reveal the probable diagnosis and treatment plan in this researchbrain metastasis tumors are detected by building a model using vgg16 architecture the kaggle brain tumor data collection is used for train and evaluate the models specified as described in the study the effectiveness of the designs is evaluated and performance traits like accuracy sensitivity and specificity are calculated and contrasted alexnet and googlenet",Brain
MedNet: A Segmentation Algorithm for Effective Lung cancer Diagnosis,https://doi.org/10.1109/icssit55814.2023.10061117,2023,"the detection of lung cancer is difficult and also impeded by the use of computed tomography for humans due to human error rate the prediction is inaccurate with the advanced techniques such as deep learning the presence of cancer can be determined and segmented effectively improvised deep learning models in artificial intelligence have generated incredible outputs as well as the traditional methods in various fields in the past analysis presently many researchers are interested in developing various deep learning methodologies to accumulate and elevate the performance of various systems in detecting lung diseases along with computed tomography images but the existing algorithms show lesser accuracy in performing segmentation of the cancerous part in this proposed work a novel algorithm for separating the cancer affected area in the lungs the segregation of cancer infected area from unaffected part of lungs in computed tomography image is known as segmentation in this proposed system a segmentation algorithm called mednet is developed in this research work mednet is introduced and trained on datasets of lungs that contains computed tomography images of lungs to execute segmentation of lung cancer three different layers such as 30 convolutional layers 3 bidirectional convolutional layers and 3 maxpooling layers are involved in mednet and proposed in such a way to overcome the existing disadvantages effectively and to increase the accuracy",Lung
MedNet: A Segmentation Algorithm for Effective Lung cancer Diagnosis,https://doi.org/10.1109/icssit55814.2023.10061117,2023,"the detection of lung cancer is difficult and also impeded by the use of computed tomography for humans due to human error rate the prediction is inaccurate with the advanced techniques such as deep learning the presence of cancer can be determined and segmented effectively improvised deep learning models in artificial intelligence have generated incredible outputs as well as the traditional methods in various fields in the past analysis presently many researchers are interested in developing various deep learning methodologies to accumulate and elevate the performance of various systems in detecting lung diseases along with computed tomography images but the existing algorithms show lesser accuracy in performing segmentation of the cancerous part in this proposed work a novel algorithm for separating the cancer affected area in the lungs the segregation of cancer infected area from unaffected part of lungs in computed tomography image is known as segmentation in this proposed system a segmentation algorithm called mednet is developed in this research work mednet is introduced and trained on datasets of lungs that contains computed tomography images of lungs to execute segmentation of lung cancer three different layers such as 30 convolutional layers 3 bidirectional convolutional layers and 3 maxpooling layers are involved in mednet and proposed in such a way to overcome the existing disadvantages effectively and to increase the accuracy",Lung
Fuzzy Hybrid Filtration based Rician Noise Removal and Classification of MRI Images without Segmentation using Deep Learning Technique,https://doi.org/10.1109/icssit55814.2023.10061104,2023,"the research aims to classify magnetic resonance imaging mri without segmentation to detect brain diseases to classify the mri images the dataset has to be preprocessed and remove the rician noise in mri images before the classification process to reduce noise in mri images developed a fuzzy hybrid filtration approach with automatically reduce rician noise technologies and quick advancements in the field of brain scans have always played an important role in evaluating and concentrating fresh perspectives on brain structure and functioning deep learning methods have shown outstanding results in classifications after preprocessing a methodology towards image classification utilizing a deep wavelet auto based encoder dwae is described which incorporates the basic feature based reduction property of the autoencoder with the image classification property of a waveletbased transformation and detects brain disease the mixture has a huge impact on shrinking the features and functionality for performing future supervised classification of brain disease with deep neural network dnn the dwae classifiers results have been compared to that of other existing classifiers including such autoencoder and it was shown that the proposed technique outperforms the others",Brain
Enhancing Privacy of information with Data Embedding in Medical MRI Images Based on Segmentation and HVS Model,https://doi.org/10.51519/journalisi.v5i1.423,2023,"the development of communications technology and the arrival of medicine modern equipment in the health domain has caused the diagnosis and treatment methods to be considered from a distance and medical centers are equipped with telemedicine systems forensic medicine organizations with daily clients and outpatient examinations such as accident clients conflict returns as well as spousal abuse doctors and employees of the organization also serve as one of the powerful arms of the judiciary following up on important cases in the medical laboratory and psychiatric commissions so that they can take steps to realize the rights of the people patient data security has become a serious concern for professionals and one of the methods is using data embedding to the protection against these risks in this method medical informatics telemedicine and forensic medicine organizations has played a pivotal role and any mistake in the reporting can be catastrophic the main purpose of this research is to present data on eprs with enhancing data embedding based on ssim and hvs with the help of medical image segmentation and focus on brain mri images in this study innovations include the addition of the hvs block based on the ssim criterion to meet transparency and robustness conditions selection of the embedding coefficient k is considered adaptively depending on the degree of uniformity of the n roi region with the image quality factor the coordinates of roi areas in one of the dct and dwt conversion blocks have been demonstrated to have better performance at concealment eprs the choice of coefficients afk which consists of the optimization frequency sensitivity function and spatial property is comparatively done to match the visual perception of the visual system the present study aims to improve the effectiveness of the proposed method improve the security level and the confidentiality of patient information and integrate the storage of patient information and image the simulation results of the proposed method considering the parameters of embedding and transparency in comparison with other methods have been done using evaluation criteria including mse psnr nc ssim and ber",Brain
AUTOMATIC 2D AND 3D SEGMENTATION OF GLIOBLASTOMA BRAIN TUMOR,https://doi.org/10.4015/s1016237222500557,2023,"the brain tumor is the most common destructive and deadly disease in general various imaging modalities such as ct mri and pet are used to evaluate the brain tumor magnetic resonance imaging mri is a prominent diagnostic method for evaluating these tumors gliomas due to their malignant nature and rapid development are the most common and aggressive form of brain tumors in the clinical routine the method of identifying tumor borders from healthy cells is still a difficult task manual segmentation takes time so we use a deep convolutional neural network to improve efficiency we present a combined dnn architecture using unet and mobilenetv2 it exploits both local characteristics and more global contextual characteristics from the 2d mri flair images the proposed network has encoder and decoder architecture the performance metrices such as dice loss dice coefficient accuracy and iou have been calculated automated segmentation of 3d mri is essential for the identification assessment and treatment of brain tumors although there is significant interest in machinelearning algorithms for computerized segmentation of brain tumors the goal of this work is to perform 3d volumetric segmentation using bratumia it is a widely available software application used to separate tumor characteristics on 3d brain mr volumes bratumia has lately been used in a number of clinical trials in this work we have segmented 2d slices and 3d volumes of mri brain tumor images",Brain
Editorial: Automatic methods for multiple sclerosis new lesions detection and segmentation,https://doi.org/10.3389/fnins.2023.1176625,2023,"editorial article front neurosci 14 march 2023sec brain imaging methods volume 17 2023 httpsdoiorg103389fnins20231176625",Brain
An automated pipeline to create an atlas of in situ hybridization gene  expression data in the adult marmoset brain,https://doi.org/10.48550/arxiv.2303.06857,2023,"we present the first automated pipeline to create an atlas of in situ hybridization gene expression in the adult marmoset brain in the same stereotaxic space the pipeline consists of segmentation of gene expression from microscopy images and registration of images to a standard space automation of this pipeline is necessary to analyze the large volume of data in the genomewide wholebrain dataset and to process images that have varying intensity profiles and expression patterns with minimal human bias to reduce the number of labelled images required for training we develop a semisupervised segmentation model we further develop an iterative algorithm to register images to a standard space enabling comparative analysis between genes and concurrent visualization with other datasets thereby facilitating a more holistic understanding of primate brain structure and function",Brain
Weakly Unsupervised Domain Adaptation for Vestibular Schwannoma  Segmentation,https://doi.org/10.48550/arxiv.2303.07093,2023,"vestibular schwannoma vs is a noncancerous tumor located next to the ear that can cause hearing loss most brain mri images acquired from patients are contrastenhanced t1 cet1 with a growing interest in highresolution t2 images hrt2 to replace cet1 which involves the use of a contrast agent as hrt2 images are currently scarce it is less likely to train robust machine learning models to segment vs or other brain structures in this work we propose a weakly supervised machine learning approach that learns from only cet1 scans and adapts to segment two structures from hrt2 scans the vs and the cochlea from the crossmoda dataset our model 1 generates fake hrt2 scans from cet1 images and segmentation masks 2 is trained using the fake hrt2 scans 3 predicts the augmented real hrt2 scans and 4 is retrained again using both the fake and real hrt2 the final result of this model has been computed on an unseen testing dataset provided by the 2022 crossmoda challenge organizers the mean dice score and average symmetric surface distance assd are 078 and 046 respectively the predicted segmentation masks achieved a dice score of 083 and an assd of 056 on the vs and a dice score of 074 and an assd of 035 on the cochleas",Brain
Mirror U-Net: Marrying Multimodal Fission with Multi-task Learning for  Semantic Segmentation in Medical Imaging,https://doi.org/10.48550/arxiv.2303.07126,2023,"positron emission tomography pet and computer tomography ct are routinely used together to detect tumors petct segmentation models can automate tumor delineation however current multimodal models do not fully exploit the complementary information in each modality as they either concatenate pet and ct data or fuse them at the decision level to combat this we propose mirror unet which replaces traditional fusion methods with multimodal fission by factorizing the multimodal representation into modalityspecific branches and an auxiliary multimodal decoder at these branches mirror unet assigns a task tailored to each modality to reinforce unimodal features while preserving multimodal features in the shared representation in contrast to previous methods that use either fission or multitask learning mirror unet combines both paradigms in a unified framework we explore various task combinations and examine which parameters to share in the model we evaluate mirror unet on the autopet petct and on the multimodal msd braintumor datasets demonstrating its effectiveness in multimodal segmentation and achieving stateoftheart performance on both datasets our code will be made publicly available",Brain
Analysis of 3D nuclear spatial architecture for prostate cancer risk stratification (Conference Presentation),https://doi.org/10.1117/12.2649164,2023,"nondestructive 3d microscopy enables the accurate characterization of diagnostically and prognostically significant microstructures in clinical specimens with significantly increased volumetric coverage than traditional 2d histology we are using opentop lightsheet microscopy to image prostate cancer biopsies and investigating the prognostic significance of 3d spatial features of nuclei within prostate cancer microstructures using a previously published 3d nuclear segmentation workflow we identify a preliminary set of 3d graphbased nuclear features to quantify the 3d spatial arrangement of nuclei in prostate cancer biopsies using a machine classifier we identify the features which prognosticate prostate cancer risk and demonstrate agreement with patient outcomes",Prostate
Multi-domain cotraining for tissue segmentation in fixed and fresh brain tissue using Mueller polarimetry (Conference Presentation),https://doi.org/10.1117/12.2649787,2023,"delineating the boundary of a tumors from healthy brain tissue is a challenging task in neurosurgery mueller polarimetry imaging promises to visualise and segment these borders in realtime based on optical properties correlated with the directionality of densely packed whitematter fiberbundles in prior work we demonstrated deeplearning methods leveraging mueller polarimetry outperformed traditional approaches with similar segmentation tasks however formalinfixation vs fresh sample tissue and differences of human vs animal brain tissue properties may hinder the direct applicability to neurosurgical scenarios to overcome this potential limitation we propose a learningbased strategy by jointly training on augmented multidomain data together with model finetuning to improve tissue segmentation",Brain
Lung Cancer Prediction by Using Deep Learning method CNN,https://doi.org/10.21203/rs.3.rs-2614821/v1,2023,"abstract lung cancer is a significant public health concern and early identification can improve patient outcomes advanced machine learning approaches can increase the precision of computeraided diagnostic cad systems that use medical pictures to diagnose diseases such as ct scans which can help find lung cancer in this paper we examine the usage of image analysis and cad while also proposing an unique method for predicting lung cancer using convolutional neural network cnn approaches our study utilized a dataset of lung ct scans from patients with and without lung cancer the lung regions important characteristics were extracted from the preprocessed pictures using segmentation and feature extraction techniques after that we used these variables to train a cnn model to identify the likelihood of lung cancer our paper demonstrates the potential of cnn techniques and image analysis in predicting lung cancer with high accuracy rates the suggested method might be utilized to create more precise and efficient cad systems for diagnosing lung cancer possibly resulting in early identification and better patient outcomesfurther research is required to examine the clinical applications of this technique and to confirm these findings in bigger datasets",Lung
Two-Branch network for brain tumor segmentation using attention mechanism and super-resolution reconstruction,https://doi.org/10.1016/j.compbiomed.2023.106751,2023,"accurate segmentation of brain tumor plays an important role in mri diagnosis and treatment monitoring of brain tumor however the degree of lesions in each patients brain tumor region is usually inconsistent with large structural differences and brain tumor mr images are characterized by low contrast and blur current deep learning algorithms often cannot achieve accurate segmentation to address this problem we propose a novel endtoend brain tumor segmentation algorithm by integrating the improved 3d unet network and superresolution image reconstruction into one framework in addition the coordinate attention module is embedded before the upsampling operation of the backbone network which enhances the capture ability of local texture feature information and global location feature information to demonstrate the segmentation results of the proposed algorithm in different brain tumor mr images we have trained and evaluated the proposed algorithm on brats datasets and compared with other deep learning algorithms by dice similarity scores on the brats2021 dataset the proposed algorithm achieves the dice similarity score of 8961 8830 9105 and the hausdorff distance 95 of 1414 mm 7810 mm 4583 mm for the enhancing tumors tumor cores and whole tumors respectively the experimental results illuminate that our method outperforms the baseline 3d unet method and yields good performance on different datasets it indicated that it is robust to segmentation of brain tumor mr images with structures vary considerably",Brain
Two-Branch network for brain tumor segmentation using attention mechanism and super-resolution reconstruction,https://doi.org/10.1016/j.compbiomed.2023.106751,2023,"accurate segmentation of brain tumor plays an important role in mri diagnosis and treatment monitoring of brain tumor however the degree of lesions in each patients brain tumor region is usually inconsistent with large structural differences and brain tumor mr images are characterized by low contrast and blur current deep learning algorithms often cannot achieve accurate segmentation to address this problem we propose a novel endtoend brain tumor segmentation algorithm by integrating the improved 3d unet network and superresolution image reconstruction into one framework in addition the coordinate attention module is embedded before the upsampling operation of the backbone network which enhances the capture ability of local texture feature information and global location feature information to demonstrate the segmentation results of the proposed algorithm in different brain tumor mr images we have trained and evaluated the proposed algorithm on brats datasets and compared with other deep learning algorithms by dice similarity scores on the brats2021 dataset the proposed algorithm achieves the dice similarity score of 8961 8830 9105 and the hausdorff distance 95 of 1414 mm 7810 mm 4583 mm for the enhancing tumors tumor cores and whole tumors respectively the experimental results illuminate that our method outperforms the baseline 3d unet method and yields good performance on different datasets it indicated that it is robust to segmentation of brain tumor mr images with structures vary considerably",Brain
A Multi-Scale Channel Attention Network for Prostate Segmentation,https://doi.org/10.1109/tcsii.2023.3257728,2023,"prostate cancer is one of the most common malignant tumors in men magnetic resonance imaging mri has evolved to an important tool for the diagnosis of prostate cancer targeted biopsy is required for accurate diagnosis this often requires mriultrasound mrius fusion as the biopsy is usually performed using transrectal ultrasound accurate prostate segmentation on mri is essential for mrius fusion biopsy however the variation in prostate shape appearance and size makes the automatic segmentation challenging given the limit of the annotated data in this paper we propose a method using multiscale and channelwise selfattention csa to recalibrate the feature maps from multiple layers by embedding the multiscale csa on the skipconnection in a unet structure called as ucanet we show the consistent improvement of the prostate segmentation in dice iou and assd for comparison we also investigate the singlescale csa in the networks and incorporate the vision transformer to test if a transformer would boost the performance experiments on a public dataset with 204 prostate mri scans show that ucanet achieves the best performance and outperforms the stateoftheart methods for prostate segmentation such as enet unet usenet and transunet",Prostate
CMM: A CNN-MLP Model for COVID-19 Lesion Segmentation and Severity Grading,https://doi.org/10.1109/tcbb.2023.3253901,2023,"in this paper a cnnmlp model cmm is proposed for covid19 lesion segmentation and severity grading in ct images the cmm starts by lung segmentation using unet and then segmenting the lesion from the lung region using a multiscale deep supervised unet mdsunet finally implementing the severity grading by a multilayer preceptor mlp in mdsunet shape prior information is fused with the input ct image to reduce the searching space of the potential segmentation outputs the multiscale input compensates for the loss of edge contour information in convolution operations in order to enhance the learning of multiscale features the multiscale deep supervision extracts supervision signals from different upsampling points on the network in addition it is empirical that the lesion which has a whiter and denser appearance tends to be more severe in the covid19 ct image so the weighted mean grayscale value wmg is proposed to depict this appearance and together with the lung and lesion area to serve as input features for the severity grading in mlp to improve the precision of lesion segmentation a label refinement method based on the frangi vessel filter is also proposed comparative experiments on covid19 public datasets show that our proposed cmm achieves high accuracy on covid19 lesion segmentation and severity grading source codes and datasets are available at our github repository uri xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkhttpsgithubcomrobotvisionlabcovid19severitygradinggituri",Lung
Brain Tumour Segmentation using S-Net and SA-Net,https://doi.org/10.1109/access.2023.3257722,2023,"image segmentation is an application area of computer vision and digital image processing that partitions a digital image into multiple image regions or segments this process involves the extraction of a set of contours from the input digital image in such a manner that pixels belonging to a region share some common characteristics or computed properties such as color texture or intensity the application domain of image segmentation is widespread and includes video surveillance object detection traffic control systems and medical imaging the application of image segmentation techniques in the field of medical imaging can be further subcategorized into virtual surgery simulation diagnosis study of anatomical structures measurement of tissue volumes location of tumors and other pathologies in this study we have proposed two new convolutional neural network cnnbased models a snet and b attention snet sanet to perform image segmentation tasks in the field of medical imaging especially to generate segmentation masks for brain tumours if present in brain medical resonance imaging mri both proposed models were developed by considering unet as the base architecture the newly proposed models have leveraged the concept of merge block to infuse both the local and global context and attention block to focus on the region of interest having a specific object additionally it uses techniques such as data augmentation to utilize the available annotated samples more efficiently the proposed models achieved a dice similarity coefficient dsc measure of 078 and 080 for the highgrade glioma hgg and lowgrade glioma lgg datasets respectively",Brain
Exploring Weakly Supervised Semantic Segmentation Ensembles for Medical  Imaging Systems,https://doi.org/10.48550/arxiv.2303.07896,2023,"reliable classification and detection of certain medical conditions in images with stateoftheart semantic segmentation networks require vast amounts of pixelwise annotation however the public availability of such datasets is minimal therefore semantic segmentation with imagelevel labels presents a promising alternative to this problem nevertheless very few works have focused on evaluating this technique and its applicability to the medical sector due to their complexity and the small number of training examples in medical datasets classifierbased weakly supervised networks like class activation maps cams struggle to extract useful information from them however most stateoftheart approaches rely on them to achieve their improvements therefore we propose a framework that can still utilize the lowquality cam predictions of complicated datasets to improve the accuracy of our results our framework achieves that by first utilizing lower threshold cams to cover the target object with high certainty second by combining multiple lowthreshold cams that even out their errors while highlighting the target object we performed exhaustive experiments on the popular multimodal brats and prostate decathlon segmentation challenge datasets using the proposed framework we have demonstrated an improved dice score of up to 8 on brats and 6 on decathlon datasets compared to the previous stateoftheart",Brain
Exploring Weakly Supervised Semantic Segmentation Ensembles for Medical  Imaging Systems,https://doi.org/10.48550/arxiv.2303.07896,2023,"reliable classification and detection of certain medical conditions in images with stateoftheart semantic segmentation networks require vast amounts of pixelwise annotation however the public availability of such datasets is minimal therefore semantic segmentation with imagelevel labels presents a promising alternative to this problem nevertheless very few works have focused on evaluating this technique and its applicability to the medical sector due to their complexity and the small number of training examples in medical datasets classifierbased weakly supervised networks like class activation maps cams struggle to extract useful information from them however most stateoftheart approaches rely on them to achieve their improvements therefore we propose a framework that can still utilize the lowquality cam predictions of complicated datasets to improve the accuracy of our results our framework achieves that by first utilizing lower threshold cams to cover the target object with high certainty second by combining multiple lowthreshold cams that even out their errors while highlighting the target object we performed exhaustive experiments on the popular multimodal brats and prostate decathlon segmentation challenge datasets using the proposed framework we have demonstrated an improved dice score of up to 8 on brats and 6 on decathlon datasets compared to the previous stateoftheart",Prostate
CarveMix: A Simple Data Augmentation Method for Brain Lesion Segmentation,https://doi.org/10.1016/j.neuroimage.2023.120041,2023,"brain lesion segmentation provides a valuable tool for clinical diagnosis and research and convolutional neural networks cnns have achieved unprecedented success in the segmentation task data augmentation is a widely used strategy to improve the training of cnns in particular data augmentation approaches that mix pairs of annotated training images have been developed these methods are easy to implement and have achieved promising results in various image processing tasks however existing data augmentation approaches based on image mixing are not designed for brain lesions and may not perform well for brain lesion segmentation thus the design of this type of simple data augmentation method for brain lesion segmentation is still an open problem in this work we propose a simple yet effective data augmentation approach dubbed as carvemix for cnnbased brain lesion segmentation like other mixingbased methods carvemix stochastically combines two existing annotated images annotated for brain lesions only to obtain new labeled samples to make our method more suitable for brain lesion segmentation carvemix is lesionaware where the image combination is performed with a focus on the lesions and preserves the lesion information specifically from one annotated image we carve a region of interest roi according to the lesion location and geometry with a variable roi size the carved roi then replaces the corresponding voxels in a second annotated image to synthesize new labeled images for network training and additional harmonization steps are applied for heterogeneous data where the two annotated images can originate from different sources besides we further propose to model the mass effect that is unique to whole brain tumor segmentation during image mixing to evaluate the proposed method experiments were performed on multiple publicly available or private datasets and the results show that our method improves the accuracy of brain lesion segmentation the code of the proposed method is available at httpsgithubcomzhangxinrubitcarvemixgit",Brain
Automated Tumor Segmentation and Brain Tissue Extraction from Multiparametric MRI of Pediatric Brain Tumors: A Multi-Institutional Study,https://doi.org/10.1093/noajnl/vdad027,2023,"abstract background brain tumors are the most common solid tumors and the leading cause of cancerrelated death among all childhood cancers tumor segmentation is essential in surgical and treatment planning and response assessment and monitoring however manual segmentation is timeconsuming and has high interoperator variability we present a multiinstitutional deep learningbased method for automated brain extraction and segmentation of pediatric brain tumors based on multiparametric mri scans methods multiparametric scans t1w t1wce t2 and t2flair of 244 pediatric patients n215 internal and n29 external cohorts with de novo brain tumors including a variety of tumor subtypes were preprocessed and manually segmented to identify the brain tissue and tumor subregions into four tumor subregions ie enhancing tumor et nonenhancing tumor net cystic components cc and peritumoral edema ed the internal cohort was split into training n151 validation n43 and withheld internal test n21 subsets deepmedic a threedimensional convolutional neural network was trained and the model parameters were tuned finally the network was evaluated on the withheld internal and external test cohorts results dice similarity score mediansd was 091010088016 for the whole tumor 073027084029 for et 07919074027 for union of all nonenhancing components ie net cc ed and 098002 for brain tissue in both internalexternal test sets conclusions our proposed automated brain extraction and tumor subregion segmentation models demonstrated accurate performance on segmentation of the brain tissue and whole tumor regions in pediatric brain tumors and can facilitate detection of abnormal regions for further clinical measurements",Brain
Automatic Brain Tumour Subregion Segmentation from Multimodal MRIs Fusing Muti-channel and Spatial Features,https://doi.org/10.1088/1742-6596/2449/1/012034,2023,"abstract it is very necessary for disease diagnosis monitoring and treatment planning to locate and segment brain tumours from 3d mri images accurately 3d segmentation from mris means classifying each voxel in 3d space it is very conducive to the relevant biological measurements and further analysis of the lesion until now brain tumour segmentation from 3d biomedical images has been a challenging worldwide task due to the tumour features variousness which varies part of unet and concatenates these features which are upsampled to the same scale to grasp the channel weight and rois the bottleneck of the network is an improved dual path attention module which convergence the advantages of channel attention and spatial attention the proposed model has been validated in the online dataset of brats 2018 the mean dice score of enhancing tumours is 0772 the mean dice score of the whole tumour is 0907 the mean dice score of the tumour core is 0819 the effectiveness of the proposed method is proved by quantitative and qualitative evaluation",Brain
Automatic Brain Tumour Subregion Segmentation from Multimodal MRIs Fusing Muti-channel and Spatial Features,https://doi.org/10.1088/1742-6596/2449/1/012034,2023,"abstract it is very necessary for disease diagnosis monitoring and treatment planning to locate and segment brain tumours from 3d mri images accurately 3d segmentation from mris means classifying each voxel in 3d space it is very conducive to the relevant biological measurements and further analysis of the lesion until now brain tumour segmentation from 3d biomedical images has been a challenging worldwide task due to the tumour features variousness which varies part of unet and concatenates these features which are upsampled to the same scale to grasp the channel weight and rois the bottleneck of the network is an improved dual path attention module which convergence the advantages of channel attention and spatial attention the proposed model has been validated in the online dataset of brats 2018 the mean dice score of enhancing tumours is 0772 the mean dice score of the whole tumour is 0907 the mean dice score of the tumour core is 0819 the effectiveness of the proposed method is proved by quantitative and qualitative evaluation",Brain
PATTERN KNOWLEDGE DISCOVERY BASED LUNG CANCER CLASSIFICATION SYSTEM,https://doi.org/10.18137/cardiometry.2023.26.623628,2023,"an accurate detection of abnormal lung nodule detection is very important for effective treatment and surgical procedure to remove the nodules this paper introduces an efficient deep learning model to classify lung cancer in both left and right lung it consists of three important stages preprocessing lung region detection and abnormal lung nodule detection further a detailed discussion about the performance of the system is given using two benchmark databases 30 lung ct images taken from the elcap dataset and 130 lung ct images taken from the lidc dataset an algorithmic framework is first created for the purpose of segmenting left and right lung region by a morphological algorithm after removing the noise by a wiener filter a well defined deep learning architecture is designed for effective classification or detection of abnormal lung nodule detection by semantic classification the proposed system is validated on lidc and elcap database and provides an average accuracy of 9786",Lung
Lung Cancer Image Segmentation and Detection Using Deep Learning Algorithms,https://doi.org/10.18137/cardiometry.2023.26.556562,2023,"beforehand opinion of lung cancer is pivotal to insure restorative treatment and increase survival rates in recent times so numerous computers backed opinion cad systems are designed for opinion of several conditions lung cancer discovery at early stage has come veritably important and also veritably easy with image processing and deep literacy ways in this design lung case computer tomography ct checkup images are used to descry and classify the lung nodes and to descry the malice position of that node the ct checkup images are segmented usingunet armature then we were working with lung images for classifying the cancer positive or negative using cnn algorithms and transfer literacy models vgg16 by using this process we get further delicacy and perfect results along with that we apply the segmentation fashion to descry the which area complaint is actuated lung ct overlook imaging is the most constantly used system for diagnosing cancer still the examination of lung ct reviews is a grueling task and is prone to private variability in this design we developed a computer backed opinion system for automatic lung cancer discovery using lung ct overlook images from kaggle we employed deep transfer literacy to handle the failure of available data and designed a convolutional neural network cnn model along with the machine literacy styles random forest rf support vector machines svm and decision tree dt the proposed approach was estimated on intimately available lung ct checkup dataset",Lung
Manual lesion segmentations for traumatic brain injury characterization,https://doi.org/10.3389/fnimg.2023.1068591,2023,"traumatic brain injury tbi often results in heterogenous lesions that can be visualized through various neuroimaging techniques such as magnetic resonance imaging mri however injury burden varies greatly between patients and structural deformations often impact usability of available analytic algorithms therefore it is difficult to segment lesions automatically and accurately in tbi cohorts mislabeled lesions will ultimately lead to inaccurate findings regarding imaging biomarkers therefore manual segmentation is currently considered the gold standard as this produces more accurate masks than existing automated algorithms these masks can provide important lesion phenotype data including location volume and intensity among others there has been a recent push to investigate the correlation between these characteristics and the onset of post traumatic epilepsy pte a disabling consequence of tbi one motivation of the epilepsy bioinformatics study for antiepileptogenic therapy epibios4rx is to identify reliable imaging biomarkers of pte here we report the protocol and importance of our manual segmentation process in patients with moderatesevere tbi enrolled in epibios4rx through these methods we have generated a dataset of 127 validated lesion segmentation masks for tbi patients these groundtruths can be used for robust pte biomarker analyses including optimization of multimodal mri analysis via inclusion of lesioned tissue labels moreover our protocol allows for analysis of the refinement process though tedious the methods reported in this work are necessary to create reliable data for effective training of future machinelearning based lesion segmentation methods in tbi patients and subsequent pte analyses",Brain
CrossTransUnet: A new computationally inexpensive tumor segmentation model for brain MRI,https://doi.org/10.1109/access.2023.3257767,2023,"brain tumors are usually fatal diseases with low life expectancies due to the organs they affect even if the tumors are benign diagnosis and treatment of these tumors are challenging tasks even for experienced physicians and experts due to the heterogeneity of tumor cells in recent years advances in deep learning dl methods have been integrated to aid in the diagnosis detection and segmentation of brain neoplasms however segmentation is a computationally expensive process typically based on convolutional neural networks cnns in the unet framework while unet has shown promising results new models and developments can be incorporated into the conventional architecture to improve performance in this research we propose three new computationally inexpensive segmentation networks inspired by transformers these networks are designed in a 4stage deep encoderdecoder structure and implement our new crossattention model along with separable convolution layers to avoid the loss of dimensionality of the activation maps and reduce the computational cost of the models while maintaining high segmentation performance the new attention model is integrated in different configurations by modifying the transition layers encoder and decoder blocks the proposed networks are evaluated against the classical unet network showing that our networks have differences of up to an order of magnitude in the number of training parameters additionally one of the models outperforms unet achieving training in significantly less time and with a dice similarity coefficient dsc of up to 94 ensuring high effectiveness in brain tumor segmentation",Brain
Lung Nodule Segmentation and Low-Confidence Region Prediction with  Uncertainty-Aware Attention Mechanism,https://doi.org/10.48550/arxiv.2303.08416,2023,"radiologists have different training and clinical experiences so they may provide various segmentation annotations for a lung nodule which causes segmentation uncertainty among multiple annotations conventional methods usually chose a single annotation as the learning target or tried to learn a latent space of various annotations still they wasted the valuable information of consensus or disagreements ingrained in the multiple annotations this paper proposes an uncertaintyaware attention mechanism uaam which utilizes consensus or disagreements among annotations to produce a better segmentation in uaam we propose a multiconfidence mask mcm which is a combination of a lowconfidence lc mask and a highconfidence hc mask lc mask indicates regions with low segmentation confidence which may cause different segmentation options among radiologists following uaam we further design an uncertaintyguide segmentation network ugsnet which contains three modulesfeature extracting module captures a general feature of a lung nodule uncertaintyaware module produce three features for the annotations union intersection and annotation set finally intersectionunion constraining module use distances between three features to balance the predictions of final segmentation lc mask and hc mask to fully demonstrate the performance of our method we propose a complex nodule challenge on lidcidri which tests ugsnets segmentation performance on the lung nodules that are difficult to segment by unet experimental results demonstrate that our method can significantly improve the segmentation performance on nodules with poor segmentation by unet",Lung
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly  Detection,https://doi.org/10.48550/arxiv.2303.08452,2023,"early and accurate disease detection is crucial for patient management and successful treatment outcomes however the automatic identification of anomalies in medical images can be challenging conventional methods rely on large labeled datasets which are difficult to obtain to overcome these limitations we introduce a novel unsupervised approach called phanes pseudo healthy generative networks for anomaly segmentation our method has the capability of reversing anomalies ie preserving healthy tissue and replacing anomalous regions with pseudohealthy ph reconstructions unlike recent diffusion models our method does not rely on a learned noise distribution nor does it introduce random alterations to the entire image instead we use latent generative networks to create masks around possible anomalies which are refined using inpainting generative networks we demonstrate the effectiveness of phanes in detecting stroke lesions in t1w brain mri datasets and show significant improvements over stateoftheart sota methods we believe that our proposed framework will open new avenues for interpretable fast and accurate anomaly segmentation with the potential to support various clinicaloriented downstream tasks",Brain
<scp>DeepChestNet</scp> : Artificial intelligence approach for <scp>COVID</scp> ‐19 detection on computed tomography images,https://doi.org/10.1002/ima.22876,2023,"the conventional approach for identifying ground glass opacities ggo in medical imaging is to use a convolutional neural network cnn a subset of artificial intelligence which provides promising performance in covid19 detection however cnn is still limited in capturing structured relationships of ggo as the texture and shape of the ggo can be confused with other structures in the image in this paper a novel framework called deepchestnet is proposed that leverages structured relationships by jointly performing segmentation and classification on the lung pulmonary lobe and ggo leading to enhanced detection of covid19 with findings the performance of deepchestnet in terms of dice similarity coefficient is 9935 9973 and 9789 for the lung pulmonary lobe and ggo segmentation respectively the experimental investigations on deepchestnetlung deepchestnetlobe and deepchestnetcovid datasets and comparison with several stateoftheart approaches reveal the great potential of deepchestnet for diagnosis of covid19 disease",Lung
<scp>CA‐UNet</scp> : Convolution and attention fusion for lung nodule segmentation,https://doi.org/10.1002/ima.22878,2023,"lung cancer is one of the deadliest cancers in the world and is a serious threat to human life lung nodules are an early manifestation of lung cancer early detection and treatment of which can improve the survival rate of patients in order to accurately segment the lung nodule regions in lung ct images caunet an encoding and decoding structure based on convolution and attention fusion is proposed based on the unet network it has improved on two points first at the skip connection the global feature information is extracted using the swin transformer block and then fused with the preextraction features and subsequently fed into the corresponding layer of the decoder second each channel information is reweighted in the decoder by the channel attention module so that the network focuses on more important channels experimental results on the lidcidri public database of lung nodules showed that the intersection of union dice similarity coefficient precision and recall of the algorithm were 8242 8986 8907 and 9244 respectively the algorithm has better segmentation performance compared to other segmentation methods",Lung
Artificial Intelligence Approach for Early Detection of Brain Tumors Using MRI Images,https://doi.org/10.3390/app13063808,2023,"artificial intelligence ai is one of the most promising approaches to health innovation the use of ai in image recognition considerably extends findings beyond the constraints of human sight the application of ai in medical imaging which relies on picture interpretation is beneficial for automatic diagnosis diagnostic radiology is evolving from a subjective perceptual talent to a more objective science thanks to ai automatic object detection in medical images is an essential ai technology in medicine the problem of detecting brain tumors at an early stage is well advanced with convolutional neural network cnn and deep learning algorithms dla the problem is that those algorithms require a training phase with a big database of more than 500 images and timeconsuming with a complex computational and expensive infrastructure this study proposes a classical automatic segmentation method for detecting brain tumors in the early stage using mri images it is based on a multilevel thresholding technique on a harmony search algorithm hso the algorithm was developed to suit mri brain segmentation and parameters selection was optimized for the purpose multiple thresholds based on the variance and entropy functions break the histogram into multiple portions and different colors are associated with each portion to eliminate the tiny arias supposed as noise and detect brain tumors morphological operations followed by a connected component analysis are utilized after segmentation the brain tumor detection performance is judged using performance parameters such as accuracy dice coefficient and jaccard index the results are compared to those acquired manually by experts in the field the results were further compared with different cnn and dla approaches using brain images dataset called the brats 2017 challenge the average dice index was used as a performance measure for the comparison the results of the proposed approach were found to be competitive in accuracy to those obtained by cnn and dla methods and much better in terms of execution time computational complexity and data management",Brain
Artificial Intelligence Approach for Early Detection of Brain Tumors Using MRI Images,https://doi.org/10.3390/app13063808,2023,"artificial intelligence ai is one of the most promising approaches to health innovation the use of ai in image recognition considerably extends findings beyond the constraints of human sight the application of ai in medical imaging which relies on picture interpretation is beneficial for automatic diagnosis diagnostic radiology is evolving from a subjective perceptual talent to a more objective science thanks to ai automatic object detection in medical images is an essential ai technology in medicine the problem of detecting brain tumors at an early stage is well advanced with convolutional neural network cnn and deep learning algorithms dla the problem is that those algorithms require a training phase with a big database of more than 500 images and timeconsuming with a complex computational and expensive infrastructure this study proposes a classical automatic segmentation method for detecting brain tumors in the early stage using mri images it is based on a multilevel thresholding technique on a harmony search algorithm hso the algorithm was developed to suit mri brain segmentation and parameters selection was optimized for the purpose multiple thresholds based on the variance and entropy functions break the histogram into multiple portions and different colors are associated with each portion to eliminate the tiny arias supposed as noise and detect brain tumors morphological operations followed by a connected component analysis are utilized after segmentation the brain tumor detection performance is judged using performance parameters such as accuracy dice coefficient and jaccard index the results are compared to those acquired manually by experts in the field the results were further compared with different cnn and dla approaches using brain images dataset called the brats 2017 challenge the average dice index was used as a performance measure for the comparison the results of the proposed approach were found to be competitive in accuracy to those obtained by cnn and dla methods and much better in terms of execution time computational complexity and data management",Brain
Systematic assessment and review of techniques based on tumour detection in brain using MRI,https://doi.org/10.1080/21681163.2023.2181020,2023,"detecting tumour with magnetic resonance imaging mri has been promising in recent years the current tumour detection strategies are used for visualising digitising and modelling the images for medical diagnosis automatic tumour region segmentation from 3d mris is essential for monitoring diagnosing and planning the treatment remedies for the disease however manual outlining needs an anatomical understanding which requires more time and can be imprecise due to human error brain tumour is serious diseases whose exposure must be quick and precise it is attained by the accomplishment of the automatic detection of the tumour using mri several automatic strategies are employed in literary works which utilise image segmentation here 50 research papers are surveyed with brain tumour detection strategies like ann clustering deep learning edgebased techniques optimisation and transformation strategies furthermore complete exploration is done in terms of publication year employed strategy datasets utilised execution tool performance measures and its values at last the problems of classical strategies and its issues with classical brain tumour detection methods are illustrated to generate the contribution",Brain
Accurate Detection of Brain Tumor Using Compound Filter and Deep Neural Network,https://doi.org/10.1007/978-3-031-28540-0_8,2023,"the unexpected growth of nerves inside the human brain that interferes with the normal function of the brain is referred to as a brain tumor magnetic resonance imaging mri is used to provide images of better resolution of the brain this paper proposes a system that applies a compound filter along with a convolution neural network cnn and support vector machine svm for the detection of brain tumors in mri for finding tumors this proposed system has been divided into the following sections preprocessing segmentation feature extraction and tumor detection this system employs a compound filter for preprocessing that is made up of gaussian mean and median filters threshold and histogrambased techniques have been applied for image segmentation and grey level cooccurrence matrix glcm for feature extraction for tumor detection the svm and cnn classifiers were employed cnn is a deep neural network dnn based classifier the tumor detection accuracy of cnn and svm classifiers have been estimated at 9806 and 9328 respectively the proposed system concludes that the accuracy of cnn is superior to svm",Brain
MR Image Block-Based Brain Tumour Detection Using GLCM Texture Features and SVM,https://doi.org/10.1007/978-981-19-9228-5_19,2023,"a brain tumour is a deadly disease and it is an unwanted cells development in the human brain in medical technology brain tumour detection and diagnosis increase the patients life days in this manuscript an effective blockbased brain tumour detection method is proposed for mr images the proposed method has four steps convert t2w images into 8 8 blocks feature extraction feature selection and classification this method uses the brain tumour segmentation brats2013 dataset with highgrade glioma hgg and lowgrade glioma lgg mri multimodal on t2weighted images feature extraction is achieved by glcm texture features the chisquare test method is implemented to rank features in the feature selection process finally the classification process is achieved by svm and it has two main phases training and testing this method uses 90000 blocks for training and 36000 blocks for testing in the combination of hgg and lgg images the blocks are classified into normal or tumour based on their features during the testing phase the proposed blockbased brain tumour detection method achieves 100 sensitivity 100 specificity and 100 accuracy in the testing phase",Brain
MR Image Block-Based Brain Tumour Detection Using GLCM Texture Features and SVM,https://doi.org/10.1007/978-981-19-9228-5_19,2023,"a brain tumour is a deadly disease and it is an unwanted cells development in the human brain in medical technology brain tumour detection and diagnosis increase the patients life days in this manuscript an effective blockbased brain tumour detection method is proposed for mr images the proposed method has four steps convert t2w images into 8 8 blocks feature extraction feature selection and classification this method uses the brain tumour segmentation brats2013 dataset with highgrade glioma hgg and lowgrade glioma lgg mri multimodal on t2weighted images feature extraction is achieved by glcm texture features the chisquare test method is implemented to rank features in the feature selection process finally the classification process is achieved by svm and it has two main phases training and testing this method uses 90000 blocks for training and 36000 blocks for testing in the combination of hgg and lgg images the blocks are classified into normal or tumour based on their features during the testing phase the proposed blockbased brain tumour detection method achieves 100 sensitivity 100 specificity and 100 accuracy in the testing phase",Brain
Diagnosis of Pulmonary Diseases from Chest X-ray Using Deep Learning Approaches,https://doi.org/10.1007/978-981-19-9228-5_7,2023,"in recent years a severe pandemic has struck worldwide with the utmost shutter enforcing a lot of stress in the medical industry moreover the increasing population has brought to light that the work bestowed upon the healthcare specialists needs to be reduced medical images like chest xrays are of utmost importance for the diagnosis of diseases such as pneumonia covid19 thorax and many more various manual image analysis techniques are timeconsuming and not always efficient deep learning models for neural networks are capable of finding hidden patterns assisting the experts in specified fields therefore collaborating these medical images with deep learning techniques has paved the path for enormous applications leading to the reduction of pressure embarked upon the health industry this paper demonstrates an approach for automatic lung diagnosing of covid19 coronavirus and thorax diseases from given cxr images using deep learning techniques the previously proposed model uses the concept of resnet18 resnet50 and xception algorithms this model gives the highest accuracy of 98 without segmentation and 95 with segmentation whereas the proposed model uses cnn and clahe algorithms which achieves an accuracy of 9922 without segmentation and 9839 with segmentation therefore this model will be able to provide assistance to health workforces and minimize manual errors precisely",Lung
Dual Uncertainty-Guided Mixing Consistency for Semi-Supervised 3D Medical Image Segmentation,https://doi.org/10.1109/tbdata.2023.3258643,2023,"3d semisupervised medical image segmentation is extremely essential in computeraided diagnosis which can reduce the timeconsuming task of performing annotation the challenges with current 3d semisupervised segmentation algorithms includes the methods limited attention to volume wise context information their inability to generate accurate pseudo labels and a failure to capture important details during data augmentation this paper proposes a dual uncertaintyguided mixing consistency network for accurate 3d semisupervised segmentation which can solve the above challenges the proposed network consists of a contrastive training module which improves the quality of augmented images by retaining the invariance of data augmentation between original data and their augmentations the dual uncertainty strategy calculates dual uncertainty between two different models to select a more confident area for subsequent segmentation the mixing volume consistency module that guides the consistency between mixing before and after segmentation for final segmentation uses dual uncertainty and can fully learn volume wise context information results from evaluative experiments on brain tumor and left atrial segmentation shows that the proposed method outperforms stateoftheart 3d semisupervised methods as confirmed by quantitative and qualitative analysis on datasets this effectively demonstrates that this study has the potential to become a medical tool for accurate segmentation code is available at uri xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlinkhttpsgithubcomyang6277dumcuri",Brain
3D Masked Autoencoding and Pseudo-labeling for Domain Adaptive  Segmentation of Heterogeneous Infant Brain MRI,https://doi.org/10.48550/arxiv.2303.09373,2023,"robust segmentation of infant brain mri across multiple ages modalities and sites remains challenging due to the intrinsic heterogeneity caused by different mri scanners vendors or acquisition sequences as well as varying stages of neurodevelopment to address this challenge previous studies have explored domain adaptation da algorithms from various perspectives including feature alignment entropy minimization contrast synthesis style transfer and pseudolabeling this paper introduces a novel framework called mapseg masked autoencoding and pseudolabelling segmentation to address the challenges of crossage crossmodality and crosssite segmentation of subcortical regions in infant brain mri utilizing 3d masked autoencoding as well as masked pseudolabeling the model is able to jointly learn from labeled source domain data and unlabeled target domain data we evaluated our framework on expertannotated datasets acquired from different ages and sites mapseg consistently outperformed other methods including previous stateoftheart supervised baselines domain generalization and domain adaptation frameworks in segmenting subcortical regions regardless of age modality or acquisition site the code and pretrained encoder will be publicly available at httpsgithubcomxuzhezmapseg",Brain
Enhanced detection of the presence and severity of COVID-19 from CT  scans using lung segmentation,https://doi.org/10.48550/arxiv.2303.09440,2023,"improving automated analysis of medical imaging will provide clinicians more options in providing care for patients the 2023 aienabled medical image analysis workshop and covid19 diagnosis competition aimiacov19d provides an opportunity to test and refine machine learning methods for detecting the presence and severity of covid19 in patients from ct scans this paper presents version 2 of cov3d a deep learning model submitted in the 2022 competition the model has been improved through a preprocessing step which segments the lungs in the ct scan and crops the input to this region it results in a validation macro f1 score for predicting the presence of covid19 in the ct scans at 932 which is significantly above the baseline of 74 it gives a macro f1 score for predicting the severity of covid19 on the validation set for task 2 as 728 which is above the baseline of 38",Lung
Enhanced detection of the presence and severity of COVID-19 from CT  scans using lung segmentation,https://doi.org/10.48550/arxiv.2303.09440,2023,"improving automated analysis of medical imaging will provide clinicians more options in providing care for patients the 2023 aienabled medical image analysis workshop and covid19 diagnosis competition aimiacov19d provides an opportunity to test and refine machine learning methods for detecting the presence and severity of covid19 in patients from ct scans this paper presents version 2 of cov3d a deep learning model submitted in the 2022 competition the model has been improved through a preprocessing step which segments the lungs in the ct scan and crops the input to this region it results in a validation macro f1 score for predicting the presence of covid19 in the ct scans at 932 which is significantly above the baseline of 74 it gives a macro f1 score for predicting the severity of covid19 on the validation set for task 2 as 728 which is above the baseline of 38",Lung
Knowledge Distillation for Adaptive MRI Prostate Segmentation Based on  Limit-Trained Multi-Teacher Models,https://doi.org/10.48550/arxiv.2303.09494,2023,"with numerous medical tasks the performance of deep models has recently experienced considerable improvements these models are often adept learners yet their intricate architectural design and high computational complexity make deploying them in clinical settings challenging particularly with devices with limited resources to deal with this issue knowledge distillation kd has been proposed as a compression method and an acceleration technology kd is an efficient learning strategy that can transfer knowledge from a burdensome model ie teacher model to a lightweight model ie student model hence we can obtain a compact model with low parameters with preserving the teachers performance therefore we develop a kdbased deep model for prostate mri segmentation in this work by combining featuresbased distillation with kullbackleibler divergence lovasz and dice losses we further demonstrate its effectiveness by applying two compression procedures 1 distilling knowledge to a student model from a single welltrained teacher and 2 since most of the medical applications have a small dataset we train multiple teachers that each one trained with a small set of images to learn an adaptive student model as close to the teachers as possible considering the desired accuracy and fast inference time extensive experiments were conducted on a public multisite prostate tumor dataset showing that the proposed adaptation kd strategy improves the dice similarity score by 9 outperforming all tested wellestablished baseline models",Prostate
Atrial Fibrillation Ablation Outcome Prediction with a Machine Learning Fusion Framework Incorporating Cardiac Computed Tomography,https://doi.org/10.1111/jce.15890,2023,"structural changes in the left atrium la modestly predict outcomes in patients undergoing catheter ablation for atrial fibrillation af machine learning ml is a promising approach to personalize af management strategies and improve predictive risk models after catheter ablation by integrating atrial geometry from cardiac computed tomography ct scans and patientspecific clinical data we hypothesized that ml approaches based on a patients specific data can identify responders to af ablationconsecutive patients undergoing af ablation who had preprocedural ct scans demographics and 1year followup data were included in the study for a retrospective analysis the inputs of models were ctderived morphological features from left atrial segmentation including the shape volume of the la la appendage and pulmonary vein ostia along with deep features learned directly from raw ct images and clinical data these were merged intelligently in a framework to learn their individual importance and produce the optimal classification321 patients 642 106 years 69 male 40 paroxysmal af were analyzed post 10fold nested crossvalidation the model trained to intelligently merge and learn appropriate weights for clinical morphological and imaging data auc 0821 outperformed those trained solely on clinical data auc 0626 morphological auc 0659 or imaging data auc 0764our machine learning approach provides an endtoend automated technique to predict af ablation outcomes using deep learning from ct images derived structural properties of la augmented by incorporation of clinical data in a merged ml framework this can help develop personalized strategies for patient selection in invasive management of af this article is protected by copyright all rights reserved",Cardiac
A Weakly Supervised U-Net Model for Precise Whole Brain Immunolabeled Cell Detection,https://doi.org/10.1101/2023.03.16.531434,2023,"cell segmentations low precision due to the intensity differences hinders widespread use of whole brain microscopy imaging previous studies used resnet or cnn to account for this problem but are unapplicable to immunolabeled signals across samples here we present a semi auto ground truth generation and weaklysupervised unetbased deeplearning precise segmentation pipeline for whole brain immunopositive cfos signals which reveals the distinct neural activity maps with different social motivations",Brain
Bipartite invariance in mouse primary visual cortex,https://doi.org/10.1101/2023.03.15.532836,2023,"a defining characteristic of intelligent systems whether natural or artificial is the ability to generalize and infer behaviorally relevant latent causes from highdimensional sensory input despite significant variations in the environment to understand how brains achieve generalization it is crucial to identify the features to which neurons respond selectively and invariantly however the highdimensional nature of visual inputs the nonlinearity of information processing in the brain and limited experimental time make it challenging to systematically characterize neuronal tuning and invariances especially for natural stimuli here we extended inception loops a paradigm that iterates between largescale recordings neural predictive models and in silico experiments followed by in vivo verification to systematically characterize single neuron invariances in the mouse primary visual cortex using the predictive model we synthesized diverse exciting inputs deis a set of inputs that differ substantially from each other while each driving a target neuron strongly and verified these deis efficacy in vivo we discovered a novel bipartite invariance one portion of the receptive field encoded phaseinvariant texturelike patterns while the other portion encoded a fixed spatial pattern our analysis revealed that the division between the fixed and invariant portions of the receptive fields aligns with object boundaries defined by spatial frequency differences present in highly activating natural images these findings suggest that bipartite invariance might play a role in segmentation by detecting texturedefined object boundaries independent of the phase of the texture we also replicated these bipartite deis in the functional connectomics microns data set which opens the way towards a circuitlevel mechanistic understanding of this novel type of invariance our study demonstrates the power of using a datadriven deep learning approach to systematically characterize neuronal invariances by applying this method across the visual hierarchy cell types and sensory modalities we can decipher how latent variables are robustly extracted from natural scenes leading to a deeper understanding of generalization",Brain
Automatic segmentation of neurovascular bundle on mri using deep learning based topological modulated network,https://doi.org/10.1002/mp.16378,2023,"purpose radiation damage on neurovascular bundles nvbs may be the cause of sexual dysfunction after radiotherapy for prostate cancer however it is challenging to delineate nvbs as organatrisks from planning cts during radiotherapy recently the integration of mr into radiotherapy made nvbs contour delineating possible in this study we aim to develop an mribased deep learning method for automatic nvb segmentation methods the proposed method named topological modulated network consists of three subnetworks ie a focal modulation a hierarchical block and a topological fully convolutional network fcn the focal modulation is used to derive the location and bounds of left and right nvbs namely the candidate volumeofinterests vois the hierarchical block aims to highlight the nvb boundaries information on derived feature map the topological fcn then segments the nvbs inside the vois by considering the topological consistency nature of the vascular delineating based on the location information of candidate vois the segmentations of nvbs can then be brought back to the input mris coordinate system results a fivefold crossvalidation study was performed on 60 patient cases to evaluate the performance of the proposed method the segmented results were compared with manual contours the dice similarity coefficient dsc and 95th percentile hausdorff distance hd95 are left nvb 081 010 149 088 mm and right nvb 080 015 154 122 mm respectively conclusion we proposed a novel deep learningbased segmentation method for nvbs on pelvic mr images the good segmentation agreement of our method with the manually drawn ground truth contours supports the feasibility of the proposed method which can be potentially used to spare nvbs during proton and photon radiotherapy and thereby improve the quality of life for prostate cancer patients this article is protected by copyright all rights reserved",Prostate
Prostate cancer segmentation from MRI by a multistream fusion encoder,https://doi.org/10.1002/mp.16374,2023,"background targeted prostate biopsy guided by multiparametric magnetic resonance imaging mpmri detects more clinically significant lesions than conventional systemic biopsy lesion segmentation is required for planning mritargeted biopsies the requirement for integrating image features available in t2weighted and diffusionweighted images poses a challenge in prostate lesion segmentation from mpmri purpose a flexible and efficient multistream fusion encoder is proposed in this work to facilitate the multiscale fusion of features from multiple imaging streams a patchbased loss function is introduced to improve the accuracy in segmenting small lesions methods the proposed multistream encoder fuses features extracted in the three imaging streams at each layer of the network thereby allowing improved feature maps to propagate downstream and benefit segmentation performance the fusion is achieved through a spatial attention map generated by optimally weighting the contribution of the convolution outputs from each stream this design provides flexibility for the network to highlight image modalities according to their relative influence on the segmentation performance the encoder also performs multiscale integration by highlighting the input feature maps lowlevel features with the spatial attention maps generated from convolution outputs highlevel features the dice similarity coefficient dsc serving as a cost function is less sensitive to incorrect segmentation for small lesions we address this issue by introducing a patchbased loss function that provides an average of the dscs obtained from local image patches this local average dsc is equally sensitive to large and small lesions as the patchbased dscs associated with small and large lesions have equal weights in this average dsc results the framework was evaluated in 931 sets of images acquired in several clinical studies at two centers in hong kong and the united kingdom in particular the training validation and test sets contain 615 144 and 172 sets of images respectively the proposed framework outperformed singlestream networks and three recently proposed multistream networks attaining f1 scores of 822 and 876 in the lesion and patient levels respectively the average inference time for an axial image was 118 ms conclusion the accuracy and efficiency afforded by the proposed framework would accelerate the mri interpretation workflow of mritargeted biopsy and focal therapies this article is protected by copyright all rights reserved",Prostate
AI Based Segmentation Technique to Identify Abnormality in MRI Images,https://doi.org/10.1109/sceecs57921.2023.10063040,2023,"medical image processing is the most demanding and upcoming fields today this paper proposes an efficient strategy for segmentation to detect abnormalities in patients brain mri images to show the differences in tumor of brain mri and its assimilation with input images a high pass filter is used in this work an ai based algorithm is proposed named as convolutional wavelet network cwn for effective segmentation of the brain mri cwn and softmax classification is done for effective segmentation this paper concludes with experimental results which indicate that the technique which is proposed gives a better accuracy 9944 than the previous models high dsc values which indicates that the model can facilitate abnormality identification in brain mris",Brain
Generating Novel Pituitary Datasets from Open-Source Imaging Data and Deep Volumetric Segmentation,https://doi.org/10.1055/s-0043-1762045,2023,"purpose the estimated incidence of pituitary adenomas in the general population is 10 to 30 yet radiographic diagnosis remains a challenge diagnosis is complicated by the heterogeneity of radiographic features in both normal eg complex anatomy pregnancy and pathologic states eg primary endocrinopathy hypophysitis clinical symptoms and laboratory testing are often equivocal which can result in misdiagnosis or unnecessary specialist referrals computer vision models can aid in pituitary adenoma diagnosis however a major challenge to model development is the lack of dedicated pituitary imaging datasets we hypothesized that deep machine learningbased volumetric segmentation models trained to extract the sellar and parasellar region from existing wholebrain mri scans could be used to generate a novel dataset of pituitary imaging",Brain
A Study on Machine Learning And Deep Learning In Medical Imaging Emphasizes MRI: A Systematic Literature Review (Preprint),https://doi.org/10.2196/preprints.47192,2023,"sec titlebackgroundtitle due to the fast growth of medical imaging technologies over the last decade medical practitioners and radiologists find it increasingly difficult to analyze and categorize medical images diagnosing surgery planning education and inquiry benefit immensely from the abundance of information in medical images sec sec titleobjectivetitle the objective of our study was to use machine learning ml and deep learning approaches have been applied for medical image analysis this study focuses on ml for mri evaluation mri we provide a brief overview of advances in medical image processing and image analysis utilizing machine learning deep learning and a few related issues sec sec titlemethodstitle we provide a brief overview of current advances in medical image processing and image analysis utilizing machine learning deep learning and a few related issues this study paper is limited to two digital databases 1 science direct and 2 google scholar this research report reviewed and discussed research publications sec sec titleresultstitle our findings are based on a systematic literature review in which thematic analysis is done and based on themes we extract a comprehensive literature review ondl approaches to analyzing brain mri data have been extensively studied by performing a systematic review deep learning dland machine learning techniques based on convolutional neural networks outperform traditional medical image classification identification and segmentation methods various issues including image localization segmentation detection and classification sec sec titleconclusionstitle dl approaches to analyzing brain mri data have been extensively studied by performing a systematic review deep learning dland machine learning techniques based on convolutional neural networks outperform traditional medical image classification identification and segmentation methods sec",Brain
Generative Adversarial Networks Can Create High Quality Artificial Prostate Cancer Magnetic Resonance Images,https://doi.org/10.3390/jpm13030547,2023,"the recent integration of opensource data with machine learning models especially in the medical field has opened new doors to studying disease progression andor regression however the ability to use medical data for machine learning approaches is limited by the specificity of data for a particular medical condition in this context the most recent technologies like generative adversarial networks gans are being looked upon as a potential way to generate highquality synthetic data that preserve the clinical variability of a condition however despite some success gan model usage remains largely minimal when depicting the heterogeneity of a disease such as prostate cancer previous studies from our group members have focused on automating the quantitative multiparametric magnetic resonance imaging mpmri using habitat risk scoring hrs maps on the prostate cancer patients in the blastm trial in the current study we aimed to use the images from the blastm trial and other sources to train the gan models generate synthetic images and validate their quality in this context we used t2weighted prostate mri images as training data for single natural image gans singans to make a generative model a deep learning semantic segmentation pipeline trained the model to segment the prostate boundary on 2d mri slices synthetic images with a highlevel segmentation boundary of the prostate were filtered and used in the quality control assessment by participating scientists with varying degrees of experience more than ten years one year or no experience to work with mri images results showed that the most experienced participating group correctly identified conventional vs synthetic images with 67 accuracy the group with one year of experience correctly identified the images with 58 accuracy and the group with no prior experience reached 50 accuracy nearly half 47 of the synthetic images were mistakenly evaluated as conventional interestingly in a blinded quality assessment a boardcertified radiologist did not significantly differentiate between conventional and synthetic images in the context of the mean quality of synthetic and conventional images furthermore to validate the usability of the generated synthetic images from prostate cancer mris we subjected these to anomaly detection along with the original images importantly the success rate of anomaly detection for quality controlapproved synthetic data in phase one corresponded to that of the conventional images in sum this study shows promise that highquality synthetic images from mris can be generated using gans such an ai model may contribute significantly to various clinical applications which involve supervised machinelearning approaches",Prostate
Vessel Density Mapping of Cerebral Small Vessels on 3D High Resolution Black Blood MRI,https://doi.org/10.1101/2023.03.18.533300,2023,"cerebral small vessels are largely inaccessible to existing clinical in vivo imaging technologies this study aims to present a novel analysis pipeline for vessel density mapping of cerebral small vessels from highresolution 3d blackblood mri at 3t twentyeight subjects 10 under 35 years old 18 over 60 years old were imaged with the t1weighted turbo spinecho with variable flip angles t1w tsevfa sequence optimized for blackblood small vessel imaging with iso05mm spatial resolution at 3t hessianbased vessel segmentation methods jerman frangi and sato filter were evaluated by vessel landmarks and manual annotation of lenticulostriate arteries lsas using optimized vessel segmentation large vessel pruning and nonlinear registration a semiautomatic pipeline was proposed for quantification of small vessel density across brain regions and further for localized detection of small vessel changes across populations voxellevel statistics was performed to compare vessel density between two age groups additionally local vessel density of aged subjects was correlated with their corresponding gross cognitive and executive function ef scores using montreal cognitive assessment moca and ef composite scores compiled with item response theory irt jerman filter showed better performance for vessel segmentation than frangi and sato filter which was employed in our pipeline cerebral small vessels on the order of a few hundred microns can be delineated using the proposed analysis pipeline on 3d blackblood mri at 3t the mean vessel density across brain regions was significantly higher in young subjects compared to aged subjects in the aged subjects localized vessel density was positively correlated with moca and irt ef scores the proposed pipeline is able to segment quantify and detect localized differences in vessel density of cerebral small vessels based on 3d highresolution blackblood mri this framework may serve as a tool for localized detection of small vessel density changes in normal aging and cerebral small vessel disease",Brain
Grade Classification of Tumors from Brain Magnetic Resonance Images Using a Deep Learning Technique,https://doi.org/10.3390/diagnostics13061153,2023,"to improve the accuracy of tumor identification it is necessary to develop a reliable automated diagnostic method in order to precisely categorize brain tumors researchers developed a variety of segmentation algorithms segmentation of brain images is generally recognized as one of the most challenging tasks in medical image processing in this article a novel automated detection and classification method was proposed the proposed approach consisted of many phases including preprocessing mri images segmenting images extracting features and classifying images during the preprocessing portion of an mri scan an adaptive filter was utilized to eliminate background noise for feature extraction the localbinary grey level cooccurrence matrix lbglcm was used and for image segmentation enhanced fuzzy cmeans clustering efcmc was used after extracting the scan features we used a deep learning model to classify mri images into two groups glioma and normal the classifications were created using a convolutional recurrent neural network crnn the proposed technique improved brain image classification from a defined input dataset mri scans from the rembrandt dataset which consisted of 620 testing and 2480 training sets were used for the research the data demonstrate that the newly proposed method outperformed its predecessors the proposed crnn strategy was compared against bp unet and resnet which are three of the most prevalent classification approaches currently being used for brain tumor classification the proposed system outcomes were 9817 accuracy 9134 specificity and 9879 sensitivity",Brain
A CAD System for Lung Cancer Detection Using Hybrid Deep Learning Techniques,https://doi.org/10.3390/diagnostics13061174,2023,"lung cancer starts and spreads in the tissues of the lungs more specifically in the tissue that forms air passages this cancer is reported as the leading cause of cancer deaths worldwide in addition to being the most fatal it is the most common type of cancer nearly 47000 patients are diagnosed with it annually worldwide this article proposes a fully automated and practical system to identify and classify lung cancer this system aims to detect cancer in its early stage to save lives if possible or reduce the death rates it involves a deep convolutional neural network dcnn technique vgg19 and another deep learning technique long shortterm memory networks lstms both tools detect and classify lung cancers after being customized and integrated furthermore image segmentation techniques are applied this system is a type of computeraided diagnosis cad after several experiments on matlab were conducted the results show that this system achieves more than 988 accuracy when using both tools together various schemes were developed to evaluate the considered disease three lung cancer datasets downloaded from the kaggle website and the luna16 grad challenge were used to train the algorithm test it and prove its correctness lastly a comparative evaluation between the proposed approach and some works from the literature is presented this evaluation focuses on the four performance metrics accuracy recall precision and fscore this system achieved an average of 9942 accuracy and 9976 9988 and 9982 for recall precision and fscore respectively when vgg19 was combined with lstms in addition the results of the comparison evaluation show that the proposed algorithm outperforms other methods and produces exquisite findings this study concludes that this model can be deployed to aid and support physicians in diagnosing lung cancer correctly and accurately this research reveals that the presented method has functionality competence and value among other implemented models",Lung
A CAD System for Lung Cancer Detection Using Hybrid Deep Learning Techniques,https://doi.org/10.3390/diagnostics13061174,2023,"lung cancer starts and spreads in the tissues of the lungs more specifically in the tissue that forms air passages this cancer is reported as the leading cause of cancer deaths worldwide in addition to being the most fatal it is the most common type of cancer nearly 47000 patients are diagnosed with it annually worldwide this article proposes a fully automated and practical system to identify and classify lung cancer this system aims to detect cancer in its early stage to save lives if possible or reduce the death rates it involves a deep convolutional neural network dcnn technique vgg19 and another deep learning technique long shortterm memory networks lstms both tools detect and classify lung cancers after being customized and integrated furthermore image segmentation techniques are applied this system is a type of computeraided diagnosis cad after several experiments on matlab were conducted the results show that this system achieves more than 988 accuracy when using both tools together various schemes were developed to evaluate the considered disease three lung cancer datasets downloaded from the kaggle website and the luna16 grad challenge were used to train the algorithm test it and prove its correctness lastly a comparative evaluation between the proposed approach and some works from the literature is presented this evaluation focuses on the four performance metrics accuracy recall precision and fscore this system achieved an average of 9942 accuracy and 9976 9988 and 9982 for recall precision and fscore respectively when vgg19 was combined with lstms in addition the results of the comparison evaluation show that the proposed algorithm outperforms other methods and produces exquisite findings this study concludes that this model can be deployed to aid and support physicians in diagnosing lung cancer correctly and accurately this research reveals that the presented method has functionality competence and value among other implemented models",Lung
An Exploration of Ventricle Regions Segmentation and Multiclass Disease Detection Using Cardiac MRI,https://doi.org/10.21203/rs.3.rs-2407564/v1,2023,"abstract in this modern era various cardiac diseases are very crucial as they cause a high mortality rate early detection of cardio vascular disease cvd is essential to prevent and control it diagnosis of cardiac disease is the process of analyzing the left and right ventricle cavities lv rv and myocardium myo from cardiac magnetic resonance cmr images as the deep learning architectures are becoming more mature segmenting and classifying cardiac mri images using deep learning is gaining more attention this work is aimed to identify five different cardiac disease subgroups namely nor minf dcm hcm and arc by employing a new deep join attention model djam technique for segmenting lv myo and rv regions separatelythis method provides advancement as the joined attention model was combined with the pooling layers and the resultant is added to the convolution layers the proposed region integrated deep residual network ridrn is used to extract the features from the segmented images for classification in this process the features of lv rv and myo are combined with a different combination the advantage of doing this process is to get the overall features without leaving any single strip of features from the three regions hence it shows a rise in the performance accuracy the random forest classification method is used to classify the underlying features for cardiac disease diagnosisthis proposed work is tested in the automated cardiac diagnosis challenge acdc dataset and it perfects the stateofart techniques",Cardiac
An Exploration of Ventricle Regions Segmentation and Multiclass Disease Detection Using Cardiac MRI,https://doi.org/10.21203/rs.3.rs-2407564/v1,2023,"abstract in this modern era various cardiac diseases are very crucial as they cause a high mortality rate early detection of cardio vascular disease cvd is essential to prevent and control it diagnosis of cardiac disease is the process of analyzing the left and right ventricle cavities lv rv and myocardium myo from cardiac magnetic resonance cmr images as the deep learning architectures are becoming more mature segmenting and classifying cardiac mri images using deep learning is gaining more attention this work is aimed to identify five different cardiac disease subgroups namely nor minf dcm hcm and arc by employing a new deep join attention model djam technique for segmenting lv myo and rv regions separatelythis method provides advancement as the joined attention model was combined with the pooling layers and the resultant is added to the convolution layers the proposed region integrated deep residual network ridrn is used to extract the features from the segmented images for classification in this process the features of lv rv and myo are combined with a different combination the advantage of doing this process is to get the overall features without leaving any single strip of features from the three regions hence it shows a rise in the performance accuracy the random forest classification method is used to classify the underlying features for cardiac disease diagnosisthis proposed work is tested in the automated cardiac diagnosis challenge acdc dataset and it perfects the stateofart techniques",Cardiac
Thresholding and Filtering Based Brain Tumor Segmentation on MRI Images,https://doi.org/10.22214/ijraset.2023.48615,2023,"abstract the brain is the interior most part of the central nervous system and is an intracranial solid neoplasm tumours are created by an abnormal and uncontrollable cell division in the brain in this work axial view of the brain image 2d from mri scan has been used because mri scan is less harmful than ct brain scan the study of brain tumor is important as it is occurring in many people in this paper an image segmentation process was proposed for the identification or detection of tumor from the brain the methodology consists of the following steps preprocessing by using greylevel sharpening and median filters segmentation of the image was performed by thresholding and also by applying the watershed segmentation finally the tumor region was obtained with its area 1",Brain
Exploring Sparse Visual Prompt for Cross-domain Semantic Segmentation,https://doi.org/10.48550/arxiv.2303.09792,2023,"visual domain prompts vdp have shown promising potential in addressing visual crossdomain problems existing methods adopt vdp in classification domain adaptation da such as tuning imagelevel or featurelevel prompts for target domains since the previous dense prompts are opaque and mask out continuous spatial details in the prompt regions it will suffer from inaccurate contextual information extraction and insufficient domainspecific feature transferring when dealing with the dense prediction ie semantic segmentation da problems therefore we propose a novel sparse visual domain prompts svdp approach tailored for addressing domain shift problems in semantic segmentation which holds minimal discrete trainable parameters eg 10 of the prompt and reserves more spatial information to better apply svdp we propose domain prompt placement dpp method to adaptively distribute several svdp on regions with large data distribution distance based on uncertainty guidance it aims to extract more local domainspecific knowledge and realizes efficient crossdomain learning furthermore we design a domain prompt updating dpu method to optimize prompt parameters differently for each target domain sample with different degrees of domain shift which helps svdp to better fit target domain knowledge experiments which are conducted on the widelyused benchmarks cityscapes foggycityscapes and acdc show that our proposed method achieves stateoftheart performances on the sourcefree adaptations including six test time adaptation and one continual testtime adaptation in semantic segmentation",Cardiac
Prototype Knowledge Distillation for Medical Segmentation with Missing  Modality,https://doi.org/10.48550/arxiv.2303.09830,2023,"multimodality medical imaging is crucial in clinical treatment as it can provide complementary information for medical image segmentation however collecting multimodal data in clinical is difficult due to the limitation of the scan time and other clinical situations as such it is clinically meaningful to develop an image segmentation paradigm to handle this missing modality problem in this paper we propose a prototype knowledge distillation protokd method to tackle the challenging problem especially for the toughest scenario when only single modal data can be accessed specifically our protokd can not only distillate the pixelwise knowledge of multimodality data to singlemodality data but also transfer intraclass and interclass feature variations such that the student model could learn more robust feature representation from the teacher model and inference with only one single modality data our method achieves stateoftheart performance on brats benchmark",Brain
Lung Cancer Detection using Artificial Neural Network on Android,https://doi.org/10.1109/gcwot57803.2023.10064658,2023,"cancer is a disease that threatens majority of the worlds survival rate lung cancer is one of most deadly malignancies having a high rate of morbidity and death compared to other cancers the goal of this paper is to identify lung cancer from a ct scan by employing image processing segmentation feature extraction and classification of lung cancer with stage detection to find reliable results artificial neural network has been used for classification and staging of cancerous nodule this concept is built on android smartphone technology and it aims to make cancer diagnosis as simple as possible early detection of lung cancer opens the gate to a variety of treatment options effective recoveries and eventually increased survival prospects the proposed work intends to promote early detection of cancer in lung with stage detection our system is able to obtain an accuracy of 965",Lung
Automated evaluation of cardiac contractile dynamics and aging prediction using machine learning in a Drosophila model,https://doi.org/10.21203/rs.3.rs-2635745/v1,2023,"abstract the drosophila model has proven tremendously powerful for understanding pathophysiological bases of several human disorders including aging and cardiovascular disease relevant highspeed imaging and highthroughput lab assays generate large volumes of highresolution videos necessitating nextgeneration methods for rapid analysis we present a platform for deep learningassisted segmentation applied to optical microscopy of drosophila hearts and the first to quantify cardiac physiological parameters during aging an experimental test dataset is used to validate a drosophila aging model we then use two novel methods to predict fly aging deeplearning video classification and machinelearning classification via cardiac parameters both models suggest excellent performance with an accuracy of 833 auc 090 and 771 auc 085 respectively furthermore we report beatlevel dynamics for predicting the prevalence of cardiac arrhythmia the presented approaches can expedite future cardiac assays for modeling human diseases in drosophila and can be extended to numerous animalhuman cardiac assays under multiple conditions significance current analysis of drosophila cardiac recordings is capable of limited cardiac physiological parameters and are errorprone and timeconsuming we present the first deeplearning pipeline for highfidelity automatic modeling of drosophila contractile dynamics we present methods for automatically calculating all relevant parameters for diagnosing cardiac performance in aging model using the machine and deep learning ageclassification approach we can predict aging hearts with an accuracy of 833 auc 090 and 771 auc 085 respectively",Cardiac
Modified convolutional neural network for lung cancer detection: Improved cat swarm-based optimal training,https://doi.org/10.3233/web-221801,2023,"lung cancer is the most lethal and severe illness in existence however lung cancer patients may live longer if they receive early detection and treatment in the medical field the best imaging technique is ct scan imaging as it is more complex for doctors to identify cancer and interpret from ct scan images consequently the computeraided diagnosis cad is more useful for doctors to find out cancerous nodules to identify lung cancer a number of cad techniques utilising machine learning ml and image processing are used nowadays the goal of this study is to present a novel method for detecting lung cancer that entails four main steps i preprocessing ii segmentation iii feature extraction and iv classification the input image is first put through a preprocessing step in which the clahe model is used to preprocess the image the segmentation phase of the preprocessed images is then initiated and it makes use of a modified level set segmentation method the retrieved features from the segmented images include statistical features colour features and texture features glcm glrm and lbp the layer fused conventional neural network lfcnn is then utilised to classify these features in the end particularly layerwise modification is carried out and along with that the lfcnn is trained by the modified cat swarm optimization mcso algorithm via selecting optimal weights the accepted scheme is then compared to the current models in terms of several metrics including recall fnr mcc fdr threat score fpr precision for accuracy specificity npv fms and sensitivity",Lung
Deep learning-based image segmentation model using an MRI-based convolutional neural network for physiological evaluation of the heart,https://doi.org/10.3389/fphys.2023.1148717,2023,"background and objective cardiovascular disease is a highfatality health issue accurate measurement of cardiovascular function depends on precise segmentation of physiological structure and accurate evaluation of functional parameters structural segmentation of heart images and calculation of the volume of different ventricular activity cycles form the basis for quantitative analysis of physiological function and can provide the necessary support for clinical physiological diagnosis as well as the analysis of various cardiac diseases therefore it is important to develop an efficient heart segmentation algorithm methods a total of 275 nuclear magnetic resonance imaging mri heart scans were collected analyzed and preprocessed from huaqiao university affiliated strait hospital and the data were used in our improved deep learning model which was designed based on the unet network the training set included 80 of the images and the remaining 20 was the test set based on five time phases from enddiastole ed to endsystole es the segmentation findings showed that it is possible to achieve improved segmentation accuracy and computational complexity by segmenting the left ventricle lv right ventricle rv and myocardium myo results we improved the dice index of the lv to 0965 and 0921 and the hausdorff index decreased to 54 and 69 in the ed and es phases respectively rv dice increased to 0938 and 0860 and the hausdorff index decreased to 117 and 126 in the ed and es respectively myo dice increased to 0889 and 0901 and the hausdorff index decreased to 83 and 92 in the ed and es respectively conclusion the model obtained in the final experiment provided more accurate segmentation of the left and right ventricles as well as the myocardium from cardiac mri the data from this model facilitate the prediction of cardiovascular disease in realtime thereby providing potential clinical utility",Cardiac
Combining quantitative and qualitative analysis for scoring pleural line in lung ultrasound,https://doi.org/10.36227/techrxiv.21732869.v2,2023,"ltpgtwith the advancement of lung disease research and the wide application of lung ultrasound lus it is essential to analyze various indicators in lus images independently to aid in clinical diagnosis in this paper we proposed a quantitative and qualitative method for extracting analyzing and scoring pleural lines with different lesions in lus images the extraction module consists of customized cascaded detection and segmentation models based on convolution and multilayer perceptron mlp the analysis module uses eight textural and three morphological parameters to quantitatively analyze the features of two different output images from the localization and segmentation models respectively to qualitatively evaluate pleural lines with different severities in lus images the scoring module adopts four supervised machine learning classifiers including support vector machine knearest neighbor random forest and decision tree we performed experiments on the 5390 lus images acquired from coronavirus disease 2019 pneumonia patients using convex ultrasound probes the experimental results demonstrated that our proposed line extraction method accurately detected and segmented pleural lines the support vector machine classifier which combined textural and morphological features as input achieved optimal scoring performance with accuracy sensitivity specificity f1 score and auc being 9447 9731 9450 09457 and 09822 respectively compared with other models our proposed method also proved to be more effective thus our proposed method has great potential for clinical application in the analysis of lus images and can aid in the diagnosis and treatment of lung disease ltpgt",Lung
A refined weakly-supervised semantic segmentation method on lung adenocarcinoma histopathology images,https://doi.org/10.21203/rs.3.rs-2695448/v1,2023,"abstract automatic segmentation of tissues from histopathology images is of greatsignificance to reduce the annotation cost hence improve the efficiency of lungadenocarcinoma diagnosis in the field of weakly supervised semanticsegmentation wsss class activation mapping cam is a widely usedtechnology that only uses imagelevel label to locate target objects while themethod based on cam can locate the target object precisely it cannot fill theentire object therefore in this paper we propose a novel method of joint refinederasure attention module rem and class reactivation mapping recam forimagelevel semantic segmentation of histopathology images specifically remconsists of two components channel attention and progressive erasure attentionchannel attention dynamically adjusts the weights of each channel based on theirrelevance and progressive erasure attention selectively removes the mostdiscriminative regions to encourage the model to explore more features thereason for this is to keep the recognition ability of each feature while expandingthe seed region moreover due to the reason that different tissues may includesimilar features caused by aggressive nature of the malignancy we employ thereactivation method to enhance the models discriminative power this methodfinetunes the model parameters by learning an additional fully connected layerwith softmax crossentropy loss sce we evaluate the proposed model on therecently released luadhistoseg dataset the results illustrate that our modelachieved a 7653 miou and outperforms stateoftheart weaklysupervisedlearning methods",Lung
A high-performance deep-learning-based pipeline for whole-brain vasculature segmentation at the capillary resolution.,https://doi.org/10.1093/bioinformatics/btad145,2023,"reconstructing and analyzing all blood vessels throughout the brain is significant for understanding brain function revealing the mechanisms of brain disease and mapping the wholebrain vascular atlas vessel segmentation is a fundamental step in reconstruction and analysis the wholebrain optical microscopic imaging method enables the acquisition of wholebrain vessel images at the capillary resolution due to the massive amount of data and the complex vascular features generated by highresolution wholebrain imaging achieving rapid and accurate segmentation of wholebrain vasculature becomes a challengewe introduce hpvsp a highperformance vessel segmentation pipeline based on deep learning the pipeline consists of three processes data blocking block prediction and block fusion we used parallel computing to parallelize this pipeline to improve the efficiency of wholebrain vessel segmentation we also designed a lightweight deep neural network based on multiresolution vessel feature extraction to segment vessels at different scales throughout the brain accurately we validated our approach on wholebrain vascular data from three transgenic mice collected by hdfmost the results show that our proposed segmentation network achieves the stateoftheart level under various evaluation metrics in contrast the parameters of the network are only 1 of those of similar networks the established segmentation pipeline could be used on various computing platforms and complete the wholebrain vessel segmentation in 3 hours we also demonstrated that our pipeline could be applied to the vascular analysisthe dataset is available at httpatlasbrainsmaticsorgali2301 the source code is freely available at httpsgithubcomvisionlyxhpvspsupplementary data are available at bioinformatics online",Brain
Lung segmentation with NASNet-Large-Decoder Net,https://doi.org/10.48550/arxiv.2303.10315,2023,"lung cancer has emerged as a severe disease that threatens human life and health the precise segmentation of lung regions is a crucial prerequisite for localizing tumors which can provide accurate information for lung image analysis in this work we first propose a lung image segmentation model using the nasnetlarge as an encoder and then followed by a decoder architecture which is one of the most commonly used architectures in deep learning for image segmentation the proposed nasnetlargedecoder architecture can extract highlevel information and expand the feature map to recover the segmentation map to further improve the segmentation results we propose a postprocessing layer to remove the irrelevant portion of the segmentation map experimental results show that an accurate segmentation model with 092 dice scores outperforms stateoftheart performance",Lung
Diff-UNet: A Diffusion Embedded Network for Volumetric Segmentation,https://doi.org/10.48550/arxiv.2303.10326,2023,"in recent years denoising diffusion models have demonstrated remarkable success in generating semantically valuable pixelwise representations for image generative modeling in this study we propose a novel endtoend framework called diffunet for medical volumetric segmentation our approach integrates the diffusion model into a standard ushaped architecture to extract semantic information from the input volume effectively resulting in excellent pixellevel representations for medical volumetric segmentation to enhance the robustness of the diffusion models prediction results we also introduce a stepuncertainty based fusion suf module during inference to combine the outputs of the diffusion models at each step we evaluate our method on three datasets including multimodal brain tumors in mri liver tumors and multiorgan ct volumes and demonstrate that diffunet outperforms other stateoftheart methods significantly our experimental results also indicate the universality and effectiveness of the proposed model the proposed framework has the potential to facilitate the accurate diagnosis and treatment of medical conditions by enabling more precise segmentation of anatomical structures the codes of diffunet are available at httpsgithubcomgexingdiffunet",Brain
A Radiomics-Incorporated Deep Ensemble Learning Model for  Multi-Parametric MRI-based Glioma Segmentation,https://doi.org/10.48550/arxiv.2303.10533,2023,"we developed a deep ensemble learning model with a radiomics spatial encoding execution for improved glioma segmentation accuracy using multiparametric mri mpmri this model was developed using 369 glioma patients with a 4modality mpmri protocol t1 contrastenhanced t1 t1ce t2 and flair in each modality volume a 3d sliding kernel was implemented across the brain to capture image heterogeneity fiftysix radiomic features were extracted within the kernel resulting in a 4th order tensor each radiomic feature can then be encoded as a 3d image volume namely a radiomic feature map rfm pca was employed for data dimension reduction and the first 4 pcs were selected four deep neural networks as submodels following the unet architecture were trained for the segmenting of a regionofinterest roi each submodel utilizes the mpmri and 1 of the 4 pcs as a 5channel input for a 2d execution the 4 softmax probability results given by the unet ensemble were superimposed and binarized by otsu method as the segmentation result three ensemble models were trained to segment enhancing tumor et tumor core tc and whole tumor wt the adopted radiomics spatial encoding execution enriches the image heterogeneity information that leads to the successful demonstration of the proposed deep ensemble model which offers a new tool for mpmri based medical image segmentation",Brain
SDPN: A Slight Dual-Path Network With Local-Global Attention Guided For Medical Image Segmentation,https://doi.org/10.1109/jbhi.2023.3260026,2023,"accurate identification of lesions is a key step in surgical planning however this task mainly exists two challenges 1 due to the complex anatomical shapes of different lesions most segmentation methods only achieve outstanding performance for a specific structure rather than other lesions with location differences 2 the huge number of parameters limits existing transformerbased segmentation models to overcome these problems we propose a novel slight dualpath network sdpn to segment variable location lesions or organs with significant differences accurately first we design a dualpath module to integrate local with global features without obvious memory consumption second a novel multispectrum attention module is proposed to pay further attention to detailed information which can automatically adapt to the variable segmentation target then the compression module based on tensor ring decomposition is designed to compress convolutional and transformer structures in the experiment four datasets including three benchmark datasets and a clinical dataset are used to evaluate sdpn results of the experiments show that sdpn performs better than other startoftheart methods for brain tumor liver tumor endometrial tumor and cardiac segmentation to ensure the generalizability we train the network on kvasirseg and test on cvcclinicdb which collected from a different institution the quantitative analysis shows that the clinical evaluation results are consistent with the experts therefore this model may be a potential candidate for the segmentation of lesions and organs segmentation with variable locations in clinical applications",Cardiac
SDPN: A Slight Dual-Path Network With Local-Global Attention Guided For Medical Image Segmentation,https://doi.org/10.1109/jbhi.2023.3260026,2023,"accurate identification of lesions is a key step in surgical planning however this task mainly exists two challenges 1 due to the complex anatomical shapes of different lesions most segmentation methods only achieve outstanding performance for a specific structure rather than other lesions with location differences 2 the huge number of parameters limits existing transformerbased segmentation models to overcome these problems we propose a novel slight dualpath network sdpn to segment variable location lesions or organs with significant differences accurately first we design a dualpath module to integrate local with global features without obvious memory consumption second a novel multispectrum attention module is proposed to pay further attention to detailed information which can automatically adapt to the variable segmentation target then the compression module based on tensor ring decomposition is designed to compress convolutional and transformer structures in the experiment four datasets including three benchmark datasets and a clinical dataset are used to evaluate sdpn results of the experiments show that sdpn performs better than other startoftheart methods for brain tumor liver tumor endometrial tumor and cardiac segmentation to ensure the generalizability we train the network on kvasirseg and test on cvcclinicdb which collected from a different institution the quantitative analysis shows that the clinical evaluation results are consistent with the experts therefore this model may be a potential candidate for the segmentation of lesions and organs segmentation with variable locations in clinical applications",Brain
Implementing Machine Vision Process to Analyze Echocardiography for Heart Health Monitoring,https://doi.org/10.1007/978-3-031-28183-9_13,2023,"machine vision analysis of echocardiography images echo has vital recent advances echocardiography images are ultrasound scans that present the cardiac structure and function that becomes helpful in a significant measure of eight standard echo views namely a2c a3c a4c a5c plax psaa psap pasm of the cardiac cycle and also identifies the disorders in this research we introduce a vision model for echo analysis with a deep convolutional neural network protected by the unet trained to phase the echoes and extract information of the right ventricle left atrium aorta septum and outer internal organ wall the data includes image bundles input to the cnn model predicts the cardiac structure by a softmax function into different categories which becomes an input to a unet architecture that encodes and decodes the layers and foretells the functioning of the heart through segmentation in summary the research covers designed architecture that presents stateoftheart for investigating echocardiography information with its benefits and drawbacks continued by future work",Cardiac
From Sparse to Precise: A Practical Editing Approach for Intracardiac  Echocardiography Segmentation,https://doi.org/10.48550/arxiv.2303.11041,2023,"accurate and safe catheter ablation procedures for patients with atrial fibrillation require precise segmentation of cardiac structures in intracardiac echocardiography ice imaging prior studies have suggested methods that employ 3d geometry information from the ice transducer to create a sparse ice volume by placing 2d frames in a 3d grid enabling training of 3d segmentation models however the resulting 3d masks from these models can be inaccurate and may lead to serious clinical complications due to the sparse sampling in ice data frames misalignment and cardiac motion to address this issue we propose an interactive editing framework that allows users to edit segmentation output by drawing scribbles on a 2d frame the user interaction is mapped to the 3d grid and utilized to execute an editing step that modifies the segmentation in the vicinity of the interaction while preserving the previous segmentation away from the interaction furthermore our framework accommodates multiple edits to the segmentation output in a sequential manner without compromising previous edits this paper presents a novel loss function and a novel evaluation metric specifically designed for editing results from crossvalidation and testing indicate that our proposed loss function outperforms standard losses and training strategies in terms of segmentation quality and following user input additionally we show quantitatively and qualitatively that subsequent edits do not compromise previous edits when using our method as opposed to standard segmentation losses overall our approach enhances the accuracy of the segmentation while avoiding undesired changes away from user interactions and without compromising the quality of previously edited regions leading to better patient outcomes",Cardiac
Left Ventricle Detection from Cardiac Magnetic Resonance Relaxometry Images Using Visual Transformer,https://doi.org/10.3390/s23063321,2023,"left ventricle lv detection from cardiac magnetic resonance cmr imaging is a fundamental step preliminary to myocardium segmentation and characterization this paper focuses on the application of a visual transformer vit a novel neural network architecture to automatically detect lv from cmr relaxometry sequences we implemented an object detector based on the vit model to identify lv from cmr multiecho t2 sequences we evaluated performances differentiated by slice location according to the american heart association model using 5fold crossvalidation and on an independent dataset of cmr t2 t2 and t1 acquisitions to the best of our knowledge this is the first attempt to localize lv from relaxometry sequences and the first application of vit for lv detection we collected an intersection over union iou index of 068 and a correct identification rate cir of blood pool centroid of 099 comparable with other stateoftheart methods iou and cir values were significantly lower in apical slices no significant differences in performances were assessed on independent t2 dataset iou 068 p 0405 cir 094 p 0066 performances were significantly worse on the t2 and t1 independent datasets t2 iou 062 cir 095 t1 iou 067 cir 098 but still encouraging considering the different types of acquisition this study confirms the feasibility of the application of vit architectures in lv detection and defines a benchmark for relaxometry imaging",Cardiac
Epoch and accuracy based empirical study for cardiac MRI segmentation using deep learning technique,https://doi.org/10.7717/peerj.14939,2023,"cardiac magnetic resonance imaging cmri is a noninvasive imaging technique to analyse the structure and function of the heart it was enhanced considerably over several years to deliver functional information for diagnosing and managing cardiovascular disease cmri image delivers noninvasive clear access to the heart and great vessels the segmentation of cmri provides quantification parameters such as myocardial viability ejection fraction cardiac chamber volume and morphological details in general experts interpret the cmr images by delineating the images manually the manual segmentation process is timeconsuming and it has been observed that the final observation varied with the opinion of the different experts convolution neural network is a newage technology that provides impressive results compared to manual ones in this study convolution neural network model is used for the segmentation task the neural network parameters have been optimized to perform on the novel data set for accurate predictions with other parameters epochs play an essential role in training the network as the network should not be underfitted or overfitted the relationship between the hyperparameter epoch and accuracy is established in the model the model delivers the accuracy of 088 in terms of the iou coefficient",Cardiac
Are uGLAD? Time will tell!,https://doi.org/10.48550/arxiv.2303.11647,2023,"we frequently encounter multiple series that are temporally correlated in our surroundings such as eeg data to examine alterations in brain activity or sensors to monitor body movements segmentation of multivariate time series data is a technique for identifying meaningful patterns or changes in the time series that can signal a shift in the systems behavior however most segmentation algorithms have been designed primarily for univariate time series and their performance on multivariate data remains largely unsatisfactory making this a challenging problem in this work we introduce a novel approach for multivariate time series segmentation using conditional independence ci graphs ci graphs are probabilistic graphical models that represents the partial correlations between the nodes we propose a domain agnostic multivariate segmentation framework texttttglad which draws a parallel between the ci graph nodes and the variables of the time series consider applying a graph recovery model textttuglad to a short interval of the time series it will result in a ci graph that shows partial correlations among the variables we extend this idea to the entire time series by utilizing a sliding window to create a batch of time intervals and then run a single textttuglad model in multitask learning mode to recover all the ci graphs simultaneously as a result we obtain a corresponding temporal ci graphs representation we then designed a firstorder and secondorder based trajectory tracking algorithms to study the evolution of these graphs across distinct intervals finally an allocation algorithm is used to determine a suitable segmentation of the temporal graph sequence texttttglad provides a competitive time complexity of on for settings where number of variables dn we demonstrate successful empirical results on a physical activity monitoring data",Brain
Deep Learning Pipeline for Preprocessing and Segmenting Cardiac Magnetic  Resonance of Single Ventricle Patients from an Image Registry,https://doi.org/10.48550/arxiv.2303.11676,2023,"purpose to develop and evaluate an endtoend deep learning pipeline for segmentation and analysis of cardiac magnetic resonance images to provide corelab processing for a multicentre registry of fontan patients materials and methods this retrospective study used training n 175 validation n 25 and testing n 50 cardiac magnetic resonance image exams collected from 13 institutions in the uk us and canada the data was used to train and evaluate a pipeline containing three deeplearning models the pipelines performance was assessed on the dice and iou score between the automated and reference standard manual segmentation cardiac function values were calculated from both the automated and manual segmentation and evaluated using blandaltman analysis and paired ttests the overall pipeline was further evaluated qualitatively on 475 unseen patient exams results for the 50 testing dataset the pipeline achieved a median dice score of 091 089094 for enddiastolic volume 086 082089 for endsystolic volume and 074 070077 for myocardial mass the deep learningderived enddiastolic volume endsystolic volume myocardial mass stroke volume and ejection fraction had no statistical difference compared to the same values derived from manual segmentation with p values all greater than 005 for the 475 unseen patient exams the pipeline achieved 68 adequate segmentation in both systole and diastole 26 needed minor adjustments in either systole or diastole 5 needed major adjustments and the cropping model only failed in 04 conclusion deep learning pipeline can provide standardised corelab segmentation for fontan patients this pipeline can now be applied to the 4500 cardiac magnetic resonance exams currently in the force registry as well as any new patients that are recruited",Cardiac
Improving Nighttime Driving-Scene Segmentation via Dual Image-adaptive Learnable Filters,https://doi.org/10.1109/tcsvt.2023.3260240,2023,"semantic segmentation on drivingscene images is vital for autonomous driving although encouraging performance has been achieved on daytime images the performance on nighttime images are less satisfactory due to the insufficient exposure and the lack of labeled data to address these issues we present an addon module called dual imageadaptive learnable filters dialfilters to improve the semantic segmentation in nighttime driving conditions aiming at exploiting the intrinsic features of drivingscene images under different illuminations dialfilters consist of two parts including an imageadaptive processing module iapm and a learnable guided filter lgf with dialfilters we design both unsupervised and supervised frameworks for nighttime drivingscene segmentation which can be trained in an endtoend manner specifically the iapm module consists of a small convolutional neural network with a set of differentiable image filters where each image can be adaptively enhanced for better segmentation with respect to the different illuminations the lgf is employed to enhance the output of segmentation network to get the final segmentation result the dialfilters are lightweight and efficient and they can be readily applied for both daytime and nighttime images our experiments show that dailfilters can significantly improve the supervised segmentation performance on acdcnight and nightcity datasets while it demonstrates the stateoftheart performance on unsupervised nighttime semantic segmentation on dark zurich and nighttime driving testbeds codes and models are available at httpsgithubcomwenyyuiaseg",Cardiac
HybridMIM: A Hybrid Masked Image Modeling Framework for 3D Medical Image  Segmentation,https://doi.org/10.48550/arxiv.2303.10333,2023,"masked image modeling mim with transformer backbones has recently been exploited as a powerful selfsupervised pretraining technique the existing mim methods adopt the strategy to mask random patches of the image and reconstruct the missing pixels which only considers semantic information at a lower level and causes a long pretraining timethis paper presents hybridmim a novel hybrid selfsupervised learning method based on masked image modeling for 3d medical image segmentationspecifically we design a twolevel masking hierarchy to specify which and how patches in subvolumes are masked effectively providing the constraints of higher level semantic information then we learn the semantic information of medical images at three levels including1 partial region prediction to reconstruct key contents of the 3d image which largely reduces the pretraining time burden pixellevel 2 patchmasking perception to learn the spatial relationship between the patches in each subvolume regionleveland 3 dropoutbased contrastive learning between samples within a minibatch which further improves the generalization ability of the framework samplelevel the proposed framework is versatile to support both cnn and transformer as encoder backbones and also enables to pretrain decoders for image segmentation we conduct comprehensive experiments on four widelyused public medical image segmentation datasets including brats2020 btcv msd liver and msd spleen the experimental results show the clear superiority of hybridmim against competing supervised methods masked pretraining approaches and other selfsupervised methods in terms of quantitative metrics timing performance and qualitative observations the codes of hybridmim are available at httpsgithubcomgexinghybridmim",Brain
Regional perception and multi-scale feature fusion network for cardiac segmentation,https://doi.org/10.1088/1361-6560/acc71f,2023,"abstract objective cardiovascular disease cvd is a group of diseases affecting cardiac and blood vessels and the shortaxis cardiac magnetic resonance cmr images are considered the gold standard for diagnosis and assessment of cvd in cmr images accurate segmentation of cardiac structures eg left ventricle assists in the parametric quantification of cardiac function however the dynamic beating of the heart renders the location of the heart with respect to other tissues difficult to resolve and the myocardium and its surrounding tissues are similar in gray scale this makes it challenging to accurately segment the cardiac images our goal is to develop a more accurate cmr image segmentation approach approach in this work we propose a regional perception and multiscale feature fusion network rmfnet for cmr image segmentation we design two regional perception modules window selection transformer wst module and grid extraction transformer get module the wst module introduces a window selection block to adaptively select the window of interest to perceive information and a windowed transformer block to enhance global information extraction within each feature window the wst module enhances the network performance by improving the window of interest the get module grids the feature maps to decrease the redundant information in the feature maps and enhances the extraction of latent feature information of the network the rmfnet further introduces a novel multiscale feature extraction msfe module to improve the ability to retain detailed information main results the rmfnet is validated with experiments on three cardiac datasets the results show the rmfnet outperforms other advanced methods in overall performance the rmfnet is further validated for generalizability on a multiorgan dataset the results show the rmfnet also surpasses other comparison methods significance accurate medical image segmentation can reduce the stress of radiologists and play an important role in imageguided clinical procedures",Cardiac
Generalized Knowledge Distillation for Unimodal Glioma Segmentation from Multimodal Models,https://doi.org/10.3390/electronics12071516,2023,"gliomas primary brain tumors arising from glial cells can be effectively identified using magnetic resonance imaging mri a widely employed diagnostic tool in clinical settings accurate glioma segmentation which is crucial for diagnosis and surgical intervention can be achieved by integrating multiple mri modalities that offer complementary information however limited access to multiple modalities in certain clinical contexts often results in suboptimal performance of glioma segmentation methods this study introduces a novel generalized knowledge distillation framework designed to transfer multimodal knowledge from a teacher model to a unimodal student model via two distinct distillation strategies segmentation graph distillation and cascade region attention distillation the former enables the student to replicate the teachers softened output whereas the latter facilitates extraction and learning of region feature information at various levels within the teacher model our evaluation of the proposed distillation strategies using the brats 2018 dataset confirms their superior performance in unimodal segmentation contexts compared with existing methods",Brain
Generalized Knowledge Distillation for Unimodal Glioma Segmentation from Multimodal Models,https://doi.org/10.3390/electronics12071516,2023,"gliomas primary brain tumors arising from glial cells can be effectively identified using magnetic resonance imaging mri a widely employed diagnostic tool in clinical settings accurate glioma segmentation which is crucial for diagnosis and surgical intervention can be achieved by integrating multiple mri modalities that offer complementary information however limited access to multiple modalities in certain clinical contexts often results in suboptimal performance of glioma segmentation methods this study introduces a novel generalized knowledge distillation framework designed to transfer multimodal knowledge from a teacher model to a unimodal student model via two distinct distillation strategies segmentation graph distillation and cascade region attention distillation the former enables the student to replicate the teachers softened output whereas the latter facilitates extraction and learning of region feature information at various levels within the teacher model our evaluation of the proposed distillation strategies using the brats 2018 dataset confirms their superior performance in unimodal segmentation contexts compared with existing methods",Brain
RAD-UNet: Research on an improved lung nodule semantic segmentation algorithm based on deep learning,https://doi.org/10.3389/fonc.2023.1084096,2023,"objective due to the small proportion of target pixels in computed tomography ct images and the high similarity with the environment convolutional neural networkbased semantic segmentation models are difficult to develop by using deep learning extracting feature information often leads to under or oversegmentation of lesions in ct images in this paper an improved convolutional neural network segmentation model known as radunet which is based on the unet encoderdecoder architecture is proposed and applied to lung nodular segmentation in ct images method the proposed radunet segmentation model includes several improved components the unet encoder is replaced by a resnet residual network module an atrous spatial pyramid pooling module is added after the unet encoder and the unet decoder is improved by introducing a crossfusion feature module with channel and spatial attention results the segmentation model was applied to the lidc dataset and a ct dataset collected by the affiliated hospital of anhui medical university the experimental results show that compared with the existing segnet 14 and unet 15 methods the proposed model demonstrates better lung lesion segmentation performance on the above two datasets the miou reached 8776 and 8813 and the f1score reached 9356 and 9372 respectively conclusion the experimental results show that the improved radunet segmentation method achieves more accurate pixellevel segmentation in ct images of lung tumours and identifies lung nodules better than the segnet 14 and unet 15 models the problems of under and oversegmentation that occur during segmentation are solved effectively improving the image segmentation performance",Lung
S<sup>3</sup>R: Shape and Semantics-based Selective Regularization for Explainable Continual Segmentation across Multiple Sites,https://doi.org/10.1109/tmi.2023.3260974,2023,"in clinical practice it is desirable for medical image segmentation models to be able to continually learn on a sequential data stream from multiple sites rather than a consolidated dataset due to storage cost and privacy restrictions however when learning on a new site existing methods struggle with a weak memorizability for previous sites with complex shape and semantic information and a poor explainability for the memory consolidation process in this work we propose a novel shape and semanticsbased selective regularization s sup xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink3sup r method for explainable crosssite continual segmentation to maintain both shape and semantic knowledge of previously learned sites specifically s sup xmlnsmmlhttpwwww3org1998mathmathml xmlnsxlinkhttpwwww3org1999xlink3sup r method adopts a selective regularization scheme to penalize changes of parameters with high joint shape and semanticsbased importance jssi weights which are estimated based on the parameter sensitivity to shape properties and reliable semantics of the segmentation object this helps to prevent the related shape and semantic knowledge from being forgotten moreover we propose an importance activation mapping iam method for memory interpretation which indicates the spatial support for important parameters to visualize the memorized content we have extensively evaluated our method on prostate segmentation and optic cup and disc segmentation tasks our method outperforms other comparison methods in reducing model forgetting and increasing explainability our code is available at httpsgithubcomjingyzhangs3r",Prostate
BIBSNet: A Deep Learning Baby Image Brain Segmentation Network for MRI Scans,https://doi.org/10.1101/2023.03.22.533696,2023,"objectives brain segmentation of infant magnetic resonance mr images is vitally important in studying developmental mental health and disease the infant brain undergoes many changes throughout the first years of postnatal life making tissue segmentation difficult for most existing algorithms here we introduce a deep neural network bibsnet baby and infant brain segmentation neural network an opensource communitydriven model that relies on data augmentation and a large sample size of manually annotated images to facilitate the production of robust and generalizable brain segmentations experimental design included in model training and testing were mr brain images on 84 participants with an age range of 08 months median postmenstrual ages of 1357 months using manually annotated real and synthetic segmentation images the model was trained using a 10fold crossvalidation procedure testing occurred on mri data processed with the dcan labs infantabcdbids processing pipeline using segmentations produced from gold standard manual annotation jointlabel fusion jlf and bibsnet to assess model performance principal observations using group analyses results suggest that cortical metrics produced using bibsnet segmentations outperforms jlf segmentations additionally when analyzing individual differences bibsnet segmentations perform even better conclusions bibsnet segmentation shows marked improvement over jlf segmentations across all age groups analyzed the bibsnet model is 600x faster compared to jlf and can be easily included in other processing pipelines",Brain
Automated deep learning segmentation of high-resolution 7 T ex vivo MRI  for quantitative analysis of structure-pathology correlations in  neurodegenerative diseases,https://doi.org/10.48550/arxiv.2303.12237,2023,"ex vivo mri of the brain provides remarkable advantages over in vivo mri for visualizing and characterizing detailed neuroanatomy and helps to link microscale histology studies with morphometric measurements however automated segmentation methods for brain mapping in ex vivo mri are not well developed primarily due to limited availability of labeled datasets and heterogeneity in scanner hardware and acquisition protocols in this work we present a high resolution dataset of 37 ex vivo postmortem human brain tissue specimens scanned on a 7t wholebody mri scanner we developed a deep learning pipeline to segment the cortical mantle by benchmarking the performance of nine deep neural architectures we then segment the four subcortical structures caudate putamen globus pallidus and thalamus white matter hyperintensities and the normal appearing white matter we show excellent generalizing capabilities across whole brain hemispheres in different specimens and also on unseen images acquired at different magnetic field strengths and different imaging sequence we then compute volumetric and localized cortical thickness measurements across key regions and link them with semiquantitative neuropathological ratings our code containerized executables and the processed datasets are publicly available at httpsgithubcompulkitkhandelwalupennpicslbrainexvivo",Brain
Deep learning for quantitative MRI brain tumor analysis,https://doi.org/10.1101/2023.03.21.23287514,2023,"the infiltrative nature of malignant gliomas results in active tumor spreading into the peritumoral edema which is not visible in conventional magnetic resonance imaging cmri even after contrast injection mr relaxometry qmri measures relaxation rates dependent on tissue properties and can offer additional contrast mechanisms to highlight the nonenhancing infiltrative tumor the aim of this study is to investigate if qmri data provides additional information compared to cmri sequences t1w t1wgd t2w flair when considering deep learningbased brain tumor 1 detection and 2 segmentation a total of 23 patients with histologically confirmed malignant glioma were retrospectively included in the study quantitative mr imaging was used to obtain r 1 1t1 r 2 1t2 and proton density maps pre and postgadolinium contrast injection conventional mr imaging was also performed a 2d cnn detection model and a 2d unet were trained on transversal slices n528 using either cmri or a combination of qmri pre and postcontrast data for tumor detection and segmentation respectively moreover trends in quantitative r 1 and r 2 rates of regions identified as relevant for tumor detection by model explainability methods were qualitatively analyzed tumor detection and segmentation performance for models trained with a combination of qmri pre and postcontrast was the highest detection mcc072 segmentation dice090 however improvements were not statistically significant compared to cmri detection mcc067 segmentation dice090 the analysis of the relaxation rates of the relevant regions identified using model explainability methods showed no differences between models trained on cmri or qmri relevant regions which fell outside the annotation showed changes in relaxation rates after contrast injection similar to those within the annotation when looking at majority of the individual cases a similar trend could not be seen when looking at relaxation trends over all the dataset in conclusion models trained on qmri data obtain similar performance to those trained on cmri data with the advantage of quantitatively measuring brain tissue properties within the scan time 118 minutes for qmri with and without contrast and 122 minutes for cmri moreover when considering individual patients regions identified by model explainability methods as relevant for tumor detection outside the manual annotation of the tumor showed changes in quantitative relaxation rates after contrast injection similar to regions within the annotation suggestive of infiltrative tumor in the peritumoral edema",Brain
Cross-modal image segmentation and synthesis in medical imaging,https://doi.org/10.1117/12.2669536,2023,"medical image is an important type of evidence for diagnosising disease however some patients can not receive a complete radiological examination due to the damage of radiation medical cost or individual differences so the transmembrane of medical images is essential genrative adversarial network gan is an unsupervised deep learning model which is widely used in the synthesis of medical images in this research paired data set which has mri images of brain is used to compare the ability of transforming t1 of t2 images by pix2pix and cyclegan peak signal to ratio psnr and mean absolute error mae are used to evaluate the quantity of predicted t2 images the weight of idenitity loss and hyperpremeters are adjusted to explore a better model of cyclegan the conclusion is that cyclegan with low weight of identity loss is better than that with high weight of identity loss",Brain
EVAC+: Multi-scale V-net with Deep Feature CRF Layers for Brain Extraction,https://doi.org/10.21203/rs.3.rs-2521938/v1,2023,"abstract brain extraction is an indispensable computational necessity for all researchers using brain imaging data however the complex structure of the interfaces between the brain meninges and human skull have not allowed a highly robust solution to emerge while previous methods have used machine learning with structural and geometric priors in mind with the development of deep learning dl there has been an increase in proposed neural network architectures to solve such problems most dl approaches focus on improving the training data with little change in the dl architecture however the amount and quality of accessible training data with expertlabeled ground truth varies between groups thus the performance of many methods heavily depends on the amount and quality of training data in this paper we propose a novel architecture we call evac evac has 3 characteristics to work around this major issue 1 a smart augmentation strategy that improves training efficiency 2 a unique way of using a conditional random fields recurrent layer that improves accuracy and 3 a new loss function that finetunes the segmentation output we compare our model to stateoftheart nondl and dl methods results show that even with limited training resources evac outperforms in most cases achieving a high and stable dice coefficient and jaccard index along with a desirable lower surface hausdorff distance more importantly our approach accurately segmented clinical and pediatric data despite the fact that the training dataset only contains healthy adults ultimately our model provides a reliable way of accurately reducing segmentation errors in complex multitissue interfacing areas of the brain we expect our method which is publicly available and opensource to be beneficial to a wide range of researchers",Brain
On-Device Unsupervised Image Segmentation,https://doi.org/10.48550/arxiv.2303.12753,2023,"along with the breakthrough of convolutional neural networks learningbased segmentation has emerged in many research works most of them are based on supervised learning requiring plenty of annotated data however to support segmentation a label for each pixel is required which is obviously expensive as a result the issue of lacking annotated segmentation data commonly exists continuous learning is a promising way to deal with this issue however it still has high demands on human labor for annotation whats more privacy is highly required in segmentation data for realworld applications which further calls for ondevice learning in this paper we aim to resolve the above issue in an alternative way instead of supervised segmentation we propose to develop efficient unsupervised segmentation that can be executed on edge devices based on our observation that segmentation can obtain high performance when pixels are mapped to a highdimension space we for the first time bring braininspired hyperdimensional computing hdc to the segmentation task we build the hdcbased unsupervised segmentation framework namely seghdc in seghdc we devise a novel encoding approach that follows the manhattan distance a clustering algorithm is further developed on top of the encoded highdimension vectors to obtain segmentation results experimental results show seghdc can significantly surpass neural networkbased unsupervised segmentation on a standard segmentation dataset dsb2018 seghdc can achieve a 280 improvement in intersection over union iou score meanwhile it achieves over 300x speedup on raspberry pi whats more for a larger size image in the bbbc005 dataset the existing approach cannot be accommodated to raspberry pi due to out of memory on the other hand seghdc can obtain segmentation results within 3 minutes while achieving a 09587 iou score",Brain
High-Resolution Swin Transformer for Automatic Medical Image Segmentation,https://doi.org/10.3390/s23073420,2023,"the resolution of feature maps is a critical factor for accurate medical image segmentation most of the existing transformerbased networks for medical image segmentation adopt a unetlike architecture which contains an encoder that converts the highresolution input image into lowresolution feature maps using a sequence of transformer blocks and a decoder that gradually generates highresolution representations from lowresolution feature maps however the procedure of recovering highresolution representations from lowresolution representations may harm the spatial precision of the generated segmentation masks unlike previous studies in this study we utilized the highresolution network hrnet design style by replacing the convolutional layers with transformer blocks continuously exchanging feature map information with different resolutions generated by the transformer blocks the proposed transformerbased network is named the highresolution swin transformer network hrstnet extensive experiments demonstrated that the hrstnet can achieve performance comparable with that of the stateoftheart transformerbased unetlike architecture on the 2021 brain tumor segmentation dataset the medical segmentation decathlons liver dataset and the btcv multiorgan segmentation dataset",Brain
Deep Neural Ideal Networks for Brain Tumour Image Segmentation,https://doi.org/10.1007/978-981-19-7615-5_27,2023,"the automated segmentation of brain tumours utilizing multimodal magnetic resonance imaging mri is crucial in researching and monitoring disease progression to aid in distinguishing gliomas into intertumoural classes efficient and precise segmentation methods are utilized to differentiate gliomas into intratumourally categorized types deep learning algorithms outperform classical contextbased computer vision techniques in circumstances that need the segmentation of objects into categories convolutional neural networks cnns are extensively used in medical image segmentation and they have significantly improved the accuracy of brain tumour segmentation in the present generation specifically this research introduces a residual network resnet a blend of two segmentation networks that employ a primary but simple combinative method to provide better and more accurate predictions after each model was trained on the brats20 challenge data it was analysed to yield segmentation results among the different methodologies examined resnet produced the most accurate results compared to unet and was thus chosen and organized in many ways to arrive at the final forecast on the validation set the ensemble acquired dice scores of 080 and 085 for the augmentation of the tumour total cancer and tumour core respectively demonstrating more excellent performance than the present technology in use",Brain
Deep Neural Ideal Networks for Brain Tumour Image Segmentation,https://doi.org/10.1007/978-981-19-7615-5_27,2023,"the automated segmentation of brain tumours utilizing multimodal magnetic resonance imaging mri is crucial in researching and monitoring disease progression to aid in distinguishing gliomas into intertumoural classes efficient and precise segmentation methods are utilized to differentiate gliomas into intratumourally categorized types deep learning algorithms outperform classical contextbased computer vision techniques in circumstances that need the segmentation of objects into categories convolutional neural networks cnns are extensively used in medical image segmentation and they have significantly improved the accuracy of brain tumour segmentation in the present generation specifically this research introduces a residual network resnet a blend of two segmentation networks that employ a primary but simple combinative method to provide better and more accurate predictions after each model was trained on the brats20 challenge data it was analysed to yield segmentation results among the different methodologies examined resnet produced the most accurate results compared to unet and was thus chosen and organized in many ways to arrive at the final forecast on the validation set the ensemble acquired dice scores of 080 and 085 for the augmentation of the tumour total cancer and tumour core respectively demonstrating more excellent performance than the present technology in use",Brain