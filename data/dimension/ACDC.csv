"About the data: Exported on Mar 06, 2023. Criteria: '""Deep Learning Techniques for Automatic MRI Cardiac Multi-Structures Segmentation and Diagnosis: Is the Problem Solved?""' in full data; Publication Year is 2023 or 2022 or 2021. © 2023 Digital Science &amp; Research Solutions Inc. All rights reserved. Parts of this work may also be protected by copyright of content providers and other third parties, which together with all rights of Digital Science, user agrees not to violate. Redistribution / external use of this work (or parts thereof) is prohibited without prior written approval. Please contact info@dimensions.ai for further information.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rank,Publication ID,DOI,PMID,PMCID,Title,Abstract,Acknowledgements,Funding,Source title,Anthology title,MeSH terms,Publication Date,PubYear,Publication Date (online),Publication Date (print),Volume,Issue,Pagination,Open Access,Publication Type,Authors,Authors (Raw Affiliation),Corresponding Authors,Authors Affiliations,Times cited,Recent citations,RCR,FCR,Source Linkout,Dimensions URL,Fields of Research (ANZSRC 2020),Sustainable Development Goals,,,,,,,,,,,
1136,pub.1154305577,10.26599/tst.2022.9010023,,,SUNet++: A Deep Network with Channel Attention for Small-Scale Object Segmentation on 3D Medical Images,"As a deep learning network with an encoder-decoder architecture, UNet and its series of improved versions have been widely used in medical image segmentation with great applications. However, when used to segment targets in 3D medical images such as magnetic resonance imaging (MRI), computed tomography (CT), these models do not model the relevance of images in vertical space, resulting in poor accurate analysis of consecutive slices of the same patient. On the other hand, the large amount of detail lost during the encoding process makes these models incapable of segmenting small-scale tumor targets. Aiming at the scene of small-scale target segmentation in 3D medical images, a fully new neural network model SUNet++ is proposed on the basis of UNet and UNet++. SUNet++ improves the existing models mainly in three aspects: 1) the modeling strategy of slice superposition is used to thoroughly excavate the three dimensional information of the data; 2) by adding an attention mechanism during the decoding process, small scale targets in the picture are retained and amplified; 3) in the up-sampling process, the transposed convolution operation is used to further enhance the effect of the model. In order to verify the effect of the model, we collected and produced a dataset of hyperintensity MRI liver-stage images containing over 400 cases of liver nodules. Experimental results on both public and proprietary datasets demonstrate the superiority of SUNet++ in small-scale target segmentation of three-dimensional medical images.",,,Tsinghua Science & Technology,,,2023-08,2023,,,28,4,628-638,Closed,Article,"Zhang, Lan; Zhang, Kejia; Pan, Haiwei","Zhang, Lan (College of Computer Science and Technology, Harbin Engineering University,Harbin,China,150001); Zhang, Kejia (College of Computer Science and Technology, Harbin Engineering University,Harbin,China,150001); Pan, Haiwei (College of Computer Science and Technology, Harbin Engineering University,Harbin,China,150001)",,"Zhang, Lan (Harbin Engineering University); Zhang, Kejia (Harbin Engineering University); Pan, Haiwei (Harbin Engineering University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154305577,40 Engineering, 4008 Electrical Engineering,,,,,,,,,,,
958,pub.1155133262,10.1016/j.bspc.2023.104631,,,An EffcientNet-encoder U-Net Joint Residual Refinement Module with Tversky–Kahneman Baroni–Urbani–Buser loss for biomedical image Segmentation,"Quantitative analysis on biomedical images has been on increasing demand nowadays and for modern computer vision approaches. While recently advanced procedures have been enforced, there is still necessity in optimizing network architecture and loss functions. Inspired by the pretrained EfficientNet-B4 and the refinement module in boundary-aware problems, we propose a new two-stage network which is called EffcientNet-encoder U-Net Joint Residual Refinement Module and we create a novel loss function called the Tversky–Kahneman Baroni–Urbani–Buser loss function. The loss function is built on the basement of the Baroni–Urbani–Buser coefficient and the Jaccard–Tanimoto coefficient and reformulated in the Tversky–Kahneman probability-weighting function. We have evaluated our algorithm on the four popular datasets: the 2018 Data Science Bowl Cell Nucleus Segmentation dataset, the Brain Tumor LGG Segmentation dataset, the Skin Lesion ISIC 2018 dataset and the MRI cardiac ACDC dataset. Several comparisons have proved that our proposed approach is noticeably promising and some of the segmentation results provide new state-of-the-art results. The code is available at https://github.com/tswizzle141/An-EffcientNet-encoder-U-Net-Joint-Residual-Refinement-Module-with-TK-BUB-Loss.",This research is funded by Vietnam National Foundation for Science and Technology Development (NAFOSTED) under grant number 102.05–2021.34.,,Biomedical Signal Processing and Control,,,2023-05,2023,,2023-05,83,,104631,Closed,Article,"Nham, Do-Hai-Ninh; Trinh, Minh-Nhat; Nguyen, Viet-Dung; Pham, Van-Truong; Tran, Thi-Thao","Nham, Do-Hai-Ninh (School of Applied Mathematics and Informatics, Hanoi University of Science and Technology, Viet Nam); Trinh, Minh-Nhat (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Viet Nam); Nguyen, Viet-Dung (School of Applied Mathematics and Informatics, Hanoi University of Science and Technology, Viet Nam); Pham, Van-Truong (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Viet Nam); Tran, Thi-Thao (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Viet Nam)","Pham, Van-Truong (Hanoi University of Science and Technology); Tran, Thi-Thao (Hanoi University of Science and Technology)","Nham, Do-Hai-Ninh (Hanoi University of Science and Technology); Trinh, Minh-Nhat (Hanoi University of Science and Technology); Nguyen, Viet-Dung (Hanoi University of Science and Technology); Pham, Van-Truong (Hanoi University of Science and Technology); Tran, Thi-Thao (Hanoi University of Science and Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155133262,"30 Agricultural, Veterinary and Food Sciences; 3006 Food Sciences; 40 Engineering; 4003 Biomedical Engineering",,,,,,,,,,,,
761,pub.1154511176,10.1016/j.patcog.2023.109318,,,Arbitrary Order Total Variation for Deformable Image Registration,"In this work, we investigate image registration in a variational framework and focus on regularization generality and solver efficiency. We first propose a variational model combining the state-of-the-art sum of absolute differences (SAD) and a new arbitrary order total variation regularization term. The main advantage is that this variational model preserves discontinuities in the resultant deformation while being robust to outlier noise. It is however non-trivial to optimize the model due to its non-convexity, non-differentiabilities, and generality in the derivative order. To tackle these, we propose to first apply linearization to the model to formulate a convex objective function and then break down the resultant convex optimization into several point-wise, closed-form subproblems using a fast, over-relaxed alternating direction method of multipliers (ADMM). With this proposed algorithm, we show that solving higher-order variational formulations is similar to solving their lower-order counterparts. Extensive experiments show that our ADMM is significantly more efficient than both the subgradient and primal-dual algorithms particularly when higher-order derivatives are used, and that our new models outperform state-of-the-art methods based on deep learning and free-form deformation. Our code implemented in both Matlab and Pytorch is publicly available at https://github.com/j-duan/AOTV.","Zhaowen Qiu is supported by the Key RD Project of Heilongjiang Province (2022ZX01A30), by the Science and Technology Program of Suzhou (ZXL2021431 and RC2021130), and by the Fundamental Research Funds for the Central Universities (2572020DR10). This research used the UK Biobank Resource under the application number 40119. The GPU computations described in this research were performed using the Baskerville Tier 2 HPC service. Baskerville is funded by the EPSRC and UKRI (EP/T022221/1 and EP/W032244/1) and is operated by Advanced Research Computing at the University of Birmingham. Jinming Duan is partially funded by the BHF Accelerator Award (AA/18/2/34218) and by the Korea Cardiovascular Bioresearch Foundation (CHORUS Seoul 2022). Xi Jia is partially supported by the Chinese Scholarship Council.",,Pattern Recognition,,,2023-05,2023,,2023-05,137,,109318,All OA, Hybrid,Article,"Duan, Jinming; Jia, Xi; Bartlett, Joseph; Lu, Wenqi; Qiu, Zhaowen","Duan, Jinming (School of Computer Science, University of Birmingham, Birmingham, UK; Alan Turing Institute, London, UK); Jia, Xi (School of Computer Science, University of Birmingham, Birmingham, UK); Bartlett, Joseph (School of Computer Science, University of Birmingham, Birmingham, UK; Department of Biomedical Engineering Melbourne Brain Centre Imaging Unit, University of Melbourne, Melbourne, Australia); Lu, Wenqi (Tissue Image Analytics Centre, Department of Computer Science, University of Warwick, Coventry, UK); Qiu, Zhaowen (Institute of Information Computer Engineering, Northeast Forestry University, Harbin, China)","Duan, Jinming (University of Birmingham; The Alan Turing Institute); Qiu, Zhaowen (Northeast Forestry University)","Duan, Jinming (University of Birmingham; The Alan Turing Institute); Jia, Xi (University of Birmingham); Bartlett, Joseph (University of Birmingham; University of Melbourne); Lu, Wenqi (University of Warwick); Qiu, Zhaowen (Northeast Forestry University)",0,0,,,https://doi.org/10.1016/j.patcog.2023.109318,https://app.dimensions.ai/details/publication/pub.1154511176,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1141,pub.1153624193,10.1016/j.artmed.2022.102476,,,Uncertainty-guided mutual consistency learning for semi-supervised medical image segmentation,"Medical image segmentation is a fundamental and critical step in many clinical approaches. Semi-supervised learning has been widely applied to medical image segmentation tasks since it alleviates the heavy burden of acquiring expert-examined annotations and takes the advantage of unlabeled data which is much easier to acquire. Although consistency learning has been proven to be an effective approach by enforcing an invariance of predictions under different distributions, existing approaches cannot make full use of region-level shape constraint and boundary-level distance information from unlabeled data. In this paper, we propose a novel uncertainty-guided mutual consistency learning framework to effectively exploit unlabeled data by integrating intra-task consistency learning from up-to-date predictions for self-ensembling and cross-task consistency learning from task-level regularization to exploit geometric shape information. The framework is guided by the estimated segmentation uncertainty of models to select out relatively certain predictions for consistency learning, so as to effectively exploit more reliable information from unlabeled data. Experiments on two publicly available benchmark datasets showed that: (1) Our proposed method can achieve significant performance improvement by leveraging unlabeled data, with up to 4.13% and 9.82% in Dice coefficient compared to supervised baseline on left atrium segmentation and brain tumor segmentation, respectively. (2) Compared with other semi-supervised segmentation methods, our proposed method achieve better segmentation performance under the same backbone network and task settings on both datasets, demonstrating the effectiveness and robustness of our method and potential transferability for other medical image segmentation tasks.","This work is supported in part by the National Key Research and Development Program of China (2016YFF0201002), and in part by the University Synergy Innovation Program of Anhui Province (GXXT-2019-044).",,Artificial Intelligence in Medicine,,,2023-04,2023,,2023-04,138,,102476,All OA, Green,Article,"Zhang, Yichi; Jiao, Rushi; Liao, Qingcheng; Li, Dongyang; Zhang, Jicong","Zhang, Yichi (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Jiao, Rushi (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Liao, Qingcheng (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Li, Dongyang (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Zhang, Jicong (School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Hefei Innovation Research Institute, Beihang University, Hefei, China; Beijing Advanced Innovation Centre for Biomedical Engineering, Beijing, China)","Zhang, Jicong (Beihang University; Beihang University; )","Zhang, Yichi (Beihang University); Jiao, Rushi (Beihang University); Liao, Qingcheng (Beihang University); Li, Dongyang (Beihang University); Zhang, Jicong (Beihang University; Beihang University)",0,0,,,http://arxiv.org/pdf/2112.02508,https://app.dimensions.ai/details/publication/pub.1153624193,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1133,pub.1153022108,10.1016/j.patcog.2022.109208,,,Region-wise loss for biomedical image segmentation,"We propose Region-wise (RW) loss for biomedical image segmentation. Region-wise loss is versatile, can simultaneously account for class imbalance and pixel importance, and it can be easily implemented as the pixel-wise multiplication between the softmax output and a RW map. We show that, under the proposed RW loss framework, certain loss functions, such as Active Contour and Boundary loss, can be reformulated similarly with appropriate RW maps, thus revealing their underlying similarities and a new perspective to understand these loss functions. We investigate the observed optimization instability caused by certain RW maps, such as Boundary loss distance maps, and we introduce a mathematically-grounded principle to avoid such instability. This principle provides excellent adaptability to any dataset and practically ensures convergence without extra regularization terms or optimization tricks. Following this principle, we propose a simple version of boundary distance maps called rectified Region-wise (RRW) maps that, as we demonstrate in our experiments, achieve state-of-the-art performance with similar or better Dice coefficients and Hausdorff distances than Dice, Focal, weighted Cross entropy, and Boundary losses in three distinct segmentation tasks. We quantify the optimization instability provided by Boundary loss distance maps, and we empirically show that our RRW maps are stable to optimize. The code to run all our experiments is publicly available at: https://github.com/jmlipman/RegionWiseLoss.",The work of J.M. Valverde was funded from the European Union’s Horizon 2020 Framework Programme (Marie Skodowska Curie grant agreement #740264 (GENOMMED)). This work has also been supported by the grant #316258 from Academy of Finland (J. Tohka).,,Pattern Recognition,,,2023-04,2023,,2023-04,136,,109208,All OA, Hybrid,Article,"Valverde, Juan Miguel; Tohka, Jussi","Valverde, Juan Miguel (A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, Kuopio 70150, Finland); Tohka, Jussi (A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, Kuopio 70150, Finland)","Valverde, Juan Miguel (University of Eastern Finland)","Valverde, Juan Miguel (University of Eastern Finland); Tohka, Jussi (University of Eastern Finland)",0,0,,,https://doi.org/10.1016/j.patcog.2022.109208,https://app.dimensions.ai/details/publication/pub.1153022108,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
906,pub.1155258662,10.1016/j.knosys.2023.110378,,,O2M-UDA: Unsupervised dynamic domain adaptation for one-to-multiple medical image segmentation,"One-to-multiple medical image segmentation aims to directly test a segmentation model trained with the medical images of a one-domain site on those of a multiple-domain site, suffering from segmentation performance degradation on multiple domains. This process avoids additional annotations and helps improve the application value of the model. However, no successful one-to-multiple unsupervised domain adaptation (O2M-UDA) work has been reported in one-to-multiple medical image segmentation due to its inherent challenges: distribution differences among multiple target domains (among-target differences) caused by different scanning equipment and distribution differences between one source domain and multiple target domains (source–target differences). In this paper, we propose an O2M-UDA framework called dynamic domain adaptation (DyDA), for one-to-multiple medical image segmentation, which has two innovations: (1) dynamic credible sample strategy (DCSS) dynamically extracts credible samples from the target site and iteratively updates their number, thus iteratively expanding the generalization boundary of the model and minimizing the among-target differences; (2) hybrid uncertainty learning (HUL) reduces the voxel-level and domain-level uncertainty simultaneously, thus minimizing the source–target differences from the detail and entire perspective concurrently. Experiments on two one-to-multiple medical image segmentation tasks have been conducted to demonstrate the performance of the proposed DyDA. The proposed DyDA achieved competitive segmentation results and high adaptation with an average of 83.8% and 48.1% dice for the two tasks, respectively, which has improved by 21.7% and 9.2% compared with no adaptation, respectively. The code developed in this study code can be downloaded at https://github.com/ZoeyJiang/DyDA.","This research was supported by the Intergovernmental Cooperation Project of the National Key Research and Development Program of China (2022YFE0116700), CAAI-Huawei MindSpore Open Fund and Scientific Research Foundation of Graduate School of Southeast University (YBPY2139). We thank the Big Data Computing Center of Southeast University for providing the facility support on the numerical calculations in this paper.",,Knowledge-Based Systems,,,2023-04,2023,,2023-04,265,,110378,Closed,Article,"Jiang, Ziyue; He, Yuting; Ye, Shuai; Shao, Pengfei; Zhu, Xiaomei; Xu, Yi; Chen, Yang; Coatrieux, Jean-Louis; Li, Shuo; Yang, Guanyu","Jiang, Ziyue (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China); He, Yuting (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China); Ye, Shuai (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China); Shao, Pengfei (Department of Urology, the First Affiliated Hospital of Nanjing Medical University, Nanjing, China); Zhu, Xiaomei (Department of Radiology, the First Affiliated Hospital of Nanjing Medical University, Nanjing, China); Xu, Yi (Department of Radiology, the First Affiliated Hospital of Nanjing Medical University, Nanjing, China); Chen, Yang (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China; Jiangsu Provincial Joint International Research Laboratory of Medical Information Processing, Nanjing, China; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs), France); Coatrieux, Jean-Louis (Univ Rennes, Inserm, LTSI - UMR1099, Rennes, F-35000, France; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs), France); Li, Shuo (Department of Biomedical Engineering and the Department of Computer and Data Science, Case Western Reserve University, Cleveland, OH 44106, USA); Yang, Guanyu (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China; Jiangsu Provincial Joint International Research Laboratory of Medical Information Processing, Nanjing, China; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs), France)","Yang, Guanyu (Ministry of Education of the People's Republic of China; ; )","Jiang, Ziyue (Ministry of Education of the People's Republic of China); He, Yuting (Ministry of Education of the People's Republic of China); Ye, Shuai (Ministry of Education of the People's Republic of China); Shao, Pengfei (Jiangsu Province Hospital); Zhu, Xiaomei (Jiangsu Province Hospital); Xu, Yi (Jiangsu Province Hospital); Chen, Yang (Ministry of Education of the People's Republic of China); Coatrieux, Jean-Louis (University of Rennes 1); Li, Shuo (Case Western Reserve University); Yang, Guanyu (Ministry of Education of the People's Republic of China)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155258662,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
961,pub.1155419104,10.1016/j.asoc.2023.110128,,,Big Model and Small Model : Remote modeling and local information extraction module for medical image segmentation,"In the past few years, convolutional neural networks (CNN) and Transformer have achieved great success in medical image segmentation, but they each have inevitable drawbacks. Among them, convolution operation is difficult to calculate the relationship between elements at a certain position and elements far away from the position in the feature map. However, Transformer tends to ignore the importance of local information when exploring the correlation between overall elements. In order to allow the network to acquire both the ability to explore local details and compute the correlation between distant elements, this paper proposes TransUNet++ based on TransUNet. Specifically, this paper proposes two modules, Big Model and Small Model, to explore the element relationship between feature maps. Among them, on the basis of the whole feature map as the basic unit, the Big model can not only calculate the correlation between distant elements in the feature map but also extract the detailed information of the local feature map. On the basis of taking 1/4 of the feature map as the basic unit, the Small model not only explores the correlation between distant elements but also extracts the local details of the feature map. We demonstrate on the Synapse multi-organ segmentation dataset(Synapse) and Automated cardiac diagnosis challenge dataset (ACDC) that using either the Big Model or the Small Model alone can improve the experimental results, and using the Big Model and the Small Model in parallel can achieve more optimal experimental results. Among them, in Synapse dataset, we achieved 80.87% dice score and 24.79% HD score, and in ACDC dataset, we achieved 91.41% dice score and 1.08% HD score.",,"This research was funded by the Scientific and technological innovation 2030 major project under Grant 2022ZD0115802, the National Science Foundation of China under Grant U1903213, and Xinjiang Uygur Autonomous Region Postgraduate Innovation Project, China under Grant XJ2022G024.",Applied Soft Computing,,,2023-03,2023,,2023-03,136,,110128,Closed,Article,"Xu, Lianghui; Wang, Liejun; Li, Yongming; Du, Anyu","Xu, Lianghui (College of Information Science and Engineering, Xinjiang University, Urumqi, 830046, Xinjiang, China); Wang, Liejun (College of Information Science and Engineering, Xinjiang University, Urumqi, 830046, Xinjiang, China); Li, Yongming (College of Information Science and Engineering, Xinjiang University, Urumqi, 830046, Xinjiang, China); Du, Anyu (College of Information Science and Engineering, Xinjiang University, Urumqi, 830046, Xinjiang, China)","Wang, Liejun (Xinjiang University)","Xu, Lianghui (Xinjiang University); Wang, Liejun (Xinjiang University); Li, Yongming (Xinjiang University); Du, Anyu (Xinjiang University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155419104,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,,
1066,pub.1155712698,10.1007/978-3-030-98661-2_109,,,Variational Models and Their Combinations with Deep Learning in Medical Image Segmentation: A Survey,"Image segmentation means to partition an image into separate meaningful regions. Segmentation in medical images can extract different organs, lesions, and other regions of interest, which helps in subsequent disease diagnosis, surgery planning, and efficacy assessment. However, medical images have many unavoidable interference factors, such as imaging noise, artificial artifacts, and mutual occlusion of organs, which make accurate segmentation highly difficult. Incorporating prior knowledge and image information into segmentation model based on variational methods has proven efficient for more accurate segmentation. In recent years, segmentation based on deep learning has been significantly developed, and the combination of classical variational method-based models with deep learning is a hot topic. In this survey, we briefly review the segmentation methods based on a variational method making use of image information and regularity information. Subsequently, we clarify how the integration of variational methods into the deep learning framework leads to more precise segmentation results.",,,,Handbook of Mathematical Models and Algorithms in Computer Vision and Imaging,,2023-02-25,2023,2023-02-25,2023,,,1001-1022,Closed,Chapter,"Gui, Luying; Ma, Jun; Yang, Xiaoping","Gui, Luying (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China); Ma, Jun (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China); Yang, Xiaoping (Department of Mathematics, Nanjing University, Nanjing, China)","Yang, Xiaoping (Nanjing University)","Gui, Luying (Nanjing University of Science and Technology); Ma, Jun (Nanjing University of Science and Technology); Yang, Xiaoping (Nanjing University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155712698,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
1454,pub.1155473631,10.3991/ijoe.v19i02.36607,,,A Convolutional Neural Network Model to Segment Myocardial Infarction from MRI Images,"Cardiovascular diseases (CVDs) are considered one of the leading causes of death worldwide. Myocardial infarction (MI) is one of the deadliest cardiac diseases that require more consideration. Recently, cardiac magnetic resonance imaging (MRI) has been applied as a standard technique for assessing such diseases. The segmentation of the left ventricle (LV) and myocardium from MRI images is vital in detecting MI disease at its early stages. The automatic segmentation of LV is still challenging due to the complex structures of MRI images, inhomogeneous LV shape and moving organs around the LV, such as the lungs and diaphragm. Thus, this study proposed a convolutional neural network (CNN) model for LV and myocardium segmentation to detect MI. The layers selection and hyper-parameters fine-tuning were applied before the training phase. The model showed robust performance based on the evaluation metrics such as accuracy, sensitivity, specificity, dice score coefficient (DSC), Jaccard index and intersection over union (IOU) with values of 0.86, 0.91, 0.84, 0.81, 0.69 and 0.83, respectively.",,,International Journal of Online and Biomedical Engineering (iJOE),,,2023-02-16,2023,2023-02-16,,19,2,150-162,Closed,Article,"Shaaf, Zakarya Farea; Jamil, Muhammad Mahadi Abdul; Ambar, Radzi","Shaaf, Zakarya Farea (Faculty of Electrical and Electronic Engineering, Universiti Tun Hussein Onn Malaysia, Parit Raja, Batu Pahat 86400, Johor, Malaysia); Jamil, Muhammad Mahadi Abdul (); Ambar, Radzi ()",,"Shaaf, Zakarya Farea (Tun Hussein Onn University of Malaysia); Jamil, Muhammad Mahadi Abdul (); Ambar, Radzi ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155473631,40 Engineering, 4003 Biomedical Engineering,3 Good Health and Well Being,,,,,,,,,,
4568,pub.1155417897,10.1016/j.media.2023.102773,36827870,,Automatic uncertainty-based quality controlled T1 mapping and ECV analysis from native and post-contrast cardiac T1 mapping images using Bayesian vision transformer,"Deep learning-based methods for cardiac MR segmentation have achieved state-of-the-art results. However, these methods can generate incorrect segmentation results which can lead to wrong clinical decisions in the downstream tasks. Automatic and accurate analysis of downstream tasks, such as myocardial tissue characterization, is highly dependent on the quality of the segmentation results. Therefore, it is of paramount importance to use quality control methods to detect the failed segmentations before further analysis. In this work, we propose a fully automatic uncertainty-based quality control framework for T1 mapping and extracellular volume (ECV) analysis. The framework consists of three parts. The first one focuses on segmentation of cardiac structures from a native and post-contrast T1 mapping dataset (n=295) using a Bayesian Swin transformer-based U-Net. In the second part, we propose a novel uncertainty-based quality control (QC) to detect inaccurate segmentation results. The QC method utilizes image-level uncertainty features as input to a random forest-based classifier/regressor to determine the quality of the segmentation outputs. The experimental results from four different types of segmentation results show that the proposed QC method achieves a mean area under the ROC curve (AUC) of 0.927 on binary classification and a mean absolute error (MAE) of 0.021 on Dice score regression, significantly outperforming other state-of-the-art uncertainty based QC methods. The performance gap is notably higher in predicting the segmentation quality from poor-performing models which shows the robustness of our method in detecting failed segmentations. After the inaccurate segmentation results are detected and rejected by the QC method, in the third part, T1 mapping and ECV values are computed automatically to characterize the myocardial tissues of healthy and cardiac pathological cases. The native myocardial T1 and ECV values computed from automatic and manual segmentations show an excellent agreement yielding Pearson coefficients of 0.990 and 0.975 (on the combined validation and test sets), respectively. From the results, we observe that the automatically computed myocardial T1 and ECV values have the ability to characterize myocardial tissues of healthy and cardiac diseases like myocardial infarction, amyloidosis, Tako-Tsubo syndrome, dilated cardiomyopathy, and hypertrophic cardiomyopathy.","This work was supported by the French National Research Agency (ANR), France , with reference ANR-19-CE45-0001-01-ACCECIT. Calculations were performed using HPC resources from DNUM CCUB (Centre de Calcul de l’Université de Bourgogne). We also thank the Mesocentre of Franche-Comté for the computing facilities.",,Medical Image Analysis,,,2023-02-15,2023,2023-02-15,2023-05,86,,102773,Closed,Article,"Arega, Tewodros Weldebirhan; Bricq, Stéphanie; Legrand, François; Jacquier, Alexis; Lalande, Alain; Meriaudeau, Fabrice","Arega, Tewodros Weldebirhan (ImViA Laboratory, Université Bourgogne Franche-Comté, Dijon, France. Electronic address: tewdrosw@gmail.com.); Bricq, Stéphanie (ImViA Laboratory, Université Bourgogne Franche-Comté, Dijon, France.); Legrand, François (ImViA Laboratory, Université Bourgogne Franche-Comté, Dijon, France.); Jacquier, Alexis (Aix-Marseille Univ, CNRS, CRMBM, 13005 Marseille, France.); Lalande, Alain (ImViA Laboratory, Université Bourgogne Franche-Comté, Dijon, France; Medical Imaging department, University Hospital of Dijon, Dijon, France.); Meriaudeau, Fabrice (ImViA Laboratory, Université Bourgogne Franche-Comté, Dijon, France.)","Arega, Tewodros Weldebirhan (Université Bourgogne Franche-Comté)","Arega, Tewodros Weldebirhan (Université Bourgogne Franche-Comté); Bricq, Stéphanie (Université Bourgogne Franche-Comté); Legrand, François (Université Bourgogne Franche-Comté); Jacquier, Alexis (Center for Magnetic Resonance in Biology and Medicine); Lalande, Alain (Université Bourgogne Franche-Comté; Centre Hospitalier Universitaire Dijon Bourgogne); Meriaudeau, Fabrice (Université Bourgogne Franche-Comté)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155417897,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
3227,pub.1155411442,10.3390/s23042112,36850717,PMC9958993,Reviewing Federated Machine Learning and Its Use in Diseases Prediction,"Machine learning (ML) has succeeded in improving our daily routines by enabling automation and improved decision making in a variety of industries such as healthcare, finance, and transportation, resulting in increased efficiency and production. However, the development and widespread use of this technology has been significantly hampered by concerns about data privacy, confidentiality, and sensitivity, particularly in healthcare and finance. The ""data hunger"" of ML describes how additional data can increase performance and accuracy, which is why this question arises. Federated learning (FL) has emerged as a technology that helps solve the privacy problem by eliminating the need to send data to a primary server and collect it where it is processed and the model is trained. To maintain privacy and improve model performance, FL shares parameters rather than data during training, in contrast to the typical ML practice of sending user data during model development. Although FL is still in its infancy, there are already applications in various industries such as healthcare, finance, transportation, and others. In addition, 32% of companies have implemented or plan to implement federated learning in the next 12-24 months, according to the latest figures from KPMG, which forecasts an increase in investment in this area from USD 107 million in 2020 to USD 538 million in 2025. In this context, this article reviews federated learning, describes it technically, differentiates it from other technologies, and discusses current FL aggregation algorithms. It also discusses the use of FL in the diagnosis of cardiovascular disease, diabetes, and cancer. Finally, the problems hindering progress in this area and future strategies to overcome these limitations are discussed in detail.",Acknowledgments: We acknowledge the support of Centre d’Entrepreneuriat et de Valorisation des Innovations (CEVI).,This research was funded by the Natural Sciences and Engineering Research Council of Canada (NSERC) grant number 06351.,Sensors,,Humans, Algorithms, Automation, Cardiovascular Diseases, Industry, Machine Learning,2023-02-13,2023,2023-02-13,,23,4,2112,All OA, Gold,Article,"Moshawrab, Mohammad; Adda, Mehdi; Bouzouane, Abdenour; Ibrahim, Hussein; Raad, Ali","Moshawrab, Mohammad (Département de Mathématiques, Informatique et Génie, Université du Québec à Rimouski, 300 Allée des Ursulines, Rimouski, QC G5L 3A1, Canada); Adda, Mehdi (Département de Mathématiques, Informatique et Génie, Université du Québec à Rimouski, 300 Allée des Ursulines, Rimouski, QC G5L 3A1, Canada); Bouzouane, Abdenour (Département d’Informatique et de Mathématique, Université du Québec à Chicoutimi, 555 Boulevard de l’Université, Chicoutimi, QC G7H 2B1, Canada); Ibrahim, Hussein (Institut Technologique de Maintenance Industrielle, 175 Rue de la Vérendrye, Sept-Îles, QC G4R 5B7, Canada); Raad, Ali (Faculty of Arts & Sciences, Islamic University of Lebanon, Wardaniyeh P.O. Box 30014, Lebanon)","Adda, Mehdi (Université du Québec à Rimouski)","Moshawrab, Mohammad (Université du Québec à Rimouski); Adda, Mehdi (Université du Québec à Rimouski); Bouzouane, Abdenour (Université du Québec à Chicoutimi); Ibrahim, Hussein (); Raad, Ali (Islamic University of Lebanon)",0,0,,,https://www.mdpi.com/1424-8220/23/4/2112/pdf?version=1676297327,https://app.dimensions.ai/details/publication/pub.1155411442,46 Information and Computing Sciences, 4604 Cybersecurity and Privacy,,,,,
5371,pub.1155368448,10.3390/life13020507,36836864,PMC9968221,Artificial Intelligence in Cardiovascular CT and MR Imaging,"The technological development of Artificial Intelligence (AI) has grown rapidly in recent years. The applications of AI to cardiovascular imaging are various and could improve the radiologists' workflow, speeding up acquisition and post-processing time, increasing image quality and diagnostic accuracy. Several studies have already proved AI applications in Coronary Computed Tomography Angiography and Cardiac Magnetic Resonance, including automatic evaluation of calcium score, quantification of coronary stenosis and plaque analysis, or the automatic quantification of heart volumes and myocardial tissue characterization. The aim of this review is to summarize the latest advances in the field of AI applied to cardiovascular CT and MR imaging.",,This research received no external funding.,Life,,,2023-02-11,2023,2023-02-11,,13,2,507,All OA, Gold,Article,"Lanzafame, Ludovica R. M.; Bucolo, Giuseppe M.; Muscogiuri, Giuseppe; Sironi, Sandro; Gaeta, Michele; Ascenti, Giorgio; Booz, Christian; Vogl, Thomas J.; Blandino, Alfredo; Mazziotti, Silvio; D’Angelo, Tommaso","Lanzafame, Ludovica R. M. (Diagnostic and Interventional Radiology Unit, BIOMORF Department, University Hospital Messina, 98124 Messina, Italy); Bucolo, Giuseppe M. (Diagnostic and Interventional Radiology Unit, BIOMORF Department, University Hospital Messina, 98124 Messina, Italy); Muscogiuri, Giuseppe (Department of Radiology, Istituto Auxologico Italiano IRCCS, San Luca Hospital, 20149 Milan, Italy; Department of Medicine and Surgery, University of Milano-Bicocca, 20854 Milan, Italy); Sironi, Sandro (Department of Medicine and Surgery, University of Milano-Bicocca, 20854 Milan, Italy; Department of Radiology, ASST Papa Giovanni XXIII, 24127 Bergamo, Italy); Gaeta, Michele (Diagnostic and Interventional Radiology Unit, BIOMORF Department, University Hospital Messina, 98124 Messina, Italy); Ascenti, Giorgio (Diagnostic and Interventional Radiology Unit, BIOMORF Department, University Hospital Messina, 98124 Messina, Italy); Booz, Christian (Division of Experimental Imaging, Department of Diagnostic and Interventional Radiology, University Hospital Frankfurt, 60590 Frankfurt am Main, Germany); Vogl, Thomas J. (Division of Experimental Imaging, Department of Diagnostic and Interventional Radiology, University Hospital Frankfurt, 60590 Frankfurt am Main, Germany); Blandino, Alfredo (Diagnostic and Interventional Radiology Unit, BIOMORF Department, University Hospital Messina, 98124 Messina, Italy); Mazziotti, Silvio (Diagnostic and Interventional Radiology Unit, BIOMORF Department, University Hospital Messina, 98124 Messina, Italy); D’Angelo, Tommaso (Diagnostic and Interventional Radiology Unit, BIOMORF Department, University Hospital Messina, 98124 Messina, Italy; Department of Radiology and Nuclear Medicine, Erasmus MC, 3015 Rotterdam, The Netherlands)","Muscogiuri, Giuseppe (Istituto Auxologico Italiano; University of Milano-Bicocca)","Lanzafame, Ludovica R. M. (Azienda Ospedaliera Universitaria Policlinico ""G. Martino""); Bucolo, Giuseppe M. (Azienda Ospedaliera Universitaria Policlinico ""G. Martino""); Muscogiuri, Giuseppe (Istituto Auxologico Italiano; University of Milano-Bicocca); Sironi, Sandro (University of Milano-Bicocca); Gaeta, Michele (Azienda Ospedaliera Universitaria Policlinico ""G. Martino""); Ascenti, Giorgio (Azienda Ospedaliera Universitaria Policlinico ""G. Martino""); Booz, Christian (University Hospital Frankfurt); Vogl, Thomas J. (University Hospital Frankfurt); Blandino, Alfredo (Azienda Ospedaliera Universitaria Policlinico ""G. Martino""); Mazziotti, Silvio (Azienda Ospedaliera Universitaria Policlinico ""G. Martino""); D’Angelo, Tommaso (Azienda Ospedaliera Universitaria Policlinico ""G. Martino""; Erasmus MC)",0,0,,,https://www.mdpi.com/2075-1729/13/2/507/pdf?version=1676113371,https://app.dimensions.ai/details/publication/pub.1155368448,31 Biological Sciences, 3101 Biochemistry and Cell Biology, 3104 Evolutionary Biology, 46 Information and Computing Sciences, 4601 Applied Computing,,,,,,,
5057,pub.1155185799,10.1016/j.cmpb.2023.107398,36773591,,PyMIC: A deep learning toolkit for annotation-efficient medical image segmentation,"BACKGROUND AND OBJECTIVE: Open-source deep learning toolkits are one of the driving forces for developing medical image segmentation models that are essential for computer-assisted diagnosis and treatment procedures. Existing toolkits mainly focus on fully supervised segmentation that assumes full and accurate pixel-level annotations are available. Such annotations are time-consuming and difficult to acquire for segmentation tasks, which makes learning from imperfect labels highly desired for reducing the annotation cost. We aim to develop a new deep learning toolkit to support annotation-efficient learning for medical image segmentation, which can accelerate and simplify the development of deep learning models with limited annotation budget, e.g., learning from partial, sparse or noisy annotations.
METHODS: Our proposed toolkit named PyMIC is a modular deep learning library for medical image segmentation tasks. In addition to basic components that support development of high-performance models for fully supervised segmentation, it contains several advanced components that are tailored for learning from imperfect annotations, such as loading annotated and unannounced images, loss functions for unannotated, partially or inaccurately annotated images, and training procedures for co-learning between multiple networks, etc. PyMIC is built on the PyTorch framework and supports development of semi-supervised, weakly supervised and noise-robust learning methods for medical image segmentation.
RESULTS: We present several illustrative medical image segmentation tasks based on PyMIC: (1) Achieving competitive performance on fully supervised learning; (2) Semi-supervised cardiac structure segmentation with only 10% training images annotated; (3) Weakly supervised segmentation using scribble annotations; and (4) Learning from noisy labels for chest radiograph segmentation.
CONCLUSIONS: The PyMIC toolkit is easy to use and facilitates efficient development of medical image segmentation models with imperfect annotations. It is modular and flexible, which enables researchers to develop high-performance models with low annotation cost. The source code is available at:https://github.com/HiLab-git/PyMIC.","This work was supported by the National Natural Science Foundation of China under Grant 61901084 and 62271115, National Key Research and Development Program of China (2020YFB1711500), the 1 · 3 · 5 project for disciplines of excellence, West China Hospital, Sichuan University (ZYYC21004).",,Computer Methods and Programs in Biomedicine,,,2023-02-07,2023,2023-02-07,2023-04,231,,107398,All OA, Green,Article,"Wang, Guotai; Luo, Xiangde; Gu, Ran; Yang, Shuojue; Qu, Yijie; Zhai, Shuwei; Zhao, Qianfei; Li, Kang; Zhang, Shaoting","Wang, Guotai (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China. Electronic address: guotai.wang@uestc.edu.cn.); Luo, Xiangde (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China.); Gu, Ran (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China.); Yang, Shuojue (Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, USA.); Qu, Yijie (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China.); Zhai, Shuwei (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China.); Zhao, Qianfei (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China.); Li, Kang (West China Biomedical Big Data Center, West China Hospital, Sichuan University, Chengdu, China.); Zhang, Shaoting (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China.)","Wang, Guotai (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory)","Wang, Guotai (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory); Luo, Xiangde (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory); Gu, Ran (University of Electronic Science and Technology of China); Yang, Shuojue (Johns Hopkins University); Qu, Yijie (University of Electronic Science and Technology of China); Zhai, Shuwei (University of Electronic Science and Technology of China); Zhao, Qianfei (University of Electronic Science and Technology of China); Li, Kang (West China Hospital of Sichuan University; Sichuan University); Zhang, Shaoting (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory)",0,0,,,http://arxiv.org/pdf/2208.09350,https://app.dimensions.ai/details/publication/pub.1155185799,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4808,pub.1155241573,10.3390/bioengineering10020225,36829720,PMC9952498,Semi-Supervised Medical Image Segmentation Guided by Bi-Directional Constrained Dual-Task Consistency,"BACKGROUND: Medical image processing tasks represented by multi-object segmentation are of great significance for surgical planning, robot-assisted surgery, and surgical safety. However, the exceptionally low contrast among tissues and limited available annotated data makes developing an automatic segmentation algorithm for pelvic CT challenging.
METHODS: A bi-direction constrained dual-task consistency model named PICT is proposed to improve segmentation quality by leveraging free unlabeled data. First, to learn more unmarked data features, it encourages the model prediction of the interpolated image to be consistent with the interpolation of the model prediction at the pixel, model, and data levels. Moreover, to constrain the error prediction of interpolation interference, PICT designs an auxiliary pseudo-supervision task that focuses on the underlying information of non-interpolation data. Finally, an effective loss algorithm for both consistency tasks is designed to ensure the complementary manner and produce more reliable predictions.
RESULTS: Quantitative experiments show that the proposed PICT achieves 87.18%, 96.42%, and 79.41% mean DSC score on ACDC, CTPelvic1k, and the individual Multi-tissue Pelvis dataset with gains of around 0.8%, 0.5%, and 1% compared to the state-of-the-art semi-supervised method. Compared to the baseline supervised method, the PICT brings over 3-9% improvements.
CONCLUSIONS: The developed PICT model can effectively leverage unlabeled data to improve segmentation quality of low contrast medical images. The segmentation result could improve the precision of surgical path planning and provide input for robot-assisted surgery.",,"This research was funded by the National Key Research and Development Program of China, grant number 2020YFB1313800, the National Natural Science Foundation of China, grant number 62027813, U20A20196, 62176266, the CAS Interdisciplinary Innovation Team, grant number JCTD-2019-07, and the Beijing Science Fund for Distinguished Young Scholars, grant number JQ21016.",Bioengineering,,,2023-02-07,2023,2023-02-07,,10,2,225,All OA, Gold,Article,"Pan, Ming-Zhang; Liao, Xiao-Lan; Li, Zhen; Deng, Ya-Wen; Chen, Yuan; Bian, Gui-Bin","Pan, Ming-Zhang (School of Mechanical Engineering, Guangxi University, Nanning 530004, China); Liao, Xiao-Lan (School of Mechanical Engineering, Guangxi University, Nanning 530004, China); Li, Zhen (School of Electronic and Information Engineering, Tongji University, Shanghai 200092, China; Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China); Deng, Ya-Wen (School of Mechanical Engineering, Guangxi University, Nanning 530004, China); Chen, Yuan (School of Mechanical Engineering, Guangxi University, Nanning 530004, China); Bian, Gui-Bin (Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China)","Bian, Gui-Bin (Institute of Automation)","Pan, Ming-Zhang (Guangxi University); Liao, Xiao-Lan (Guangxi University); Li, Zhen (Tongji University; Institute of Automation); Deng, Ya-Wen (Guangxi University); Chen, Yuan (Guangxi University); Bian, Gui-Bin (Institute of Automation)",0,0,,,https://www.mdpi.com/2306-5354/10/2/225/pdf?version=1675784097,https://app.dimensions.ai/details/publication/pub.1155241573,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,
1550,pub.1155154890,10.1007/978-981-19-6634-7_42,,,Scaling and Cutout Data Augmentation for Cardiac Segmentation,"Convolutional neural network (CNN) has a compelling learning capability, especially on spatial data representation, crucial in dealing with complex learning tasks. However, it requires extensive training data to optimally fit the model, making it susceptible to overfitting problems when the data is scarce, thus limiting its generalization ability. Therefore, it is essential to collect enough data or supplement the dataset with artificial data to improve the performance of the CNN model. In this paper, simple data augmentation through the geometry transformations of scaling and cutting is explored to augment the training dataset for cardiac segmentation. The generated images and labels are combined with the original dataset to double the training data size. Three state-of-the-art semantic segmentation models, which are U-Net, TernausNet, and DabNet, were used to validate the performance improvement of the proposed data augmentation method. The best performance improvement is returned by DabNet with an increment of 0.24% and 5.14% for mean accuracy and mean intersection over union, respectively. Hence, a better segmentation performance will enable medical practitioners to localize the organs effectively and efficiently.",The researchers acknowledge research funds from Universiti Kebangsaan Malaysia through Geran Universiti Penyelidikan (GUP-2019–008) and Ministry of Higher Education Malaysia through Fundamental Research Grant Scheme (FRGS/1/2019/ICT02/UKM/02/1).,,Lecture Notes in Networks and Systems,Proceedings of International Conference on Data Science and Applications,,2023-02-07,2023,2023-02-07,2023,552,,599-609,Closed,Chapter,"Elizar, Elizar; Zulkifley, Mohd Asyraf; Muharar, Rusdha","Elizar, Elizar (University Kebangsaan Malaysia, 43600, Bangi, Selangor, Malaysia; Universitas Syiah Kuala, Kopelma Darussalam, 23111, Banda Aceh, Aceh, Indonesia); Zulkifley, Mohd Asyraf (University Kebangsaan Malaysia, 43600, Bangi, Selangor, Malaysia); Muharar, Rusdha (Universitas Syiah Kuala, Kopelma Darussalam, 23111, Banda Aceh, Aceh, Indonesia)","Zulkifley, Mohd Asyraf (National University of Malaysia)","Elizar, Elizar (National University of Malaysia; Syiah Kuala University); Zulkifley, Mohd Asyraf (National University of Malaysia); Muharar, Rusdha (Syiah Kuala University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155154890,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
827,pub.1155159970,10.1109/tmi.2023.3243069,,,CAT: Constrained Adversarial Training for Anatomically-plausible Semi-supervised Segmentation,"Deep learning models for semi-supervised medical image segmentation have achieved unprecedented performance for a wide range of tasks. Despite their high accuracy, these models may however yield predictions that are considered anatomically impossible by clinicians. Moreover, incorporating complex anatomical constraints into standard deep learning frameworks remains challenging due to their non-differentiable nature. To address these limitations, we propose a Constrained Adversarial Training (CAT) method that learns how to produce anatomically plausible segmentations. Unlike approaches focusing solely on accuracy measures like Dice, our method considers complex anatomical constraints like connectivity, convexity, and symmetry which cannot be easily modeled in a loss function. The problem of non-differentiable constraints is solved using a Reinforce algorithm which enables to obtain a gradient for violated constraints. To generate constraint-violating examples on the fly, and thereby obtain useful gradients, our method adopts an adversarial training strategy which modifies training images to maximize the constraint loss, and then updates the network to be robust to these adversarial examples. The proposed method offers a generic and efficient way to add complex segmentation constraints on top of any segmentation network. Experiments on synthetic data and four clinically-relevant datasets demonstrate the effectiveness of our method in terms of segmentation accuracy and anatomical plausibility.",,,IEEE Transactions on Medical Imaging,,,2023-02-07,2023,2023-02-07,,PP,99,1-1,Closed,Article,"Wang, Ping; Peng, Jizong; Pedersoli, Marco; Zhou, Yuanfeng; Zhang, Caiming; Desrosiers, Christian","Wang, Ping (Software and IT department, &#x00C9;cole de technologie sup&#x00E9;rieure(ETS), Montreal, Canada); Peng, Jizong (Software and IT department, ETS, Montreal, Canada); Pedersoli, Marco (Software and IT department, ETS, Montreal, Canada); Zhou, Yuanfeng (School of Software, Shandong University, Jinan, China); Zhang, Caiming (School of Software, Shandong University, Jinan, China); Desrosiers, Christian (Software and IT department, ETS, Montreal, Canada)",,"Wang, Ping (); Peng, Jizong (); Pedersoli, Marco (); Zhou, Yuanfeng (Shandong University); Zhang, Caiming (Shandong University); Desrosiers, Christian ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155159970,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
2067,pub.1154965332,10.1016/j.media.2023.102762,36738650,,"Transforming medical imaging with Transformers? A comparative review of key properties, current progresses, and future perspectives","Transformer, one of the latest technological advances of deep learning, has gained prevalence in natural language processing or computer vision. Since medical imaging bear some resemblance to computer vision, it is natural to inquire about the status quo of Transformers in medical imaging and ask the question: can the Transformer models transform medical imaging? In this paper, we attempt to make a response to the inquiry. After a brief introduction of the fundamentals of Transformers, especially in comparison with convolutional neural networks (CNNs), and highlighting key defining properties that characterize the Transformers, we offer a comprehensive review of the state-of-the-art Transformer-based approaches for medical imaging and exhibit current research progresses made in the areas of medical image segmentation, recognition, detection, registration, reconstruction, enhancement, etc. In particular, what distinguishes our review lies in its organization based on the Transformer's key defining properties, which are mostly derived from comparing the Transformer and CNN, and its type of architecture, which specifies the manner in which the Transformer and CNN are combined, all helping the readers to best understand the rationale behind the reviewed approaches. We conclude with discussions of future perspectives.","Li and Zhou are supported by National Natural Science Foundation of China (NSFC) under grant No. 62271465. Chen is supported by U01-CA140204 and R01-EB031023 from the National Institutes of Health, USA .",,Medical Image Analysis,,"Humans; Diagnostic Imaging; Neural Networks, Computer",2023-01-31,2023,2023-01-31,2023-04,85,,102762,All OA, Green,Article,"Li, Jun; Chen, Junyu; Tang, Yucheng; Wang, Ce; Landman, Bennett A; Zhou, S Kevin","Li, Jun (Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China.); Chen, Junyu (Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins Medical Institutes, Baltimore, MD, USA.); Tang, Yucheng (Department of Electrical and Computer Engineering, Vanderbilt University, Nashville, TN, USA.); Wang, Ce (Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China.); Landman, Bennett A (Department of Electrical and Computer Engineering, Vanderbilt University, Nashville, TN, USA.); Zhou, S Kevin (Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China; School of Biomedical Engineering & Suzhou Institute for Advanced Research, Center for Medical Imaging, Robotics, and Analytic Computing & Learning (MIRACLE), University of Science and Technology of China, Suzhou 215123, China. Electronic address: skevinzhou@ustc.edu.cn.)","Zhou, S Kevin (Institute of Computing Technology; University of Science and Technology of China)","Li, Jun (Institute of Computing Technology); Chen, Junyu (Johns Hopkins University); Tang, Yucheng (Vanderbilt University); Wang, Ce (Institute of Computing Technology); Landman, Bennett A (Vanderbilt University); Zhou, S Kevin (Institute of Computing Technology; University of Science and Technology of China)",3,3,,,http://arxiv.org/pdf/2206.01136,https://app.dimensions.ai/details/publication/pub.1154965332,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
6270,pub.1154980644,10.3390/bioengineering10020166,36829660,PMC9952238,Myocardial Segmentation of Tagged Magnetic Resonance Images with Transfer Learning Using Generative Cine-To-Tagged Dataset Transformation,"The use of deep learning (DL) segmentation in cardiac MRI has the potential to streamline the radiology workflow, particularly for the measurement of myocardial strain. Recent efforts in DL motion tracking models have drastically reduced the time needed to measure the heart's displacement field and the subsequent myocardial strain estimation. However, the selection of initial myocardial reference points is not automated and still requires manual input from domain experts. Segmentation of the myocardium is a key step for initializing reference points. While high-performing myocardial segmentation models exist for cine images, this is not the case for tagged images. In this work, we developed and compared two novel DL models (nnU-net and Segmentation ResNet VAE) for the segmentation of myocardium from tagged CMR images. We implemented two methods to transform cardiac cine images into tagged images, allowing us to leverage large public annotated cine datasets. The cine-to-tagged methods included (i) a novel physics-driven transformation model, and (ii) a generative adversarial network (GAN) style transfer model. We show that pretrained models perform better (+2.8 Dice coefficient percentage points) and converge faster (6×) than models trained from scratch. The best-performing method relies on a pretraining with an unpaired, unlabeled, and structure-preserving generative model trained to transform cine images into their tagged-appearing equivalents. Our state-of-the-art myocardium segmentation network reached a Dice coefficient of 0.828 and 95th percentile Hausdorff distance of 4.745 mm on a held-out test set. This performance is comparable to existing state-of-the-art segmentation networks for cine images.",,This work was partly supported by NIH R01 HL152256 and HL131823 to DBE.,Bioengineering,,,2023-01-28,2023,2023-01-28,,10,2,166,All OA, Gold,Article,"Dhaene, Arnaud P; Loecher, Michael; Wilson, Alexander J; Ennis, Daniel B","Dhaene, Arnaud P (Department of Radiology, Stanford University, Stanford, CA 94305, USA.; Signal Processing Laboratory (LTS4), École Polytechnique Fédérale de Lausanne (EPFL), 1015 Lausanne, Switzerland.); Loecher, Michael (Department of Radiology, Stanford University, Stanford, CA 94305, USA.; Stanford Cardiovascular Institute, Stanford University, Stanford, CA 94305, USA.); Wilson, Alexander J (Department of Radiology, Stanford University, Stanford, CA 94305, USA.; Stanford Cardiovascular Institute, Stanford University, Stanford, CA 94305, USA.); Ennis, Daniel B (Department of Radiology, Stanford University, Stanford, CA 94305, USA.; Stanford Cardiovascular Institute, Stanford University, Stanford, CA 94305, USA.)","Loecher, Michael (Stanford University; Stanford Medicine; Stanford University); Ennis, Daniel B (Stanford University; Stanford Medicine; Stanford University)","Dhaene, Arnaud P (Stanford University; École Polytechnique Fédérale de Lausanne); Loecher, Michael (Stanford University; Stanford Medicine; Stanford University); Wilson, Alexander J (Stanford University; Stanford Medicine; Stanford University); Ennis, Daniel B (Stanford University; Stanford Medicine; Stanford University)",0,0,,,https://www.mdpi.com/2306-5354/10/2/166/pdf?version=1674889337,https://app.dimensions.ai/details/publication/pub.1154980644,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,
5668,pub.1154873439,10.3389/fphys.2023.1027076,36776975,PMC9909347,Dilated convolution network with edge fusion block and directional feature maps for cardiac MRI segmentation,"Cardiac magnetic resonance imaging (MRI) segmentation task refers to the accurate segmentation of ventricle and myocardium, which is a prerequisite for evaluating the soundness of cardiac function. With the development of deep learning in medical imaging, more and more heart segmentation methods based on deep learning have been proposed. Due to the fuzzy boundary and uneven intensity distribution of cardiac MRI, some existing methods do not make full use of multi-scale characteristic information and have the problem of ambiguity between classes. In this paper, we propose a dilated convolution network with edge fusion block and directional feature maps for cardiac MRI segmentation. The network uses feature fusion module to preserve boundary information, and adopts the direction field module to obtain the feature maps to improve the original segmentation features. Firstly, multi-scale feature information is obtained and fused through dilated convolutional layers of different scales while downsampling. Secondly, in the decoding stage, the edge fusion block integrates the edge features into the side output of the encoder and concatenates them with the upsampled features. Finally, the concatenated features utilize the direction field to improve the original segmentation features and generate the final result. Our propose method conducts comprehensive comparative experiments on the automated cardiac diagnosis challenge (ACDC) and myocardial pathological segmentation (MyoPS) datasets. The results show that the proposed cardiac MRI segmentation method has better performance compared to other existing methods.","Thanks to all authors for their contributions to this article, and thanks to Jinan University for providing a good platform.","This research was funded by the National Natural Science Foundation of China (61901192) (JB), the Science and Technology Program of Guangzhou (202201010544) (JB), Guangdong Provincial Key Laboratory of Traditional Chinese Medicine Informatization (2021B1212040007) (YL). And National Key Research and Development Project (2019YFC0120100, and 2019YFC0121907) (JB and YL).",Frontiers in Physiology,,,2023-01-26,2023,2023-01-26,,14,,1027076,All OA, Gold,Article,"Chen, Zhensen; Bai, Jieyun; Lu, Yaosheng","Chen, Zhensen (Guangdong Provincial Key Laboratory of Traditional Chinese Medicine Information Technology, Jinan University, Guangzhou, China; College of Information Science and Technology, Jinan University, Guangzhou, China); Bai, Jieyun (Guangdong Provincial Key Laboratory of Traditional Chinese Medicine Information Technology, Jinan University, Guangzhou, China; College of Information Science and Technology, Jinan University, Guangzhou, China); Lu, Yaosheng (Guangdong Provincial Key Laboratory of Traditional Chinese Medicine Information Technology, Jinan University, Guangzhou, China; College of Information Science and Technology, Jinan University, Guangzhou, China)","Bai, Jieyun (Jinan University; Jinan University); Lu, Yaosheng (Jinan University; Jinan University)","Chen, Zhensen (Jinan University; Jinan University); Bai, Jieyun (Jinan University; Jinan University); Lu, Yaosheng (Jinan University; Jinan University)",0,0,,,https://www.frontiersin.org/articles/10.3389/fphys.2023.1027076/pdf,https://app.dimensions.ai/details/publication/pub.1154873439,31 Biological Sciences, 3101 Biochemistry and Cell Biology, 32 Biomedical and Clinical Sciences, 3208 Medical Physiology,,,,,,,,
755,pub.1155169716,10.32604/cmc.2023.035888,,,Deep Learning for Image Segmentation: A Focus on Medical Imaging,"Image segmentation is crucial for various research areas. Many computer vision applications depend on segmenting images to understand the scene, such as autonomous driving, surveillance systems, robotics, and medical imaging. With the recent advances in deep learning (DL) and its confounding results in image segmentation, more attention has been drawn to its use in medical image segmentation. This article introduces a survey of the state-of-the-art deep convolution neural network (CNN) models and mechanisms utilized in image segmentation. First, segmentation models are categorized based on their model architecture and primary working principle. Then, CNN categories are described, and various models are discussed within each category. Compared with other existing surveys, several applications with multiple architectural adaptations are discussed within each category. A comparative summary is included to give the reader insights into utilized architectures in different applications and datasets. This study focuses on medical image segmentation applications, where the most widely used architectures are illustrated, and other promising models are suggested that have proven their success in different domains. Finally, the present work discusses current limitations and solutions along with future trends in the field.",,"This research work was supported by the Information Technology Industry Development Agency (ITIDA), Egypt (Project No. CFP181).",Computers Materials & Continua,,,2023-01-24,2023,2023-01-24,2023,75,1,1995-2024,All OA, Gold,Article,"Khalifa, Ali F.; Badr, Eman","Khalifa, Ali F. (Faculty of Computers and Artificial Intelligence, Cairo University, Giza, 12613, Egypt); Badr, Eman (Faculty of Computers and Artificial Intelligence, Cairo University, Giza, 12613, Egypt; Zewail City of Science and Technology, Giza, 12578, Egypt)","Badr, Eman (Cairo University; Zewail City of Science and Technology)","Khalifa, Ali F. (Cairo University); Badr, Eman (Cairo University; Zewail City of Science and Technology)",0,0,,,https://file.techscience.com/files/cmc/2023/TSP_CMC-75-1/TSP_CMC_35888/TSP_CMC_35888.pdf,https://app.dimensions.ai/details/publication/pub.1155169716,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
6069,pub.1154379604,10.1088/1361-6560/acb19a,36623323,,Cross-convolutional transformer for automated multi-organs segmentation in a variety of medical images,"Objective.It is a huge challenge for multi-organs segmentation in various medical images based on a consistent algorithm with the development of deep learning methods. We therefore develop a deep learning method based on cross-convolutional transformer for these automated- segmentation to obtain better generalization and accuracy.Approach.We propose a cross-convolutional transformer network (C2Former) to solve the segmentation problem. Specifically, we first redesign a novel cross-convolutional self-attention mechanism in terms of the algorithm to integrate local and global contexts and model long-distance and short-distance dependencies to enhance the semantic feature understanding of images. Then multi-scale feature edge fusion module is proposed to combine the image edge features, which effectively form multi-scale feature streams and establish reliable relational connections in the global context. Finally, we use three different modalities, imaging three different anatomical regions to train and test multi organs and evaluate segmentation performance.Main results.We use the evaluation metrics of Dice similarity coefficient (DSC) and 95% Hausdorff distance (HD95) for each dataset. Experiments showed the average DSC of 83.22% and HD95 of 17.55 mm on the Synapse dataset (CT images of abdominal multi-organ), the average DSC of 91.42% and HD95 of 1.06 mm on the ACDC dataset (MRI of cardiac substructures) and the average DSC of 86.78% and HD95 of 16.85 mm on the ISIC 2017 dataset (skin cancer images). In each dataset, our proposed method consistently outperforms the compared networks.Significance.The proposed deep learning network provides a generalized and accurate solution method for multi-organ segmentation in the three different datasets. It has the potential to be applied to a variety of medical datasets for structural segmentation.","This manuscript has not been published or presented elsewhere in part or in entirety and is not under consideration by another journal. The study design was approved by the appropriate ethics review board. We have read and understood your journal’s policies, and we believe that neither the manuscript nor the study violates any of these. There are no conflicts of interest to declare.",,Physics in Medicine and Biology,,"Humans; Neural Networks, Computer; Image Processing, Computer-Assisted; Algorithms; Magnetic Resonance Imaging; Skin Neoplasms",2023-01-23,2023,2023-01-23,2023-02-07,68,3,35008,All OA, Hybrid,Article,"Wang, Jing; Zhao, Haiyue; Liang, Wei; Wang, Shuyu; Zhang, Yan","Wang, Jing (School of Information Science and Engineering Department, Shandong University, 72 Binghai Road, Jimo, Qingdao, Shandong, People’s Republic of China); Zhao, Haiyue (Shandong Youth University of Political Science, No.31699 Jing Shi East Road, Li Xia District, Jinan, Shandong, People’s Republic of China); Liang, Wei (Department of ecological environment of Shandong, No.3377 Jing Shi Road, Jinan, People’s Republic of China); Wang, Shuyu (Shandong Youth University of Political Science, No.31699 Jing Shi East Road, Li Xia District, Jinan, Shandong, People’s Republic of China); Zhang, Yan (Shandong Mental Health Center, No.49 Wen Hua Dong Road, Li Xia District, Jinan, Shandong, People’s Republic of China)","Zhang, Yan (Shandong Mental Health Center)","Wang, Jing (Shandong University); Zhao, Haiyue (Shandong Youth University of Political Science); Liang, Wei (); Wang, Shuyu (Shandong Youth University of Political Science); Zhang, Yan (Shandong Mental Health Center)",0,0,,,https://iopscience.iop.org/article/10.1088/1361-6560/acb19a/pdf,https://app.dimensions.ai/details/publication/pub.1154379604,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,
6293,pub.1154738802,10.1038/s41598-023-28348-y,36681759,PMC9867728,Deep learning can yield clinically useful right ventricular segmentations faster than fully manual analysis,"Right ventricular (RV) volumes are commonly obtained through time-consuming manual delineations of cardiac magnetic resonance (CMR) images. Deep learning-based methods can generate RV delineations, but few studies have assessed their ability to accelerate clinical practice. Therefore, we aimed to develop a clinical pipeline for deep learning-based RV delineations and validate its ability to reduce the manual delineation time. Quality-controlled delineations in short-axis CMR scans from 1114 subjects were used for development. Time reduction was assessed by two observers using 50 additional clinical scans. Automated delineations were subjectively rated as (A) sufficient for clinical use, or as needing (B) minor or (C) major corrections. Times were measured for manual corrections of delineations rated as B or C, and for fully manual delineations on all 50 scans. Fifty-eight % of automated delineations were rated as A, 42% as B, and none as C. The average time was 6 min for a fully manual delineation, 2 s for an automated delineation, and 2 min for a minor correction, yielding a time reduction of 87%. The deep learning-based pipeline could substantially reduce the time needed to manually obtain clinically applicable delineations, indicating ability to yield right ventricular assessments faster than fully manual analysis in clinical practice. However, these results may not generalize to clinics using other RV delineation guidelines.","The authors would like to thank the Department of Clinical Physiology at Lund University for providing a seamless collaboration between the clinic and the Lund Cardiac MR Group. In addition, the authors would like to acknowledge the hard work of the PhD students in the group that have contributed to the pool of RV delineations.","Open access funding provided by Lund University. This study was funded by the Swedish Research Council, the Medical Faculty at Lund University, Region of Scania (ALF Dnr 47405, 46121 and 47401), the Knut and Alice Wallenberg foundation, as well as the Heart and Lung Foundation.",Scientific Reports,,Humans, Deep Learning, Heart Ventricles, Heart, Magnetic Resonance Imaging, Heart Diseases,2023-01-21,2023,2023-01-21,,13,1,1216,All OA, Gold,Article,"Åkesson, Julius; Ostenfeld, Ellen; Carlsson, Marcus; Arheden, Håkan; Heiberg, Einar","Åkesson, Julius (Clinical Physiology, Department of Clinical Sciences Lund, Lund University, Skåne University Hospital, Lund, Sweden; Department of Biomedical Engineering, Faculty of Engineering, Lund University, Lund, Sweden); Ostenfeld, Ellen (Clinical Physiology, Department of Clinical Sciences Lund, Lund University, Skåne University Hospital, Lund, Sweden); Carlsson, Marcus (Clinical Physiology, Department of Clinical Sciences Lund, Lund University, Skåne University Hospital, Lund, Sweden); Arheden, Håkan (Clinical Physiology, Department of Clinical Sciences Lund, Lund University, Skåne University Hospital, Lund, Sweden); Heiberg, Einar (Clinical Physiology, Department of Clinical Sciences Lund, Lund University, Skåne University Hospital, Lund, Sweden)","Åkesson, Julius (Lund University; Skåne University Hospital; Lund University)","Åkesson, Julius (Lund University; Skåne University Hospital; Lund University); Ostenfeld, Ellen (Lund University; Skåne University Hospital); Carlsson, Marcus (Lund University; Skåne University Hospital); Arheden, Håkan (Lund University; Skåne University Hospital); Heiberg, Einar (Lund University; Skåne University Hospital)",0,0,,,https://www.nature.com/articles/s41598-023-28348-y.pdf,https://app.dimensions.ai/details/publication/pub.1154738802,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 51 Physical Sciences,,,,
870,pub.1154645446,10.1109/tmi.2023.3237183,,,Reliable Mutual Distillation for Medical Image Segmentation under Imperfect Annotations,"Convolutional neural networks (CNNs) have made enormous progress in medical image segmentation. The learning of CNNs is dependent on a large amount of training data with fine annotations. The workload of data labeling can be significantly relieved via collecting imperfect annotations which only match the underlying ground truths coarsely. However, label noises which are systematically introduced by the annotation protocols, severely hinders the learning of CNN-based segmentation models. Hence, we devise a novel collaborative learning framework in which two segmentation models cooperate to combat label noises in coarse annotations. First, the complementary knowledge of two models is explored by making one model clean training data for the other model. Secondly, to further alleviate the negative impact of label noises and make sufficient usage of the training data, the specific reliable knowledge of each model is distilled into the other model with augmentation-based consistency constraints. A reliability-aware sample selection strategy is incorporated for guaranteeing the quality of the distilled knowledge. Moreover, we employ joint data and model augmentations to expand the usage of reliable knowledge. Extensive experiments on two benchmarks showcase the superiority of our proposed method against existing methods under annotations with different noise levels. For example, our approach can improve existing methods by nearly 3% DSC on the lung lesion segmentation dataset LIDC-IDRI under annotations with 80% noise ratio.",,,IEEE Transactions on Medical Imaging,,,2023-01-19,2023,2023-01-19,,PP,99,1-1,Closed,Article,"Fang, Chaowei; Wang, Qian; Cheng, Lechao; Gao, Zhifan; Pan, Chengwei; Cao, Zhen; Zheng, Zhaohui; Zhang, Dingwen","Fang, Chaowei (School of Artificial Intelligence, Xidian University, Xi&#x2019;an, China); Wang, Qian (School of Artificial Intelligence, Xidian University, Xi&#x2019;an, China); Cheng, Lechao (Zhejiang Lab, Hangzhou, China); Gao, Zhifan (School of Biomedical Engineering, Sun Yat-sen University, Shenzhen, China); Pan, Chengwei (Institute of Artificial Intelligence, Beihang University, Beijing, China); Cao, Zhen (School of Artificial Intelligence, Xidian University, Xi&#x2019;an, China); Zheng, Zhaohui (Department of Clinical Immunology, Xijing Hospital, The Fourth Military Medical University, Xi&#x2019;an, China); Zhang, Dingwen (School of Automation, Brain and Artificial Intelligence Laboratory, Northwestern Polytechnical University, Xi&#x2019;an, China)",,"Fang, Chaowei (Xidian University); Wang, Qian (Xidian University); Cheng, Lechao (Zhejiang Lab); Gao, Zhifan (Sun Yat-sen University); Pan, Chengwei (Beihang University); Cao, Zhen (Xidian University); Zheng, Zhaohui (Air Force Medical University; Xijing Hospital); Zhang, Dingwen (Northwestern Polytechnical University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154645446,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,,
909,pub.1154501212,10.48550/arxiv.2301.04882,,,ZScribbleSeg: Zen and the Art of Scribble Supervised Medical Image  Segmentation,"Curating a large scale fully-annotated dataset can be both labour-intensive
and expertise-demanding, especially for medical images. To alleviate this
problem, we propose to utilize solely scribble annotations for weakly
supervised segmentation. Existing solutions mainly leverage selective losses
computed solely on annotated areas and generate pseudo gold standard
segmentation by propagating labels to adjacent areas. However, these methods
could suffer from the inaccurate and sometimes unrealistic pseudo segmentation
due to the insufficient supervision and incomplete shape features. Different
from previous efforts, we first investigate the principle of ''good scribble
annotations'', which leads to efficient scribble forms via supervision
maximization and randomness simulation. Furthermore, we introduce
regularization terms to encode the spatial relationship and shape prior, where
a new formulation is developed to estimate the mixture ratios of label classes.
These ratios are critical in identifying the unlabeled pixels for each class
and correcting erroneous predictions, thus the accurate estimation lays the
foundation for the incorporation of spatial prior. Finally, we integrate the
efficient scribble supervision with the prior into a unified framework, denoted
as ZScribbleSeg, and apply the method to multiple scenarios. Leveraging only
scribble annotations, ZScribbleSeg set new state-of-the-arts on four
segmentation tasks using ACDC, MSCMRseg, MyoPS and PPSS datasets.",,,arXiv,,,2023-01-12,2023,,,,,,All OA, Green,Preprint,"Zhang, Ke; Zhuang, Xiahai","Zhang, Ke (); Zhuang, Xiahai ()",,"Zhang, Ke (); Zhuang, Xiahai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154501212,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1451,pub.1154431738,10.1007/s00740-022-00474-9,,,Künstliche Intelligenz und Radiomics,"Clinical/methodical issueCardiac diseases are the leading cause of death. Many diseases can be specifically treated once a valid diagnosis is established. Cardiac magnetic resonance imaging (MRI) plays a central role in the workup of many cardiac pathologies. However, image acquisition as well as interpretation and related secondary image evaluation are time-consuming and complex.Standard radiological methodsCardiac MRI is becoming increasingly established in international guidelines for the evaluation of cardiac function and differential diagnosis of a wide variety of cardiac diseases.Methodological innovationsCardiac MRI has limited reproducibility due to the acquisition technique and interpretation of findings with complex secondary measurements. Artificial intelligence techniques and radiomics offer the potential to improve the acquisition, interpretation, and reproducibility of cardiac MRI.PerformanceResearch suggests that artificial intelligence and radiomic analysis can improve cardiac MRI in terms of image acquisition and also diagnostic and prognostic value. Furthermore, the implementation of artificial intelligence and radiomics may result in the identification of new biomarkers.Achievements and practical recommendationsThe implementation of artificial intelligence in cardiac MRI has great potential. However, the current level of evidence is still limited in some aspects; in particular there are too few prospective and large multicenter studies available. As a result, the algorithms developed are often not sufficiently validated scientifically and are not yet applied in clinical routine.",,,Wiener klinisches Magazin,,,2023-01-11,2023,2023-01-11,2023-02,26,1,4-10,Closed,Article,"Rau, Alexander; Soschynski, Martin; Taron, Jana; Ruile, Philipp; Schlett, Christopher L.; Bamberg, Fabian; Krauss, Tobias","Rau, Alexander (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Soschynski, Martin (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Taron, Jana (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Ruile, Philipp (Klinik für Klinik für Kardiologie und Angiologie, Universitäts-Herzzentrum Freiburg – Bad Krozingen, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Bad Krozingen, Deutschland); Schlett, Christopher L. (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Bamberg, Fabian (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Krauss, Tobias (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland)","Rau, Alexander (University of Freiburg; University Medical Center Freiburg)","Rau, Alexander (University of Freiburg; University Medical Center Freiburg); Soschynski, Martin (University of Freiburg; University Medical Center Freiburg); Taron, Jana (University of Freiburg; University Medical Center Freiburg); Ruile, Philipp (Universitäts-Herzzentrum Freiburg-Bad Krozingen); Schlett, Christopher L. (University of Freiburg; University Medical Center Freiburg); Bamberg, Fabian (University of Freiburg; University Medical Center Freiburg); Krauss, Tobias (University of Freiburg; University Medical Center Freiburg)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154431738,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,,,,,,
1303,pub.1154424344,10.48550/arxiv.2301.04401,,,An atrium segmentation network with location guidance and siamese  adjustment,"The segmentation of atrial scan images is of great significance for the
three-dimensional reconstruction of the atrium and the surgical positioning.
Most of the existing segmentation networks adopt a 2D structure and only take
original images as input, ignoring the context information of 3D images and the
role of prior information. In this paper, we propose an atrium segmentation
network LGSANet with location guidance and siamese adjustment, which takes
adjacent three slices of images as input and adopts an end-to-end approach to
achieve coarse-to-fine atrial segmentation. The location guidance(LG) block
uses the prior information of the localization map to guide the encoding
features of the fine segmentation stage, and the siamese adjustment(SA) block
uses the context information to adjust the segmentation edges. On the atrium
datasets of ACDC and ASC, sufficient experiments prove that our method can
adapt to many classic 2D segmentation networks, so that it can obtain
significant performance improvements.",,,arXiv,,,2023-01-11,2023,,,,,,All OA, Green,Preprint,"Xie, Yuhan; Zhang, Zhiyong; Chen, Shaolong; Qiu, Changzhen","Xie, Yuhan (); Zhang, Zhiyong (); Chen, Shaolong (); Qiu, Changzhen ()",,"Xie, Yuhan (); Zhang, Zhiyong (); Chen, Shaolong (); Qiu, Changzhen ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154424344,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1251,pub.1155160425,10.1109/wacv56688.2023.00365,,,The Fully Convolutional Transformer for Medical Image Segmentation,"We propose a novel transformer, capable of segmenting medical images of varying modalities. Challenges posed by the fine-grained nature of medical image analysis mean that the adaptation of the transformer for their analysis is still at nascent stages. The overwhelming success of the UNet lay in its ability to appreciate the fine-grained nature of the segmentation task, an ability which existing transformer based models do not currently posses. To address this shortcoming, we propose The Fully Convolutional Transformer (FCT), which builds on the proven ability of Convolutional Neural Networks to learn effective image representations, and combines them with the ability of Transformers to effectively capture long-term dependencies in its inputs. The FCT is the first fully convolutional Transformer model in medical imaging literature. It processes its input in two stages, where first, it learns to extract long range semantic dependencies from the input image, and then learns to capture hierarchical global attributes from the features. FCT is compact, accurate and robust. Our results show that it outperforms all existing transformer architectures by large margins across multiple medical image segmentation datasets of varying data modalities without the need for any pre-training. FCT outperforms its immediate competitor on the ACDC dataset by 1.3%, on the Synapse dataset by 4.4%, on the Spleen dataset by 1.2% and on ISIC 2017 dataset by 1.1% on the dice metric, with up to five times fewer parameters. On the ACDC Post-2017-MICCAI-Challenge online test set, our model sets a new state-of-the-art on unseen MRI test cases out-performing large ensemble models as well as nnUNet with considerably fewer parameters. Our code, environments and models will be available via GitHub†.","C.K. and R.M-S. were supported by UKRI project 104690, iCAIRD, funded by Innovate UK, and from EPSRC grant EP/M01326X/1, QuantIC. R.M-S. and D.H. were also supported by EPSRC grant EP/R018634/1, Closed-loop Data Science. D.H. was also supported by EPSRC grant EP/T017899/1.","C.K. and R.M-S. were supported by UKRI project 104690, iCAIRD, funded by Innovate UK, and from EPSRC grant EP/M01326X/1, QuantIC. R.M-S. and D.H. were also supported by EPSRC grant EP/R018634/1, Closed-loop Data Science. D.H. was also supported by EPSRC grant EP/T017899/1.",,2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),,2023-01-07,2023,,2023-01-07,0,,3649-3658,All OA, Green,Proceeding,"Tragakis, Athanasios; Kaul, Chaitanya; Murray-Smith, Roderick; Husmeier, Dirk","Tragakis, Athanasios (Mathematics and Statistics, University of Glasgow, United Kingdom, G12 8QW); Kaul, Chaitanya (School of Computing Science, University of Glasgow, United Kingdom, G12 8RZ); Murray-Smith, Roderick (School of Computing Science, University of Glasgow, United Kingdom, G12 8RZ); Husmeier, Dirk (Mathematics and Statistics, University of Glasgow, United Kingdom, G12 8QW)","Tragakis, Athanasios (University of Glasgow)","Tragakis, Athanasios (University of Glasgow); Kaul, Chaitanya (University of Glasgow); Murray-Smith, Roderick (University of Glasgow); Husmeier, Dirk (University of Glasgow)",1,1,,,http://arxiv.org/pdf/2206.00566,https://app.dimensions.ai/details/publication/pub.1155160425,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
5867,pub.1154236812,10.1371/journal.pdig.0000159,36812626,PMC9931226,Interpretable machine learning for automated left ventricular scar quantification in hypertrophic cardiomyopathy patients,"Scar quantification on cardiovascular magnetic resonance (CMR) late gadolinium enhancement (LGE) images is important in risk stratifying patients with hypertrophic cardiomyopathy (HCM) due to the importance of scar burden in predicting clinical outcomes. We aimed to develop a machine learning (ML) model that contours left ventricular (LV) endo- and epicardial borders and quantifies CMR LGE images from HCM patients.We retrospectively studied 2557 unprocessed images from 307 HCM patients followed at the University Health Network (Canada) and Tufts Medical Center (USA). LGE images were manually segmented by two experts using two different software packages. Using 6SD LGE intensity cutoff as the gold standard, a 2-dimensional convolutional neural network (CNN) was trained on 80% and tested on the remaining 20% of the data. Model performance was evaluated using the Dice Similarity Coefficient (DSC), Bland-Altman, and Pearson's correlation. The 6SD model DSC scores were good to excellent at 0.91 ± 0.04, 0.83 ± 0.03, and 0.64 ± 0.09 for the LV endocardium, epicardium, and scar segmentation, respectively. The bias and limits of agreement for the percentage of LGE to LV mass were low (-0.53 ± 2.71%), and correlation high (r = 0.92). This fully automated interpretable ML algorithm allows rapid and accurate scar quantification from CMR LGE images. This program does not require manual image pre-processing, and was trained with multiple experts and software, increasing its generalizability.",,"Funding for this study was provided by the Peter Munk Cardiology Center Innovation Fund and the MSH-UHN AMO Innovation Fund. BW is partially supported by the CIFAR AI Chair Program. WT is supported by a Heart and Stroke Foundation of Canada National New Investigator Award. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.",PLOS Digital Health,,,2023-01-04,2023,2023-01-04,,2,1,e0000159,All OA, Gold,Article,"Navidi, Zeinab; Sun, Jesse; Chan, Raymond H; Hanneman, Kate; Al-Arnawoot, Amna; Munim, Alif; Rakowski, Harry; Maron, Martin S; Woo, Anna; Wang, Bo; Tsang, Wendy","Navidi, Zeinab (Division of Cardiology, Peter Munk Cardiac Center, Toronto General Hospital, University Health Network, University of Toronto, Toronto, Canada.; Department of Computer Science, University of Toronto, Toronto, Canada.; Vector Institute, Toronto, Canada.); Sun, Jesse (Division of Cardiology, Peter Munk Cardiac Center, Toronto General Hospital, University Health Network, University of Toronto, Toronto, Canada.); Chan, Raymond H (Division of Cardiology, Peter Munk Cardiac Center, Toronto General Hospital, University Health Network, University of Toronto, Toronto, Canada.); Hanneman, Kate (Department of Radiology, University Health Network, University of Toronto, Toronto, Canada.); Al-Arnawoot, Amna (Department of Radiology, University Health Network, University of Toronto, Toronto, Canada.); Munim, Alif (Vector Institute, Toronto, Canada.); Rakowski, Harry (Division of Cardiology, Peter Munk Cardiac Center, Toronto General Hospital, University Health Network, University of Toronto, Toronto, Canada.); Maron, Martin S (Division of Cardiology, Tufts Medical Center, Boston, United States of America.); Woo, Anna (Division of Cardiology, Peter Munk Cardiac Center, Toronto General Hospital, University Health Network, University of Toronto, Toronto, Canada.); Wang, Bo (Division of Cardiology, Peter Munk Cardiac Center, Toronto General Hospital, University Health Network, University of Toronto, Toronto, Canada.; Department of Computer Science, University of Toronto, Toronto, Canada.; Vector Institute, Toronto, Canada.; Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, Canada.); Tsang, Wendy (Division of Cardiology, Peter Munk Cardiac Center, Toronto General Hospital, University Health Network, University of Toronto, Toronto, Canada.)","Tsang, Wendy (University of Toronto)","Navidi, Zeinab (University of Toronto; University of Toronto; Vector Institute); Sun, Jesse (University of Toronto); Chan, Raymond H (University of Toronto); Hanneman, Kate (University Health Network; University of Toronto); Al-Arnawoot, Amna (University Health Network; University of Toronto); Munim, Alif (Vector Institute); Rakowski, Harry (University of Toronto); Maron, Martin S (Tufts Medical Center); Woo, Anna (University of Toronto); Wang, Bo (University of Toronto; University of Toronto; Vector Institute; University of Toronto); Tsang, Wendy (University of Toronto)",0,0,,,https://journals.plos.org/digitalhealth/article/file?id=10.1371/journal.pdig.0000159&type=printable,https://app.dimensions.ai/details/publication/pub.1154236812,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
957,pub.1154351173,10.48550/arxiv.2301.02554,,,MSCDA: Multi-level Semantic-guided Contrast Improves Unsupervised Domain  Adaptation for Breast MRI Segmentation in Small Datasets,"Deep learning (DL) applied to breast tissue segmentation in magnetic
resonance imaging (MRI) has received increased attention in the last decade,
however, the domain shift which arises from different vendors, acquisition
protocols, and biological heterogeneity, remains an important but challenging
obstacle on the path towards clinical implementation. Recently, unsupervised
domain adaptation (UDA) methods have attempted to mitigate this problem by
incorporating self-training with contrastive learning. To better exploit the
underlying semantic information of the image at different levels, we propose a
Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA) framework to
align the feature representation between domains. In particular, we extend the
contrastive loss by incorporating pixel-to-pixel, pixel-to-centroid, and
centroid-to-centroid contrasts to integrate semantic information of images. We
utilize a category-wise cross-domain sampling strategy to sample anchors from
target images and build a hybrid memory bank to store samples from source
images. Two breast MRI datasets were retrospectively collected: The source
dataset contains non-contrast MRI examinations from 11 healthy volunteers and
the target dataset contains contrast-enhanced MRI examinations of 134 invasive
breast cancer patients. We set up experiments from source T2W image to target
dynamic contrast-enhanced (DCE)-T1W image (T2W-to-T1W) and from source T1W
image to target T2W image (T1W-to-T2W). The proposed method achieved Dice
similarity coefficient (DSC) of 89.2\% and 84.0\% in T2W-to-T1W and T1W-to-T2W,
respectively, outperforming state-of-the-art methods. Notably, good performance
is still achieved with a smaller source dataset, proving that our framework is
label-efficient.",,,arXiv,,,2023-01-04,2023,,,,,,All OA, Green,Preprint,"Kuang, Sheng; Woodruff, Henry C.; Granzier, Renee; van Nijnatten, Thiemo J. A.; Lobbes, Marc B. I.; Smidt, Marjolein L.; Lambin, Philippe; Mehrkanoon, Siamak","Kuang, Sheng (); Woodruff, Henry C. (); Granzier, Renee (); van Nijnatten, Thiemo J. A. (); Lobbes, Marc B. I. (); Smidt, Marjolein L. (); Lambin, Philippe (); Mehrkanoon, Siamak ()",,"Kuang, Sheng (); Woodruff, Henry C. (); Granzier, Renee (); van Nijnatten, Thiemo J. A. (); Lobbes, Marc B. I. (); Smidt, Marjolein L. (); Lambin, Philippe (); Mehrkanoon, Siamak ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154351173,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1071,pub.1154688242,10.1109/access.2023.3238058,,,GMCNet: A Generative Multi-Resolution Framework for Cardiac Registration,"Deformable image registration plays a crucial role in estimating cardiac deformation from a sequence of images. However, existing registration methods primarily process images as pairs instead of processing all images in a sequence together. This study proposes a novel end-to-end learning-free generative multi-resolution convolutional neural network (GMCNet) with the primary focus of registering images in a sequence. Even though learning-based methods have yielded high performance for image registration, their performance depends on their ability to learn information from a large number of samples which are difficult to obtain and might bias the framework to the specific domain of data. The proposed learning-free method eliminates the need for a dedicated training set while exploiting the capabilities of neural networks to achieve accurate deformation fields. Due to its capability of parameter sharing through the architecture, the GMCNet can be used as a groupwise registration as well as pairwise registration. The proposed method was evaluated on three different clinical cardiac magnetic resonance imaging datasets and compared quantitatively against nine other state-of-the-art learning and optimization-based algorithms. The proposed method outperformed other methods in all comparisons and yielded average Dice metric values ranging from 0.85 to 0.88 for the datasets. Different aspects of the GMCNet are also explored by assessing 1) the robustness; 2) performance on pairwise registration; 3) the influence of spatial transformation in a controlled environment; and 4) the impact of different multi-resolution structures. The results demonstrate that using temporal information to estimate the deformation fields leads to more accurate registration results and improved robustness under different noise levels. Moreover, the proposed method does not need images for training, and therefore, its prediction is not domain-specific and can be applied to any sequence of images.",(Nilanjan Ray and Kumaradevan Punithakumar are co-first authors.),,IEEE Access,,,2023-01-01,2023,2023-01-19,2023-01-01,11,,8185-8198,All OA, Gold,Article,"Sheikhjafari, Ameneh; Noga, Michelle; Ahmed, Ahmed; Ray, Nilanjan; Punithakumar, Kumaradevan","Sheikhjafari, Ameneh (Department of Computing Science, University of Alberta, Edmonton, AB, T6G 2G8, Canada; Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, AB, T6G 2G8, Canada); Noga, Michelle (Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, AB, T6G 2G8, Canada); Ahmed, Ahmed (Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, T6G 2G8, Canada); Ray, Nilanjan (Department of Computing Science, University of Alberta, Edmonton, AB, T6G 2G8, Canada); Punithakumar, Kumaradevan (Department of Computing Science, University of Alberta, Edmonton, AB, T6G 2G8, Canada; Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, AB, T6G 2G8, Canada)","Sheikhjafari, Ameneh (University of Alberta; University of Alberta)","Sheikhjafari, Ameneh (University of Alberta; University of Alberta); Noga, Michelle (University of Alberta); Ahmed, Ahmed (University of Alberta); Ray, Nilanjan (University of Alberta); Punithakumar, Kumaradevan (University of Alberta; University of Alberta)",0,0,,,https://ieeexplore.ieee.org/ielx7/6287639/10005208/10021322.pdf,https://app.dimensions.ai/details/publication/pub.1154688242,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
910,pub.1154912114,10.1016/b978-0-323-89831-7.00003-1,,,6 Patient-specific 3D bioprinting for in situ tissue engineering and regenerative medicine,"3D printing is one of the fundamental technologies that significantly contributes to medicine personalization. Unlike the general medical approach, personalized medicine suggests more effective and patient-oriented treatments at different levels, which accounts for specific needs and characteristics of the patient. Furthermore, healthcare providers can significantly increase their efficiency by customizing treatment strategies, predicting treatment outcomes more precisely, and minimizing the risks of failures. Main medical applications that involve 3D bioprinting technology can be arranged into three categories: (1) 3D bioprinting of vascularized organs and tissues in vitro, (2) in situ bioprinting and, (3) 3D in vitro tissue models. Various constructs have already been successfully produced using 3D technology, including printing of cells, blood vessels, cartilages, bones, bandages, corneas, liver tissues for drug tests, and customized drugs. The recent advances in 3D human tissues and organs modeling allowed numerous studies on infection’s mechanisms and effects of different therapeutic agents and drugs on 3D-printed human tissues. For the past decade, several successful cases of fabrication functional organs using 3D printing technologies have been reported. In parallel with in vitro 3D bioprinting technology, in situ 3D printing directly onto the defect site is developing rapidly. Recent studies have demonstrated that in situ 3D printing provides a powerful technological solution, which is expected to become a routine in various clinical applications and personalized medical treatments.",,,,3D Printing in Medicine,,2023,2023,,2023,,,149-178,All OA, Gold,Chapter,"Akilbekova, Dana; Turlybekuly, Amanzhol","Akilbekova, Dana (School of Engineering and Digital Science, Chemical and Materials Engineering Department, Nazarbayev University, Nur-Sultan, Kazakhstan); Turlybekuly, Amanzhol (School of Engineering and Digital Science, Chemical and Materials Engineering Department, Nazarbayev University, Nur-Sultan, Kazakhstan)",,"Akilbekova, Dana (Nazarbayev University); Turlybekuly, Amanzhol (Nazarbayev University)",0,0,,,https://doi.org/10.1016/b978-0-323-89831-7.00003-1,https://app.dimensions.ai/details/publication/pub.1154912114,32 Biomedical and Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering,3 Good Health and Well Being,,,,,,,,
755,pub.1154911399,10.1016/b978-0-12-821983-6.00008-4,,,Chapter 8 Left ventricle segmentation and quantification using deep learning,"Cardiac MRI is a widely used noninvasive tool that can provide us with an evaluation of cardiac anatomy and function. It can also be used for heart diagnosis. Heart diagnosis through the estimation of physiological heart parameters requires careful segmentation of the left ventricle (LV) from the images of cardiac MRI. Therefore we aim at building a new deep learning method for the automated delineation and quantification of the LV from cine cardiac MRI. Our goal is to reach lower errors for the calculated heart parameters than the previous works by introducing a new deep learning cardiac segmentation method. Our pipeline starts with an accurate LV localization by finding LV cavity center point using a fully convolutional neural network (FCN) model called FCN1. Then, from all heart sections, we extract a region of interest (ROI) that encompasses the LV. A segmentation for the LV cavity and myocardium is performed from the extracted ROIs using FCN called FCN2. The FCN2 model is associated with multiple bottleneck layers and uses less memory footprint than traditional models such as U-net. Furthermore, we introduced a novel loss function called radial loss that works on minimizing the distance between the ground truth LV contours and the predicted contours. After myocardial segmentation, we estimate the functional and mass parameters of the LV. We used the Automated Cardiac Diagnosis Challenge (ACDC-2017) dataset to validate our pipeline, which provided better segmentation, accurate calculation of heart parameters, and produced fewer errors compared to other approaches applied on the same dataset. Additionally, our segmentation approach showed that it can generalize well across different datasets by validating its performance on a locally collected cardiac dataset. To sum up, we propose a novel deep learning framework that we can translate it into a clinical tool for cardiac diagnosis.",,,,Cardiovascular and Coronary Artery Imaging,,2023,2023,,2023,,,113-147,Closed,Chapter,"Abdeltawab, Hisham; Khalifa, Fahmi; Taher, Fatma; Ghazal, Mohammed; Mahmoud, Ali; El-Baz, Ayman S.","Abdeltawab, Hisham (Bioengineering Department, University of Louisville, Louisville, KY, United States); Khalifa, Fahmi (Bioengineering Department, University of Louisville, Louisville, KY, United States); Taher, Fatma (College of Technological Innovation, Zayed University, Dubai, United Arab Emirates); Ghazal, Mohammed (Electrical, Computer and Biomedical Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates); Mahmoud, Ali (Bioimaging Lab, Bioengineering Department, University of Louisville, Louisville, KY, United States); El-Baz, Ayman S. (University of Louisville, Louisville, KY, United States; University of Louisville at Alamein International University (UofL-AIU), New Alamein City, Egypt)",,"Abdeltawab, Hisham (University of Louisville); Khalifa, Fahmi (University of Louisville); Taher, Fatma (Zayed University); Ghazal, Mohammed (Abu Dhabi University); Mahmoud, Ali (University of Louisville); El-Baz, Ayman S. (University of Louisville)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154911399,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
151,pub.1154832587,10.1007/978-3-031-15542-0,,,Role of Data-Intensive Distributed Computing Systems in Designing Data Solutions,"This book discusses the application of data systems and data-driven infrastructure in existing industrial systems in order to optimize workflow, utilize hidden potential, and make existing systems free from vulnerabilities. The book discusses application of data in the health sector, public transportation, the financial institutions, and in battling natural disasters, among others. Topics include real-time applications in the current big data perspective; improving security in IoT devices; data backup techniques for systems; artificial intelligence-based outlier prediction; machine learning in OpenFlow Network; and application of deep learning in blockchain enabled applications. This book is intended for a variety of readers from professional industries, organizations, and students.",,,EAI/Springer Innovations in Communication and Computing,,,2023,2023,,2023,,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1154832587,46 Information and Computing Sciences, 4606 Distributed Computing and Systems Software,,,,,,,,,,,
69,pub.1155154853,10.1007/978-981-19-6634-7,,,"Proceedings of International Conference on Data Science and Applications, ICDSA 2022, Volume 2","This book gathers outstanding papers presented at the International Conference on Data Science and Applications (ICDSA 2022), organized by Soft Computing Research Society (SCRS) and Jadavpur University, Kolkata, India, from 26 to 27 March 2022. It covers theoretical and empirical developments in various areas of big data analytics, big data technologies, decision tree learning, wireless communication, wireless sensor networking, bioinformatics and systems, artificial neural networks, deep learning, genetic algorithms, data mining, fuzzy logic, optimization algorithms, image processing, computational intelligence in civil engineering, and creative computing.",,,Lecture Notes in Networks and Systems,,,2023,2023,,2023,552,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1155154853,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science,,,,,,,,,,
28,pub.1155712689,10.1007/978-3-030-98661-2,,,"Handbook of Mathematical Models and Algorithms in Computer Vision and Imaging, Mathematical Imaging and Vision","This handbook gathers together the state of the art on mathematical models and algorithms for imaging and vision. Its emphasis lies on rigorous mathematical methods, which represent the optimal solutions to a class of imaging and vision problems, and on effective algorithms, which are necessary for the methods to be translated to practical use in various applications. Viewing discrete images as data sampled from functional surfaces enables the use of advanced tools from calculus, functions and calculus of variations, and nonlinear optimization, and provides the basis of high-resolution imaging through geometry and variational models. Besides, optimization naturally connects traditional model-driven approaches to the emerging data-driven approaches of machine and deep learning. No other framework can provide comparable accuracy and precision to imaging and vision. Written by leading researchers in imaging and vision, the chapters in this handbook all start with gentle introductions, which make this work accessible to graduate students. For newcomers to the field, the book provides a comprehensive and fast-track introduction to the content, to save time and get on with tackling new and emerging challenges. For researchers, exposure to the state of the art of research works leads to an overall view of the entire field so as to guide new research directions and avoid pitfalls in moving the field forward and looking into the next decades of imaging and information services. This work can greatly benefit graduate students, researchers, and practitioners in imaging and vision; applied mathematicians; medical imagers; engineers; and computer scientists.",,,,,,2023,2023,,2023,,,,All OA, Bronze,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm:978-3-030-98661-2/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1155712689,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
957,pub.1154064201,10.1109/tbme.2022.3232730,,,Estimating Uncertainty in Neural Networks for Cardiac MRI Segmentation: A Benchmark Study,"Objective: Convolutional neural networks (CNNs) have demonstrated promise in automated cardiac magnetic resonance image segmentation. However, when using CNNs in a large real-world dataset, it is important to quantify segmentation uncertainty and identify segmentations which could be problematic. In this work, we performed a systematic study of Bayesian and non-Bayesian methods for estimating uncertainty in segmentation neural networks. Methods: We evaluated Bayes by Backprop, Monte Carlo Dropout, Deep Ensembles, and Stochastic Segmentation Networks in terms of segmentation accuracy, probability calibration, uncertainty on out-of-distribution images, and segmentation quality control. Results: We observed that Deep Ensembles outperformed the other methods except for images with heavy noise and blurring distortions. We showed that Bayes by Backprop is more robust to noise distortions while Stochastic Segmentation Networks are more resistant to blurring distortions. For segmentation quality control, we showed that segmentation uncertainty is correlated with segmentation accuracy for all the methods. With the incorporation of uncertainty estimates, we were able to reduce the percentage of poor segmentation to 5% by flagging 31–48% of the most uncertain segmentations for manual review, substantially lower than random review without using neural network uncertainty (reviewing 75–78% of all images). Conclusion: This work provides a comprehensive evaluation of uncertainty estimation methods and showed that Deep Ensembles outperformed other methods in most cases. Significance: Neural network uncertainty measures can help identify potentially inaccurate segmentations and alert users for manual review.",,,IEEE Transactions on Biomedical Engineering,,,2022-12-30,2022,2022-12-30,,PP,99,1-12,All OA, Green,Article,"Ng, Matthew; Guo, Fumin; Biswas, Labonny; Petersen, Steffen E.; Piechnik, Stefan K.; Neubauer, Stefan; Wright, Graham","Ng, Matthew (Physical Sciences Platform at Sunnybrook Research Institute and Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada); Guo, Fumin (Physical Sciences Platform at Sunnybrook Research Institute and Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada); Biswas, Labonny (Physical Sciences Platform at Sunnybrook Research Institute and Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada); Petersen, Steffen E. (William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, U.K.); Piechnik, Stefan K. (Division of Cardiovascular Medicine, Oxford NIHR Biomedical Research Centre, Radcliffe Department of Medicine, University of Oxford, Oxford, U.K.); Neubauer, Stefan (Division of Cardiovascular Medicine, Oxford NIHR Biomedical Research Centre, Radcliffe Department of Medicine, University of Oxford, Oxford, U.K.); Wright, Graham (Physical Sciences Platform at Sunnybrook Research Institute and Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada)",,"Ng, Matthew (University of Toronto); Guo, Fumin (University of Toronto); Biswas, Labonny (University of Toronto); Petersen, Steffen E. (Queen Mary University of London); Piechnik, Stefan K. (NIHR Oxford Musculoskeletal Biomedical Research Centre; University of Oxford); Neubauer, Stefan (NIHR Oxford Musculoskeletal Biomedical Research Centre; University of Oxford); Wright, Graham (University of Toronto)",0,0,,,http://arxiv.org/pdf/2012.15772,https://app.dimensions.ai/details/publication/pub.1154064201,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
6279,pub.1154058718,10.1007/s11517-022-02723-9,36580181,,Dual encoder network with transformer-CNN for multi-organ segmentation,"Medical image segmentation is a critical step in many imaging applications. Automatic segmentation has gained extensive concern using a convolutional neural network (CNN). However, the traditional CNN-based methods fail to extract global and long-range contextual information due to local convolution operation. Transformer overcomes the limitation of CNN-based models. Inspired by the success of transformers in computer vision (CV), many researchers focus on designing the transformer-based U-shaped method in medical image segmentation. The transformer-based approach cannot effectively capture the fine-grained details. This paper proposes a dual encoder network with transformer-CNN for multi-organ segmentation. The new segmentation framework takes full advantage of CNN and transformer to enhance the segmentation accuracy. The Swin-transformer encoder extracts global information, and the CNN encoder captures local information. We introduce fusion modules to fuse convolutional features and the sequence of features from the transformer. Feature fusion is concatenated through the skip connection to smooth the decision boundary effectively. We extensively evaluate our method on the synapse multi-organ CT dataset and the automated cardiac diagnosis challenge (ACDC) dataset. The results demonstrate that the proposed method achieves Dice similarity coefficient (DSC) metrics of 80.68% and 91.12% on the synapse multi-organ CT and ACDC datasets, respectively. We perform the ablation studies on the ACDC dataset, demonstrating the effectiveness of critical components of our method. Our results match the ground-truth boundary more consistently than the existing models. Our approach gains more accurate results on challenging 2D images for multi-organ segmentation. Compared with the state-of-the-art methods, our proposed method achieves superior performance in multi-organ segmentation tasks.Graphical AbstractThe key process in medical image segmentation.",,"This study was funded by the National Natural Science Foundation of China (grant numbers 61504055 and 61701218), the Natural Science Foundation of Hunan Province of China (grant numbers 2020JJ4514 and 2020JJ4519), and the Postgraduate Research Innovation Project of Hunan Province of China (grant numbers CX20200934). This study was also funded by Hunan provincial base for scientific and technological innovation cooperation.",Medical & Biological Engineering & Computing,,"Benchmarking; Electric Power Supplies; Heart; Neural Networks, Computer; Synapses; Image Processing, Computer-Assisted",2022-12-29,2022,2022-12-29,2023-03,61,3,661-671,Closed,Article,"Hong, Zhifang; Chen, Mingzhi; Hu, Weijie; Yan, Shiyu; Qu, Aiping; Chen, Lingna; Chen, Junxi","Hong, Zhifang (Computer School, University of South China, 421001, Hengyang, China); Chen, Mingzhi (College of Mechanical and Vehicle Engineering, Hunan University, 410082, Hengyang, China); Hu, Weijie (School of Economics and Management, Beijing University of Chemical Technology, 100029, Beijing, China); Yan, Shiyu (Computer School, University of South China, 421001, Hengyang, China); Qu, Aiping (Computer School, University of South China, 421001, Hengyang, China); Chen, Lingna (Computer School, University of South China, 421001, Hengyang, China); Chen, Junxi (Affiliated Nanhua Hospital, University of South China, 421001, Hengyang, China)","Chen, Lingna (University of South China)","Hong, Zhifang (University of South China); Chen, Mingzhi (Hunan University); Hu, Weijie (Beijing University of Chemical Technology); Yan, Shiyu (University of South China); Qu, Aiping (University of South China); Chen, Lingna (University of South China); Chen, Junxi (University of South China)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154058718,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1133,pub.1154053900,10.48550/arxiv.2212.13715,,,MyI-Net: Fully Automatic Detection and Quantification of Myocardial  Infarction from Cardiovascular MRI Images,"A ""heart attack"" or myocardial infarction (MI), occurs when an artery
supplying blood to the heart is abruptly occluded. The ""gold standard"" method
for imaging MI is Cardiovascular Magnetic Resonance Imaging (MRI), with
intravenously administered gadolinium-based contrast (late gadolinium
enhancement). However, no ""gold standard"" fully automated method for the
quantification of MI exists. In this work, we propose an end-to-end fully
automatic system (MyI-Net) for the detection and quantification of MI in MRI
images. This has the potential to reduce the uncertainty due to the technical
variability across labs and inherent problems of the data and labels. Our
system consists of four processing stages designed to maintain the flow of
information across scales. First, features from raw MRI images are generated
using feature extractors built on ResNet and MoblieNet architectures. This is
followed by the Atrous Spatial Pyramid Pooling (ASPP) to produce spatial
information at different scales to preserve more image context. High-level
features from ASPP and initial low-level features are concatenated at the third
stage and then passed to the fourth stage where spatial information is
recovered via up-sampling to produce final image segmentation output into: i)
background, ii) heart muscle, iii) blood and iv) scar areas. New models were
compared with state-of-art models and manual quantification. Our models showed
favorable performance in global segmentation and scar tissue detection relative
to state-of-the-art work, including a four-fold better performance in matching
scar pixels to contours produced by clinicians.",,,arXiv,,,2022-12-28,2022,,,,,,All OA, Green,Preprint,"Wang, Shuihua; Abdelaty, Ahmed M. S. E. K; Parke, Kelly; Arnold, J Ranjit; McCann, Gerry P; Tyukin, Ivan Y","Wang, Shuihua (); Abdelaty, Ahmed M. S. E. K (); Parke, Kelly (); Arnold, J Ranjit (); McCann, Gerry P (); Tyukin, Ivan Y ()",,"Wang, Shuihua (); Abdelaty, Ahmed M. S. E. K (); Parke, Kelly (); Arnold, J Ranjit (); McCann, Gerry P (); Tyukin, Ivan Y ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154053900,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
4121,pub.1153962393,10.1002/mp.16182,36565150,,Deep supervised dictionary learning by algorithm unrolling—Application to fast 2D dynamic MR image reconstruction,"BACKGROUND: Unrolled neural networks (NNs) have been extensively applied to different image reconstruction problems across all imaging modalities. A key component of the latter is that they allow for physics-informed learning of the regularization method, which is parametrized by the NN. However, due to the lack of understanding of deep NNs from a theoretical point of view, unrolled NNs are still black-boxes when the regularizers are given by deep NNs, for example, U-Nets.
PURPOSE: Dictionarylearning (DL) is a well-established regularization method, which is based on learning a transform to sparsely approximate the signals of interest. Typically, DL-based image reconstruction either employs a dictionary, which was pretrained on a set of patches which were extracted from ground-truth images or a dictionary which is jointly trained during the reconstruction. However, in both cases, the used DL-algorithms are not designed to take into account the reconstruction problem or the underlying physical model, which describes the imaging process. In this work, we propose a DL-algorithm based on unrolled NNs to overcome these limitations.
METHODS: We construct an unrolled NN, which corresponds to an unrolled DL-based reconstruction algorithm and train the unrolled NN to optimize its weights, that is, the atoms of the dictionary, by back-propagation in a supervised manner. Further, we propose a new way to employ a 2D dictionary in the spatio-temporal domain. We tested and evaluated the method on an accelerated cardiac cine MR image reconstruction problem using 216/36/36 dynamic images for training, validation, and testing and compared it to two well-known state-of-the-art approaches for cardiac cine MRI based on deep iterative CNNs. Further, we analyze the obtained dictionaries in terms of dictionary-coherence and structure of the atoms. Last, we compare the reported methods in terms of stability by applying them to an entirely different dataset consisting of 49 different test images.
RESULTS: The investigated physics-informed DL-approach yields significantly more accurate reconstructions compared to the DL-method, which uses dictionaries obtained by decoupled pretraining, thereby providing an improvement of up to 4.90 dB in terms of PSNR and 5% in terms of SSIM. Further, the proposed spatio-temporal 2D dictionary outperforms the 1D and 3D dictionaries by preventing smoothing of image details while still accurately removing undersampling artifacts and noise resulting in an increase of up to 1.10 dB in terms of PSNR and 4% in terms of SSIM. Although being surpassed by the CNNs on the first dataset, the proposed NNs-based DL method is more stable compared to the latter approach and yields comparable results on the second dataset. Last, it has the advantage of being entirely interpretable in each component.
CONCLUSIONS: The presented physics-informed NN can be used as training algorithm for a classical and interpretable data-driven regularization method based on a learned dictionary, which can then not only be linked to the considered data but also to the reconstruction method that the NN defines.",We thank Dr. Florian Burger and Gert Lindner for their support for using the high‐performance computing cluster of the Physikalisch‐Technische Bundesanstalt and the cloud‐services required for some of the experiments.,,Medical Physics,,,2022-12-24,2022,2023-01-17,2022-12-24,,,,All OA, Hybrid,Article,"Kofler, Andreas; Pali, Marie‐Christine; Schaeffter, Tobias; Kolbitsch, Christoph","Kofler, Andreas (Physikalisch‐Technische Bundesanstalt (PTB), Braunschweig and Berlin, Germany); Pali, Marie‐Christine (Department of Mathematics, University of Innsbruck, Innsbruck, Austria); Schaeffter, Tobias (Physikalisch‐Technische Bundesanstalt (PTB), Braunschweig and Berlin, Germany; Division of Imaging Sciences and Biomedical Engineering, King's College London, London, UK; Department of Medical Engineering, Technical University of Berlin, Berlin, Germany); Kolbitsch, Christoph (Physikalisch‐Technische Bundesanstalt (PTB), Braunschweig and Berlin, Germany; Division of Imaging Sciences and Biomedical Engineering, King's College London, London, UK)","Kofler, Andreas (Physikalisch-Technische Bundesanstalt)","Kofler, Andreas (Physikalisch-Technische Bundesanstalt); Pali, Marie‐Christine (Universität Innsbruck); Schaeffter, Tobias (Physikalisch-Technische Bundesanstalt; King's College London; Technical University of Berlin); Kolbitsch, Christoph (Physikalisch-Technische Bundesanstalt; King's College London)",0,0,,,https://doi.org/10.1002/mp.16182,https://app.dimensions.ai/details/publication/pub.1153962393,40 Engineering, 4006 Communications Engineering,,,,,,,,,,
1010,pub.1153979938,10.48550/arxiv.2212.12303,,,Introduction to Machine Learning for Physicians: A Survival Guide for  Data Deluge,"Many modern research fields increasingly rely on collecting and analysing
massive, often unstructured, and unwieldy datasets. Consequently, there is
growing interest in machine learning and artificial intelligence applications
that can harness this `data deluge'. This broad nontechnical overview provides
a gentle introduction to machine learning with a specific focus on medical and
biological applications. We explain the common types of machine learning
algorithms and typical tasks that can be solved, illustrating the basics with
concrete examples from healthcare. Lastly, we provide an outlook on open
challenges, limitations, and potential impacts of machine-learning-powered
medicine.",,,arXiv,,,2022-12-23,2022,,,,,,All OA, Green,Preprint,"Marcinkevičs, Ričards; Ozkan, Ece; Vogt, Julia E.","Marcinkevičs, Ričards (); Ozkan, Ece (); Vogt, Julia E. ()",,"Marcinkevičs, Ričards (); Ozkan, Ece (); Vogt, Julia E. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153979938,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,
5037,pub.1153871659,10.1016/j.compbiomed.2022.106439,36566623,,Hybrid-scale contextual fusion network for medical image segmentation,"Medical image segmentation result is an essential reference for disease diagnosis. Recently, with the development and application of convolutional neural networks, medical image processing has significantly developed. However, most existing automatic segmentation tasks are still challenging due to various positions, sizes, and shapes, resulting in poor segmentation performance. In addition, most of the current methods use the encoder-decoder architecture for feature extraction, focusing on the acquisition of semantic information but ignoring the specific target and global context information. In this work, we propose a hybrid-scale contextual fusion network to capture the richer spatial and semantic information. First, a hybrid-scale embedding layer (HEL) is employed before the transformer. By mixing each embedding with multiple patches, the object information of different scales can be captured availably. Further, we present a standard transformer to model long-range dependencies in the first two skip connections. Meanwhile, the pooling transformer (PTrans) is employed to handle long input sequences in the following two skip connections. By leveraging the global average pooling operation and the corresponding transformer block, the spatial structure information of the target will be learned effectively. In the last, dual-branch channel attention module (DCA) is proposed to focus on crucial channel features and conduct multi-level features fusion simultaneously. By utilizing the fusion scheme, richer context and fine-grained features are captured and encoded efficiently. Extensive experiments on three public datasets demonstrate that the proposed method outperforms state-of-the-art methods.","This work was supported in part by the provincial natural science foundation of Anhui, China under Grant 1908085MF217 and in part by the Natural Science Research Project of Anhui Provincial Education Department, China under Grant KJ2019A0022918005.",,Computers in Biology and Medicine,,"Image Processing, Computer-Assisted; Learning; Neural Networks, Computer; Semantics",2022-12-22,2022,2022-12-22,2023-01,152,,106439,Closed,Article,"Bao, Hua; Zhu, Yuqing; Li, Qing","Bao, Hua (The Key Laboratory of Intelligent Computing and Signal Processing Ministry of Education, Hefei 230601, China; The School of Artificial Intelligence, Anhui University, Hefei 230601, China. Electronic address: baohua@ahu.edu.cn.); Zhu, Yuqing (The Key Laboratory of Intelligent Computing and Signal Processing Ministry of Education, Hefei 230601, China; The School of Electrical Engineering and Automation, Anhui University, Hefei 230601, China.); Li, Qing (The Key Laboratory of Intelligent Computing and Signal Processing Ministry of Education, Hefei 230601, China; The School of Electrical Engineering and Automation, Anhui University, Hefei 230601, China.)","Bao, Hua (; Anhui University)","Bao, Hua (Anhui University); Zhu, Yuqing (Anhui University); Li, Qing (Anhui University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1153871659,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1517,pub.1154644874,10.1109/rivf55975.2022.10013852,,,An Attention-PiDi-UNet and Focal Active Contour loss for Biomedical Image Segmentation,"Biomedical image analysis has been of paramount importance in modern computer vision recently. While up-to-date procedures have notched up success in medical imaging, there is still necessity to optimise the network and the loss function. Motivated by the PiDiNet architecture and the Active Contour methods, we propose a new Attention-PiDi-UNet architecture and a new Focal Active Contour loss. Our proposed method is evaluated on the three popular datasets: the MRI cardiac ACDC dataset (3-D images), the Skin Lesion ISIC 2018 dataset and the PH2 dataset (both in 2-D images). Several experiments have comfirmed our proposed method effectiveness with outstanding segmentation results.","This research is supported by the Hanoi University of Science and Technology (HUST). Minh-Nhat Trinh was funded by Vingroup JSC and supported by the Master, PhD Scholarship Programme of Vingroup Innovation Foundation (VINIF), Institute of Big Data, code VINIF.2021.ThS.33.","This research is supported by the Hanoi University of Science and Technology (HUST). Minh-Nhat Trinh was funded by Vingroup JSC and supported by the Master, PhD Scholarship Programme of Vingroup Innovation Foundation (VINIF), Institute of Big Data, code VINIF.2021.ThS.33.",,2022 RIVF International Conference on Computing and Communication Technologies (RIVF),,2022-12-22,2022,,2022-12-22,0,,635-640,Closed,Proceeding,"Trinh, Minh-Nhat; Nham, Do-Hai-Ninh; Pham, Van-Truong; Tran, Thi-Thao","Trinh, Minh-Nhat (Department of Automation Engineering, School of Electrical and Electronic Engineering Hanoi University of Science and Technology, Hanoi, Vietnam); Nham, Do-Hai-Ninh (School of Applied Mathematics and Informatics Hanoi University of Science and Technology, Hanoi, Vietnam); Pham, Van-Truong (Department of Automation Engineering, School of Electrical and Electronic Engineering Hanoi University of Science and Technology, Hanoi, Vietnam); Tran, Thi-Thao (Department of Automation Engineering, School of Electrical and Electronic Engineering Hanoi University of Science and Technology, Hanoi, Vietnam)",,"Trinh, Minh-Nhat (Hanoi University of Science and Technology); Nham, Do-Hai-Ninh (Hanoi University of Science and Technology); Pham, Van-Truong (Hanoi University of Science and Technology); Tran, Thi-Thao (Hanoi University of Science and Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154644874,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
5035,pub.1153834431,10.1016/j.xcrm.2022.100869,36543095,PMC9798021,"Advancing cardiovascular medicine with machine learning: Progress, potential, and perspective","Recent advances in machine learning (ML) have made it possible to analyze high-dimensional and complex data-such as free text, images, waveforms, videos, and sound-in an automated manner by successfully learning complex associations within these data. Cardiovascular medicine is particularly well poised to take advantage of these ML advances, due to the widespread digitization of medical data and the large number of diagnostic tests used to evaluate cardiovascular disease. Various ML approaches have successfully been applied to cardiovascular tests and diseases to automate interpretation, accurately perform measurements, and, in some cases, predict novel diagnoses from less invasive tests, effectively expanding the utility of more widely accessible diagnostic tests. Here, we present examples of some impactful advances in cardiovascular medicine using ML across a variety of modalities, with a focus on deep learning applications.","Author contributions
        J.P.B. and G.H.T. contributed to manuscript conceptualization, literature review, writing, and revising.
      
      
        Declaration of interests
        G.H.T. has previously received research grants from General Electric, Janssen Pharmaceuticals, and MyoKardia, Inc., a subsidiary of Bristol Myers Squibb; and received consulting fees from MyoKardia. G.H.T. received funding from NHLBI-K23HL135274.",,Cell Reports Medicine,,Humans, Machine Learning, Cardiovascular Diseases,2022-12-20,2022,2022-12-20,2022-12,3,12,100869,All OA, Gold,Article,"Barrios, Joshua P.; Tison, Geoffrey H.","Barrios, Joshua P. (Department of Medicine, Division of Cardiology, University of California, San Francisco, 555 Mission Bay Blvd South Box 3120, San Francisco, CA 94158, USA); Tison, Geoffrey H. (Department of Medicine, Division of Cardiology, University of California, San Francisco, 555 Mission Bay Blvd South Box 3120, San Francisco, CA 94158, USA; Bakar Computational Health Sciences Institute, University of California, San Francisco, 555 Mission Bay Blvd South Box 3120, San Francisco, CA 94158, USA)","Tison, Geoffrey H. (University of California, San Francisco; University of California, San Francisco)","Barrios, Joshua P. (University of California, San Francisco); Tison, Geoffrey H. (University of California, San Francisco; University of California, San Francisco)",0,0,,,http://www.cell.com/article/S2666379122004335/pdf,https://app.dimensions.ai/details/publication/pub.1153834431,32 Biomedical and Clinical Sciences,3 Good Health and Well Being,,,,,,,,
1550,pub.1153645056,10.1007/978-3-031-21014-3_34,,,"AMLP-Conv, a 3D Axial Long-range Interaction Multilayer Perceptron for CNNs","While Convolutional neural networks (CNN) have been the backbone of medical image analysis for years, their limited long-range interaction restrains their ability to encode long distance anatomical relationships. On the other hand, the current approach to capture long distance relationships, Transformers, is constrained by their quadratic scaling and their data inefficiency (arising from their lack of inductive biases). In this paper, we introduce the 3D Axial Multilayer Perceptron (AMLP), a long-range interaction module whose complexity scales linearly with spatial dimensions. This module is merged with CNNs to form the AMLP-Conv module, a long-range augmented convolution with strong inductive biases. Once combined with U-Net, our AMLP-Conv module leads to significant improvement, outperforming most transformer based U-Nets on the ACDC dataset, and reaching a new state-of-the-art result on the Multi-Modal Whole Heart Segmentation (MM-WHS) dataset with an almost 1.1% Dice score improvement over the previous scores on the Computed Tomography (CT) modality.",,,Lecture Notes in Computer Science,Machine Learning in Medical Imaging,,2022-12-16,2022,2022-12-16,2022,13583,,328-337,Closed,Chapter,"Bonheur, Savinien; Pienn, Michael; Olschewski, Horst; Bischof, Horst; Urschler, Martin","Bonheur, Savinien (Ludwig Boltzmann Institute for Lung Vascular Research, Graz, Austria; Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria); Pienn, Michael (Ludwig Boltzmann Institute for Lung Vascular Research, Graz, Austria); Olschewski, Horst (Ludwig Boltzmann Institute for Lung Vascular Research, Graz, Austria; Department of Internal Medicine, Medical University of Graz, Graz, Austria); Bischof, Horst (Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria); Urschler, Martin (School of Computer Science, University of Auckland, Auckland, New Zealand)","Bonheur, Savinien (Ludwig Boltzmann Institute for Lung Vascular Research; Graz University of Technology)","Bonheur, Savinien (Ludwig Boltzmann Institute for Lung Vascular Research; Graz University of Technology); Pienn, Michael (Ludwig Boltzmann Institute for Lung Vascular Research); Olschewski, Horst (Ludwig Boltzmann Institute for Lung Vascular Research; Medical University of Graz); Bischof, Horst (Graz University of Technology); Urschler, Martin (University of Auckland)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153645056,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
6046,pub.1153626048,10.3389/fcvm.2022.1009445,36588550,PMC9797833,Deep learning automates detection of wall motion abnormalities via measurement of longitudinal strain from ECG-gated CT images,"Introduction: 4D cardiac CT (cineCT) is increasingly used to evaluate cardiac dynamics. While echocardiography and CMR have demonstrated the utility of longitudinal strain (LS) measures, measuring LS from cineCT currently requires reformatting the 4D dataset into long-axis imaging planes and delineating the endocardial boundary across time. In this work, we demonstrate the ability of a recently published deep learning framework to automatically and accurately measure LS for detection of wall motion abnormalities (WMA).
Methods: One hundred clinical cineCT studies were evaluated by three experienced cardiac CT readers to identify whether each AHA segment had a WMA. Fifty cases were used for method development and an independent group of 50 were used for testing. A previously developed convolutional neural network was used to automatically segment the LV bloodpool and to define the 2, 3, and 4 CH long-axis imaging planes. LS was measured as the perimeter of the bloodpool for each long-axis plane. Two smoothing approaches were developed to avoid artifacts due to papillary muscle insertion and texture of the endocardial surface. The impact of the smoothing was evaluated by comparison of LS estimates to LV ejection fraction and the fractional area change of the corresponding view.
Results: The automated, DL approach successfully analyzed 48/50 patients in the training cohort and 47/50 in the testing cohort. The optimal LS cutoff for identification of WMA was -21.8, -15.4, and -16.6% for the 2-, 3-, and 4-CH views in the training cohort. This led to correct labeling of 85, 85, and 83% of 2-, 3-, and 4-CH views, respectively, in the testing cohort. Per-study accuracy was 83% (84% sensitivity and 82% specificity). Smoothing significantly improved agreement between LS and fractional area change (R 2: 2 CH = 0.38 vs. 0.89 vs. 0.92).
Conclusion: Automated LV blood pool segmentation and long-axis plane delineation via deep learning enables automatic LS assessment. LS values accurately identify regional wall motion abnormalities and may be used to complement standard visual assessments.",,FC was supported by National Institutes of Health grant HL 143113.,Frontiers in Cardiovascular Medicine,,,2022-12-15,2022,2022-12-15,,9,,1009445,All OA, Gold,Article,"Li, Hui; Chen, Zhennong; Kahn, Andrew M.; Kligerman, Seth; Narayan, Hari K.; Contijoch, Francisco J.","Li, Hui (Department of Bioengineering, University of California, San Diego, La Jolla, CA, United States); Chen, Zhennong (Department of Bioengineering, University of California, San Diego, La Jolla, CA, United States); Kahn, Andrew M. (Department of Medicine, Division of Cardiovascular Medicine, University of California, San Diego, La Jolla, CA, United States); Kligerman, Seth (Department of Radiology, University of California, San Diego, La Jolla, CA, United States); Narayan, Hari K. (Department of Pediatrics, University of California, San Diego, La Jolla, CA, United States); Contijoch, Francisco J. (Department of Bioengineering, University of California, San Diego, La Jolla, CA, United States; Department of Radiology, University of California, San Diego, La Jolla, CA, United States)","Contijoch, Francisco J. (University of California, San Diego; University of California, San Diego)","Li, Hui (University of California, San Diego); Chen, Zhennong (University of California, San Diego); Kahn, Andrew M. (University of California, San Diego); Kligerman, Seth (University of California, San Diego); Narayan, Hari K. (University of California, San Diego); Contijoch, Francisco J. (University of California, San Diego; University of California, San Diego)",0,0,,,https://www.frontiersin.org/articles/10.3389/fcvm.2022.1009445/pdf,https://app.dimensions.ai/details/publication/pub.1153626048,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1519,pub.1153604076,10.48550/arxiv.2212.06278,,,Efficient Bayesian Uncertainty Estimation for nnU-Net,"The self-configuring nnU-Net has achieved leading performance in a large
range of medical image segmentation challenges. It is widely considered as the
model of choice and a strong baseline for medical image segmentation. However,
despite its extraordinary performance, nnU-Net does not supply a measure of
uncertainty to indicate its possible failure. This can be problematic for
large-scale image segmentation applications, where data are heterogeneous and
nnU-Net may fail without notice. In this work, we introduce a novel method to
estimate nnU-Net uncertainty for medical image segmentation. We propose a
highly effective scheme for posterior sampling of weight space for Bayesian
uncertainty estimation. Different from previous baseline methods such as Monte
Carlo Dropout and mean-field Bayesian Neural Networks, our proposed method does
not require a variational architecture and keeps the original nnU-Net
architecture intact, thereby preserving its excellent performance and ease of
use. Additionally, we boost the segmentation performance over the original
nnU-Net via marginalizing multi-modal posterior models. We applied our method
on the public ACDC and M&M datasets of cardiac MRI and demonstrated improved
uncertainty estimation over a range of baseline methods. The proposed method
further strengthens nnU-Net for medical image segmentation in terms of both
segmentation accuracy and quality control.",,,arXiv,,,2022-12-12,2022,,,,,,All OA, Green,Preprint,"Zhao, Yidong; Yang, Changchun; Schweidtmann, Artur; Tao, Qian","Zhao, Yidong (); Yang, Changchun (); Schweidtmann, Artur (); Tao, Qian ()",,"Zhao, Yidong (); Yang, Changchun (); Schweidtmann, Artur (); Tao, Qian ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153604076,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1583,pub.1154178699,10.1109/bibm55620.2022.9995653,,,Multi-Scale Prototype Constraints with Relation Aggregation for Semi-supervised Medical Image Segmentation,"Semi-supervised learning alleviates the problem of lack of labeled data, which has attracted wide attention in the field of medical image segmentation. In this paper, we propose a multi-scale prototype constrained architecture with relation aggregation for semi-supervised medical image segmentation. Concretely, we design the multi-scale prototype constraints such that the ground truth of labeled data can guide the segmentation of unlabeled data through the prototype. Furthermore, to better obtain the related prior knowledge from the annotation information, we designed the relation aggregation module, which can transmit relevant information between the labeled and unlabeled data. Comprehensive quantitative and qualitative evaluations show that our method is a general and efficient method for semi-supervised medical image segmentation.",,,,2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,2022-12-08,2022,,2022-12-08,0,,1517-1520,Closed,Proceeding,"Dong, Jiashun; Quan, Hongyan; Han, Jun","Dong, Jiashun (School of Computer Science and Technology, East China Normal University); Quan, Hongyan (School of Computer Science and Technology, East China Normal University); Han, Jun (Department of General Surgery, Zhongshan Hospital, Fudan University)","Dong, Jiashun (East China Normal University)","Dong, Jiashun (East China Normal University); Quan, Hongyan (East China Normal University); Han, Jun ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154178699,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1459,pub.1154178085,10.1109/bibm55620.2022.9994849,,,Deep Learning Based Parametrization of Diffeomorphic Image Registration for the Application of Cardiac Image Segmentation,"Cardiac segmentation from magnetic resonance imaging (MRI) is one of the essential tasks to analyze the anatomy and function of the heart for the assessment and diagnosis of cardiac diseases. However, manual annotation is difficult and time consuming. This study proposes a novel end-to-end supervised cardiac MRI segmentation framework based on a diffeomorphic deformable registration that can segment the left ventricle from 2D and 3D images or volumes. In order to represent the actual cardiac deformation, the methodology parameterizes the transformation using radial and rotational components, computed using a deep learning approach The method was evaluated over three different data sets and showed significant improvements compared to exacting learning and non-learning based methods in terms of the Dice score and Hausdorff distance metrics.",The authors wish to thank Alberta Innovates for the AICE Concepts funding that supported this research work.,The authors wish to thank Alberta Innovates for the AICE Concepts funding that supported this research work.,,2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,2022-12-08,2022,,2022-12-08,0,,1164-1169,Closed,Proceeding,"Sheikhjafari, Ameneh; Krishnaswamy, Deepa; Noga, Michelle; Ray, Nilanjan; Punithakumar, Kumaradevan","Sheikhjafari, Ameneh (Dept. of Computing Science Dept. of Radiology and Diagnostic Imaging, Edmonton, Canada); Krishnaswamy, Deepa (Dept. of Radiology and Diagnostic Imaging, Edmonton, Canada); Noga, Michelle (Dept. of Radiology and Diagnostic Imaging, Edmonton, Canada); Ray, Nilanjan (Dept. of Computing Science, Edmonton, Canada); Punithakumar, Kumaradevan (Dept. of Radiology and Diagnostic Imaging, Edmonton, Canada)","Sheikhjafari, Ameneh ","Sheikhjafari, Ameneh (); Krishnaswamy, Deepa (); Noga, Michelle (); Ray, Nilanjan (); Punithakumar, Kumaradevan ()",1,1,,,,https://app.dimensions.ai/details/publication/pub.1154178085,32 Biomedical and Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1348,pub.1154178579,10.1109/bibm55620.2022.9995501,,,Collaborative Transformer-CNN Learning for Semi-supervised Medical Image Segmentation,"Convolutional Neural Networks (CNNs) and Transformers have recently demonstrated promising performance in a multitude of supervised medical image segmentation tasks. However, the success of these methods heavily depends on massive annotated data for training, which is time-consuming and laborious to acquire, especially for pixel-wise annotation that requires medical expertise and clinical experience. To address this issue, we present a novel framework called Collaborative Transformer-CNN Learning (CTCL) for semi-supervised medical image segmentation. Specifically, Our CTCL combines cross teaching with hard pseudo labels (CTH) and mutual learning with soft pseudo labels (MLS) to simultaneously train the Transformer-CNN models, thus making full use of the unlabeled data for the supervision of the segmentation task while reducing the uncertainty and noises of pseudo labels. Furthermore, considering the large structural differences between the Transformer and CNN models, we utilize consistency regularization (CR) to make the predictions consistent and determined via minimizing classifier determinacy discrepancy. Extensive experiments on a popular medical image benchmark demonstrate that our method yields superior results compared with existing state-of-the-art semi-supervised learning methods.",This research is supported by the National Key R&amp,D Program (Grant No.2018AAA0102600).,This research is supported by the National Key R&D Program (Grant No.2018AAA0102600).,,2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,2022-12-08,2022,,2022-12-08,0,,1058-1065,Closed,Proceeding,"Li, Wei; Yang, Huihua","Li, Wei (School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China); Yang, Huihua (School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China)","Yang, Huihua (Beijing University of Posts and Telecommunications)","Li, Wei (Beijing University of Posts and Telecommunications); Yang, Huihua (Beijing University of Posts and Telecommunications)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154178579,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1134,pub.1153517978,10.48550/arxiv.2212.04497,,,UNETR++: Delving into Efficient and Accurate 3D Medical Image  Segmentation,"Owing to the success of transformer models, recent works study their
applicability in 3D medical segmentation tasks. Within the transformer models,
the self-attention mechanism is one of the main building blocks that strives to
capture long-range dependencies, compared to the local convolutional-based
design. However, the self-attention operation has quadratic complexity which
proves to be a computational bottleneck, especially in volumetric medical
imaging, where the inputs are 3D with numerous slices. In this paper, we
propose a 3D medical image segmentation approach, named UNETR++, that offers
both high-quality segmentation masks as well as efficiency in terms of
parameters and compute cost. The core of our design is the introduction of a
novel efficient paired attention (EPA) block that efficiently learns spatial
and channel-wise discriminative features using a pair of inter-dependent
branches based on spatial and channel attention. Our spatial attention
formulation is efficient having linear complexity with respect to the input
sequence length. To enable communication between spatial and channel-focused
branches, we share the weights of query and key mapping functions that provide
a complimentary benefit (paired attention), while also reducing the overall
network parameters. Our extensive evaluations on three benchmarks, Synapse,
BTCV and ACDC, reveal the effectiveness of the proposed contributions in terms
of both efficiency and accuracy. On Synapse dataset, our UNETR++ sets a new
state-of-the-art with a Dice Similarity Score of 87.2%, while being
significantly efficient with a reduction of over 71% in terms of both
parameters and FLOPs, compared to the best existing method in the literature.
Code: https://github.com/Amshaker/unetr_plus_plus.",,,arXiv,,,2022-12-08,2022,,,,,,All OA, Green,Preprint,"Shaker, Abdelrahman; Maaz, Muhammad; Rasheed, Hanoona; Khan, Salman; Yang, Ming-Hsuan; Khan, Fahad Shahbaz","Shaker, Abdelrahman (); Maaz, Muhammad (); Rasheed, Hanoona (); Khan, Salman (); Yang, Ming-Hsuan (); Khan, Fahad Shahbaz ()",,"Shaker, Abdelrahman (); Maaz, Muhammad (); Rasheed, Hanoona (); Khan, Salman (); Yang, Ming-Hsuan (); Khan, Fahad Shahbaz ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153517978,40 Engineering, 4008 Electrical Engineering, 46 Information and Computing Sciences,,,,,,,,,
909,pub.1153410146,10.1007/978-981-19-6649-1_7,,,Cardiac Digital Twin Modeling,"A cardiac digital twin is a virtual representation of an individual patient’s heart. The geometric representation of the personalized computational model can be obtained from imaging data of the patient’s specific cardiac anatomy. Based on measured clinical data, electrophysiological parameters of the model can be continuously adjusted and optimized to accurately capture the functional behavior of the patient’s heart in silico. Digital twins have proven valuable for a wide variety of cardiovascular applications including the prediction of optimal ablation targets for a successful termination of cardiac arrhythmias and predicting the risk of sudden cardiac death. Yet, several challenges like the automated and robust generation of personalized computer models with clinical data lie ahead and need to be addressed for a reliable application of digital twins in daily clinical practice.","The authors acknowledge funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska- Curie grant agreement No.860974 (PersonalizeAF), from the EMPIR programme co-financed by the Participating States and from the European Union’s Horizon 2020 research and innovation programme under grant MedalCare 18HLT07, and from the European High-Performance Computing Joint Undertaking EuroHPC (JU) under grant agreement No 955495 (MICROCARD). The JU receives support from the European Union’s Horizon 2020 research and innovation programme and France, Italy, Germany, Austria, Norway, Switzerland.",,Lecture Notes in Bioengineering,Innovative Treatment Strategies for Clinical Electrophysiology,,2022-12-07,2022,2022-12-07,2022,,,111-134,Closed,Chapter,"Loewe, Axel; Martínez Díaz, Patricia; Nagel, Claudia; Sánchez, Jorge","Loewe, Axel (Institute of Biomedical Engineering, Karlsruhe Institute of Technology (KIT), Kaiserstr. 12, 76131, Karlsruhe, Germany); Martínez Díaz, Patricia (Institute of Biomedical Engineering, Karlsruhe Institute of Technology (KIT), Kaiserstr. 12, 76131, Karlsruhe, Germany); Nagel, Claudia (Institute of Biomedical Engineering, Karlsruhe Institute of Technology (KIT), Kaiserstr. 12, 76131, Karlsruhe, Germany); Sánchez, Jorge (Institute of Biomedical Engineering, Karlsruhe Institute of Technology (KIT), Kaiserstr. 12, 76131, Karlsruhe, Germany)","Loewe, Axel (Karlsruhe Institute of Technology)","Loewe, Axel (Karlsruhe Institute of Technology); Martínez Díaz, Patricia (Karlsruhe Institute of Technology); Nagel, Claudia (Karlsruhe Institute of Technology); Sánchez, Jorge (Karlsruhe Institute of Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153410146,32 Biomedical and Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering,3 Good Health and Well Being,,,,,,,,,
5037,pub.1149638971,10.1109/tmi.2022.3193029,35862335,PMC9910788,Disentangled Representation Learning for OCTA Vessel Segmentation With Limited Training Data,"Optical coherence tomography angiography (OCTA) is an imaging modality that can be used for analyzing retinal vasculature. Quantitative assessment of en face OCTA images requires accurate segmentation of the capillaries. Using deep learning approaches for this task faces two major challenges. First, acquiring sufficient manual delineations for training can take hundreds of hours. Second, OCTA images suffer from numerous contrast-related artifacts that are currently inherent to the modality and vary dramatically across scanners. We propose to solve both problems by learning a disentanglement of an anatomy component and a local contrast component from paired OCTA scans. With the contrast removed from the anatomy component, a deep learning model that takes the anatomy component as input can learn to segment vessels with a limited portion of the training images being manually labeled. Our method demonstrates state-of-the-art performance for OCTA vessel segmentation.","This work was supported in part by the NIH/National Eye Institute (NEI) under Grant R01-EY032284, in part by the NIH/National Institute of Neurological Disorders and Stroke (NINDS) under Grant R01-NS082347, and in part by the Intramural Research Program of the NIH, National Institute on Aging. This work involved human subjects or animals in its research. Approval of all ethical and experimental procedures and protocols was granted by the relevant local Institutional Review Boards, and performed in line with the Declaration of Helsinki.","This work was supported in part by the NIH/National Eye Institute (NEI) under Grant R01-EY032284, in part by the NIH/National Institute of Neurological Disorders and Stroke (NINDS) under Grant R01-NS082347, and in part by the Intramural Research Program of the NIH, National Institute on Aging.",IEEE Transactions on Medical Imaging,,"Tomography, Optical Coherence; Retinal Vessels; Angiography; Capillaries; Artifacts",2022-12-02,2022,2022-12-02,2022-12,41,12,3686-3698,All OA, Hybrid,Article,"Liu, Yihao; Carass, Aaron; Zuo, Lianrui; He, Yufan; Han, Shuo; Gregori, Lorenzo; Murray, Sean; Mishra, Rohit; Lei, Jianqin; Calabresi, Peter A.; Saidha, Shiv; Prince, Jerry L.","Liu, Yihao (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA); Carass, Aaron (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA); Zuo, Lianrui (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA; Laboratory of Behavioral Neuroscience, National Institute on Aging, and the National Institute of Health, Baltimore, MD, 20892, USA); He, Yufan (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA); Han, Shuo (Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA); Gregori, Lorenzo (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA); Murray, Sean (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA); Mishra, Rohit (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA); Lei, Jianqin (Ophthalmology Department, First Affiliated Hospital, Xi’an Jiaotong University, Xi’an, 710061, China); Calabresi, Peter A. (Department of Neurology, Johns Hopkins Hospital, Baltimore, MD, 21287, USA); Saidha, Shiv (Department of Neurology, Johns Hopkins Hospital, Baltimore, MD, 21287, USA); Prince, Jerry L. (Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA)","Liu, Yihao (Johns Hopkins University)","Liu, Yihao (Johns Hopkins University); Carass, Aaron (Johns Hopkins University); Zuo, Lianrui (Johns Hopkins University; National Institute on Aging); He, Yufan (Johns Hopkins University); Han, Shuo (Johns Hopkins University); Gregori, Lorenzo (Johns Hopkins University); Murray, Sean (Johns Hopkins University); Mishra, Rohit (Johns Hopkins University); Lei, Jianqin (Xi'an Jiaotong University); Calabresi, Peter A. (Johns Hopkins Hospital); Saidha, Shiv (Johns Hopkins Hospital); Prince, Jerry L. (Johns Hopkins University)",3,3,,,https://ieeexplore.ieee.org/ielx7/42/9969446/09834971.pdf,https://app.dimensions.ai/details/publication/pub.1149638971,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1066,pub.1152050197,10.1016/j.knosys.2022.110033,,,DCNet: Diversity convolutional network for ventricle segmentation on short-axis cardiac magnetic resonance images,"To accurately and simultaneously segment myocardium, left and right ventricles at the end-diastolic (ED) and end-systolic (ES) phases from short-axis cardiac magnetic resonance (CMR) images with inherent variability in appearance, shape, and location of the region of interest (ROI), we propose a diversity convolutional network (DCNet) that aims to solve ventricle under- and over-segmentation problems. DCNet is composed of three stages: the integration of diversity features, recoding of diversity features, and decoding of integrated features. To enhance the representational capacity and enrich the feature space of a single convolution, we design a diversity convolution block during the first stage. During the second stage, we design a dual-path channel attention mechanism to simultaneously select average and maximum features. In addition, we use a soft Dice loss function to assist in the network’s training. We conducted experiments on the 2017 Automated Cardiac Diagnosis Challenge (ACDC 2017), 2019 Multi-Sequence Cardiac MR Segmentation Challenge (MS-CMRSeg 2019), and 2020 Myocardial Pathology Segmentation Challenge (MyoPS 2020) datasets. We submitted our test results on the ACDC dataset to an online test platform, the proposed DCNet achieved Dice scores of 95.80%, 91.77%, and 91.57% in the left ventricle, right ventricle, and myocardium segmentation tasks, respectively. Compared with four representative networks, the proposed DCNet achieves the best results on balanced steady state free precession (bSSFP) cine sequence and late gadolinium enhancement (LGE) CMR sequences on the MS-CMRSeg and MyoPS datasets. Therefore, the proposed method is promising for automatic ventricle segmentation in clinical applications. We uploaded the code to https://github.com/fly1995/DCNet.","This work was supported by the National Key Research and Development Program of China [2019YFE0110800], National Natural Science Foundation of China [61972060, 62027827], Natural Science Foundation of Chongqing [cstc2020jcyj-zdxmX0025, cstc2019cxcyljrc-td0270, cstc2019jcyj-cxttX0002], and Innovative Talents Program for Doctoral students of Chongqing University of Posts and Telecommunications, China [BYJS202110].",,Knowledge-Based Systems,,,2022-12,2022,,2022-12,258,,110033,Closed,Article,"Li, Feiyan; Li, Weisheng; Gao, Xinbo; Liu, Rui; Xiao, Bin","Li, Feiyan (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Li, Weisheng (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Gao, Xinbo (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Liu, Rui (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Xiao, Bin (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China)","Li, Weisheng (Chongqing University of Posts and Telecommunications)","Li, Feiyan (Chongqing University of Posts and Telecommunications); Li, Weisheng (Chongqing University of Posts and Telecommunications); Gao, Xinbo (Chongqing University of Posts and Telecommunications); Liu, Rui (Chongqing University of Posts and Telecommunications); Xiao, Bin (Chongqing University of Posts and Telecommunications)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152050197,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
5667,pub.1153154071,10.1186/s12968-022-00899-5,36437452,PMC9703740,Cardiovascular magnetic resonance images with susceptibility artifacts: artificial intelligence with spatial-attention for ventricular volumes and mass assessment,"BackgroundSegmentation of cardiovascular magnetic resonance (CMR) images is an essential step for evaluating dimensional and functional ventricular parameters as ejection fraction (EF) but may be limited by artifacts, which represent the major challenge to automatically derive clinical information. The aim of this study is to investigate the accuracy of a deep learning (DL) approach for automatic segmentation of cardiac structures from CMR images characterized by magnetic susceptibility artifact in patient with cardiac implanted electronic devices (CIED).MethodsIn this retrospective study, 230 patients (100 with CIED) who underwent clinically indicated CMR were used to developed and test a DL model. A novel convolutional neural network was proposed to extract the left ventricle (LV) and right (RV) ventricle endocardium and LV epicardium. In order to perform a successful segmentation, it is important the network learns to identify salient image regions even during local magnetic field inhomogeneities. The proposed network takes advantage from a spatial attention module to selectively process the most relevant information and focus on the structures of interest. To improve segmentation, especially for images with artifacts, multiple loss functions were minimized in unison. Segmentation results were assessed against manual tracings and commercial CMR analysis software cvi42(Circle Cardiovascular Imaging, Calgary, Alberta, Canada). An external dataset of 56 patients with CIED was used to assess model generalizability.ResultsIn the internal datasets, on image with artifacts, the median Dice coefficients for end-diastolic LV cavity, LV myocardium and RV cavity, were 0.93, 0.77 and 0.87 and 0.91, 0.82, and 0.83 in end-systole, respectively. The proposed method reached higher segmentation accuracy than commercial software, with performance comparable to expert inter-observer variability (bias ± 95%LoA): LVEF 1 ± 8% vs 3 ± 9%, RVEF − 2 ± 15% vs 3 ± 21%. In the external cohort, EF well correlated with manual tracing (intraclass correlation coefficient: LVEF 0.98, RVEF 0.93). The automatic approach was significant faster than manual segmentation in providing cardiac parameters (approximately 1.5 s vs 450 s).ConclusionsExperimental results show that the proposed method reached promising performance in cardiac segmentation from CMR images with susceptibility artifacts and alleviates time consuming expert physician contour segmentation.",Not applicable.,This research was supported by the Italian Ministry of Health-Ricerca Corrente to Centro Cardiologico Monzino IRCCS.,Journal of Cardiovascular Magnetic Resonance,,Humans, Artifacts, Artificial Intelligence, Retrospective Studies, Predictive Value of Tests, Magnetic Resonance Imaging, Attention,2022-11-28,2022,2022-11-28,,24,1,62,All OA, Gold,Article,"Penso, Marco; Babbaro, Mario; Moccia, Sara; Guglielmo, Marco; Carerj, Maria Ludovica; Giacari, Carlo Maria; Chiesa, Mattia; Maragna, Riccardo; Rabbat, Mark G.; Barison, Andrea; Martini, Nicola; Pepi, Mauro; Caiani, Enrico G.; Pontone, Gianluca","Penso, Marco (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy; Department of Electronics, Information and Biomedical Engineering, Politecnico di Milano, Milan, Italy); Babbaro, Mario (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy); Moccia, Sara (The BioRobotics Institute and Department of Excellence in Robotics and AI, Scuola Superiore Sant’Anna, Pisa, Italy); Guglielmo, Marco (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy); Carerj, Maria Ludovica (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy; Department of Biomedical Sciences and Morphological and Functional Imaging, “G. Martino” University Hospital Messina, Messina, Italy); Giacari, Carlo Maria (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy); Chiesa, Mattia (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy; Department of Electronics, Information and Biomedical Engineering, Politecnico di Milano, Milan, Italy); Maragna, Riccardo (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy); Rabbat, Mark G. (Loyola University of Chicago, Chicago, IL, USA; Edward Hines Jr. VA Hospital, Hines, IL, USA); Barison, Andrea (Fondazione Toscana Gabriele Monasterio, Pisa, Italy); Martini, Nicola (Fondazione Toscana Gabriele Monasterio, Pisa, Italy); Pepi, Mauro (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy); Caiani, Enrico G. (Department of Electronics, Information and Biomedical Engineering, Politecnico di Milano, Milan, Italy; Istituto di Elettronica e di Ingegneria dell’Informazione e delle Telecomunicazioni, Consiglio Nazionale delle Ricerche, Milan, Italy); Pontone, Gianluca (Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, Via C. Parea 4, 20138, Milan, Italy)","Penso, Marco (Centro Cardiologico Monzino; Politecnico di Milano)","Penso, Marco (Centro Cardiologico Monzino; Politecnico di Milano); Babbaro, Mario (Centro Cardiologico Monzino); Moccia, Sara (Sant'Anna School of Advanced Studies); Guglielmo, Marco (Centro Cardiologico Monzino); Carerj, Maria Ludovica (Centro Cardiologico Monzino; Azienda Ospedaliera Universitaria Policlinico ""G. Martino""); Giacari, Carlo Maria (Centro Cardiologico Monzino); Chiesa, Mattia (Centro Cardiologico Monzino; Politecnico di Milano); Maragna, Riccardo (Centro Cardiologico Monzino); Rabbat, Mark G. (Loyola University Chicago; Edward Hines, Jr. VA Hospital); Barison, Andrea (Fondazione Toscana Gabriele Monasterio); Martini, Nicola (Fondazione Toscana Gabriele Monasterio); Pepi, Mauro (Centro Cardiologico Monzino); Caiani, Enrico G. (Politecnico di Milano; National Research Council); Pontone, Gianluca (Centro Cardiologico Monzino)",0,0,,,https://jcmr-online.biomedcentral.com/counter/pdf/10.1186/s12968-022-00899-5,https://app.dimensions.ai/details/publication/pub.1153154071,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,
1583,pub.1155456875,10.1109/indicon56171.2022.10039741,,,Left Atrium Segmentation Using Deep Learning Model,"Atrium segmentation is a very important task for cardiologists, especially in the left atrium (LA). Since the chances of narrowing are common in that area where blood stops flowing and which causes a heart attack. To tackle this problem, Artificial Intelligence can play an important role in segmenting the blockage area. There are many models for segmenting the left atrium such as Convolutional Neural Network (CNN), bidirectional Long Short Term Memory (LSTM) etc. Hybridize method can be an efficient method for segmenting the left atrium The most common method used is to hybridize CNN and LSTM. By analyzing the above models, it was found that the dice score was not working well even after making the model hybridized. The dice score is considered in the range from 0.85 to 0.92 for segmenting the left atrium. In our work, a U-Net model has been developed for segmenting the left atrium and the model has been developed with a change in parameters. It was observed that this model achieved a dice score of 0.94, which was found comparatively more accurate than any other hybridized model.",,,,2022 IEEE 19th India Council International Conference (INDICON),,2022-11-26,2022,,2022-11-26,0,,1-5,Closed,Proceeding,"Aryan, Rishav; Kejriwal, Vaibhav; Patel, Vaishnavi; Aggarwal, Ansh; Khanna, Vibhum; Thomas, Shweta B; S, Sangeetha","Aryan, Rishav (Vellore Institute of Technology,Department of Electronics and Communication Engineering,Vellore,Tamil Nadu,India,632014); Kejriwal, Vaibhav (Vellore Institute of Technology,Department of Electronics and Communication Engineering,Vellore,Tamil Nadu,India,632014); Patel, Vaishnavi (Vellore Institute of Technology,Department of Electronics and Communication Engineering,Vellore,Tamil Nadu,India,632014); Aggarwal, Ansh (Vellore Institute of Technology,Department of Electronics and Communication Engineering,Vellore,Tamil Nadu,India,632014); Khanna, Vibhum (Vellore Institute of Technology,Department of Electronics and Communication Engineering,Vellore,Tamil Nadu,India,632014); Thomas, Shweta B (Vellore Institute of Technology,Department of Electronics and Communication Engineering,Vellore,Tamil Nadu,India,632014); S, Sangeetha (Vellore Institute of Technology,Department of Electronics and Communication Engineering,Vellore,Tamil Nadu,India,632014)","Aryan, Rishav (Vellore Institute of Technology University)","Aryan, Rishav (Vellore Institute of Technology University); Kejriwal, Vaibhav (Vellore Institute of Technology University); Patel, Vaishnavi (Vellore Institute of Technology University); Aggarwal, Ansh (Vellore Institute of Technology University); Khanna, Vibhum (Vellore Institute of Technology University); Thomas, Shweta B (Vellore Institute of Technology University); S, Sangeetha (Vellore Institute of Technology University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1155456875,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1515,pub.1154092919,10.1109/ciees55704.2022.9990762,,,Prediction of Cardiovascular Disease using Machine Learning Algorithms,"Nowadays, cardiovascular diseases are one of those diseases that cause the most deaths globally. According to the report of the WHO, approximately 1 crore 79 lakh people lost their lives due to cardiovascular disease in the year 2019. This death represents almost 32% of all deaths that occurred globally. And, of the 32% of deaths, 85% were caused solely by heart attacks and strokes. The best way to avoid these premature deaths is to detect cardiovascular disease as soon as possible. This survey explains how machine learning and deep learning can aid in the early detection of cardiovascular disease, allowing us to avoid many premature deaths. Our model achieved a maximum accuracy of 83.33% with a mean squared error of 0.1667%.",,,,"2022 International Conference on Communications, Information, Electronic and Energy Systems (CIEES)",,2022-11-26,2022,,2022-11-26,0,,1-6,Closed,Proceeding,"Ravi, Rohit; Madhavan, P.","Ravi, Rohit (Dept. of Computing Technologies, School of Computing SRMIST, Chennai, India); Madhavan, P. (Dept. of Computing Technologies, School of Computing SRMIST, Chennai, India)","Ravi, Rohit ","Ravi, Rohit (); Madhavan, P. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154092919,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,,
1618,pub.1153015277,10.1016/j.media.2022.102704,36473414,,Data synthesis and adversarial networks: A review and meta-analysis in cancer imaging,"Despite technological and medical advances, the detection, interpretation, and treatment of cancer based on imaging data continue to pose significant challenges. These include inter-observer variability, class imbalance, dataset shifts, inter- and intra-tumour heterogeneity, malignancy determination, and treatment effect uncertainty. Given the recent advancements in image synthesis, Generative Adversarial Networks (GANs), and adversarial training, we assess the potential of these technologies to address a number of key challenges of cancer imaging. We categorise these challenges into (a) data scarcity and imbalance, (b) data access and privacy, (c) data annotation and segmentation, (d) cancer detection and diagnosis, and (e) tumour profiling, treatment planning and monitoring. Based on our analysis of 164 publications that apply adversarial training techniques in the context of cancer imaging, we highlight multiple underexplored solutions with research potential. We further contribute the Synthesis Study Trustworthiness Test (SynTRUST), a meta-analysis framework for assessing the validation rigour of medical image synthesis studies. SynTRUST is based on 26 concrete measures of thoroughness, reproducibility, usefulness, scalability, and tenability. Based on SynTRUST, we analyse 16 of the most promising cancer imaging challenge solutions and observe a high validation rigour in general, but also several desirable improvements. With this work, we strive to bridge the gap between the needs of the clinical cancer imaging community and the current and prospective research on data synthesis and adversarial networks in the artificial intelligence community.",This project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 952103.,,Medical Image Analysis,,"Humans; Image Processing, Computer-Assisted; Artificial Intelligence; Reproducibility of Results; Prospective Studies; Neoplasms; Magnetic Resonance Imaging",2022-11-24,2022,2022-11-24,2023-02,84,,102704,All OA, Green,Article,"Osuala, Richard; Kushibar, Kaisar; Garrucho, Lidia; Linardos, Akis; Szafranowska, Zuzanna; Klein, Stefan; Glocker, Ben; Diaz, Oliver; Lekadir, Karim","Osuala, Richard (Artificial Intelligence in Medicine Lab (BCN-AIM), Facultat de Matemàtiques i Informàtica, Universitat de Barcelona, Spain. Electronic address: richard.osuala@ub.edu.); Kushibar, Kaisar (Artificial Intelligence in Medicine Lab (BCN-AIM), Facultat de Matemàtiques i Informàtica, Universitat de Barcelona, Spain.); Garrucho, Lidia (Artificial Intelligence in Medicine Lab (BCN-AIM), Facultat de Matemàtiques i Informàtica, Universitat de Barcelona, Spain.); Linardos, Akis (Artificial Intelligence in Medicine Lab (BCN-AIM), Facultat de Matemàtiques i Informàtica, Universitat de Barcelona, Spain.); Szafranowska, Zuzanna (Artificial Intelligence in Medicine Lab (BCN-AIM), Facultat de Matemàtiques i Informàtica, Universitat de Barcelona, Spain.); Klein, Stefan (Biomedical Imaging Group Rotterdam, Department of Radiology & Nuclear Medicine, Erasmus MC, Rotterdam, The Netherlands.); Glocker, Ben (Biomedical Image Analysis Group, Department of Computing, Imperial College London, UK.); Diaz, Oliver (Artificial Intelligence in Medicine Lab (BCN-AIM), Facultat de Matemàtiques i Informàtica, Universitat de Barcelona, Spain.); Lekadir, Karim (Artificial Intelligence in Medicine Lab (BCN-AIM), Facultat de Matemàtiques i Informàtica, Universitat de Barcelona, Spain.)","Osuala, Richard (University of Barcelona)","Osuala, Richard (University of Barcelona); Kushibar, Kaisar (University of Barcelona); Garrucho, Lidia (University of Barcelona); Linardos, Akis (University of Barcelona); Szafranowska, Zuzanna (University of Barcelona); Klein, Stefan (Erasmus MC); Glocker, Ben (Imperial College London); Diaz, Oliver (University of Barcelona); Lekadir, Karim (University of Barcelona)",2,2,,,https://pure.eur.nl/ws/files/77475022/1_s2.0_S1361841522003322_main.pdf,https://app.dimensions.ai/details/publication/pub.1153015277,32 Biomedical and Clinical Sciences, 3211 Oncology and Carcinogenesis,,,,,,,,,,
913,pub.1153158580,10.48550/arxiv.2211.13828,,,Joint segmentation and discontinuity-preserving deformable registration:  Application to cardiac cine-MR images,"Medical image registration is a challenging task involving the estimation of
spatial transformations to establish anatomical correspondence between pairs or
groups of images. Recently, deep learning-based image registration methods have
been widely explored, and demonstrated to enable fast and accurate image
registration in a variety of applications. However, most deep learning-based
registration methods assume that the deformation fields are smooth and
continuous everywhere in the image domain, which is not always true, especially
when registering images whose fields of view contain discontinuities at
tissue/organ boundaries. In such scenarios, enforcing smooth, globally
continuous deformation fields leads to incorrect/implausible registration
results. We propose a novel discontinuity-preserving image registration method
to tackle this challenge, which ensures globally discontinuous and locally
smooth deformation fields, leading to more accurate and realistic registration
results. The proposed method leverages the complementary nature of image
segmentation and registration and enables joint segmentation and pair-wise
registration of images. A co-attention block is proposed in the segmentation
component of the network to learn the structural correlations in the input
images, while a discontinuity-preserving registration strategy is employed in
the registration component of the network to ensure plausibility in the
estimated deformation fields at tissue/organ interfaces. We evaluate our method
on the task of intra-subject spatio-temporal image registration using
large-scale cinematic cardiac magnetic resonance image sequences, and
demonstrate that our method achieves significant improvements over the
state-of-the-art for medical image registration, and produces high-quality
segmentation masks for the regions of interest.",,,arXiv,,,2022-11-24,2022,,,,,,All OA, Green,Preprint,"Chen, Xiang; Xia, Yan; Ravikumar, Nishant; Frangi, Alejandro F","Chen, Xiang (); Xia, Yan (); Ravikumar, Nishant (); Frangi, Alejandro F ()",,"Chen, Xiang (); Xia, Yan (); Ravikumar, Nishant (); Frangi, Alejandro F ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153158580,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
4551,pub.1152946348,10.3389/fninf.2022.933230,36483313,PMC9724825,Review of Generative Adversarial Networks in mono- and cross-modal biomedical image registration,"Biomedical image registration refers to aligning corresponding anatomical structures among different images, which is critical to many tasks, such as brain atlas building, tumor growth monitoring, and image fusion-based medical diagnosis. However, high-throughput biomedical image registration remains challenging due to inherent variations in the intensity, texture, and anatomy resulting from different imaging modalities, different sample preparation methods, or different developmental stages of the imaged subject. Recently, Generative Adversarial Networks (GAN) have attracted increasing interest in both mono- and cross-modal biomedical image registrations due to their special ability to eliminate the modal variance and their adversarial training strategy. This paper provides a comprehensive survey of the GAN-based mono- and cross-modal biomedical image registration methods. According to the different implementation strategies, we organize the GAN-based mono- and cross-modal biomedical image registration methods into four categories: modality translation, symmetric learning, adversarial strategies, and joint training. The key concepts, the main contributions, and the advantages and disadvantages of the different strategies are summarized and discussed. Finally, we analyze the statistics of all the cited works from different points of view and reveal future trends for GAN-based biomedical image registration studies.",The authors acknowledge the high-performance computing platform of Anhui University for providing computing resources.,"This research was funded by the National Natural Science Foundation of China (61871411, 62271003, and 62201008), the Sci-Tech Innovation 2030 Agenda (2022ZD0205200 and 2022ZD0205204), the University Synergy Innovation Program of Anhui Province (GXXT-2021-001), and the Natural Science Foundation of the Education Department of Anhui Province (KJ2021A0017).",Frontiers in Neuroinformatics,,,2022-11-22,2022,2022-11-22,,16,,933230,All OA, Gold,Article,"Han, Tingting; Wu, Jun; Luo, Wenting; Wang, Huiming; Jin, Zhe; Qu, Lei","Han, Tingting (Ministry of Education Key Laboratory of Intelligent Computing and Signal Processing, Information Materials and Intelligent Sensing Laboratory of Anhui Province, Anhui University, Hefei, China); Wu, Jun (Ministry of Education Key Laboratory of Intelligent Computing and Signal Processing, Information Materials and Intelligent Sensing Laboratory of Anhui Province, Anhui University, Hefei, China); Luo, Wenting (Ministry of Education Key Laboratory of Intelligent Computing and Signal Processing, Information Materials and Intelligent Sensing Laboratory of Anhui Province, Anhui University, Hefei, China); Wang, Huiming (Ministry of Education Key Laboratory of Intelligent Computing and Signal Processing, Information Materials and Intelligent Sensing Laboratory of Anhui Province, Anhui University, Hefei, China); Jin, Zhe (School of Artificial Intelligence, Anhui University, Hefei, China); Qu, Lei (Ministry of Education Key Laboratory of Intelligent Computing and Signal Processing, Information Materials and Intelligent Sensing Laboratory of Anhui Province, Anhui University, Hefei, China; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Hefei, China; SEU-ALLEN Joint Center, Institute for Brain and Intelligence, Southeast University, Nanjing, China)","Qu, Lei (Anhui University; ; Southeast University)","Han, Tingting (Anhui University); Wu, Jun (Anhui University); Luo, Wenting (Anhui University); Wang, Huiming (Anhui University); Jin, Zhe (Anhui University); Qu, Lei (Anhui University; Southeast University)",0,0,,,https://www.frontiersin.org/articles/10.3389/fninf.2022.933230/pdf,https://app.dimensions.ai/details/publication/pub.1152946348,32 Biomedical and Clinical Sciences, 3209 Neurosciences, 46 Information and Computing Sciences, 4601 Applied Computing, 4611 Machine Learning,,,,,,,
1071,pub.1152866051,10.1002/9781119808404.ch11,,,Machine Learning Application for Modeling and Design Optimization of High Frequency Structures,"A brief review of the applications of machine learning to the electromagnetic modeling and design optimization of high‐frequency structures is presented. The structure of artificial neural networks (ANNs), their training, and testing phases are discussed. The applications of ANNs to the forward and inverse modeling of electromagnetic structures are presented. Machine learning is applied to accelerate electromagnetic modeling methods such as Method of Moments (MoM), Finite Difference Time‐Domain (FDTD), and variational methods. Finally, emerging applications of machine learning in unsupervised electromagnetic modeling and some future search directions are highlighted.",,,,Advances in Time‐Domain Computational Electromagnetic Methods,,2022-11-18,2022,2022-11-18,2022-11,,,423-451,Closed,Chapter,"Bakr, Mohamed H.; Ali, Shirook; Elsherbeni, Atef Z.","Bakr, Mohamed H. (); Ali, Shirook (); Elsherbeni, Atef Z. ()",,"Bakr, Mohamed H. (); Ali, Shirook (); Elsherbeni, Atef Z. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152866051,40 Engineering, 4006 Communications Engineering, 4008 Electrical Engineering,,,,,,,,,,
5350,pub.1152826447,10.1002/mp.16108,36395472,,Fully automated cardiac MRI segmentation using dilated residual network,"PURPOSE: Cardiac ventricle segmentation from cine magnetic resonance imaging (CMRI) is a recognized modality for the noninvasive assessment of cardiovascular pathologies. Deep learning based algorithms achieved state-of-the-art result performance from CMRI cardiac ventricle segmentation. However, most approaches received less attention at the bottom layer of UNet, where main features are lost due to pixel degradation. To increase performance, it is important to handle the bottleneck layer of UNet properly. Considering this problem, we enhanced the performance of main features at the bottom layer of network.
METHOD: We developed a fully automatic pipeline for segmenting the right ventricle (RV), myocardium (MYO), and left ventricle (LV) by incorporating short-axis CMRI sequence images. We propose a dilated residual network (DRN) to capture the features at full resolution in the bottleneck of UNet. Thus, it significantly increases spatial and temporal information and maintains the localization accuracy. A data-augmentation technique is employed to avoid overfitting and class imbalance problems. Finally, output from each expanding path is added pixel-wise to improve the training response.
RESULTS: We used and evaluated our proposed method on automatic cardiac diagnosis challenge (ACDC). The test set consists of 50 patient records. The overall dice similarity coefficient (DSC) we achieved for our model is 0.924 ± 0.03, 0.907 ± 0.01, and 0.949 ± 0.05 for RV, MYO, and LV, respectively. Similarly, we obtained hausdorff distance (HD) scores of 10.09 ± 0.01, 7.25 ± 0.05, and 6.86 ± 0.02 mm for RV, MYO, and LV, respectively. The results show superior performance and outperformed state-of-the-art methods in terms of accuracy and reached expert-level segmentation. Consequently, the overall DSC and HD result improved by 1.0% and 1.5%, respectively.
CONCLUSION: We designed a dilated residual UNet (DRN) for cardiac ventricle segmentation using short-axis CMRI. Our method has the advantage of restoring and capturing spatial and temporal information by expanding the receptive field without degrading the image main features in the bottleneck of UNet. Our method is highly accurate and quick, taking 0.28 s on average to process 2D MR images. Also, the network was designed to work on predictions of individual MR images to segment the ventricular region, for which our model outperforms many state-of-the-art methods.","This work was supported by the National Natural Science Foundation of China (U2013205, 62073309, 6210021302), and in part by the Chinese Academy of Sciences Youth Innovation Promotion Association Excellent Member Program (Y201968), Guangdong Basic and Applied Basic Research Foundation (2022B1515020042), and Shenzhen Science and Technology Program (JCYJ20220818101603008).",,Medical Physics,,,2022-11-17,2022,2022-12-07,2022-11-17,,,,Closed,Article,"Ahmad, Faizan; Hou, Wenguo; Xiong, Jing; Xia, Zeyang","Ahmad, Faizan (Soft Robotics Research Center, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; University of Chinese Academy of Sciences, Beijing, China); Hou, Wenguo (Soft Robotics Research Center, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China); Xiong, Jing (Medical Robotics and Minimally Invasive Surgical Devices, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences Shenzhen, China); Xia, Zeyang (Soft Robotics Research Center, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; CAS Key Laboratory of Human‐Machine Intelligence‐Synergy Systems, Shenzhen Institute of Advanced Technology, Shenzhen, China)","Xia, Zeyang (Shenzhen Institutes of Advanced Technology; Shenzhen Institutes of Advanced Technology)","Ahmad, Faizan (Shenzhen Institutes of Advanced Technology; University of Chinese Academy of Sciences); Hou, Wenguo (Shenzhen Institutes of Advanced Technology); Xiong, Jing (Shenzhen Institutes of Advanced Technology); Xia, Zeyang (Shenzhen Institutes of Advanced Technology; Shenzhen Institutes of Advanced Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152826447,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
3941,pub.1152823541,10.1016/j.media.2022.102688,36493702,,On the usability of synthetic data for improving the robustness of deep learning-based segmentation of cardiac magnetic resonance images,"Deep learning-based segmentation methods provide an effective and automated way for assessing the structure and function of the heart in cardiac magnetic resonance (CMR) images. However, despite their state-of-the-art performance on images acquired from the same source (same scanner or scanner vendor) as images used during training, their performance degrades significantly on images coming from different domains. A straightforward approach to tackle this issue consists of acquiring large quantities of multi-site and multi-vendor data, which is practically infeasible. Generative adversarial networks (GANs) for image synthesis present a promising solution for tackling data limitations in medical imaging and addressing the generalization capability of segmentation models. In this work, we explore the usability of synthesized short-axis CMR images generated using a segmentation-informed conditional GAN, to improve the robustness of heart cavity segmentation models in a variety of different settings. The GAN is trained on paired real images and corresponding segmentation maps belonging to both the heart and the surrounding tissue, reinforcing the synthesis of semantically-consistent and realistic images. First, we evaluate the segmentation performance of a model trained solely with synthetic data and show that it only slightly underperforms compared to the baseline trained with real data. By further combining real with synthetic data during training, we observe a substantial improvement in segmentation performance (up to 4% and 40% in terms of Dice score and Hausdorff distance) across multiple data-sets collected from various sites and scanner. This is additionally demonstrated across state-of-the-art 2D and 3D segmentation networks, whereby the obtained results demonstrate the potential of the proposed method in tackling the presence of the domain shift in medical data. Finally, we thoroughly analyze the quality of synthetic data and its ability to replace real MR images during training, as well as provide an insight into important aspects of utilizing synthetic images for segmentation.","This research is a part of the openGTN project, supported by the European Union in the Marie Curie Innovative Training Networks (ITN) fellowship program under project No. 764465.",,Medical Image Analysis,,"Humans; Deep Learning; Magnetic Resonance Imaging; Heart; Tomography, X-Ray Computed; Image Processing, Computer-Assisted",2022-11-17,2022,2022-11-17,2023-02,84,,102688,All OA, Green,Article,"Al Khalil, Yasmina; Amirrajab, Sina; Lorenz, Cristian; Weese, Jürgen; Pluim, Josien; Breeuwer, Marcel","Al Khalil, Yasmina (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands. Electronic address: y.al.khalil@tue.nl.); Amirrajab, Sina (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands. Electronic address: s.amirrajab@tue.nl.); Lorenz, Cristian (Philips Research Laboratories, Hamburg, Germany. Electronic address: cristian.lorenz@philips.com.); Weese, Jürgen (Philips Research Laboratories, Hamburg, Germany. Electronic address: juergen.weese@philips.com.); Pluim, Josien (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands. Electronic address: j.pluim@tue.nl.); Breeuwer, Marcel (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands; Philips Healthcare, MR R&D - Clinical Science, Best, The Netherlands. Electronic address: m.breeuwer@tue.nl.)","Al Khalil, Yasmina (Eindhoven University of Technology); Amirrajab, Sina (Eindhoven University of Technology)","Al Khalil, Yasmina (Eindhoven University of Technology); Amirrajab, Sina (Eindhoven University of Technology); Lorenz, Cristian (Philips (Germany)); Weese, Jürgen (Philips (Germany)); Pluim, Josien (Eindhoven University of Technology); Breeuwer, Marcel (Eindhoven University of Technology; Philips (Netherlands))",1,1,,,https://pure.tue.nl/ws/files/250234181/1_s2.0_S1361841522003164_main.pdf,https://app.dimensions.ai/details/publication/pub.1152823541,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
1255,pub.1152787010,10.1007/s11760-022-02388-9,,,DS-UNeXt: depthwise separable convolution network with large convolutional kernel for medical image segmentation,"Accurate automatic segmentation of medical images is required in computer-aided diagnosis systems in clinical medicine. Convolutional neural networks (CNNs) based on U-shaped structures are widely used in medical image segmentation tasks. However, due to the intrinsic locality of the convolution operation, it is difficult for CNN-based approaches to learn the global information and long-range semantic information interactions using Swin-Unet. However, we find that UNet and Swin-Unet have the worst segmentation performance on small masses. To remedy this problem, this paper presents an end-to-end depthwise separable U-shaped convolution network with a large convolution kernel (DS-UNeXt) for the medical image segmentation of computed tomography (CT) images and magnetic resonance images (MRIs). Our network has a larger receptive field to extract features, which is useful for boosting the performance of multiscale medical segmentations. In DS-UNeXt, parallel depthwise separable spatial pooling (PDSP) is proposed to aggregate the global information. PDSP consists of multiple parallel depthwise separable convolutions to enhance the high-level semantic features. The proposed DS-UNeXt achieves Dice indices of 80.65% and 90.88% on the synapse for the multiorgan segmentation dataset and the automatic cardiac diagnosis challenge (ACDC) dataset, respectively. Moreover, extensive experiments show that DS-UNeXt transcends several state-of-the-art segmentation networks.",,"This work was supported by the Natural Science Foundation of Chongqing, China (Grant No. cstc2021jcyj-msxmX0605), and Science and Technology Foundation of Chongqing Education Commission (Grant No. KJQN202001137).","Signal, Image and Video Processing",,,2022-11-16,2022,2022-11-16,,,,1-9,Closed,Article,"Huang, Tongyuan; Chen, Jiangxia; Jiang, Linfeng","Huang, Tongyuan (School of Artificial Intelligence, Chongqing University of Technology, 40400, Chongqing, China); Chen, Jiangxia (School of Artificial Intelligence, Chongqing University of Technology, 40400, Chongqing, China); Jiang, Linfeng (School of Artificial Intelligence, Chongqing University of Technology, 40400, Chongqing, China)","Huang, Tongyuan (Chongqing University of Technology)","Huang, Tongyuan (Chongqing University of Technology); Chen, Jiangxia (Chongqing University of Technology); Jiang, Linfeng (Chongqing University of Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152787010,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science,,,,,,,,,,
1687,pub.1154765162,10.1109/sibircon56155.2022.10016940,,,Computational anatomy atlas using multilayer perceptron with Lipschitz regularization,"A computational anatomy atlas is a set of internal organ geometries. It is based on data of real patients and complemented with virtual cases by using a some numerical approach. Atlases are in demand in computational physiology, especially in cardiological and neurophysiological applications. Usually, atlas generation uses explicit object representation, such as voxel models or surface meshes. In this paper, we propose a method of atlas generation using an implicit representation of 3D objects. Our approach has two key stages. The first stage converts voxel models of segmented organs to implicit form using the usual multilayer perceptron. This stage smooths the model and reduces memory consumption. The second stage uses a multilayer perceptron with Lipschitz regularization. This neural network provides a smooth transition between implicitly defined 3D geometries. Our work shows examples of models of the left and right human ventricles. All code and data for this work are open.",,"This work has been supported by the grants the Russian Science Foundation, RSF 22-21-00930.",,"2022 IEEE International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON)",,2022-11-13,2022,,2022-11-13,0,,680-683,All OA, Green,Proceeding,"Ushenin, Konstantin; Dordiuk, Vladislav; Dzhigil, Maksim","Ushenin, Konstantin (Institute of Immunology and Physiology, Ekaterinburg, Russia; Ural Federal University, Ekaterinburg, Russia); Dordiuk, Vladislav (Institute of Immunology and Physiology, Ekaterinburg, Russia; Ural Federal University, Ekaterinburg, Russia); Dzhigil, Maksim (Institute of Immunology and Physiology, Ekaterinburg, Russia)","Ushenin, Konstantin (Institute of Immunology and Physiology; Ural Federal University)","Ushenin, Konstantin (Institute of Immunology and Physiology; Ural Federal University); Dordiuk, Vladislav (Institute of Immunology and Physiology; Ural Federal University); Dzhigil, Maksim (Institute of Immunology and Physiology)",0,0,,,http://arxiv.org/pdf/2211.03122,https://app.dimensions.ai/details/publication/pub.1154765162,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1014,pub.1152637746,10.48550/arxiv.2211.04862,,,Domain-incremental Cardiac Image Segmentation with Style-oriented Replay  and Domain-sensitive Feature Whitening,"Contemporary methods have shown promising results on cardiac image
segmentation, but merely in static learning, i.e., optimizing the network once
for all, ignoring potential needs for model updating. In real-world scenarios,
new data continues to be gathered from multiple institutions over time and new
demands keep growing to pursue more satisfying performance. The desired model
should incrementally learn from each incoming dataset and progressively update
with improved functionality as time goes by. As the datasets sequentially
delivered from multiple sites are normally heterogenous with domain
discrepancy, each updated model should not catastrophically forget previously
learned domains while well generalizing to currently arrived domains or even
unseen domains. In medical scenarios, this is particularly challenging as
accessing or storing past data is commonly not allowed due to data privacy. To
this end, we propose a novel domain-incremental learning framework to recover
past domain inputs first and then regularly replay them during model
optimization. Particularly, we first present a style-oriented replay module to
enable structure-realistic and memory-efficient reproduction of past data, and
then incorporate the replayed past data to jointly optimize the model with
current data to alleviate catastrophic forgetting. During optimization, we
additionally perform domain-sensitive feature whitening to suppress model's
dependency on features that are sensitive to domain changes (e.g.,
domain-distinctive style features) to assist domain-invariant feature
exploration and gradually improve the generalization performance of the
network. We have extensively evaluated our approach with the M&Ms Dataset in
single-domain and compound-domain incremental learning settings with improved
performance over other comparison approaches.",,,arXiv,,,2022-11-09,2022,,,,,,All OA, Green,Preprint,"Li, Kang; Yu, Lequan; Heng, Pheng-Ann","Li, Kang (); Yu, Lequan (); Heng, Pheng-Ann ()",,"Li, Kang (); Yu, Lequan (); Heng, Pheng-Ann ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152637746,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
78,pub.1152861008,10.1002/9781119808404,,,Advances in Time-Domain Computational Electromagnetic Methods,,,,,,,2022-11-08,2022,2022-11-08,2022-11,,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1152861008,,,,,,,,,,,,,
5054,pub.1152547369,10.1016/j.media.2022.102670,36413905,,Segmentation with mixed supervision: Confidence maximization helps knowledge distillation,"Despite achieving promising results in a breadth of medical image segmentation tasks, deep neural networks (DNNs) require large training datasets with pixel-wise annotations. Obtaining these curated datasets is a cumbersome process which limits the applicability of DNNs in scenarios where annotated images are scarce. Mixed supervision is an appealing alternative for mitigating this obstacle. In this setting, only a small fraction of the data contains complete pixel-wise annotations and other images have a weaker form of supervision, e.g., only a handful of pixels are labeled. In this work, we propose a dual-branch architecture, where the upper branch (teacher) receives strong annotations, while the bottom one (student) is driven by limited supervision and guided by the upper branch. Combined with a standard cross-entropy loss over the labeled pixels, our novel formulation integrates two important terms: (i) a Shannon entropy loss defined over the less-supervised images, which encourages confident student predictions in the bottom branch; and (ii) a Kullback-Leibler (KL) divergence term, which transfers the knowledge (i.e., predictions) of the strongly supervised branch to the less-supervised branch and guides the entropy (student-confidence) term to avoid trivial solutions. We show that the synergy between the entropy and KL divergence yields substantial improvements in performance. We also discuss an interesting link between Shannon-entropy minimization and standard pseudo-mask generation, and argue that the former should be preferred over the latter for leveraging information from unlabeled pixels. We evaluate the effectiveness of the proposed formulation through a series of quantitative and qualitative experiments using two publicly available datasets. Results demonstrate that our method significantly outperforms other strategies for semantic segmentation within a mixed-supervision framework, as well as recent semi-supervised approaches. Moreover, in line with recent observations in classification, we show that the branch trained with reduced supervision and guided by the top branch largely outperforms the latter. Our code is publicly available: https://github.com/by-liu/ConfKD.","This work is supported by the National Science and Engineering Research Council of Canada (NSERC), via its Discovery Grant program. We also thank Calcul Quebec and Compute Canada .",,Medical Image Analysis,,"Humans; Entropy; Semantics; Neural Networks, Computer",2022-11-07,2022,2022-11-07,2023-01,83,,102670,All OA, Green,Article,"Liu, Bingyuan; Desrosiers, Christian; Ben Ayed, Ismail; Dolz, Jose","Liu, Bingyuan (ÉTS Montréal, Canada. Electronic address: bingyuan.Liu@etsmtl.ca.); Desrosiers, Christian (ÉTS Montréal, Canada.); Ben Ayed, Ismail (ÉTS Montréal, Canada; Centre de recherche du Centre hospitalier de l'Université de Montréal (CRCHUM), Canada.); Dolz, Jose (ÉTS Montréal, Canada; Centre de recherche du Centre hospitalier de l'Université de Montréal (CRCHUM), Canada. Electronic address: jose.dolz@etsmtl.ca.)","Liu, Bingyuan ; Dolz, Jose (; Centre Hospitalier de l’Université de Montréal)","Liu, Bingyuan (); Desrosiers, Christian (); Ben Ayed, Ismail (Centre Hospitalier de l’Université de Montréal); Dolz, Jose (Centre Hospitalier de l’Université de Montréal)",0,0,,,http://arxiv.org/pdf/2109.10902,https://app.dimensions.ai/details/publication/pub.1152547369,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
4551,pub.1130620848,10.1109/tpami.2020.3013679,32886606,PMC9721526,A Topological Loss Function for Deep-Learning Based Image Segmentation Using Persistent Homology,"We introduce a method for training neural networks to perform image or volume segmentation in which prior knowledge about the topology of the segmented object can be explicitly provided and then incorporated into the training process. By using the differentiable properties of persistent homology, a concept used in topological data analysis, we can specify the desired topology of segmented objects in terms of their Betti numbers and then drive the proposed segmentations to contain the specified topological features. Importantly this process does not require any ground-truth labels, just prior knowledge of the topology of the structure being segmented. We demonstrate our approach in four experiments: one on MNIST image denoising and digit recognition, one on left ventricular myocardium segmentation from magnetic resonance imaging data from the UK Biobank, one on the ACDC public challenge dataset and one on placenta segmentation from 3-D ultrasound. We find that embedding explicit prior knowledge in neural network segmentation tasks is most beneficial when the segmentation task is especially challenging and that it can be used in either a semi-supervised or post-processing context to extract a useful training gradient from images without pixelwise labels.","This work was supported by the EPSRC programme Grant ‘SmartHeart’ (EP/P001009/1), the Wellcome Trust IEH Award [102431], the Wellcome EPSRC Centre for Medical Engineering at School of Biomedical Engineering and Imaging Sciences, Kings College London (WT 203148/Z/16/Z) and by the National Institute for Health Research (NIHR) Biomedical Research Centre at Guys and St Thomas NHS Foundation Trust and Kings College London. This research has been conducted using the UK Biobank Resource under Application Numbers 17806 and 40119. The authors would like to thank NVIDIA for kindly donating the Quadro P6000 GPU used in this research. The code for running the MNIST experiment is available at https://github.com/JamesClough/topograd. The MNIST dataset is available at http://yann.lecun.com/exdb/mnist/. The UK Biobank dataset is available to approved projects at https://www.ukbiobank.ac.uk/. The ACDC dataset is available at https://acdc.creatis.insa-lyon.fr/. The authors are unable to release the placenta dataset due to lack of patient consent for data sharing.","This work was supported by the EPSRC programme Grant SmartHeart (EP/P001009/1), the Wellcome Trust IEH Award [102431], the Wellcome EPSRC Centre for Medical Engineering at School of Biomedical Engineering and Imaging Sciences, Kings College London (WT 203148/Z/16/Z) and by the National Institute for Health Research (NIHR) Biomedical Research Centre at Guys and St Thomas NHS Foundation Trust and Kings College London.",IEEE Transactions on Pattern Analysis and Machine Intelligence,,"Image Processing, Computer-Assisted; Deep Learning; Algorithms; Neural Networks, Computer; Magnetic Resonance Imaging",2022-11-07,2022,2022-11-07,2022-12,44,12,8766-8778,All OA, Hybrid,Article,"Clough, James R.; Byrne, Nicholas; Oksuz, Ilkay; Zimmer, Veronika A.; Schnabel, Julia A.; King, Andrew P.","Clough, James R. (School of Biomedical Engineering and Imaging Sciences, King's College London, WC2R 2LS, London, United Kingdom); Byrne, Nicholas (School of Biomedical Engineering and Imaging Sciences, King's College London, WC2R 2LS, London, United Kingdom); Oksuz, Ilkay (School of Biomedical Engineering and Imaging Sciences, King's College London, WC2R 2LS, London, United Kingdom; Computer Engineering Department, Istanbul Technical University, 34467, Sariyer/Istanbul, Turkey); Zimmer, Veronika A. (School of Biomedical Engineering and Imaging Sciences, King's College London, WC2R 2LS, London, United Kingdom); Schnabel, Julia A. (School of Biomedical Engineering and Imaging Sciences, King's College London, WC2R 2LS, London, United Kingdom); King, Andrew P. (School of Biomedical Engineering and Imaging Sciences, King's College London, WC2R 2LS, London, United Kingdom)","Clough, James R. (King's College London)","Clough, James R. (King's College London); Byrne, Nicholas (King's College London); Oksuz, Ilkay (King's College London; Istanbul Technical University); Zimmer, Veronika A. (King's College London); Schnabel, Julia A. (King's College London); King, Andrew P. (King's College London)",55,52,,,https://ieeexplore.ieee.org/ielx7/34/9940447/09186664.pdf,https://app.dimensions.ai/details/publication/pub.1130620848,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4530,pub.1152541456,10.1016/j.media.2022.102682,36403311,,Generative myocardial motion tracking via latent space exploration with biomechanics-informed prior,"Myocardial motion and deformation are rich descriptors that characterize cardiac function. Image registration, as the most commonly used technique for myocardial motion tracking, is an ill-posed inverse problem which often requires prior assumptions on the solution space. In contrast to most existing approaches which impose explicit generic regularization such as smoothness, in this work we propose a novel method that can implicitly learn an application-specific biomechanics-informed prior and embed it into a neural network-parameterized transformation model. Particularly, the proposed method leverages a variational autoencoder-based generative model to learn a manifold for biomechanically plausible deformations. The motion tracking then can be performed via traversing the learnt manifold to search for the optimal transformations while considering the sequence information. The proposed method is validated on three public cardiac cine MRI datasets with comprehensive evaluations. The results demonstrate that the proposed method can outperform other approaches, yielding higher motion tracking accuracy with reasonable volume preservation and better generalizability to varying data distributions. It also enables better estimates of myocardial strains, which indicates the potential of the method in characterizing spatiotemporal signatures for understanding cardiovascular diseases.","This work was supported by EPSRC, UK Grant SmartHeart (EP/P001009/1) and ERC Grant Deep4MI (884622). S. Wang was supported by the Shanghai Sailing Programs of Shanghai Municipal Science and Technology Committee, China (22YF1409300). C. Chen was supported by UKRI Innovate UK Grant (No.104691). W. Bai was supported by EPSRC, UK Grant DeepGeM (EP/W01842X/1).",,Medical Image Analysis,,Humans, Space Flight,2022-11-07,2022,2022-11-07,2023-01,83,,102682,All OA, Green,Article,"Qin, Chen; Wang, Shuo; Chen, Chen; Bai, Wenjia; Rueckert, Daniel","Qin, Chen (Department of Electrical and Electronic Engineering and I-X, Imperial College London, UK. Electronic address: c.qin15@imperial.ac.uk.); Wang, Shuo (Digital Medical Research Center, School of Basic Medical Sciences, Fudan University, China. Electronic address: shuowang@fudan.edu.cn.); Chen, Chen (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK.); Bai, Wenjia (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK; Department of Brain Sciences, Imperial College London, UK; Data Science Institute, Imperial College London, UK.); Rueckert, Daniel (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK; Institute for AI and Informatics, Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.)","Qin, Chen (Imperial College London); Wang, Shuo (Fudan University)","Qin, Chen (Imperial College London); Wang, Shuo (Fudan University); Chen, Chen (Imperial College London); Bai, Wenjia (Imperial College London); Rueckert, Daniel (Imperial College London; Technical University of Munich; Rechts der Isar Hospital)",0,0,,,http://arxiv.org/pdf/2206.03830,https://app.dimensions.ai/details/publication/pub.1152541456,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,
1688,pub.1152570781,10.48550/arxiv.2211.03122,,,Computational anatomy atlas using multilayer perceptron with Lipschitz  regularization,"A computational anatomy atlas is a set of internal organ geometries. It is
based on data of real patients and complemented with virtual cases by using a
some numerical approach. Atlases are in demand in computational physiology,
especially in cardiological and neurophysiological applications. Usually, atlas
generation uses explicit object representation, such as voxel models or surface
meshes. In this paper, we propose a method of atlas generation using an
implicit representation of 3D objects. Our approach has two key stages. The
first stage converts voxel models of segmented organs to implicit form using
the usual multilayer perceptron. This stage smooths the model and reduces
memory consumption. The second stage uses a multilayer perceptron with
Lipschitz regularization. This neural network provides a smooth transition
between implicitly defined 3D geometries. Our work shows examples of models of
the left and right human ventricles. All code and data for this work are open.",,,arXiv,,,2022-11-06,2022,,,,,,All OA, Green,Preprint,"Ushenin, Konstantin; Dzhigil, Maksim; Dordiuk, Vladislav","Ushenin, Konstantin (); Dzhigil, Maksim (); Dordiuk, Vladislav ()",,"Ushenin, Konstantin (); Dzhigil, Maksim (); Dordiuk, Vladislav ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152570781,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1344,pub.1154574367,10.1109/ice3is56585.2022.10010273,,,Comparing of CNN Algorithms for Feature Extraction and Classification on Cardiac MRI,"Deep Learning (DL) has been incorporated into image processing, including cardiac MRI images to address Machine Learning (ML) issues, the best model based on research evaluation is still up for debate among experts in the field. The diversity of datasets has characteristics that are not always in accordance with the objectives of the research to be carried out. Each of the existing models each has a different performance achievement. This review contributes to presenting various datasets and DL models related to their application to cardiac MRI images. The proposed classification method goes through several main stages, including object detection to obtain the region of interest (RoI), segmentation to obtain feature maps, classification with a fully connected layer (FCN).",,,,2022 2nd International Conference on Electronic and Electrical Engineering and Intelligent System (ICE3IS),,2022-11-05,2022,,2022-11-05,0,,375-380,Closed,Proceeding,"Irmawati, Dessy; Wahyunggoro, Oyas; Soesanti, Indah","Irmawati, Dessy (Department of Electrical Engineering and Information Technology, Gadjah Mada University, Yogyakarta, Indonesia); Wahyunggoro, Oyas (Department of Electrical Engineering and Information Technology, Gadjah Mada University, Yogyakarta, Indonesia); Soesanti, Indah (Department of Electrical Engineering and Information Technology, Gadjah Mada University, Yogyakarta, Indonesia)",,"Irmawati, Dessy (Gadjah Mada University); Wahyunggoro, Oyas (Gadjah Mada University); Soesanti, Indah (Gadjah Mada University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154574367,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1258,pub.1150765678,10.1016/j.knosys.2022.109859,,,TransUNet+: Redesigning the skip connection to enhance features in medical image segmentation,"The new architecture TransUNet, which combines convolutional neural networks (CNNs) and transformers, has displayed competitive performance in medical image segmentation. In this paper, an efficient model named TransUNet+, which can achieve promising results with a redesigned skip connection, is proposed for medical image segmentation. The redesigned skip connection contains an enhancement module, which can effectively enhance the skip features to improve global attention by using the score matrix of the transformer block. As the column vectors of the score matrix represent the relationship between the patches and the whole image, they can be used for feature enhancement. To validate the proposed TransUNet+, series of experiments are performed based on three different medical image segmentation datasets covering multiple imaging modalities. Experimental results show that the proposed TransUNet+ outperforms other state-of-the-art methods based on three datasets, and the proposed TransUNet+ displays better performance in small organ segmentation.","This work is supported by the National Natural Science Foundation of China [No. 61836011] and the Department of Science and Technology of Sichuan Province, China [2021YFS0399].",,Knowledge-Based Systems,,,2022-11,2022,,2022-11,256,,109859,Closed,Article,"Liu, Yuhang; Wang, Han; Chen, Zugang; Huangliang, Kehan; Zhang, Haixian","Liu, Yuhang (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, PR China); Wang, Han (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, PR China); Chen, Zugang (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, PR China); Huangliang, Kehan (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, PR China); Zhang, Haixian (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, PR China)","Zhang, Haixian (Sichuan University)","Liu, Yuhang (Sichuan University); Wang, Han (Sichuan University); Chen, Zugang (Sichuan University); Huangliang, Kehan (Sichuan University); Zhang, Haixian (Sichuan University)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1150765678,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
6482,pub.1152360916,10.1155/2022/5311825,36353681,PMC9640236,Multiresolution Mutual Assistance Network for Cardiac Magnetic Resonance Images Segmentation,"The automatic segmentation of cardiac magnetic resonance (MR) images is the basis for the diagnosis of cardiac-related diseases. However, the segmentation of cardiac MR images is a challenging task due to the inhomogeneity of MR images intensity distribution and the unclear boundaries between adjacent tissues. In this paper, we propose a novel multiresolution mutual assistance network (MMA-Net) for cardiac MR images segmentation. It is mainly composed of multibranch input module, multiresolution mutual assistance module, and multilabel deep supervision. First, the multibranch input module helps the network to extract local and global features more pertinently. Then, the multiresolution mutual assistance module implements multiresolution feature interaction and progressively improves semantic features to more completely express the information of the tissue. Finally, the multilabel deep supervision is proposed to generate the final segmentation map. We compare with state-of-the-art medical image segmentation methods on the medical image computing and computer-assisted intervention (MICCAI) automated cardiac diagnosis challenge datasets and the MICCAI atrial segmentation challenge datasets. The mean dice scores of our method in the left atrium, right ventricle, myocardium, and left ventricle are 0.919, 0.920, 0.881, and 0.960, respectively. The analysis of evaluation indicators and segmentation results shows that our method achieves the best performance in cardiac magnetic resonance images segmentation.",This work was supported in part by the Science and Technology Planning Project of Guangdong Science and Technology Department under Grant Guangdong Key Laboratory of Advanced IntelliSense Technology (2019B121203006).,,Journal of Healthcare Engineering,,"Humans; Magnetic Resonance Imaging; Heart Ventricles; Heart Atria; Image Processing, Computer-Assisted",2022-10-31,2022,2022-10-31,2022-10-31,2022,,5311825,All OA, Gold,Article,"Chen, Shaolong; Qiu, Changzhen; Yang, Weiping; Zhang, Zhiyong","Chen, Shaolong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518107, China, sysu.edu.cn); Qiu, Changzhen (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518107, China, sysu.edu.cn); Yang, Weiping (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518107, China, sysu.edu.cn); Zhang, Zhiyong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518107, China, sysu.edu.cn)","Zhang, Zhiyong (Sun Yat-sen University)","Chen, Shaolong (Sun Yat-sen University); Qiu, Changzhen (Sun Yat-sen University); Yang, Weiping (Sun Yat-sen University); Zhang, Zhiyong (Sun Yat-sen University)",0,0,,,https://downloads.hindawi.com/journals/jhe/2022/5311825.pdf,https://app.dimensions.ai/details/publication/pub.1152360916,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,
1251,pub.1152281673,10.48550/arxiv.2210.15566,,,UNet-2022: Exploring Dynamics in Non-isomorphic Architecture,"Recent medical image segmentation models are mostly hybrid, which integrate
self-attention and convolution layers into the non-isomorphic architecture.
However, one potential drawback of these approaches is that they failed to
provide an intuitive explanation of why this hybrid combination manner is
beneficial, making it difficult for subsequent work to make improvements on top
of them. To address this issue, we first analyze the differences between the
weight allocation mechanisms of the self-attention and convolution. Based on
this analysis, we propose to construct a parallel non-isomorphic block that
takes the advantages of self-attention and convolution with simple
parallelization. We name the resulting U-shape segmentation model as UNet-2022.
In experiments, UNet-2022 obviously outperforms its counterparts in a range
segmentation tasks, including abdominal multi-organ segmentation, automatic
cardiac diagnosis, neural structures segmentation, and skin lesion
segmentation, sometimes surpassing the best performing baseline by 4%.
Specifically, UNet-2022 surpasses nnUNet, the most recognized segmentation
model at present, by large margins. These phenomena indicate the potential of
UNet-2022 to become the model of choice for medical image segmentation.",,,arXiv,,,2022-10-27,2022,,,,,,All OA, Green,Preprint,"Guo, Jiansen; Zhou, Hong-Yu; Wang, Liansheng; Yu, Yizhou","Guo, Jiansen (); Zhou, Hong-Yu (); Wang, Liansheng (); Yu, Yizhou ()",,"Guo, Jiansen (); Zhou, Hong-Yu (); Wang, Liansheng (); Yu, Yizhou ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152281673,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1550,pub.1152281182,10.48550/arxiv.2210.15075,,,IDEAL: Improved DEnse locAL Contrastive Learning for Semi-Supervised  Medical Image Segmentation,"Due to the scarcity of labeled data, Contrastive Self-Supervised Learning
(SSL) frameworks have lately shown great potential in several medical image
analysis tasks. However, the existing contrastive mechanisms are sub-optimal
for dense pixel-level segmentation tasks due to their inability to mine local
features. To this end, we extend the concept of metric learning to the
segmentation task, using a dense (dis)similarity learning for pre-training a
deep encoder network, and employing a semi-supervised paradigm to fine-tune for
the downstream task. Specifically, we propose a simple convolutional projection
head for obtaining dense pixel-level features, and a new contrastive loss to
utilize these dense projections thereby improving the local representations. A
bidirectional consistency regularization mechanism involving two-stream model
training is devised for the downstream task. Upon comparison, our IDEAL method
outperforms the SoTA methods by fair margins on cardiac MRI segmentation.",,,arXiv,,,2022-10-26,2022,,,,,,All OA, Green,Preprint,"Basak, Hritam; Chattopadhyay, Soumitri; Kundu, Rohit; Nag, Sayan; Mallipeddi, Rammohan","Basak, Hritam (); Chattopadhyay, Soumitri (); Kundu, Rohit (); Nag, Sayan (); Mallipeddi, Rammohan ()",,"Basak, Hritam (); Chattopadhyay, Soumitri (); Kundu, Rohit (); Nag, Sayan (); Mallipeddi, Rammohan ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152281182,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
907,pub.1152281016,10.48550/arxiv.2210.14909,,,Automated Diagnosis of Cardiovascular Diseases from Cardiac Magnetic  Resonance Imaging Using Deep Learning Models: A Review,"In recent years, cardiovascular diseases (CVDs) have become one of the
leading causes of mortality globally. CVDs appear with minor symptoms and
progressively get worse. The majority of people experience symptoms such as
exhaustion, shortness of breath, ankle swelling, fluid retention, and other
symptoms when starting CVD. Coronary artery disease (CAD), arrhythmia,
cardiomyopathy, congenital heart defect (CHD), mitral regurgitation, and angina
are the most common CVDs. Clinical methods such as blood tests,
electrocardiography (ECG) signals, and medical imaging are the most effective
methods used for the detection of CVDs. Among the diagnostic methods, cardiac
magnetic resonance imaging (CMR) is increasingly used to diagnose, monitor the
disease, plan treatment and predict CVDs. Coupled with all the advantages of
CMR data, CVDs diagnosis is challenging for physicians due to many slices of
data, low contrast, etc. To address these issues, deep learning (DL) techniques
have been employed to the diagnosis of CVDs using CMR data, and much research
is currently being conducted in this field. This review provides an overview of
the studies performed in CVDs detection using CMR images and DL techniques. The
introduction section examined CVDs types, diagnostic methods, and the most
important medical imaging techniques. In the following, investigations to
detect CVDs using CMR images and the most significant DL methods are presented.
Another section discussed the challenges in diagnosing CVDs from CMR data.
Next, the discussion section discusses the results of this review, and future
work in CVDs diagnosis from CMR images and DL techniques are outlined. The most
important findings of this study are presented in the conclusion section.",,,arXiv,,,2022-10-26,2022,,,,,,All OA, Green,Preprint,"Jafari, Mahboobeh; Shoeibi, Afshin; Khodatars, Marjane; Ghassemi, Navid; Moridian, Parisa; Delfan, Niloufar; Alizadehsani, Roohallah; Khosravi, Abbas; Ling, Sai Ho; Zhang, Yu-Dong; Wang, Shui-Hua; Gorriz, Juan M.; Rokny, Hamid Alinejad; Acharya, U. Rajendra","Jafari, Mahboobeh (); Shoeibi, Afshin (); Khodatars, Marjane (); Ghassemi, Navid (); Moridian, Parisa (); Delfan, Niloufar (); Alizadehsani, Roohallah (); Khosravi, Abbas (); Ling, Sai Ho (); Zhang, Yu-Dong (); Wang, Shui-Hua (); Gorriz, Juan M. (); Rokny, Hamid Alinejad (); Acharya, U. Rajendra ()",,"Jafari, Mahboobeh (); Shoeibi, Afshin (); Khodatars, Marjane (); Ghassemi, Navid (); Moridian, Parisa (); Delfan, Niloufar (); Alizadehsani, Roohallah (); Khosravi, Abbas (); Ling, Sai Ho (); Zhang, Yu-Dong (); Wang, Shui-Hua (); Gorriz, Juan M. (); Rokny, Hamid Alinejad (); Acharya, U. Rajendra ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152281016,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,,,,
1213,pub.1152271454,10.32604/cmes.2022.023195,,,An Interpretable CNN for the Segmentation of the Left Ventricle in Cardiac MRI by Real-Time Visualization,"The interpretability of deep learning models has emerged as a compelling area in artificial intelligence research. The safety criteria for medical imaging are highly stringent, and models are required for an explanation. However, existing convolutional neural network solutions for left ventricular segmentation are viewed in terms of inputs and outputs. Thus, the interpretability of CNNs has come into the spotlight. Since medical imaging data are limited, many methods to fine-tune medical imaging models that are popular in transfer models have been built using massive public ImageNet datasets by the transfer learning method. Unfortunately, this generates many unreliable parameters and makes it difficult to generate plausible explanations from these models. In this study, we trained from scratch rather than relying on transfer learning, creating a novel interpretable approach for autonomously segmenting the left ventricle with a cardiac MRI. Our enhanced GPU training system implemented interpretable global average pooling for graphics using deep learning. The deep learning tasks were simplified. Simplification included data management, neural network architecture, and training. Our system monitored and analyzed the gradient changes of different layers with dynamic visualizations in real-time and selected the optimal deployment model. Our results demonstrated that the proposed method was feasible and efficient: the Dice coefficient reached 94.48%, and the accuracy reached 99.7%. It was found that no current transfer learning models could perform comparably to the ImageNet transfer learning architectures. This model is lightweight and more convenient to deploy on mobile devices than transfer learning models.",,,Computer Modeling in Engineering & Sciences,,,2022-10-21,2022,2022-10-21,2023,135,2,1571-1587,All OA, Gold,Article,"Liu, Jun; Yuan, Geng; Yang, Changdi; Song, Houbing; Luo, Liang","Liu, Jun (Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, 15217, USA); Yuan, Geng (Department of Electrical & Computer Engineering, College of Engineering, Northeastern University, Boston, MA, 02115, USA); Yang, Changdi (Department of Electrical & Computer Engineering, College of Engineering, Northeastern University, Boston, MA, 02115, USA); Song, Houbing (Security and Optimization for Networked Globe Laboratory (SONG Lab), Embry-Riddle Aeronautical University, Daytona Beach, FL, 32114, USA); Luo, Liang (School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, 610054, China)","Luo, Liang (University of Electronic Science and Technology of China)","Liu, Jun (Carnegie Mellon University); Yuan, Geng (Northeastern University); Yang, Changdi (Northeastern University); Song, Houbing (Embry–Riddle Aeronautical University); Luo, Liang (University of Electronic Science and Technology of China)",0,0,,,https://file.techscience.com/ueditor/files/cmes/TSP_CMES-135-2/TSP_CMES_23195/TSP_CMES_23195.pdf,https://app.dimensions.ai/details/publication/pub.1152271454,49 Mathematical Sciences, 4901 Applied Mathematics, 4903 Numerical and Computational Mathematics,,,,,,,,,
4551,pub.1152004404,10.1109/tmi.2022.3215798,36260571,,A Framework for Simulating Cardiac MR Images with Varying Anatomy and Contrast,"One of the limiting factors for the development and adoption of novel deep-learning (DL) based medical image analysis methods is the scarcity of labeled medical images. Medical image simulation and synthesis can provide solutions by generating ample training data with corresponding ground truth labels. Despite recent advances, generated images demonstrate limited realism and diversity. In this work, we develop a flexible framework for simulating cardiac magnetic resonance (MR) images with variable anatomical and imaging characteristics for the purpose of creating a diversified virtual population. We advance previous works on both cardiac MR image simulation and anatomical modeling to increase the realism in terms of both image appearance and underlying anatomy. To diversify the generated images, we define parameters: 1) to alter the anatomy, 2) to assign MR tissue properties to various tissue types, and 3) to manipulate the image contrast via acquisition parameters. The proposed framework is optimized to generate a substantial number of cardiac MR images with ground truth labels suitable for downstream supervised tasks. A database of virtual subjects is simulated and its usefulness for aiding a DL segmentation method is evaluated. Our experiments show that training completely with simulated images can perform comparable with a model trained with real images for heart cavity segmentation in mid-ventricular slices. Moreover, such data can be used in addition to classical augmentation for boosting the performance when training data is limited, particularly by increasing the contrast and anatomical variation, leading to better regularization and generalization. The database is publicly available at https://osf.io/ bkzhm/ and the simulation code will be available at https: //github.com/sinaamirrajab/CMRI_Simulation.",,,IEEE Transactions on Medical Imaging,,,2022-10-19,2022,2022-10-19,2022-10-19,PP,99,1-1,All OA, Hybrid,Article,"Amirrajab, Sina; Khalil, Yasmina Al; Lorenz, Cristian; Weese, Jurgen; Pluim, Josien; Breeuwer, Marcel","Amirrajab, Sina (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands); Khalil, Yasmina Al (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands); Lorenz, Cristian (Philips Research Laboratories, Hamburg, Germany); Weese, Jurgen (Philips Research Laboratories, Hamburg, Germany); Pluim, Josien (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands); Breeuwer, Marcel (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands)",,"Amirrajab, Sina (Eindhoven University of Technology); Khalil, Yasmina Al (Eindhoven University of Technology); Lorenz, Cristian (Philips (Germany)); Weese, Jurgen (Philips (Germany)); Pluim, Josien (Eindhoven University of Technology); Breeuwer, Marcel (Eindhoven University of Technology)",0,0,,,https://ieeexplore.ieee.org/ielx7/42/4359023/09924194.pdf,https://app.dimensions.ai/details/publication/pub.1152004404,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1620,pub.1152463870,10.1109/icip46576.2022.9897494,,,ACT-NET: Asymmetric Co-Teacher Network for Semi-Supervised Memory-Efficient Medical Image Segmentation,"While deep models have shown promising performance in medical image segmentation, they heavily rely on a large amount of well-annotated data, which is difficult to access, especially in clinical practice. On the other hand, high-accuracy deep models usually come in large model sizes, limiting their employment in real scenarios. In this work, we propose a novel asymmetric co-teacher framework, ACT-Net, to alleviate the burden on both expensive annotations and computational costs for semi-supervised knowledge distillation. We advance teacher-student learning with a co-teacher network to facilitate asymmetric knowledge distillation from large models to small ones by alternating student and teacher roles, obtaining tiny but accurate models for clinical employment. To verify the effectiveness of our ACT-Net, we employ the ACDC dataset for cardiac substructure segmentation in our experiments. Extensive experimental results demonstrate that ACT-Net outperforms other knowledge distillation methods and achieves lossless segmentation performance with 250× fewer parameters.",,,,2022 IEEE International Conference on Image Processing (ICIP),,2022-10-19,2022,,2022-10-19,0,,1426-1430,All OA, Green,Proceeding,"Zhao, Ziyuan; Zhu, Andong; Zeng, Zeng; Veeravalli, Bharadwaj; Guan, Cuntai","Zhao, Ziyuan (Institute of Infocomm Research (I, 2, R), A*STAR, Singapore; Artificial Intelligence, Analytics And Informatics (AI, 3, ), A*STAR, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore); Zhu, Andong (School of Electrical and Computer Engineering, National University of Singapore, Singapore); Zeng, Zeng (Institute of Infocomm Research (I, 2, R), A*STAR, Singapore; Artificial Intelligence, Analytics And Informatics (AI, 3, ), A*STAR, Singapore); Veeravalli, Bharadwaj (School of Electrical and Computer Engineering, National University of Singapore, Singapore); Guan, Cuntai (School of Computer Science and Engineering, Nanyang Technological University, Singapore)","Zhao, Ziyuan (Institute for Infocomm Research; Agency for Science, Technology and Research; Nanyang Technological University)","Zhao, Ziyuan (Institute for Infocomm Research; Agency for Science, Technology and Research; Nanyang Technological University); Zhu, Andong (National University of Singapore); Zeng, Zeng (Institute for Infocomm Research; Agency for Science, Technology and Research); Veeravalli, Bharadwaj (National University of Singapore); Guan, Cuntai (Nanyang Technological University)",0,0,,,http://arxiv.org/pdf/2207.01900,https://app.dimensions.ai/details/publication/pub.1152463870,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1619,pub.1152463858,10.1109/icip46576.2022.9897482,,,Computationally-Efficient Vision Transformer for Medical Image Semantic Segmentation Via Dual Pseudo-Label Supervision,"Ubiquitous accumulation of large volumes of data, and increased availability of annotated medical data in particular, has made it possible to show the many and varied benefits of deep learning to the semantic segmentation of medical images. Nevertheless, data access and annotation come at a high cost in clinician time. The power of Vision Transformer (ViT) is well-documented for generic computer vision tasks involving millions of images of every day objects, of which only relatively few have been annotated. Its translation to relatively more modest (i.e. thousands of images of) medical data is not immediately straightforward. This paper presents practical avenues for training a Computationally-Efficient Semi-Supervised Vision Transformer (CESS-ViT) for medical image segmentation task. We propose a self-attention-based image segmentation network which requires only limited computational resources. Additionally, we develop a dual pseudo-label supervision scheme for use with semi-supervision in a simple pure ViT. Our method has been evaluated on a publicly available cardiac MRI dataset with direct comparison against other semi-supervised methods. Our results illustrate the proposed ViT-based semi-supervised method outperforms the existing methods in the semantic segmentation of cardiac ventricles.",,,,2022 IEEE International Conference on Image Processing (ICIP),,2022-10-19,2022,,2022-10-19,0,,1961-1965,All OA, Green,Proceeding,"Wang, Ziyang; Dong, Nanqing; Voiculescu, Irina","Wang, Ziyang (Department of Computer Science, University of Oxford, UK); Dong, Nanqing (Department of Computer Science, University of Oxford, UK); Voiculescu, Irina (Department of Computer Science, University of Oxford, UK)","Wang, Ziyang (University of Oxford)","Wang, Ziyang (University of Oxford); Dong, Nanqing (University of Oxford); Voiculescu, Irina (University of Oxford)",3,3,,,https://ora.ox.ac.uk/objects/uuid:ec5d1512-97d2-40ae-aff9-b48bfaa1bbef/files/sfn107017p,https://app.dimensions.ai/details/publication/pub.1152463858,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1070,pub.1152021807,10.48550/arxiv.2210.10956,,,Non-Iterative Scribble-Supervised Learning with Pacing Pseudo-Masks for  Medical Image Segmentation,"Scribble-supervised medical image segmentation tackles the limitation of
sparse masks. Conventional approaches alternate between: labeling pseudo-masks
and optimizing network parameters. However, such iterative two-stage paradigm
is unwieldy and could be trapped in poor local optima since the networks
undesirably regress to the erroneous pseudo-masks. To address these issues, we
propose a non-iterative method where a stream of varying (pacing) pseudo-masks
teach a network via consistency training, named PacingPseudo. Our motivation
lies first in a non-iterative process. Interestingly, it can be achieved
gracefully by a siamese architecture, wherein a stream of pseudo-masks
naturally assimilate a stream of predicted masks during training. Second, we
make the consistency training effective with two necessary designs: (i) entropy
regularization to obtain high-confidence pseudo-masks for effective teaching;
and (ii) distorted augmentations to create discrepancy between the pseudo-mask
and predicted-mask streams for consistency regularization. Third, we devise a
new memory bank mechanism that provides an extra source of ensemble features to
complement scarce labeled pixels. The efficacy of the proposed PacingPseudo is
validated on three public medical image datasets, including the segmentation
tasks of abdominal multi-organs, cardiac structures, and myocardium. Extensive
experiments demonstrate our PacingPseudo improves the baseline by large margins
and consistently outcompetes several previous methods. In some cases, our
PacingPseudo achieves comparable performance with its fully-supervised
counterparts, showing the feasibility of our method for the challenging
scribble-supervised segmentation applications. The code and scribble
annotations will be publicly available.",,,arXiv,,,2022-10-19,2022,,,,,,All OA, Green,Preprint,"Yang, Zefan; Lin, Di; Ni, Dong; Wang, Yi","Yang, Zefan (); Lin, Di (); Ni, Dong (); Wang, Yi ()",,"Yang, Zefan (); Lin, Di (); Ni, Dong (); Wang, Yi ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152021807,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
3941,pub.1152002986,10.1109/tpami.2022.3215186,36251907,,Minimizing Estimated Risks on Unlabeled Data: A New Formulation for Semi-Supervised Medical Image Segmentation,"Supervised segmentation can be costly, particularly in applications of biomedical image analysis where large scale manual annotations from experts are generally too expensive to be available. Semi-supervised segmentation, able to learn from both the labeled and unlabeled images, could be an efficient and effective alternative for such scenarios. In this work, we propose a new formulation based on risk minimization, which makes full use of the unlabeled images. Different from most of the existing approaches which solely explicitly guarantee the minimization of prediction risks from the labeled training images, the new formulation also considers the risks on unlabeled images. Particularly, this is achieved via an unbiased estimator, based on which we develop a general framework for semi-supervised image segmentation. We validate this framework on three medical image segmentation tasks, namely cardiac segmentation on ACDC2017, optic cup and disc segmentation on REFUGE dataset and 3D whole heart segmentation on MM-WHS dataset. Results show that the proposed estimator is effective, and the segmentation method achieves superior performance and demonstrates great potential compared to the other state-of-the-art approaches. Our code and data will be released via https://zmiclab.github.io/projects.html, once the manuscript is accepted for publication.",,,IEEE Transactions on Pattern Analysis and Machine Intelligence,,,2022-10-17,2022,2022-10-17,2022-10-17,PP,99,1-17,Closed,Article,"Wu, Fuping; Zhuang, Xiahai","Wu, Fuping (School of Data Science, and Department of Statistics, Fudan University, Shanghai, China); Zhuang, Xiahai (School of Data Science, Fudan University, China)",,"Wu, Fuping (Fudan University); Zhuang, Xiahai (Fudan University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1152002986,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
1519,pub.1151979824,10.48550/arxiv.2210.08066,,,Optimizing Vision Transformers for Medical Image Segmentation,"For medical image semantic segmentation (MISS), Vision Transformers have
emerged as strong alternatives to convolutional neural networks thanks to their
inherent ability to capture long-range correlations. However, existing research
uses off-the-shelf vision Transformer blocks based on linear projections and
feature processing which lack spatial and local context to refine organ
boundaries. Furthermore, Transformers do not generalize well on small medical
imaging datasets and rely on large-scale pre-training due to limited inductive
biases. To address these problems, we demonstrate the design of a compact and
accurate Transformer network for MISS, CS-Unet, which introduces convolutions
in a multi-stage design for hierarchically enhancing spatial and local modeling
ability of Transformers. This is mainly achieved by our well-designed
Convolutional Swin Transformer (CST) block which merges convolutions with
Multi-Head Self-Attention and Feed-Forward Networks for providing inherent
localized spatial context and inductive biases. Experiments demonstrate CS-Unet
without pre-training outperforms other counterparts by large margins on
multi-organ and cardiac datasets with fewer parameters and achieves
state-of-the-art performance. Our code is available at Github.",,,arXiv,,,2022-10-14,2022,,,,,,All OA, Green,Preprint,"Liu, Qianying; Kaul, Chaitanya; Wang, Jun; Anagnostopoulos, Christos; Murray-Smith, Roderick; Deligianni, Fani","Liu, Qianying (); Kaul, Chaitanya (); Wang, Jun (); Anagnostopoulos, Christos (); Murray-Smith, Roderick (); Deligianni, Fani ()",,"Liu, Qianying (); Kaul, Chaitanya (); Wang, Jun (); Anagnostopoulos, Christos (); Murray-Smith, Roderick (); Deligianni, Fani ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151979824,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1066,pub.1151853270,10.1002/ima.22818,,,Ventricular segmentation and modeling using topological watershed transformation and harmonic state model,"This paper proposes an adapted ventricular segmentation method based on topological watershed transform. Segmentation will allow spatio‐temporal modeling of trajectories of the different points belonging to the borders of the ventricle using a harmonic motion model that is able to describe such motion over the entire cardiac cycle. In addition, extraction of the adopted canonical state vector and the corresponding state equations guarantees an optimal efficacy and a gradual transition from order n to order n + 1. To validate the proposed approach, an intern‐image base was used. Our results show a promising ability to discern whether subjects are healthy or pathological with an 80% success rate.","A special thanks goes to the whole team of the radiology department of Fattouma Bourguiba hospital in Monastir, Tunisia.",,International Journal of Imaging Systems and Technology,,,2022-10-13,2022,2022-10-13,,,,,All OA, Green,Article,"Mahmoudi, Ramzi","Mahmoudi, Ramzi (Laboratory of Medical Imaging Technology, LTIM‐LR12ES06, Faculty of Medicine of Monastir, University of Monastir, Monastir, Tunisia; Computer Science Laboratory Gaspard‐Monge, Mixed Unit CNRS‐UMLV‐ESIEE UMR8049, ESIEE, University of Paris‐Est, Paris, France)","Mahmoudi, Ramzi (University of Monastir; Paris-Est Créteil University)","Mahmoudi, Ramzi (University of Monastir; Paris-Est Créteil University)",0,0,,,https://hal.archives-ouvertes.fr/hal-03836924/file/13_Final%20accepted%20version.pdf,https://app.dimensions.ai/details/publication/pub.1151853270,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1692,pub.1151848889,10.48550/arxiv.2210.06385,,,The Extreme Cardiac MRI Analysis Challenge under Respiratory Motion  (CMRxMotion),"The quality of cardiac magnetic resonance (CMR) imaging is susceptible to
respiratory motion artifacts. The model robustness of automated segmentation
techniques in face of real-world respiratory motion artifacts is unclear. This
manuscript describes the design of extreme cardiac MRI analysis challenge under
respiratory motion (CMRxMotion Challenge). The challenge aims to establish a
public benchmark dataset to assess the effects of respiratory motion on image
quality and examine the robustness of segmentation models. The challenge
recruited 40 healthy volunteers to perform different breath-hold behaviors
during one imaging visit, obtaining paired cine imaging with artifacts.
Radiologists assessed the image quality and annotated the level of respiratory
motion artifacts. For those images with diagnostic quality, radiologists
further segmented the left ventricle, left ventricle myocardium and right
ventricle. The images of training set (20 volunteers) along with the
annotations are released to the challenge participants, to develop an automated
image quality assessment model (Task 1) and an automated segmentation model
(Task 2). The images of validation set (5 volunteers) are released to the
challenge participants but the annotations are withheld for online evaluation
of submitted predictions. Both the images and annotations of the test set (15
volunteers) were withheld and only used for offline evaluation of submitted
containerized dockers. The image quality assessment task is quantitatively
evaluated by the Cohen's kappa statistics and the segmentation task is
evaluated by the Dice scores and Hausdorff distances.",,,arXiv,,,2022-10-12,2022,,,,,,All OA, Green,Preprint,"Wang, Shuo; Qin, Chen; Wang, Chengyan; Wang, Kang; Wang, Haoran; Chen, Chen; Ouyang, Cheng; Kuang, Xutong; Dai, Chengliang; Mo, Yuanhan; Shi, Zhang; Dai, Chenchen; Chen, Xinrong; Wang, He; Bai, Wenjia","Wang, Shuo (); Qin, Chen (); Wang, Chengyan (); Wang, Kang (); Wang, Haoran (); Chen, Chen (); Ouyang, Cheng (); Kuang, Xutong (); Dai, Chengliang (); Mo, Yuanhan (); Shi, Zhang (); Dai, Chenchen (); Chen, Xinrong (); Wang, He (); Bai, Wenjia ()",,"Wang, Shuo (); Qin, Chen (); Wang, Chengyan (); Wang, Kang (); Wang, Haoran (); Chen, Chen (); Ouyang, Cheng (); Kuang, Xutong (); Dai, Chengliang (); Mo, Yuanhan (); Shi, Zhang (); Dai, Chenchen (); Chen, Xinrong (); Wang, He (); Bai, Wenjia ()",1,1,,,,https://app.dimensions.ai/details/publication/pub.1151848889,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,
649,pub.1151848478,10.48550/arxiv.2210.05952,,,3D Brain and Heart Volume Generative Models: A Survey,"Generative models such as generative adversarial networks and autoencoders
have gained a great deal of attention in the medical field due to their
excellent data generation capability. This paper provides a comprehensive
survey of generative models for three-dimensional (3D) volumes, focusing on the
brain and heart. A new and elaborate taxonomy of unconditional and conditional
generative models is proposed to cover diverse medical tasks for the brain and
heart: unconditional synthesis, classification, conditional synthesis,
segmentation, denoising, detection, and registration. We provide relevant
background, examine each task and also suggest potential future directions. A
list of the latest publications will be updated on Github to keep up with the
rapid influx of papers at
https://github.com/csyanbin/3D-Medical-Generative-Survey.",,,arXiv,,,2022-10-12,2022,,,,,,All OA, Green,Preprint,"Liu, Yanbin; Dwivedi, Girish; Boussaid, Farid; Bennamoun, Mohammed","Liu, Yanbin (); Dwivedi, Girish (); Boussaid, Farid (); Bennamoun, Mohammed ()",,"Liu, Yanbin (); Dwivedi, Girish (); Boussaid, Farid (); Bennamoun, Mohammed ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151848478,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1770,pub.1151744633,10.1063/5.0101144,,,Deep learning watershed algorithm to calculate cardiac stroke volume of the left ventricle for the analysis to detect person suffering from cardiac vascular diseases using cardiac MRI data,"The broadly used approach for cardiac image segmentation is deep learning. In deep learning, the watershed algorithm is a conventional procedure used for segmentation that is for segregating different regions in an image. This paper calculated the cardiac stroke volume of the left ventricle per heartbeat of a healthy person and patients having Cardio Vascular Diseases (CVD) using a magnetic resonance image (MRI) data set. This paper plots the graph of the cardiac stroke volume of the left ventricle of healthy people and CVD patients. The graph is a plot by taking the mean of 15 healthy persons and 15 CVD patients’ cardiac stroke volume of the left ventricle. Finally, by using the watershed algorithm, the analysis can detect whether the person is suffering from CVD.",,,AIP Conference Proceedings,INNOVATIONS AND RESEARCH IN MARINE ELECTRICAL AND ELECTRONICS ENGINEERING: ICIRMEEE 2021,,2022-10-10,2022,,2022-10-10,2455,1,30003,Closed,Proceeding,"Pawar, Shilpa Devram; Wallis, Shipra; Singha, Priyanka; Singh, Divya","Pawar, Shilpa Devram (Army Institute of Technology, Pune, India); Wallis, Shipra (Army Institute of Technology, Pune, India); Singha, Priyanka (Army Institute of Technology, Pune, India); Singh, Divya (Army Institute of Technology, Pune, India)","Pawar, Shilpa Devram (University of Pune)","Pawar, Shilpa Devram (University of Pune); Wallis, Shipra (University of Pune); Singha, Priyanka (University of Pune); Singh, Divya (University of Pune)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151744633,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,,
5667,pub.1151714092,10.3390/life12101570,36295005,PMC9604839,nn-TransUNet: An Automatic Deep Learning Pipeline for Heart MRI Segmentation,"Cardiovascular disease (CVD) is a disease with high mortality in modern times. The segmentation task for MRI to extract the related organs for CVD is essential for diagnosis. Currently, a large number of deep learning methods are designed for medical image segmentation tasks. However, the design of segmentation algorithms tends to have more focus on deepening the network architectures and tuning the parameters and hyperparameters manually, which not only leads to a high time and effort consumption, but also causes the problem that the architectures and setting designed for a single task only performs well in a single dataset, but have low performance in other cases. In this paper, nn-TransUNet, an automatic deep learning pipeline for MRI segmentation of the heart is proposed to combine the experiment planning of nnU-net and the network architecture of TransUNet. nn-TransUNet uses vision transformers and convolution layers in the design of the encoder and takes up convolution layers as decoder. With the adaptive preprocessing and network training plan generated by the proposed automatic experiment planning pipeline, nn-TransUNet is able to fulfill the target of medical image segmentation in heart MRI tasks. nn-TransUNet achieved state-of-the-art level in heart MRI segmentation task on Automatic Cardiac Diagnosis Challenge (ACDC) Dataset. It also saves the effort and time to manually tune the parameters and hyperparameters, which can reduce the burden on researchers.","Thanks for Bernard et al., by Antonelli et al. and Zhuang for opening source ACDC, MSD02 and MyoPS 2020 datasets, which are the experimental datasets of this research.","This work was supported by the National Natural Science Foundation of China under Grants 62066047, 61966037.",Life,,,2022-10-09,2022,2022-10-09,,12,10,1570,All OA, Gold,Article,"Zhao, Li; Zhou, Dongming; Jin, Xin; Zhu, Weina","Zhao, Li (School of Information Science and Engineering, Yunnan University, Kunming 650504, China); Zhou, Dongming (School of Information Science and Engineering, Yunnan University, Kunming 650504, China); Jin, Xin (School of Software, Yunnan University, Kunming 650504, China); Zhu, Weina (School of Information Science and Engineering, Yunnan University, Kunming 650504, China)","Zhu, Weina (Yunnan University)","Zhao, Li (Yunnan University); Zhou, Dongming (Yunnan University); Jin, Xin (Yunnan University); Zhu, Weina (Yunnan University)",1,1,,,https://www.mdpi.com/2075-1729/12/10/1570/pdf?version=1665365822,https://app.dimensions.ai/details/publication/pub.1151714092,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,
1134,pub.1151716930,10.48550/arxiv.2210.03299,,,Topology-Preserving Segmentation Network,"Medical image segmentation aims to automatically extract anatomical or
pathological structures in the human body. Most objects or regions of interest
are of similar patterns. For example, the relative location and the relative
size of the lung and the kidney differ little among subjects. Incorporating
these morphology rules as prior knowledge into the segmentation model is
believed to be an effective way to enhance the accuracy of the segmentation
results. Motivated by this, we propose in this work the Topology-Preserving
Segmentation Network (TPSN) which can predict segmentation masks with the same
topology prescribed for specific tasks. TPSN is a deformation-based model that
yields a deformation map through an encoder-decoder architecture to warp the
template masks into a target shape approximating the region to segment.
Comparing to the segmentation framework based on pixel-wise classification,
deformation-based segmentation models that warp a template to enclose the
regions are more convenient to enforce geometric constraints. In our framework,
we carefully design the ReLU Jacobian regularization term to enforce the
bijectivity of the deformation map. As such, the predicted mask by TPSN has the
same topology as that of the template prior mask.",,,arXiv,,,2022-10-06,2022,,,,,,All OA, Green,Preprint,"Zhang, Han; Lui, Lok Ming","Zhang, Han (); Lui, Lok Ming ()",,"Zhang, Han (); Lui, Lok Ming ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151716930,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
4533,pub.1151603219,10.1016/j.heliyon.2022.e10872,36267381,PMC9576885,Application of AI in cardiovascular multimodality imaging,"Technical advances in artificial intelligence (AI) in cardiac imaging are rapidly improving the reproducibility of this approach and the possibility to reduce time necessary to generate a report. In cardiac computed tomography angiography (CCTA) the main application of AI in clinical practice is focused on detection of stenosis, characterization of coronary plaques, and detection of myocardial ischemia. In cardiac magnetic resonance (CMR) the application of AI is focused on post-processing and particularly on the segmentation of cardiac chambers during late gadolinium enhancement. In echocardiography, the application of AI is focused on segmentation of cardiac chambers and is helpful for valvular function and wall motion abnormalities. The common thread represented by all of these techniques aims to shorten the time of interpretation without loss of information compared to the standard approach. In this review we provide an overview of AI applications in multimodality cardiac imaging.",,"This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.",Heliyon,,,2022-10-05,2022,2022-10-05,2022-10,8,10,e10872,All OA, Gold,Article,"Muscogiuri, Giuseppe; Volpato, Valentina; Cau, Riccardo; Chiesa, Mattia; Saba, Luca; Guglielmo, Marco; Senatieri, Alberto; Chierchia, Gregorio; Pontone, Gianluca; Dell’Aversana, Serena; Schoepf, U. Joseph; Andrews, Mason G.; Basile, Paolo; Guaricci, Andrea Igoren; Marra, Paolo; Muraru, Denisa; Badano, Luigi P.; Sironi, Sandro","Muscogiuri, Giuseppe (Department of Radiology, Istituto Auxologico Italiano IRCCS, San Luca Hospital, Italy; School of Medicine, University of Milano-Bicocca, Milan, Italy); Volpato, Valentina (Department of Cardiac, Neurological and Metabolic Sciences, San Luca Hospital, Istituto Auxologico Italiano IRCCS, Milan, Italy; IRCCS Ospedale Galeazzi - Sant'Ambrogio, University Cardiology Department, Milan, Italy); Cau, Riccardo (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari, Polo di Monserrato, Cagliari, Italy); Chiesa, Mattia (Centro Cardiologico Monzino IRCCS, Milan, Italy); Saba, Luca (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari, Polo di Monserrato, Cagliari, Italy); Guglielmo, Marco (Department of Cardiology, Division of Heart and Lungs, Utrecht University, Utrecht University Medical Center, Utrecht, the Netherlands); Senatieri, Alberto (School of Medicine, University of Milano-Bicocca, Milan, Italy); Chierchia, Gregorio (School of Medicine, University of Milano-Bicocca, Milan, Italy); Pontone, Gianluca (Centro Cardiologico Monzino IRCCS, Milan, Italy); Dell’Aversana, Serena (Department of Radiology, Ospedale S. Maria Delle Grazie - ASL Napoli 2 Nord, Pozzuoli, Italy); Schoepf, U. Joseph (Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Ashley River Tower, 25 Courtenay Dr., Charleston, SC, USA); Andrews, Mason G. (Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Ashley River Tower, 25 Courtenay Dr., Charleston, SC, USA); Basile, Paolo (University Cardiology Unit, Department of Emergency and Organ Transplantation, University of Bari, Bari, Italy); Guaricci, Andrea Igoren (University Cardiology Unit, Department of Emergency and Organ Transplantation, University of Bari, Bari, Italy); Marra, Paolo (Department of Radiology, ASST Papa Giovanni XXIII, 24127 Bergamo, Italy); Muraru, Denisa (School of Medicine, University of Milano-Bicocca, Milan, Italy; Department of Cardiac, Neurological and Metabolic Sciences, San Luca Hospital, Istituto Auxologico Italiano IRCCS, Milan, Italy); Badano, Luigi P. (School of Medicine, University of Milano-Bicocca, Milan, Italy; Department of Cardiac, Neurological and Metabolic Sciences, San Luca Hospital, Istituto Auxologico Italiano IRCCS, Milan, Italy); Sironi, Sandro (School of Medicine, University of Milano-Bicocca, Milan, Italy; Department of Radiology, ASST Papa Giovanni XXIII, 24127 Bergamo, Italy)","Muscogiuri, Giuseppe (Istituto Auxologico Italiano; University of Milano-Bicocca)","Muscogiuri, Giuseppe (Istituto Auxologico Italiano; University of Milano-Bicocca); Volpato, Valentina (Istituto Auxologico Italiano); Cau, Riccardo (Azienda Ospedaliero-Universitaria Cagliari); Chiesa, Mattia (Centro Cardiologico Monzino); Saba, Luca (Azienda Ospedaliero-Universitaria Cagliari); Guglielmo, Marco (University Medical Center Utrecht; Utrecht University); Senatieri, Alberto (University of Milano-Bicocca); Chierchia, Gregorio (University of Milano-Bicocca); Pontone, Gianluca (Centro Cardiologico Monzino); Dell’Aversana, Serena (); Schoepf, U. Joseph (Medical University of South Carolina); Andrews, Mason G. (Medical University of South Carolina); Basile, Paolo (University of Bari Aldo Moro); Guaricci, Andrea Igoren (University of Bari Aldo Moro); Marra, Paolo (); Muraru, Denisa (University of Milano-Bicocca; Istituto Auxologico Italiano); Badano, Luigi P. (University of Milano-Bicocca; Istituto Auxologico Italiano); Sironi, Sandro (University of Milano-Bicocca)",1,1,,,http://www.cell.com/article/S2405844022021600/pdf,https://app.dimensions.ai/details/publication/pub.1151603219,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 40 Engineering, 4003 Biomedical Engineering,,,,,,,,
4323,pub.1141168863,10.1109/tpami.2021.3113077,34529562,,CyCoSeg: A Cyclic Collaborative Framework for Automated Medical Image Segmentation,"Deep neural networks have been tremendously successful at segmenting objects in images. However, it has been shown they still have limitations on challenging problems such as the segmentation of medical images. The main reason behind this lower success resides in the reduced size of the object in the image. In this paper we overcome this limitation through a cyclic collaborative framework, CyCoSeg. The proposed framework is based on a deep active shape model (D-ASM), which provides prior information about the shape of the object, and a semantic segmentation network (SSN). These two models collaborate to reach the desired segmentation by influencing each other: SSN helps D-ASM identify relevant keypoints in the image through an Expectation Maximization formulation, while D-ASM provides a segmentation proposal that guides the SSN. This cycle is repeated until both models converge. Extensive experimental evaluation shows CyCoSeg boosts the performance of the baseline models, including several popular SSNs, while avoiding major architectural modifications. The effectiveness of our method is demonstrated on the left ventricle segmentation on two benchmark datasets, where our approach achieves one of the most competitive results in segmentation accuracy. Furthermore, its generalization is demonstrated for lungs and kidneys segmentation in CT scans.",,This work was supported in part by the LARSyS - FCT Project UIDB/50009/2020 and in part by the PhD Program under Grant PD/BD/150628/2020. The Titan Xp used in this research was donated by the NVIDIA Corporation.,IEEE Transactions on Pattern Analysis and Machine Intelligence,,"Algorithms; Image Processing, Computer-Assisted; Neural Networks, Computer; Tomography, X-Ray Computed",2022-10-04,2022,2022-10-04,2022-11,44,11,8167-8182,Closed,Article,"Medley, Daniela O.; Santiago, Carlos; Nascimento, Jacinto C.","Medley, Daniela O. (Instituto de Sistemas e Robótica, Instituto Superior Técnico, 1049-001, Lisbon, Portugal); Santiago, Carlos (Instituto de Sistemas e Robótica, Instituto Superior Técnico, 1049-001, Lisbon, Portugal); Nascimento, Jacinto C. (Instituto de Sistemas e Robótica, Instituto Superior Técnico, 1049-001, Lisbon, Portugal)","Medley, Daniela O. (University of Lisbon)","Medley, Daniela O. (University of Lisbon); Santiago, Carlos (University of Lisbon); Nascimento, Jacinto C. (University of Lisbon)",3,3,,,,https://app.dimensions.ai/details/publication/pub.1141168863,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
4766,pub.1151551617,10.1109/tmi.2022.3211195,36191115,,Domain-incremental Cardiac Image Segmentation with Style-oriented Replay and Domain-sensitive Feature Whitening,"Contemporary methods have shown promising results on cardiac image segmentation, but merely in static learning, i.e., optimizing the network once for all, ignoring potential needs for model updating. In real-world scenarios, new data continues to be gathered from multiple institutions over time and new demands keep growing to pursue more satisfying performance. The desired model should incrementally learn from each incoming dataset and progressively update with improved functionality as time goes by. As the datasets sequentially delivered from multiple sites are normally heterogenous with domain discrepancy, each updated model should not catastrophically forget previously learned domains while well generalizing to currently arrived domains or even unseen domains. In medical scenarios, this is particularly challenging as accessing or storing past data is commonly not allowed due to data privacy. To this end, we propose a novel domain-incremental learning framework to recover past domain inputs first and then regularly replay them during model optimization. Particularly, we first present a style-oriented replay module to enable structure-realistic and memory-efficient reproduction of past data, and then incorporate the replayed past data to jointly optimize the model with current data to alleviate catastrophic forgetting. During optimization, we additionally perform domain-sensitive feature whitening to suppress model's dependency on features that are sensitive to domain changes (e.g., domain-distinctive style features) to assist domain-invariant feature exploration and gradually improve the generalization performance of the network. We have extensively evaluated our approach with the M&Ms Dataset in single-domain and compound-domain incremental learning settings. Our approach outperforms other comparison methods with less forgetting on past domains and better generalization on current domains and unseen domains.",,,IEEE Transactions on Medical Imaging,,,2022-10-03,2022,2022-10-03,2022-10-03,PP,99,1-1,All OA, Green,Article,"Li, Kang; Yu, Lequan; Heng, Pheng-Ann","Li, Kang (Department of Computer Science and Engineering, and the Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, HKSAR, China); Yu, Lequan (Department of Statistics and Actuarial Science, The University of Hong Kong, HKSAR, China); Heng, Pheng-Ann (Department of Computer Science and Engineering, and the Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, HKSAR, China)",,"Li, Kang (Chinese University of Hong Kong); Yu, Lequan (University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong)",0,0,,,http://arxiv.org/pdf/2211.04862,https://app.dimensions.ai/details/publication/pub.1151551617,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1133,pub.1151660210,10.1016/j.bbe.2022.09.005,,,Semi-supervised structure attentive temporal mixup coherence for medical image segmentation,"Deep convolutional neural networks have shown eminent performance in medical image segmentation in supervised learning. However, this success is predicated on the availability of large volumes of pixel-level labeled data, making these approaches impractical when labeled data is scarce. On the other hand, semi-supervised learning utilizes pertinent information from unlabeled data along with minimal labeled data, alleviating the demand for labeled data. In this paper, we leverage the mixup-based risk minimization operator in a student–teacher-based semi-supervised paradigm along with structure-aware constraints to enforce consistency coherence among the student predictions for unlabeled samples and the teacher predictions for the corresponding mixup sample by significantly diminishing the need for labeled data. Besides, due to the intrinsic simplicity of the linear combination operation used for generating mixup samples, the proposed method stands at a computational advantage over existing consistency regularization-based SSL methods. We experimentally validate the performance of the proposed model on two public benchmark datasets, namely the Left Atrial (LA) and Automatic Cardiac Diagnosis Challenge (ACDC) datasets. Notably, on the LA dataset’s lowest labeled data set-up (5%), the proposed method significantly improved the Dice Similarity Coefficient and the Jaccard Similarity Coefficient by 1.08% and 1.46%, respectively. Furthermore, we demonstrate the efficacy of the proposed method with a consistent improvement across various labeled data proportions on the aforementioned datasets.",,,Journal of Applied Biomedicine,,,2022-10,2022,,2022-10,42,4,1149-1161,Closed,Article,"Pawan, S.J.; Jeevan, Govind; Rajan, Jeny","Pawan, S.J. (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangalore - 575025, Karnataka, India); Jeevan, Govind (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangalore - 575025, Karnataka, India); Rajan, Jeny (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangalore - 575025, Karnataka, India)","Pawan, S.J. (National Institute of Technology Karnataka)","Pawan, S.J. (National Institute of Technology Karnataka); Jeevan, Govind (National Institute of Technology Karnataka); Rajan, Jeny (National Institute of Technology Karnataka)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1151660210,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
863,pub.1151404502,10.48550/arxiv.2209.13476,,,Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with  Extremely Limited Labels,"Recent studies on contrastive learning have achieved remarkable performance
solely by leveraging few labels in the context of medical image segmentation.
Existing methods mainly focus on instance discrimination and invariant mapping.
However, they face three common pitfalls: (1) tailness: medical image data
usually follows an implicit long-tail class distribution. Blindly leveraging
all pixels in training hence can lead to the data imbalance issues, and cause
deteriorated performance; (2) consistency: it remains unclear whether a
segmentation model has learned meaningful and yet consistent anatomical
features due to the intra-class variations between different anatomical
features; and (3) diversity: the intra-slice correlations within the entire
dataset have received significantly less attention. This motivates us to seek a
principled approach for strategically making use of the dataset itself to
discover similar yet distinct samples from different anatomical views. In this
paper, we introduce a novel semi-supervised 2D medical image segmentation
framework termed Mine yOur owN Anatomy (MONA), and make three contributions.
First, prior work argues that every pixel equally matters to the model
training; we observe empirically that this alone is unlikely to define
meaningful anatomical features, mainly due to lacking the supervision signal.
We show two simple solutions towards learning invariances - through the use of
stronger data augmentations and nearest neighbors. Second, we construct a set
of objectives that encourage the model to be capable of decomposing medical
images into a collection of anatomical features in an unsupervised manner.
Lastly, our extensive results on three benchmark datasets with different
labeled settings validate the effectiveness of our proposed MONA which achieves
new state-of-the-art under different labeled settings.",,,arXiv,,,2022-09-27,2022,,,,,,All OA, Green,Preprint,"You, Chenyu; Dai, Weicheng; Liu, Fenglin; Su, Haoran; Zhang, Xiaoran; Li, Xiaoxiao; Clifton, David A.; Staib, Lawrence; Duncan, James S.","You, Chenyu (); Dai, Weicheng (); Liu, Fenglin (); Su, Haoran (); Zhang, Xiaoran (); Li, Xiaoxiao (); Clifton, David A. (); Staib, Lawrence (); Duncan, James S. ()",,"You, Chenyu (); Dai, Weicheng (); Liu, Fenglin (); Su, Haoran (); Zhang, Xiaoran (); Li, Xiaoxiao (); Clifton, David A. (); Staib, Lawrence (); Duncan, James S. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151404502,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
696,pub.1151404217,10.48550/arxiv.2209.13177,,,"A Survey of Fairness in Medical Image Analysis: Concepts, Algorithms,  Evaluations, and Challenges","Fairness, a criterion focuses on evaluating algorithm performance on
different demographic groups, has gained attention in natural language
processing, recommendation system and facial recognition. Since there are
plenty of demographic attributes in medical image samples, it is important to
understand the concepts of fairness, be acquainted with unfairness mitigation
techniques, evaluate fairness degree of an algorithm and recognize challenges
in fairness issues in medical image analysis (MedIA). In this paper, we first
give a comprehensive and precise definition of fairness, following by
introducing currently used techniques in fairness issues in MedIA. After that,
we list public medical image datasets that contain demographic attributes for
facilitating the fairness research and summarize current algorithms concerning
fairness in MedIA. To help achieve a better understanding of fairness, and call
attention to fairness related issues in MedIA, experiments are conducted
comparing the difference between fairness and data imbalance, verifying the
existence of unfairness in various MedIA tasks, especially in classification,
segmentation and detection, and evaluating the effectiveness of unfairness
mitigation algorithms. Finally, we conclude with opportunities and challenges
in fairness in MedIA.",,,arXiv,,,2022-09-27,2022,,,,,,All OA, Green,Preprint,"Xu, Zikang; Li, Jun; Yao, Qingsong; Li, Han; Shi, Xin; Zhou, S. Kevin","Xu, Zikang (); Li, Jun (); Yao, Qingsong (); Li, Han (); Shi, Xin (); Zhou, S. Kevin ()",,"Xu, Zikang (); Li, Jun (); Yao, Qingsong (); Li, Han (); Shi, Xin (); Zhou, S. Kevin ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151404217,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1074,pub.1151307653,10.1631/fitee.2200102,,,Visual recognition of cardiac pathology based on 3D parametric model reconstruction,"Visual recognition of cardiac images is important for cardiac pathology diagnosis and treatment. Due to the limited availability of annotated datasets, traditional methods usually extract features directly from two-dimensional slices of three-dimensional (3D) heart images, followed by pathological classification. This process may not ensure the overall anatomical consistency in 3D heart. A new method for classification of cardiac pathology is therefore proposed based on 3D parametric model reconstruction. First, 3D heart models are reconstructed based on multiple 3D volumes of cardiac imaging data at the end-systole (ES) and end-diastole (ED) phases. Next, based on these reconstructed 3D hearts, 3D parametric models are constructed through the statistical shape model (SSM), and then the heart data are augmented via the variation in shape parameters of one 3D parametric model with visual knowledge constraints. Finally, shape and motion features of 3D heart models across two phases are extracted to classify cardiac pathology. Comprehensive experiments on the automated cardiac diagnosis challenge (ACDC) dataset of the Statistical Atlases and Computational Modelling of the Heart (STACOM) workshop confirm the superior performance and efficiency of this proposed approach.",,,Frontiers of Information Technology & Electronic Engineering,,,2022-09-24,2022,2022-09-24,2022-09,23,9,1324-1337,Closed,Article,"Xiao, Jinxiao; Li, Yansong; Tian, Yun; Xu, Dongrong; Li, Penghui; Zhao, Shifeng; Pan, Yunhe","Xiao, Jinxiao (School of Artificial Intelligence, Beijing Normal University, 100875, Beijing, China); Li, Yansong (School of Artificial Intelligence, Beijing Normal University, 100875, Beijing, China); Tian, Yun (School of Artificial Intelligence, Beijing Normal University, 100875, Beijing, China); Xu, Dongrong (Department of Psychiatry, Columbia University & New York State Psychiatric Institute, 10032, New York, USA; College of Computer Science and Technology, Zhejiang University, 310027, Hangzhou, China); Li, Penghui (School of Artificial Intelligence, Beijing Normal University, 100875, Beijing, China); Zhao, Shifeng (School of Artificial Intelligence, Beijing Normal University, 100875, Beijing, China); Pan, Yunhe (College of Computer Science and Technology, Zhejiang University, 310027, Hangzhou, China)","Tian, Yun (Beijing Normal University)","Xiao, Jinxiao (Beijing Normal University); Li, Yansong (Beijing Normal University); Tian, Yun (Beijing Normal University); Xu, Dongrong (NewYork–Presbyterian Hospital; Zhejiang University); Li, Penghui (Beijing Normal University); Zhao, Shifeng (Beijing Normal University); Pan, Yunhe (Zhejiang University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151307653,"40 Engineering; 4006 Communications Engineering; 4008 Electrical Engineering; 4009 Electronics, Sensors and Digital Hardware",,,,,,,,,,,,
1580,pub.1151155497,10.1007/978-3-031-16980-9_4,,,Pathology Synthesis of 3D Consistent Cardiac MR Images Using 2D VAEs and GANs,"We propose a method for synthesizing cardiac MR images with plausible heart shapes and realistic appearances for the purpose of generating labeled data for deep-learning (DL) training. It breaks down the image synthesis into label deformation and label-to-image translation tasks. The former is achieved via latent space interpolation in a VAE model, while the latter is accomplished via a conditional GAN model. We devise an approach for label manipulation in the latent space of the trained VAE model, namely pathology synthesis, aiming to synthesize a series of pseudo-pathological synthetic subjects with characteristics of a desired heart disease. Furthermore, we propose to model the relationship between 2D slices in the latent space of the VAE via estimating the correlation coefficient matrix between the latent vectors and utilizing it to correlate elements of randomly drawn samples before decoding to image space. This simple yet effective approach results in generating 3D consistent subjects from 2D slice-by-slice generations. Such an approach could provide a solution to diversify and enrich the available database of cardiac MR images and to pave the way for the development of generalizable DL based image analysis algorithms. The code will be available at https://github.com/sinaamirrajab/CardiacPathologySynthesis.","This research is a part of the OpenGTN project, supported by the European Union in the Marie Curie Innovative Training Networks (ITN) program under project No. 76446.",,Lecture Notes in Computer Science,Simulation and Synthesis in Medical Imaging,,2022-09-21,2022,2022-09-21,2022,13570,,34-42,All OA, Green,Chapter,"Amirrajab, Sina; Lorenz, Cristian; Weese, Juergen; Pluim, Josien; Breeuwer, Marcel","Amirrajab, Sina (Biomedical Engineering Department, Eindhoven University of Technology, Eindhoven, The Netherlands); Lorenz, Cristian (Philips Research Laboratories, Hamburg, Germany); Weese, Juergen (Philips Research Laboratories, Hamburg, Germany); Pluim, Josien (Biomedical Engineering Department, Eindhoven University of Technology, Eindhoven, The Netherlands); Breeuwer, Marcel (Biomedical Engineering Department, Eindhoven University of Technology, Eindhoven, The Netherlands; Philips Healthcare, MR R&D - Clinical Science, Best, The Netherlands)","Amirrajab, Sina (Eindhoven University of Technology)","Amirrajab, Sina (Eindhoven University of Technology); Lorenz, Cristian (Philips (Germany)); Weese, Juergen (Philips (Germany)); Pluim, Josien (Eindhoven University of Technology); Breeuwer, Marcel (Eindhoven University of Technology; Philips (Netherlands))",0,0,,,http://arxiv.org/pdf/2209.04223,https://app.dimensions.ai/details/publication/pub.1151155497,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
3947,pub.1151148790,10.3389/fcvm.2022.1009131,36204566,PMC9530662,Artificial intelligence in cardiac magnetic resonance fingerprinting,"Magnetic resonance fingerprinting (MRF) is a fast MRI-based technique that allows for multiparametric quantitative characterization of the tissues of interest in a single acquisition. In particular, it has gained attention in the field of cardiac imaging due to its ability to provide simultaneous and co-registered myocardial T1 and T2 mapping in a single breath-held cardiac MRF scan, in addition to other parameters. Initial results in small healthy subject groups and clinical studies have demonstrated the feasibility and potential of MRF imaging. Ongoing research is being conducted to improve the accuracy, efficiency, and robustness of cardiac MRF. However, these improvements usually increase the complexity of image reconstruction and dictionary generation and introduce the need for sequence optimization. Each of these steps increase the computational demand and processing time of MRF. The latest advances in artificial intelligence (AI), including progress in deep learning and the development of neural networks for MRI, now present an opportunity to efficiently address these issues. Artificial intelligence can be used to optimize candidate sequences and reduce the memory demand and computational time required for reconstruction and post-processing. Recently, proposed machine learning-based approaches have been shown to reduce dictionary generation and reconstruction times by several orders of magnitude. Such applications of AI should help to remove these bottlenecks and speed up cardiac MRF, improving its practical utility and allowing for its potential inclusion in clinical routine. This review aims to summarize the latest developments in artificial intelligence applied to cardiac MRF. Particularly, we focus on the application of machine learning at different steps of the MRF process, such as sequence optimization, dictionary generation and image reconstruction.",,"The authors acknowledge financial support from the BHF PG/18/59/33955 and RG/20/1/34802, EPSRC EP/V044087/1, EP/P001009, EP/P032311/1, EP/P007619, Wellcome EPSRC Center for Medical Engineering (NS/A000049/1), Millennium Institute for Intelligent Healthcare Engineering ICN2021_004, FONDECYT 1210637 and 1210638, ANID - Basal FB210024, Millenium Nucleus NCN19_161, and the Department of health via the National Institute for Health Research (NIHR) comprehensive Biomedical Research Center award to Guy's and St. Thomas' NHS Foundation Trust.",Frontiers in Cardiovascular Medicine,,,2022-09-20,2022,2022-09-20,,9,,1009131,All OA, Gold,Article,"Velasco, Carlos; Fletcher, Thomas J.; Botnar, René M.; Prieto, Claudia","Velasco, Carlos (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Fletcher, Thomas J. (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Botnar, René M. (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Institute for Biological and Medical Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Millennium Institute for Intelligent Healthcare Engineering, Santiago, Chile); Prieto, Claudia (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Institute for Biological and Medical Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Millennium Institute for Intelligent Healthcare Engineering, Santiago, Chile)","Velasco, Carlos (King's College London)","Velasco, Carlos (King's College London); Fletcher, Thomas J. (King's College London); Botnar, René M. (King's College London; Pontificia Universidad Católica de Chile); Prieto, Claudia (King's College London; Pontificia Universidad Católica de Chile)",0,0,,,https://www.frontiersin.org/articles/10.3389/fcvm.2022.1009131/pdf,https://app.dimensions.ai/details/publication/pub.1151148790,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
1070,pub.1151156014,10.1007/s10489-022-04118-7,,,A semantic segmentation model for lumbar MRI images using divergence loss,"Automatic diagnosis of lumbar diseases is very important for improving diagnostic efficiency and optimizing the allocation of medical resources. Lumbar spinal stenosis (LSS) is a common disease of the lumbar spine that causes lower back pain and leg pain. Some geometric indicators of axial lumbar magnetic resonance imaging (MRI), such as the intervertebral disc area, the dural sac area, and the anteroposterior diameter, are important for diagnosis and treatment. An important prestep for the automatic measurement of these geometric indicators is semantic image segmentation. Traditional medical image semantic segmentation models generally use the pixel-wise loss function as the optimization objective, which produces illogical segmentation results during inferring and interferes with subsequent measurements of geometric indicators. We introduce Gaussian divergence loss (DVG-loss) and, combined with contour loss, propose a new loss function to optimize the segmentation model and achieve better results in the lumbar MRI image segmentation task. The improvement brought by the proposed loss function is mainly reflected in the geometrical appearance of segmentation results instead of the pixel-wise quantitative metrics. But we must make sure that the quantitative metrics won’t deteriorate. So first, we compare the proposed method with previous models quantitatively. And then, ablation studies are conducted on different loss functions and it is shown that our proposed loss function considerably reduces the irregular edges and isolated island regions caused by misclassification.","This work was supported in part by key research and development program of Hebei Province, innovative product R &amp; D of wearable lumbar rehabilitation flexible exoskeleton robot under Grant 20371801D, in part by National key research and development program of China under Grant 2019YFB1312500.",,Applied Intelligence,,,2022-09-20,2022,2022-09-20,,,,1-14,Closed,Article,"Hou, Chao; Zhang, Weiqi; Wang, Hongbo; Liu, Fei; Liu, Defeng; Chang, Jingyuan","Hou, Chao (Academy for Engineering & Technology, Fudan University, 200082, Shanghai, China; Intelligent Robot Engineering Research Center of Ministry of Education, 2000433, Shanghai, China); Zhang, Weiqi (Academy for Engineering & Technology, Fudan University, 200082, Shanghai, China; Intelligent Robot Engineering Research Center of Ministry of Education, 2000433, Shanghai, China); Wang, Hongbo (Academy for Engineering & Technology, Fudan University, 200082, Shanghai, China; Intelligent Robot Engineering Research Center of Ministry of Education, 2000433, Shanghai, China); Liu, Fei (First Hospital of Qinhuangdao, 066000, Qinhuangdao, Hebei, China); Liu, Defeng (First Hospital of Qinhuangdao, 066000, Qinhuangdao, Hebei, China); Chang, Jingyuan (Parallel Robot and Mechatronic System Laboratory of Hebei Province, Organization, 066004, Qinhuangdao, Hebei, China)","Wang, Hongbo (Fudan University; ); Liu, Fei (First Hospital of Qinhuangdao)","Hou, Chao (Fudan University); Zhang, Weiqi (Fudan University); Wang, Hongbo (Fudan University); Liu, Fei (First Hospital of Qinhuangdao); Liu, Defeng (First Hospital of Qinhuangdao); Chang, Jingyuan ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151156014,46 Information and Computing Sciences,,,,,,,,,,,,
3791,pub.1151140027,10.3390/pharmaceutics14091964,36145711,PMC9503448,Modern Approaches for the Treatment of Heart Failure: Recent Advances and Future Perspectives,"Heart failure (HF) is a progressively deteriorating medical condition that significantly reduces both the patients' life expectancy and quality of life. Even though real progress was made in the past decades in the discovery of novel pharmacological treatments for HF, the prevention of premature deaths has only been marginally alleviated. Despite the availability of a plethora of pharmaceutical approaches, proper management of HF is still challenging. Thus, a myriad of experimental and clinical studies focusing on the discovery of new and provocative underlying mechanisms of HF physiopathology pave the way for the development of novel HF therapeutic approaches. Furthermore, recent technological advances made possible the development of various interventional techniques and device-based approaches for the treatment of HF. Since many of these modern approaches interfere with various well-known pathological mechanisms in HF, they have a real ability to complement and or increase the efficiency of existing medications and thus improve the prognosis and survival rate of HF patients. Their promising and encouraging results reported to date compel the extension of heart failure treatment beyond the classical view. The aim of this review was to summarize modern approaches, new perspectives, and future directions for the treatment of HF.",,This research received no external funding.,Pharmaceutics,,,2022-09-17,2022,2022-09-17,,14,9,1964,All OA, Gold,Article,"Popa, Irene Paula; Haba, Mihai Ștefan Cristian; Mărănducă, Minela Aida; Tănase, Daniela Maria; Șerban, Dragomir N.; Șerban, Lăcrămioara Ionela; Iliescu, Radu; Tudorancea, Ionuț","Popa, Irene Paula (Cardiology Clinic, “St. Spiridon” County Clinical Emergency Hospital, 700111 Iași, Romania); Haba, Mihai Ștefan Cristian (Cardiology Clinic, “St. Spiridon” County Clinical Emergency Hospital, 700111 Iași, Romania; Department of Internal Medicine, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iași, Romania); Mărănducă, Minela Aida (Department of Physiology, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iași, Romania); Tănase, Daniela Maria (Department of Internal Medicine, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iași, Romania; Internal Medicine Clinic, “St. Spiridon” County Clinical Emergency Hospital, 700115 Iași, Romania); Șerban, Dragomir N. (Department of Physiology, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iași, Romania); Șerban, Lăcrămioara Ionela (Department of Physiology, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iași, Romania); Iliescu, Radu (Department of Pharmacology, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iași, Romania); Tudorancea, Ionuț (Cardiology Clinic, “St. Spiridon” County Clinical Emergency Hospital, 700111 Iași, Romania; Department of Physiology, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iași, Romania)","Tudorancea, Ionuț (; Grigore T. Popa University of Medicine and Pharmacy)","Popa, Irene Paula (); Haba, Mihai Ștefan Cristian (Grigore T. Popa University of Medicine and Pharmacy); Mărănducă, Minela Aida (Grigore T. Popa University of Medicine and Pharmacy); Tănase, Daniela Maria (Grigore T. Popa University of Medicine and Pharmacy); Șerban, Dragomir N. (Grigore T. Popa University of Medicine and Pharmacy); Șerban, Lăcrămioara Ionela (Grigore T. Popa University of Medicine and Pharmacy); Iliescu, Radu (Grigore T. Popa University of Medicine and Pharmacy); Tudorancea, Ionuț (Grigore T. Popa University of Medicine and Pharmacy)",0,0,,,https://www.mdpi.com/1999-4923/14/9/1964/pdf?version=1663406517,https://app.dimensions.ai/details/publication/pub.1151140027,32 Biomedical and Clinical Sciences, 3214 Pharmacology and Pharmaceutical Sciences,3 Good Health and Well Being,,,,,,,,,
1395,pub.1151072755,10.1007/978-3-031-16449-1_67,,,vMFNet: Compositionality Meets Domain-Generalised Segmentation,"Training medical image segmentation models usually requires a large amount of labeled data. By contrast, humans can quickly learn to accurately recognise anatomy of interest from medical (e.g. MRI and CT) images with some limited guidance. Such recognition ability can easily generalise to new images from different clinical centres. This rapid and generalisable learning ability is mostly due to the compositional structure of image patterns in the human brain, which is less incorporated in medical image segmentation. In this paper, we model the compositional components (i.e. patterns) of human anatomy as learnable von-Mises-Fisher (vMF) kernels, which are robust to images collected from different domains (e.g. clinical centres). The image features can be decomposed to (or composed by) the components with the composing operations, i.e. the vMF likelihoods. The vMF likelihoods tell how likely each anatomical part is at each position of the image. Hence, the segmentation mask can be predicted based on the vMF likelihoods. Moreover, with a reconstruction module, unlabeled data can also be used to learn the vMF kernels and likelihoods by recombining them to reconstruct the input image. Extensive experiments show that the proposed vMFNet achieves improved generalisation performance on two benchmarks, especially when annotations are limited. Code is publicly available at: https://github.com/vios-s/vMFNet.","This work was supported by the University of Edinburgh, the Royal Academy of Engineering and Canon Medical Research Europe by a PhD studentship to Xiao Liu. This work was partially supported by the Alan Turing Institute under the EPSRC grant EP/N510129/1. S.A. Tsaftaris acknowledges the support of Canon Medical and the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme (grant RCSRF1819 8 25).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2022,,2022-09-17,2022,2022-09-17,2022,13437,,704-714,All OA, Green,Chapter,"Liu, Xiao; Thermos, Spyridon; Sanchez, Pedro; O’Neil, Alison Q.; Tsaftaris, Sotirios A.","Liu, Xiao (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; Canon Medical Research Europe Ltd., Edinburgh, UK); Thermos, Spyridon (AC Codewheel Ltd, Larnaca, Cyprus); Sanchez, Pedro (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; Canon Medical Research Europe Ltd., Edinburgh, UK); O’Neil, Alison Q. (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; Canon Medical Research Europe Ltd., Edinburgh, UK); Tsaftaris, Sotirios A. (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; The Alan Turing Institute, London, UK; Canon Medical Research Europe Ltd., Edinburgh, UK)","Liu, Xiao (University of Edinburgh; )","Liu, Xiao (University of Edinburgh); Thermos, Spyridon (Alexander College); Sanchez, Pedro (University of Edinburgh); O’Neil, Alison Q. (University of Edinburgh); Tsaftaris, Sotirios A. (University of Edinburgh; The Alan Turing Institute)",0,0,,,http://arxiv.org/pdf/2206.14538,https://app.dimensions.ai/details/publication/pub.1151072755,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1403,pub.1150997094,10.1007/978-3-031-16431-6_50,,,Scribble-Supervised Medical Image Segmentation via Dual-Branch Network and Dynamically Mixed Pseudo Labels Supervision,"Medical image segmentation plays an irreplaceable role in computer-assisted diagnosis, treatment planning and following-up. Collecting and annotating a large-scale dataset is crucial to training a powerful segmentation model, but producing high-quality segmentation masks is an expensive and time-consuming procedure. Recently, weakly-supervised learning that uses sparse annotations (points, scribbles, bounding boxes) for network training has achieved encouraging performance and shown the potential for annotation cost reduction. However, due to the limited supervision signal of sparse annotations, it is still challenging to employ them for networks training directly. In this work, we propose a simple yet efficient scribble-supervised image segmentation method and apply it to cardiac MRI segmentation. Specifically, we employ a dual-branch network with one encoder and two slightly different decoders for image segmentation and dynamically mix the two decoders’ predictions to generate pseudo labels for auxiliary supervision. By combining the scribble supervision and auxiliary pseudo labels supervision, the dual-branch network can efficiently learn from scribble annotations end-to-end. Experiments on the public ACDC dataset show that our method performs better than current scribble-supervised segmentation methods and also outperforms several semi-supervised segmentation methods. Code is available: https://github.com/HiLab-git/WSL4MIS.","This work was supported by the National Natural Science Foundations of China [81771921, 61901084] funding and key research and development project of Sichuan province, China [no. 2020YFG0084]. This work was also supported by the Beijing Nova Program [Z201100006820064].",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2022,,2022-09-15,2022,2022-09-15,2022,13431,,528-538,All OA, Green,Chapter,"Luo, Xiangde; Hu, Minhao; Liao, Wenjun; Zhai, Shuwei; Song, Tao; Wang, Guotai; Zhang, Shaoting","Luo, Xiangde (University of Electronic Science and Technology of China, Chengdu, China; Shanghai AI Lab, Shanghai, China); Hu, Minhao (SenseTime Research, Shanghai, China); Liao, Wenjun (University of Electronic Science and Technology of China, Chengdu, China); Zhai, Shuwei (University of Electronic Science and Technology of China, Chengdu, China); Song, Tao (SenseTime Research, Shanghai, China); Wang, Guotai (University of Electronic Science and Technology of China, Chengdu, China; Shanghai AI Lab, Shanghai, China); Zhang, Shaoting (University of Electronic Science and Technology of China, Chengdu, China; Shanghai AI Lab, Shanghai, China)","Wang, Guotai (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory)","Luo, Xiangde (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory); Hu, Minhao (); Liao, Wenjun (University of Electronic Science and Technology of China); Zhai, Shuwei (University of Electronic Science and Technology of China); Song, Tao (); Wang, Guotai (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory); Zhang, Shaoting (University of Electronic Science and Technology of China; Shanghai Artificial Intelligence Laboratory)",10,10,,,http://arxiv.org/pdf/2203.02106,https://app.dimensions.ai/details/publication/pub.1150997094,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
3783,pub.1139995701,10.1109/tpami.2021.3100536,34314356,,AbdomenCT-1K: Is Abdominal Organ Segmentation a Solved Problem?,"With the unprecedented developments in deep learning, automatic segmentation of main abdominal organs seems to be a solved problem as state-of-the-art (SOTA) methods have achieved comparable results with inter-rater variability on many benchmark datasets. However, most of the existing abdominal datasets only contain single-center, single-phase, single-vendor, or single-disease cases, and it is unclear whether the excellent performance can generalize on diverse datasets. This paper presents a large and diverse abdominal CT organ segmentation dataset, termed AbdomenCT-1K, with more than 1000 (1K) CT scans from 12 medical centers, including multi-phase, multi-vendor, and multi-disease cases. Furthermore, we conduct a large-scale study for liver, kidney, spleen, and pancreas segmentation and reveal the unsolved segmentation problems of the SOTA methods, such as the limited generalization ability on distinct medical centers, phases, and unseen diseases. To advance the unsolved problems, we further build four organ segmentation benchmarks for fully supervised, semi-supervised, weakly supervised, and continual learning, which are currently challenging and active research topics. Accordingly, we develop a simple and effective method for each benchmark, which can be used as out-of-the-box methods and strong baselines. We believe the AbdomenCT-1K dataset will promote future in-depth research towards clinical applicable abdominal organ segmentation methods.","This work was supported by China’s Ministry of Science and Technology under Grant 2020YFA0713800 and National Natural Science Foundation of China under Grants 11971229, No. 12090023.","This work was supported by China's Ministry of Science and Technology under Grant 2020YFA0713800 and National Natural Science Foundation of China under Grants 11971229, No. 12090023.",IEEE Transactions on Pattern Analysis and Machine Intelligence,,"Abdomen; Algorithms; Pancreas; Spleen; Tomography, X-Ray Computed",2022-09-14,2022,2022-09-14,2022-10,44,10,6695-6714,All OA, Green,Article,"Ma, Jun; Zhang, Yao; Gu, Song; Zhu, Cheng; Ge, Cheng; Zhang, Yichi; An, Xingle; Wang, Congcong; Wang, Qiyuan; Liu, Xin; Cao, Shucheng; Zhang, Qi; Liu, Shangqing; Wang, Yunpeng; Li, Yuhui; He, Jian; Yang, Xiaoping","Ma, Jun (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, 210094, China); Zhang, Yao (Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100864, China; University of Chinese Academy of Sciences, Beijing, 100049, China); Gu, Song (School of Automation, Nanjing University of Information Science and Technology, Nanjing, 210044, China); Zhu, Cheng (Shenzhen Haichuang Medical CO., LTD., Shenzhen, 518000, China); Ge, Cheng (Institute of Bioinformatics and Medical Engineering, Jiangsu University of Technology, Changzhou, 213001, China); Zhang, Yichi (School of Biological Science and Medical Engineering, Beihang University, Beijing, 100191, China); An, Xingle (Beijing Infervision Technology CO. LTD., Beijing, 100089, China); Wang, Congcong (School of Computer Science and Engineering, Tianjin University of Technology, Tianjin, 300222, China; Department of Computer Science, Norwegian University of Science and Technology, 7491, Trondheim, Norway); Wang, Qiyuan (School of Electronic Science and Engineering, Nanjing University, Nanjing, 210023, China); Liu, Xin (Suzhou LungCare Medical Technology Co., Ltd, Suzhou, 215021, China); Cao, Shucheng (Bioengineering, Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955, Saudi Arabia); Zhang, Qi (Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Taipa, Macau, 999078, China); Liu, Shangqing (School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China); Wang, Yunpeng (Institutes of Biomedical Sciences, Fudan University, Shanghai, 200433, China); Li, Yuhui (Computational Biology, University of Southern California, Los Angeles, CA, 90007, USA); He, Jian (Department of Nuclear Medicine, Nanjing Drum Tower Hospital, Nanjing, 210008, China); Yang, Xiaoping (Department of Mathematics, Nanjing University, Nanjing, 210023, China)","Ma, Jun (Nanjing University of Science and Technology)","Ma, Jun (Nanjing University of Science and Technology); Zhang, Yao (Institute of Computing Technology; University of Chinese Academy of Sciences); Gu, Song (Nanjing University of Information Science and Technology); Zhu, Cheng (); Ge, Cheng (Jiangsu University of Technology); Zhang, Yichi (Beihang University); An, Xingle (InferVision (China)); Wang, Congcong (Tianjin University of Technology; Norwegian University of Science and Technology); Wang, Qiyuan (Nanjing University); Liu, Xin (); Cao, Shucheng (King Abdullah University of Science and Technology); Zhang, Qi (University of Macau); Liu, Shangqing (Southern Medical University); Wang, Yunpeng (Fudan University); Li, Yuhui (University of Southern California); He, Jian (Nanjing Drum Tower Hospital); Yang, Xiaoping (Nanjing University)",65,65,,,https://repository.kaust.edu.sa/bitstream/10754/665793/1/Preprintfile1.pdf,https://app.dimensions.ai/details/publication/pub.1139995701,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1299,pub.1150988255,10.48550/arxiv.2209.05778,,,Self-supervised motion descriptor for cardiac phase detection in 4D CMR  based on discrete vector field estimations,"Cardiac magnetic resonance (CMR) sequences visualise the cardiac function
voxel-wise over time. Simultaneously, deep learning-based deformable image
registration is able to estimate discrete vector fields which warp one time
step of a CMR sequence to the following in a self-supervised manner. However,
despite the rich source of information included in these 3D+t vector fields, a
standardised interpretation is challenging and the clinical applications remain
limited so far. In this work, we show how to efficiently use a deformable
vector field to describe the underlying dynamic process of a cardiac cycle in
form of a derived 1D motion descriptor. Additionally, based on the expected
cardiovascular physiological properties of a contracting or relaxing ventricle,
we define a set of rules that enables the identification of five cardiovascular
phases including the end-systole (ES) and end-diastole (ED) without the usage
of labels. We evaluate the plausibility of the motion descriptor on two
challenging multi-disease, -center, -scanner short-axis CMR datasets. First, by
reporting quantitative measures such as the periodic frame difference for the
extracted phases. Second, by comparing qualitatively the general pattern when
we temporally resample and align the motion descriptors of all instances across
both datasets. The average periodic frame difference for the ED, ES key phases
of our approach is $0.80\pm{0.85}$, $0.69\pm{0.79}$ which is slightly better
than the inter-observer variability ($1.07\pm{0.86}$, $0.91\pm{1.6}$) and the
supervised baseline method ($1.18\pm{1.91}$, $1.21\pm{1.78}$). Code and labels
will be made available on our GitHub repository.
https://github.com/Cardio-AI/cmr-phase-detection",,,arXiv,,,2022-09-13,2022,,,,,,All OA, Green,Preprint,"Koehler, Sven; Hussain, Tarique; Hussain, Hamza; Young, Daniel; Sarikouch, Samir; Pickhardt, Thomas; Greil, Gerald; Engelhardt, Sandy","Koehler, Sven (); Hussain, Tarique (); Hussain, Hamza (); Young, Daniel (); Sarikouch, Samir (); Pickhardt, Thomas (); Greil, Gerald (); Engelhardt, Sandy ()",,"Koehler, Sven (); Hussain, Tarique (); Hussain, Hamza (); Young, Daniel (); Sarikouch, Samir (); Pickhardt, Thomas (); Greil, Gerald (); Engelhardt, Sandy ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150988255,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1010,pub.1151183568,10.48550/arxiv.2209.09641,,,Calibrating Segmentation Networks with Margin-based Label Smoothing,"Despite the undeniable progress in visual recognition tasks fueled by deep
neural networks, there exists recent evidence showing that these models are
poorly calibrated, resulting in over-confident predictions. The standard
practices of minimizing the cross entropy loss during training promote the
predicted softmax probabilities to match the one-hot label assignments.
Nevertheless, this yields a pre-softmax activation of the correct class that is
significantly larger than the remaining activations, which exacerbates the
miscalibration problem. Recent observations from the classification literature
suggest that loss functions that embed implicit or explicit maximization of the
entropy of predictions yield state-of-the-art calibration performances. Despite
these findings, the impact of these losses in the relevant task of calibrating
medical image segmentation networks remains unexplored. In this work, we
provide a unifying constrained-optimization perspective of current
state-of-the-art calibration losses. Specifically, these losses could be viewed
as approximations of a linear penalty (or a Lagrangian term) imposing equality
constraints on logit distances. This points to an important limitation of such
underlying equality constraints, whose ensuing gradients constantly push
towards a non-informative solution, which might prevent from reaching the best
compromise between the discriminative performance and calibration of the model
during gradient-based optimization. Following our observations, we propose a
simple and flexible generalization based on inequality constraints, which
imposes a controllable margin on logit distances. Comprehensive experiments on
a variety of public medical image segmentation benchmarks demonstrate that our
method sets novel state-of-the-art results on these tasks in terms of network
calibration, whereas the discriminative performance is also improved.",,,arXiv,,,2022-09-09,2022,,,,,,All OA, Green,Preprint,"Murugesan, Balamurali; Liu, Bingyuan; Galdran, Adrian; Ayed, Ismail Ben; Dolz, Jose","Murugesan, Balamurali (); Liu, Bingyuan (); Galdran, Adrian (); Ayed, Ismail Ben (); Dolz, Jose ()",,"Murugesan, Balamurali (); Liu, Bingyuan (); Galdran, Adrian (); Ayed, Ismail Ben (); Dolz, Jose ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151183568,46 Information and Computing Sciences, 4611 Machine Learning,10 Reduced Inequalities,,,,,,,,,
5706,pub.1150792361,10.1007/s00392-022-02088-x,36066609,,Towards automatic classification of cardiovascular magnetic resonance Task Force Criteria for diagnosis of arrhythmogenic right ventricular cardiomyopathy,"BackgroundArrhythmogenic right ventricular cardiomyopathy (ARVC) is diagnosed according to the Task Force Criteria (TFC) in which cardiovascular magnetic resonance (CMR) imaging plays an important role. Our study aims to apply an automatic deep learning-based segmentation for right and left ventricular CMR assessment and evaluate this approach for classification of the CMR TFC.MethodsWe included 227 subjects suspected of ARVC who underwent CMR. Subjects were classified into (1) ARVC patients fulfilling TFC; (2) at-risk family members; and (3) controls. To perform automatic segmentation, a Bayesian Dilated Residual Neural Network was trained and tested. Performance of automatic versus manual segmentation was assessed using Dice-coefficient and Hausdorff distance. Since automatic segmentation is most challenging in basal slices, manual correction of the automatic segmentation in the most basal slice was simulated (automatic−basal). CMR TFC calculated using manual and automatic−basal segmentation were compared using Cohen’s Kappa (κ).ResultsAutomatic segmentation was trained on CMRs of 70 subjects (39.6 ± 18.1 years, 47% female) and tested on 157 subjects (36.9 ± 17.6 years, 59% female). Dice-coefficient and Hausdorff distance showed good agreement between manual and automatic segmentations (≥ 0.89 and ≤ 10.6 mm, respectively) which further improved after simulated correction of the most basal slice (≥ 0.92 and ≤ 9.2 mm, p < 0.001). Pearson correlation of volumetric and functional CMR measurements was good to excellent (automatic (r = 0.78–0.99, p < 0.001) and automatic−basal (r = 0.88–0.99, p < 0.001) measurements). CMR TFC classification using automatic−basal segmentations was comparable to manual segmentations (κ 0.98 ± 0.02) with comparable diagnostic performance.ConclusionsCombining automatic segmentation of CMRs with correction of the most basal slice results in accurate CMR TFC classification of subjects suspected of ARVC.Graphical abstract",We thank the ARVC patients and families who have made this work possible.,"Dr. Bourfiss is supported by the Alexandre Suerman Stipend of the UMC Utrecht (2017). J. Sander is supported by the Dutch Technology Foundation (DLMedIA program (P15-26)) with participation of Pie Medical Imaging. Dr. te Riele is supported by the Dutch Heart Foundation (grant no. 2015T058), the UMC Utrecht Fellowship Clinical Research Talent, and the CVON PREDICT Young Talent Program. Dr. Asselbergs is supported by UCL Hospitals NIHR Biomedical Research Center. The Netherlands ACM Registry (www.acmregistry.nl) is supported by the Netherlands Heart Institute (project 06901).",Clinical Research in Cardiology,,,2022-09-06,2022,2022-09-06,2022-09-06,,,1-16,All OA, Hybrid,Article,"Bourfiss, Mimount; Sander, Jörg; de Vos, Bob D.; te Riele, Anneline S. J. M.; Asselbergs, Folkert W.; Išgum, Ivana; Velthuis, Birgitta K.","Bourfiss, Mimount (Department of Medicine, Division of Cardiology, University Medical Center Utrecht, Utrecht University, Heidelberglaan 100, 3584 CX, Utrecht, The Netherlands); Sander, Jörg (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers, University of Amsterdam, Amsterdam, The Netherlands); de Vos, Bob D. (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers, University of Amsterdam, Amsterdam, The Netherlands; Amsterdam Cardiovascular Sciences, Heart Failure & Arrhythmias, Amsterdam, The Netherlands); te Riele, Anneline S. J. M. (Department of Medicine, Division of Cardiology, University Medical Center Utrecht, Utrecht University, Heidelberglaan 100, 3584 CX, Utrecht, The Netherlands; Netherlands Heart Institute, Utrecht, The Netherlands); Asselbergs, Folkert W. (Department of Medicine, Division of Cardiology, University Medical Center Utrecht, Utrecht University, Heidelberglaan 100, 3584 CX, Utrecht, The Netherlands; Institute of Cardiovascular Science, Faculty of Population Health Sciences, University College London, London, UK; Health Data Research UK and Institute of Health Informatics, University College London, London, UK); Išgum, Ivana (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers, University of Amsterdam, Amsterdam, The Netherlands; Amsterdam Cardiovascular Sciences, Heart Failure & Arrhythmias, Amsterdam, The Netherlands; Department of Radiology and Nuclear Medicine, Amsterdam University Medical Centers, University of Amsterdam, Amsterdam, The Netherlands); Velthuis, Birgitta K. (Department of Radiology, University Medical Center Utrecht, Utrecht University, Utrecht, The Netherlands)","Bourfiss, Mimount (University Medical Center Utrecht; Utrecht University)","Bourfiss, Mimount (University Medical Center Utrecht; Utrecht University); Sander, Jörg (University of Amsterdam); de Vos, Bob D. (University of Amsterdam); te Riele, Anneline S. J. M. (University Medical Center Utrecht; Utrecht University; Netherlands Heart Institute); Asselbergs, Folkert W. (University Medical Center Utrecht; Utrecht University; University College London; Health Data Research UK; University College London); Išgum, Ivana (University of Amsterdam; University of Amsterdam); Velthuis, Birgitta K. (University Medical Center Utrecht; Utrecht University)",0,0,,,https://link.springer.com/content/pdf/10.1007/s00392-022-02088-x.pdf,https://app.dimensions.ai/details/publication/pub.1150792361,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1651,pub.1150817416,10.48550/arxiv.2209.02470,,,Multi-task Swin Transformer for Motion Artifacts Classification and  Cardiac Magnetic Resonance Image Segmentation,"Cardiac Magnetic Resonance Imaging is commonly used for the assessment of the
cardiac anatomy and function. The delineations of left and right ventricle
blood pools and left ventricular myocardium are important for the diagnosis of
cardiac diseases. Unfortunately, the movement of a patient during the CMR
acquisition procedure may result in motion artifacts appearing in the final
image. Such artifacts decrease the diagnostic quality of CMR images and force
redoing of the procedure. In this paper, we present a Multi-task Swin UNEt
TRansformer network for simultaneous solving of two tasks in the CMRxMotion
challenge: CMR segmentation and motion artifacts classification. We utilize
both segmentation and classification as a multi-task learning approach which
allows us to determine the diagnostic quality of CMR and generate masks at the
same time. CMR images are classified into three diagnostic quality classes,
whereas, all samples with non-severe motion artifacts are being segmented.
Ensemble of five networks trained using 5-Fold Cross-validation achieves
segmentation performance of DICE coefficient of 0.871 and classification
accuracy of 0.595.",,,arXiv,,,2022-09-06,2022,,,,,,All OA, Green,Preprint,"Grzeszczyk, Michal K.; Płotka, Szymon; Sitek, Arkadiusz","Grzeszczyk, Michal K. (); Płotka, Szymon (); Sitek, Arkadiusz ()",,"Grzeszczyk, Michal K. (); Płotka, Szymon (); Sitek, Arkadiusz ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150817416,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
4788,pub.1150681747,10.1016/j.cmpb.2022.107099,36116398,,Efficient Combination of CNN and Transformer for Dual-Teacher Uncertainty-guided Semi-supervised Medical Image Segmentation,"BACKGROUND AND OBJECTIVE: Deep learning-based methods for fast target segmentation of magnetic resonance imaging (MRI) have become increasingly popular in recent years. Generally, the success of deep learning methods in medical image segmentation tasks relies on a large amount of labeled data. The time-consuming and labor-intensive problem of data annotation is a major challenge in medical image segmentation tasks. The aim of this work is to enhance the segmentation of MR images using a semi-supervised learning-based method using a small amount of labeled data and a large amount of unlabeled data.
METHODS: To utilize the effective information of the unlabeled data, we designed the method of guiding the Student segmentation model simultaneously by the Dual-Teacher structure of CNN and transformer forming the subject network. Both Teacher A and Student models are CNNs, and the TA-S module they form is a mean teacher structure with added data noise. In the TB-S module formed by the combination of Student and Teacher B models, their backbone networks CNN and transformer capture the local and global information of the image at the same time, respectively, to create pseudo labels for each other and perform cross-supervision. The Dual-Teacher guides the Student through synchronous training and performs knowledge rectification and communication with each other through consistent regular constraints, which better utilizes the valid information in the unlabeled data. In addition, the segmentation predictions of Teacher A and Student and Teacher A and Teacher B are screened for uncertainty assessment during the training process to enhance the prediction accuracy and generalization of the model. This method uses the mechanism of simultaneous training of the synthetic structure composed of TA-S and TB-S modules to jointly guide the optimization of the Student model to obtain better segmentation ability.
RESULTS: We evaluated the proposed method on a publicly available MRI dataset from a cardiac segmentation competition organized by MICCAI in 2017. Compared with several existing state-of-the-art semi-supervised segmentation methods, the method achieves better segmentation results in terms of Dice coefficient and HD distance evaluation metrics of 0.878 and 4.9 mm and 0.886 and 5.0 mm, respectively, using a training set containing only 10% and 20% of labeled data.
CONCLUSION: This method fuses CNN and transformer to design a new Teacher-Student semi-supervised learning optimization strategy, which greatly improves the utilization of a large number of unlabeled medical images and the effectiveness of model segmentation results.","The authors are grateful to the reviewers for their valuable comments, which have greatly improved the paper. This work was supported by the Natural Science Foundation of Jiangsu Province of China under Grant BK20190079, National Natural Science Foundation of China under Grants U2141234 and 62176105, the Key Research and Development Program of China under Grant 2017YFE0128500.",,Computer Methods and Programs in Biomedicine,,"Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Uncertainty; Supervised Machine Learning; Magnetic Resonance Imaging",2022-09-02,2022,2022-09-02,2022-11,226,,107099,Closed,Article,"Xiao, Zhiyong; Su, Yixin; Deng, Zhaohong; Zhang, Weidong","Xiao, Zhiyong (School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi214122, China.); Su, Yixin (School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi214122, China.); Deng, Zhaohong (School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi214122, China.); Zhang, Weidong (Department of Automation, Shanghai JiaoTong University, Shanghai200240, China. Electronic address: wdzhang@sjtu.edu.cn.)","Zhang, Weidong (Shanghai Jiao Tong University)","Xiao, Zhiyong (Jiangnan University); Su, Yixin (Jiangnan University); Deng, Zhaohong (Jiangnan University); Zhang, Weidong (Shanghai Jiao Tong University)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1150681747,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
4526,pub.1150712156,10.3390/biomedicines10092157,36140258,PMC9495955,Interplay between Artificial Intelligence and Biomechanics Modeling in the Cardiovascular Disease Prediction,"Cardiovascular disease (CVD) is the most common cause of morbidity and mortality worldwide, and early accurate diagnosis is the key point for improving and optimizing the prognosis of CVD. Recent progress in artificial intelligence (AI), especially machine learning (ML) technology, makes it possible to predict CVD. In this review, we first briefly introduced the overview development of artificial intelligence. Then we summarized some ML applications in cardiovascular diseases, including ML-based models to directly predict CVD based on risk factors or medical imaging findings and the ML-based hemodynamics with vascular geometries, equations, and methods for indirect assessment of CVD. We also discussed case studies where ML could be used as the surrogate for computational fluid dynamics in data-driven models and physics-driven models. ML models could be a surrogate for computational fluid dynamics, accelerate the process of disease prediction, and reduce manual intervention. Lastly, we briefly summarized the research difficulties and prospected the future development of AI technology in cardiovascular diseases.",,"This work was funded by the National Natural Science Research Foundation of China Grants-in-Aid (No. 11827803, 31971244, 31570947, 32071311, and U20A20390).",Biomedicines,,,2022-09-01,2022,2022-09-01,,10,9,2157,All OA, Gold,Article,"Li, Xiaoyin; Liu, Xiao; Deng, Xiaoyan; Fan, Yubo","Li, Xiaoyin (Beijing Advanced Innovation Centre for Biomedical Engineering, Key Laboratory for Biomechanics and Mechanobiology of Chinese Education Ministry, School of Biological Science and Medical Engineering, Beihang University, Beijing 100083, China.); Liu, Xiao (Beijing Advanced Innovation Centre for Biomedical Engineering, Key Laboratory for Biomechanics and Mechanobiology of Chinese Education Ministry, School of Biological Science and Medical Engineering, Beihang University, Beijing 100083, China.); Deng, Xiaoyan (Beijing Advanced Innovation Centre for Biomedical Engineering, Key Laboratory for Biomechanics and Mechanobiology of Chinese Education Ministry, School of Biological Science and Medical Engineering, Beihang University, Beijing 100083, China.); Fan, Yubo (Beijing Advanced Innovation Centre for Biomedical Engineering, Key Laboratory for Biomechanics and Mechanobiology of Chinese Education Ministry, School of Biological Science and Medical Engineering, Beihang University, Beijing 100083, China.; School of Engineering Medicine, Beihang University, Beijing 100083, China.)","Liu, Xiao (Beihang University); Fan, Yubo (Beihang University; Beihang University)","Li, Xiaoyin (Beihang University); Liu, Xiao (Beihang University); Deng, Xiaoyan (Beihang University); Fan, Yubo (Beihang University; Beihang University)",0,0,,,https://www.mdpi.com/2227-9059/10/9/2157/pdf?version=1662112182,https://app.dimensions.ai/details/publication/pub.1150712156,31 Biological Sciences, 3101 Biochemistry and Cell Biology, 32 Biomedical and Clinical Sciences, 3214 Pharmacology and Pharmaceutical Sciences, 34 Chemical Sciences, 3404 Medicinal and Biomolecular Chemistry,3 Good Health and Well Being,,,,,
1517,pub.1150755698,10.48550/arxiv.2209.00726,,,Learning correspondences of cardiac motion from images using  biomechanics-informed modeling,"Learning spatial-temporal correspondences in cardiac motion from images is
important for understanding the underlying dynamics of cardiac anatomical
structures. Many methods explicitly impose smoothness constraints such as the
$\mathcal{L}_2$ norm on the displacement vector field (DVF), while usually
ignoring biomechanical feasibility in the transformation. Other geometric
constraints either regularize specific regions of interest such as imposing
incompressibility on the myocardium or introduce additional steps such as
training a separate network-based regularizer on physically simulated datasets.
In this work, we propose an explicit biomechanics-informed prior as
regularization on the predicted DVF in modeling a more generic biomechanically
plausible transformation within all cardiac structures without introducing
additional training complexity. We validate our methods on two publicly
available datasets in the context of 2D MRI data and perform extensive
experiments to illustrate the effectiveness and robustness of our proposed
methods compared to other competing regularization schemes. Our proposed
methods better preserve biomechanical properties by visual assessment and show
advantages in segmentation performance using quantitative evaluation metrics.
The code is publicly available at
\url{https://github.com/Voldemort108X/bioinformed_reg}.",,,arXiv,,,2022-09-01,2022,,,,,,All OA, Green,Preprint,"Zhang, Xiaoran; You, Chenyu; Ahn, Shawn; Zhuang, Juntang; Staib, Lawrence; Duncan, James","Zhang, Xiaoran (); You, Chenyu (); Ahn, Shawn (); Zhuang, Juntang (); Staib, Lawrence (); Duncan, James ()",,"Zhang, Xiaoran (); You, Chenyu (); Ahn, Shawn (); Zhuang, Juntang (); Staib, Lawrence (); Duncan, James ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150755698,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1396,pub.1150679818,10.48550/arxiv.2209.00314,,,Self-Supervised Pretraining for 2D Medical Image Segmentation,"Supervised machine learning provides state-of-the-art solutions to a wide
range of computer vision problems. However, the need for copious labelled
training data limits the capabilities of these algorithms in scenarios where
such input is scarce or expensive. Self-supervised learning offers a way to
lower the need for manually annotated data by pretraining models for a specific
domain on unlabelled data. In this approach, labelled data are solely required
to fine-tune models for downstream tasks. Medical image segmentation is a field
where labelling data requires expert knowledge and collecting large labelled
datasets is challenging; therefore, self-supervised learning algorithms promise
substantial improvements in this field. Despite this, self-supervised learning
algorithms are used rarely to pretrain medical image segmentation networks. In
this paper, we elaborate and analyse the effectiveness of supervised and
self-supervised pretraining approaches on downstream medical image
segmentation, focusing on convergence and data efficiency. We find that
self-supervised pretraining on natural images and target-domain-specific images
leads to the fastest and most stable downstream convergence. In our experiments
on the ACDC cardiac segmentation dataset, this pretraining approach achieves
4-5 times faster fine-tuning convergence compared to an ImageNet pretrained
model. We also show that this approach requires less than five epochs of
pretraining on domain-specific data to achieve such improvement in the
downstream convergence time. Finally, we find that, in low-data scenarios,
supervised ImageNet pretraining achieves the best accuracy, requiring less than
100 annotated samples to realise close to minimal error.",,,arXiv,,,2022-09-01,2022,,,,,,All OA, Green,Preprint,"Kalapos, András; Gyires-Tóth, Bálint","Kalapos, András (); Gyires-Tóth, Bálint ()",,"Kalapos, András (); Gyires-Tóth, Bálint ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150679818,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4611 Machine Learning,,,,,,,,,
1014,pub.1154832594,10.1007/978-3-031-15542-0_15,,,Left Ventricle Volume Analysis in Cardiac MRI Images Using Convolutional Neural Networks,"Cardiac magnetic resonance imaging is used to detect cardiovascular diseases in the early stage of diagnosis, preventing cardiac disease worsening. There are numerous methods to detect cardiac diseases in the early stages. But in this chapter, we discussed convolutional neural networks, which are used to predict cardiovascular diseases. Convolutional neural networks are used for image segmentation, particularly for finding left ventricle volume segmentation in a short-axis view (SAX) image. The dataset we used is from Kaggle’s Second Annual Data Science Bowl (SADSB), which has 500 patients’ cardiac images for training, 200 patients’ cardiac images for validation that can be used for training, and 440 patients’ cardiac images for testing. The metrics we used are continuous ranked probability score (CRPS) used for the Kaggle’s Second Annual Data Science Bowl challenge evaluation. The proposed model achieved the CRPS value of 0.043 on the test.",,,EAI/Springer Innovations in Communication and Computing,Role of Data-Intensive Distributed Computing Systems in Designing Data Solutions,,2022-09-01,2022,2022-09-01,2023,,,295-320,Closed,Chapter,"Yadhav, Palakala Sai Krishna; Kumar, K. Susheel; Singh, Nagendra Pratap","Yadhav, Palakala Sai Krishna (Department of Computer Science and Engineering, National Institute of Technology Hamirpur, Hamirpur, India); Kumar, K. Susheel (Department of Computer Science and Engineering, National Institute of Technology Hamirpur, Hamirpur, India); Singh, Nagendra Pratap (Department of Computer Science and Engineering, National Institute of Technology Hamirpur, Hamirpur, India)","Yadhav, Palakala Sai Krishna (National Institute of Technology Hamirpur)","Yadhav, Palakala Sai Krishna (National Institute of Technology Hamirpur); Kumar, K. Susheel (National Institute of Technology Hamirpur); Singh, Nagendra Pratap (National Institute of Technology Hamirpur)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154832594,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,3 Good Health and Well Being,,,,,,,,,
1295,pub.1149760557,10.1016/j.bspc.2022.103960,,,Combining edge guidance and feature pyramid for medical image segmentation,"Automatic segmentation of medical images is very important for computer-aided diagnosis. The U-shaped and skip-connection based on convolution (UNet) has achieved the most advanced performance in the field of medical image segmentation. However, most existing UNet-based methods have the problem of coarse segmentation of tissue edges. We propose a novel edge guidance feature pyramid network (EGFPNet) for medical image segmentation with the following contributions. First, we synthesize local edge information and global location information to obtain tissue edge features. Second, in order to better utilize the edge information, we propose an edge guidance feature pyramid (EGFP). Edge features interact with area features of different scales to form complementary features of different scales. These complementary features of different scales also interact to represent the complete information of the tissue and improve the adaptability to different tissue scales. We compare with state-of-the-art medical image segmentation methods on the automated cardiac diagnosis challenge (ACDC) and the 2018 atrial segmentation challenge (2018 ASC). Our method achieved average dice score of 0.929 for right ventricle (RV), 0.886 for myocardium (Myo), 0.958 for left ventricle (LV), and 0.920 for left atrium (LA). Experimental results on two medical image segmentation datasets show that our method outperforms six state-of-the-art medical image segmentation methods. The code is available at https://github.com/jinancsl/EGFPNet.","The author thanks the whole authors in the referred articles. In addition, the author would also like to thank Jiuying Chen and Ruiyang Guo. This work was supported in part by the Science and Technology Planning Project of Guangdong Science and Technology Department under Grant Guangdong Key Laboratory of Advanced IntelliSense Technology (2019B121203006).",,Biomedical Signal Processing and Control,,,2022-09,2022,,2022-09,78,,103960,Closed,Article,"Chen, Shaolong; Qiu, Changzhen; Yang, Weiping; Zhang, Zhiyong","Chen, Shaolong (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China); Qiu, Changzhen (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China); Yang, Weiping (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China); Zhang, Zhiyong (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China)","Zhang, Zhiyong (Sun Yat-sen University)","Chen, Shaolong (Sun Yat-sen University); Qiu, Changzhen (Sun Yat-sen University); Yang, Weiping (Sun Yat-sen University); Zhang, Zhiyong (Sun Yat-sen University)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1149760557,40 Engineering, 4003 Biomedical Engineering,3 Good Health and Well Being,,,,,,,,,,
1210,pub.1148786291,10.1016/j.bspc.2022.103870,,,DC-net: Dual-Consistency semi-supervised learning for 3D left atrium segmentation from MRI,"Objective: Left atrial segmentation is very important for the treatment of atrial fibrillation. One factor limiting the automatic segmentation of the left atrium is that training network needs a large amount of labeled data, which is expensive and time-consuming. Using limited labeled data for accurate segmentation is our key concern. Methods: In this work, we propose a novel dual-consistency semi-supervised learning method for left atrium segmentation from 3D MR images. Our framework can effectively leverage limited labeled data and abundant unlabeled data by enforcing consistent predictions under model-level and structure-level perturbations. As for model-level perturbations, we employ a shared encoder and two slightly different decoders. Different decoders can output different predictions. As for structure-level spatial contextual perturbations, two sub-volumes with an overlapping region are randomly cropped, taking as inputs under different spatial contexts. Therefore, the proposed method can maintain the invariance of segmentation results when perturbed by different spatial contexts, and be robust to slight perturbations of networks. Results: Our method are evaluated on the public Atrial Segmentation Challenge dataset. The evaluation metrics of Dice, Jaccard, ASD and 95HD are 90.05%, 82.01%, 1.74 voxel and 7.03 voxel when we use 20% labeled data and 80% unlabeled data. The results show that the proposed method outperforms other exiting semi-supervised methods. Conclusion and Significance: The proposed semi-supervised method can achieve accurate segmentation of left atrium by utilizing limited labeled data and abundant unlabeled data, offering an effective way for doctors to diagnose and treat atrial fibrillation.","This work was supported partly by the Fundamental Research Funds for the Central Universities (Grant No. 2020XD-A04-2), partly by the National Natural Science Foundation of China (Grant No. 62173045, 61673192), and partly supported by BUPT Excellent Ph.D. Students Foundation (CX2021314), partially supported by the Research Grant Council (RGC) of Hong Kong under Grant 11212321 and Grant ECS-21212720, Basic and Applied Basic Research Foundation of Guangdong Province under Grant 2019A1515110175, and Science Technology and Innovation Committee of Shenzhen under Grant SGDX20210823104001011.",,Biomedical Signal Processing and Control,,,2022-09,2022,,2022-09,78,,103870,Closed,Article,"Wang, Junying; Liu, Xiaoli; Yin, Jianqin; Ding, Pengxiang","Wang, Junying (Beijing University of Posts and Telecommunications, Beijing, China); Liu, Xiaoli (Beijing University of Posts and Telecommunications, Beijing, China); Yin, Jianqin (Beijing University of Posts and Telecommunications, Beijing, China); Ding, Pengxiang (Beijing University of Posts and Telecommunications, Beijing, China)","Yin, Jianqin (Beijing University of Posts and Telecommunications)","Wang, Junying (Beijing University of Posts and Telecommunications); Liu, Xiaoli (Beijing University of Posts and Telecommunications); Yin, Jianqin (Beijing University of Posts and Telecommunications); Ding, Pengxiang (Beijing University of Posts and Telecommunications)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1148786291,"30 Agricultural, Veterinary and Food Sciences; 3006 Food Sciences; 40 Engineering; 4003 Biomedical Engineering",,,,,,,,,,,,
5053,pub.1150632306,10.1109/tmi.2022.3203309,36044487,PMC7614102,A Persistent Homology-Based Topological Loss for CNN-Based Multiclass Segmentation of CMR,"Multi-class segmentation of cardiac magnetic resonance (CMR) images seeks a separation of data into anatomical components with known structure and configuration. The most popular CNN-based methods are optimised using pixel wise loss functions, ignorant of the spatially extended features that characterise anatomy. Therefore, whilst sharing a high spatial overlap with the ground truth, inferred CNN-based segmentations can lack coherence, including spurious connected components, holes and voids. Such results are implausible, violating anticipated anatomical topology. In response, (single-class) persistent homology-based loss functions have been proposed to capture global anatomical features. Our work extends these approaches to the task of multi-class segmentation. Building an enriched topological description of all class labels and class label pairs, our loss functions make predictable and statistically significant improvements in segmentation topology using a CNN-based post-processing framework. We also present (and make available) a highly efficient implementation based on cubical complexes and parallel execution, enabling practical application within high resolution 3D data for the first time. We demonstrate our approach on 2D short axis and 3D whole heart CMR segmentation, advancing a detailed and faithful analysis of performance on two publicly available datasets.",,"This work was supported in part by the Engineering and Physical Sciences Research Council (EPSRC) Programme under Grant SmartHeart EP/P001009/1; in part by the Wellcome Trust Innovative Engineering for Health (IEH) under Award 102431; in part by the Wellcome EPSRC Centre for Medical Engineering, School of Biomedical Engineering and Imaging Sciences (BMEIS), King’s College London (KCL), under Grant WT 203148/Z/16/Z; and in part by the National Institute for Health and Care Research (NIHR) Biomedical Research Centre at Guys and St Thomas NHS Foundation Trust (GSTT) and King’s College London. The work of Nick Byrne was supported by NIHR through the Doctoral Research Fellow under Grant DRF-2017-10-085.",IEEE Transactions on Medical Imaging,,,2022-08-31,2022,2022-08-31,2022-08-31,42,1,3-14,All OA, Green,Article,"Byrne, Nick; Clough, James R.; Valverde, Israel; Montana, Giovanni; King, Andrew P.","Byrne, Nick (School of BMEIS, KCL, London, SE1 7EH, U.K.; Medical Physics Department, GSTT, London, SE1 7EH, U.K.); Clough, James R. (School of BMEIS, KCL, London, SE1 7EH, U.K.); Valverde, Israel (School of BMEIS, KCL, London, SE1 7EH, U.K.; Paediatric Cardiology Department, GSTT, London, SE1 7EH, U.K.); Montana, Giovanni (Warwick Manufacturing Group, University of Warwick, Coventry, CV4 7AL, U.K.); King, Andrew P. (School of BMEIS, KCL, London, SE1 7EH, U.K.)","Byrne, Nick (King's College London; )","Byrne, Nick (King's College London); Clough, James R. (King's College London); Valverde, Israel (King's College London); Montana, Giovanni (University of Warwick); King, Andrew P. (King's College London)",0,0,,,http://arxiv.org/pdf/2107.12689,https://app.dimensions.ai/details/publication/pub.1150632306,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1454,pub.1150679627,10.48550/arxiv.2209.00123,,,Addressing Class Imbalance in Semi-supervised Image Segmentation: A  Study on Cardiac MRI,"Due to the imbalanced and limited data, semi-supervised medical image
segmentation methods often fail to produce superior performance for some
specific tailed classes. Inadequate training for those particular classes could
introduce more noise to the generated pseudo labels, affecting overall
learning. To alleviate this shortcoming and identify the under-performing
classes, we propose maintaining a confidence array that records class-wise
performance during training. A fuzzy fusion of these confidence scores is
proposed to adaptively prioritize individual confidence metrics in every sample
rather than traditional ensemble approaches, where a set of predefined fixed
weights are assigned for all the test cases. Further, we introduce a robust
class-wise sampling method and dynamic stabilization for a better training
strategy. Our proposed method considers all the under-performing classes with
dynamic weighting and tries to remove most of the noises during training. Upon
evaluation on two cardiac MRI datasets, ACDC and MMWHS, our proposed method
shows effectiveness and generalizability and outperforms several
state-of-the-art methods found in the literature.",,,arXiv,,,2022-08-31,2022,,,,,,All OA, Green,Preprint,"Basak, Hritam; Ghosal, Sagnik; Sarkar, Ram","Basak, Hritam (); Ghosal, Sagnik (); Sarkar, Ram ()",,"Basak, Hritam (); Ghosal, Sagnik (); Sarkar, Ram ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150679627,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
4154,pub.1150555625,10.1016/j.media.2022.102597,36095907,,Enhancing MR image segmentation with realistic adversarial data augmentation,"The success of neural networks on medical image segmentation tasks typically relies on large labeled datasets for model training. However, acquiring and manually labeling a large medical image set is resource-intensive, expensive, and sometimes impractical due to data sharing and privacy issues. To address this challenge, we propose AdvChain, a generic adversarial data augmentation framework, aiming at improving both the diversity and effectiveness of training data for medical image segmentation tasks. AdvChain augments data with dynamic data augmentation, generating randomly chained photo-metric and geometric transformations to resemble realistic yet challenging imaging variations to expand training data. By jointly optimizing the data augmentation model and a segmentation network during training, challenging examples are generated to enhance network generalizability for the downstream task. The proposed adversarial data augmentation does not rely on generative networks and can be used as a plug-in module in general segmentation networks. It is computationally efficient and applicable for both low-shot supervised and semi-supervised learning. We analyze and evaluate the method on two MR image segmentation tasks: cardiac segmentation and prostate segmentation with limited labeled data. Results show that the proposed approach can alleviate the need for labeled data while improving model generalization ability, indicating its practical value in medical imaging applications.","This work was supported by two EPSRC Grants (EP/P001009/1, EP/R005982/1) and the ERC Grant (884622). W. Bai was supported by EPSRC DeepGeM Grant (EP/W01842X/1). S. Wang was supported by the Shanghai Sailing Programs of Shanghai Municipal Science and Technology Committee, China (22YF1409300).",,Medical Image Analysis,,"Humans; Male; Image Processing, Computer-Assisted; Neural Networks, Computer; Supervised Machine Learning",2022-08-28,2022,2022-08-28,2022-11,82,,102597,All OA, Hybrid,Article,"Chen, Chen; Qin, Chen; Ouyang, Cheng; Li, Zeju; Wang, Shuo; Qiu, Huaqi; Chen, Liang; Tarroni, Giacomo; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (Department of Computing, Imperial College London, UK. Electronic address: chen.chen15@imperial.ac.uk.); Qin, Chen (Institute for Digital Communications, School of Engineering, University of Edinburgh, UK; Department of Electronics and Electrical Engineering, Imperial College London, UK.); Ouyang, Cheng (Department of Computing, Imperial College London, UK.); Li, Zeju (Department of Computing, Imperial College London, UK.); Wang, Shuo (Digital Medicine Research Centre, School of Basic Medical Sciences, Fudan University, China; Shanghai Key Laboratory of MICCAI, Shanghai, China.); Qiu, Huaqi (Department of Computing, Imperial College London, UK.); Chen, Liang (Department of Computing, Imperial College London, UK.); Tarroni, Giacomo (Department of Computing, Imperial College London, UK; CitAI Research Centre, Department of Computer Science, City, University of London, UK.); Bai, Wenjia (Department of Computing, Imperial College London, UK; Department of Brain Sciences, Imperial College London, UK; Data Science Institute, Imperial College London, UK.); Rueckert, Daniel (Department of Computing, Imperial College London, UK; Klinikum rechts der Isar, Technical University of Munich, Germany.)","Chen, Chen (Imperial College London)","Chen, Chen (Imperial College London); Qin, Chen (University of Edinburgh; Imperial College London); Ouyang, Cheng (Imperial College London); Li, Zeju (Imperial College London); Wang, Shuo (Fudan University); Qiu, Huaqi (Imperial College London); Chen, Liang (Imperial College London); Tarroni, Giacomo (Imperial College London; University of London); Bai, Wenjia (Imperial College London); Rueckert, Daniel (Imperial College London; Rechts der Isar Hospital; Technical University of Munich)",7,7,,,https://doi.org/10.1016/j.media.2022.102597,https://app.dimensions.ai/details/publication/pub.1150555625,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
1725,pub.1150593505,10.48550/arxiv.2208.13275,,,Unsupervised diffeomorphic cardiac image registration using  parameterization of the deformation field,"This study proposes an end-to-end unsupervised diffeomorphic deformable
registration framework based on moving mesh parameterization. Using this
parameterization, a deformation field can be modeled with its transformation
Jacobian determinant and curl of end velocity field. The new model of the
deformation field has three important advantages; firstly, it relaxes the need
for an explicit regularization term and the corresponding weight in the cost
function. The smoothness is implicitly embedded in the solution which results
in a physically plausible deformation field. Secondly, it guarantees
diffeomorphism through explicit constraints applied to the transformation
Jacobian determinant to keep it positive. Finally, it is suitable for cardiac
data processing, since the nature of this parameterization is to define the
deformation field in terms of the radial and rotational components. The
effectiveness of the algorithm is investigated by evaluating the proposed
method on three different data sets including 2D and 3D cardiac MRI scans. The
results demonstrate that the proposed framework outperforms existing
learning-based and non-learning-based methods while generating diffeomorphic
transformations.",,,arXiv,,,2022-08-28,2022,,,,,,All OA, Green,Preprint,"Sheikhjafari, Ameneh; Krishnaswamy, Deepa; Noga, Michelle; Ray, Nilanjan; Punithakumar, Kumaradevan","Sheikhjafari, Ameneh (); Krishnaswamy, Deepa (); Noga, Michelle (); Ray, Nilanjan (); Punithakumar, Kumaradevan ()",,"Sheikhjafari, Ameneh (); Krishnaswamy, Deepa (); Noga, Michelle (); Ray, Nilanjan (); Punithakumar, Kumaradevan ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150593505,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
4362,pub.1150492950,10.1007/s00117-022-01060-0,36006439,,Künstliche Intelligenz und Radiomics,"Clinical/methodical issueCardiac diseases are the leading cause of death. Many diseases can be specifically treated once a valid diagnosis is established. Cardiac magnetic resonance imaging (MRI) plays a central role in the workup of many cardiac pathologies. However, image acquisition as well as interpretation and related secondary image evaluation are time-consuming and complex.Standard radiological methodsCardiac MRI is becoming increasingly established in international guidelines for the evaluation of cardiac function and differential diagnosis of a wide variety of cardiac diseases.Methodological innovationsCardiac MRI has limited reproducibility due to the acquisition technique and interpretation of findings with complex secondary measurements. Artificial intelligence techniques and radiomics offer the potential to improve the acquisition, interpretation, and reproducibility of cardiac MRI.PerformanceResearch suggests that artificial intelligence and radiomic analysis can improve cardiac MRI in terms of image acquisition and also diagnostic and prognostic value. Furthermore, the implementation of artificial intelligence and radiomics may result in the identification of new biomarkers.Achievements and practical recommendationsThe implementation of artificial intelligence in cardiac MRI has great potential. However, the current level of evidence is still limited in some aspects; in particular there are too few prospective and large multicenter studies available. As a result, the algorithms developed are often not sufficiently validated scientifically and are not yet applied in clinical routine.",,,Die Radiologie,,Humans, Artificial Intelligence, Reproducibility of Results, Prospective Studies, Magnetic Resonance Imaging, Heart Diseases,2022-08-25,2022,2022-08-25,2022-11,62,11,947-953,Closed,Article,"Rau, Alexander; Soschynski, Martin; Taron, Jana; Ruile, Philipp; Schlett, Christopher L.; Bamberg, Fabian; Krauss, Tobias","Rau, Alexander (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Soschynski, Martin (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Taron, Jana (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Ruile, Philipp (Klinik für Klinik für Kardiologie und Angiologie, Universitäts-Herzzentrum Freiburg – Bad Krozingen, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Bad Krozingen, Deutschland); Schlett, Christopher L. (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Bamberg, Fabian (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland); Krauss, Tobias (Klinik für Diagnostische und Interventionelle Radiologie, Universitätsklinikum Freiburg, Medizinische Fakultät, Albert-Ludwigs-Universität Freiburg, Freiburg, Deutschland)","Rau, Alexander (University Medical Center Freiburg; University of Freiburg)","Rau, Alexander (University Medical Center Freiburg; University of Freiburg); Soschynski, Martin (University Medical Center Freiburg; University of Freiburg); Taron, Jana (University Medical Center Freiburg; University of Freiburg); Ruile, Philipp (Universitäts-Herzzentrum Freiburg-Bad Krozingen); Schlett, Christopher L. (University Medical Center Freiburg; University of Freiburg); Bamberg, Fabian (University Medical Center Freiburg; University of Freiburg); Krauss, Tobias (University Medical Center Freiburg; University of Freiburg)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150492950,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,
1299,pub.1153211421,10.1109/icpr56361.2022.9956530,,,Pixel-accurate Segmentation of Surgical Tools based on Bounding Box Annotations,"Detection and segmentation of surgical instruments is an important problem for laparoscopic surgery. Accurate pixel-wise instrument segmentation is a useful intermediate task for the development of computer-assisted surgery systems, such as pose estimation, surgical phase estimation, enhanced image fusion, video retrieval and others. In this paper we describe a deep learning-based approach to instrument segmentation, which addresses the binary segmentation problem in which every pixel in an image is labeled as instrument or background. The key novelty of our approach relates to the use of training data which is inexpensive and fast to acquire. First, our approach relies on weak annotations provided as bounding boxes of the instruments, which are much faster and cheaper to obtain than a dense pixel-level annotations. Second, to further improve the system’s accuracy we propose a novel approach to generate synthetic training images. Our approach achieves state-of-the-art results, outperforming previously proposed methods for automatic instrument segmentation, based only on weak annotations.",,,,2022 26th International Conference on Pattern Recognition (ICPR),,2022-08-25,2022,,2022-08-25,0,,5096-5103,Closed,Proceeding,"Leifman, George; Aides, Amit; Golany, Tomer; Freedman, Daniel; Rivlin, Ehud","Leifman, George (Google Research); Aides, Amit (Google Research); Golany, Tomer (Google Research); Freedman, Daniel (Google Research); Rivlin, Ehud (Google Research)","Leifman, George (Google (United States))","Leifman, George (Google (United States)); Aides, Amit (Google (United States)); Golany, Tomer (Google (United States)); Freedman, Daniel (Google (United States)); Rivlin, Ehud (Google (United States))",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153211421,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
5334,pub.1150454966,10.1016/j.compbiomed.2022.106034,36058068,,Uncertainty teacher with dense focal loss for semi-supervised medical image segmentation,"In medical scenarios, obtaining pixel-level annotations for medical images is expensive and time-consuming, even if considering its importance for automating segmentation tasks. Due to the scarcity of labels in the training phase, semi-supervised methods are widely applied for various medical tasks. To better utilize the unlabeled data, several works have explored the method of uncertainty estimation and exhibited huge success. Despite their impressive performance, we believe that the underlying information of the unlabeled data has been largely unexplored. Meanwhile, there is an extreme foreground-background class imbalance during the training phase of semantic segmentation, which may cause a vast number of easily classified samples to overwhelm the loss during training and lead to a model collapse. In this paper, we proposed uncertainty teacher with dense focal loss, a method that can take good advantage of unlabeled data simultaneously and address the class imbalance problem, based on Deep Co-Training. On one hand, the uncertainty teacher framework is presented to better utilize the unlabeled data by introducing a novel method to regularize uncertainty in the right direction, and the uncertainty is estimated by Monte Carlo Sampling. On the other hand, the dense focal loss is proposed to help solve the class imbalance problem between different classes of samples in medical image segmentation and effectively convert the multi-variate entropy into a multiple binary entropy. We implemented our method on three challenging public medical datasets and experimental results have shown desirable improvements to state-of-the-art.","This research is supported by the National Natural Science Foundation of China (No. 62032013), the Fundamental Research Funds for the Central Universities, China (Nos. N2224001-7 and N2116020) and the Natural Science Foundation of Liaoning Province, China (No. 2021-YGJC-24).",,Computers in Biology and Medicine,,"Deep Learning; Entropy; Image Processing, Computer-Assisted; Neural Networks, Computer; Uncertainty",2022-08-24,2022,2022-08-24,2022-10,149,,106034,Closed,Article,"Chen, Jialei; Fu, Chong; Xie, Haoyu; Zheng, Xu; Geng, Rong; Sham, Chiu-Wing","Chen, Jialei (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Fu, Chong (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China; Engineering Research Center of Security Technology of Complex Network System, Ministry of Education, China; Key Laboratory of Intelligent Computing in Medical Image, Ministry of Education, Northeastern University, Shenyang 110819, China. Electronic address: fuchong@mail.neu.edu.cn.); Xie, Haoyu (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Zheng, Xu (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Geng, Rong (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Sham, Chiu-Wing (School of Computer Science, The University of Auckland, New Zealand.)","Fu, Chong (Ministry of Education of the People's Republic of China; Northeastern University)","Chen, Jialei (Northeastern University); Fu, Chong (Ministry of Education of the People's Republic of China; Northeastern University); Xie, Haoyu (Northeastern University); Zheng, Xu (Northeastern University); Geng, Rong (Northeastern University); Sham, Chiu-Wing (University of Auckland)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150454966,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
5331,pub.1150461210,10.1016/j.compbiomed.2022.106051,36055155,,Uncertainty-aware deep co-training for semi-supervised medical image segmentation,"Semi-supervised learning has made significant strides in the medical domain since it alleviates the heavy burden of collecting abundant pixel-wise annotated data for semantic segmentation tasks. Existing semi-supervised approaches enhance the ability to extract features from unlabeled data with prior knowledge obtained from limited labeled data. However, due to the scarcity of labeled data, the features extracted by the models are limited in supervised learning, and the quality of predictions for unlabeled data also cannot be guaranteed. Both will impede consistency training. To this end, we proposed a novel uncertainty-aware scheme to make models learn regions purposefully. Specifically, we employ Monte Carlo Sampling as an estimation method to attain an uncertainty map, which can serve as a weight for losses to force the models to focus on the valuable region according to the characteristics of supervised learning and unsupervised learning. Simultaneously, in the backward process, we joint unsupervised and supervised losses to accelerate the convergence of the network via enhancing the gradient flow between different tasks. Quantitatively, we conduct extensive experiments on three challenging medical datasets. Experimental results show desirable improvements to state-of-the-art counterparts.","This work was supported by the National Natural Science Foundation of China (No. 62032013), the Fundamental Research Funds for the Central Universities, China (Nos. N2224001-7 and N2116020) and the Natural Science Foundation of Liaoning Province, China (No. 2021-YGJC-24).",,Computers in Biology and Medicine,,"Image Processing, Computer-Assisted; Supervised Machine Learning; Uncertainty",2022-08-24,2022,2022-08-24,2022-10,149,,106051,All OA, Green,Article,"Zheng, Xu; Fu, Chong; Xie, Haoyu; Chen, Jialei; Wang, Xingwei; Sham, Chiu-Wing","Zheng, Xu (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Fu, Chong (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China; Engineering Research Center of Security Technology of Complex Network System, Ministry of Education, China; Key Laboratory of Intelligent Computing in Medical Image, Ministry of Education, Northeastern University, Shenyang 110819, China. Electronic address: fuchong@mail.neu.edu.cn.); Xie, Haoyu (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Chen, Jialei (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Wang, Xingwei (School of Computer Science and Engineering, Northeastern University, Shenyang 110819, China.); Sham, Chiu-Wing (School of Computer Science, The University of Auckland, New Zealand.)","Fu, Chong (Ministry of Education of the People's Republic of China; Northeastern University)","Zheng, Xu (Northeastern University); Fu, Chong (Ministry of Education of the People's Republic of China; Northeastern University); Xie, Haoyu (Northeastern University); Chen, Jialei (Northeastern University); Wang, Xingwei (Northeastern University); Sham, Chiu-Wing (University of Auckland)",1,1,,,http://arxiv.org/pdf/2111.11629,https://app.dimensions.ai/details/publication/pub.1150461210,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1070,pub.1150422536,10.48550/arxiv.2208.09910,,,Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic  Segmentation,"In this work, we revisit the weak-to-strong consistency framework,
popularized by FixMatch from semi-supervised classification, where the
prediction of a weakly perturbed image serves as supervision for its strongly
perturbed version. Intriguingly, we observe that such a simple pipeline already
achieves competitive results against recent advanced works, when transferred to
our segmentation scenario. Its success heavily relies on the manual design of
strong data augmentations, however, which may be limited and inadequate to
explore a broader perturbation space. Motivated by this, we propose an
auxiliary feature perturbation stream as a supplement, leading to an expanded
perturbation space. On the other, to sufficiently probe original image-level
augmentations, we present a dual-stream perturbation technique, enabling two
strong views to be simultaneously guided by a common weak view. Consequently,
our overall Unified Dual-Stream Perturbations approach (UniMatch) surpasses all
existing methods significantly across all evaluation protocols on the Pascal,
Cityscapes, and COCO benchmarks. We also demonstrate the superiority of our
method in remote sensing interpretation and medical image analysis. Code is
available at https://github.com/LiheYoung/UniMatch.",,,arXiv,,,2022-08-21,2022,,,,,,All OA, Green,Preprint,"Yang, Lihe; Qi, Lei; Feng, Litong; Zhang, Wayne; Shi, Yinghuan","Yang, Lihe (); Qi, Lei (); Feng, Litong (); Zhang, Wayne (); Shi, Yinghuan ()",,"Yang, Lihe (); Qi, Lei (); Feng, Litong (); Zhang, Wayne (); Shi, Yinghuan ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150422536,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1133,pub.1150393840,10.48550/arxiv.2208.09350,,,PyMIC: A deep learning toolkit for annotation-efficient medical image  segmentation,"Background and Objective: Open-source deep learning toolkits are one of the
driving forces for developing medical image segmentation models. Existing
toolkits mainly focus on fully supervised segmentation and require full and
accurate pixel-level annotations that are time-consuming and difficult to
acquire for segmentation tasks, which makes learning from imperfect labels
highly desired for reducing the annotation cost. We aim to develop a new deep
learning toolkit to support annotation-efficient learning for medical image
segmentation.
  Methods: Our proposed toolkit named PyMIC is a modular deep learning library
for medical image segmentation tasks. In addition to basic components that
support development of high-performance models for fully supervised
segmentation, it contains several advanced components tailored for learning
from imperfect annotations, such as loading annotated and unannounced images,
loss functions for unannotated, partially or inaccurately annotated images, and
training procedures for co-learning between multiple networks, etc. PyMIC
supports development of semi-supervised, weakly supervised and noise-robust
learning methods for medical image segmentation.
  Results: We present several illustrative medical image segmentation tasks
based on PyMIC: (1) Achieving competitive performance on fully supervised
learning; (2) Semi-supervised cardiac structure segmentation with only 10%
training images annotated; (3) Weakly supervised segmentation using scribble
annotations; and (4) Learning from noisy labels for chest radiograph
segmentation.
  Conclusions: The PyMIC toolkit is easy to use and facilitates efficient
development of medical image segmentation models with imperfect annotations. It
is modular and flexible, which enables researchers to develop high-performance
models with low annotation cost. The source code is available at:
https://github.com/HiLab-git/PyMIC.",,,arXiv,,,2022-08-19,2022,,,,,,All OA, Green,Preprint,"Wang, Guotai; Luo, Xiangde; Gu, Ran; Yang, Shuojue; Qu, Yijie; Zhai, Shuwei; Zhao, Qianfei; Li, Kang; Zhang, Shaoting","Wang, Guotai (); Luo, Xiangde (); Gu, Ran (); Yang, Shuojue (); Qu, Yijie (); Zhai, Shuwei (); Zhao, Qianfei (); Li, Kang (); Zhang, Shaoting ()",,"Wang, Guotai (); Luo, Xiangde (); Gu, Ran (); Yang, Shuojue (); Qu, Yijie (); Zhai, Shuwei (); Zhao, Qianfei (); Li, Kang (); Zhang, Shaoting ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150393840,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1066,pub.1150302890,10.21203/rs.3.rs-1930459/v1,,,Clinical validation of a fully automated framework for ventricular segmentation and wall motion classification from cine CMR,"Background We present the clinical validation of an AI-based framework for automatic ventricular segmentation and quantification, and automatic wall motion classification from cine CMR. Methods The framework was evaluated using two datasets, the SCMR Consensus dataset and a cohort private dataset composed by 146 patients. The automatic segmentation of left ventricle (LV) of SCMR Consensus dataset was evaluated through Dice Similarity Coefficient (DSC). The ventricular function quantification was assessed by processing both datasets, measuring LV and right ventricle (RV) end-diastolic and end-systolic volumes, ejection fraction (EF), and left ventricle mass (LVM). The validation was based on agreement indices, such as the intra-class correlation coefficients (ICC). Automatic wall motion classification was performed using the cohort dataset, and assessed using confusion matrix metrics. Results The comparison between the proposed framework and experts' manual performances on ventricular segmentation and function quantification processes showed high levels of contouring overlap (DSC=0.72), and agreement (ICC > 0.96 and ICC > 0.81 for volumes and EFs of LV and RV, respectively, and ICC > 0.78 for LVM). The automatic wall motion analysis obtained a classification accuracy of 0.77, with a sensitivity value of 1.00, meaning no false negative.. Conclusions The validation results confirmed the proposed framework robustness and generalization capabilities. Moreover, our proposal demonstrated its potential for automatic wall motion classification in clinical practice.",,,Research Square,,,2022-08-17,2022,2022-08-17,,,,,All OA, Green,Preprint,"Costa, Eva; Barros, Carla; Pinto, Adriano; Martins, Nelson; Tondi, Lara; Pica, Silvia; Pereira, Vitor Hugo; Lombardi, Massimo","Costa, Eva (AI4MedImaging Medical Solutions); Barros, Carla (AI4MedImaging Medical Solutions); Pinto, Adriano (AI4MedImaging Medical Solutions); Martins, Nelson (AI4MedImaging Medical Solutions); Tondi, Lara (IRCCS Policlinico San Donato); Pica, Silvia (IRCCS Policlinico San Donato); Pereira, Vitor Hugo (AI4MedImaging Medical Solutions; Life and Health Sciences Reseach Institute, School of Medicine, University of Minho); Lombardi, Massimo (IRCCS Policlinico San Donato)",,"Costa, Eva (); Barros, Carla (); Pinto, Adriano (); Martins, Nelson (); Tondi, Lara (IRCCS Policlinico San Donato); Pica, Silvia (IRCCS Policlinico San Donato); Pereira, Vitor Hugo (University of Minho); Lombardi, Massimo (IRCCS Policlinico San Donato)",0,0,,,https://www.researchsquare.com/article/rs-1930459/latest.pdf,https://app.dimensions.ai/details/publication/pub.1150302890,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
794,pub.1150264316,10.48550/arxiv.2208.06643,,,Medical image analysis based on transformer: A Review,"The transformer has dominated the natural language processing (NLP) field for
a long time. Recently, the transformer-based method has been adopted into the
computer vision (CV) field and shows promising results. As an important branch
of the CV field, medical image analysis joins the wave of the transformer-based
method rightfully. In this review, we illustrate the principle of the attention
mechanism, and the detailed structures of the transformer, and depict how the
transformer is adopted into medical image analysis. We organize the
transformer-based medical image analysis applications in a sequence of
different tasks, including classification, segmentation, synthesis,
registration, localization, detection, captioning, and denoising. For the
mainstream classification and segmentation tasks, we further divided the
corresponding works based on different medical imaging modalities. The datasets
corresponding to the related works are also organized. We include thirteen
modalities and more than twenty objects in our work.",,,arXiv,,,2022-08-13,2022,,,,,,All OA, Green,Preprint,"Liu, Zhaoshan; Lv, Qiujie; Lee, Chau Hung; Shen, Lei","Liu, Zhaoshan (); Lv, Qiujie (); Lee, Chau Hung (); Shen, Lei ()",,"Liu, Zhaoshan (); Lv, Qiujie (); Lee, Chau Hung (); Shen, Lei ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150264316,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
4788,pub.1150159728,10.1016/j.media.2022.102564,35994968,,Distributed contrastive learning for medical image segmentation,"Supervised deep learning needs a large amount of labeled data to achieve high performance. However, in medical imaging analysis, each site may only have a limited amount of data and labels, which makes learning ineffective. Federated learning (FL) can learn a shared model from decentralized data. But traditional FL requires fully-labeled data for training, which is very expensive to obtain. Self-supervised contrastive learning (CL) can learn from unlabeled data for pre-training, followed by fine-tuning with limited annotations. However, when adopting CL in FL, the limited data diversity on each site makes federated contrastive learning (FCL) ineffective. In this work, we propose two federated self-supervised learning frameworks for volumetric medical image segmentation with limited annotations. The first one features high accuracy and fits high-performance servers with high-speed connections. The second one features lower communication costs, suitable for mobile devices. In the first framework, features are exchanged during FCL to provide diverse contrastive data to each site for effective local CL while keeping raw data private. Global structural matching aligns local and remote features for a unified feature space among different sites. In the second framework, to reduce the communication cost for feature exchanging, we propose an optimized method FCLOpt that does not rely on negative samples. To reduce the communications of model download, we propose the predictive target network update (PTNU) that predicts the parameters of the target network. Based on PTNU, we propose the distance prediction (DP) to remove most of the uploads of the target network. Experiments on a cardiac MRI dataset show the proposed two frameworks substantially improve the segmentation and generalization performance compared with state-of-the-art techniques.","This work used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation, United States grant number ACI-1548562. Specifically, it used the Bridges system, which is supported by NSF, United States award number ACI-1445606, at the Pittsburgh Supercomputing Center (PSC).",,Medical Image Analysis,,Humans, Magnetic Resonance Imaging, Supervised Machine Learning,2022-08-12,2022,2022-08-12,2022-10,81,,102564,All OA, Green,Article,"Wu, Yawen; Zeng, Dewen; Wang, Zhepeng; Shi, Yiyu; Hu, Jingtong","Wu, Yawen (University of Pittsburgh, Pittsburgh PA 15260, USA. Electronic address: yawen.wu@pitt.edu.); Zeng, Dewen (University of Notre Dame, Notre Dame IN 46556, USA.); Wang, Zhepeng (George Mason University, Fairfax VA 22030, USA.); Shi, Yiyu (University of Notre Dame, Notre Dame IN 46556, USA.); Hu, Jingtong (University of Pittsburgh, Pittsburgh PA 15260, USA.)","Wu, Yawen (University of Pittsburgh)","Wu, Yawen (University of Pittsburgh); Zeng, Dewen (University of Notre Dame); Wang, Zhepeng (George Mason University); Shi, Yiyu (University of Notre Dame); Hu, Jingtong (University of Pittsburgh)",1,1,,,http://arxiv.org/pdf/2208.03808,https://app.dimensions.ai/details/publication/pub.1150159728,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,
1251,pub.1150138633,10.21203/rs.3.rs-1840375/v1,,,"Novel Domain Knowledge Encoding Enables Machine Learning of Rapid, Expert-level Segmentation of Cardiac Computed Tomography","Ablation is a common therapeutic procedure for atrial fibrillation (AF), that is guided to specific targets in the heart often after laborious segmentation of computed tomography. Machine learning (ML) can automate such tasks but requires large training datasets. Inspired by natural intelligence, which builds conceptual models to learn without large datasets, we mathematically encoded domain knowledge of atrial geometry to accelerate ML segmentation. In test cohorts (N=160) at 2 institutions, Dice scores were 96.7% (IQR: 95.3% to 97.7%) and 93.5% (IQR: 91.9% to 94.7%) with similar anatomic agreement to experts (r=0.99; p<0.0001). In a prospective study of patients undergoing AF ablation (N=42), our approach reduced segmentation time by 85% (2.28±0.8 vs 15.0±6.9 minutes; p<0.0001), with similar Dice (p=0.07) versus experts. This approach may broaden the availability of AF ablation, and more broadly shows that encoding of domain knowledge may reduce the dependence of ML on large training datasets.",,,Research Square,,,2022-08-10,2022,2022-08-10,,,,,All OA, Green,Preprint,"Feng, Ruibin; Deb, Brototo; Ganesan, Prasanth; Tjong, Fleur; Rogers, Albert; Ruipérez-Campillo, Samuel; Somani, Sulaiman; Rodrigo, Miguel; Clopton, Paul; Zou, James; Zaharia, Matei; Narayan, Sanjiv","Feng, Ruibin (Stanford University); Deb, Brototo (Stanford University); Ganesan, Prasanth (Stanford University); Tjong, Fleur (Stanford University); Rogers, Albert (Stanford University); Ruipérez-Campillo, Samuel (Stanford University); Somani, Sulaiman (Stanford University); Rodrigo, Miguel (Stanford University); Clopton, Paul (Stanford University); Zou, James (Stanford University); Zaharia, Matei (Stanford University); Narayan, Sanjiv (Stanford University)",,"Feng, Ruibin (Stanford University); Deb, Brototo (Stanford University); Ganesan, Prasanth (Stanford University); Tjong, Fleur (Stanford University); Rogers, Albert (Stanford University); Ruipérez-Campillo, Samuel (Stanford University); Somani, Sulaiman (Stanford University); Rodrigo, Miguel (Stanford University); Clopton, Paul (Stanford University); Zou, James (Stanford University); Zaharia, Matei (Stanford University); Narayan, Sanjiv (Stanford University)",0,0,,,https://www.researchsquare.com/article/rs-1840375/latest.pdf,https://app.dimensions.ai/details/publication/pub.1150138633,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
1344,pub.1150047517,10.1007/978-3-031-13321-3_30,,,Shape Prior Based Myocardial Segmentation with Anatomically Motivated Pose Model,We extend the shape-prior based geometric approach developed for myocardial segmentation in cardiac CT imagery by incorporating minimal user input in the form of anatomical constraints to guide the segmentation process resulting in significantly improved results. The shape-prior based geometric approach involves estimating coefficients of a low-dimensional principal component analysis based shape representation along with a set of rigid 3D pose parameters of three separate surfaces corresponding to left (LV)/right (RV) ventricles and Epicardium (Epi) by optimizing a novel Chan-Vese like image appearance model with gradient descent. We enhance this framework by allowing experienced clinical users to identify the centers of the three anatomies in apical slices and a common anatomical cardiac base slice. We integrate this minimal user input as anatomical constraints in the segmentation process by replacing the rigid 3D pose model with a novel blended model which incorporates rigidity only within 2D slices while incorporating non-rigid effects of shear and torsion along the third (axial) dimension. With this new formulation we achieved significantly improved segmentation results in terms of average symmetric surface-to-surface distances (mm): LV 1.05 ± 0.27, RV 1.7 ± 0.40, Epi 1.22 ± 0.56 compared to LV 2.3 ± 0.50, RV 1.13 ± 0.21, Epi 3.3 ± 0.50 with rigid 3D pose model.,,,Lecture Notes in Computer Science,Image Analysis and Processing. ICIAP 2022 Workshops,,2022-08-07,2022,2022-08-07,2022,13373,,338-350,Closed,Chapter,"Dahiya, Navdeep; Piccinelli, Marina; Garcia, Ernest; Yezzi, Anthony","Dahiya, Navdeep (Georgia Institute of Technology, 30332, Atlanta, GA, USA); Piccinelli, Marina (Emory University, 30322, Atlanta, GA, USA); Garcia, Ernest (Emory University, 30322, Atlanta, GA, USA); Yezzi, Anthony (Georgia Institute of Technology, 30332, Atlanta, GA, USA)","Dahiya, Navdeep (Georgia Institute of Technology)","Dahiya, Navdeep (Georgia Institute of Technology); Piccinelli, Marina (Emory University); Garcia, Ernest (Emory University); Yezzi, Anthony (Georgia Institute of Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150047517,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,
961,pub.1150096453,10.48550/arxiv.2208.03808,,,Distributed Contrastive Learning for Medical Image Segmentation,"Supervised deep learning needs a large amount of labeled data to achieve high
performance. However, in medical imaging analysis, each site may only have a
limited amount of data and labels, which makes learning ineffective. Federated
learning (FL) can learn a shared model from decentralized data. But traditional
FL requires fully-labeled data for training, which is very expensive to obtain.
Self-supervised contrastive learning (CL) can learn from unlabeled data for
pre-training, followed by fine-tuning with limited annotations. However, when
adopting CL in FL, the limited data diversity on each site makes federated
contrastive learning (FCL) ineffective. In this work, we propose two federated
self-supervised learning frameworks for volumetric medical image segmentation
with limited annotations. The first one features high accuracy and fits
high-performance servers with high-speed connections. The second one features
lower communication costs, suitable for mobile devices. In the first framework,
features are exchanged during FCL to provide diverse contrastive data to each
site for effective local CL while keeping raw data private. Global structural
matching aligns local and remote features for a unified feature space among
different sites. In the second framework, to reduce the communication cost for
feature exchanging, we propose an optimized method FCLOpt that does not rely on
negative samples. To reduce the communications of model download, we propose
the predictive target network update (PTNU) that predicts the parameters of the
target network. Based on PTNU, we propose the distance prediction (DP) to
remove most of the uploads of the target network. Experiments on a cardiac MRI
dataset show the proposed two frameworks substantially improve the segmentation
and generalization performance compared with state-of-the-art techniques.",,,arXiv,,,2022-08-07,2022,,,,,,All OA, Green,Preprint,"Wu, Yawen; Zeng, Dewen; Wang, Zhepeng; Shi, Yiyu; Hu, Jingtong","Wu, Yawen (); Zeng, Dewen (); Wang, Zhepeng (); Shi, Yiyu (); Hu, Jingtong ()",,"Wu, Yawen (); Zeng, Dewen (); Wang, Zhepeng (); Shi, Yiyu (); Hu, Jingtong ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150096453,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1396,pub.1150069047,10.48550/arxiv.2208.02870,,,Improved post-hoc probability calibration for out-of-domain MRI  segmentation,"Probability calibration for deep models is highly desirable in
safety-critical applications such as medical imaging. It makes output
probabilities of deep networks interpretable, by aligning prediction
probability with the actual accuracy in test data. In image segmentation,
well-calibrated probabilities allow radiologists to identify regions where
model-predicted segmentations are unreliable. These unreliable predictions
often occur to out-of-domain (OOD) images that are caused by imaging artifacts
or unseen imaging protocols. Unfortunately, most previous calibration methods
for image segmentation perform sub-optimally on OOD images. To reduce the
calibration error when confronted with OOD images, we propose a novel post-hoc
calibration model. Our model leverages the pixel susceptibility against
perturbations at the local level, and the shape prior information at the global
level. The model is tested on cardiac MRI segmentation datasets that contain
unseen imaging artifacts and images from an unseen imaging protocol. We
demonstrate reduced calibration errors compared with the state-of-the-art
calibration algorithm.",,,arXiv,,,2022-08-04,2022,,,,,,All OA, Green,Preprint,"Ouyang, Cheng; Wang, Shuo; Chen, Chen; Li, Zeju; Bai, Wenjia; Kainz, Bernhard; Rueckert, Daniel","Ouyang, Cheng (); Wang, Shuo (); Chen, Chen (); Li, Zeju (); Bai, Wenjia (); Kainz, Bernhard (); Rueckert, Daniel ()",,"Ouyang, Cheng (); Wang, Shuo (); Chen, Chen (); Li, Zeju (); Bai, Wenjia (); Kainz, Bernhard (); Rueckert, Daniel ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150069047,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1512,pub.1150831752,10.1088/1742-6596/2327/1/012073,,,A Review on the Detection of the Post COVID-19 Symptoms for Long Term Diseased Patients using Machine Learning Algorithms,"Long term diseases require continuous monitoring, sometimes periodic monitoring to verify if any serious concern requires an attention. In recent years, it is noticed that the COVID-19 pandemic has triggered serious concern towards the long-term diseased individuals. As the mortality rate of the COVID-19 clearly indicates that the highest percentage of deaths reflect in the individuals suffering from long term diseases such as diabetes, pneumonia, cardiovascular and acute renal failure. Though they are tested for COVID negative through conventional apparatus, it doesn’t confer that they are completely out of post consequences. Hence a periodic, if necessary continuous monitoring needs to be aided, which in current scenario is a challenging task. Hence, our current article reviews the use of machine learning algorithms to detect and diagnose pre and post COVID-19 effects on long term diseased patients.",,,Journal of Physics Conference Series,,,2022-08-01,2022,,2022-08-01,2327,1,12073,All OA, Gold,Article,"Patibandla, Anitha","Patibandla, Anitha (Research Scholar, Dept.of ECE, Lovely Professional University, Punjab, India)",,"Patibandla, Anitha (Lovely Professional University)",0,0,,,https://doi.org/10.1088/1742-6596/2327/1/012073,https://app.dimensions.ai/details/publication/pub.1150831752,51 Physical Sciences,3 Good Health and Well Being,,,,,,,,,,
5033,pub.1149144086,10.1142/s0129065722500435,35912583,,An Efficient Semi-Supervised Framework with Multi-Task and Curriculum Learning for Medical Image Segmentation,"A practical problem in supervised deep learning for medical image segmentation is the lack of labeled data which is expensive and time-consuming to acquire. In contrast, there is a considerable amount of unlabeled data available in the clinic. To make better use of the unlabeled data and improve the generalization on limited labeled data, in this paper, a novel semi-supervised segmentation method via multi-task curriculum learning is presented. Here, curriculum learning means that when training the network, simpler knowledge is preferentially learned to assist the learning of more difficult knowledge. Concretely, our framework consists of a main segmentation task and two auxiliary tasks, i.e. the feature regression task and target detection task. The two auxiliary tasks predict some relatively simpler image-level attributes and bounding boxes as the pseudo labels for the main segmentation task, enforcing the pixel-level segmentation result to match the distribution of these pseudo labels. In addition, to solve the problem of class imbalance in the images, a bounding-box-based attention (BBA) module is embedded, enabling the segmentation network to concern more about the target region rather than the background. Furthermore, to alleviate the adverse effects caused by the possible deviation of pseudo labels, error tolerance mechanisms are also adopted in the auxiliary tasks, including inequality constraint and bounding-box amplification. Our method is validated on ACDC2017 and PROMISE12 datasets. Experimental results demonstrate that compared with the full supervision method and state-of-the-art semi-supervised methods, our method yields a much better segmentation performance on a small labeled dataset. Code is available at https://github.com/DeepMedLab/MTCL.",,,International Journal of Neural Systems,,"Curriculum; Data Curation; Datasets as Topic; Image Processing, Computer-Assisted; Supervised Machine Learning",2022-07-30,2022,2022-07-30,2022-09,32,9,2250043,Closed,Article,"Wang, Kaiping; Wang, Yan; Zhan, Bo; Yang, Yujie; Zu, Chen; Wu, Xi; Zhou, Jiliu; Nie, Dong; Zhou, Luping","Wang, Kaiping (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Wang, Yan (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Zhan, Bo (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Yang, Yujie (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Zu, Chen (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Wu, Xi (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Zhou, Jiliu (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Nie, Dong (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.); Zhou, Luping (College of Computer Science, Sichuan University, Section 1, Southern 1st Ring Rd, Chengdu, Sichuan 610065, P. R. China.)","Wang, Yan (Sichuan University)","Wang, Kaiping (Sichuan University); Wang, Yan (Sichuan University); Zhan, Bo (Sichuan University); Yang, Yujie (Sichuan University); Zu, Chen (Sichuan University); Wu, Xi (Sichuan University); Zhou, Jiliu (Sichuan University); Nie, Dong (Sichuan University); Zhou, Luping (Sichuan University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1149144086,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1581,pub.1154062879,10.1109/gtsd54989.2022.9989083,,,DR-Unet++: An Approach for Left Ventricle Segmentation from Magnetic Resonance Images,"Precise and automatic segmentation of the left ventricle (LV) in cardiac magnetic resonance imaging (MRI) can help cardiologists make accurate diagnoses and decisions. In the revolution of Deep Learning, many LV image segmentation models have been developed and shown promising performance. Nevertheless, segmentation of the LV is still a nontrivial task due to challenges in the cardiac MR images such as the presence of intensity inhomogeneity, clutter, and object size variations. In this study, we propose DR- Unet++, an enhanced DR-Unet architecture, for cardiac segmentation tasks. The DR-Unet++ model, which utilizes advanced Deep Learning techniques, provides better feature extraction for the segmentation of desired segmented objects. Our tests on the ACDC dataset and Sunnybrook Cardiac dataset show that DR-Unet++ outperforms other modern models in terms of Dice coefficient and IoU metric and demonstrates its potential in biomedical image segmentation tasks.",This research is funded by the Hanoi University of Science and Technology (HUST) under project number T2021-PC-005.,This research is funded by the Hanoi University of Science and Technology (HUST) under project number T2021-PC-005.,,2022 6th International Conference on Green Technology and Sustainable Development (GTSD),,2022-07-30,2022,,2022-07-30,0,,1048-1052,Closed,Proceeding,"Le, Dinh-Hung; Le, Nhat-Minh; Le, Khac-Hung; Pham, Van-Truong; Tran, Thi-Thao","Le, Dinh-Hung (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Hanoi, Vietnam); Le, Nhat-Minh (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Hanoi, Vietnam); Le, Khac-Hung (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Hanoi, Vietnam); Pham, Van-Truong (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Hanoi, Vietnam); Tran, Thi-Thao (Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi University of Science and Technology, Hanoi, Vietnam)",,"Le, Dinh-Hung (Hanoi University of Science and Technology); Le, Nhat-Minh (Hanoi University of Science and Technology); Le, Khac-Hung (Hanoi University of Science and Technology); Pham, Van-Truong (Hanoi University of Science and Technology); Tran, Thi-Thao (Hanoi University of Science and Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154062879,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,,
1347,pub.1149895268,10.48550/arxiv.2207.14552,,,ScaleFormer: Revisiting the Transformer-based Backbones from a  Scale-wise Perspective for Medical Image Segmentation,"Recently, a variety of vision transformers have been developed as their
capability of modeling long-range dependency. In current transformer-based
backbones for medical image segmentation, convolutional layers were replaced
with pure transformers, or transformers were added to the deepest encoder to
learn global context. However, there are mainly two challenges in a scale-wise
perspective: (1) intra-scale problem: the existing methods lacked in extracting
local-global cues in each scale, which may impact the signal propagation of
small objects; (2) inter-scale problem: the existing methods failed to explore
distinctive information from multiple scales, which may hinder the
representation learning from objects with widely variable size, shape and
location. To address these limitations, we propose a novel backbone, namely
ScaleFormer, with two appealing designs: (1) A scale-wise intra-scale
transformer is designed to couple the CNN-based local features with the
transformer-based global cues in each scale, where the row-wise and column-wise
global dependencies can be extracted by a lightweight Dual-Axis MSA. (2) A
simple and effective spatial-aware inter-scale transformer is designed to
interact among consensual regions in multiple scales, which can highlight the
cross-scale dependency and resolve the complex scale variations. Experimental
results on different benchmarks demonstrate that our Scale-Former outperforms
the current state-of-the-art methods. The code is publicly available at:
https://github.com/ZJUGiveLab/ScaleFormer.",,,arXiv,,,2022-07-29,2022,,,,,,All OA, Green,Preprint,"Huang, Huimin; Xie1, Shiao; Lin, Lanfen; Iwamoto, Yutaro; Han, Xianhua; Chen, Yen-Wei; Tong, Ruofeng","Huang, Huimin (); Xie1, Shiao (); Lin, Lanfen (); Iwamoto, Yutaro (); Han, Xianhua (); Chen, Yen-Wei (); Tong, Ruofeng ()",,"Huang, Huimin (); Xie1, Shiao (); Lin, Lanfen (); Iwamoto, Yutaro (); Han, Xianhua (); Chen, Yen-Wei (); Tong, Ruofeng ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149895268,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
6484,pub.1149814314,10.1002/jmri.28374,35900119,,Comparison of DeepStrain and Feature Tracking for Cardiac MRI Strain Analysis,"BACKGROUND: Myocardial feature tracking (FT) provides a comprehensive analysis of myocardial deformation from cine balanced steady-state free-precession images (bSSFP). However, FT remains time-consuming, precluding its clinical adoption.
PURPOSE: To compare left-ventricular global radial strain (GRS) and global circumferential strain (GCS) values measured using automated DeepStrain analysis of short-axis cine images to those calculated using manual commercially available FT analysis.
STUDY TYPE: Retrospective, single-center.
POPULATION: A total of 30 healthy subjects and 120 patients with cardiac disease for DeepStrain development. For evaluation, 47 healthy subjects (36 male, 53 ± 5 years) and 533 patients who had undergone a clinical cardiac MRI (373 male, 59 ± 14 years). FIELD STRENGTH/SEQUENCE: bSSFP sequence at 1.5 T (Phillips) and 3 T (Siemens).
ASSESSMENT: Automated DeepStrain measurements of GRS and GCS were compared to commercially available FT (Circle, cvi42) measures obtained by readers with 1 year and 3 years of experience. Comparisons were performed overall and stratified by scanner manufacturer.
STATISTICAL TESTS: Paired t-test, linear regression slope, Pearson correlation coefficient (r).
RESULTS: Overall, FT and DeepStrain measurements of GCS were not significantly different (P = 0.207), but measures of GRS were significantly different. Measurements of GRS from Philips (slope = 1.06 [1.03 1.08], r = 0.85) and Siemens (slope = 1.04 [0.99 1.09], r = 0.83) data showed a very strong correlation and agreement between techniques. Measurements of GCS from Philips (slope = 0.98 [0.98 1.01], r = 0.91) and Siemens (slope = 1.0 [0.96 1.03], r = 0.88) data similarly showed a very strong correlation. The average analysis time per subject was 4.1 ± 1.2 minutes for FT and 34.7 ± 3.3 seconds for DeepStrain, representing a 7-fold reduction in analysis time.
DATA CONCLUSION: This study demonstrated high correlation of myocardial GCS and GRS measurements between freely available fully automated DeepStrain and commercially available manual FT software, with substantial time-saving in the analysis.
EVIDENCE LEVEL: 3 TECHNICAL EFFICACY: Stage 3.",,,Journal of Magnetic Resonance Imaging,,,2022-07-28,2022,2022-07-28,2022-07-28,,,,Closed,Article,"Morales, Manuel A.; Cirillo, Julia; Nakata, Kei; Kucukseymen, Selcuk; Ngo, Long H.; Izquierdo‐Garcia, David; Catana, Ciprian; Nezafat, Reza","Morales, Manuel A. (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, Massachusetts, USA); Cirillo, Julia (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, Massachusetts, USA); Nakata, Kei (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, Massachusetts, USA); Kucukseymen, Selcuk (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, Massachusetts, USA); Ngo, Long H. (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, Massachusetts, USA); Izquierdo‐Garcia, David (Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Boston, Massachusetts, USA; Harvard‐MIT Division of Health Sciences and Technology, Cambridge, Massachusetts, USA); Catana, Ciprian (Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Boston, Massachusetts, USA); Nezafat, Reza (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, Massachusetts, USA)","Nezafat, Reza (Beth Israel Deaconess Medical Center; Harvard University)","Morales, Manuel A. (Beth Israel Deaconess Medical Center; Harvard University); Cirillo, Julia (Beth Israel Deaconess Medical Center; Harvard University); Nakata, Kei (Beth Israel Deaconess Medical Center; Harvard University); Kucukseymen, Selcuk (Beth Israel Deaconess Medical Center; Harvard University); Ngo, Long H. (Beth Israel Deaconess Medical Center; Harvard University); Izquierdo‐Garcia, David (Athinoula A. Martinos Center for Biomedical Imaging; Harvard–MIT Division of Health Sciences and Technology); Catana, Ciprian (Athinoula A. Martinos Center for Biomedical Imaging); Nezafat, Reza (Beth Israel Deaconess Medical Center; Harvard University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1149814314,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,,
1397,pub.1151129502,10.1109/icivc55077.2022.9886218,,,CAU: A Consensus Model of Augmented Unlabeled Data for Medical Image Segmentation,"Medical image segmentation plays an important role in medical diagnosis and treatment. However, medical image data are more expensive and time-consuming to obtain than ordinary image data. In this paper, we propose a novel semi-supervised method named CAU for medical image segmentation, which can easily use Convolutional Neural Networks (CNNs) to segment 2D images. The network learns through a combination of common supervision losses for labeled data and losses for unlabeled data. Specifically, we augment the unlabeled data strongly and weakly and send them to the student model and the teacher model respectively. We take full advantage of unlabeled data learning through a novel combination of minimizing the difference between network predictions for different data augmentation processing scenarios and using an unsupervised loss of min-entropy on the outputs of the two networks. In order to improve the regularization effect, we use the teacher-student model to optimize the teacher model by averaging the student model weights. Experiments show that our method in labeled data experiments with 5%, 10%,35% and 50% labeled data on Automated Cardiac Diagnosis Challeng(ACDC) dataset exceeds the fully supervised algorithm using the same amount of data and the existing popular semi-supervised learning algorithms 1.922% ~ 4.451%(Dice),0.841 ~ 5.031(Asd) and 0.06 ~ 1.116(HD95), respectively, and the Dice index exceeds the fully supervised algorithm 0.019% with 50% labeled data, which verifies its effectiveness in medical image segmentation.",The paper is sponsored by Sponsored by Shanghai Pujiang Program with grant number 21PJD026.,The paper is sponsored by Sponsored by Shanghai Pujiang Program with grant number 21PJD026.,,"2022 7th International Conference on Image, Vision and Computing (ICIVC)",,2022-07-28,2022,,2022-07-28,0,,368-374,Closed,Proceeding,"Cheng, Wenli; Jiao, Jiajia","Cheng, Wenli (College of Information Engineering, Shanghai Maritime University Shanghai Maritime University); Jiao, Jiajia (College of Information Engineering, Shanghai Maritime University Shanghai Maritime University)","Cheng, Wenli ","Cheng, Wenli (); Jiao, Jiajia ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151129502,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1138,pub.1149763627,10.48550/arxiv.2207.11683,,,PCA: Semi-supervised Segmentation with Patch Confidence Adversarial  Training,"Deep learning based semi-supervised learning (SSL) methods have achieved
strong performance in medical image segmentation, which can alleviate doctors'
expensive annotation by utilizing a large amount of unlabeled data. Unlike most
existing semi-supervised learning methods, adversarial training based methods
distinguish samples from different sources by learning the data distribution of
the segmentation map, leading the segmenter to generate more accurate
predictions. We argue that the current performance restrictions for such
approaches are the problems of feature extraction and learning preference. In
this paper, we propose a new semi-supervised adversarial method called Patch
Confidence Adversarial Training (PCA) for medical image segmentation. Rather
than single scalar classification results or pixel-level confidence maps, our
proposed discriminator creates patch confidence maps and classifies them at the
scale of the patches. The prediction of unlabeled data learns the pixel
structure and context information in each patch to get enough gradient
feedback, which aids the discriminator in convergent to an optimal state and
improves semi-supervised segmentation performance. Furthermore, at the
discriminator's input, we supplement semantic information constraints on
images, making it simpler for unlabeled data to fit the expected data
distribution. Extensive experiments on the Automated Cardiac Diagnosis
Challenge (ACDC) 2017 dataset and the Brain Tumor Segmentation (BraTS) 2019
challenge dataset show that our method outperforms the state-of-the-art
semi-supervised methods, which demonstrates its effectiveness for medical image
segmentation.",,,arXiv,,,2022-07-24,2022,,,,,,All OA, Green,Preprint,"Xu, Zihang; Xu, Zhenghua; Zhang, Shuo; Lukasiewicz, Thomas","Xu, Zihang (); Xu, Zhenghua (); Zhang, Shuo (); Lukasiewicz, Thomas ()",,"Xu, Zihang (); Xu, Zhenghua (); Zhang, Shuo (); Lukasiewicz, Thomas ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149763627,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1459,pub.1150639897,10.1109/cbms55023.2022.00031,,,Left and Right Ventricular Segmentation Based on 3D Region-Aware U-Net,"The cardiac is one of the essential organs, and the segmentation of the left and right ventricular of cardiac is essential in diagnosing various heart diseases. The most popular method for the segmentation of 3D MRI images is the nnUNet. However, the 3D MRI volume of the ventricular contains other organs which interfere with the segmentation of the ventricular. Hence, we proposed a novel region-aware U-Net segmentation method RegUNet for ventricular segmentation. RegUNet improves the ventricular's segmentation performance by first capturing the region of interest (RoI) of the ventricular and then segmenting the ventricular with the captured RoI features, which reduces the segmentation module's difficulty by keeping the cardiac's features and leaving others such that RegUNet can focus on ventricular segmentation. Besides, since the model segments the ventricular with the captured RoI features, it saves the model's computing resources from identifying the background of the volume. Since 3D cardiac MRI volumes scanned by the different devices have diverse statistical characteristics, which causes the model's performance in processing the multi-source cardiac volumes to be unstable. We stabilize the model's performance with a multi-sources feature normalization strategy, which normalizes the feature from a different source with different parameters. We validated the proposed method on the M&MS dataset, a multi-sources 3D MRI cardiac segmentation dataset. Experiments showed that RegUNet's segmentation ability reached the state-of-the-art.",,"This work was supported in part by grants from the National Natural Science Foundation of China (Nos. 61973221 and 62002232), the Natural Science Foundation of Guangdong Province of China (No. 2019A1515011165), and the Shenzhen Research Foundation for Basic Re-search, China (No.20200824213635001).",,2022 IEEE 35th International Symposium on Computer-Based Medical Systems (CBMS),,2022-07-23,2022,,2022-07-23,0,,137-142,Closed,Proceeding,"Huang, Xiaoting; Chen, Wenjie; Liu, Xueting; Wu, Huisi; Wen, Zhenkun; Shen, Linlin","Huang, Xiaoting (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China); Chen, Wenjie (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China); Liu, Xueting (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China); Wu, Huisi (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China); Wen, Zhenkun (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China); Shen, Linlin (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China)",,"Huang, Xiaoting (Shenzhen University); Chen, Wenjie (Shenzhen University); Liu, Xueting (Shenzhen University); Wu, Huisi (Shenzhen University); Wen, Zhenkun (Shenzhen University); Shen, Linlin (Shenzhen University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150639897,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
1516,pub.1150532995,10.1109/icme52920.2022.9859940,,,Cross U-Net: Reconstructing Cardiac MR Image for Segmentation,"It is essential to develop a more accurate segmentation method of cardiac MR image (CMRI) because segmentation results can affect further diagnoses of heart conditions. In this paper, we put forth a novel network model. It can learn the intrinsic structure and inter-dependence (ISID) of segmentation targets in the input CMRI and incorporate them to guide segmentation assignments. We argue that the ISID of segmentation targets is a crucial feature for improving segmentation accuracy. However, this feature is lost during the stage of training pixel-wise classification networks. The application ability of our approach is evaluated on the public dataset of the Automated Cardiac Diagnosis Challenge (ACDC), and the results exhibited that ours could reduce false predicted labels, particularly in basal and apical slices. In addition, we submitted segmentation results to the evaluation platform of ACDC and obtained an average Dice score of 0.92.",,,,2022 IEEE International Conference on Multimedia and Expo (ICME),,2022-07-22,2022,,2022-07-22,0,,1-6,Closed,Proceeding,"Zheng, Hong; Wang, Lili; Chen, Yucheng; Li, Xiaoning","Zheng, Hong (College of Computer Science, Sichuan Normal University, Chengdu, 610101, China); Wang, Lili (Department of Cardiology, West China Hospital, Sichuan University, Chengdu, 610041, China); Chen, Yucheng (Department of Cardiology, West China Hospital, Sichuan University, Chengdu, 610041, China); Li, Xiaoning (College of Computer Science, Sichuan Normal University, Chengdu, 610101, China)",,"Zheng, Hong (Sichuan Normal University); Wang, Lili (West China Hospital of Sichuan University); Chen, Yucheng (West China Hospital of Sichuan University); Li, Xiaoning (Sichuan Normal University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150532995,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1512,pub.1150533035,10.1109/icme52920.2022.9859985,,,Context Correlation Aware Network for Cardiac Segmentation,"Automatically segmenting the anatomical structure of the heart from the cardiac magnetic resonance (CMR) images offers a great potential to augment the traditional healthcare strategy for the quantitative analysis of cardiac contractile function. Most of the existing CNN-based methods for cardiac segmentation tend to ignore the misalignment issues during the feature aggregation process and not fully use multi-scale context and contour information, which may lead to the unexpected misclassification caused by the falsely aligned contextual features and the discontinuity in the edge of segmentation maps. To resolve these issues, we proposed a context correlation aware network (CCA-Net). In CCA-Net, a volume correlation flow module was designed to align contour features and semantic features from adjacent levels, which offered the guidance to wrap low-resolution semantic features into high-resolution features. Besides, a residual gated squeeze module was utilized to explicitly model the boundaries and enhance the representations. Extensive experiments on the multi-sequence cardiac magnetic resonance segmentation challenge (MS-CMRSeg 2019) dataset and MICCAI challenge 2017 automatic cardiac diagnosis challenge (ACDC) dataset demonstrated that CCA-Net was superior to other state-of-the-art methods.",,"This work was partly supported by the National Natural Science Foundation of China (62103071), the Natural Science Foundation of Chongqing (cstc2021jcyj-msxmX0526) and the Science and Technology Research Program of Chongqing Municipal Education Commission (Grant No. KJQN202100630).",,2022 IEEE International Conference on Multimedia and Expo (ICME),,2022-07-22,2022,,2022-07-22,0,,1-6,Closed,Proceeding,"Fan, Junchao; Pei, Jiawei; Bi, Xiuli; Xiao, Bin; Liò, Pietro","Fan, Junchao (Chongqing University of Posts and Telecommunications, Chongqing, China); Pei, Jiawei (Chongqing University of Posts and Telecommunications, Chongqing, China); Bi, Xiuli (Chongqing University of Posts and Telecommunications, Chongqing, China); Xiao, Bin (Chongqing University of Posts and Telecommunications, Chongqing, China); Liò, Pietro (University of Cambridge, Cambridge, the UK)","Bi, Xiuli (Chongqing University of Posts and Telecommunications)","Fan, Junchao (Chongqing University of Posts and Telecommunications); Pei, Jiawei (Chongqing University of Posts and Telecommunications); Bi, Xiuli (Chongqing University of Posts and Telecommunications); Xiao, Bin (Chongqing University of Posts and Telecommunications); Liò, Pietro (University of Cambridge)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150533035,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
5668,pub.1149639140,10.1016/j.cpcardiol.2022.101330,35870544,,Artificial Intelligence and Cardiovascular Magnetic Resonance Imaging in Myocardial Infarction Patients,"Cardiovascular magnetic resonance (CMR) is an important cardiac imaging tool for assessing the prognostic extent of myocardial injury after myocardial infarction (MI). Within the context of clinical trials, CMR is also useful for assessing the efficacy of potential cardioprotective therapies in reducing MI size and preventing adverse left ventricular (LV) remodelling in reperfused MI. However, manual contouring and analysis can be time-consuming with interobserver and intra-observer variability, which can in turn lead to reduction in accuracy and precision of analysis. There is thus a need to automate CMR scan analysis in MI patients to save time, increase accuracy, increase reproducibility and increase precision. In this regard, automated imaging analysis techniques based on artificial intelligence (AI) that are developed with machine learning (ML), and more specifically deep learning (DL) strategies, can enable efficient, robust, accurate and clinician-friendly tools to be built so as to try and improve both clinician productivity and quality of patient care. In this review, we discuss basic concepts of ML in CMR, important prognostic CMR imaging biomarkers in MI and the utility of current ML applications in their analysis as assessed in research studies. We highlight potential barriers to the mainstream implementation of these automated strategies and discuss related governance and quality control issues. Lastly, we discuss the future role of ML applications in clinical trials and the need for global collaboration in growing this field.",,"Funding: Jun Hua Chong (JHC) has been supported by the Singapore Ministry of Health's National Medical Research Council Research Training Fellowship (FLWSHP19may-0013), National Medical Research Council Collaborative Centre Grant Seed Funding (NHCS-CGSF/2019/002) and New Toyo Cardiovascular Research and Education Fund (07/FY2021/EX(SL)/77-A131). SEP acknowledges support from the “SmartHeart” EPSRC programme grant (www.nihr.ac.uk; EP/P001009/1). SEP has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 825903 (euCanSHare project).",Current Problems in Cardiology,,Humans, Artificial Intelligence, Reproducibility of Results, Myocardial Infarction, Magnetic Resonance Imaging, Ventricular Remodeling,2022-07-21,2022,2022-07-21,2022-12,47,12,101330,All OA, Hybrid,Article,"Chong, Jun Hua; Abdulkareem, Musa; Petersen, Steffen E; Khanji, Mohammed Y","Chong, Jun Hua (National Heart Centre Singapore, Singapore; Cardiovascular Sciences Academic Clinical Programme, Duke-National University of Singapore Medical School, Singapore. Electronic address: jun.chong@gtc.ox.ac.uk.); Abdulkareem, Musa (Barts Heart Centre, Barts Health National Health Service Trust, London, UK; National Institute for Health Research Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University of London, London, UK; Health Data Research UK, London, UK.); Petersen, Steffen E (Barts Heart Centre, Barts Health National Health Service Trust, London, UK; National Institute for Health Research Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University of London, London, UK; Health Data Research UK, London, UK; The Alan Turing Institute, London, UK.); Khanji, Mohammed Y (Barts Heart Centre, Barts Health National Health Service Trust, London, UK; National Institute for Health Research Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University of London, London, UK; Department of Cardiology, Newham University Hospital, Barts Health NHS Trust, London, UK.)","Chong, Jun Hua (National Heart Centre Singapore; Duke NUS Graduate Medical School)","Chong, Jun Hua (National Heart Centre Singapore; Duke NUS Graduate Medical School); Abdulkareem, Musa (St Bartholomew's Hospital; Queen Mary University of London; Health Data Research UK); Petersen, Steffen E (St Bartholomew's Hospital; Queen Mary University of London; Health Data Research UK; The Alan Turing Institute); Khanji, Mohammed Y (St Bartholomew's Hospital; Queen Mary University of London; Newham University Hospital)",1,1,,,https://doi.org/10.1016/j.cpcardiol.2022.101330,https://app.dimensions.ai/details/publication/pub.1149639140,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,3 Good Health and Well Being,,,,
4135,pub.1149635347,10.1016/j.media.2022.102533,35952418,,Shape constrained CNN for segmentation guided prediction of myocardial shape and pose parameters in cardiac MRI,"Semantic segmentation using convolutional neural networks (CNNs) is the state-of-the-art for many medical image segmentation tasks including myocardial segmentation in cardiac MR images. However, the predicted segmentation maps obtained from such standard CNN do not allow direct quantification of regional shape properties such as regional wall thickness. Furthermore, the CNNs lack explicit shape constraints, occasionally resulting in unrealistic segmentations. In this paper, we use a CNN to predict shape parameters of an underlying statistical shape model of the myocardium learned from a training set of images. Additionally, the cardiac pose is predicted, which allows to reconstruct the myocardial contours. The integrated shape model regularizes the predicted contours and guarantees realistic shapes. We enforce robustness of shape and pose prediction by simultaneously performing pixel-wise semantic segmentation during training and define two loss functions to impose consistency between the two predicted representations: one distance-based loss and one overlap-based loss. We evaluated the proposed method in a 5-fold cross validation on an in-house clinical dataset with 75 subjects and on the ACDC and LVQuan19 public datasets. We show that the two newly defined loss functions successfully increase the consistency between shape and pose parameters and semantic segmentation, which leads to a significant improvement of the reconstructed myocardial contours. Additionally, these loss functions drastically reduce the occurrence of unrealistic shapes in the semantic segmentation output.",Sofie Tilborghs is supported by a Ph.D. fellowship of the Research Foundation - Flanders (FWO). This work is partially funded by KU Leuven Internal Funds C24/18/047 (promotor F. Maes) and also received funding from the Flemish Government under the Onderzoeksprogramma Artificiële Intelligentie (AI) Vlaanderen programme.,,Medical Image Analysis,,"Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Myocardium; Neural Networks, Computer",2022-07-21,2022,2022-07-21,2022-10,81,,102533,All OA, Green,Article,"Tilborghs, Sofie; Bogaert, Jan; Maes, Frederik","Tilborghs, Sofie (Department of Electrical Engineering, ESAT/PSI, KU Leuven, Leuven, Belgium; Medical Imaging Research Center, UZ Leuven, Herestraat 49 - 7003, Leuven 3000, Belgium. Electronic address: sofie.tilborghs@kuleuven.be.); Bogaert, Jan (Department of Imaging and Pathology, Radiology, KU Leuven, Leuven, Belgium; Medical Imaging Research Center, UZ Leuven, Herestraat 49 - 7003, Leuven 3000, Belgium.); Maes, Frederik (Department of Electrical Engineering, ESAT/PSI, KU Leuven, Leuven, Belgium; Medical Imaging Research Center, UZ Leuven, Herestraat 49 - 7003, Leuven 3000, Belgium.)","Tilborghs, Sofie (KU Leuven; Universitair Ziekenhuis Leuven)","Tilborghs, Sofie (KU Leuven; Universitair Ziekenhuis Leuven); Bogaert, Jan (KU Leuven; Universitair Ziekenhuis Leuven); Maes, Frederik (KU Leuven; Universitair Ziekenhuis Leuven)",0,0,,,http://arxiv.org/pdf/2203.01089,https://app.dimensions.ai/details/publication/pub.1149635347,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
1396,pub.1149637283,10.48550/arxiv.2207.09521,,,The Dice loss in the context of missing or empty labels: Introducing  $\Phi$ and $\epsilon$,"Albeit the Dice loss is one of the dominant loss functions in medical image
segmentation, most research omits a closer look at its derivative, i.e. the
real motor of the optimization when using gradient descent. In this paper, we
highlight the peculiar action of the Dice loss in the presence of missing or
empty labels. First, we formulate a theoretical basis that gives a general
description of the Dice loss and its derivative. It turns out that the choice
of the reduction dimensions $\Phi$ and the smoothing term $\epsilon$ is
non-trivial and greatly influences its behavior. We find and propose heuristic
combinations of $\Phi$ and $\epsilon$ that work in a segmentation setting with
either missing or empty labels. Second, we empirically validate these findings
in a binary and multiclass segmentation setting using two publicly available
datasets. We confirm that the choice of $\Phi$ and $\epsilon$ is indeed
pivotal. With $\Phi$ chosen such that the reductions happen over a single batch
(and class) element and with a negligible $\epsilon$, the Dice loss deals with
missing labels naturally and performs similarly compared to recent adaptations
specific for missing labels. With $\Phi$ chosen such that the reductions happen
over multiple batch elements or with a heuristic value for $\epsilon$, the Dice
loss handles empty labels correctly. We believe that this work highlights some
essential perspectives and hope that it encourages researchers to better
describe their exact implementation of the Dice loss in future work.",,,arXiv,,,2022-07-19,2022,,,,,,All OA, Green,Preprint,"Tilborghs, Sofie; Bertels, Jeroen; Robben, David; Vandermeulen, Dirk; Maes, Frederik","Tilborghs, Sofie (); Bertels, Jeroen (); Robben, David (); Vandermeulen, Dirk (); Maes, Frederik ()",,"Tilborghs, Sofie (); Bertels, Jeroen (); Robben, David (); Vandermeulen, Dirk (); Maes, Frederik ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149637283,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1515,pub.1150464165,10.1109/indiscon54605.2022.9862847,,,Heart Disease Diagnosis using Deep Learning,"This paper deals with the design and implementation of an automated algorithm which will efficiently calculate Ejection Fraction of Left Ventricle (LV) of the heart from its MRI. For several years, cardiac Magnetic Resonance Imaging (MRI) has been used by medical professionals to treat patients with various cardiovascular ailments. This is because Magnetic Resonance Imaging is a great non-invasive medical imaging technique. Due to the variability of MRIs, it is very time consuming and strenuous for medical professionals to manually analyze them in order to diagnose and treat patients. This study deals with the automated segmentation of the LV in order to calculate ejection fraction which is in turn used to diagnose the patients. Images obtained from MRIs are generally in DICOM format, hence basic pre-processing techniques have been used to convert the DICOM images into PNG format. Then segmentation of Left Ventricle is performed, and required volumes are calculated which are utilized to compute ejection fraction. This algorithm will reduce the time taken to analyze MRIs by providing better accuracy and ease to specialists. To develop this automated algorithm, image processing along with deep learning (convolutional neural networks) has been used and an accuracy of over eighty-one percent has been achieved.","The authors would like to deeply thank our mentor, Dr. Manoj Sankhe, Head of Department – Electronics and Telecommunication Engineering, SVKM’S NMIMS MUKESH PATEL SCHOOL OF TECHNOLOGY MANAGEMENT AND ENGINEERING for providing the necessary guidance and support in order to successfully complete this research. The authors would also like to profoundly thank Dr. Deepak Patkar, Director - Medical Services &amp; Head – Imaging and his department at NANAVATI MAX SUPER SPECIALTY HOSPITAL, Mumbai for extending his support in providing the required real-world data used for predicting the outcome of model in this study. Additionally, the authors would like express their gratitude towards SVKM’S NMIMS MUKESH PATEL SCHOOL OF TECHNOLOGY MANAGEMENT AND ENGINEERING for providing all the necessary resources for the successful completion of this research.",,,2022 IEEE India Council International Subsections Conference (INDISCON),,2022-07-17,2022,,2022-07-17,0,,1-6,Closed,Proceeding,"Mehta, Kush; Subramanian, Kirtana","Mehta, Kush (Dept. of Electronics and Telecomm Engineering, Svkm’s Nmims Mpstme, Mumbai, India); Subramanian, Kirtana (Dept. of Electronics and Telecomm Engineering, Svkm’s Nmims Mpstme, Mumbai, India)","Mehta, Kush ","Mehta, Kush (); Subramanian, Kirtana ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150464165,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,,
3237,pub.1149526643,10.1016/j.media.2022.102532,35872359,,Cardiac MRI segmentation with sparse annotations: Ensembling deep learning uncertainty and shape priors,"The performance of deep learning for cardiac magnetic resonance imaging (MRI) segmentation is oftentimes degraded when using small datasets and sparse annotations for training or adapting a pre-trained model to previously unseen datasets. Here, we developed and evaluated an approach to addressing some of these issues to facilitate broader use of deep learning for short-axis cardiac MRI segmentation. We developed a globally optimal label fusion (GOLF) algorithm that enforced spatial smoothness to generate consensus segmentation from segmentation predictions provided by a deep learning ensemble algorithm. The GOLF consensus was entered into an uncertainty-guided coupled continuous kernel cut (ugCCKC) algorithm that employed normalized cut, image-grid continuous regularization, and ""nesting"" and circular shape priors of the left ventricular myocardium (LVM) and cavity (LVC). In addition, the uncertainty measurements derived from the segmentation predictions were used to constrain the similarity of GOLF and final segmentation. We optimized ugCCKC through upper bound relaxation, for which we developed an efficient coupled continuous max-flow algorithm implemented in an iterative manner. We showed that GOLF yielded average symmetric surface distance (ASSD) 0.2-0.8 mm lower than an averaging method with higher or similar Dice similarity coefficient (DSC). We also demonstrated that ugCCKC incorporating the shape priors improved DSC by 0.01-0.05 and reduced ASSD by 0.1-0.9 mm. In addition, we integrated GOLF and ugCCKC into a deep learning ensemble algorithm by refining the segmentation of an unannotated dataset and using the refined segmentation to update the trained models. With the proposed framework, we demonstrated the capability of using relatively small datasets (5-10 subjects) with sparse (5-25% slices labeled) annotations to train a deep learning algorithm, while achieving DSC of 0.871-0.893 for LVM and 0.933-0.959 for LVC on the LVQuan dataset, and these were 0.844-0.871 for LVM and 0.923-0.931 for LVC on the ACDC dataset. Furthermore, we showed that the proposed approach can be adapted to substantially alleviate the domain shift issue. Moreover, we calculated a number of commonly used LV function measurements using the derived segmentation and observed strong correlations (Pearson r=0.77-1.00, p<0.001) between algorithm and manual LV function analyses. These results suggest that the developed approaches can be used to facilitate broader application of deep learning in research and clinical cardiac MR imaging workflow.","We acknowledge the use of the facilities of Compute Canada. This work was funded by Canadian Institutes of Health Research (CIHR) MOP: #93531, Ontario Research Fund and GE Healthcare, and National Natural Science Foundation of China No. 81571754.",,Medical Image Analysis,,"Deep Learning; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Uncertainty",2022-07-16,2022,2022-07-16,2022-10,81,,102532,Closed,Article,"Guo, Fumin; Ng, Matthew; Kuling, Grey; Wright, Graham","Guo, Fumin (Wuhan National Laboratory for Optoelectronics, Biomedical Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Medical Biophysics, University of Toronto, Toronto, Canada; Sunnybrook Research Institute, University of Toronto, Toronto, Canada. Electronic address: fguo@hust.edu.cn.); Ng, Matthew (Department of Medical Biophysics, University of Toronto, Toronto, Canada; Sunnybrook Research Institute, University of Toronto, Toronto, Canada.); Kuling, Grey (Department of Medical Biophysics, University of Toronto, Toronto, Canada; Sunnybrook Research Institute, University of Toronto, Toronto, Canada.); Wright, Graham (Department of Medical Biophysics, University of Toronto, Toronto, Canada; Sunnybrook Research Institute, University of Toronto, Toronto, Canada.)","Guo, Fumin (Huazhong University of Science and Technology; University of Toronto)","Guo, Fumin (Huazhong University of Science and Technology; University of Toronto); Ng, Matthew (University of Toronto); Kuling, Grey (University of Toronto); Wright, Graham (University of Toronto)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1149526643,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
5074,pub.1149391016,10.3390/jimaging8070194,35877637,PMC9318676,Cardiac Disease Classification Using Two-Dimensional Thickness and Few-Shot Learning Based on Magnetic Resonance Imaging Image Segmentation,"Cardiac cine magnetic resonance imaging (MRI) is a widely used technique for the noninvasive assessment of cardiac functions. Deep neural networks have achieved considerable progress in overcoming various challenges in cine MRI analysis. However, deep learning models cannot be used for classification because limited cine MRI data are available. To overcome this problem, features from cine image settings are derived by handcrafting and addition of other clinical features to the classical machine learning approach for ensuring the model fits the MRI device settings and image parameters required in the analysis. In this study, a novel method was proposed for classifying heart disease (cardiomyopathy patient groups) using only segmented output maps. In the encoder-decoder network, the fully convolutional EfficientNetB5-UNet was modified to perform the semantic segmentation of the MRI image slice. A two-dimensional thickness algorithm was used to combine the segmentation outputs for the 2D representation of images of the end-diastole (ED) and end-systole (ES) cardiac volumes. The thickness images were subsequently used for classification by using a few-shot model with an adaptive subspace classifier. Model performance was verified by applying the model to the 2017 MICCAI Medical Image Computing and Computer-Assisted Intervention dataset. High segmentation performance was achieved as follows: the average Dice coefficients of segmentation were 96.24% (ED) and 89.92% (ES) for the left ventricle (LV); the values for the right ventricle (RV) were 92.90% (ED) and 86.92% (ES). The values for myocardium were 88.90% (ED) and 90.48% (ES). An accuracy score of 92% was achieved in the classification of various cardiomyopathy groups without clinical features. A novel rapid analysis approach was proposed for heart disease diagnosis, especially for cardiomyopathy conditions using cine MRI based on segmented output maps.",We thank to Post-2017-MICCAI-challenge testing phase organizer for ACDC dataset and the support to conduct segmentation and diagnosis testing.,"This study was funded by Universitas Diponegoro, Republic of Indonesia under the scheme “Collaboration Research” Award Number 2009/UN7.5.8/PP/2020, and supported by the JSPS KAKENHI Grant Number JP20K16729, Kyushu University, Japan. Project granted to A.W., A.S., E.A.S. and F.A.N., M.K. and H.A.",Journal of Imaging,,,2022-07-11,2022,2022-07-11,,8,7,194,All OA, Gold,Article,"Wibowo, Adi; Triadyaksa, Pandji; Sugiharto, Aris; Sarwoko, Eko Adi; Nugroho, Fajar Agung; Arai, Hideo; Kawakubo, Masateru","Wibowo, Adi (Department of Informatics, Tembalang FSM Campus, Universitas Diponegoro, Semarang 50275, Indonesia;, arissugiharto@lecturer.undip.ac.id, (A.S.);, ekoadisarwoko@lecturer.undip.ac.id, (E.A.S.);, fajar@lecturer.undip.ac.id, (F.A.N.)); Triadyaksa, Pandji (Department of Physics, Tembalang FSM Campus, Universitas Diponegoro, Semarang 50275, Indonesia;, p.triadyaksa@fisika.fsm.undip.ac.id); Sugiharto, Aris (Department of Informatics, Tembalang FSM Campus, Universitas Diponegoro, Semarang 50275, Indonesia;, arissugiharto@lecturer.undip.ac.id, (A.S.);, ekoadisarwoko@lecturer.undip.ac.id, (E.A.S.);, fajar@lecturer.undip.ac.id, (F.A.N.)); Sarwoko, Eko Adi (Department of Informatics, Tembalang FSM Campus, Universitas Diponegoro, Semarang 50275, Indonesia;, arissugiharto@lecturer.undip.ac.id, (A.S.);, ekoadisarwoko@lecturer.undip.ac.id, (E.A.S.);, fajar@lecturer.undip.ac.id, (F.A.N.)); Nugroho, Fajar Agung (Department of Informatics, Tembalang FSM Campus, Universitas Diponegoro, Semarang 50275, Indonesia;, arissugiharto@lecturer.undip.ac.id, (A.S.);, ekoadisarwoko@lecturer.undip.ac.id, (E.A.S.);, fajar@lecturer.undip.ac.id, (F.A.N.)); Arai, Hideo (Fukuokaken Saiseikai Futsukaichi Hospital, Fukuoka 818-8516, Japan;, fukuoka.hideo@gmail.com); Kawakubo, Masateru (Department of Health Sciences, Faculty of Medical Sciences, Kyushu University, Fukuoka 812-8582, Japan;, kawakubo.masateru.968@m.kyushu-u.ac.jp)","Wibowo, Adi (Diponegoro University)","Wibowo, Adi (Diponegoro University); Triadyaksa, Pandji (Diponegoro University); Sugiharto, Aris (Diponegoro University); Sarwoko, Eko Adi (Diponegoro University); Nugroho, Fajar Agung (Diponegoro University); Arai, Hideo (); Kawakubo, Masateru (Kyushu University)",1,1,,,https://www.mdpi.com/2313-433X/8/7/194/pdf?version=1657533822,https://app.dimensions.ai/details/publication/pub.1149391016,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,
4530,pub.1149359829,10.1016/j.media.2022.102528,35834896,,Cardiac segmentation on late gadolinium enhancement MRI: A benchmark study from multi-sequence cardiac MR segmentation challenge,"Accurate computing, analysis and modeling of the ventricles and myocardium from medical images are important, especially in the diagnosis and treatment management for patients suffering from myocardial infarction (MI). Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) provides an important protocol to visualize MI. However, compared with the other sequences LGE CMR images with gold standard labels are particularly limited. This paper presents the selective results from the Multi-Sequence Cardiac MR (MS-CMR) Segmentation challenge, in conjunction with MICCAI 2019. The challenge offered a data set of paired MS-CMR images, including auxiliary CMR sequences as well as LGE CMR, from 45 patients who underwent cardiomyopathy. It was aimed to develop new algorithms, as well as benchmark existing ones for LGE CMR segmentation focusing on myocardial wall of the left ventricle and blood cavity of the two ventricles. In addition, the paired MS-CMR images could enable algorithms to combine the complementary information from the other sequences for the ventricle segmentation of LGE CMR. Nine representative works were selected for evaluation and comparisons, among which three methods are unsupervised domain adaptation (UDA) methods and the other six are supervised. The results showed that the average performance of the nine methods was comparable to the inter-observer variations. Particularly, the top-ranking algorithms from both the supervised and UDA methods could generate reliable and robust segmentation results. The success of these methods was mainly attributed to the inclusion of the auxiliary sequences from the MS-CMR images, which provide important label information for the training of deep neural networks. The challenge continues as an ongoing resource, and the gold standard segmentation as well as the MS-CMR images of both the training and test data are available upon registration via its homepage (www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mscmrseg/).","This work was funded by the National Natural Science Foundation of China (Grant no. 61971142, 62111530195 and 62011540404) and the development fund for Shanghai talents (No. 2020015).",,Medical Image Analysis,,Benchmarking, Contrast Media, Gadolinium, Heart, Humans, Magnetic Resonance Imaging, Myocardial Infarction, Myocardium,2022-07-09,2022,2022-07-09,2022-10,81,,102528,All OA, Green,Article,"Zhuang, Xiahai; Xu, Jiahang; Luo, Xinzhe; Chen, Chen; Ouyang, Cheng; Rueckert, Daniel; Campello, Victor M; Lekadir, Karim; Vesal, Sulaiman; RaviKumar, Nishant; Liu, Yashu; Luo, Gongning; Chen, Jingkun; Li, Hongwei; Ly, Buntheng; Sermesant, Maxime; Roth, Holger; Zhu, Wentao; Wang, Jiexiang; Ding, Xinghao; Wang, Xinyue; Yang, Sen; Li, Lei","Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China. Electronic address: https://www.sdspeople.fudan.edu.cn/zhuangxiahai/?); Xu, Jiahang (School of Data Science, Fudan University, Shanghai, China. Electronic address: jhxu18@fudan.edu.cn.); Luo, Xinzhe (School of Data Science, Fudan University, Shanghai, China.); Chen, Chen (Biomedical Image Analysis Group, Imperial College London, London, UK.); Ouyang, Cheng (Biomedical Image Analysis Group, Imperial College London, London, UK.); Rueckert, Daniel (Biomedical Image Analysis Group, Imperial College London, London, UK.); Campello, Victor M (Department Mathematics & Computer Science, Universitat de Barcelona, Barcelona, Spain.); Lekadir, Karim (Department Mathematics & Computer Science, Universitat de Barcelona, Barcelona, Spain.); Vesal, Sulaiman (Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany.); RaviKumar, Nishant (Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany.); Liu, Yashu (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Luo, Gongning (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Chen, Jingkun (Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China.); Li, Hongwei (Department of Informatics, Technical University of Munich, Germany.); Ly, Buntheng (INRIA, Université Côte d'Azur, Sophia Antipolis, France.); Sermesant, Maxime (INRIA, Université Côte d'Azur, Sophia Antipolis, France.); Roth, Holger (NVIDIA, Bethesda, USA.); Zhu, Wentao (NVIDIA, Bethesda, USA.); Wang, Jiexiang (School of Informatics, Xiamen University, Xiamen, China.); Ding, Xinghao (School of Informatics, Xiamen University, Xiamen, China.); Wang, Xinyue (College of Electrical Engineering, Sichuan University, Chengdu, China.); Yang, Sen (College of Electrical Engineering, Sichuan University, Chengdu, China; Tencent AI Lab, Shenzhen, China.); Li, Lei (School of Data Science, Fudan University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China. Electronic address: lilei.sky@sjtu.edu.cn.)","Zhuang, Xiahai (Fudan University); Xu, Jiahang (Fudan University); Li, Lei (Fudan University; Shanghai Jiao Tong University)","Zhuang, Xiahai (Fudan University); Xu, Jiahang (Fudan University); Luo, Xinzhe (Fudan University); Chen, Chen (Imperial College London); Ouyang, Cheng (Imperial College London); Rueckert, Daniel (Imperial College London); Campello, Victor M (University of Barcelona); Lekadir, Karim (University of Barcelona); Vesal, Sulaiman (University of Erlangen-Nuremberg); RaviKumar, Nishant (University of Erlangen-Nuremberg); Liu, Yashu (Harbin Institute of Technology); Luo, Gongning (Harbin Institute of Technology); Chen, Jingkun (Southern University of Science and Technology); Li, Hongwei (Technical University of Munich); Ly, Buntheng (); Sermesant, Maxime (); Roth, Holger (Nvidia (United States)); Zhu, Wentao (Nvidia (United States)); Wang, Jiexiang (Xiamen University); Ding, Xinghao (Xiamen University); Wang, Xinyue (Sichuan University); Yang, Sen (Sichuan University; Tencent (China)); Li, Lei (Fudan University; Shanghai Jiao Tong University)",8,7,,,http://arxiv.org/pdf/2006.12434,https://app.dimensions.ai/details/publication/pub.1149359829,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,
5350,pub.1149265576,10.3390/jcm11133910,35807195,PMC9267740,Artificial Intelligence in Cardiology—A Narrative Review of Current Status,"Artificial intelligence (AI) is an integral part of clinical decision support systems (CDSS), offering methods to approximate human reasoning and computationally infer decisions. Such methods are generally based on medical knowledge, either directly encoded with rules or automatically extracted from medical data using machine learning (ML). ML techniques, such as Artificial Neural Networks (ANNs) and support vector machines (SVMs), are based on mathematical models with parameters that can be optimally tuned using appropriate algorithms. The ever-increasing computational capacity of today's computer systems enables more complex ML systems with millions of parameters, bringing AI closer to human intelligence. With this objective, the term deep learning (DL) has been introduced to characterize ML based on deep ANN (DNN) architectures with multiple layers of artificial neurons. Despite all of these promises, the impact of AI in current clinical practice is still limited. However, this could change shortly, as the significantly increased papers in AI, machine learning and deep learning in cardiology show. We highlight the significant achievements of recent years in nearly all areas of cardiology and underscore the mounting evidence suggesting how AI will take a central stage in the field.",,This research received no external funding.,Journal of Clinical Medicine,,,2022-07-05,2022,2022-07-05,,11,13,3910,All OA, Gold,Article,"Koulaouzidis, George; Jadczyk, Tomasz; Iakovidis, Dimitris K.; Koulaouzidis, Anastasios; Bisnaire, Marc; Charisopoulou, Dafni","Koulaouzidis, George (Department of Biochemical Sciences, Pomeranian Medical University (PMU), 70-204 Szczecin, Poland;, koulaou@yahoo.co.uk); Jadczyk, Tomasz (Division of Cardiology and Structural Heart Diseases, Medical University of Silesia, 40-551 Katowice, Poland;, tomasz.jadczyk@gmail.com; International Clinical Research Center, St. Anne’s University Hospital Brno, 656 91 Brno, Czech Republic); Iakovidis, Dimitris K. (Department of Computer Science and Biomedical Informatics, University of Thessaly, 40500 Lamia, Greece;, diakovidis@uth.gr); Koulaouzidis, Anastasios (Department of Social Medicine & Public Health, Pomeranian Medical University (PMU), 70-204 Szczecin, Poland; Department of Medicine, OUH Svendborg Sygehus, 5700 Svendborg, Denmark; Surgical Research Unit, Odense University Hospital, 5000 Odense, Denmark; Department of Clinical Research, University of Southern Denmark (SDU), 5000 Odense, Denmark); Bisnaire, Marc (Cardiology Research and Scientific Advancements, UVA Research, Toronto, ON L3R 3Z3, Canada;, marc.bisnaire@uvaresearch.com); Charisopoulou, Dafni (Academic Centre for Congenital Heart Disease, 6500 HB Nijmegen, The Netherlands;, dafnithess@yahoo.com; Amalia Children’s Hospital, Radboud University Medical Centre, 6525 GA Nijmegen, The Netherlands)","Koulaouzidis, Anastasios (Pomeranian Medical University; Svendborg Sygehus; Odense University Hospital; University of Southern Denmark)","Koulaouzidis, George (Pomeranian Medical University); Jadczyk, Tomasz (Medical University of Silesia; International Clinical Research Center of St. Anne's University Hospital Brno); Iakovidis, Dimitris K. (University of Thessaly); Koulaouzidis, Anastasios (Pomeranian Medical University; Svendborg Sygehus; Odense University Hospital; University of Southern Denmark); Bisnaire, Marc (); Charisopoulou, Dafni (Amalia Kinderziekenhuis)",4,4,,,https://www.mdpi.com/2077-0383/11/13/3910/pdf?version=1657011873,https://app.dimensions.ai/details/publication/pub.1149265576,32 Biomedical and Clinical Sciences,,,,,,,,,,,
1577,pub.1149253247,10.48550/arxiv.2207.01900,,,ACT-Net: Asymmetric Co-Teacher Network for Semi-supervised  Memory-efficient Medical Image Segmentation,"While deep models have shown promising performance in medical image
segmentation, they heavily rely on a large amount of well-annotated data, which
is difficult to access, especially in clinical practice. On the other hand,
high-accuracy deep models usually come in large model sizes, limiting their
employment in real scenarios. In this work, we propose a novel asymmetric
co-teacher framework, ACT-Net, to alleviate the burden on both expensive
annotations and computational costs for semi-supervised knowledge distillation.
We advance teacher-student learning with a co-teacher network to facilitate
asymmetric knowledge distillation from large models to small ones by
alternating student and teacher roles, obtaining tiny but accurate models for
clinical employment. To verify the effectiveness of our ACT-Net, we employ the
ACDC dataset for cardiac substructure segmentation in our experiments.
Extensive experimental results demonstrate that ACT-Net outperforms other
knowledge distillation methods and achieves lossless segmentation performance
with 250x fewer parameters.",,,arXiv,,,2022-07-05,2022,,,,,,All OA, Green,Preprint,"Zhao, Ziyuan; Zhu, Andong; Zeng, Zeng; Veeravalli, Bharadwaj; Guan, Cuntai","Zhao, Ziyuan (); Zhu, Andong (); Zeng, Zeng (); Veeravalli, Bharadwaj (); Guan, Cuntai ()",,"Zhao, Ziyuan (); Zhu, Andong (); Zeng, Zeng (); Veeravalli, Bharadwaj (); Guan, Cuntai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149253247,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1066,pub.1149253141,10.48550/arxiv.2207.01791,,,A deep cascade of ensemble of dual domain networks with gradient-based  T1 assistance and perceptual refinement for fast MRI reconstruction,"Deep learning networks have shown promising results in fast magnetic
resonance imaging (MRI) reconstruction. In our work, we develop deep networks
to further improve the quantitative and the perceptual quality of
reconstruction. To begin with, we propose reconsynergynet (RSN), a network that
combines the complementary benefits of independently operating on both the
image and the Fourier domain. For a single-coil acquisition, we introduce deep
cascade RSN (DC-RSN), a cascade of RSN blocks interleaved with data fidelity
(DF) units. Secondly, we improve the structure recovery of DC-RSN for T2
weighted Imaging (T2WI) through assistance of T1 weighted imaging (T1WI), a
sequence with short acquisition time. T1 assistance is provided to DC-RSN
through a gradient of log feature (GOLF) fusion. Furthermore, we propose
perceptual refinement network (PRN) to refine the reconstructions for better
visual information fidelity (VIF), a metric highly correlated to radiologists
opinion on the image quality. Lastly, for multi-coil acquisition, we propose
variable splitting RSN (VS-RSN), a deep cascade of blocks, each block
containing RSN, multi-coil DF unit, and a weighted average module. We
extensively validate our models DC-RSN and VS-RSN for single-coil and
multi-coil acquisitions and report the state-of-the-art performance. We obtain
a SSIM of 0.768, 0.923, 0.878 for knee single-coil-4x, multi-coil-4x, and
multi-coil-8x in fastMRI. We also conduct experiments to demonstrate the
efficacy of GOLF based T1 assistance and PRN.",,,arXiv,,,2022-07-04,2022,,,,,,All OA, Green,Preprint,"Murugesan, Balamurali; Ramanarayanan, Sriprabha; Vijayarangan, Sricharan; Ram, Keerthi; Jagannathan, Naranamangalam R; Sivaprakasam, Mohanasankar","Murugesan, Balamurali (); Ramanarayanan, Sriprabha (); Vijayarangan, Sricharan (); Ram, Keerthi (); Jagannathan, Naranamangalam R (); Sivaprakasam, Mohanasankar ()",,"Murugesan, Balamurali (); Ramanarayanan, Sriprabha (); Vijayarangan, Sricharan (); Ram, Keerthi (); Jagannathan, Naranamangalam R (); Sivaprakasam, Mohanasankar ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149253141,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,
8077,pub.1150860641,10.1109/embc48229.2022.9871950,36085880,,3D Cardiac Substructures Segmentation from CMRI using Generative Adversarial Network (GAN),"Cardiac magnetic resonance imaging (CMRI) improves the diagnosis of cardiovascular diseases by providing images at high spatio-temporal resolution helping physicians in providing correct treatment plans. Segmentation and identification of various substructures of the heart at different cardiac phases of end-systole and end-diastole helps in the extraction of ventricular function information such as stroke volume, ejection fraction, myocardium thickness, etc. Manual delineation of the substructures is tedious, time-consuming, and error-prone. We have implemented a 3D GAN that includes 3D contextual information capable of segmenting and identifying the substructures at different cardiac phases with improved accuracy. Our method is evaluated on the ACDC dataset (4 pathologies, 1 healthy group) to show that the proposed out-performs other methods in literature with less amount of data. Also, the proposed provided a better Dice score in segmentation surpassing other methods on a blind-tested M&Ms dataset.",,,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),Cardiovascular Diseases, Heart, Humans, Magnetic Resonance Imaging, Stroke Volume, Ventricular Function,2022-07,2022,,2022-07,0,,1698-1701,Closed,Proceeding,"Kanakatte, Aparna; Bhatia, Divya; Ghose, Avik","Kanakatte, Aparna (TCS Research, Bengaluru, India); Bhatia, Divya (TCS Research, Bengaluru, India); Ghose, Avik (TCS Research, Bengaluru, India)",,"Kanakatte, Aparna (); Bhatia, Divya (); Ghose, Avik ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150860641,32 Biomedical and Clinical Sciences, 40 Engineering, 4013 Geomatic Engineering, 46 Information and Computing Sciences,,,,
8065,pub.1150860472,10.1109/embc48229.2022.9871780,36085846,,Joint Segmentation and Uncertainty Estimation of Ventricular Structures from Cardiac MRI using a Bayesian CondenseUNet,"While convolutional neural networks (CNNs) have shown potential in segmenting cardiac structures from magnetic resonance (MR) images, their clinical applications still fall short of providing reliable cardiac segmentation. As a result, it is critical to quantify segmentation uncertainty in order to identify which segmentations might be troublesome. Moreover, quantifying uncertainty is critical in real-world scenarios, where input distributions are frequently moved from the training distribution due to sample bias and non-stationarity. Therefore, well-calibrated uncertainty estimates provide information on whether a model's output should (or should not) be trusted in such situations. In this work, we used a Bayesian version of our previously proposed CondenseUNet [1] framework featuring both a learned group structure and a regularized weight-pruner to reduce the computational cost in volumetric image segmentation and help quantify predictive uncertainty. Our study further showcases the potential of our deep-learning framework to evaluate the correlation between the uncertainty and the segmentation errors for a given model. The proposed model was trained and tested on the Automated Cardiac Diagnosis Challenge (ACDC) dataset featuring 150 cine cardiac MRI patient dataset for the segmentation and uncertainty estimation of the left ventricle (LV), right ventricle (RV), and myocardium (Myo) at end-diastole (ED) and end-systole (ES) phases.",,"Research reported in this publication was supported by the National Institute of General Medical Sciences Award No. R35GM128877 of the National Institutes of Health, and the Office of Advanced Cyber infrastructure Award No. 1808530 of the National Science Foundation.",Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Bayes Theorem; Heart Ventricles; Humans; Magnetic Resonance Imaging; Neural Networks, Computer; Uncertainty",2022-07,2022,,2022-07,0,,5047-5050,Closed,Proceeding,"Hasan, S. M. Kamrul; Linte, Cristian A.","Hasan, S. M. Kamrul (Center for Imaging Science); Linte, Cristian A. (Center for Imaging Science; Biomedical Engineering, Rochester Institute of Technology, Rochester, NY)",,"Hasan, S. M. Kamrul (); Linte, Cristian A. (Rochester Institute of Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150860472,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
7909,pub.1150860061,10.1109/embc48229.2022.9871368,36085817,,Cardiac Anomaly Detection from Cine MRI Images using Physiological Features and Random Forest Classifier,"Computer-aided diagnosis (CAD) with cine MRI is a foremost research topic to enable improved, faster, and more accurate diagnosis of cardiovascular diseases (CVD). However, current approaches that use manual visualization or conventional clinical indices can lack accuracy for borderline cases. Also, manual visualization of 3D/4D MR data is time-consuming and expert-dependent. We try to simplify this process by creating an end-to-end automated CAD system that segments the critical substructures of the heart. The new domain-related physiological features are then calculated from the segmented regions. These features are fed to a random forest classifier that identifies the anomaly. We have obtained a very high accuracy when testing this end-to-end approach on the Automated Cardiac Diagnosis challenge (ACDC) dataset (4 pathologies, 1 normal). To prove the generalizability of the method we have blind-tested this approach on M&Ms-2 dataset which is a multi-center, multi-vendor, and multi-disease dataset with better than 90% accuracy.",,,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Cardiovascular Diseases; Diagnosis, Computer-Assisted; Heart; Heart Defects, Congenital; Humans; Magnetic Resonance Imaging, Cine",2022-07,2022,,2022-07,0,,3801-3804,Closed,Proceeding,"Bhatia, Divya; Kanakatte, Aparna; Ghose, Avik","Bhatia, Divya (TCS Research, Bengaluru, India); Kanakatte, Aparna (TCS Research, Bengaluru, India); Ghose, Avik (TCS Research, Bengaluru, India)",,"Bhatia, Divya (); Kanakatte, Aparna (); Ghose, Avik ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150860061,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,,
6734,pub.1150859803,10.1109/embc48229.2022.9871109,36086096,,nnUNet-based Multi-modality Breast MRI Segmentation and Tissue-Delineating Phantom for Robotic Tumor Surgery Planning,"Segmentation of the thoracic region and breast tissues is crucial for analyzing and diagnosing the presence of breast masses. This paper introduces a medical image segmentation architecture that aggregates two neural networks based on the state-of-the-art nnU-Net. Additionally, this study proposes a polyvinyl alcohol cryogel (PVA-C) breast phantom, based on its automated segmentation approach, to enable planning and navigation experiments for robotic breast surgery. The dataset consists of multimodality breast MRI of T2W and STIR images obtained from 10 patients. A statistical analysis of segmentation tasks emphasizes the Dice Similarity Coefficient (DSC), segmentation accuracy, sensitivity, and specificity. We first use a single class labeling to segment the breast region and then exploit it as an input for three-class labeling to segment fatty, fibroglandular (FGT), and tumorous tissues. The first network has a 0.95 DCS, while the second network has a 0.95, 0.83, and 0.41 for fat, FGT, and tumor classes, respectively. Clinical Relevance-This research is relevant to the breast surgery community as it establishes a deep learning-based (DL) algorithmic and phantomic foundation for surgical planning and navigation that will exploit preoperative multimodal MRI and intraoperative ultrasound to achieve highly cosmetic breast surgery. In addition, the planning and navigation will guide a robot that can cut, resect, bag, and grasp a tissue mass that encapsulates breast tumors and positive tissue margins. This image-guided robotic approach promises to potentiate the accuracy of breast surgeons and improve patient outcomes.",This work was supported by Old Dominion University (Biomedical Engineering) and by Eastern Virginia Medical School.,Research supported by Old Dominion University (ODU) and Eastern Virginia Medical School (EVMS) funding.,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),Breast Neoplasms, Deep Learning, Female, Humans, Magnetic Resonance Imaging, Robotic Surgical Procedures, Robotics,2022-07,2022,,2022-07,0,,3495-3501,Closed,Proceeding,"Alqaoud, Motaz; Plemmons, John; Feliberti, Eric; Dong, Siqin; Kaipa, Krishnanand; Fichtinger, Gabor; Xiao, Yiming; Audette, Michel A.","Alqaoud, Motaz (Biomedical Engineering, ODU, Norfolk, VA, 23529, USA); Plemmons, John (EVMS (Radiology and Surgery), Norfolk, VA, 23507, USA); Feliberti, Eric (EVMS (Radiology and Surgery), Norfolk, VA, 23507, USA); Dong, Siqin (Mechanical & Aerospace Engineering, ODU, Norfolk, VA); Kaipa, Krishnanand (Mechanical & Aerospace Engineering, ODU, Norfolk, VA); Fichtinger, Gabor (School of Computing, Queen's University, Kingston, ON, Canada); Xiao, Yiming (Computer Science & Software Engineering, Concordia University, Montreal, QC, Canada); Audette, Michel A. (Biomedical Engineering, ODU, Norfolk, VA, 23529, USA)","Audette, Michel A. (Old Dominion University)","Alqaoud, Motaz (Old Dominion University); Plemmons, John (Eastern Virginia Medical School); Feliberti, Eric (Eastern Virginia Medical School); Dong, Siqin (Old Dominion University); Kaipa, Krishnanand (Old Dominion University); Fichtinger, Gabor (Queen's University); Xiao, Yiming (Concordia University); Audette, Michel A. (Old Dominion University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150859803,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 3211 Oncology and Carcinogenesis, 46 Information and Computing Sciences,,,
6062,pub.1149097810,10.1016/j.compbiomed.2022.105799,35792472,,GraformerDIR: Graph convolution transformer for deformable image registration,"PURPOSE: Deformable image registration (DIR) plays an important role in assisting disease diagnosis. The emergence of the Transformer enables the DIR framework to extract long-range dependencies, which relieves the limitations of intrinsic locality caused by convolution operation. However, suffering from the interference of missing or spurious connections, it is a challenging task for Transformer-based methods to capture the high-quality long-range dependencies.
METHODS: In this paper, by staking the graph convolution Transformer (Graformer) layer at the bottom of the feature extraction network, we propose a Graformer-based DIR framework, named GraformerDIR. The Graformer layer is consist of the Graformer module and the Cheby-shev graph convolution module. Among them, the Graformer module is designed to capture high-quality long-range dependencies. Cheby-shev graph convolution module is employed to further enlarge the receptive field.
RESULTS: The performance and generalizability of GraformerDIR have been evaluated on publicly available brain datasets including the OASIS, LPBA40, and MGH10 datasets. Compared with VoxelMorph, the GraformerDIR has obtained performance improvements of 4.6% in Dice similarity coefficient (DSC) and 0.055 mm in the average symmetric surface distance (ASD) while reducing the non-positive rate of Jacobin determinant (Npr.Jac) index about 60 times on publicly available OASIS dataset. On unseen dataset MGH10, the GraformerDIR has obtained the performance improvements of 4.1% in DSC and 0.084 mm in ASD compared with VoxelMorph, which demonstrates the GraformerDIR with better generalizability. The promising performance on the clinical cardiac dataset ACDC indicates the GraformerDIR is practicable.
CONCLUSION: With the advantage of Transformer and graph convolution, the GraformerDIR has obtained comparable performance with the state-of-the-art method VoxelMorph.","This paper was supported by the key specialized research and development program of Henan Province (Grant No. 202102210170, 212102210148), the Open Fund Project of Key Laboratory of Grain Information Processing Control (Grant No. KFJJ2021101), and the Innovative Funds Plan of Henan University of Technology (Grant No. 2021ZKCJ14).",,Computers in Biology and Medicine,,"Algorithms; Head; Image Processing, Computer-Assisted; Radiotherapy Planning, Computer-Assisted",2022-06-30,2022,2022-06-30,2022-08,147,,105799,Closed,Article,"Yang, Tiejun; Bai, Xinhao; Cui, Xiaojuan; Gong, Yuehong; Li, Lei","Yang, Tiejun (Key Laboratory of Grain Information Processing and Control (HAUT), Ministry of Education, Zhengzhou, 450001, China; Henan Key Laboratory of Grain Photoelectric Detection and Control (HAUT), Zhengzhou, 450001, China; School of Artificial Intelligence and Big Data, Henan University of Technology, Zhengzhou, 450001, China.); Bai, Xinhao (School of Information Science and Engineering, Henan University of Technology, Zhengzhou, 450001, China. Electronic address: xinhaobai@stu.haut.edu.cn.); Cui, Xiaojuan (School of Information Science and Engineering, Henan University of Technology, Zhengzhou, 450001, China.); Gong, Yuehong (School of Information Science and Engineering, Henan University of Technology, Zhengzhou, 450001, China.); Li, Lei (School of Information Science and Engineering, Henan University of Technology, Zhengzhou, 450001, China.)","Bai, Xinhao (Henan University of Technology)","Yang, Tiejun (Henan University of Technology); Bai, Xinhao (Henan University of Technology); Cui, Xiaojuan (Henan University of Technology); Gong, Yuehong (Henan University of Technology); Li, Lei (Henan University of Technology)",3,3,,,,https://app.dimensions.ai/details/publication/pub.1149097810,46 Information and Computing Sciences, 4601 Applied Computing,,,,,,,,,,,
1452,pub.1149106681,10.48550/arxiv.2206.14541,,,Why patient data cannot be easily forgotten?,"Rights provisioned within data protection regulations, permit patients to
request that knowledge about their information be eliminated by data holders.
With the advent of AI learned on data, one can imagine that such rights can
extent to requests for forgetting knowledge of patient's data within AI models.
However, forgetting patients' imaging data from AI models, is still an
under-explored problem. In this paper, we study the influence of patient data
on model performance and formulate two hypotheses for a patient's data: either
they are common and similar to other patients or form edge cases, i.e. unique
and rare cases. We show that it is not possible to easily forget patient data.
We propose a targeted forgetting approach to perform patient-wise forgetting.
Extensive experiments on the benchmark Automated Cardiac Diagnosis Challenge
dataset showcase the improved performance of the proposed targeted forgetting
approach as opposed to a state-of-the-art method.",,,arXiv,,,2022-06-29,2022,,,,,,All OA, Green,Preprint,"Su, Ruolin; Liu, Xiao; Tsaftaris, Sotirios A.","Su, Ruolin (); Liu, Xiao (); Tsaftaris, Sotirios A. ()",,"Su, Ruolin (); Liu, Xiao (); Tsaftaris, Sotirios A. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149106681,46 Information and Computing Sciences, 4604 Cybersecurity and Privacy,,,,,,,,,,
1346,pub.1149106678,10.48550/arxiv.2206.14538,,,vMFNet: Compositionality Meets Domain-generalised Segmentation,"Training medical image segmentation models usually requires a large amount of
labeled data. By contrast, humans can quickly learn to accurately recognise
anatomy of interest from medical (e.g. MRI and CT) images with some limited
guidance. Such recognition ability can easily generalise to new images from
different clinical centres. This rapid and generalisable learning ability is
mostly due to the compositional structure of image patterns in the human brain,
which is less incorporated in medical image segmentation. In this paper, we
model the compositional components (i.e. patterns) of human anatomy as
learnable von-Mises-Fisher (vMF) kernels, which are robust to images collected
from different domains (e.g. clinical centres). The image features can be
decomposed to (or composed by) the components with the composing operations,
i.e. the vMF likelihoods. The vMF likelihoods tell how likely each anatomical
part is at each position of the image. Hence, the segmentation mask can be
predicted based on the vMF likelihoods. Moreover, with a reconstruction module,
unlabeled data can also be used to learn the vMF kernels and likelihoods by
recombining them to reconstruct the input image. Extensive experiments show
that the proposed vMFNet achieves improved generalisation performance on two
benchmarks, especially when annotations are limited. Code is publicly available
at: https://github.com/vios-s/vMFNet.",,,arXiv,,,2022-06-29,2022,,,,,,All OA, Green,Preprint,"Liu, Xiao; Thermos, Spyridon; Sanchez, Pedro; O'Neil, Alison Q.; Tsaftaris, Sotirios A.","Liu, Xiao (); Thermos, Spyridon (); Sanchez, Pedro (); O'Neil, Alison Q. (); Tsaftaris, Sotirios A. ()",,"Liu, Xiao (); Thermos, Spyridon (); Sanchez, Pedro (); O'Neil, Alison Q. (); Tsaftaris, Sotirios A. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149106678,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1251,pub.1149106555,10.48550/arxiv.2206.14409,,,C2FTrans: Coarse-to-Fine Transformers for Medical Image Segmentation,"Convolutional neural networks (CNN), the most prevailing architecture for
deep-learning based medical image analysis, are still functionally limited by
their intrinsic inductive biases and inadequate receptive fields. Transformer,
born to address this issue, has drawn explosive attention in natural language
processing and computer vision due to its remarkable ability in capturing
long-range dependency. However, most recent transformer-based methods for
medical image segmentation directly apply vanilla transformers as an auxiliary
module in CNN-based methods, resulting in severe detail loss due to the rigid
patch partitioning scheme in transformers. To address this problem, we propose
C2FTrans, a novel multi-scale architecture that formulates medical image
segmentation as a coarse-to-fine procedure. C2FTrans mainly consists of a
cross-scale global transformer (CGT) which addresses local contextual
similarity in CNN and a boundary-aware local transformer (BLT) which overcomes
boundary uncertainty brought by rigid patch partitioning in transformers.
Specifically, CGT builds global dependency across three different small-scale
feature maps to obtain rich global semantic features with an acceptable
computational cost, while BLT captures mid-range dependency by adaptively
generating windows around boundaries under the guidance of entropy to reduce
computational complexity and minimize detail loss based on large-scale feature
maps. Extensive experimental results on three public datasets demonstrate the
superior performance of C2FTrans against state-of-the-art CNN-based and
transformer-based methods with fewer parameters and lower FLOPs. We believe the
design of C2FTrans would further inspire future work on developing efficient
and lightweight transformers for medical image segmentation. The source code of
this paper is publicly available at https://github.com/xianlin7/C2FTrans.",,,arXiv,,,2022-06-29,2022,,,,,,All OA, Green,Preprint,"Lin, Xian; Yu, Li; Cheng, Kwang-Ting; Yan, Zengqiang","Lin, Xian (); Yu, Li (); Cheng, Kwang-Ting (); Yan, Zengqiang ()",,"Lin, Xian (); Yu, Li (); Cheng, Kwang-Ting (); Yan, Zengqiang ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149106555,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1519,pub.1149024480,10.48550/arxiv.2206.13295,,,Diffusion Deformable Model for 4D Temporal Medical Image Generation,"Temporal volume images with 3D+t (4D) information are often used in medical
imaging to statistically analyze temporal dynamics or capture disease
progression. Although deep-learning-based generative models for natural images
have been extensively studied, approaches for temporal medical image generation
such as 4D cardiac volume data are limited. In this work, we present a novel
deep learning model that generates intermediate temporal volumes between source
and target volumes. Specifically, we propose a diffusion deformable model (DDM)
by adapting the denoising diffusion probabilistic model that has recently been
widely investigated for realistic image generation. Our proposed DDM is
composed of the diffusion and the deformation modules so that DDM can learn
spatial deformation information between the source and target volumes and
provide a latent code for generating intermediate frames along a geodesic path.
Once our model is trained, the latent code estimated from the diffusion module
is simply interpolated and fed into the deformation module, which enables DDM
to generate temporal frames along the continuous trajectory while preserving
the topology of the source image. We demonstrate the proposed method with the
4D cardiac MR image generation between the diastolic and systolic phases for
each subject. Compared to the existing deformation methods, our DDM achieves
high performance on temporal volume generation.",,,arXiv,,,2022-06-27,2022,,,,,,All OA, Green,Preprint,"Kim, Boah; Ye, Jong Chul","Kim, Boah (); Ye, Jong Chul ()",,"Kim, Boah (); Ye, Jong Chul ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149024480,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1251,pub.1151380743,10.1109/cvpr52688.2022.01136,,,CycleMix: A Holistic Strategy for Medical Image Segmentation from Scribble Supervision,"Curating a large set of fully annotated training data can be costly, especially for the tasks of medical image segmentation. Scribble, a weaker form of annotation, is more obtainable in practice, but training segmentation models from limited supervision of scribbles is still challenging. To address the difficulties, we propose a new framework for scribble learning-based medical image segmentation, which is composed of mix augmentation and cycle consistency and thus is referred to as CycleMix. For augmentation of supervision, CycleMix adopts the mixup strategy with a dedicated design of random occlusion, to perform increments and decrements of scribbles. For regularization of supervision, CycleMix intensifies the training objective with consistency losses to penalize inconsistent segmentation, which results in significant improvement of segmentation performance. Results on two open datasets, i.e., ACDC and MSCMRseg, showed that the proposed method achieved exhilarating performance, demonstrating comparable or even better accuracy than the fully-supervised methods. The code and expert-made scribble annotationsfor MSCMRseg are publicly available at https://github.com/BWGZK/CycleMix.",,"This work was funded by the National Natural Science Foundation of China (grant no. 61971142, 62111530195 and 62011540404) and the development fund for Shanghai talents (no. 2020015).",,2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),,2022-06-24,2022,,2022-06-24,0,,11646-11655,All OA, Green,Proceeding,"Zhang, Ke; Zhuang, Xiahai","Zhang, Ke (Fudan University); Zhuang, Xiahai (Fudan University)","Zhuang, Xiahai (Fudan University)","Zhang, Ke (Fudan University); Zhuang, Xiahai (Fudan University)",7,7,,,http://arxiv.org/pdf/2203.01475,https://app.dimensions.ai/details/publication/pub.1151380743,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
1209,pub.1151380745,10.1109/cvpr52688.2022.01138,,,C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image,"Recently, many excellent weakly supervised semantic segmentation (WSSS) works are proposed based on class activation mapping (CAM). However, there are few works that consider the characteristics of medical images. In this paper, we find that there are mainly two challenges of medical images in WSSS: i) the boundary of object foreground and background is not clear; ii) the co-occurrence phenomenon is very severe in training stage. We thus propose a Causal CAM (C-CAM) method to overcome the above challenges. Our method is motivated by two cause-effect chains including category-causality chain and anatomy-causality chain. The category-causality chain represents the image content (cause) affects the category (effect). The anatomy-causality chain represents the anatomical structure (cause) affects the organ segmentation (effect). Extensive experiments were conducted on three public medical image data sets. Our C-CAM generates the best pseudo masks with the DSC of 77.26%, 80.34% and 78.15% on ProMRI, ACDC and CHAOS compared with other CAM-like methods. The pseudo masks of C-CAM are further used to improve the segmentation performance for organ segmentation tasks. Our C-CAM achieves DSC of 83.83% on ProMRI and DSC of 87.54% on ACDC, which outperforms state-of-the-art WSSS methods. Our code is available athttps://github.com/Tian-lab/C-CAM.","This work was supported in part by NSFC under grant Nos. 62173269 and 61876148, Natural Science Basic Research Plan in Shaanxi Province of China under Grant No. 2022JM-324, Key Research and Development Program of Shaanxi Province of China under Grant No. 2020GXLH-Y-008, Social Science Foundation of Shaanxi Province of China under Grant No. 2021K014.","This work was supported in part by NSFC under grant Nos. 62173269 and 61876148, Natural Science Basic Research Plan in Shaanxi Province of China under Grant No. 2022JM-324, Key Research and Development Program of Shaanxi Province of China under Grant No. 2020GXLH-Y-008, Social Science Foundation of Shaanxi Province of China under Grant No. 2021K014.",,2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),,2022-06-24,2022,,2022-06-24,0,,11666-11675,Closed,Proceeding,"Chen, Zhang; Tian, Zhiqiang; Zhu, Jihua; Li, Ce; Du, Shaoyi","Chen, Zhang (Xi'an Jiaotong University, Xi'an, China); Tian, Zhiqiang (Xi'an Jiaotong University, Xi'an, China); Zhu, Jihua (Xi'an Jiaotong University, Xi'an, China); Li, Ce (Lanzhou University of Technology, Xi'an, China); Du, Shaoyi (Xi'an Jiaotong University, Xi'an, China)","Tian, Zhiqiang (Xi'an Jiaotong University); Du, Shaoyi (Xi'an Jiaotong University)","Chen, Zhang (Xi'an Jiaotong University); Tian, Zhiqiang (Xi'an Jiaotong University); Zhu, Jihua (Xi'an Jiaotong University); Li, Ce (Lanzhou University of Technology); Du, Shaoyi (Xi'an Jiaotong University)",3,3,,,,https://app.dimensions.ai/details/publication/pub.1151380745,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
1512,pub.1149626904,10.1109/ist55454.2022.9827772,,,Activation Function Selection for U-net Multi-structures Segmentation of End-Diastole and End-Systole Frames of Cine Cardiac MRI,"Heart disease, especially Coronary Heart Disease (CHD) is a major cause of morbidity and mortality in all corners of the world. In Indonesia in particular, this disease is the highest burden of government financing. The heart as an important organ in humans has a complexity in its structure, for example, the appearance of the left ventricle will look different in two phases of heart rate, End-Diastole (ED) and End-Systole (ES). In this study, the discussion focuses on the multi-structures segmentation of the 2017 ACDC public cine cardiac MRI dataset consisting of training data from 100 patients and test data from 50 patients. Annotations made by experts are included in the training data. The Deep Learning segmentation model is built based on the 2D U-net architecture by taking into account the selection of activation functions, especially in ED and ES frames. The experimental results show that the use of ReLU activation gives better results than MISH with an accuracy of 99% for both ED and ES frames, 2% higher than ED with MISH. Furthermore, although in general the loss from multiclass segmentation is said to be good with a value range of 10 – 2, the loss due to ReLU shows better results, which is 0.02 lower than 0.04 MISH. Furthermore, the mean IoU value, quantifying the similarity between the original image and the predicted image, was found to be 0.815 for ED with ReLU and this value was 0.2 higher than ED with MISH. As for ES, the mean IoU between ReLU and MISH is not much different, which is around 0.7. As sustainability, in the next research, it is necessary to search for known method for classifying by right each part of the multi-structures heart, particularly the myocardium, in an effort to help diagnose CHD cases.","The authors thank the University Center of Excellence on Artificial Intelligence for Healthcare and Society (UCE AIHes), Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia, for supporting this work. We also thank dr. Sony Hilal Wicaksono, Sp.JP, Subsp.PKV(K) (Indonesia University Hospital) for his expertise consultation.","The authors thank the University Center of Excellence on Artificial Intelligence for Healthcare and Society (UCE AIHes), Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia, for supporting this work. We also thank dr. Sony Hilal Wicaksono, Sp.JP, Subsp.PKV(K) (Indonesia University Hospital) for his expertise consultation.",,2022 IEEE International Conference on Imaging Systems and Techniques (IST),,2022-06-23,2022,,2022-06-23,0,,1-6,Closed,Proceeding,"Riandini; Purnama, I Ketut Eddy; Yuniarno, Eko Mulyanto; Purnomo, Mauridhi Hery","Riandini (Dept. of Electrical Engineering, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Dept. of Electrical Engineering, Polteknik Negeri Jakarta, Depok, Indonesia); Purnama, I Ketut Eddy (Dept. of Electrical Engineering Dept. of Computer Engineering, University Center of Excellence on Artificial Intelligence for Healthcare and Society (UCE AIHeS) Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia); Yuniarno, Eko Mulyanto (Dept. of Electrical Engineering Dept. of Computer Engineering, University Center of Excellence on Artificial Intelligence for Healthcare and Society (UCE AIHeS) Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia); Purnomo, Mauridhi Hery (Dept. of Electrical Engineering Dept. of Computer Engineering, University Center of Excellence on Artificial Intelligence for Healthcare and Society (UCE AIHeS) Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia)",,"Riandini (Sepuluh Nopember Institute of Technology); Purnama, I Ketut Eddy (Sepuluh Nopember Institute of Technology); Yuniarno, Eko Mulyanto (Sepuluh Nopember Institute of Technology); Purnomo, Mauridhi Hery (Sepuluh Nopember Institute of Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149626904,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,,
5074,pub.1148809525,10.1007/s11517-022-02612-1,35726000,,Comparison of two-dimensional and three-dimensional U-Net architectures for segmentation of adipose tissue in cardiac magnetic resonance images,"Abstract

The process of identifying cardiac adipose tissue (CAT) from volumetric magnetic resonance imaging of the heart is tedious, time-consuming, and often dependent on observer interpretation. Many 2-dimensional (2D) convolutional neural networks (CNNs) have been implemented to automate the cardiac segmentation process, but none have attempted to identify CAT. Furthermore, the results from automatic segmentation of other cardiac structures leave room for improvement. This study investigated the viability of a 3-dimensional (3D) CNN in comparison to a similar 2D CNN. Both models used a U-Net architecture to simultaneously classify CAT, left myocardium, left ventricle, and right myocardium. The multi-phase model trained with multiple observers’ segmentations reached a whole-volume Dice similarity coefficient (DSC) of 0.925 across all classes and 0.640 for CAT specifically; the corresponding 2D model’s DSC across all classes was 0.902 and 0.590 for CAT specifically. This 3D model also achieved a higher level of CAT-specific DSC agreement with a group of observers with a Williams Index score of 0.973 in comparison to the 2D model’s score of 0.822.Graphical abstract",,"This study was supported by the National Heart, Lung, and Blood Institute of the National Institutes of Health under award number R15HL145576 and the internal Southern Illinois University Edwardsville Vaughnie Lindsay New Investigator Award.",Medical & Biological Engineering & Computing,,"Adipose Tissue; Heart; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer",2022-06-20,2022,2022-06-20,2022-08,60,8,2291-2306,Closed,Article,"Kulasekara, Michaela; Dinh, Vu Quang; Fernandez-del-Valle, Maria; Klingensmith, Jon D.","Kulasekara, Michaela (Department of Electrical and Computer Engineering, Southern Illinois University Edwardsville, Box 1801, 62026, Edwardsville, IL, USA); Dinh, Vu Quang (Department of Electrical and Computer Engineering, Southern Illinois University Edwardsville, Box 1801, 62026, Edwardsville, IL, USA); Fernandez-del-Valle, Maria (Department of Functional Biology, University of Oviedo, Oviedo, Spain; Health Research Institute of the Principality of Asturias (ISPA), Asturias, Spain); Klingensmith, Jon D. (Department of Electrical and Computer Engineering, Southern Illinois University Edwardsville, Box 1801, 62026, Edwardsville, IL, USA)","Klingensmith, Jon D. (Southern Illinois University Edwardsville)","Kulasekara, Michaela (Southern Illinois University Edwardsville); Dinh, Vu Quang (Southern Illinois University Edwardsville); Fernandez-del-Valle, Maria (University of Oviedo; Instituto de Investigación Sanitaria del Principado de Asturias); Klingensmith, Jon D. (Southern Illinois University Edwardsville)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1148809525,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
1451,pub.1150377062,10.1109/aic55036.2022.9848901,,,Search Engine for Assorted Media in Chat Applications,"The mobile industry has come across many revolutionizing advancements in its technologies over the past three decades, making mobile phones an integral part of everyone’s daily lives. With the exponential advent of this technology to handle work on chat applications for prolonged hours, there has been a great increase in the interconnectivity of different sections of society, both economically and demographically. Existing chat applications provide in-built search engines that are competent in handling text searches but cannot search for different types of media, both visual and audible, which may be present in the chat. This paper proposes a novel approach that allows chat applications to use an inbuilt media search engine that performs searches for all the disparate media that the chat holds, using keywords. The machine learning model detects the objects from the media files and maps those objects’ keywords to the list of images. These keywords may be any of the objects that can be detected in those media files. Say, a user searches for the keyword ‘Table’ in the search engine, and he gets all the images having tables. This feature saves time for the user as no manual work is required to search for any media exchanged in the chat by scrolling and searching in case of many media files. This idea blooms out from within the feedback that the real-world audience has provided when asked for their expectations from a “perfect” chat application. The entire study associated with this paper conforms with the problem statement and guarantees the user a more comfortable and helpful experience while using the proposed feature. The proposed method uses TensorFlow-Lite and Google Machine Learning (ML) Kit’s Image Labelling APIs to detect the keywords that together characterize the media present in the chat. This method is found to be performing accurately for all types of media (especially photos) when manually tested with real-world data.",,,,2022 IEEE World Conference on Applied Intelligence and Computing (AIC),,2022-06-19,2022,,2022-06-19,0,,130-135,Closed,Proceeding,"Pandey, Aditya; Jaiswal, Ishita; Pandey, Shekhar","Pandey, Aditya (Computer Science and Information Technology, KIET Group of Institutions, Delhi-NCR, Ghaziabad, India); Jaiswal, Ishita (Computer Science and Engineering KIET Group of Institutions, Delhi-NCR, Ghaziabad, India); Pandey, Shekhar (Information Technology KIET Group of Institutions, Delhi-NCR, Ghaziabad, India)","Pandey, Aditya (Dr. A.P.J. Abdul Kalam Technical University)","Pandey, Aditya (Dr. A.P.J. Abdul Kalam Technical University); Jaiswal, Ishita (Dr. A.P.J. Abdul Kalam Technical University); Pandey, Shekhar (Dr. A.P.J. Abdul Kalam Technical University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150377062,"36 Creative Arts and Writing; 3605 Screen and Digital Media; 46 Information and Computing Sciences; 4605 Data Management and Data Science; 47 Language, Communication and Culture; 4701 Communication and Media Studies",,,,,,,,,,,,
5667,pub.1148763032,10.1016/j.media.2022.102515,35780593,,Segmentation only uses sparse annotations: Unified weakly and semi-supervised learning in medical images,"Since segmentation labeling is usually time-consuming and annotating medical images requires professional expertise, it is laborious to obtain a large-scale, high-quality annotated segmentation dataset. We propose a novel weakly- and semi-supervised framework named SOUSA (Segmentation Only Uses Sparse Annotations), aiming at learning from a small set of sparse annotated data and a large amount of unlabeled data. The proposed framework contains a teacher model and a student model. The student model is weakly supervised by scribbles and a Geodesic distance map derived from scribbles. Meanwhile, a large amount of unlabeled data with various perturbations are fed to student and teacher models. The consistency of their output predictions is imposed by Mean Square Error (MSE) loss and a carefully designed Multi-angle Projection Reconstruction (MPR) loss. Extensive experiments are conducted to demonstrate the robustness and generalization ability of our proposed method. Results show that our method outperforms weakly- and semi-supervised state-of-the-art methods on multiple datasets. Furthermore, our method achieves a competitive performance with some fully supervised methods with dense annotation when the size of the dataset is limited.","This study was supported by Guangzhou Key Research and Development Project (No. 202206080008, X-JW), National Natural Science Foundation of China (No. 82002221, FG and No. 82102475, M-EZ), and Guangzhou Basic and Applied Basic Research Fund (No. 202102020820, FG), and National Key Clinical Discipline.. The funders had no role in study design, data collection, data analysis and interpretation, preparation of the manuscript, or decision to publish.",,Medical Image Analysis,,"Deep Learning; Humans; Image Processing, Computer-Assisted; Supervised Machine Learning",2022-06-17,2022,2022-06-17,2022-08,80,,102515,Closed,Article,"Gao, Feng; Hu, Minhao; Zhong, Min-Er; Feng, Shixiang; Tian, Xuwei; Meng, Xiaochun; Ni-Jia-Ti, Ma-Yi-di-Li; Huang, Zeping; Lv, Minyi; Song, Tao; Zhang, Xiaofan; Zou, Xiaoguang; Wu, Xiaojian","Gao, Feng (Department of Colorectal Surgery, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China; Guangdong Provincial Key Laboratory of Colorectal and Pelvic Floor Diseases, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China. Electronic address: gaof57@mail.sysu.edu.cn.); Hu, Minhao (SenseTime Research, Shanghai, China.); Zhong, Min-Er (Department of Colorectal Surgery, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China; Guangdong Provincial Key Laboratory of Colorectal and Pelvic Floor Diseases, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China.); Feng, Shixiang (SenseTime Research, Shanghai, China.); Tian, Xuwei (Clinical Medical Research Center, The First People's Hospital of Kashi Prefecture, Kashi, Xinjiang, China.); Meng, Xiaochun (Guangdong Provincial Key Laboratory of Colorectal and Pelvic Floor Diseases, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China; Department of Radiology, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China.); Ni-Jia-Ti, Ma-Yi-di-Li (Department of Radiology, The First People's Hospital of Kashi Prefecture, Kashi, Xinjiang, China.); Huang, Zeping (Department of Colorectal Surgery, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China; Guangdong Provincial Key Laboratory of Colorectal and Pelvic Floor Diseases, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China.); Lv, Minyi (Department of Colorectal Surgery, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China; Guangdong Provincial Key Laboratory of Colorectal and Pelvic Floor Diseases, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China.); Song, Tao (SenseTime Research, Shanghai, China.); Zhang, Xiaofan (Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China; Shanghai AI Laboratory, Shanghai, China. Electronic address: xiaofan.zhang@sjtu.edu.cn.); Zou, Xiaoguang (Clinical Medical Research Center, The First People's Hospital of Kashi Prefecture, Kashi, Xinjiang, China. Electronic address: zxgks@163.com.); Wu, Xiaojian (Department of Colorectal Surgery, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China; Guangdong Provincial Key Laboratory of Colorectal and Pelvic Floor Diseases, The Sixth Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province 510655, China. Electronic address: wuxjian@mail.sysu.edu.cn.)","Zhang, Xiaofan (Shanghai Jiao Tong University; Shanghai Artificial Intelligence Laboratory)","Gao, Feng (Sun Yat-sen University); Hu, Minhao (); Zhong, Min-Er (Sun Yat-sen University); Feng, Shixiang (); Tian, Xuwei (); Meng, Xiaochun (Sun Yat-sen University); Ni-Jia-Ti, Ma-Yi-di-Li (); Huang, Zeping (Sun Yat-sen University); Lv, Minyi (Sun Yat-sen University); Song, Tao (); Zhang, Xiaofan (Shanghai Jiao Tong University; Shanghai Artificial Intelligence Laboratory); Zou, Xiaoguang (); Wu, Xiaojian (Sun Yat-sen University)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1148763032,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
3032,pub.1148757411,10.1016/j.media.2022.102516,35751992,,Learning disentangled representations in the imaging domain,"Disentangled representation learning has been proposed as an approach to learning general representations even in the absence of, or with limited, supervision. A good general representation can be fine-tuned for new target tasks using modest amounts of data, or used directly in unseen domains achieving remarkable performance in the corresponding task. This alleviation of the data and annotation requirements offers tantalising prospects for applications in computer vision and healthcare. In this tutorial paper, we motivate the need for disentangled representations, revisit key concepts, and describe practical building blocks and criteria for learning such representations. We survey applications in medical imaging emphasising choices made in exemplar key works, and then discuss links to computer vision applications. We conclude by presenting limitations, challenges, and opportunities.","This work was supported by the Royal Academy of Engineering and Canon Medical Research Europe, and partially supported by the Alan Turing Institute under the EPSRC grant EP/N510129/1. S.A. Tsaftaris acknowledges the support of Canon Medical and the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme (grant RCSRF1819 8 25). We thank the participants of the DREAM tutorials for feedback. For the purpose of open access, the author has applied a Creative Commons Attribution (CC BY) licence to any Author Accepted Manuscript version arising from this submission.",,Medical Image Analysis,,Humans, Learning, Machine Learning, Software,2022-06-17,2022,2022-06-17,2022-08,80,,102516,All OA, Hybrid,Article,"Liu, Xiao; Sanchez, Pedro; Thermos, Spyridon; O'Neil, Alison Q; Tsaftaris, Sotirios A","Liu, Xiao (School of Engineering, The University of Edinburgh, Edinburgh EH9 3FG, UK. Electronic address: Xiao.Liu@ed.ac.uk.); Sanchez, Pedro (School of Engineering, The University of Edinburgh, Edinburgh EH9 3FG, UK.); Thermos, Spyridon (School of Engineering, The University of Edinburgh, Edinburgh EH9 3FG, UK.); O'Neil, Alison Q (School of Engineering, The University of Edinburgh, Edinburgh EH9 3FG, UK; Canon Medical Research Europe, Edinburgh EH6 5NP, UK.); Tsaftaris, Sotirios A (School of Engineering, The University of Edinburgh, Edinburgh EH9 3FG, UK; The Alan Turing Institute, London NW1 2DB, UK.)","Liu, Xiao (University of Edinburgh)","Liu, Xiao (University of Edinburgh); Sanchez, Pedro (University of Edinburgh); Thermos, Spyridon (University of Edinburgh); O'Neil, Alison Q (University of Edinburgh); Tsaftaris, Sotirios A (University of Edinburgh; The Alan Turing Institute)",9,9,,,https://doi.org/10.1016/j.media.2022.102516,https://app.dimensions.ai/details/publication/pub.1148757411,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,
1071,pub.1148758824,10.48550/arxiv.2206.08023,,,AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile  Medical Image Segmentation,"Despite the considerable progress in automatic abdominal multi-organ
segmentation from CT/MRI scans in recent years, a comprehensive evaluation of
the models' capabilities is hampered by the lack of a large-scale benchmark
from diverse clinical scenarios. Constraint by the high cost of collecting and
labeling 3D medical data, most of the deep learning models to date are driven
by datasets with a limited number of organs of interest or samples, which still
limits the power of modern deep models and makes it difficult to provide a
fully comprehensive and fair estimate of various methods. To mitigate the
limitations, we present AMOS, a large-scale, diverse, clinical dataset for
abdominal organ segmentation. AMOS provides 500 CT and 100 MRI scans collected
from multi-center, multi-vendor, multi-modality, multi-phase, multi-disease
patients, each with voxel-level annotations of 15 abdominal organs, providing
challenging examples and test-bed for studying robust segmentation algorithms
under diverse targets and scenarios. We further benchmark several
state-of-the-art medical segmentation models to evaluate the status of the
existing methods on this new challenging dataset. We have made our datasets,
benchmark servers, and baselines publicly available, and hope to inspire future
research. Information can be found at https://amos22.grand-challenge.org.",,,arXiv,,,2022-06-16,2022,,,,,,All OA, Green,Preprint,"Ji, Yuanfeng; Bai, Haotian; Yang, Jie; Ge, Chongjian; Zhu, Ye; Zhang, Ruimao; Li, Zhen; Zhang, Lingyan; Ma, Wanling; Wan, Xiang; Luo, Ping","Ji, Yuanfeng (); Bai, Haotian (); Yang, Jie (); Ge, Chongjian (); Zhu, Ye (); Zhang, Ruimao (); Li, Zhen (); Zhang, Lingyan (); Ma, Wanling (); Wan, Xiang (); Luo, Ping ()",,"Ji, Yuanfeng (); Bai, Haotian (); Yang, Jie (); Ge, Chongjian (); Zhu, Ye (); Zhang, Ruimao (); Li, Zhen (); Zhang, Lingyan (); Ma, Wanling (); Wan, Xiang (); Luo, Ping ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148758824,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,
1141,pub.1148758508,10.48550/arxiv.2206.07364,,,Seeking Common Ground While Reserving Differences: Multiple Anatomy  Collaborative Framework for Undersampled MRI Reconstruction,"Recently, deep neural networks have greatly advanced undersampled Magnetic
Resonance Image (MRI) reconstruction, wherein most studies follow the
one-anatomy-one-network fashion, i.e., each expert network is trained and
evaluated for a specific anatomy. Apart from inefficiency in training multiple
independent models, such convention ignores the shared de-aliasing knowledge
across various anatomies which can benefit each other. To explore the shared
knowledge, one naive way is to combine all the data from various anatomies to
train an all-round network. Unfortunately, despite the existence of the shared
de-aliasing knowledge, we reveal that the exclusive knowledge across different
anatomies can deteriorate specific reconstruction targets, yielding overall
performance degradation. Observing this, in this study, we present a novel deep
MRI reconstruction framework with both anatomy-shared and anatomy-specific
parameterized learners, aiming to ""seek common ground while reserving
differences"" across different anatomies.Particularly, the primary
anatomy-shared learners are exposed to different anatomies to model flourishing
shared knowledge, while the efficient anatomy-specific learners are trained
with their target anatomy for exclusive knowledge. Four different
implementations of anatomy-specific learners are presented and explored on the
top of our framework in two MRI reconstruction networks. Comprehensive
experiments on brain, knee and cardiac MRI datasets demonstrate that three of
these learners are able to enhance reconstruction performance via multiple
anatomy collaborative learning.",,,arXiv,,,2022-06-15,2022,,,,,,All OA, Green,Preprint,"Yan, Jiangpeng; Yu, Chenghui; Chen, Hanbo; Xu, Zhe; Huang, Junzhou; Li, Xiu; Yao, Jianhua","Yan, Jiangpeng (); Yu, Chenghui (); Chen, Hanbo (); Xu, Zhe (); Huang, Junzhou (); Li, Xiu (); Yao, Jianhua ()",,"Yan, Jiangpeng (); Yu, Chenghui (); Chen, Hanbo (); Xu, Zhe (); Huang, Junzhou (); Li, Xiu (); Yao, Jianhua ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148758508,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1070,pub.1148758938,10.48550/arxiv.2206.08137,,,"Large-scale, multi-centre, multi-disease validation of an AI clinical  tool for cine CMR analysis","INTRODUCTION: Artificial intelligence (AI) has the potential to facilitate
the automation of CMR analysis for biomarker extraction. However, most AI
algorithms are trained on a specific input domain (e.g., single scanner vendor
or hospital-tailored imaging protocol) and lack the robustness to perform
optimally when applied to CMR data from other input domains. METHODS: Our
proposed framework consists of an AI-based algorithm for biventricular
segmentation of short-axis images, followed by a post-analysis quality control
to detect erroneous results. The segmentation algorithm was trained on a large
dataset of clinical CMR scans from two NHS hospitals (n=2793) and validated on
additional cases from this dataset (n=441) and on five external datasets
(n=6808). The validation data included CMR scans of patients with a range of
diseases acquired at 12 different centres using CMR scanners from all major
vendors. RESULTS: Our method yielded median Dice scores over 87%, translating
into median absolute errors in cardiac biomarkers within the range of
inter-observer variability: <8.4mL (left ventricle), <9.2mL (right ventricle),
<13.3g (left ventricular mass), and <5.9% (ejection fraction) across all
datasets. Stratification of cases according to phenotypes of cardiac disease
and scanner vendors showed good agreement. CONCLUSIONS: We show that our
proposed tool, which combines a state-of-the-art AI algorithm trained on a
large-scale multi-domain CMR dataset with a post-analysis quality control,
allows us to robustly deal with routine clinical data from multiple centres,
vendors, and cardiac diseases. This is a fundamental step for the clinical
translation of AI algorithms. Moreover, our method yields a range of additional
biomarkers of cardiac function (filling and ejection rates, regional wall
motion, and strain) at no extra computational cost.",,,arXiv,,,2022-06-15,2022,,,,,,All OA, Green,Preprint,"Mariscal-Harana, Jorge; Asher, Clint; Vergani, Vittoria; Rizvi, Maleeha; Keehn, Louise; Kim, Raymond J.; Judd, Robert M.; Petersen, Steffen E.; Razavi, Reza; King, Andrew; Ruijsink, Bram; Puyol-Antón, Esther","Mariscal-Harana, Jorge (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK); Asher, Clint (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK; Department of Adult and Paediatric Cardiology, Guy's and St Thomas' NHS Foundation Trust, London, UK); Vergani, Vittoria (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK); Rizvi, Maleeha (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK; Department of Adult and Paediatric Cardiology, Guy's and St Thomas' NHS Foundation Trust, London, UK); Keehn, Louise (Department of Clinical Pharmacology, King's College London British Heart Foundation Centre, St Thomas' Hospital, London, UK); Kim, Raymond J. (Division of Cardiology, Department of Medicine, Duke University, Durham, North Carolina, USA); Judd, Robert M. (Division of Cardiology, Department of Medicine, Duke University, Durham, North Carolina, USA); Petersen, Steffen E. (National Institute for Health Research; Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, London, UK; Health Data Research UK, London, UK; Alan Turing Institute, London, UK); Razavi, Reza (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK; Department of Adult and Paediatric Cardiology, Guy's and St Thomas' NHS Foundation Trust, London, UK); King, Andrew (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK); Ruijsink, Bram (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK; Department of Adult and Paediatric Cardiology, Guy's and St Thomas' NHS Foundation Trust, London, UK; Department of Cardiology, Heart and Lung Division, University Medical Center Utrecht, Utrecht, The Netherlands); Puyol-Antón, Esther (School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK)",,"Mariscal-Harana, Jorge (King's College London); Asher, Clint (King's College London; Guy's and St Thomas' NHS Foundation Trust); Vergani, Vittoria (King's College London); Rizvi, Maleeha (King's College London; Guy's and St Thomas' NHS Foundation Trust); Keehn, Louise (St Thomas' Hospital); Kim, Raymond J. (Duke University); Judd, Robert M. (Duke University); Petersen, Steffen E. (National Institute for Health Research; St Bartholomew's Hospital; Health Data Research UK; The Alan Turing Institute); Razavi, Reza (King's College London; Guy's and St Thomas' NHS Foundation Trust); King, Andrew (King's College London); Ruijsink, Bram (King's College London; Guy's and St Thomas' NHS Foundation Trust; University Medical Center Utrecht); Puyol-Antón, Esther (King's College London)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148758938,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,3 Good Health and Well Being,,,,,,,,
1451,pub.1148728439,10.48550/arxiv.2206.07163,,,DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction  via A Structure-Specific Generative Method,"Joint 2D cardiac segmentation and 3D volume reconstruction are fundamental to
building statistical cardiac anatomy models and understanding functional
mechanisms from motion patterns. However, due to the low through-plane
resolution of cine MR and high inter-subject variance, accurately segmenting
cardiac images and reconstructing the 3D volume are challenging. In this study,
we propose an end-to-end latent-space-based framework, DeepRecon, that
generates multiple clinically essential outcomes, including accurate image
segmentation, synthetic high-resolution 3D image, and 3D reconstructed volume.
Our method identifies the optimal latent representation of the cine image that
contains accurate semantic information for cardiac structures. In particular,
our model jointly generates synthetic images with accurate semantic information
and segmentation of the cardiac structures using the optimal latent
representation. We further explore downstream applications of 3D shape
reconstruction and 4D motion pattern adaptation by the different latent-space
manipulation strategies.The simultaneously generated high-resolution images
present a high interpretable value to assess the cardiac shape and
motion.Experimental results demonstrate the effectiveness of our approach on
multiple fronts including 2D segmentation, 3D reconstruction, downstream 4D
motion pattern adaption performance.",,,arXiv,,,2022-06-14,2022,,,,,,All OA, Green,Preprint,"Chang, Qi; Yan, Zhennan; Zhou, Mu; Liu, Di; Sawalha, Khalid; Ye, Meng; Zhangli, Qilong; Kanski, Mikael; Aref, Subhi Al; Axel, Leon; Metaxas, Dimitris","Chang, Qi (); Yan, Zhennan (); Zhou, Mu (); Liu, Di (); Sawalha, Khalid (); Ye, Meng (); Zhangli, Qilong (); Kanski, Mikael (); Aref, Subhi Al (); Axel, Leon (); Metaxas, Dimitris ()",,"Chang, Qi (); Yan, Zhennan (); Zhou, Mu (); Liu, Di (); Sawalha, Khalid (); Ye, Meng (); Zhangli, Qilong (); Kanski, Mikael (); Aref, Subhi Al (); Axel, Leon (); Metaxas, Dimitris ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148728439,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
6069,pub.1148550857,10.1016/j.compmedimag.2022.102088,35780703,,Bridging 2D and 3D segmentation networks for computation-efficient volumetric medical image segmentation: An empirical study of 2.5D solutions,"Recently, deep convolutional neural networks have achieved great success for medical image segmentation. However, unlike segmentation of natural images, most medical images such as MRI and CT are volumetric data. In order to make full use of volumetric information, 3D CNNs are widely used. However, 3D CNNs suffer from higher inference time and computation cost, which hinders their further clinical applications. Additionally, with the increased number of parameters, the risk of overfitting is higher, especially for medical images where data and annotations are expensive to acquire. To issue this problem, many 2.5D segmentation methods have been proposed to make use of volumetric spatial information with less computation cost. Despite these works lead to improvements on a variety of segmentation tasks, to the best of our knowledge, there has not previously been a large-scale empirical comparison of these methods. In this paper, we aim to present a review of the latest developments of 2.5D methods for volumetric medical image segmentation. Additionally, to compare the performance and effectiveness of these methods, we provide an empirical study of these methods on three representative segmentation tasks involving different modalities and targets. Our experimental results highlight that 3D CNNs may not always be the best choice. Despite all these 2.5D methods can bring performance gains to 2D baseline, not all the methods hold the benefits on different datasets. We hope the results and conclusions of our study will prove useful for the community on exploring and developing efficient volumetric medical image segmentation methods.","This work is supported by the National Key Research and Development Program of China under Grant 2016YFF0201002, the University Synergy Innovation Program of Anhui Province under Grant GXXT-2019–044, and the National Natural Science Foundation of China under Grant 61301005.",,Computerized Medical Imaging and Graphics,,"Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Neural Networks, Computer",2022-06-09,2022,2022-06-09,2022-07,99,,102088,All OA, Green,Article,"Zhang, Yichi; Liao, Qingcheng; Ding, Le; Zhang, Jicong","Zhang, Yichi (School of Biological Science and Medical Engineering, Beihang University, Beijing, China.); Liao, Qingcheng (School of Biological Science and Medical Engineering, Beihang University, Beijing, China.); Ding, Le (School of Biological Science and Medical Engineering, Beihang University, Beijing, China.); Zhang, Jicong (School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Hefei Innovation Research Institute, Beihang University, Hefei, China; Beijing Advanced Innovation Centre for Biomedical Engineering, Beijing, China; Beijing Advanced Innovation Centre for Big Data-Based Precision Medicine, Beijing, China. Electronic address: jicongzhang@buaa.edu.cn.)","Zhang, Jicong (Beihang University; )","Zhang, Yichi (Beihang University); Liao, Qingcheng (Beihang University); Ding, Le (Beihang University); Zhang, Jicong (Beihang University)",3,3,,,http://arxiv.org/pdf/2010.06163,https://app.dimensions.ai/details/publication/pub.1148550857,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5057,pub.1148548333,10.1016/j.compbiomed.2022.105715,35715262,,Adaptive area-preserving parameterization of open and closed anatomical surfaces,"The parameterization of open and closed anatomical surfaces is of fundamental importance in many biomedical applications. Spherical harmonics, a set of basis functions defined on the unit sphere, are widely used for anatomical shape description. However, establishing a one-to-one correspondence between the object surface and the entire unit sphere may induce a large geometric distortion in case the shape of the surface is too different from a perfect sphere. In this work, we propose adaptive area-preserving parameterization methods for simply-connected open and closed surfaces with the target of the parameterization being a spherical cap. Our methods optimize the shape of the parameter domain along with the mapping from the object surface to the parameter domain. The object surface will be globally mapped to an optimal spherical cap region of the unit sphere in an area-preserving manner while also exhibiting low conformal distortion. We further develop a set of spherical harmonics-like basis functions defined over the adaptive spherical cap domain, which we call the adaptive harmonics. Experimental results show that the proposed parameterization methods outperform the existing methods for both open and closed anatomical surfaces in terms of area and angle distortion. Surface description of the object surfaces can be effectively achieved using a novel combination of the adaptive parameterization and the adaptive harmonics. Our work provides a novel way of mapping anatomical surfaces with improved accuracy and greater flexibility. More broadly, the idea of using an adaptive parameter domain allows easy handling of a wide range of biomedical shapes.","This work was supported in part by the National Science Foundation, USA under Grant No. DMS-2002103 (to G. P. T. Choi), and the Prime Ministers Research Fellowship (PMRF) , Government of India (to A. Giri).",,Computers in Biology and Medicine,,"Algorithms; Image Enhancement; Imaging, Three-Dimensional",2022-06-09,2022,2022-06-09,2022-09,148,,105715,All OA, Green,Article,"Choi, Gary P T; Giri, Amita; Kumar, Lalan","Choi, Gary P T (Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA, USA. Electronic address: ptchoi@mit.edu.); Giri, Amita (Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India.); Kumar, Lalan (Department of Electrical Engineering and Bharti School of Telecommunication, Indian Institute of Technology Delhi, New Delhi, India.)","Choi, Gary P T (Massachusetts Institute of Technology)","Choi, Gary P T (Massachusetts Institute of Technology); Giri, Amita (Indian Institute of Technology Delhi); Kumar, Lalan (Indian Institute of Technology Delhi)",2,2,,,http://arxiv.org/pdf/2111.04265,https://app.dimensions.ai/details/publication/pub.1148548333,31 Biological Sciences, 3102 Bioinformatics and Computational Biology, 42 Health Sciences, 4203 Health Services and Systems, 46 Information and Computing Sciences, 4601 Applied Computing,,,,,,
1454,pub.1148556425,10.48550/arxiv.2206.04336,,,Joint Modeling of Image and Label Statistics for Enhancing Model  Generalizability of Medical Image Segmentation,"Although supervised deep-learning has achieved promising performance in
medical image segmentation, many methods cannot generalize well on unseen data,
limiting their real-world applicability. To address this problem, we propose a
deep learning-based Bayesian framework, which jointly models image and label
statistics, utilizing the domain-irrelevant contour of a medical image for
segmentation. Specifically, we first decompose an image into components of
contour and basis. Then, we model the expected label as a variable only related
to the contour. Finally, we develop a variational Bayesian framework to infer
the posterior distributions of these variables, including the contour, the
basis, and the label. The framework is implemented with neural networks, thus
is referred to as deep Bayesian segmentation. Results on the task of
cross-sequence cardiac MRI segmentation show that our method set a new state of
the art for model generalizability. Particularly, the BayeSeg model trained
with LGE MRI generalized well on T2 images and outperformed other models with
great margins, i.e., over 0.47 in terms of average Dice. Our code is available
at https://zmiclab.github.io/projects.html.",,,arXiv,,,2022-06-09,2022,,,,,,All OA, Green,Preprint,"Gao, Shangqi; Zhou, Hangqi; Gao, Yibo; Zhuang, Xiahai","Gao, Shangqi (); Zhou, Hangqi (); Gao, Yibo (); Zhuang, Xiahai ()",,"Gao, Shangqi (); Zhou, Hangqi (); Gao, Yibo (); Zhuang, Xiahai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148556425,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1014,pub.1148555906,10.48550/arxiv.2206.03830,,,Generative Myocardial Motion Tracking via Latent Space Exploration with  Biomechanics-informed Prior,"Myocardial motion and deformation are rich descriptors that characterize
cardiac function. Image registration, as the most commonly used technique for
myocardial motion tracking, is an ill-posed inverse problem which often
requires prior assumptions on the solution space. In contrast to most existing
approaches which impose explicit generic regularization such as smoothness, in
this work we propose a novel method that can implicitly learn an
application-specific biomechanics-informed prior and embed it into a neural
network-parameterized transformation model. Particularly, the proposed method
leverages a variational autoencoder-based generative model to learn a manifold
for biomechanically plausible deformations. The motion tracking then can be
performed via traversing the learnt manifold to search for the optimal
transformations while considering the sequence information. The proposed method
is validated on three public cardiac cine MRI datasets with comprehensive
evaluations. The results demonstrate that the proposed method can outperform
other approaches, yielding higher motion tracking accuracy with reasonable
volume preservation and better generalizability to varying data distributions.
It also enables better estimates of myocardial strains, which indicates the
potential of the method in characterizing spatiotemporal signatures for
understanding cardiovascular diseases.",,,arXiv,,,2022-06-08,2022,,,,,,All OA, Green,Preprint,"Qin, Chen; Wang, Shuo; Chen, Chen; Bai, Wenjia; Rueckert, Daniel","Qin, Chen (); Wang, Shuo (); Chen, Chen (); Bai, Wenjia (); Rueckert, Daniel ()",,"Qin, Chen (); Wang, Shuo (); Chen, Chen (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148555906,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1516,pub.1148489253,10.48550/arxiv.2206.02118,,,ShapePU: A New PU Learning Framework Regularized by Global Consistency  for Scribble Supervised Cardiac Segmentation,"Cardiac segmentation is an essential step for the diagnosis of cardiovascular
diseases. However, pixel-wise dense labeling is both costly and time-consuming.
Scribble, as a form of sparse annotation, is more accessible than full
annotations. However, it's particularly challenging to train a segmentation
network with weak supervision from scribbles. To tackle this problem, we
propose a new scribble-guided method for cardiac segmentation, based on the
Positive-Unlabeled (PU) learning framework and global consistency
regularization, and termed as ShapePU. To leverage unlabeled pixels via PU
learning, we first present an Expectation-Maximization (EM) algorithm to
estimate the proportion of each class in the unlabeled pixels. Given the
estimated ratios, we then introduce the marginal probability maximization to
identify the classes of unlabeled pixels. To exploit shape knowledge, we apply
cutout operations to training images, and penalize the inconsistent
segmentation results. Evaluated on two open datasets, i.e, ACDC and MSCMRseg,
our scribble-supervised ShapePU surpassed the fully supervised approach
respectively by 1.4% and 9.8% in average Dice, and outperformed the
state-of-the-art weakly supervised and PU learning methods by large margins.
Our code is available at https://github.com/BWGZK/ShapePU.",,,arXiv,,,2022-06-05,2022,,,,,,All OA, Green,Preprint,"Zhang, Ke; Zhuang, Xiahai","Zhang, Ke (); Zhuang, Xiahai ()",,"Zhang, Ke (); Zhuang, Xiahai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148489253,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1344,pub.1148489433,10.48550/arxiv.2206.02307,,,Bootstrapping Semi-supervised Medical Image Segmentation with  Anatomical-aware Contrastive Distillation,"Contrastive learning has shown great promise over annotation scarcity
problems in the context of medical image segmentation. Existing approaches
typically assume a balanced class distribution for both labeled and unlabeled
medical images. However, medical image data in reality is commonly imbalanced
(i.e., multi-class label imbalance), which naturally yields blurry contours and
usually incorrectly labels rare objects. Moreover, it remains unclear whether
all negative samples are equally negative. In this work, we present ACTION, an
Anatomical-aware ConTrastive dIstillatiON framework, for semi-supervised
medical image segmentation. Specifically, we first develop an iterative
contrastive distillation algorithm by softly labeling the negatives rather than
binary supervision between positive and negative pairs. We also capture more
semantically similar features from the randomly chosen negative set compared to
the positives to enforce the diversity of the sampled data. Second, we raise a
more important question: Can we really handle imbalanced samples to yield
better performance? Hence, the key innovation in ACTION is to learn global
semantic relationship across the entire dataset and local anatomical features
among the neighbouring pixels with minimal additional memory footprint. During
the training, we introduce anatomical contrast by actively sampling a sparse
set of hard negative pixels, which can generate smoother segmentation
boundaries and more accurate predictions. Extensive experiments across two
benchmark datasets and different unlabeled settings show that ACTION performs
comparable or better than the current state-of-the-art supervised and
semi-supervised methods. Our code and models will be publicly available.",,,arXiv,,,2022-06-05,2022,,,,,,All OA, Green,Preprint,"You, Chenyu; Dai, Weicheng; Staib, Lawrence; Duncan, James S.","You, Chenyu (); Dai, Weicheng (); Staib, Lawrence (); Duncan, James S. ()",,"You, Chenyu (); Dai, Weicheng (); Staib, Lawrence (); Duncan, James S. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148489433,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5667,pub.1148374914,10.1038/s41598-022-12378-z,35654902,PMC9163082,Towards fully automated segmentation of rat cardiac MRI by leveraging deep learning frameworks,"Automated segmentation of human cardiac magnetic resonance datasets has been steadily improving during recent years. Similar applications would be highly useful to improve and speed up the studies of cardiac function in rodents in the preclinical context. However, the transfer of such segmentation methods to the preclinical research is compounded by the limited number of datasets and lower image resolution. In this paper we present a successful application of deep architectures 3D cardiac segmentation for rats in preclinical contexts which to our knowledge has not yet been reported. We developed segmentation models that expand on the standard U-Net architecture and evaluated models separately trained for systole and diastole phases (2MSA) and a single model trained for all phases (1MSA). Furthermore, we calibrated model outputs using a Gaussian process (GP)-based prior to improve phase selection. The resulting models approach human performance in terms of left ventricular segmentation quality and ejection fraction (EF) estimation in both 1MSA and 2MSA settings (Sørensen-Dice score 0.91 ± 0.072 and 0.93 ± 0.032, respectively). 2MSA achieved a mean absolute difference between estimated and reference EF of 3.5 ± 2.5%, while 1MSA resulted in 4.1 ± 3.0%. Applying GPs to 1MSA enabled automating systole and diastole phase selection. Both segmentation approaches (1MSA and 2MSA) were statistically equivalent. Combined with a proposed cardiac phase selection strategy, our work presents an important first step towards a fully automated segmentation pipeline in the context of rat cardiac analysis.","The authors would like to thank Johan Karlsson, Edmund Watson, Tobias Noeske, Juan Pedro Vigueras-Guillén, Margareta Behrendt and Abdel Bidar for the fruitful discussions, help and support throughout the project.","All authors were funded by Biopharmaceutical R&D, AstraZeneca Pepparedsleden 1, SE 43183 Mölndal, Sweden.",Scientific Reports,,Animals, Deep Learning, Heart, Heart Ventricles, Magnetic Resonance Imaging, Radiography, Rats,2022-06-02,2022,2022-06-02,,12,1,9193,All OA, Gold,Article,"Fernández-Llaneza, Daniel; Gondová, Andrea; Vince, Harris; Patra, Arijit; Zurek, Magdalena; Konings, Peter; Kagelid, Patrik; Hultin, Leif","Fernández-Llaneza, Daniel (Clinical Pharmacology and Safety Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden); Gondová, Andrea (Clinical Pharmacology and Safety Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden); Vince, Harris (Clinical Pharmacology and Safety Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden); Patra, Arijit (Clinical Pharmacology and Safety Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden); Zurek, Magdalena (Clinical Pharmacology and Safety Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden); Konings, Peter (Data Sciences and Quantitative Biology, Discovery Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden); Kagelid, Patrik (Clinical Pharmacology and Safety Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden); Hultin, Leif (Clinical Pharmacology and Safety Sciences, Biopharmaceuticals R&D, AstraZeneca, Pepparedsleden 1, 431 83, Mölndal, SE, Sweden)","Fernández-Llaneza, Daniel (AstraZeneca (Sweden))","Fernández-Llaneza, Daniel (AstraZeneca (Sweden)); Gondová, Andrea (AstraZeneca (Sweden)); Vince, Harris (AstraZeneca (Sweden)); Patra, Arijit (AstraZeneca (Sweden)); Zurek, Magdalena (AstraZeneca (Sweden)); Konings, Peter (AstraZeneca (Sweden)); Kagelid, Patrik (AstraZeneca (Sweden)); Hultin, Leif (AstraZeneca (Sweden))",0,0,,,https://www.nature.com/articles/s41598-022-12378-z.pdf,https://app.dimensions.ai/details/publication/pub.1148374914,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,
1398,pub.1148488878,10.48550/arxiv.2206.01737,,,MaxStyle: Adversarial Style Composition for Robust Medical Image  Segmentation,"Convolutional neural networks (CNNs) have achieved remarkable segmentation
accuracy on benchmark datasets where training and test sets are from the same
domain, yet their performance can degrade significantly on unseen domains,
which hinders the deployment of CNNs in many clinical scenarios. Most existing
works improve model out-of-domain (OOD) robustness by collecting multi-domain
datasets for training, which is expensive and may not always be feasible due to
privacy and logistical issues. In this work, we focus on improving model
robustness using a single-domain dataset only. We propose a novel data
augmentation framework called MaxStyle, which maximizes the effectiveness of
style augmentation for model OOD performance. It attaches an auxiliary
style-augmented image decoder to a segmentation network for robust feature
learning and data augmentation. Importantly, MaxStyle augments data with
improved image style diversity and hardness, by expanding the style space with
noise and searching for the worst-case style composition of latent features via
adversarial training. With extensive experiments on multiple public cardiac and
prostate MR datasets, we demonstrate that MaxStyle leads to significantly
improved out-of-distribution robustness against unseen corruptions as well as
common distribution shifts across multiple, different, unseen sites and unknown
image sequences under both low- and high-training data settings. The code can
be found at https://github.com/cherise215/MaxStyle.",,,arXiv,,,2022-06-02,2022,,,,,,All OA, Green,Preprint,"Chen, Chen; Li, Zeju; Ouyang, Cheng; Sinclair, Matt; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (); Li, Zeju (); Ouyang, Cheng (); Sinclair, Matt (); Bai, Wenjia (); Rueckert, Daniel ()",,"Chen, Chen (); Li, Zeju (); Ouyang, Cheng (); Sinclair, Matt (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148488878,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
568,pub.1148408535,10.48550/arxiv.2206.01136,,,"Transforming medical imaging with Transformers? A comparative review of  key properties, current progresses, and future perspectives","Transformer, the latest technological advance of deep learning, has gained
prevalence in natural language processing or computer vision. Since medical
imaging bear some resemblance to computer vision, it is natural to inquire
about the status quo of Transformers in medical imaging and ask the question:
can the Transformer models transform medical imaging? In this paper, we attempt
to make a response to the inquiry. After a brief introduction of the
fundamentals of Transformers, especially in comparison with convolutional
neural networks (CNNs), and highlighting key defining properties that
characterize the Transformers, we offer a comprehensive review of the
state-of-the-art Transformer-based approaches for medical imaging and exhibit
current research progresses made in the areas of medical image segmentation,
recognition, detection, registration, reconstruction, enhancement, etc. In
particular, what distinguishes our review lies in its organization based on the
Transformer's key defining properties, which are mostly derived from comparing
the Transformer and CNN, and its type of architecture, which specifies the
manner in which the Transformer and CNN are combined, all helping the readers
to best understand the rationale behind the reviewed approaches. We conclude
with discussions of future perspectives.",,,arXiv,,,2022-06-02,2022,,,,,,All OA, Green,Preprint,"Li, Jun; Chen, Junyu; Tang, Yucheng; Wang, Ce; Landman, Bennett A.; Zhou, S. Kevin","Li, Jun (); Chen, Junyu (); Tang, Yucheng (); Wang, Ce (); Landman, Bennett A. (); Zhou, S. Kevin ()",,"Li, Jun (); Chen, Junyu (); Tang, Yucheng (); Wang, Ce (); Landman, Bennett A. (); Zhou, S. Kevin ()",1,1,,,,https://app.dimensions.ai/details/publication/pub.1148408535,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1299,pub.1148380484,10.48550/arxiv.2206.00566,,,The Fully Convolutional Transformer for Medical Image Segmentation,"We propose a novel transformer model, capable of segmenting medical images of
varying modalities. Challenges posed by the fine grained nature of medical
image analysis mean that the adaptation of the transformer for their analysis
is still at nascent stages. The overwhelming success of the UNet lay in its
ability to appreciate the fine-grained nature of the segmentation task, an
ability which existing transformer based models do not currently posses. To
address this shortcoming, we propose The Fully Convolutional Transformer (FCT),
which builds on the proven ability of Convolutional Neural Networks to learn
effective image representations, and combines them with the ability of
Transformers to effectively capture long-term dependencies in its inputs. The
FCT is the first fully convolutional Transformer model in medical imaging
literature. It processes its input in two stages, where first, it learns to
extract long range semantic dependencies from the input image, and then learns
to capture hierarchical global attributes from the features. FCT is compact,
accurate and robust. Our results show that it outperforms all existing
transformer architectures by large margins across multiple medical image
segmentation datasets of varying data modalities without the need for any
pre-training. FCT outperforms its immediate competitor on the ACDC dataset by
1.3%, on the Synapse dataset by 4.4%, on the Spleen dataset by 1.2% and on ISIC
2017 dataset by 1.1% on the dice metric, with up to five times fewer
parameters. Our code, environments and models will be available via GitHub.",,,arXiv,,,2022-06-01,2022,,,,,,All OA, Green,Preprint,"Tragakis, Athanasios; Kaul, Chaitanya; Murray-Smith, Roderick; Husmeier, Dirk","Tragakis, Athanasios (); Kaul, Chaitanya (); Murray-Smith, Roderick (); Husmeier, Dirk ()",,"Tragakis, Athanasios (); Kaul, Chaitanya (); Murray-Smith, Roderick (); Husmeier, Dirk ()",1,1,,,,https://app.dimensions.ai/details/publication/pub.1148380484,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
4791,pub.1148243553,10.1117/1.jmi.9.5.052407,35692896,PMC9142841,Knowledge distillation with ensembles of convolutional neural networks for medical image segmentation,"Purpose: Ensembles of convolutional neural networks (CNNs) often outperform a single CNN in medical image segmentation tasks, but inference is computationally more expensive and makes ensembles unattractive for some applications. We compared the performance of differently constructed ensembles with the performance of CNNs derived from these ensembles using knowledge distillation, a technique for reducing the footprint of large models such as ensembles. Approach: We investigated two different types of ensembles, namely, diverse ensembles of networks with three different architectures and two different loss-functions, and uniform ensembles of networks with the same architecture but initialized with different random seeds. For each ensemble, additionally, a single student network was trained to mimic the class probabilities predicted by the teacher model, the ensemble. We evaluated the performance of each network, the ensembles, and the corresponding distilled networks across three different publicly available datasets. These included chest computed tomography scans with four annotated organs of interest, brain magnetic resonance imaging (MRI) with six annotated brain structures, and cardiac cine-MRI with three annotated heart structures. Results: Both uniform and diverse ensembles obtained better results than any of the individual networks in the ensemble. Furthermore, applying knowledge distillation resulted in a single network that was smaller and faster without compromising performance compared with the ensemble it learned from. The distilled networks significantly outperformed the same network trained with reference segmentation instead of knowledge distillation. Conclusion: Knowledge distillation can compress segmentation ensembles of uniform or diverse composition into a single CNN while maintaining the performance of the ensemble.","This work is part of the research program Deep Learning for Medical Image Analysis under project number P15-26, financed by the Dutch Technology Foundation with contribution by Philips Healthcare.",,Journal of Medical Imaging,,,2022-05-28,2022,2022-05-28,2022-09,9,5,052407-052407,All OA, Hybrid,Article,"Noothout, Julia M. H.; Lessmann, Nikolas; van Eede, Matthijs C.; van Harten, Louis D.; Sogancioglu, Ecem; Heslinga, Friso G.; Veta, Mitko; van Ginneken, Bram; Išgum, Ivana","Noothout, Julia M. H. (Amsterdam University Medical Center, University of Amsterdam, Department of Biomedical Engineering and Physics, Amsterdam, The Netherlands); Lessmann, Nikolas (Radboud University Medical Center, Department of Medical Imaging, Nijmegen, The Netherlands); van Eede, Matthijs C. (Amsterdam University Medical Center, University of Amsterdam, Department of Biomedical Engineering and Physics, Amsterdam, The Netherlands); van Harten, Louis D. (Amsterdam University Medical Center, University of Amsterdam, Department of Biomedical Engineering and Physics, Amsterdam, The Netherlands); Sogancioglu, Ecem (Radboud University Medical Center, Department of Medical Imaging, Nijmegen, The Netherlands); Heslinga, Friso G. (Eindhoven University of Technology, Department of Biomedical Engineering, Eindhoven, The Netherlands); Veta, Mitko (Eindhoven University of Technology, Department of Biomedical Engineering, Eindhoven, The Netherlands); van Ginneken, Bram (Radboud University Medical Center, Department of Medical Imaging, Nijmegen, The Netherlands); Išgum, Ivana (Amsterdam University Medical Center, University of Amsterdam, Department of Biomedical Engineering and Physics, Amsterdam, The Netherlands; Amsterdam University Medical Center, University of Amsterdam, Department of Radiology and Nuclear Medicine, Amsterdam, The Netherlands; Amsterdam University Medical Center, University of Amsterdam, Amsterdam Cardiovascular Sciences, Heart Failure & Arrhythmias, Amsterdam, The Netherlands; University of Amsterdam, Informatics Institute, Amsterdam, The Netherlands)","Lessmann, Nikolas (Radboud University Nijmegen Medical Centre); Veta, Mitko (Eindhoven University of Technology)","Noothout, Julia M. H. (University of Amsterdam); Lessmann, Nikolas (Radboud University Nijmegen Medical Centre); van Eede, Matthijs C. (University of Amsterdam); van Harten, Louis D. (University of Amsterdam); Sogancioglu, Ecem (Radboud University Nijmegen Medical Centre); Heslinga, Friso G. (Eindhoven University of Technology); Veta, Mitko (Eindhoven University of Technology); van Ginneken, Bram (Radboud University Nijmegen Medical Centre); Išgum, Ivana (University of Amsterdam; University of Amsterdam; University of Amsterdam; University of Amsterdam)",2,2,,,https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-9/issue-5/052407/Knowledge-distillation-with-ensembles-of-convolutional-neural-networks-for-medical/10.1117/1.JMI.9.5.052407.pdf,https://app.dimensions.ai/details/publication/pub.1148243553,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering,,,,,,,,
1395,pub.1148187175,10.48550/arxiv.2205.12429,,,Interaction of a priori Anatomic Knowledge with Self-Supervised  Contrastive Learning in Cardiac Magnetic Resonance Imaging,"Training deep learning models on cardiac magnetic resonance imaging (CMR) can
be a challenge due to the small amount of expert generated labels and inherent
complexity of data source. Self-supervised contrastive learning (SSCL) has
recently been shown to boost performance in several medical imaging tasks.
However, it is unclear how much the pre-trained representation reflects the
primary organ of interest compared to spurious surrounding tissue. In this
work, we evaluate the optimal method of incorporating prior knowledge of
anatomy into a SSCL training paradigm. Specifically, we evaluate using a
segmentation network to explicitly local the heart in CMR images, followed by
SSCL pretraining in multiple diagnostic tasks. We find that using a priori
knowledge of anatomy can greatly improve the downstream diagnostic performance.
Furthermore, SSCL pre-training with in-domain data generally improved
downstream performance and more human-like saliency compared to end-to-end
training and ImageNet pre-trained networks. However, introducing anatomic
knowledge to pre-training generally does not have significant impact.",,,arXiv,,,2022-05-24,2022,,,,,,All OA, Green,Preprint,"Nakashima, Makiya; Jang, Inyeop; Basnet, Ramesh; Benovoy, Mitchel; Tang, W. H. Wilson; Nguyen, Christopher; Kwon, Deborah; Hwang, Tae Hyun; Chen, David","Nakashima, Makiya (); Jang, Inyeop (); Basnet, Ramesh (); Benovoy, Mitchel (); Tang, W. H. Wilson (); Nguyen, Christopher (); Kwon, Deborah (); Hwang, Tae Hyun (); Chen, David ()",,"Nakashima, Makiya (); Jang, Inyeop (); Basnet, Ramesh (); Benovoy, Mitchel (); Tang, W. H. Wilson (); Nguyen, Christopher (); Kwon, Deborah (); Hwang, Tae Hyun (); Chen, David ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148187175,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4772,pub.1148018312,10.3390/jcm11102866,35628992,PMC9147423,The Applications of Artificial Intelligence in Cardiovascular Magnetic Resonance—A Comprehensive Review,"Cardiovascular disease remains an integral field on which new research in both the biomedical and technological fields is based, as it remains the leading cause of mortality and morbidity worldwide. However, despite the progress of cardiac imaging techniques, the heart remains a challenging organ to study. Artificial intelligence (AI) has emerged as one of the major innovations in the field of diagnostic imaging, with a dramatic impact on cardiovascular magnetic resonance imaging (CMR). AI will be increasingly present in the medical world, with strong potential for greater diagnostic efficiency and accuracy. Regarding the use of AI in image acquisition and reconstruction, the main role was to reduce the time of image acquisition and analysis, one of the biggest challenges concerning magnetic resonance; moreover, it has been seen to play a role in the automatic correction of artifacts. The use of these techniques in image segmentation has allowed automatic and accurate quantification of the volumes and masses of the left and right ventricles, with occasional need for manual correction. Furthermore, AI can be a useful tool to directly help the clinician in the diagnosis and derivation of prognostic information of cardiovascular diseases. This review addresses the applications and future prospects of AI in CMR imaging, from image acquisition and reconstruction to image segmentation, tissue characterization, diagnostic evaluation, and prognostication.",,This research received no external funding.,Journal of Clinical Medicine,,,2022-05-19,2022,2022-05-19,,11,10,2866,All OA, Gold,Article,"Argentiero, Adriana; Muscogiuri, Giuseppe; Rabbat, Mark G.; Martini, Chiara; Soldato, Nicolò; Basile, Paolo; Baggiano, Andrea; Mushtaq, Saima; Fusini, Laura; Mancini, Maria Elisabetta; Gaibazzi, Nicola; Santobuono, Vincenzo Ezio; Sironi, Sandro; Pontone, Gianluca; Guaricci, Andrea Igoren","Argentiero, Adriana (University Cardiology Unit, Cardio-Thoracic Department, Policlinic University Hospital, 70121 Bari, Italy;, adrianaargentiero92@gmail.com, (A.A.);, nicolo.soldato@gmail.com, (N.S.);, pabas2304@gmail.com, (P.B.);, eziosantobuono@gmail.com, (V.E.S.)); Muscogiuri, Giuseppe (School of Medicine and Surgery, University of Milano-Bicocca, 20126 Milan, Italy;, g.muscogiuri@gmail.com, (G.M.);, sandro.sironi@unimib.it, (S.S.); Department of Radiology, IRCCS Istituto Auxologico Italiano, San Luca Hospital, 20149 Milan, Italy); Rabbat, Mark G. (Division of Cardiology, Loyola University of Chicago, Chicago, IL 60660, USA;, mrabbat@lumc.edu); Martini, Chiara (Radiologic Sciences, Department of Medicine and Surgery, University of Parma, 43126 Parma, Italy;, chiaramartini10@gmail.com); Soldato, Nicolò (University Cardiology Unit, Cardio-Thoracic Department, Policlinic University Hospital, 70121 Bari, Italy;, adrianaargentiero92@gmail.com, (A.A.);, nicolo.soldato@gmail.com, (N.S.);, pabas2304@gmail.com, (P.B.);, eziosantobuono@gmail.com, (V.E.S.)); Basile, Paolo (University Cardiology Unit, Cardio-Thoracic Department, Policlinic University Hospital, 70121 Bari, Italy;, adrianaargentiero92@gmail.com, (A.A.);, nicolo.soldato@gmail.com, (N.S.);, pabas2304@gmail.com, (P.B.);, eziosantobuono@gmail.com, (V.E.S.)); Baggiano, Andrea (Perioperative and Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, 20138 Milan, Italy;, andrea.baggiano@cardiologicomonzino.it, (A.B.);, saima.mushtaq@ccfm.it, (S.M.);, laura.fusini@cardiologicomonzino.it, (L.F.);, maria.mancini@cardiologicomonzino.it, (M.E.M.);, gianluca.pontone@cardiologicomonzino.it, (G.P.)); Mushtaq, Saima (Perioperative and Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, 20138 Milan, Italy;, andrea.baggiano@cardiologicomonzino.it, (A.B.);, saima.mushtaq@ccfm.it, (S.M.);, laura.fusini@cardiologicomonzino.it, (L.F.);, maria.mancini@cardiologicomonzino.it, (M.E.M.);, gianluca.pontone@cardiologicomonzino.it, (G.P.)); Fusini, Laura (Perioperative and Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, 20138 Milan, Italy;, andrea.baggiano@cardiologicomonzino.it, (A.B.);, saima.mushtaq@ccfm.it, (S.M.);, laura.fusini@cardiologicomonzino.it, (L.F.);, maria.mancini@cardiologicomonzino.it, (M.E.M.);, gianluca.pontone@cardiologicomonzino.it, (G.P.)); Mancini, Maria Elisabetta (Perioperative and Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, 20138 Milan, Italy;, andrea.baggiano@cardiologicomonzino.it, (A.B.);, saima.mushtaq@ccfm.it, (S.M.);, laura.fusini@cardiologicomonzino.it, (L.F.);, maria.mancini@cardiologicomonzino.it, (M.E.M.);, gianluca.pontone@cardiologicomonzino.it, (G.P.)); Gaibazzi, Nicola (Department of Cardiology, Azienda Ospedaliero-Universitaria, 43126 Parma, Italy;, ngaibazzi@gmail.com); Santobuono, Vincenzo Ezio (University Cardiology Unit, Cardio-Thoracic Department, Policlinic University Hospital, 70121 Bari, Italy;, adrianaargentiero92@gmail.com, (A.A.);, nicolo.soldato@gmail.com, (N.S.);, pabas2304@gmail.com, (P.B.);, eziosantobuono@gmail.com, (V.E.S.)); Sironi, Sandro (School of Medicine and Surgery, University of Milano-Bicocca, 20126 Milan, Italy;, g.muscogiuri@gmail.com, (G.M.);, sandro.sironi@unimib.it, (S.S.); Department of Radiology, ASST Papa Giovanni XXIII Hospital, 24127 Bergamo, Italy); Pontone, Gianluca (Perioperative and Cardiovascular Imaging Department, Centro Cardiologico Monzino IRCCS, 20138 Milan, Italy;, andrea.baggiano@cardiologicomonzino.it, (A.B.);, saima.mushtaq@ccfm.it, (S.M.);, laura.fusini@cardiologicomonzino.it, (L.F.);, maria.mancini@cardiologicomonzino.it, (M.E.M.);, gianluca.pontone@cardiologicomonzino.it, (G.P.)); Guaricci, Andrea Igoren (University Cardiology Unit, Cardio-Thoracic Department, Policlinic University Hospital, 70121 Bari, Italy;, adrianaargentiero92@gmail.com, (A.A.);, nicolo.soldato@gmail.com, (N.S.);, pabas2304@gmail.com, (P.B.);, eziosantobuono@gmail.com, (V.E.S.); Department of Emergency and Organ Transplantation, University of Bari, 70121 Bari, Italy)","Guaricci, Andrea Igoren (; University of Bari Aldo Moro)","Argentiero, Adriana (); Muscogiuri, Giuseppe (University of Milano-Bicocca; Istituto Auxologico Italiano); Rabbat, Mark G. (Loyola University Chicago); Martini, Chiara (University of Parma); Soldato, Nicolò (); Basile, Paolo (); Baggiano, Andrea (Centro Cardiologico Monzino); Mushtaq, Saima (Centro Cardiologico Monzino); Fusini, Laura (Centro Cardiologico Monzino); Mancini, Maria Elisabetta (Centro Cardiologico Monzino); Gaibazzi, Nicola (Ospedale di Parma); Santobuono, Vincenzo Ezio (); Sironi, Sandro (University of Milano-Bicocca; Ospedale Papa Giovanni XXIII); Pontone, Gianluca (Centro Cardiologico Monzino); Guaricci, Andrea Igoren (University of Bari Aldo Moro)",4,4,,,https://www.mdpi.com/2077-0383/11/10/2866/pdf?version=1652948805,https://app.dimensions.ai/details/publication/pub.1148018312,32 Biomedical and Clinical Sciences,3 Good Health and Well Being,,,,,,,,,,
6517,pub.1147979681,10.3390/s22103820,35632229,PMC9145221,Multiresolution Aggregation Transformer UNet Based on Multiscale Input and Coordinate Attention for Medical Image Segmentation,"The latest medical image segmentation methods uses UNet and transformer structures with great success. Multiscale feature fusion is one of the important factors affecting the accuracy of medical image segmentation. Existing transformer-based UNet methods do not comprehensively explore multiscale feature fusion, and there is still much room for improvement. In this paper, we propose a novel multiresolution aggregation transformer UNet (MRA-TUNet) based on multiscale input and coordinate attention for medical image segmentation. It realizes multiresolution aggregation from the following two aspects: (1) On the input side, a multiresolution aggregation module is used to fuse the input image information of different resolutions, which enhances the input features of the network. (2) On the output side, an output feature selection module is used to fuse the output information of different scales to better extract coarse-grained information and fine-grained information. We try to introduce a coordinate attention structure for the first time to further improve the segmentation performance. We compare with state-of-the-art medical image segmentation methods on the automated cardiac diagnosis challenge and the 2018 atrial segmentation challenge. Our method achieved average dice score of 0.911 for right ventricle (RV), 0.890 for myocardium (Myo), 0.961 for left ventricle (LV), and 0.923 for left atrium (LA). The experimental results on two datasets show that our method outperforms eight state-of-the-art medical image segmentation methods in dice score, precision, and recall.","The author thanks the whole authors in the referred articles. In addition, the author would also like to thank Jiuying Chen and Ruiyang Guo. This study was supported by Sun Yat-sen University.",This work was supported in part by the Science and Technology Planning Project of Guangdong Science and Technology Department under Grant Guangdong Key Laboratory of Advanced IntelliSense Technology (2019B121203006).,Sensors,,"Attention; Heart; Heart Ventricles; Image Processing, Computer-Assisted",2022-05-18,2022,2022-05-18,,22,10,3820,All OA, Gold,Article,"Chen, Shaolong; Qiu, Changzhen; Yang, Weiping; Zhang, Zhiyong","Chen, Shaolong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.); Qiu, Changzhen (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.); Yang, Weiping (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.); Zhang, Zhiyong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.)","Zhang, Zhiyong (Sun Yat-sen University)","Chen, Shaolong (Sun Yat-sen University); Qiu, Changzhen (Sun Yat-sen University); Yang, Weiping (Sun Yat-sen University); Zhang, Zhiyong (Sun Yat-sen University)",3,3,,,https://www.mdpi.com/1424-8220/22/10/3820/pdf?version=1652860408,https://app.dimensions.ai/details/publication/pub.1147979681,46 Information and Computing Sciences, 4605 Data Management and Data Science,3 Good Health and Well Being,,,,,,,,,
6270,pub.1147963431,10.1007/s10334-022-01017-3,35585430,,Right ventricular strain and volume analyses through deep learning-based fully automatic segmentation based on radial long-axis reconstruction of short-axis cine magnetic resonance images,"ObjectiveWe propose a deep learning-based fully automatic right ventricle (RV) segmentation technique that targets radially reconstructed long-axis (RLA) images of the center of the RV region in routine short axis (SA) cardiovascular magnetic resonance (CMR) images. Accordingly, the purpose of this study is to compare the accuracy of deep learning-based fully automatic segmentation of RLA images with the accuracy of conventional deep learning-based segmentation in SA orientation in terms of the measurements of RV strain parameters.Materials and methodsWe compared the accuracies of the above-mentioned methods in RV segmentations and in measuring RV strain parameters by Dice similarity coefficients (DSCs) and correlation coefficients.ResultsDSC of RV segmentation of the RLA method exhibited a higher value than those of the conventional SA methods (0.84 vs. 0.61). Correlation coefficient with respect to manual RV strain measurements in the fully automatic RLA were superior to those in SA measurements (0.5–0.7 vs. 0.1–0.2).DiscussionOur proposed RLA realizes accurate fully automatic extraction of the entire RV region from an available CMR cine image without any additional imaging. Our findings overcome the complexity of image analysis in CMR without the limitations of the RV visualization in echocardiography.",We thank Editage (www.editage.com) for the English language editing.,This work was supported by the Center for Clinical and Translational Research of Kyushu University Hospital and the JSPS KAKENHI JP20K16729.,"Magnetic Resonance Materials in Physics, Biology and Medicine",,"Heart Ventricles; Magnetic Resonance Imaging, Cine; Deep Learning; Magnetic Resonance Imaging; Image Processing, Computer-Assisted; Reproducibility of Results",2022-05-18,2022,2022-05-18,2022-12,35,6,911-921,Closed,Article,"Kawakubo, Masateru; Moriyama, Daichi; Yamasaki, Yuzo; Abe, Kohtaro; Hosokawa, Kazuya; Moriyama, Tetsuhiro; Triadyaksa, Pandji; Wibowo, Adi; Nagao, Michinobu; Arai, Hideo; Nishimura, Hiroshi; Kadokami, Toshiaki","Kawakubo, Masateru (Department of Health Sciences, Faculty of Medical Sciences, Kyushu University, 3-1-1 Maidashi, Higashi-ku, Fukuoka-shi, 812-8582, Fukuoka, Japan); Moriyama, Daichi (Department of Health Sciences, School of Medical Sciences, Kyushu University, Fukuoka, Japan; Department of Radiological Technology, Hiroshima City Hiroshima Citizens Hospital, Hiroshima, Japan); Yamasaki, Yuzo (Department of Clinical Radiology, Graduate School of Medical Sciences, Kyushu University, Fukuoka, Japan); Abe, Kohtaro (Department of Cardiovascular Medicine, Graduate School of Medical Sciences, Kyushu University, Fukuoka, Japan); Hosokawa, Kazuya (Department of Cardiovascular Medicine, Graduate School of Medical Sciences, Kyushu University, Fukuoka, Japan); Moriyama, Tetsuhiro (Institute of Mathematics for Industry, Kyushu University, Fukuoka, Japan); Triadyaksa, Pandji (Department of Physics, Faculty of Science and Mathematics, Universitas Diponegoro, Semarang, Indonesia); Wibowo, Adi (Department of Computer Science, Faculty of Science and Mathematics, Universitas Diponegoro, Semarang, Indonesia); Nagao, Michinobu (Department of Diagnostic Imaging and Nuclear Medicine, Tokyo Women’s Medical University, Tokyo, Japan); Arai, Hideo (Fukuokaken Saiseikai, Futsukaichi Hospital, Fukuoka, Japan); Nishimura, Hiroshi (Fukuokaken Saiseikai, Futsukaichi Hospital, Fukuoka, Japan); Kadokami, Toshiaki (Fukuokaken Saiseikai, Futsukaichi Hospital, Fukuoka, Japan)","Kawakubo, Masateru (Kyushu University)","Kawakubo, Masateru (Kyushu University); Moriyama, Daichi (Kyushu University; Hiroshima City Hiroshima Citizens Hospital); Yamasaki, Yuzo (Kyushu University); Abe, Kohtaro (Kyushu University); Hosokawa, Kazuya (Kyushu University); Moriyama, Tetsuhiro (Kyushu University); Triadyaksa, Pandji (Diponegoro University); Wibowo, Adi (Diponegoro University); Nagao, Michinobu (Tokyo Women's Medical University); Arai, Hideo (); Nishimura, Hiroshi (); Kadokami, Toshiaki ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147963431,32 Biomedical and Clinical Sciences, 46 Information and Computing Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
2832,pub.1147949776,10.3390/tomography8030108,35645394,PMC9149962,Automated Coronary Optical Coherence Tomography Feature Extraction with Application to Three-Dimensional Reconstruction,"Coronary optical coherence tomography (OCT) is an intravascular, near-infrared light-based imaging modality capable of reaching axial resolutions of 10-20 µm. This resolution allows for accurate determination of high-risk plaque features, such as thin cap fibroatheroma; however, visualization of morphological features alone still provides unreliable positive predictive capability for plaque progression or future major adverse cardiovascular events (MACE). Biomechanical simulation could assist in this prediction, but this requires extracting morphological features from intravascular imaging to construct accurate three-dimensional (3D) simulations of patients' arteries. Extracting these features is a laborious process, often carried out manually by trained experts. To address this challenge, numerous techniques have emerged to automate these processes while simultaneously overcoming difficulties associated with OCT imaging, such as its limited penetration depth. This systematic review summarizes advances in automated segmentation techniques from the past five years (2016-2021) with a focus on their application to the 3D reconstruction of vessels and their subsequent simulation. We discuss four categories based on the feature being processed, namely: coronary lumen; artery layers; plaque characteristics and subtypes; and stents. Areas for future innovation are also discussed as well as their potential for future translation.",,"H.J.C. is supported by a Future Leaders Scholarship from the Westpac Scholars Trust (FL19518) and acknowledges support from The University of Adelaide, School of Mechanical Engineering and the Department of Education, Skills and Employment Research Training Program (RTP) scholarship. J.L is supported by the National Health and Medical Research Council (NHMRC) Investigator Grant (GNT2008462) and the National Heart Foundation of Australia Future Leader Fellowship Grant (105608). P.J.P. receives a Level 2 Future Leader Fellowship from the National Heart Foundation of Australia (FLF102056) and Level 2 Career Development Fellowship from the NHMRC (CDF1161506). J.L and P.J.P would like to acknowledge The Hospital Research Foundation 2021/17/QA25292 and NHMRC Ideas Grant (APP2001646).",Tomography,,"Coronary Artery Disease; Humans; Imaging, Three-Dimensional; Plaque, Atherosclerotic; Tomography, Optical Coherence",2022-05-17,2022,2022-05-17,,8,3,1307-1349,All OA, Gold,Article,"Carpenter, Harry J.; Ghayesh, Mergen H.; Zander, Anthony C.; Li, Jiawen; Di Giovanni, Giuseppe; Psaltis, Peter J.","Carpenter, Harry J. (School of Mechanical Engineering, University of Adelaide, Adelaide, SA 5005, Australia;, anthony.zander@adelaide.edu.au); Ghayesh, Mergen H. (School of Mechanical Engineering, University of Adelaide, Adelaide, SA 5005, Australia;, anthony.zander@adelaide.edu.au); Zander, Anthony C. (School of Mechanical Engineering, University of Adelaide, Adelaide, SA 5005, Australia;, anthony.zander@adelaide.edu.au); Li, Jiawen (School of Electrical Electronic Engineering, University of Adelaide, Adelaide, SA 5005, Australia;, jiawen.li01@adelaide.edu.au; Australian Research Council Centre of Excellence for Nanoscale BioPhotonics, The University of Adelaide, Adelaide, SA 5005, Australia; Institute for Photonics and Advanced Sensing, University of Adelaide, Adelaide, SA 5005, Australia); Di Giovanni, Giuseppe (Vascular Research Centre, Lifelong Health Theme, South Australian Health and Medical Research Institute (SAHMRI), Adelaide, SA 5000, Australia;, giuseppe.digiovanni@sahmri.com, (G.D.G.);, peter.psaltis@adelaide.edu.au, (P.J.P.)); Psaltis, Peter J. (Vascular Research Centre, Lifelong Health Theme, South Australian Health and Medical Research Institute (SAHMRI), Adelaide, SA 5000, Australia;, giuseppe.digiovanni@sahmri.com, (G.D.G.);, peter.psaltis@adelaide.edu.au, (P.J.P.); Adelaide Medical School, University of Adelaide, Adelaide, SA 5005, Australia; Department of Cardiology, Central Adelaide Local Health Network, Adelaide, SA 5000, Australia)","Carpenter, Harry J. (University of Adelaide); Ghayesh, Mergen H. (University of Adelaide)","Carpenter, Harry J. (University of Adelaide); Ghayesh, Mergen H. (University of Adelaide); Zander, Anthony C. (University of Adelaide); Li, Jiawen (University of Adelaide; University of Adelaide; University of Adelaide); Di Giovanni, Giuseppe (South Australian Health and Medical Research Institute); Psaltis, Peter J. (South Australian Health and Medical Research Institute; University of Adelaide; SA Health)",1,1,,,https://www.mdpi.com/2379-139X/8/3/108/pdf?version=1652947361,https://app.dimensions.ai/details/publication/pub.1147949776,32 Biomedical and Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering,,,,,,,,,
6050,pub.1147900050,10.1177/01617346221099435,35574925,,Cardiac Segmentation Method Based on Domain Knowledge,"Echocardiography plays an important role in the clinical diagnosis of cardiovascular diseases. Cardiac function assessment by echocardiography is a crucial process in daily cardiology. However, cardiac segmentation in echocardiography is a challenging task due to shadows and speckle noise. The traditional manual segmentation method is a time-consuming process and limited by inter-observer variability. In this paper, we present a fast and accurate echocardiographic automatic segmentation framework based on Convolutional neural networks (CNN). We propose FAUet, a segmentation method serially integrated U-Net with coordinate attention mechanism and domain feature loss from VGG19 pre-trained on the ImageNet dataset. The coordinate attention mechanism can capture long-range dependencies along one spatial direction and meanwhile preserve precise positional information along the other spatial direction. And the domain feature loss is more concerned with the topology of cardiac structures by exploiting their higher-level features. In this research, we use a two-dimensional echocardiogram (2DE) of 88 patients from two devices, Philips Epiq 7C and Mindray Resona 7T, to segment the left ventricle (LV), interventricular septal (IVS), and posterior left ventricular wall (PLVW). We also draw the gradient weighted class activation mapping (Grad-CAM) to improve the interpretability of the segmentation results. Compared with the traditional U-Net, the proposed segmentation method shows better performance. The mean Dice Score Coefficient (Dice) of LV, IVS, and PLVW of FAUet can achieve 0.932, 0.848, and 0.868, and the average Dice of the three objects can achieve 0.883. Statistical analysis showed that there is no significant difference between the segmentation results of the two devices. The proposed method can realize fast and accurate segmentation of 2DE with a low time cost. Combining coordinate attention module and feature loss with the original U-Net framework can significantly increase the performance of the algorithm.",,"Funding The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This research was supported by Foundation of Shenzhen Science and Technology Planning Project (No. GJHZ20200731095205015) ,the International Cooperation Foundation of Tsinghua Shenzhen International Graduate School (No. HW2021001), Shenzhen Key Medical Discipline Construction Fund(No. SZXK019) and The Natural Science Foundation of Guangdong Province (No. 2022A1515011120).",Ultrasonic Imaging,,"Echocardiography; Heart; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2022-05-14,2022,2022-05-14,2022-05,44,2-3,105-117,Closed,Article,"Wang, Yingni; Chen, Wenbin; Tang, Tianhong; Xie, Wenquan; Jiang, Yong; Zhang, Huabin; Zhou, Xiaobo; Yuan, Kehong","Wang, Yingni (Graduate School at Shenzhen, Tsinghua University, Shenzhen, China); Chen, Wenbin (Department of Echocardiography, Fuwai Hospital Chinese Academy of Medical Sciences, Shenzhen, China); Tang, Tianhong (Department of Echocardiography, Fuwai Hospital Chinese Academy of Medical Sciences, Shenzhen, China); Xie, Wenquan (Graduate School at Shenzhen, Tsinghua University, Shenzhen, China); Jiang, Yong (Department of Echocardiography, Fuwai Hospital Chinese Academy of Medical Sciences, Shenzhen, China); Zhang, Huabin (Beijing Tsinghua Changgung Hospital, Tsinghua University, Beijing, China); Zhou, Xiaobo (School of Biomedical Informatics, University of Texas Health Sciences Center at Houston, Houston, TX, USA); Yuan, Kehong (Graduate School at Shenzhen, Tsinghua University, Shenzhen, China)","Jiang, Yong (Fuwai Hospital); Yuan, Kehong (Tsinghua University)","Wang, Yingni (Tsinghua University); Chen, Wenbin (Fuwai Hospital); Tang, Tianhong (Fuwai Hospital); Xie, Wenquan (Tsinghua University); Jiang, Yong (Fuwai Hospital); Zhang, Huabin (Tsinghua University; Beijing Tsinghua Chang Gung Hospital); Zhou, Xiaobo (The University of Texas Health Science Center at Houston); Yuan, Kehong (Tsinghua University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147900050,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
4788,pub.1147882778,10.1016/j.cmpb.2022.106889,35649296,,A systematic review of multi-slice and multi-frame descriptors in cardiac MRI exams,"Computer-Aided Diagnosis systems have been developed to help medical professional in their decision making routines towards a more accurate diagnosis. These systems process medical exams such as Magnetic Resonance (MRI) in order to quantify meaningful features. These can be used with similarity-measuring techniques in a Content-Based Image Retrieval context, or inputted into a machine learning classifier in order to support early disease detection. For cardiac MRIs, single slice descriptors have been proposed in the two-dimensional domain, shape descriptors have been proposed in the three-dimensional domain, and previous reviews have mapped these two descriptor categories. Nonetheless, no systematic review on these descriptors have looked at full cardiac MRI images sets. We have reviewed the literature by searching for descriptors that consider the whole slice set (multi-slice) or frames (multi-frame) in cardiac MRI exams. We discuss descriptors and techniques, the datasets that were used, and the different evaluation metrics. Finally, we highlight literature gaps and research opportunities.",The authors declare no conflict of interest. This study was financed in part by the Brazilian National Council of Scientific and Technological Development (CNPq) (Grant 309030/2019-6) and the São Paulo Research Foundation (FAPESP) (Grant 2014/50889-7-): National Institute of Science and Technology – Medicine Assisted by Scientific Computing (INCT-MACC).,,Computer Methods and Programs in Biomedicine,,"Algorithms; Diagnosis, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Radiography",2022-05-14,2022,2022-05-14,2022-06,221,,106889,Closed,Article,"Delmondes, Pedro H M; Nunes, Fátima L S","Delmondes, Pedro H M (Universidade de São Paulo, São Paulo, SP, Brazil. Electronic address: pedro.delmondes@usp.br.); Nunes, Fátima L S (Universidade de São Paulo, São Paulo, SP, Brazil.)","Delmondes, Pedro H M (Universidade de São Paulo)","Delmondes, Pedro H M (Universidade de São Paulo); Nunes, Fátima L S (Universidade de São Paulo)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1147882778,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
1454,pub.1147899537,10.48550/arxiv.2205.06779,,,Scribble2D5: Weakly-Supervised Volumetric Image Segmentation via  Scribble Annotations,"Recently, weakly-supervised image segmentation using weak annotations like
scribbles has gained great attention, since such annotations are much easier to
obtain compared to time-consuming and label-intensive labeling at the
pixel/voxel level. However, because scribbles lack structure information of
region of interest (ROI), existing scribble-based methods suffer from poor
boundary localization. Furthermore, most current methods are designed for 2D
image segmentation, which do not fully leverage the volumetric information if
directly applied to image slices. In this paper, we propose a scribble-based
volumetric image segmentation, Scribble2D5, which tackles 3D anisotropic image
segmentation and improves boundary prediction. To achieve this, we augment a
2.5D attention UNet with a proposed label propagation module to extend semantic
information from scribbles and a combination of static and active boundary
prediction to learn ROI's boundary and regularize its shape. Extensive
experiments on three public datasets demonstrate Scribble2D5 significantly
outperforms current scribble-based methods and approaches the performance of
fully-supervised ones. Our code is available online.",,,arXiv,,,2022-05-13,2022,,,,,,All OA, Green,Preprint,"Chen, Qiuhui; Hong, Yi","Chen, Qiuhui (); Hong, Yi ()",,"Chen, Qiuhui (); Hong, Yi ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147899537,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
1733,pub.1147630671,10.1117/12.2634721,,,Spectral normalized CycleGAN with application in semi-supervised semantic segmentation of sonar images,"The effectiveness of CycleGAN is demonstrated to outperform recent approaches for semi-supervised semantic segmentation on public segmentation benchmarks for a small number of the labelled data. However CycleGAN tends to generate same semantic segmentation results for acoustic image datasets, and can’t retain target details. To solve this problem, an spectral normalized CycleGAN network (SNCycleGAN) is presented, which applies spectral normalization to both generators and discriminators to stabilize the training of GANs. The experimental results demonstrate that semi-supervised training of SNCycleGAN helps to achieve reasonably accurate sonar targets segmentation from limited labelled data without using transfer learning, and surpass supervised training in detail preservation.",,,Proceedings of SPIE,International Conference on Electronic Information Engineering and Computer Communication (EIECC 2021),,2022-05-04,2022,,,12172,,1217224-1217224-7,All OA, Green,Proceeding,"Zhang, Zhisheng; Tang, Jingsong; Zhang, Peng; Ning, Mingqiang; Li, Han; Wu, Haoran","Zhang, Zhisheng (Naval Univ. of Engineering (China)); Tang, Jingsong (Naval Univ. of Engineering (China)); Zhang, Peng (Naval Univ. of Engineering (China)); Ning, Mingqiang (Naval Univ. of Engineering (China)); Li, Han (Naval Univ. of Engineering (China)); Wu, Haoran (Naval Univ. of Engineering (China))",,"Zhang, Zhisheng (Naval University of Engineering); Tang, Jingsong (Naval University of Engineering); Zhang, Peng (Naval University of Engineering); Ning, Mingqiang (Naval University of Engineering); Li, Han (Naval University of Engineering); Wu, Haoran (Naval University of Engineering)",0,0,,,https://downloads.hindawi.com/journals/cin/2022/1274260.pdf,https://app.dimensions.ai/details/publication/pub.1147630671,"40 Engineering; 4006 Communications Engineering; 4009 Electronics, Sensors and Digital Hardware; 51 Physical Sciences; 5102 Atomic, Molecular and Optical Physics",,,,,,,,,,,
1212,pub.1147630865,10.1155/2022/5906877,,,LSTM-Based RNN Framework to Remove Motion Artifacts in Dynamic Multicontrast MR Images with Registration Model,"Today, many people under the age of 10 are being examined for brain-related issues, including tumours, without displaying any symptoms. It is not unusual for children to develop brain-related concerns such as tumours and central nervous system disorders, which may affect 15% of the population. Medical experts believe that the irregular eating habits (junk food) and the consumption of pesticide-tainted fruits and vegetables are to blame. The human body is naturally resistant to harmful gears, but only up to a point. If it exceeds the limit, a cell manipulation process is automatically initiated that can remove dangerous inactive tissues from the cell membrane and later grows into tumour blockage in the human body. Thus, the adoption of an advanced computer-based diagnostic system is highly recommended in order to generate visually enhanced images for anomaly identification and infectious tissue segmentation. In most cases, an MR image is chosen since it is easier to distinguish between affected and nonaffected tissue. Conventional convolution neural network (CCNN) mapping and feature extraction are difficult because of the vast volume of data. In addition, it takes a lengthy time for the MRI scanning process to obtain diverse positions for anomaly identification. Aside from the discomfort, the patient may experience motion abnormalities. Recurrent neural network (RNN) classifies tumour regions into several isolated portions much faster and more accurately, so that it can be prevented. To remove motion artefacts from dynamic multicontrast MR images, a novel long short-term memory- (LSTM-) based RNN framework is introduced in this research. With this method, the MR image’s visual quality is improved over CCNN while simultaneously mapping a larger volume and extracting more quiet characteristics than CCNN can. DC-CNN, SMSR-CNN, FMSI-CNN, and DRCA-CNN results are compared. For both low and high signal-to-noise ratios, the suggested LSTM-based RNN framework has gained reasonable feature intelligibility (SNRs). In comparison to previous approaches, it requires less computing and has higher accuracy when it comes to detecting infected portions.",,,Wireless Communications and Mobile Computing,,,2022-05-04,2022,,2022-05-04,2022,,1-12,All OA, Gold,Article,"Ayub, Shahanaz; Kannan, R. Jagadeesh; S, Shitharth; Alsini, Raed; Hasanin, Tawfiq; Sasidhar, Choragudi","Ayub, Shahanaz (Electronics and Communication Engineering Department, Bundelkhand Institute of Engineering and Technology, Jhansi, Uttar Pradesh, India); Kannan, R. Jagadeesh (School of Computer & Engineering, Vellore Institute of Technology, Chennai Campus, India); S, Shitharth (Department of Computer Science & Engineering, Kebri Dehar University, Kebri Dehar, Ethiopia); Alsini, Raed (Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia); Hasanin, Tawfiq (Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia); Sasidhar, Choragudi (Department of Computer Applications, Annamacharya Institute of Technology and Sciences, Rajampet, 516 126 Andhra Pradesh, India)","S, Shitharth ","Ayub, Shahanaz (Dr. A.P.J. Abdul Kalam Technical University); Kannan, R. Jagadeesh (Vellore Institute of Technology University); S, Shitharth (); Alsini, Raed (King Abdulaziz University); Hasanin, Tawfiq (King Abdulaziz University); Sasidhar, Choragudi (Jawaharlal Nehru Technological University Anantapur)",1,1,,,https://downloads.hindawi.com/journals/wcmc/2022/5906877.pdf,https://app.dimensions.ai/details/publication/pub.1147630865,40 Engineering, 4006 Communications Engineering, 4008 Electrical Engineering, 46 Information and Computing Sciences, 4606 Distributed Computing and Systems Software,,,,,,,
1071,pub.1147626352,10.48550/arxiv.2205.01673,,,A Deep Learning-based Integrated Framework for Quality-aware  Undersampled Cine Cardiac MRI Reconstruction and Analysis,"Cine cardiac magnetic resonance (CMR) imaging is considered the gold standard
for cardiac function evaluation. However, cine CMR acquisition is inherently
slow and in recent decades considerable effort has been put into accelerating
scan times without compromising image quality or the accuracy of derived
results. In this paper, we present a fully-automated, quality-controlled
integrated framework for reconstruction, segmentation and downstream analysis
of undersampled cine CMR data. The framework enables active acquisition of
radial k-space data, in which acquisition can be stopped as soon as acquired
data are sufficient to produce high quality reconstructions and segmentations.
This results in reduced scan times and automated analysis, enabling robust and
accurate estimation of functional biomarkers. To demonstrate the feasibility of
the proposed approach, we perform realistic simulations of radial k-space
acquisitions on a dataset of subjects from the UK Biobank and present results
on in-vivo cine CMR k-space data collected from healthy subjects. The results
demonstrate that our method can produce quality-controlled images in a mean
scan time reduced from 12 to 4 seconds per slice, and that image quality is
sufficient to allow clinically relevant parameters to be automatically
estimated to within 5% mean absolute difference.",,,arXiv,,,2022-05-02,2022,,,,,,All OA, Green,Preprint,"Machado, Inês P.; Puyol-Antón, Esther; Hammernik, Kerstin; Cruz, Gastão; Ugurlu, Devran; Olakorede, Ihsane; Oksuz, Ilkay; Ruijsink, Bram; Castelo-Branco, Miguel; Young, Alistair A.; Prieto, Claudia; Schnabel, Julia A.; King, Andrew P.","Machado, Inês P. (); Puyol-Antón, Esther (); Hammernik, Kerstin (); Cruz, Gastão (); Ugurlu, Devran (); Olakorede, Ihsane (); Oksuz, Ilkay (); Ruijsink, Bram (); Castelo-Branco, Miguel (); Young, Alistair A. (); Prieto, Claudia (); Schnabel, Julia A. (); King, Andrew P. ()",,"Machado, Inês P. (); Puyol-Antón, Esther (); Hammernik, Kerstin (); Cruz, Gastão (); Ugurlu, Devran (); Olakorede, Ihsane (); Oksuz, Ilkay (); Ruijsink, Bram (); Castelo-Branco, Miguel (); Young, Alistair A. (); Prieto, Claudia (); Schnabel, Julia A. (); King, Andrew P. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147626352,32 Biomedical and Clinical Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
1010,pub.1144313611,10.1016/j.patcog.2021.108515,,,Collaborative boundary-aware context encoding networks for error map prediction,"Accurately assessing the medical image segmentation quality of the automatically generated predictions is essential for guaranteeing the reliability of the results of computer-assisted diagnosis (CAD). Many researchers have studied segmentation quality estimation without labeled ground truths. Recently, a novel idea is proposed, which transforms segmentation quality assessment (SQA) into the pixel-wise or voxel-wise error map segmentation task. However, the simple application of vanilla segmentation structures in medical domain fails to achieve satisfactory error segmentation results. In this paper, we propose collaborative boundary-aware context encoding networks called EP-Net for error segmentation task. Specifically, we propose a collaborative feature transformation branch for better feature fusion between images and masks, and precise localization of error regions. Further, we propose a context encoding module to utilize the global predictor from the error map to enhance the feature representation and regularize the networks. Extensive experiments on IBSR V2.0 dataset, ACDC dataset and M&Ms dataset demonstrate that EP-Net achieves better error segmentation results compared with the traditional segmentation patterns. Based on error prediction results, we obtain a proxy metric of segmentation quality, which has high Pearson correlation coefficient with the real segmentation accuracy on all datasets.",This work was supported by the National Natural Science Foundation of China under Grants 62173265,,Pattern Recognition,,,2022-05,2022,,2022-05,125,,108515,All OA, Green,Article,"Zhang, Zhenxi; Tian, Chunna; Gao, Xinbo; Li, Jie; Jiao, Zhicheng; Wang, Cui; Zhong, Zhusi","Zhang, Zhenxi (School of Electronic Engineering, Xidian University, Xi’an 710071, China); Tian, Chunna (School of Electronic Engineering, Xidian University, Xi’an 710071, China); Gao, Xinbo (School of Electronic Engineering, Xidian University, Xi’an 710071, China); Li, Jie (School of Electronic Engineering, Xidian University, Xi’an 710071, China); Jiao, Zhicheng (Department of Diagnostic Imaging, Brown University); Wang, Cui (School of Electronic Engineering, Xidian University, Xi’an 710071, China); Zhong, Zhusi (School of Electronic Engineering, Xidian University, Xi’an 710071, China)","Tian, Chunna (Xidian University)","Zhang, Zhenxi (Xidian University); Tian, Chunna (Xidian University); Gao, Xinbo (Xidian University); Li, Jie (Xidian University); Jiao, Zhicheng (Brown University); Wang, Cui (Xidian University); Zhong, Zhusi (Xidian University)",2,2,,,http://arxiv.org/pdf/2006.14345,https://app.dimensions.ai/details/publication/pub.1144313611,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science,,,,,,,,,
6726,pub.1147514838,10.1155/2022/1274260,35528354,PMC9071973,Spectral Normalized CycleGAN with Application in Semisupervised Semantic Segmentation of Sonar Images,"The effectiveness of CycleGAN is demonstrated to outperform recent approaches for semisupervised semantic segmentation on public segmentation benchmarks. In contrast to analog images, however, the acoustic images are unbalanced and often exhibit speckle noise. As a consequence, CycleGAN is prone to mode-collapse and cannot retain target details when applied directly to the sonar image dataset. To address this problem, a spectral normalized CycleGAN network is presented, which applies spectral normalization to both generators and discriminators to stabilize the training of GANs. Without using a pretrained model, the experimental results demonstrate that our simple yet effective method helps to achieve reasonably accurate sonar targets segmentation results.",This research was supported by National Natural Science Foundation of China (Grant Nos. 42176187 and 41906162) and China’s National Natural Science Foundation (Grant Nos. 42176187 and 41906162).,,Computational Intelligence and Neuroscience,,"Image Processing, Computer-Assisted; Semantics",2022-04-28,2022,2022-04-28,2022-04-28,2022,,1274260,All OA, Gold,Article,"Zhang, Zhisheng; Tang, Jinsong; Zhong, Heping; Wu, Haoran; Zhang, Peng; Ning, Mingqiang","Zhang, Zhisheng (Institute of Electronic Engineering, Naval University of Engineering, Wuhan, China, hjgcdx.cn); Tang, Jinsong (Institute of Electronic Engineering, Naval University of Engineering, Wuhan, China, hjgcdx.cn); Zhong, Heping (Institute of Electronic Engineering, Naval University of Engineering, Wuhan, China, hjgcdx.cn); Wu, Haoran (Institute of Electronic Engineering, Naval University of Engineering, Wuhan, China, hjgcdx.cn); Zhang, Peng (Institute of Electronic Engineering, Naval University of Engineering, Wuhan, China, hjgcdx.cn); Ning, Mingqiang (Institute of Electronic Engineering, Naval University of Engineering, Wuhan, China, hjgcdx.cn)","Tang, Jinsong (Naval University of Engineering)","Zhang, Zhisheng (Naval University of Engineering); Tang, Jinsong (Naval University of Engineering); Zhong, Heping (Naval University of Engineering); Wu, Haoran (Naval University of Engineering); Zhang, Peng (Naval University of Engineering); Ning, Mingqiang (Naval University of Engineering)",0,0,,,https://downloads.hindawi.com/journals/cin/2022/1274260.pdf,https://app.dimensions.ai/details/publication/pub.1147514838,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
3791,pub.1147388741,10.1161/circresaha.121.319969,35482840,PMC9070103,Harnessing Big Data to Advance Treatment and Understanding of Pulmonary Hypertension,"Pulmonary hypertension is a complex disease with multiple causes, corresponding to phenotypic heterogeneity and variable therapeutic responses. Advancing understanding of pulmonary hypertension pathogenesis is likely to hinge on integrated methods that leverage data from health records, imaging, novel molecular -omics profiling, and other modalities. In this review, we summarize key data sets generated thus far in the field and describe analytical methods that hold promise for deciphering the molecular mechanisms that underpin pulmonary vascular remodeling, including machine learning, network medicine, and functional genetics. We also detail how genetic and subphenotyping approaches enable earlier diagnosis, refined prognostication, and optimized treatment prediction. We propose strategies that identify functionally important molecular pathways, bolstered by findings across multi-omics platforms, which are well-positioned to individualize drug therapy selection and advance precision medicine in this highly morbid disease.","Advantages, challenges, and pitfalls with avoidance strategies. ML indicates machine learning; PAH, pulmonary arterial hypertension; and TRIPOD, transparent reporting of a multivariable prediction model for individual prognosis or diagnosis area under the receiver operating characteristic curve chloride intracellular channel protein 4 genome-wide association studies high-density lipoprotein interleukin idiopathic pulmonary arterial hypertension machine learning magnetic resonance neural precursor cell expressed developmentally downregulated protein 9 nuclear factor-κB N-terminal pro-B-type natriuretic peptide pulmonary arterial hypertension pulmonary hypertension protein-protein interactions Pulmonary Vascular Disease ‘-Omics’ project pulmonary vascular resistance quantitative trait loci Registry to Evaluate Early and Long-Term PAH Management right ventricle very-low-density lipoprotein Disclosures B.A. Maron reports consultant roles for Actelion Pharmaceuticals and Tenax, and a Grant/ Contract from Deerfield Company. The other authors report no conflicts.",,Circulation Research,,"Big Data; Humans; Hypertension, Pulmonary; Machine Learning; Precision Medicine",2022-04-28,2022,2022-04-28,2022-04-29,130,9,1423-1444,Closed,Article,"Rhodes, Christopher J; Sweatt, Andrew J; Maron, Bradley A","Rhodes, Christopher J (Department of Medicine, National Heart and Lung Institute, Imperial College London, United Kingdom (C.J.R.).); Sweatt, Andrew J (Department of Medicine, National Heart and Lung Institute, Imperial College London, United Kingdom (C.J.R.).); Maron, Bradley A (Division of Cardiovascular Medicine, Department of Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, MA (B.A.M.).; Division of Cardiology, VA Boston Healthcare System, West Roxbury, MA (B.A.M.).)",,"Rhodes, Christopher J (); Sweatt, Andrew J (); Maron, Bradley A (Brigham and Women's Hospital; Harvard University)",5,5,,,,https://app.dimensions.ai/details/publication/pub.1147388741,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,,,,,
6479,pub.1147316264,10.1038/s41598-022-10464-w,35459270,PMC9033783,Introduction of Lazy Luna an automatic software-driven multilevel comparison of ventricular function quantification in cardiovascular magnetic resonance imaging,Cardiovascular magnetic resonance imaging is the gold standard for cardiac function assessment. Quantification of clinical results (CR) requires precise segmentation. Clinicians statistically compare CRs to ensure reproducibility. Convolutional Neural Network developers compare their results via metrics. Aim: Introducing software capable of automatic multilevel comparison. A multilevel analysis covering segmentations and CRs builds on a generic software backend. Metrics and CRs are calculated with geometric accuracy. Segmentations and CRs are connected to track errors and their effects. An interactive GUI makes the software accessible to different users. The software’s multilevel comparison was tested on a use case based on cardiac function assessment. The software shows good reader agreement in CRs and segmentation metrics (Dice > 90%). Decomposing differences by cardiac position revealed excellent agreement in midventricular slices: > 90% but poorer segmentations in apical (> 71%) and basal slices (> 74%). Further decomposition by contour type locates the largest millilitre differences in the basal right cavity (> 3 ml). Visual inspection shows these differences being caused by different basal slice choices. The software illuminated reader differences on several levels. Producing spreadsheets and figures concerning metric values and CR differences was automated. A multilevel reader comparison is feasible and extendable to other cardiac structures in the future.,"We wish to thank the members of the WG CMR for input at different steps. TH receives funding from the German Research Foundation (GRK2260, BIOQIC). At time of the software’s conception TH was a Master’s student employee at Siemens Healthineers, Erlangen Germany.",Open Access funding enabled and organized by Projekt DEAL.,Scientific Reports,,"Magnetic Resonance Imaging; Neural Networks, Computer; Reproducibility of Results; Software; Ventricular Function",2022-04-22,2022,2022-04-22,,12,1,6629,All OA, Gold,Article,"Hadler, Thomas; Wetzl, Jens; Lange, Steffen; Geppert, Christian; Fenski, Max; Abazi, Endri; Gröschel, Jan; Ammann, Clemens; Wenson, Felix; Töpper, Agnieszka; Däuber, Sascha; Schulz-Menger, Jeanette","Hadler, Thomas (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-Delbrück-Center for Molecular Medicine in the Helmholtz Association and the Charité - Universitätsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany); Wetzl, Jens (Siemens Healthineers, Erlangen, Germany); Lange, Steffen (Department of Computer Sciences, Hochschule Darmstadt - University of Applied Sciences, Darmstadt, Germany); Geppert, Christian (Siemens Healthineers, Erlangen, Germany); Fenski, Max (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-Delbrück-Center for Molecular Medicine in the Helmholtz Association and the Charité - Universitätsmedizin Berlin, Berlin, Germany); Abazi, Endri (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-Delbrück-Center for Molecular Medicine in the Helmholtz Association and the Charité - Universitätsmedizin Berlin, Berlin, Germany); Gröschel, Jan (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-Delbrück-Center for Molecular Medicine in the Helmholtz Association and the Charité - Universitätsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany); Ammann, Clemens (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany); Wenson, Felix (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-Delbrück-Center for Molecular Medicine in the Helmholtz Association and the Charité - Universitätsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany); Töpper, Agnieszka (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-Delbrück-Center for Molecular Medicine in the Helmholtz Association and the Charité - Universitätsmedizin Berlin, Berlin, Germany; Department of Internal Medicine III, Cardiology, Lutherstadt Wittenberg, Evangelisches Krankenhaus Paul Gerhardt Stift, Wittenberg, Germany); Däuber, Sascha (Siemens Healthineers, Erlangen, Germany); Schulz-Menger, Jeanette (Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-Delbrück-Center for Molecular Medicine in the Helmholtz Association and the Charité - Universitätsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany; Department of Cardiology and Nephrology, HELIOS Hospital Berlin-Buch, Berlin, Germany)","Schulz-Menger, Jeanette (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine; German Centre for Cardiovascular Research; Helios Hospital Berlin-Buch)","Hadler, Thomas (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine; German Centre for Cardiovascular Research); Wetzl, Jens (Siemens Healthcare (Germany)); Lange, Steffen (Darmstadt University of Applied Sciences); Geppert, Christian (Siemens Healthcare (Germany)); Fenski, Max (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine); Abazi, Endri (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine); Gröschel, Jan (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine; German Centre for Cardiovascular Research); Ammann, Clemens (Charité - University Medicine Berlin); Wenson, Felix (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine; German Centre for Cardiovascular Research); Töpper, Agnieszka (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine); Däuber, Sascha (Siemens Healthcare (Germany)); Schulz-Menger, Jeanette (Charité - University Medicine Berlin; Max Delbrück Center for Molecular Medicine; German Centre for Cardiovascular Research; Helios Hospital Berlin-Buch)",1,1,,,https://www.nature.com/articles/s41598-022-10464-w.pdf,https://app.dimensions.ai/details/publication/pub.1147316264,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 4612 Software Engineering,,,,,,,,
3956,pub.1145725948,10.2196/28114,35451980,PMC9077503,Understanding the Research Landscape of Deep Learning in Biomedical Science: Scientometric Analysis,"BACKGROUND: Advances in biomedical research using deep learning techniques have generated a large volume of related literature. However, there is a lack of scientometric studies that provide a bird's-eye view of them. This absence has led to a partial and fragmented understanding of the field and its progress.
OBJECTIVE: This study aimed to gain a quantitative and qualitative understanding of the scientific domain by analyzing diverse bibliographic entities that represent the research landscape from multiple perspectives and levels of granularity.
METHODS: We searched and retrieved 978 deep learning studies in biomedicine from the PubMed database. A scientometric analysis was performed by analyzing the metadata, content of influential works, and cited references.
RESULTS: In the process, we identified the current leading fields, major research topics and techniques, knowledge diffusion, and research collaboration. There was a predominant focus on applying deep learning, especially convolutional neural networks, to radiology and medical imaging, whereas a few studies focused on protein or genome analysis. Radiology and medical imaging also appeared to be the most significant knowledge sources and an important field in knowledge diffusion, followed by computer science and electrical engineering. A coauthorship analysis revealed various collaborations among engineering-oriented and biomedicine-oriented clusters of disciplines.
CONCLUSIONS: This study investigated the landscape of deep learning research in biomedicine and confirmed its interdisciplinary nature. Although it has been successful, we believe that there is a need for diverse applications in certain areas to further boost the contributions of deep learning in addressing biomedical research problems. We expect the results of this study to help researchers and communities better align their present and future work.",,,Journal of Medical Internet Research,,"Bibliometrics; Biomedical Research; Deep Learning; Humans; Metadata; Neural Networks, Computer; Publications",2022-04-22,2022,2022-04-22,,24,4,e28114,All OA, Gold,Article,"Nam, Seojin; Kim, Donghun; Jung, Woojin; Zhu, Yongjun","Nam, Seojin (Department of Library and Information Science, Sungkyunkwan University, Seoul, Republic of Korea); Kim, Donghun (Department of Library and Information Science, Sungkyunkwan University, Seoul, Republic of Korea); Jung, Woojin (Department of Library and Information Science, Sungkyunkwan University, Seoul, Republic of Korea); Zhu, Yongjun (Department of Library and Information Science, Yonsei University, Seoul, Republic of Korea)","Zhu, Yongjun (Yonsei University)","Nam, Seojin (Sungkyunkwan University); Kim, Donghun (Sungkyunkwan University); Jung, Woojin (Sungkyunkwan University); Zhu, Yongjun (Yonsei University)",1,1,,,https://www.jmir.org/2022/4/e28114/PDF,https://app.dimensions.ai/details/publication/pub.1145725948,42 Health Sciences, 4203 Health Services and Systems,,,,,,,,,,
1398,pub.1147406943,10.48550/arxiv.2204.10983,,,Federated Contrastive Learning for Volumetric Medical Image Segmentation,"Supervised deep learning needs a large amount of labeled data to achieve high
performance. However, in medical imaging analysis, each site may only have a
limited amount of data and labels, which makes learning ineffective. Federated
learning (FL) can help in this regard by learning a shared model while keeping
training data local for privacy. Traditional FL requires fully-labeled data for
training, which is inconvenient or sometimes infeasible to obtain due to high
labeling cost and the requirement of expertise. Contrastive learning (CL), as a
self-supervised learning approach, can effectively learn from unlabeled data to
pre-train a neural network encoder, followed by fine-tuning for downstream
tasks with limited annotations. However, when adopting CL in FL, the limited
data diversity on each client makes federated contrastive learning (FCL)
ineffective. In this work, we propose an FCL framework for volumetric medical
image segmentation with limited annotations. More specifically, we exchange the
features in the FCL pre-training process such that diverse contrastive data are
provided to each site for effective local CL while keeping raw data private.
Based on the exchanged features, global structural matching further leverages
the structural similarity to align local features to the remote ones such that
a unified feature space can be learned among different sites. Experiments on a
cardiac MRI dataset show the proposed framework substantially improves the
segmentation performance compared with state-of-the-art techniques.",,,arXiv,,,2022-04-22,2022,,,,,,All OA, Green,Preprint,"Wu, Yawen; Zeng, Dewen; Wang, Zhepeng; Shi, Yiyu; Hu, Jingtong","Wu, Yawen (); Zeng, Dewen (); Wang, Zhepeng (); Shi, Yiyu (); Hu, Jingtong ()",,"Wu, Yawen (); Zeng, Dewen (); Wang, Zhepeng (); Shi, Yiyu (); Hu, Jingtong ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147406943,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1067,pub.1147287923,10.1007/978-3-030-92087-6_33,,,Artificial Intelligence-Based Evaluation of Functional Cardiac Magnetic Resonance Imaging,"Cardiac magnetic resonance (CMR) is the current gold standard imaging modality for evaluation of cardiac function in clinical practice and scientific research. Its quantitative evaluation, however, is time-consuming and labor-intensive for human observers. Over the last three decades, there has been active development in the medical image analysis society to design artificial intelligence (AI) methods for automated analysis of functional CMR. In this article, we review existing AI methods for three basic tasks, namely, cardiac segmentation, cardiac motion tracking, and functional parameter estimation. Instead of only focusing on the latest advancements in deep learning, we review a broader range of AI methods developed in the past decades, categorized into (1) image-based methods that only utilize information from a given image, (2) model-based methods that integrate a priori information from a limited annotated dataset, and (3) data-based methods that learn from massive annotated dataset. The evolution of AI methods demonstrates an increasing trend of information integration and underlies the consistently improving performance. Finally, we discuss the current limitations and future directions of AI research for functional CMR. AI plays an increasingly important role in CMR analysis, while future research should be devoted to make AI more explainable, accountable, and controllable, for it to be reliably used in clinical practice.",,,Contemporary Medical Imaging,Artificial Intelligence in Cardiothoracic Imaging,,2022-04-22,2022,2022-04-22,2022,,,321-331,Closed,Chapter,"Tao, Qian; van der Geest, Rob J.","Tao, Qian (Department of Imaging Physics, Delft University of Technology, Delft, The Netherlands; Department of Radiology, Leiden University Medical Center, Leiden, The Netherlands); van der Geest, Rob J. (Department of Radiology, Leiden University Medical Center, Leiden, The Netherlands)","Tao, Qian (Delft University of Technology; Leiden University Medical Center)","Tao, Qian (Delft University of Technology; Leiden University Medical Center); van der Geest, Rob J. (Leiden University Medical Center)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147287923,46 Information and Computing Sciences, 4608 Human-Centred Computing,,,,,,,,,,,
6255,pub.1147265611,10.1155/2022/1368878,35539443,PMC9046000,Artificial Intelligence Enabled Fully Automated CMR Function Quantification for Optimized Risk Stratification in Patients Undergoing Transcatheter Aortic Valve Replacement,"Background: Cardiovascular magnetic resonance imaging is considered the reference standard for assessing cardiac morphology and function and has demonstrated prognostic utility in patients undergoing transcatheter aortic valve replacement (TAVR). Novel fully automated analyses may facilitate data analyses but have not yet been compared against conventional manual data acquisition in patients with severe aortic stenosis (AS).
Methods: Fully automated and manual biventricular assessments were performed in 139 AS patients scheduled for TAVR using commercially available software (suiteHEART®, Neosoft; QMass®, Medis Medical Imaging Systems). Volumetric assessment included left ventricular (LV) mass, LV/right ventricular (RV) end-diastolic/end-systolic volume, LV/RV stroke volume, and LV/RV ejection fraction (EF). Results of fully automated and manual analyses were compared. Regression analyses and receiver operator characteristics including area under the curve (AUC) calculation for prediction of the primary study endpoint cardiovascular (CV) death were performed.
Results: Fully automated and manual assessment of LVEF revealed similar prediction of CV mortality in univariable (manual: hazard ratio (HR) 0.970 (95% CI 0.943-0.997) p=0.032; automated: HR 0.967 (95% CI 0.939-0.995) p=0.022) and multivariable analyses (model 1: (including significant univariable parameters) manual: HR 0.968 (95% CI 0.938-0.999) p=0.043; automated: HR 0.963 [95% CI 0.933-0.995] p=0.024; model 2: (including CV risk factors) manual: HR 0.962 (95% CI 0.920-0.996) p=0.027; automated: HR 0.954 (95% CI 0.920-0.989) p=0.011). There were no differences in AUC (LVEF fully automated: 0.686; manual: 0.661; p=0.21). Absolute values of LV volumes differed significantly between automated and manual approaches (p < 0.001 for all). Fully automated quantification resulted in a time saving of 10 minutes per patient.
Conclusion: Fully automated biventricular volumetric assessments enable efficient and equal risk prediction compared to conventional manual approaches. In addition to significant time saving, this may provide the tools for optimized clinical management and stratification of patients with severe AS undergoing TAVR.",,,Journal of Interventional Cardiology,,"Aortic Valve; Aortic Valve Stenosis; Artificial Intelligence; Humans; Risk Assessment; Stroke Volume; Transcatheter Aortic Valve Replacement; Ventricular Function, Left",2022-04-20,2022,2022-04-20,2022-04-20,2022,,1368878,All OA, Gold,Article,"Evertz, Ruben; Lange, Torben; Backhaus, Sören J.; Schulz, Alexander; Beuthner, Bo Eric; Topci, Rodi; Toischer, Karl; Puls, Miriam; Kowallick, Johannes T.; Hasenfuß, Gerd; Schuster, Andreas","Evertz, Ruben (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Lange, Torben (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Backhaus, Sören J. (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Schulz, Alexander (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Beuthner, Bo Eric (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Topci, Rodi (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Toischer, Karl (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Puls, Miriam (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Kowallick, Johannes T. (German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de; University Medical Center Göttingen (UMG), Department of Diagnostic & Interventional Radiology, Göttingen, Germany, uni-goettingen.de); Hasenfuß, Gerd (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de); Schuster, Andreas (University Medical Center Göttingen (UMG), Department of Cardiology and Pneumology, Göttingen, Germany, uni-goettingen.de; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany, dzhk.de)","Schuster, Andreas (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research)","Evertz, Ruben (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Lange, Torben (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Backhaus, Sören J. (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Schulz, Alexander (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Beuthner, Bo Eric (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Topci, Rodi (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Toischer, Karl (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Puls, Miriam (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Kowallick, Johannes T. (German Centre for Cardiovascular Research; Universitätsmedizin Göttingen); Hasenfuß, Gerd (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Schuster, Andreas (Universitätsmedizin Göttingen; German Centre for Cardiovascular Research)",0,0,,,https://downloads.hindawi.com/journals/jitc/2022/1368878.pdf,https://app.dimensions.ai/details/publication/pub.1147265611,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
1173,pub.1147215379,10.1049/ipr2.12503,,,A dense R‐CNN multi‐target instance segmentation model and its application in medical image processing,"In the medical image analysis domain, medical image segmentation has a significant impact on the quantitative analysis of organ or tissue function, as the first and critical component of diagnosis and treatment pipeline. In this paper, a dense R‐CNN segmentation model based on dual‐attention are proposed for medical images multi‐target instance segmentation. The model combines channel and spatial attention mechanism to extract image features and fuse multi‐scale feature information hierarchically. It combines up‐sampling strategies such as dilated convolution and bilinear interpolation to strengthen the distinguishability between multi‐target instances and pixel‐level features in other regions. The multi‐target detection mechanism of R‐CNN is combined with the multi‐scale feature extraction and fusion ability of dense convolution network. In the encoding stage, the multi‐scale hybrid bottleneck module and deformable convolution are introduced to extract more accurate structural feature information and increase the receptive‐field. In the decoding stage, the bilinear interpolation and the adaptive hierarchical fusion mechanism are used to strengthen the distinguishability between the target region and other regions, and improve the accuracy of instance segmentation. Taking cardiac MRI segmentation as an example, the left and right ventricles, and left ventricular myocardium are selected as segmentation targets. The pixel accuracy is 90.82%, the class pixel accuracy is 87.91%, the mean intersection‐over‐union is 81.52%, the Dice coefficient is 89.82%, and Hausdorff distance is 9.2, which is improved compared with other methods. It verifies the accuracy and applicability of the proposed method for multi‐target instance segmentation of medical images.",This research was funded by the SDUST Research Fund under grant No. 2019TDJH102.,,IET Image Processing,,,2022-04-19,2022,2022-04-19,2022-07,16,9,2495-2505,Closed,Article,"Yang, Ruiping; Yu, Jiguo; Yin, Jian; Liu, Kun; Xu, Shaohua","Yang, Ruiping (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, 266590, P. R. China); Yu, Jiguo (Big Data Institute, Qilu University of Technology, Jinan, 250353, P. R. China; Shandong Laboratory of Computer Networks, Jinan, 250014, P. R. China); Yin, Jian (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, 266590, P. R. China); Liu, Kun (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, 266590, P. R. China); Xu, Shaohua (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, 266590, P. R. China)","Liu, Kun (Shandong University of Science and Technology)","Yang, Ruiping (Shandong University of Science and Technology); Yu, Jiguo (Qilu University of Technology); Yin, Jian (Shandong University of Science and Technology); Liu, Kun (Shandong University of Science and Technology); Xu, Shaohua (Shandong University of Science and Technology)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1147215379,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
4788,pub.1147055889,10.1016/j.media.2022.102445,35468554,,Rapid inference of personalised left-ventricular meshes by deformation-based differentiable mesh voxelization,"We propose a differentiable volumetric mesh voxelization technique based on deformation of a shape-model, and demonstrate that it can be used to predict left-ventricular anatomies directly from magnetic resonance image slice data. The predicted anatomies are volumetric meshes suitable for direct inclusion in biophysical simulations. The proposed method can leverage existing (pixel-based) segmentation networks, and does not require any ground truth paired image and mesh training data. We demonstrate that this approach produces accurate predictions from few slices, and can combine information from images acquired in different views (e.g. fusing shape information from short axis and long axis slices). We demonstrate that the proposed method is several times faster than a state-of-the-art registration based method. Additionally, we show that our method can correct for slice misalignment, and is robust to incomplete and inaccurate input data. We further demonstrate that by fitting a mesh to every frame of 4D data we can determine ejection fraction, stroke volume and strain.","The authors acknowledge the financial support of the PHRT SWISSHEART Failure Network, Swiss National Science Foundation (SNF) grant PZ00P2 174144, and Swiss National Science Foundation (SNF) grant 325230_197702.",,Medical Image Analysis,,"Heart Ventricles; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Stroke Volume; Surgical Mesh",2022-04-12,2022,2022-04-12,2022-07,79,,102445,All OA, Hybrid,Article,"Joyce, Thomas; Buoso, Stefano; Stoeck, Christian T; Kozerke, Sebastian","Joyce, Thomas (Institute for Biomedical Engineering, ETH Zurich and University Zurich, Zurich, Switzerland. Electronic address: joyce@biomed.ee.ethz.ch.); Buoso, Stefano (Institute for Biomedical Engineering, ETH Zurich and University Zurich, Zurich, Switzerland.); Stoeck, Christian T (Institute for Biomedical Engineering, ETH Zurich and University Zurich, Zurich, Switzerland.); Kozerke, Sebastian (Institute for Biomedical Engineering, ETH Zurich and University Zurich, Zurich, Switzerland.)","Joyce, Thomas (Institute for Biomedical Engineering)","Joyce, Thomas (Institute for Biomedical Engineering); Buoso, Stefano (Institute for Biomedical Engineering); Stoeck, Christian T (Institute for Biomedical Engineering); Kozerke, Sebastian (Institute for Biomedical Engineering)",1,1,,,https://doi.org/10.1016/j.media.2022.102445,https://app.dimensions.ai/details/publication/pub.1147055889,40 Engineering,,,,,,,,,,,
6084,pub.1146969364,10.3389/fcvm.2022.831080,35479280,PMC9035693,DeepStrain Evidence of Asymptomatic Left Ventricular Diastolic and Systolic Dysfunction in Young Adults With Cardiac Risk Factors,"Purpose: To evaluate if a fully-automatic deep learning method for myocardial strain analysis based on magnetic resonance imaging (MRI) cine images can detect asymptomatic dysfunction in young adults with cardiac risk factors.
Methods: An automated workflow termed DeepStrain was implemented using two U-Net models for segmentation and motion tracking. DeepStrain was trained and tested using short-axis cine-MRI images from healthy subjects and patients with cardiac disease. Subsequently, subjects aged 18-45 years were prospectively recruited and classified among age- and gender-matched groups: risk factor group (RFG) 1 including overweight without hypertension or type 2 diabetes; RFG2 including hypertension without type 2 diabetes, regardless of overweight; RFG3 including type 2 diabetes, regardless of overweight or hypertension. Subjects underwent cardiac short-axis cine-MRI image acquisition. Differences in DeepStrain-based left ventricular global circumferential and radial strain and strain rate among groups were evaluated.
Results: The cohort consisted of 119 participants: 30 controls, 39 in RFG1, 30 in RFG2, and 20 in RFG3. Despite comparable (>0.05) left-ventricular mass, volumes, and ejection fraction, all groups (RFG1, RFG2, RFG3) showed signs of asymptomatic left ventricular diastolic and systolic dysfunction, evidenced by lower circumferential early-diastolic strain rate (<0.05, <0.001, <0.01), and lower septal circumferential end-systolic strain (<0.001, <0.05, <0.001) compared with controls. Multivariate linear regression showed that body surface area correlated negatively with all strain measures (<0.01), and mean arterial pressure correlated negatively with early-diastolic strain rate (<0.01).
Conclusion: DeepStrain fully-automatically provided evidence of asymptomatic left ventricular diastolic and systolic dysfunction in asymptomatic young adults with overweight, hypertension, and type 2 diabetes risk factors.",We acknowledge the support of NVIDIA Corporation with the donation of the Titan X Pascal GPU used for this research.,This work was supported by the Dutch Heart Association (2016T042) and in part by the U.S. National Cancer Institute under Grant 1R01CA218187-01A1.,Frontiers in Cardiovascular Medicine,,,2022-04-11,2022,2022-04-11,,9,,831080,All OA, Gold,Article,"Morales, Manuel A.; Snel, Gert J. H.; van den Boomen, Maaike; Borra, Ronald J. H.; van Deursen, Vincent M.; Slart, Riemer H. J. A.; Izquierdo-Garcia, David; Prakken, Niek H. J.; Catana, Ciprian","Morales, Manuel A. (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA, United States); Snel, Gert J. H. (Department of Radiology, Medical Imaging Center, University Medical Center Groningen, University of Groningen, Groningen, Netherlands); van den Boomen, Maaike (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Department of Radiology, Medical Imaging Center, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Cardiovascular Research Center, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States); Borra, Ronald J. H. (Department of Radiology, Medical Imaging Center, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Department of Nuclear Medicine and Molecular Imaging, Medical Imaging Center, University Medical Center Groningen, University of Groningen, Groningen, Netherlands); van Deursen, Vincent M. (Department of Cardiology, University Medical Center Groningen, University of Groningen, Groningen, Netherlands); Slart, Riemer H. J. A. (Department of Nuclear Medicine and Molecular Imaging, Medical Imaging Center, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Department of Biomedical Photonic Imaging, Faculty of Science and Technology, University of Twente, Enschede, Netherlands); Izquierdo-Garcia, David (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA, United States); Prakken, Niek H. J. (Department of Radiology, Medical Imaging Center, University Medical Center Groningen, University of Groningen, Groningen, Netherlands); Catana, Ciprian (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States)","Morales, Manuel A. (Massachusetts General Hospital; Harvard University; Harvard–MIT Division of Health Sciences and Technology); Catana, Ciprian (Massachusetts General Hospital; Harvard University)","Morales, Manuel A. (Massachusetts General Hospital; Harvard University; Harvard–MIT Division of Health Sciences and Technology); Snel, Gert J. H. (University of Groningen; University Medical Center Groningen); van den Boomen, Maaike (Massachusetts General Hospital; Harvard University; University of Groningen; University Medical Center Groningen; Massachusetts General Hospital; Harvard University); Borra, Ronald J. H. (University of Groningen; University Medical Center Groningen; University of Groningen; University Medical Center Groningen); van Deursen, Vincent M. (University of Groningen; University Medical Center Groningen); Slart, Riemer H. J. A. (University of Groningen; University Medical Center Groningen; University of Twente); Izquierdo-Garcia, David (Massachusetts General Hospital; Harvard University; Harvard–MIT Division of Health Sciences and Technology); Prakken, Niek H. J. (University of Groningen; University Medical Center Groningen); Catana, Ciprian (Massachusetts General Hospital; Harvard University)",0,0,,,https://www.frontiersin.org/articles/10.3389/fcvm.2022.831080/pdf,https://app.dimensions.ai/details/publication/pub.1146969364,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
4154,pub.1146956010,10.1016/j.media.2022.102447,35509136,,Semi-supervised medical image segmentation via a tripled-uncertainty guided mean teacher model with contrastive learning,"Due to the difficulty in accessing a large amount of labeled data, semi-supervised learning is becoming an attractive solution in medical image segmentation. To make use of unlabeled data, current popular semi-supervised methods (e.g., temporal ensembling, mean teacher) mainly impose data-level and model-level consistency on unlabeled data. In this paper, we argue that in addition to these strategies, we could further utilize auxiliary tasks and consider task-level consistency to better excavate effective representations from unlabeled data for segmentation. Specifically, we introduce two auxiliary tasks, i.e., a foreground and background reconstruction task for capturing semantic information and a signed distance field (SDF) prediction task for imposing shape constraint, and explore the mutual promotion effect between the two auxiliary and the segmentation tasks based on mean teacher architecture. Moreover, to handle the potential bias of the teacher model caused by annotation scarcity, we develop a tripled-uncertainty guided framework to encourage the three tasks in the student model to learn more reliable knowledge from the teacher. When calculating uncertainty, we propose an uncertainty weighted integration (UWI) strategy for yielding the segmentation predictions of the teacher. In addition, following the advance of unsupervised learning in leveraging the unlabeled data, we also incorporate a contrastive learning based constraint to help the encoders extract more distinct representations to promote the medical image segmentation performance. Extensive experiments on the public 2017 ACDC dataset and the PROMISE12 dataset have demonstrated the effectiveness of our method.",This work is supported by National Natural Science Foundation of China (NSFC 62071314) and Sichuan Science and Technology Program (2021YFG0326).,,Medical Image Analysis,,"Humans; Image Processing, Computer-Assisted; Supervised Machine Learning; Uncertainty",2022-04-08,2022,2022-04-08,2022-07,79,,102447,Closed,Article,"Wang, Kaiping; Zhan, Bo; Zu, Chen; Wu, Xi; Zhou, Jiliu; Zhou, Luping; Wang, Yan","Wang, Kaiping (School of Computer Science, Sichuan University, Chengdu, China.); Zhan, Bo (School of Computer Science, Sichuan University, Chengdu, China.); Zu, Chen (Department of Risk Controlling Research, JD.COM, China.); Wu, Xi (School of Computer Science, Chengdu University of Information Technology, China.); Zhou, Jiliu (School of Computer Science, Sichuan University, Chengdu, China; School of Computer Science, Chengdu University of Information Technology, China.); Zhou, Luping (School of Electrical and Information Engineering, University of Sydney, Australia.); Wang, Yan (School of Computer Science, Sichuan University, Chengdu, China. Electronic address: wangyanscu@hotmail.com.)","Wang, Yan (Sichuan University)","Wang, Kaiping (Sichuan University); Zhan, Bo (Sichuan University); Zu, Chen (Jingdong (China)); Wu, Xi (Chengdu University of Information Technology); Zhou, Jiliu (Sichuan University; Chengdu University of Information Technology); Zhou, Luping (The University of Sydney); Wang, Yan (Sichuan University)",14,14,,,,https://app.dimensions.ai/details/publication/pub.1146956010,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
5686,pub.1146920481,10.1186/s12968-022-00855-3,35387651,PMC8988415,Training and clinical testing of artificial intelligence derived right atrial cardiovascular magnetic resonance measurements,"BackgroundRight atrial (RA) area predicts mortality in patients with pulmonary hypertension, and is recommended by the European Society of Cardiology/European Respiratory Society pulmonary hypertension guidelines. The advent of deep learning may allow more reliable measurement of RA areas to improve clinical assessments. The aim of this study was to automate cardiovascular magnetic resonance (CMR) RA area measurements and evaluate the clinical utility by assessing repeatability, correlation with invasive haemodynamics and prognostic value.MethodsA deep learning RA area CMR contouring model was trained in a multicentre cohort of 365 patients with pulmonary hypertension, left ventricular pathology and healthy subjects. Inter-study repeatability (intraclass correlation coefficient (ICC)) and agreement of contours (DICE similarity coefficient (DSC)) were assessed in a prospective cohort (n = 36). Clinical testing and mortality prediction was performed in n = 400 patients that were not used in the training nor prospective cohort, and the correlation of automatic and manual RA measurements with invasive haemodynamics assessed in n = 212/400. Radiologist quality control (QC) was performed in the ASPIRE registry, n = 3795 patients. The primary QC observer evaluated all the segmentations and recorded them as satisfactory, suboptimal or failure. A second QC observer analysed a random subcohort to assess QC agreement (n = 1018).ResultsAll deep learning RA measurements showed higher interstudy repeatability (ICC 0.91 to 0.95) compared to manual RA measurements (1st observer ICC 0.82 to 0.88, 2nd observer ICC 0.88 to 0.91). DSC showed high agreement comparing automatic artificial intelligence and manual CMR readers. Maximal RA area mean and standard deviation (SD) DSC metric for observer 1 vs observer 2, automatic measurements vs observer 1 and automatic measurements vs observer 2 is 92.4 ± 3.5 cm2, 91.2 ± 4.5 cm2 and 93.2 ± 3.2 cm2, respectively. Minimal RA area mean and SD DSC metric for observer 1 vs observer 2, automatic measurements vs observer 1 and automatic measurements vs observer 2 was 89.8 ± 3.9 cm2, 87.0 ± 5.8 cm2 and 91.8 ± 4.8 cm2. Automatic RA area measurements all showed moderate correlation with invasive parameters (r = 0.45 to 0.66), manual (r = 0.36 to 0.57). Maximal RA area could accurately predict elevated mean RA pressure low and high-risk thresholds (area under the receiver operating characteristic curve artificial intelligence = 0.82/0.87 vs manual = 0.78/0.83), and predicted mortality similar to manual measurements, both p < 0.01. In the QC evaluation, artificial intelligence segmentations were suboptimal at 108/3795 and a low failure rate of 16/3795. In a subcohort (n = 1018), agreement by two QC observers was excellent, kappa 0.84.ConclusionAutomatic artificial intelligence CMR derived RA size and function are accurate, have excellent repeatability, moderate associations with invasive haemodynamics and predict mortality.",Not applicable.,"Andrew Swift is supported by a Wellcome Trust fellowship grant 205188/Z/16/Z. This work was supported by an NIHR AI Award, AI_AWARD01706.",Journal of Cardiovascular Magnetic Resonance,,"Artificial Intelligence; Heart Ventricles; Humans; Hypertension, Pulmonary; Magnetic Resonance Spectroscopy; Predictive Value of Tests; Prospective Studies; Reproducibility of Results",2022-04-07,2022,2022-04-07,2022-12,24,1,25,All OA, Gold,Article,"Alandejani, Faisal; Alabed, Samer; Garg, Pankaj; Goh, Ze Ming; Karunasaagarar, Kavita; Sharkey, Michael; Salehi, Mahan; Aldabbagh, Ziad; Dwivedi, Krit; Mamalakis, Michail; Metherall, Pete; Uthoff, Johanna; Johns, Chris; Rothman, Alexander; Condliffe, Robin; Hameed, Abdul; Charalampoplous, Athanasios; Lu, Haiping; Plein, Sven; Greenwood, John P.; Lawrie, Allan; Wild, Jim M.; de Koning, Patrick J. H.; Kiely, David G.; Van Der Geest, Rob; Swift, Andrew J.","Alandejani, Faisal (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Alabed, Samer (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK; INSIGNEO, Institute for In Silico Medicine, University of Sheffield, Sheffield, UK); Garg, Pankaj (Norwich Medical School, University of East Anglia, Norwich, UK); Goh, Ze Ming (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Karunasaagarar, Kavita (Radiology Department, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Sharkey, Michael (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK; Radiology Department, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Salehi, Mahan (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Aldabbagh, Ziad (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Dwivedi, Krit (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Mamalakis, Michail (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Metherall, Pete (Radiology Department, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Uthoff, Johanna (Department of Computer Science, University of Sheffield, Sheffield, UK); Johns, Chris (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Rothman, Alexander (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK; INSIGNEO, Institute for In Silico Medicine, University of Sheffield, Sheffield, UK; Sheffield Pulmonary Vascular Disease Unit, Royal Hallamshire Hospital, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Condliffe, Robin (Sheffield Pulmonary Vascular Disease Unit, Royal Hallamshire Hospital, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Hameed, Abdul (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK; Sheffield Pulmonary Vascular Disease Unit, Royal Hallamshire Hospital, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Charalampoplous, Athanasios (Sheffield Pulmonary Vascular Disease Unit, Royal Hallamshire Hospital, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Lu, Haiping (INSIGNEO, Institute for In Silico Medicine, University of Sheffield, Sheffield, UK; Department of Computer Science, University of Sheffield, Sheffield, UK); Plein, Sven (Multidisciplinary Cardiovascular Research Centre (MCRC) &, Biomedical Imaging Science Department, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Clarendon Way, Leeds, UK); Greenwood, John P. (Multidisciplinary Cardiovascular Research Centre (MCRC) &, Biomedical Imaging Science Department, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Clarendon Way, Leeds, UK); Lawrie, Allan (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK); Wild, Jim M. (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK; INSIGNEO, Institute for In Silico Medicine, University of Sheffield, Sheffield, UK); de Koning, Patrick J. H. (Division of Image Processing, Department of Radiology, Leiden University Medical Center, Leiden, Netherlands); Kiely, David G. (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK; INSIGNEO, Institute for In Silico Medicine, University of Sheffield, Sheffield, UK; Sheffield Pulmonary Vascular Disease Unit, Royal Hallamshire Hospital, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, UK); Van Der Geest, Rob (Division of Image Processing, Department of Radiology, Leiden University Medical Center, Leiden, Netherlands); Swift, Andrew J. (Department of Infection, Immunity and Cardiovascular Disease, University of Sheffield, Sheffield, UK; INSIGNEO, Institute for In Silico Medicine, University of Sheffield, Sheffield, UK)","Swift, Andrew J. (University of Sheffield; University of Sheffield)","Alandejani, Faisal (University of Sheffield); Alabed, Samer (University of Sheffield; University of Sheffield); Garg, Pankaj (University of East Anglia); Goh, Ze Ming (University of Sheffield); Karunasaagarar, Kavita (Sheffield Teaching Hospitals NHS Foundation Trust); Sharkey, Michael (University of Sheffield; Sheffield Teaching Hospitals NHS Foundation Trust); Salehi, Mahan (University of Sheffield); Aldabbagh, Ziad (University of Sheffield); Dwivedi, Krit (University of Sheffield); Mamalakis, Michail (University of Sheffield); Metherall, Pete (Sheffield Teaching Hospitals NHS Foundation Trust); Uthoff, Johanna (University of Sheffield); Johns, Chris (University of Sheffield); Rothman, Alexander (University of Sheffield; University of Sheffield; Royal Hallamshire Hospital); Condliffe, Robin (Royal Hallamshire Hospital); Hameed, Abdul (University of Sheffield; Royal Hallamshire Hospital); Charalampoplous, Athanasios (Royal Hallamshire Hospital); Lu, Haiping (University of Sheffield; University of Sheffield); Plein, Sven (University of Leeds); Greenwood, John P. (University of Leeds); Lawrie, Allan (University of Sheffield); Wild, Jim M. (University of Sheffield; University of Sheffield); de Koning, Patrick J. H. (Leiden University Medical Center); Kiely, David G. (University of Sheffield; University of Sheffield; Royal Hallamshire Hospital); Van Der Geest, Rob (Leiden University Medical Center); Swift, Andrew J. (University of Sheffield; University of Sheffield)",5,5,,,https://jcmr-online.biomedcentral.com/counter/pdf/10.1186/s12968-022-00855-3,https://app.dimensions.ai/details/publication/pub.1146920481,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
5351,pub.1146941580,10.3389/fcvm.2022.859310,35463778,PMC9021445,Fairness in Cardiac Magnetic Resonance Imaging: Assessing Sex and Racial Bias in Deep Learning-Based Segmentation,"Background: Artificial intelligence (AI) techniques have been proposed for automation of cine CMR segmentation for functional quantification. However, in other applications AI models have been shown to have potential for sex and/or racial bias. The objective of this paper is to perform the first analysis of sex/racial bias in AI-based cine CMR segmentation using a large-scale database.
Methods: A state-of-the-art deep learning (DL) model was used for automatic segmentation of both ventricles and the myocardium from cine short-axis CMR. The dataset consisted of end-diastole and end-systole short-axis cine CMR images of 5,903 subjects from the UK Biobank database (61.5 ± 7.1 years, 52% male, 81% white). To assess sex and racial bias, we compared Dice scores and errors in measurements of biventricular volumes and function between patients grouped by race and sex. To investigate whether segmentation bias could be explained by potential confounders, a multivariate linear regression and ANCOVA were performed.
Results: Results on the overall population showed an excellent agreement between the manual and automatic segmentations. We found statistically significant differences in Dice scores between races (white ∼94% vs. minority ethnic groups 86-89%) as well as in absolute/relative errors in volumetric and functional measures, showing that the AI model was biased against minority racial groups, even after correction for possible confounders. The results of a multivariate linear regression analysis showed that no covariate could explain the Dice score bias between racial groups. However, for the Mixed and Black race groups, sex showed a weak positive association with the Dice score. The results of an ANCOVA analysis showed that race was the main factor that can explain the overall difference in Dice scores between racial groups.
Conclusion: We have shown that racial bias can exist in DL-based cine CMR segmentation models when training with a database that is sex-balanced but not race-balanced such as the UK Biobank.","This research has been conducted using the UK Biobank Resource (application numbers 17,806 and 2,964) on a GPU generously donated by NVIDIA Corporation. The UK Biobank data are available for approved projects from https://www.ukbiobank.ac.uk/.","EP-A and AK were supported by the EPSRC (EP/R005516/1) and by core funding from the Wellcome/EPSRC Centre for Medical Engineering (WT203148/Z/16/Z). This research was funded in whole, or in part, by the Wellcome Trust WT203148/Z/16/Z. For the purpose of open access, the author has applied a CC BY public copyright license to any author accepted manuscript version arising from this submission. SEP, AK, and RR acknowledge funding from the EPSRC through the Smart Heart Programme grant (EP/P001009/1). EP-A, BR, JM, AK, and RR acknowledged support from the Wellcome/EPSRC Centre for Medical Engineering at King’s College London (WT 203148/Z/16/Z), the NIHR Cardiovascular MedTech Co-operative award to the Guy’s and St Thomas’ NHS Foundation Trust and the Department of Health National Institute for Health Research (NIHR) comprehensive Biomedical Research Centre award to Guy’s & St Thomas’ NHS Foundation Trust in partnership with King’s College London. SEP, SN, and SKP acknowledged the British Heart Foundation for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5,000 CMR scans (www.bhf.org.uk; PG/14/89/31194). SEP acknowledged support from the National Institute for Health Research (NIHR) Biomedical Research Centre at Barts. SEP has received funding from the European Union’s Horizon 2020 Research and Innovation Programme under grant agreement No 825903 (euCanSHare project). SEP also acknowledged support from the CAP-AI Programme, London’s First AI Enabling Programme focused on stimulating growth in the capital’s AI Sector. CAP-AI was led by Capital Enterprise in partnership with Barts Health NHS Trust and Digital Catapult and was funded by the European Regional Development Fund and Barts Charity. SEP acknowledged support from the Health Data Research UK, an initiative funded by UK Research and Innovation, Department of Health and Social Care (England) and the devolved administrations, and leading medical research charities. SN and SKP were supported by the Oxford NIHR Biomedical Research Centre and the Oxford British Heart Foundation Centre of Research Excellence.",Frontiers in Cardiovascular Medicine,,,2022-04-07,2022,2022-04-07,,9,,859310,All OA, Gold,Article,"Puyol-Antón, Esther; Ruijsink, Bram; Harana, Jorge Mariscal; Piechnik, Stefan K.; Neubauer, Stefan; Petersen, Steffen E.; Razavi, Reza; Chowienczyk, Phil; King, Andrew P.","Puyol-Antón, Esther (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom); Ruijsink, Bram (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Department of Adult and Paediatric Cardiology, Guy’s and St Thomas’ NHS Foundation Trust, London, United Kingdom; Division of Heart and Lungs, Department of Cardiology, University Medical Centre Utrecht, Utrecht, Netherlands); Harana, Jorge Mariscal (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom); Piechnik, Stefan K. (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom); Neubauer, Stefan (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom); Petersen, Steffen E. (National Institute for Health Research (NIHR) Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University London, London, United Kingdom; Barts Heart Centre, St Bartholomew’s Hospital, Barts Health NHS Trust, London, United Kingdom; Health Data Research UK, London, United Kingdom; Alan Turing Institute, London, United Kingdom); Razavi, Reza (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Department of Adult and Paediatric Cardiology, Guy’s and St Thomas’ NHS Foundation Trust, London, United Kingdom); Chowienczyk, Phil (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; British Heart Foundation Centre, King’s College London, London, United Kingdom); King, Andrew P. (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom)","Puyol-Antón, Esther (King's College London)","Puyol-Antón, Esther (King's College London); Ruijsink, Bram (King's College London; Guy's and St Thomas' NHS Foundation Trust; University Medical Center Utrecht); Harana, Jorge Mariscal (King's College London); Piechnik, Stefan K. (University of Oxford); Neubauer, Stefan (University of Oxford); Petersen, Steffen E. (Queen Mary University of London; St Bartholomew's Hospital; Health Data Research UK; The Alan Turing Institute); Razavi, Reza (King's College London; Guy's and St Thomas' NHS Foundation Trust); Chowienczyk, Phil (King's College London; King's College London); King, Andrew P. (King's College London)",9,9,,,https://www.frontiersin.org/articles/10.3389/fcvm.2022.859310/pdf,https://app.dimensions.ai/details/publication/pub.1146941580,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1649,pub.1146861087,10.1007/978-3-658-36932-3_43,,,Comparison of Evaluation Metrics for Landmark Detection in CMR Images,"Cardiac magnetic resonance (CMR) images are widely used for cardiac diagnosis and ventricular assessment. Extracting specific landmarks like the right ventricular insertion points is of importance for spatial alignment and 3D modelling. The automatic detection of such landmarks has been tackled by multiple groups using Deep Learning, but relatively little attention has been paid to the failure cases of evaluation metrics in this field. In this work, we extended the public ACDC dataset with additional labels of the right ventricular insertion points and compare different variants of a heatmap-based landmark detection pipeline. In this comparison, we demonstrate very likely pitfalls of apparently simple detection and localisation metrics which highlights the importance of a clear detection strategy and the definition of an upper-limit for localisation based metrics. Our preliminary results indicate that a combination of different metrics are necessary, as they yield different winners for method comparison. Additionally, they highlight the need of a comprehensive metric description and evaluation standardisation, especially for the error cases where no metrics could be computed or where no lower/upper boundary of a metric exists. Code and labels: https://github.com/Cardio-AI/rvip_landmark_detection",,,Informatik aktuell,Bildverarbeitung für die Medizin 2022,,2022-04-05,2022,2022-04-05,2022,,,198-203,All OA, Green,Chapter,"Koehler, Sven; Sharan, Lalith; Kuhm, Julian; Ghanaat, Arman; Gordejeva, Jelizaveta; Simon, Nike K.; Grell, Niko M.; André, Florian; Engelhardt, Sandy","Koehler, Sven (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland; DZHK (German Centre for Cardiovascular Research), partner site Heidelberg/Mannheim, Heidelberg, Deutschland); Sharan, Lalith (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland; DZHK (German Centre for Cardiovascular Research), partner site Heidelberg/Mannheim, Heidelberg, Deutschland); Kuhm, Julian (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland); Ghanaat, Arman (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland); Gordejeva, Jelizaveta (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland); Simon, Nike K. (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland); Grell, Niko M. (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland); André, Florian (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland); Engelhardt, Sandy (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Heidelberg, Deutschland; DZHK (German Centre for Cardiovascular Research), partner site Heidelberg/Mannheim, Heidelberg, Deutschland)","Koehler, Sven (University Hospital Heidelberg; )","Koehler, Sven (University Hospital Heidelberg); Sharan, Lalith (University Hospital Heidelberg); Kuhm, Julian (University Hospital Heidelberg); Ghanaat, Arman (University Hospital Heidelberg); Gordejeva, Jelizaveta (University Hospital Heidelberg); Simon, Nike K. (University Hospital Heidelberg); Grell, Niko M. (University Hospital Heidelberg); André, Florian (University Hospital Heidelberg); Engelhardt, Sandy (University Hospital Heidelberg)",2,2,,,http://arxiv.org/pdf/2201.10410,https://app.dimensions.ai/details/publication/pub.1146861087,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
8087,pub.1146815651,10.1117/12.2612269,35634478,PMC9137403,Calibration of cine MRI segmentation probability for uncertainty estimation using a multi-task cross-task learning architecture,"While deep learning has shown potential in solving a variety of medical image analysis problems including segmentation, registration, motion estimation, etc., their applications in the real-world clinical setting are still not affluent due to the lack of reliability caused by the failures of deep learning models in prediction. Furthermore, deep learning models need a large number of labeled datasets. In this work, we propose a novel method that incorporates uncertainty estimation to detect failures in the segmentation masks generated by CNNs. Our study further showcases the potential of our model to evaluate the correlation between the uncertainty and the segmentation errors for a given model. Furthermore, we introduce a multi-task cross-task learning consistency approach to enforce the correlation between the pixel-level (segmentation) and the geometric-level (distance map) tasks. Our extensive experimentation with varied quantities of labeled data in the training sets justifies the effectiveness of our model for the segmentation and uncertainty estimation of the left ventricle (LV), right ventricle (RV), and myocardium (Myo) at end-diastole (ED) and end-systole (ES) phases from cine MRI images available through the MICCAI 2017 ACDC Challenge Dataset. Our study serves as a proof-of-concept of how uncertainty measure correlates with the erroneous segmentation generated by different deep learning models, further showcasing the potential of our model to flag low-quality segmentation from a given model in our future study.",,,Proceedings of SPIE,"Medical Imaging 2022: Image-Guided Procedures, Robotic Interventions, and Modeling",,2022-04-04,2022,2022-04-04,2022,12034,,120340t-120340t-6,All OA, Green,Proceeding,"Hasan, S M Kamrul; Linte, Cristian A","Hasan, S M Kamrul (Biomedical Modeling, Visualization and Image-guided Navigation (BiMVisIGN) Lab, RIT.; Center for Imaging Science, Rochester Institute of Technology, NY, USA.); Linte, Cristian A (Biomedical Modeling, Visualization and Image-guided Navigation (BiMVisIGN) Lab, RIT.; Center for Imaging Science, Rochester Institute of Technology, NY, USA.; Biomedical Engineering, Rochester Institute of Technology, NY, USA.)",,"Hasan, S M Kamrul (Rochester Institute of Technology); Linte, Cristian A (Rochester Institute of Technology; Rochester Institute of Technology)",0,0,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9137403,https://app.dimensions.ai/details/publication/pub.1146815651,"40 Engineering; 4006 Communications Engineering; 4009 Electronics, Sensors and Digital Hardware; 51 Physical Sciences; 5102 Atomic, Molecular and Optical Physics",,,,,,,,,,,
1544,pub.1145704710,10.1117/12.2612968,,,Deep mutual GANs: representation learning from multiple experts,"Representation learning is one of the canonical objectives of most deep learning models. However, the learning of real-world clinical data is often compromised by their inherently imbalanced or long-tailed distribution wherein a few classes have significantly larger numbers of training instances than do the other classes. In this study, we investigated the representation learning of such long-tailed data distributions by the use of a deep mutual ensemble generative adversarial network. Our proposed framework consists of multiple powerful pre-trained discriminator networks that transfer knowledge to multiple individual untrained generator networks. During the training process, each generator learns to collaborate with the other generators. Additionally, each generator receives feedback from the individual discriminators in an adversarial manner. Especially, we explored the use of mutual information shared between the independent generators that makes our framework robust against misclassification of long-tailed data distributions in medical image analysis. We evaluated our proposed framework on four public datasets that represented different medical imaging modalities and imbalance ratios. Our experimental results show that our proposed framework benefits from ensemble learning and shared mutual learning, and achieves compelling results on several medical imaging benchmarks. Thus, our approach offers potential advantages over traditional deep learning in real-world applications.",,,Progress in Biomedical Optics and Imaging,"Medical Imaging 2022: Imaging Informatics for Healthcare, Research, and Applications",,2022-04-04,2022,,,12037,,120370u-120370u-7,Closed,Proceeding,"Rezaei, Mina; Näppi, Janne J.; Bischl, Bernd; Yoshida, Hiroyuki","Rezaei, Mina (Ludwig-Maximilian Univ. (Germany)); Näppi, Janne J. (Massachusetts General Hospital (United States)); Bischl, Bernd (Ludwig-Maximilian Univ. (Germany)); Yoshida, Hiroyuki (Massachusetts General Hospital (United States))",,"Rezaei, Mina (); Näppi, Janne J. (Massachusetts General Hospital); Bischl, Bernd (); Yoshida, Hiroyuki (Massachusetts General Hospital)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145704710,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
173,pub.1146506567,10.1002/9781119792673,,,Bioinformatics and Medical Applications,,,,,,,2022-04-03,2022,2022-04-15,2022-04-03,,,,Closed,Edited Book,,,,,1,1,,,,https://app.dimensions.ai/details/publication/pub.1146506567,,,,,,,,,,,,,
6069,pub.1146798038,10.1002/acm2.13597,35363415,PMC9121042,The auto segmentation for cardiac structures using a dual‐input deep learning network based on vision saliency and transformer,"PURPOSE: Accurate segmentation of cardiac structures on coronary CT angiography (CCTA) images is crucial for the morphological analysis, measurement, and functional evaluation. In this study, we achieve accurate automatic segmentation of cardiac structures on CCTA image by adopting an innovative deep learning method based on visual attention mechanism and transformer network, and its practical application value is discussed.
METHODS: We developed a dual-input deep learning network based on visual saliency and transformer (VST), which consists of self-attention mechanism for cardiac structures segmentation. Sixty patients' CCTA subjects were randomly selected as a development set, which were manual marked by an experienced technician. The proposed vision attention and transformer mode was trained on the patients CCTA images, with a manual contour-derived binary mask used as the learning-based target. We also used the deep supervision strategy by adding auxiliary losses. The loss function of our model was the sum of the Dice loss and cross-entropy loss. To quantitatively evaluate the segmentation results, we calculated the Dice similarity coefficient (DSC) and Hausdorff distance (HD). Meanwhile, we compare the volume of automatic segmentation and manual segmentation to analyze whether there is statistical difference.
RESULTS: Fivefold cross-validation was used to benchmark the segmentation method. The results showed the left ventricular myocardium (LVM, DSC = 0.87), the left ventricular (LV, DSC = 0.94), the left atrial (LA, DSC = 0.90), the right ventricular (RV, DSC = 0.92), the right atrial (RA, DSC = 0.91), and the aortic (AO, DSC = 0.96). The average DSC was 0.92, and HD was 7.2 ± 2.1 mm. In volume comparison, except LVM and LA (p < 0.05), there was no significant statistical difference in other structures. Proposed method for structural segmentation fit well with the true profile of the cardiac substructure, and the model prediction results closed to the manual annotation.
CONCLUSIONS: The adoption of the dual-input and transformer architecture based on visual saliency has high sensitivity and specificity to cardiac structures segmentation, which can obviously improve the accuracy of automatic substructure segmentation. This is of gr.",We gratefully acknowledge the valuable cooperation of Dr. Zhang Nan (Beijing Anzhen Hospital) in preparing this paper.,,Journal of Applied Clinical Medical Physics,,"Computed Tomography Angiography; Deep Learning; Heart; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Tomography, X-Ray Computed",2022-04,2022,2022-04,2022-05,23,5,e13597,All OA, Green,Article,"Wang, Jing; Wang, Shuyu; Liang, Wei; Zhang, Nan; Zhang, Yan","Wang, Jing (Department of Electric Information Engineering, Shandong Youth University Of Political Science, Jinan, China); Wang, Shuyu (Department of Electric Information Engineering, Shandong Youth University Of Political Science, Jinan, China); Liang, Wei (Department of Ecological Environment Statistics, Ecological Environment Department of Shandong, Jinan, China); Zhang, Nan (Department of Radiology, Beijing Anzhen Hospital, Capital Medical University, Beijing, China); Zhang, Yan (Department of Radiology, Shandong Mental Health Center, Shandong University, Jinan, China)","Zhang, Yan (Shandong University; Shandong Mental Health Center)","Wang, Jing (Shandong Youth University of Political Science); Wang, Shuyu (Shandong Youth University of Political Science); Liang, Wei (); Zhang, Nan (Beijing Anzhen Hospital; Capital Medical University); Zhang, Yan (Shandong University; Shandong Mental Health Center)",0,0,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9121042,https://app.dimensions.ai/details/publication/pub.1146798038,32 Biomedical and Clinical Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
1692,pub.1147404425,10.1109/isbi52829.2022.9761602,,,An Exceedingly Simple Consistency Regularization Method For Semi-Supervised Medical Image Segmentation,"The scarcity of pixel-level annotation is a prevalent problem in medical image segmentation tasks. In this paper, we introduce a novel regularization strategy involving interpolation-based mixing for semi-supervised medical image segmentation. The proposed method is a new consistency regularization strategy that encourages segmentation of interpolation of two unlabelled data to be consistent with the interpolation of segmentation maps of those data. This method represents a specific type of data-adaptive regularization paradigm which aids to minimize the overfitting of labelled data un-der high confidence values. The proposed method is advantageous over adversarial and generative models as it requires no additional computation. Upon evaluation on two publicly available MRI datasets: ACDC and MMWHS, experimental results demonstrate the superiority of the proposed method in comparison to existing semi-supervised models. Code is available at: https://github.com/hritam-98/ICT-MedSeg",,,,2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI),,2022-03-31,2022,,2022-03-31,0,,1-4,Closed,Proceeding,"Basak, Hritam; Bhattacharya, Rajarshi; Hussain, Rukhshanda; Chatterjee, Agniv","Basak, Hritam (Dept. of Electrical Engg., Jadavpur University, Kolkata, India, 700032); Bhattacharya, Rajarshi (Dept. of Electrical Engg., Jadavpur University, Kolkata, India, 700032); Hussain, Rukhshanda (Dept. of Electrical Engg., Jadavpur University, Kolkata, India, 700032); Chatterjee, Agniv (Dept. of Electrical Engg., Jadavpur University, Kolkata, India, 700032)","Basak, Hritam (Jadavpur University)","Basak, Hritam (Jadavpur University); Bhattacharya, Rajarshi (Jadavpur University); Hussain, Rukhshanda (Jadavpur University); Chatterjee, Agniv (Jadavpur University)",5,5,,,,https://app.dimensions.ai/details/publication/pub.1147404425,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,,
1212,pub.1146726181,10.48550/arxiv.2203.15177,,,Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network  for Surgical Tools Segmentation,"A common problem with segmentation of medical images using neural networks is
the difficulty to obtain a significant number of pixel-level annotated data for
training. To address this issue, we proposed a semi-supervised segmentation
network based on contrastive learning. In contrast to the previous
state-of-the-art, we introduce Min-Max Similarity (MMS), a contrastive learning
form of dual-view training by employing classifiers and projectors to build
all-negative, and positive and negative feature pairs, respectively, to
formulate the learning as solving a MMS problem. The all-negative pairs are
used to supervise the networks learning from different views and to capture
general features, and the consistency of unlabeled predictions is measured by
pixel-wise contrastive loss between positive and negative pairs. To
quantitatively and qualitatively evaluate our proposed method, we test it on
four public endoscopy surgical tool segmentation datasets and one cochlear
implant surgery dataset, which we manually annotated. Results indicate that our
proposed method consistently outperforms state-of-the-art semi-supervised and
fully supervised segmentation algorithms. And our semi-supervised segmentation
algorithm can successfully recognize unknown surgical tools and provide good
predictions. Also, our MMS approach could achieve inference speeds of about 40
frames per second (fps) and is suitable to deal with the real-time video
segmentation.",,,arXiv,,,2022-03-28,2022,,,,,,All OA, Green,Preprint,"Lou, Ange; Tawfik, Kareem; Yao, Xing; Liu, Ziteng; Noble, Jack","Lou, Ange (); Tawfik, Kareem (); Yao, Xing (); Liu, Ziteng (); Noble, Jack ()",,"Lou, Ange (); Tawfik, Kareem (); Yao, Xing (); Liu, Ziteng (); Noble, Jack ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146726181,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4808,pub.1146519833,10.1016/j.media.2022.102428,35500498,,Deep learning methods for automatic evaluation of delayed enhancement-MRI. The results of the EMIDEC challenge,"A key factor for assessing the state of the heart after myocardial infarction (MI) is to measure whether the myocardium segment is viable after reperfusion or revascularization therapy. Delayed enhancement-MRI or DE-MRI, which is performed 10 min after injection of the contrast agent, provides high contrast between viable and nonviable myocardium and is therefore a method of choice to evaluate the extent of MI. To automatically assess myocardial status, the results of the EMIDEC challenge that focused on this task are presented in this paper. The challenge's main objectives were twofold. First, to evaluate if deep learning methods can distinguish between non-infarct and pathological exams, i.e. exams with or without hyperenhanced area. Second, to automatically calculate the extent of myocardial infarction. The publicly available database consists of 150 exams divided into 50 cases without any hyperenhanced area after injection of a contrast agent and 100 cases with myocardial infarction (and then with a hyperenhanced area on DE-MRI), whatever their inclusion in the cardiac emergency department. Along with MRI, clinical characteristics are also provided. The obtained results issued from several works show that the automatic classification of an exam is a reachable task (the best method providing an accuracy of 0.92), and the automatic segmentation of the myocardium is possible. However, the segmentation of the diseased area needs to be improved, mainly due to the small size of these areas and the lack of contrast with the surrounding structures.",This work was supported by the ADVANCES project founded by ISITE-BFC project (number ANR-15-IDEX-0003) and by the french ADVANCES project founded (contract ANR-17-EURE-0002).,,Medical Image Analysis,,Contrast Media, Deep Learning, Humans, Magnetic Resonance Imaging, Myocardial Infarction, Myocardium,2022-03-24,2022,2022-03-24,2022-07,79,,102428,All OA, Green,Article,"Lalande, Alain; Chen, Zhihao; Pommier, Thibaut; Decourselle, Thomas; Qayyum, Abdul; Salomon, Michel; Ginhac, Dominique; Skandarani, Youssef; Boucher, Arnaud; Brahim, Khawla; de Bruijne, Marleen; Camarasa, Robin; Correia, Teresa M; Feng, Xue; Girum, Kibrom B; Hennemuth, Anja; Huellebrand, Markus; Hussain, Raabid; Ivantsits, Matthias; Ma, Jun; Meyer, Craig; Sharma, Rishabh; Shi, Jixi; Tsekos, Nikolaos V; Varela, Marta; Wang, Xiyue; Yang, Sen; Zhang, Hannu; Zhang, Yichi; Zhou, Yuncheng; Zhuang, Xiahai; Couturier, Raphael; Meriaudeau, Fabrice","Lalande, Alain (ImViA Laboratory, University of Burgundy, Dijon, France; MRI Department, University Hospital of Dijon, Dijon, France. Electronic address: alain.lalande@u-bourgogne.fr.); Chen, Zhihao (Femto-ST Laboratory, University of Franche-Comté, Belfort, France.); Pommier, Thibaut (Cardiology Department, University Hospital of Dijon, Dijon, France.); Decourselle, Thomas (CASIS - CArdiac Simulation & Imaging Software SAS, Quetigny, France.); Qayyum, Abdul (ImViA Laboratory, University of Burgundy, Dijon, France.); Salomon, Michel (Femto-ST Laboratory, University of Franche-Comté, Belfort, France.); Ginhac, Dominique (ImViA Laboratory, University of Burgundy, Dijon, France.); Skandarani, Youssef (ImViA Laboratory, University of Burgundy, Dijon, France.); Boucher, Arnaud (ImViA Laboratory, University of Burgundy, Dijon, France.); Brahim, Khawla (ImViA Laboratory, University of Burgundy, Dijon, France; National Engineering School of Sousse, University of Sousse, Sousse, Tunisia; LASEE laboratory, National Engineering School of Monastir, University of Monastir, Monastir, Tunisia.); de Bruijne, Marleen (Biomedical Imaging Group Rotterdam, Erasmus MC, Rotterdam, the Netherlands; Department of Radiology and Nuclear Medicine, Erasmus MC, Rotterdam, the Netherlands; Department of Computer Science, University of Copenhagen, Copenhagen, Denmark.); Camarasa, Robin (Biomedical Imaging Group Rotterdam, Erasmus MC, Rotterdam, the Netherlands; Department of Radiology and Nuclear Medicine, Erasmus MC, Rotterdam, the Netherlands.); Correia, Teresa M (Centre of Marine Sciences, University of Algarve, Faro, Portugal; School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom.); Feng, Xue (Department of Biomedical Engineering, University of Virginia, Charlottesville, USA.); Girum, Kibrom B (ImViA Laboratory, University of Burgundy, Dijon, France.); Hennemuth, Anja (Charité - Universitätsmedizin Berlin, Berlin, Germany; Fraunhofer MEVIS, Bremen, Germany; German Centre for Cardiovascular Research, Berlin, Germany.); Huellebrand, Markus (Charité - Universitätsmedizin Berlin, Berlin, Germany; Fraunhofer MEVIS, Bremen, Germany.); Hussain, Raabid (ImViA Laboratory, University of Burgundy, Dijon, France.); Ivantsits, Matthias (Charité - Universitätsmedizin Berlin, Berlin, Germany.); Ma, Jun (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China.); Meyer, Craig (Department of Biomedical Engineering, University of Virginia, Charlottesville, USA.); Sharma, Rishabh (Data Analysis and Intelligent Systems Lab, Department of Computer Science, University of Houston, Houston, USA; Medical Robotics and Imaging Lab, Department of Computer Science, University of Houston, Houston, USA.); Shi, Jixi (Femto-ST Laboratory, University of Franche-Comté, Belfort, France.); Tsekos, Nikolaos V (Medical Robotics and Imaging Lab, Department of Computer Science, University of Houston, Houston, USA.); Varela, Marta (National Heart and Lung Institute, Imperial College London, London, United Kingdom.); Wang, Xiyue (College of Computer Science, Sichuan University, Chengdu, China.); Yang, Sen (College of Biomedical Engineering, Sichuan University, Chengdu, China.); Zhang, Hannu (Charité - Universitätsmedizin Berlin, Berlin, Germany.); Zhang, Yichi (School of Biological Science and Medical Engineering, Beihang University, Beijing, China.); Zhou, Yuncheng (School of Data Science, Fudan University, Shanghai, China.); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China.); Couturier, Raphael (Femto-ST Laboratory, University of Franche-Comté, Belfort, France.); Meriaudeau, Fabrice (ImViA Laboratory, University of Burgundy, Dijon, France.)","Lalande, Alain (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne)","Lalande, Alain (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne); Chen, Zhihao (University of Franche-Comté); Pommier, Thibaut (Centre Hospitalier Universitaire Dijon Bourgogne); Decourselle, Thomas (); Qayyum, Abdul (University of Burgundy); Salomon, Michel (University of Franche-Comté); Ginhac, Dominique (University of Burgundy); Skandarani, Youssef (University of Burgundy); Boucher, Arnaud (University of Burgundy); Brahim, Khawla (University of Burgundy; University of Sousse; University of Monastir); de Bruijne, Marleen (Erasmus MC; University of Copenhagen); Camarasa, Robin (Erasmus MC); Correia, Teresa M (University of Algarve; King's College London); Feng, Xue (University of Virginia); Girum, Kibrom B (University of Burgundy); Hennemuth, Anja (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine; German Centre for Cardiovascular Research); Huellebrand, Markus (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine); Hussain, Raabid (University of Burgundy); Ivantsits, Matthias (Charité - University Medicine Berlin); Ma, Jun (Nanjing University of Science and Technology); Meyer, Craig (University of Virginia); Sharma, Rishabh (University of Houston); Shi, Jixi (University of Franche-Comté); Tsekos, Nikolaos V (University of Houston); Varela, Marta (Imperial College London); Wang, Xiyue (Sichuan University); Yang, Sen (Sichuan University); Zhang, Hannu (Charité - University Medicine Berlin); Zhang, Yichi (Beihang University); Zhou, Yuncheng (Fudan University); Zhuang, Xiahai (Fudan University); Couturier, Raphael (University of Franche-Comté); Meriaudeau, Fabrice (University of Burgundy)",6,6,,,https://pure.eur.nl/ws/files/57130279/Deep_learning_methods_for_automatic_evaluation_of_delayed_enhancement_MRI._The_results_of_the_EMIDEC_challenge.pdf,https://app.dimensions.ai/details/publication/pub.1146519833,40 Engineering, 4003 Biomedical Engineering,,,,,
4526,pub.1146513990,10.1016/j.media.2022.102426,35367712,,Towards reliable cardiac image segmentation: Assessing image-level and pixel-level segmentation quality via self-reflective references,"Cardiac image segmentation is a fundamental step in cardiovascular disease diagnosis, where many deep learning models have achieved promising performance. However, when deploying these well-trained models for real clinical usage, the network will inevitably produce inferior results due to domain shifts, motion artifacts, etc. How to avoid the potential poor-quality segmentations involved in clinical decision making is crucial for reliable computer-aided cardiac disease diagnosis. To this end, we develop a quality control method to identify failure segmentations by measuring their qualities, and report them to physicians for professional opinions. In specific, we propose a reference-based framework to assess the image-level quality (i.e. per-class Dice) for overall evaluation and pixel-level quality (i.e. pixel-wise correct map) to locate mis-segmented regions. Following previous works, we create informative references first, and investigate their relative relationships (e.g. differences) to the inputs to expose segmentation failures. However, we generate and leverage the references in different ways. We instantiate the references by recovering input images from segmentations by a self-reflective reference generator. If the segmentation is of good quality, the reference (i.e. the reconstructed image) will be close to the input image, and the inconsistency between them would be a good indicator to deduce the qualities. To effectively explore these inconsistency, we employ a difference investigator equipped with semantic class-aware compactness constraint to force the correctly-segmented features more separable to the wrongly-segmented ones. The experiments on ACDC and MSCMR datasets demonstrated our method could effectively capture segmentation failures, and the results on low-quality (Dice∈[0,0.6)), medium-quality (Dice∈[0.6,0.8)) and high-quality (Dice∈[0.8,1.0)) segmentations showed satisfying robustness of our method.","This work is supported by Key-Area Research and Development Program of Guangdong Province, China under Grant 2020B010165004, Hong Kong RGC TRS Project No. T42-409/18-R, Hong Kong Innovation and Technology Fund Project No. GHP/110/19SZ, National Natural Science Foundation of China with Project No. U1813204, and HKU Startup Fund and HKU Seed Fund for Basic Research for New Staff with Project No. 202009185079.",,Medical Image Analysis,,"Heart; Heart Diseases; Humans; Image Processing, Computer-Assisted",2022-03-24,2022,2022-03-24,2022-05,78,,102426,Closed,Article,"Li, Kang; Yu, Lequan; Heng, Pheng-Ann","Li, Kang (The Department of Computer Science and Engineering, The Chinese University of Hong Kong, HKSAR, China. Electronic address: kli@cse.cuhk.edu.hk.); Yu, Lequan (The Department of Statistics and Actuarial Science, The University of Hong Kong, HKSAR, China.); Heng, Pheng-Ann (The Department of Computer Science and Engineering, The Chinese University of Hong Kong, HKSAR, China.)","Li, Kang (Chinese University of Hong Kong)","Li, Kang (Chinese University of Hong Kong); Yu, Lequan (University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong)",3,3,,,,https://app.dimensions.ai/details/publication/pub.1146513990,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
1451,pub.1146502086,10.1002/9781119792673.ch6,,,Heart Disease Classification Using Regional Wall Thickness by Ensemble Classifier,"In recent years, heart disease is becoming a major problem in human beings. The diverse of syndromes that will infect the heart is known as the heart disease. Cardiac magnetic resonance images are formed using the radio waves and an influential magnetic field, which will produce pictures with a detailed structure of within and around the heart which can be used to identify the cardiac disease through various learning techniques that are used to evaluate the heart's anatomy and function in patients. In this chapter, ensemble classification model is used to classify the type of heart disease. Automated cardiac diagnosis challenge dataset is taken for prediction of heart disease that consists of 150 subjects which is evenly divided among all five classes. The dataset is initially pre‐processed to eliminate the noise in image followed by the Region of Interest extraction and segmentation based on densely fully convolutional network, and the feature extraction to extract the values to calculate the ejection fraction value. Based on the Then, the heart disease is classified by using the ejection fraction value representing the regional wall thickness.",,,,Bioinformatics and Medical Applications,,2022-03-23,2022,2022-03-23,2022-04-03,,,99-116,Closed,Chapter,"Prakash, J.; Vinoth, Kumar B.; Sandhya, R.","Prakash, J. (Department of Computer Science and Engineering, PSG College of Technology, Coimbatore, Tamil Nadu, India); Vinoth, Kumar B. (Department of Information and Technology, PSG College of Technology, Coimbatore, Tamil Nadu, India); Sandhya, R. (Department of Computer Science and Engineering, PSG College of Technology, Coimbatore, Tamil Nadu, India)",,"Prakash, J. (Anna University, Chennai); Vinoth, Kumar B. (Anna University, Chennai); Sandhya, R. (Anna University, Chennai)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146502086,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 46 Information and Computing Sciences,,,,,,,,,,
1517,pub.1146477635,10.48550/arxiv.2203.10726,,,TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation  with Transformers,"Combining information from multi-view images is crucial to improve the
performance and robustness of automated methods for disease diagnosis. However,
due to the non-alignment characteristics of multi-view images, building
correlation and data fusion across views largely remain an open problem. In
this study, we present TransFusion, a Transformer-based architecture to merge
divergent multi-view imaging information using convolutional layers and
powerful attention mechanisms. In particular, the Divergent Fusion Attention
(DiFA) module is proposed for rich cross-view context modeling and semantic
dependency mining, addressing the critical issue of capturing long-range
correlations between unaligned data from different image views. We further
propose the Multi-Scale Attention (MSA) to collect global correspondence of
multi-scale feature representations. We evaluate TransFusion on the
Multi-Disease, Multi-View \& Multi-Center Right Ventricular Segmentation in
Cardiac MRI (M\&Ms-2) challenge cohort. TransFusion demonstrates leading
performance against the state-of-the-art methods and opens up new perspectives
for multi-view imaging integration towards robust medical image segmentation.",,,arXiv,,,2022-03-21,2022,,,,,,All OA, Green,Preprint,"Liu, Di; Gao, Yunhe; Zhangli, Qilong; Han, Ligong; He, Xiaoxiao; Xia, Zhaoyang; Wen, Song; Chang, Qi; Yan, Zhennan; Zhou, Mu; Metaxas, Dimitris","Liu, Di (); Gao, Yunhe (); Zhangli, Qilong (); Han, Ligong (); He, Xiaoxiao (); Xia, Zhaoyang (); Wen, Song (); Chang, Qi (); Yan, Zhennan (); Zhou, Mu (); Metaxas, Dimitris ()",,"Liu, Di (); Gao, Yunhe (); Zhangli, Qilong (); Han, Ligong (); He, Xiaoxiao (); Xia, Zhaoyang (); Wen, Song (); Chang, Qi (); Yan, Zhennan (); Zhou, Mu (); Metaxas, Dimitris ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146477635,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science,,,,,,,,,
906,pub.1146477339,10.48550/arxiv.2203.10417,,,Attri-VAE: attribute-based interpretable representations of medical  images with variational autoencoders,"Deep learning (DL) methods where interpretability is intrinsically considered
as part of the model are required to better understand the relationship of
clinical and imaging-based attributes with DL outcomes, thus facilitating their
use in the reasoning behind medical decisions. Latent space representations
built with variational autoencoders (VAE) do not ensure individual control of
data attributes. Attribute-based methods enforcing attribute disentanglement
have been proposed in the literature for classical computer vision tasks in
benchmark data. In this paper, we propose a VAE approach, the Attri-VAE, that
includes an attribute regularization term to associate clinical and medical
imaging attributes with different regularized dimensions in the generated
latent space, enabling a better-disentangled interpretation of the attributes.
Furthermore, the generated attention maps explained the attribute encoding in
the regularized latent space dimensions. Using the Attri-VAE approach we
analyzed healthy and myocardial infarction patients with clinical, cardiac
morphology, and radiomics attributes. The proposed model provided an excellent
trade-off between reconstruction fidelity, disentanglement, and
interpretability, outperforming state-of-the-art VAE approaches according to
several quantitative metrics. The resulting latent space allowed the generation
of realistic synthetic data in the trajectory between two distinct input
samples or along a specific attribute dimension to better interpret changes
between different cardiac conditions.",,,arXiv,,,2022-03-19,2022,,,,,,All OA, Green,Preprint,"Cetin, Irem; Stephens, Maialen; Camara, Oscar; Ballester, Miguel Angel Gonzalez","Cetin, Irem (); Stephens, Maialen (); Camara, Oscar (); Ballester, Miguel Angel Gonzalez ()",,"Cetin, Irem (); Stephens, Maialen (); Camara, Oscar (); Ballester, Miguel Angel Gonzalez ()",1,1,,,,https://app.dimensions.ai/details/publication/pub.1146477339,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5350,pub.1146290971,10.1109/jbhi.2022.3158897,35290192,,HDL: Hybrid Deep Learning for the Synthesis of Myocardial Velocity Maps in Digital Twins for Cardiac Analysis,"Synthetic digital twins based on medical data accelerate the acquisition, labelling and decision making procedure in digital healthcare. A core part of digital healthcare twins is modelbased data synthesis, which permits the generation of realistic medical signals without requiring to cope with the modelling complexity of anatomical and biochemical phenomena producing them in reality. Unfortunately, algorithms for cardiac data synthesis have been so far scarcely studied in the literature. An important imaging modality in the cardiac examination is three-directional CINE multislice myocardial velocity mapping (3Dir MVM), which provides a quantitative assessment of cardiac motion in three orthogonal directions of the left ventricle. The long acquisition time and complex acquisition produce make it more urgent to produce synthetic digital twins of this imaging modality. In this study, we propose a hybrid deep learning (HDL) network, especially for synthetic 3Dir MVM data. Our algorithm is featured by a hybrid UNet and a Generative Adversarial Network with a foreground-background generation scheme. The experimental results show that from temporally down-sampled magnitude CINE images (six times), our proposed algorithm can still successfully synthesise high temporal resolution 3Dir MVM CMR data (PSNR=42.32) with precise left ventricle segmentation (DICE=0.92). These performance scores indicate that our proposed HDL algorithm can be implemented in real-world digital twins for myocardial velocity mapping data simulation. To the best of our knowledge, this work is the first one in the literature investigating digital twins of the 3Dir MVM CMR, which has shown great potential for improving the efficiency of clinical studies via synthesised cardiac data.",,,IEEE Journal of Biomedical and Health Informatics,,,2022-03-15,2022,2022-03-15,2022-03-15,PP,99,1-1,All OA, Green,Article,"Xing, Xiaodan; Del Ser, Javier; Wu, Yinzhe; Li, Yang; Xia, Jun; Lei, Xu; Firmin, David; Gatehouse, Peter; Yang, Guang","Xing, Xiaodan (Imperial College London, 4615 London, United Kingdom of Great Britain and Northern Ireland); Del Ser, Javier (University of the Basque Country, 16402 Bilbao, Pas Vasco, Spain); Wu, Yinzhe (Imperial College London, 4615 London, United Kingdom of Great Britain and Northern Ireland); Li, Yang (Department of Automation Sciences and Electrical Engineering, Beijing, China, 100191); Xia, Jun (Department of Radiology, Shenzhen Second People's Hospital, 499778 Shenzhen, Guangdong, China); Lei, Xu (Department of Radiology, Beijing, China); Firmin, David (Cardiovascular Research Centre, Royal Brompton Hospital, the National Heart and Lung Institute, Imperial College London, London, United Kingdom of Great Britain and Northern Ireland); Gatehouse, Peter (Imperial College London, 4615 London, United Kingdom of Great Britain and Northern Ireland); Yang, Guang (Imperial College London, 4615 London, United Kingdom of Great Britain and Northern Ireland, SW7 2AZ)",,"Xing, Xiaodan (Imperial College London); Del Ser, Javier (University of the Basque Country); Wu, Yinzhe (Imperial College London); Li, Yang (); Xia, Jun (Shenzhen Second People's Hospital); Lei, Xu (); Firmin, David (Imperial College London); Gatehouse, Peter (Imperial College London); Yang, Guang (Imperial College London)",7,7,,,http://arxiv.org/pdf/2203.05564,https://app.dimensions.ai/details/publication/pub.1146290971,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5667,pub.1146179708,10.3389/fcvm.2022.829512,35360025,PMC8960112,A Collaborative Approach for the Development and Application of Machine Learning Solutions for CMR-Based Cardiac Disease Classification,"The quality and acceptance of machine learning (ML) approaches in cardiovascular data interpretation depends strongly on model design and training and the interaction with the clinical experts. We hypothesize that a software infrastructure for the training and application of ML models can support the improvement of the model training and provide relevant information for understanding the classification-relevant data features. The presented solution supports an iterative training, evaluation, and exploration of machine-learning-based multimodal data interpretation methods considering cardiac MRI data. Correction, annotation, and exploration of clinical data and interpretation of results are supported through dedicated interactive visual analytics tools. We test the presented concept with two use cases from the ACDC and EMIDEC cardiac MRI image analysis challenges. In both applications, pre-trained 2D U-Nets are used for segmentation, and classifiers are trained for diagnostic tasks using radiomics features of the segmented anatomical structures. The solution was successfully used to identify outliers in automatic segmentation and image acquisition. The targeted curation and addition of expert annotations improved the performance of the machine learning models. Clinical experts were supported in understanding specific anatomical and functional characteristics of the assigned disease classes.",,"This work was partially funded by the BMBF project Berlin Institute for the Foundations of Learning and Data (Grant Number 01IS18037E) and by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – SFB-1470 – B06.",Frontiers in Cardiovascular Medicine,,,2022-03-10,2022,2022-03-10,,9,,829512,All OA, Gold,Article,"Huellebrand, Markus; Ivantsits, Matthias; Tautz, Lennart; Kelle, Sebastian; Hennemuth, Anja","Huellebrand, Markus (Institute of Cardiovascular Computer-Assisted Medicine, Charité—Universitätsmedizin Berlin, Berlin, Germany; Cardiovascular Research and Development, Fraunhofer MEVIS, Bremen, Germany); Ivantsits, Matthias (Institute of Cardiovascular Computer-Assisted Medicine, Charité—Universitätsmedizin Berlin, Berlin, Germany); Tautz, Lennart (Cardiovascular Research and Development, Fraunhofer MEVIS, Bremen, Germany); Kelle, Sebastian (Institute of Cardiovascular Computer-Assisted Medicine, Charité—Universitätsmedizin Berlin, Berlin, Germany; German Centre for Cardiovascular Research (DZHK), Berlin, Germany; German Heart Center Berlin (DHZB), Berlin, Germany); Hennemuth, Anja (Institute of Cardiovascular Computer-Assisted Medicine, Charité—Universitätsmedizin Berlin, Berlin, Germany; Cardiovascular Research and Development, Fraunhofer MEVIS, Bremen, Germany; German Centre for Cardiovascular Research (DZHK), Berlin, Germany; Department of Diagnostic and Interventional Radiology and Nuclear Medicine, University Medical Center Hamburg-Eppendorf, Hamburg, Germany)","Huellebrand, Markus (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine)","Huellebrand, Markus (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine); Ivantsits, Matthias (Charité - University Medicine Berlin); Tautz, Lennart (Fraunhofer Institute for Digital Medicine); Kelle, Sebastian (Charité - University Medicine Berlin; German Centre for Cardiovascular Research; Deutsches Herzzentrum Berlin); Hennemuth, Anja (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine; German Centre for Cardiovascular Research; University Medical Center Hamburg-Eppendorf)",2,2,,,https://www.frontiersin.org/articles/10.3389/fcvm.2022.829512/pdf,https://app.dimensions.ai/details/publication/pub.1146179708,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,3 Good Health and Well Being,,,,,,,,,
5074,pub.1146202479,10.3390/biomedicines10030639,35327441,PMC8944952,Strategies for Sudden Cardiac Death Prevention,"Sudden cardiac death (SCD) represents a major challenge in modern medicine. The prevention of SCD orbits on two levels, the general population level and individual level. Much research has been done with the aim to improve risk stratification of SCD, although no radical changes in evidence and in therapeutic strategy have been achieved. Artificial intelligence (AI), and in particular machine learning (ML) models, represent novel technologic tools that promise to improve predictive ability of fatal arrhythmic events. In this review, firstly, we analyzed the electrophysiological basis and the major clues of SCD prevention at population and individual level; secondly, we reviewed the main research where ML models were used for risk stratification in other field of cardiology, suggesting its potentiality in the field of SCD prevention.",,,Biomedicines,,,2022-03-10,2022,2022-03-10,,10,3,639,All OA, Gold,Article,"Corianò, Mattia; Tona, Francesco","Corianò, Mattia (Department of Cardiac, Thoracic, Vascular Sciences and Public Health, University of Padova, 35128 Padova, Italy.); Tona, Francesco (Department of Cardiac, Thoracic, Vascular Sciences and Public Health, University of Padova, 35128 Padova, Italy.)","Tona, Francesco (University of Padua)","Corianò, Mattia (University of Padua); Tona, Francesco (University of Padua)",1,1,,,https://www.mdpi.com/2227-9059/10/3/639/pdf?version=1646902474,https://app.dimensions.ai/details/publication/pub.1146202479,31 Biological Sciences, 3101 Biochemistry and Cell Biology,,,,,,,,,,
1516,pub.1146181589,10.48550/arxiv.2203.04568,,,PHTrans: Parallelly Aggregating Global and Local Representations for  Medical Image Segmentation,"The success of Transformer in computer vision has attracted increasing
attention in the medical imaging community. Especially for medical image
segmentation, many excellent hybrid architectures based on convolutional neural
networks (CNNs) and Transformer have been presented and achieve impressive
performance. However, most of these methods, which embed modular Transformer
into CNNs, struggle to reach their full potential. In this paper, we propose a
novel hybrid architecture for medical image segmentation called PHTrans, which
parallelly hybridizes Transformer and CNN in main building blocks to produce
hierarchical representations from global and local features and adaptively
aggregate them, aiming to fully exploit their strengths to obtain better
segmentation performance. Specifically, PHTrans follows the U-shaped
encoder-decoder design and introduces the parallel hybird module in deep
stages, where convolution blocks and the modified 3D Swin Transformer learn
local features and global dependencies separately, then a sequence-to-volume
operation unifies the dimensions of the outputs to achieve feature aggregation.
Extensive experimental results on both Multi-Atlas Labeling Beyond the Cranial
Vault and Automated Cardiac Diagnosis Challeng datasets corroborate its
effectiveness, consistently outperforming state-of-the-art methods. The code is
available at: https://github.com/lseventeen/PHTrans.",,,arXiv,,,2022-03-09,2022,,,,,,All OA, Green,Preprint,"Liu, Wentao; Tian, Tong; Xu, Weijin; Yang, Huihua; Pan, Xipeng; Yan, Songlin; Wang, Lemeng","Liu, Wentao (); Tian, Tong (); Xu, Weijin (); Yang, Huihua (); Pan, Xipeng (); Yan, Songlin (); Wang, Lemeng ()",,"Liu, Wentao (); Tian, Tong (); Xu, Weijin (); Yang, Huihua (); Pan, Xipeng (); Yan, Songlin (); Wang, Lemeng ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146181589,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1133,pub.1146252294,10.48550/arxiv.2203.05564,,,HDL: Hybrid Deep Learning for the Synthesis of Myocardial Velocity Maps  in Digital Twins for Cardiac Analysis,"Synthetic digital twins based on medical data accelerate the acquisition,
labelling and decision making procedure in digital healthcare. A core part of
digital healthcare twins is model-based data synthesis, which permits the
generation of realistic medical signals without requiring to cope with the
modelling complexity of anatomical and biochemical phenomena producing them in
reality. Unfortunately, algorithms for cardiac data synthesis have been so far
scarcely studied in the literature. An important imaging modality in the
cardiac examination is three-directional CINE multi-slice myocardial velocity
mapping (3Dir MVM), which provides a quantitative assessment of cardiac motion
in three orthogonal directions of the left ventricle. The long acquisition time
and complex acquisition produce make it more urgent to produce synthetic
digital twins of this imaging modality. In this study, we propose a hybrid deep
learning (HDL) network, especially for synthetic 3Dir MVM data. Our algorithm
is featured by a hybrid UNet and a Generative Adversarial Network with a
foreground-background generation scheme. The experimental results show that
from temporally down-sampled magnitude CINE images (six times), our proposed
algorithm can still successfully synthesise high temporal resolution 3Dir MVM
CMR data (PSNR=42.32) with precise left ventricle segmentation (DICE=0.92).
These performance scores indicate that our proposed HDL algorithm can be
implemented in real-world digital twins for myocardial velocity mapping data
simulation. To the best of our knowledge, this work is the first one in the
literature investigating digital twins of the 3Dir MVM CMR, which has shown
great potential for improving the efficiency of clinical studies via
synthesised cardiac data.",,,arXiv,,,2022-03-09,2022,,,,,,All OA, Green,Preprint,"Xing, Xiaodan; Del Ser, Javier; Wu, Yinzhe; Li, Yang; Xia, Jun; Xu, Lei; Firmin, David; Gatehouse, Peter; Yang, Guang","Xing, Xiaodan (); Del Ser, Javier (); Wu, Yinzhe (); Li, Yang (); Xia, Jun (); Xu, Lei (); Firmin, David (); Gatehouse, Peter (); Yang, Guang ()",,"Xing, Xiaodan (); Del Ser, Javier (); Wu, Yinzhe (); Li, Yang (); Xia, Jun (); Xu, Lei (); Firmin, David (); Gatehouse, Peter (); Yang, Guang ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146252294,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5074,pub.1146085915,10.3390/diagnostics12030639,35328192,PMC8947201,Computer-Assisted Pterygium Screening System: A Review,"Pterygium is an eye condition that causes the fibrovascular tissues to grow towards the corneal region. At the early stage, it is not a harmful condition, except for slight discomfort for the patients. However, it will start to affect the eyesight of the patient once the tissues encroach towards the corneal region, with a more serious impact if it has grown into the pupil region. Therefore, this condition needs to be identified as early as possible to halt its growth, with the use of simple eye drops and sunglasses. One of the associated risk factors for this condition is a low educational level, which explains the reason that the majority of the patients are not aware of this condition. Hence, it is important to develop an automated pterygium screening system based on simple imaging modalities such as a mobile phone camera so that it can be assessed by many people. During the early stage of automated pterygium screening system development, conventional machine learning techniques such as support vector machines and artificial neural networks are the de facto algorithms to detect the presence of pterygium tissues. However, with the arrival of the deep learning era, coupled with the availability of large training data, deep learning networks have replaced the conventional networks in screening for the pterygium condition. The deep learning networks have been successfully implemented for three major purposes, which are to classify an image regarding whether there is the presence of pterygium tissues or not, to localize the lesion tissues through object detection methodology, and to semantically segment the lesion tissues at the pixel level. This review paper summarizes the type, severity, risk factors, and existing state-of-the-art technology in automated pterygium screening systems. A few available datasets are also discussed in this paper for both classification and segmentation tasks. In conclusion, a computer-assisted pterygium screening system will benefit many people all over the world, especially in alerting them to the possibility of having this condition so that preventive actions can be advised at an early stage.",,,Diagnostics,,,2022-03-05,2022,2022-03-05,,12,3,639,All OA, Gold,Article,"Abdani, Siti Raihanah; Zulkifley, Mohd Asyraf; Shahrimin, Mohamad Ibrani; Zulkifley, Nuraisyah Hani","Abdani, Siti Raihanah (Faculty of Humanities, Management and Science, Universiti Putra Malaysia (Bintulu Campus), Bintulu 97008, Sarawak, Malaysia;, raihanah.abdani@siswa.ukm.edu.my, (S.R.A.);, ibrani@upm.edu.my, (M.I.S.)); Zulkifley, Mohd Asyraf (Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering and Built Environment, Universiti Kebangsaan Malaysia, Bangi 43600, Selangor, Malaysia); Shahrimin, Mohamad Ibrani (Faculty of Humanities, Management and Science, Universiti Putra Malaysia (Bintulu Campus), Bintulu 97008, Sarawak, Malaysia;, raihanah.abdani@siswa.ukm.edu.my, (S.R.A.);, ibrani@upm.edu.my, (M.I.S.)); Zulkifley, Nuraisyah Hani (Community Health Department, Faculty of Medicine and Health Sciences, Universiti Putra Malaysia, Serdang 43400, Selangor, Malaysia;, hanizulkifley@moh.gov.my)","Zulkifley, Mohd Asyraf (National University of Malaysia)","Abdani, Siti Raihanah (Universiti Putra Malaysia); Zulkifley, Mohd Asyraf (National University of Malaysia); Shahrimin, Mohamad Ibrani (Universiti Putra Malaysia); Zulkifley, Nuraisyah Hani (Universiti Putra Malaysia)",2,2,,,https://www.mdpi.com/2075-4418/12/3/639/pdf?version=1646631570,https://app.dimensions.ai/details/publication/pub.1146085915,32 Biomedical and Clinical Sciences, 3212 Ophthalmology and Optometry,,,,,,,,,,
5351,pub.1146053440,10.1109/access.2022.3156894,35656515,PMC9159704,Medical Image Segmentation Using Transformer Networks,"Deep learning models represent the state of the art in medical image segmentation. Most of these models are fully-convolutional networks (FCNs), namely each layer processes the output of the preceding layer with convolution operations. The convolution operation enjoys several important properties such as sparse interactions, parameter sharing, and translation equivariance. Because of these properties, FCNs possess a strong and useful inductive bias for image modeling and analysis. However, they also have certain important shortcomings, such as performing a fixed and pre-determined operation on a test image regardless of its content and difficulty in modeling long-range interactions. In this work we show that a different deep neural network architecture, based entirely on self-attention between neighboring image patches and without any convolution operations, can achieve more accurate segmentations than FCNs. Our proposed model is based directly on the transformer network architecture. Given a 3D image block, our network divides it into non-overlapping 3D patches and computes a 1D embedding for each patch. The network predicts the segmentation map for the block based on the self-attention between these patch embeddings. Furthermore, in order to address the common problem of scarcity of labeled medical images, we propose methods for pre-training this model on large corpora of unlabeled images. Our experiments show that the proposed model can achieve segmentation accuracies that are better than several state of the art FCN architectures on two datasets. Our proposed network can be trained using only tens of labeled images. Moreover, with the proposed pre-training strategies, our network outperforms FCNs when labeled training data is small.","This work was supported in part by the National Institute of Biomedical Imaging and Bioengineering and the National Institute of Neurological Disorders and Stroke of the National Institutes of Health (NIH) under Award R01EB031849, Award R01NS106030, and Award R01EB032366; in part by the Office of the Director of the NIH under Award S10OD0250111; and in part by a Technological Innovations in Neuroscience Award from the McKnight Foundation. The work of Haoran Dou was supported by the EPSRC Doctoral Training Partnership (DTP) Studentship. The content of this publication is solely the responsibility of the authors and does not necessarily represent the official views of the NIH or the McKnight Foundation.","This work was supported in part by the National Institute of Biomedical Imaging and Bioengineering and the National Institute of Neurological Disorders and Stroke of the National Institutes of Health (NIH) under Award R01EB031849, Award R01NS106030, and Award R01EB032366; in part by the Office of the Director of the NIH under Award S10OD0250111; and in part by a Technological Innovations in Neuroscience Award from the McKnight Foundation. The work of Haoran Dou was supported by the EPSRC Doctoral Training Partnership (DTP) Studentship. The content of this publication is solely the responsibility of the authors and does not necessarily represent the official views of the NIH or the McKnight Foundation.",IEEE Access,,,2022-03-04,2022,2022-03-04,2022,10,,29322-29332,All OA, Gold,Article,"Karimi, Davood; Dou, Haoran; Gholipour, Ali","Karimi, Davood (Department of Radiology, Boston Children’s Hospital, Harvard Medical School, Boston, MA, 02115, USA); Dou, Haoran (Centre for Computational Imaging & Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, LS2 9JT, U.K.); Gholipour, Ali (Department of Radiology, Boston Children’s Hospital, Harvard Medical School, Boston, MA, 02115, USA)","Karimi, Davood (Boston Children's Hospital; Harvard University)","Karimi, Davood (Boston Children's Hospital; Harvard University); Dou, Haoran (University of Leeds); Gholipour, Ali (Boston Children's Hospital; Harvard University)",4,4,,,https://ieeexplore.ieee.org/ielx7/6287639/9668973/09729189.pdf,https://app.dimensions.ai/details/publication/pub.1146053440,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5339,pub.1146004701,10.1038/s41598-022-07186-4,35241683,PMC8894335,Federated learning for multi-center imaging diagnostics: a simulation study in cardiovascular disease,"Deep learning models can enable accurate and efficient disease diagnosis, but have thus far been hampered by the data scarcity present in the medical world. Automated diagnosis studies have been constrained by underpowered single-center datasets, and although some results have shown promise, their generalizability to other institutions remains questionable as the data heterogeneity between institutions is not taken into account. By allowing models to be trained in a distributed manner that preserves patients’ privacy, federated learning promises to alleviate these issues, by enabling diligent multi-center studies. We present the first simulated federated learning study on the modality of cardiovascular magnetic resonance and use four centers derived from subsets of the M&M and ACDC datasets, focusing on the diagnosis of hypertrophic cardiomyopathy. We adapt a 3D-CNN network pretrained on action recognition and explore two different ways of incorporating shape prior information to the model, and four different data augmentation set-ups, systematically analyzing their impact on the different collaborative learning choices. We show that despite the small size of data (180 subjects derived from four centers), the privacy preserving federated learning achieves promising results that are competitive with traditional centralized learning. We further find that federatively trained models exhibit increased robustness and are more sensitive to domain shift effects.","This project has received funding from the European Union’s Horizon 2020 research and innovation programme under Grant agreement No. 952103, EuCanImage.",,Scientific Reports,,Cardiovascular Diseases, Computer Simulation, Confidentiality, Humans, Magnetic Resonance Imaging, Privacy,2022-03-03,2022,2022-03-03,,12,1,3551,All OA, Gold,Article,"Linardos, Akis; Kushibar, Kaisar; Walsh, Sean; Gkontra, Polyxeni; Lekadir, Karim","Linardos, Akis (Department of Mathematics and Computer Science, University of Barcelona, 08007, Barcelona, Spain); Kushibar, Kaisar (Department of Mathematics and Computer Science, University of Barcelona, 08007, Barcelona, Spain); Walsh, Sean (Radiomics, 4000, Liège, Belgium); Gkontra, Polyxeni (Department of Mathematics and Computer Science, University of Barcelona, 08007, Barcelona, Spain); Lekadir, Karim (Department of Mathematics and Computer Science, University of Barcelona, 08007, Barcelona, Spain)","Linardos, Akis (University of Barcelona)","Linardos, Akis (University of Barcelona); Kushibar, Kaisar (University of Barcelona); Walsh, Sean (); Gkontra, Polyxeni (University of Barcelona); Lekadir, Karim (University of Barcelona)",8,8,,,https://www.nature.com/articles/s41598-022-07186-4.pdf,https://app.dimensions.ai/details/publication/pub.1146004701,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,3 Good Health and Well Being,,,
2256,pub.1146024905,10.3389/fcvm.2022.826283,35310962,PMC8927633,Cardiac MR: From Theory to Practice,"Cardiovascular disease (CVD) is the leading single cause of morbidity and mortality, causing over 17. 9 million deaths worldwide per year with associated costs of over $800 billion. Improving prevention, diagnosis, and treatment of CVD is therefore a global priority. Cardiovascular magnetic resonance (CMR) has emerged as a clinically important technique for the assessment of cardiovascular anatomy, function, perfusion, and viability. However, diversity and complexity of imaging, reconstruction and analysis methods pose some limitations to the widespread use of CMR. Especially in view of recent developments in the field of machine learning that provide novel solutions to address existing problems, it is necessary to bridge the gap between the clinical and scientific communities. This review covers five essential aspects of CMR to provide a comprehensive overview ranging from CVDs to CMR pulse sequence design, acquisition protocols, motion handling, image reconstruction and quantitative analysis of the obtained data. (1) The basic MR physics of CMR is introduced. Basic pulse sequence building blocks that are commonly used in CMR imaging are presented. Sequences containing these building blocks are formed for parametric mapping and functional imaging techniques. Commonly perceived artifacts and potential countermeasures are discussed for these methods. (2) CMR methods for identifying CVDs are illustrated. Basic anatomy and functional processes are described to understand the cardiac pathologies and how they can be captured by CMR imaging. (3) The planning and conduct of a complete CMR exam which is targeted for the respective pathology is shown. Building blocks are illustrated to create an efficient and patient-centered workflow. Further strategies to cope with challenging patients are discussed. (4) Imaging acceleration and reconstruction techniques are presented that enable acquisition of spatial, temporal, and parametric dynamics of the cardiac cycle. The handling of respiratory and cardiac motion strategies as well as their integration into the reconstruction processes is showcased. (5) Recent advances on deep learning-based reconstructions for this purpose are summarized. Furthermore, an overview of novel deep learning image segmentation and analysis methods is provided with a focus on automatic, fast and reliable extraction of biomarkers and parameters of clinical relevance.","Caitlin Penny (Queensland X-Ray, Mater Hospital Brisbane, Brisbane, Australia) contributed to the intellectual content of Section Clinical Cardiovascular MR: How Should We Perform the Examination.","This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy—EXC 2180 #390900677 and EXC 2064/1 #390727645. This work was part of a project that has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No. 867450.",Frontiers in Cardiovascular Medicine,,,2022-03-03,2022,2022-03-03,,9,,826283,All OA, Gold,Article,"Ismail, Tevfik F.; Strugnell, Wendy; Coletti, Chiara; Božić-Iven, Maša; Weingärtner, Sebastian; Hammernik, Kerstin; Correia, Teresa; Küstner, Thomas","Ismail, Tevfik F. (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Cardiology Department, Guy's and St Thomas' Hospital, London, United Kingdom); Strugnell, Wendy (Queensland X-Ray, Mater Hospital Brisbane, Brisbane, QLD, Australia); Coletti, Chiara (Magnetic Resonance Systems Lab, Delft University of Technology, Delft, Netherlands); Božić-Iven, Maša (Magnetic Resonance Systems Lab, Delft University of Technology, Delft, Netherlands; Computer Assisted Clinical Medicine, Heidelberg University, Mannheim, Germany); Weingärtner, Sebastian (Magnetic Resonance Systems Lab, Delft University of Technology, Delft, Netherlands); Hammernik, Kerstin (Lab for AI in Medicine, Technical University of Munich, Munich, Germany; Department of Computing, Imperial College London, London, United Kingdom); Correia, Teresa (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Centre of Marine Sciences, Faro, Portugal); Küstner, Thomas (Medical Image and Data Analysis (MIDAS.lab), Department of Diagnostic and Interventional Radiology, University Hospital of Tübingen, Tübingen, Germany)","Correia, Teresa (King's College London; University of Algarve); Küstner, Thomas (Universitätsklinikum Tübingen)","Ismail, Tevfik F. (King's College London; St Thomas' Hospital); Strugnell, Wendy (Mater Adult Hospital); Coletti, Chiara (Delft University of Technology); Božić-Iven, Maša (Delft University of Technology; Heidelberg University); Weingärtner, Sebastian (Delft University of Technology); Hammernik, Kerstin (Technical University of Munich; Imperial College London); Correia, Teresa (King's College London; University of Algarve); Küstner, Thomas (Universitätsklinikum Tübingen)",3,3,,,https://www.frontiersin.org/articles/10.3389/fcvm.2022.826283/pdf,https://app.dimensions.ai/details/publication/pub.1146024905,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,,,,,
1395,pub.1146094505,10.48550/arxiv.2203.02106,,,Scribble-Supervised Medical Image Segmentation via Dual-Branch Network  and Dynamically Mixed Pseudo Labels Supervision,"Medical image segmentation plays an irreplaceable role in computer-assisted
diagnosis, treatment planning, and following-up. Collecting and annotating a
large-scale dataset is crucial to training a powerful segmentation model, but
producing high-quality segmentation masks is an expensive and time-consuming
procedure. Recently, weakly-supervised learning that uses sparse annotations
(points, scribbles, bounding boxes) for network training has achieved
encouraging performance and shown the potential for annotation cost reduction.
However, due to the limited supervision signal of sparse annotations, it is
still challenging to employ them for networks training directly. In this work,
we propose a simple yet efficient scribble-supervised image segmentation method
and apply it to cardiac MRI segmentation. Specifically, we employ a dual-branch
network with one encoder and two slightly different decoders for image
segmentation and dynamically mix the two decoders' predictions to generate
pseudo labels for auxiliary supervision. By combining the scribble supervision
and auxiliary pseudo labels supervision, the dual-branch network can
efficiently learn from scribble annotations end-to-end. Experiments on the
public ACDC dataset show that our method performs better than current
scribble-supervised segmentation methods and also outperforms several
semi-supervised segmentation methods.",,,arXiv,,,2022-03-03,2022,,,,,,All OA, Green,Preprint,"Luo, Xiangde; Hu, Minhao; Liao, Wenjun; Zhai, Shuwei; Song, Tao; Wang, Guotai; Zhang, Shaoting","Luo, Xiangde (); Hu, Minhao (); Liao, Wenjun (); Zhai, Shuwei (); Song, Tao (); Wang, Guotai (); Zhang, Shaoting ()",,"Luo, Xiangde (); Hu, Minhao (); Liao, Wenjun (); Zhai, Shuwei (); Song, Tao (); Wang, Guotai (); Zhang, Shaoting ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146094505,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1254,pub.1146046525,10.48550/arxiv.2203.01475,,,CycleMix: A Holistic Strategy for Medical Image Segmentation from  Scribble Supervision,"Curating a large set of fully annotated training data can be costly,
especially for the tasks of medical image segmentation. Scribble, a weaker form
of annotation, is more obtainable in practice, but training segmentation models
from limited supervision of scribbles is still challenging. To address the
difficulties, we propose a new framework for scribble learning-based medical
image segmentation, which is composed of mix augmentation and cycle consistency
and thus is referred to as CycleMix. For augmentation of supervision, CycleMix
adopts the mixup strategy with a dedicated design of random occlusion, to
perform increments and decrements of scribbles. For regularization of
supervision, CycleMix intensifies the training objective with consistency
losses to penalize inconsistent segmentation, which results in significant
improvement of segmentation performance. Results on two open datasets, i.e.,
ACDC and MSCMRseg, showed that the proposed method achieved exhilarating
performance, demonstrating comparable or even better accuracy than the
fully-supervised methods. The code and expert-made scribble annotations for
MSCMRseg are publicly available at https://github.com/BWGZK/CycleMix.",,,arXiv,,,2022-03-02,2022,,,,,,All OA, Green,Preprint,"Zhang, Ke; Zhuang, Xiahai","Zhang, Ke (); Zhuang, Xiahai ()",,"Zhang, Ke (); Zhuang, Xiahai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146046525,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
788,pub.1146008595,10.48550/arxiv.2203.01089,,,Shape constrained CNN for segmentation guided prediction of myocardial  shape and pose parameters in cardiac MRI,"Semantic segmentation using convolutional neural networks (CNNs) is the
state-of-the-art for many medical image segmentation tasks including myocardial
segmentation in cardiac MR images. However, the predicted segmentation maps
obtained from such standard CNN do not allow direct quantification of regional
shape properties such as regional wall thickness. Furthermore, the CNNs lack
explicit shape constraints, occasionally resulting in unrealistic
segmentations. In this paper, we use a CNN to predict shape parameters of an
underlying statistical shape model of the myocardium learned from a training
set of images. Additionally, the cardiac pose is predicted, which allows to
reconstruct the myocardial contours. The integrated shape model regularizes the
predicted contours and guarantees realistic shapes. We enforce robustness of
shape and pose prediction by simultaneously performing pixel-wise semantic
segmentation during training and define two loss functions to impose
consistency between the two predicted representations: one distance-based loss
and one overlap-based loss. We evaluated the proposed method in a 5-fold cross
validation on an in-house clinical dataset with 75 subjects and on the ACDC and
LVQuan19 public datasets. We show the benefits of simultaneous semantic
segmentation and the two newly defined loss functions for the prediction of
shape parameters. Our method achieved a correlation of 99% for left ventricular
(LV) area on the three datasets, between 91% and 97% for myocardial area,
98-99% for LV dimensions and between 80% and 92% for regional wall thickness.",,,arXiv,,,2022-03-02,2022,,,,,,All OA, Green,Preprint,"Tilborghs, Sofie; Bogaert, Jan; Maes, Frederik","Tilborghs, Sofie (); Bogaert, Jan (); Maes, Frederik ()",,"Tilborghs, Sofie (); Bogaert, Jan (); Maes, Frederik ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146008595,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
6279,pub.1145946251,10.1007/s10278-021-00529-z,35233722,PMC9156613,Deep Learning-based Automated Aortic Area and Distensibility Assessment: the Multi-Ethnic Study of Atherosclerosis (MESA),"This study details application of deep learning for automatic segmentation of the ascending and descending aorta from 2D phase-contrast cine magnetic resonance imaging for automatic aortic analysis on the large MESA cohort with assessment on an external cohort of thoracic aortic aneurysm (TAA) patients. This study includes images and corresponding analysis of the ascending and descending aorta at the pulmonary artery bifurcation from the MESA study. Train, validation, and internal test sets consisted of 1123 studies (24,282 images), 374 studies (8067 images), and 375 studies (8069 images), respectively. The external test set of TAAs consisted of 37 studies (3224 images). CNN performance was evaluated utilizing a dice coefficient and concordance correlation coefficients (CCC) of geometric parameters. Dice coefficients were as high as 97.55% (CI: 97.47–97.62%) and 93.56% (CI: 84.63–96.68%) on the internal and external test of TAAs, respectively. CCC for maximum and minimum and ascending aortic area were 0.969 and 0.950, respectively, on the internal test set and 0.997 and 0.995, respectively, for the external test. The absolute differences between manual and deep learning segmentations for ascending and descending aortic distensibility were 0.0194 × 10−4 ± 9.67 × 10−4 and 0.002 ± 0.001 mmHg−1, respectively, on the internal test set and 0.44 × 10−4 ± 20.4 × 10−4 and 0.002 ± 0.001 mmHg−1, respectively, on the external test set. We successfully developed a U-Net-based aortic segmentation and analysis algorithm in both MESA and in external cases of TAA.","The authors thank the other investigators, the staff, and the participants of the MESA study for their valuable contributions. A full list of participating MESA investigators and institutions can be found at http://www.mesa-nhlbi.org.","This research was supported by contracts HHSN268201500003I, N01-HC-95159, N01-HC-95160, N01-HC-95161, N01-HC-95162, N01-HC-95163, N01-HC-95164, N01-HC-95165, N01-HC-95166, N01-HC-95167, N01-HC-95168, and N01-HC-95169 from the National Heart, Lung, and Blood Institute, and by grants UL1-TR-000040, UL1-TR-001079, and UL1-TR-001420 from the National Center for Advancing Translational Sciences (NCATS).",Journal of Digital Imaging,,Algorithms, Aorta, Atherosclerosis, Deep Learning, Humans, Magnetic Resonance Imaging,2022-03-01,2022,2022-03-01,2022-06,35,3,594-604,All OA, Green,Article,"Jani, Vivek P.; Kachenoura, Nadjia; Redheuil, Alban; Teixido-Tura, Gisela; Bouaou, Kevin; Bollache, Emilie; Mousseaux, Elie; De Cesare, Alain; Kutty, Shelby; Wu, Colin O.; Bluemke, David A.; Lima, Joao A. C.; Ambale-Venkatesh, Bharath","Jani, Vivek P. (Department of Radiology, Johns Hopkins University, 600 North Wolfe St, 21287, Baltimore, MD, USA); Kachenoura, Nadjia (Sorbonne Université, Laboratoire d’Imagerie Biomédicale, INSERM, CNRS, Paris, France); Redheuil, Alban (Sorbonne Université, Laboratoire d’Imagerie Biomédicale, INSERM, CNRS, Paris, France); Teixido-Tura, Gisela (Hospital Vall d’Hebron, Barcelona, Spain); Bouaou, Kevin (Sorbonne Université, Laboratoire d’Imagerie Biomédicale, INSERM, CNRS, Paris, France); Bollache, Emilie (Sorbonne Université, Laboratoire d’Imagerie Biomédicale, INSERM, CNRS, Paris, France); Mousseaux, Elie (Université de Paris, Hôpital Européen Georges Pompidou, APHP, INSERM PARCC, Paris, France); De Cesare, Alain (Sorbonne Université, Laboratoire d’Imagerie Biomédicale, INSERM, CNRS, Paris, France); Kutty, Shelby (Department of Radiology, Johns Hopkins University, 600 North Wolfe St, 21287, Baltimore, MD, USA); Wu, Colin O. (Office of Biostatistics Research, Division of Intramural Research, National Heart, Lung and Blood Institute, National Institutes of Health, Bethesda, MD, USA); Bluemke, David A. (University of Wisconsin School of Medicine and Public Health, Madison, WI, USA); Lima, Joao A. C. (Department of Radiology, Johns Hopkins University, 600 North Wolfe St, 21287, Baltimore, MD, USA); Ambale-Venkatesh, Bharath (Department of Radiology, Johns Hopkins University, 600 North Wolfe St, 21287, Baltimore, MD, USA)","Ambale-Venkatesh, Bharath (Johns Hopkins University)","Jani, Vivek P. (Johns Hopkins University); Kachenoura, Nadjia (Sorbonne University); Redheuil, Alban (Sorbonne University); Teixido-Tura, Gisela (Vall d'Hebron Hospital Universitari); Bouaou, Kevin (Sorbonne University); Bollache, Emilie (Sorbonne University); Mousseaux, Elie (); De Cesare, Alain (Sorbonne University); Kutty, Shelby (Johns Hopkins University); Wu, Colin O. (National Heart Lung and Blood Institute); Bluemke, David A. (University of Wisconsin–Madison); Lima, Joao A. C. (Johns Hopkins University); Ambale-Venkatesh, Bharath (Johns Hopkins University)",0,0,,,http://arxiv.org/pdf/2103.02417,https://app.dimensions.ai/details/publication/pub.1145946251,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,
1452,pub.1142197671,10.1016/j.patrec.2021.10.025,,,Effective extraction of ventricles and myocardium objects from cardiac magnetic resonance images with a multi-task learning U-Net,"Accurate extraction of semantic objects such as ventricles and myocardium from magnetic resonance (MR) images is one essential but very challenging task for the diagnosis of the cardiac diseases. To tackle this problem, in this paper, an automatic end-to-end supervised deep learning framework is proposed, using a multi-task learning based U-Net (MTL-UNet). Specifically, an edge extraction module and a fusion-based module are introduced for effectively capturing the contextual information such as continuous edges and consistent spatial patterns in terms of intensity and texture features. With a weighted triple loss including the dice loss, the cross-entropy loss and the edge loss, the accuracy of object segmentation and extraction has been effectively improved. Extensive experiments on the publicly available ACDC 2017 dataset have validated the efficacy and efficiency of the proposed MTL-UNet model.","This work was supported in part by the Dazhi Scholarship of the Guangdong Polytechnic Normal University, National Natural Science Foundation of China (62072122), Education Department of Guangdong Province (2019KSYS009), China, and a Feasibility Study supported by EPSRC (Engineering and Physics Sciences Research Council) Centre for Multiscale Soft Tissue Mechanics - with application to heart cancer.",,Pattern Recognition Letters,,,2022-03,2022,,2022-03,155,,165-170,All OA, Green,Article,"Ren, Jinchang; Sun, He; Zhao, Huimin; Gao, Hao; Maclellan, Calum; Zhao, Sophia; Luo, Xiaoyu","Ren, Jinchang (School of Computer Sciences, Guangdong Polytechnic Normal University, Guangzhou 510655, China; National Subsea Centre, Robert Gordon University, Aberdeen, UK); Sun, He (School of Computer Science, Beijing Institute of Technology, Beijing 100081, China); Zhao, Huimin (School of Computer Sciences, Guangdong Polytechnic Normal University, Guangzhou 510655, China); Gao, Hao (School of Mathematics and Statistics, University of Glasgow, Glasgow, UK); Maclellan, Calum (Centre for Signal and Image Processing, University of Strathclyde, Glasgow, UK); Zhao, Sophia (Centre for Signal and Image Processing, University of Strathclyde, Glasgow, UK); Luo, Xiaoyu (School of Mathematics and Statistics, University of Glasgow, Glasgow, UK)","Ren, Jinchang (Guangdong Polytechnic Normal University; Robert Gordon University); Zhao, Huimin (Guangdong Polytechnic Normal University)","Ren, Jinchang (Guangdong Polytechnic Normal University; Robert Gordon University); Sun, He (Beijing Institute of Technology); Zhao, Huimin (Guangdong Polytechnic Normal University); Gao, Hao (University of Glasgow); Maclellan, Calum (University of Strathclyde); Zhao, Sophia (University of Strathclyde); Luo, Xiaoyu (University of Glasgow)",5,5,,,https://rgu-repository.worktribe.com/preview/1569288/REN%202021%20Effective%20extraction%20of%20ventricles%20%28AAM%29.pdf,https://app.dimensions.ai/details/publication/pub.1142197671,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science,,,,,,,,,
1213,pub.1145203773,10.1016/j.oceaneng.2022.110578,,,Probabilistic prediction of the heave motions of a semi-submersible by a deep learning model,"The real-time motion prediction of a floating offshore platform refers to forecasting its motions in the following one- or two-wave cycles, which helps improve the performance of a motion compensation system and provides useful early warning information. In this study, we extend a deep learning (DL) model, which could give deterministic predictions about the heave motion of a floating semi-submersible 20 to 50 s ahead with good accuracy, to quantify its uncertainty of the predictive time series with the help of the dropout technique. By repeating the inference several times, it is found that the collection of the predictive time series is a Gaussian process (GP). The DL model with dropout learned a kernel inside, and the learning procedure was similar to GP regression. Adding noise into training data could help the model to learn more robust features from the training data, thereby leading to a better performance on test data with a wide noise level range. This study extends the understanding of the DL model to predict the wave excited motions of an offshore platform.","This study was supported by Major Science and Technology project of Hainan Province (ZDKJ2019001), Hainan Province Natural Science Foundation (521QN276) and Ministry of Industry and Information Technology of China (MC-202030-H04).",,Ocean Engineering,,,2022-03,2022,,2022-03,247,,110578,Closed,Article,"Guo, Xiaoxian; Zhang, Xiantao; Tian, Xinliang; Lu, Wenyue; Li, Xin","Guo, Xiaoxian (State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai 200240, China; SJTU Yazhou Bay Institute of Deepsea Technology, Sanya, Hainan, 572000, China); Zhang, Xiantao (State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai 200240, China; SJTU Yazhou Bay Institute of Deepsea Technology, Sanya, Hainan, 572000, China); Tian, Xinliang (State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai 200240, China; SJTU Yazhou Bay Institute of Deepsea Technology, Sanya, Hainan, 572000, China); Lu, Wenyue (State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai 200240, China; SJTU Yazhou Bay Institute of Deepsea Technology, Sanya, Hainan, 572000, China); Li, Xin (State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai 200240, China; SJTU Yazhou Bay Institute of Deepsea Technology, Sanya, Hainan, 572000, China)","Li, Xin (Shanghai Jiao Tong University; )","Guo, Xiaoxian (Shanghai Jiao Tong University); Zhang, Xiantao (Shanghai Jiao Tong University); Tian, Xinliang (Shanghai Jiao Tong University); Lu, Wenyue (Shanghai Jiao Tong University); Li, Xin (Shanghai Jiao Tong University)",5,5,,,,https://app.dimensions.ai/details/publication/pub.1145203773,40 Engineering, 4015 Maritime Engineering,,,,,,,,,,,
953,pub.1144162891,10.1016/j.knosys.2021.108021,,,Semi-supervised NPC segmentation with uncertainty and attention guided consistency,"Segmentation of nasopharyngeal carcinoma (NPC) from computed tomography (CT) image is conducive to the clinical healthcare. Nevertheless, due to the large shape variations, boundary ambiguity, as well as the limited available annotations, NPC segmentation remains to be a challenging task. In this paper, we propose a two-stage semi-supervised segmentation framework for automatic NPC segmentation, which includes a region of interest (ROI) cropping stage and a semi-supervised segmentation stage. Specifically, considering the large individual variability of NPC tumors, we first employ a coarse-Res-Unet (CRU) to extract the rough target areas from the CT images and thus obtain the cropped ROI images. Then, both the entire CT images and the corresponding ROI images are input to a self-attention embedded semi-supervised mean teacher (SSMT) model to generate the ROI-focused segmentation results. Here, to relieve the potential misdirection from the teacher model caused by annotation scarcity, we introduce the uncertainty estimation to guide the student model to gradually learn the reliable predictions from the teacher model. Meanwhile, to fully explore the inherent semantic information of unlabeled data, we also encourage the attention maps from these two models to be consistent at feature level. Furthermore, we design a refinement procedure and reuse the ROI attention maps generated by the well-trained SSMT to retrain the first stage, improving the quality of ROI images. The updated ROI images are further leveraged to refine SSMT to predict the final segmentation results. Note that the uncertainty estimation and the attention maps reveal the confidence and attention of the model for the intermediate features respectively, which can provide explainable evaluation to the quality of segmentation results. Experimental results on an in-house NPC dataset and a public 2017 ACDC dataset demonstrate that our method is superior to other semi-supervised segmentation methods and also has good generalization ability.","This work is supported by National Natural Science Foundation of China (NSFC 62071314) and Sichuan Science and Technology Program, China (2021YFG0326, 2020YFG0079).",,Knowledge-Based Systems,,,2022-03,2022,,2022-03,239,,108021,Closed,Article,"Hu, Lin; Li, Jiaxin; Peng, Xingchen; Xiao, Jianghong; Zhan, Bo; Zu, Chen; Wu, Xi; Zhou, Jiliu; Wang, Yan","Hu, Lin (School of Computer Science, Sichuan University, China); Li, Jiaxin (Department of Liver Surgery, West China Hospital, Sichuan University, China); Peng, Xingchen (Department of Biotherapy, Cancer Center, West China Hospital, Sichuan University, China); Xiao, Jianghong (Department of Radiation Oncology, Cancer Center, West China Hospital, Sichuan University, China); Zhan, Bo (School of Computer Science, Sichuan University, China); Zu, Chen (Department of Risk Controlling Research, JD.com, China); Wu, Xi (School of Computer Science, Chengdu University of Information Technology, China); Zhou, Jiliu (School of Computer Science, Sichuan University, China; School of Computer Science, Chengdu University of Information Technology, China); Wang, Yan (School of Computer Science, Sichuan University, China)","Wang, Yan (Sichuan University)","Hu, Lin (Sichuan University); Li, Jiaxin (Sichuan University; West China Hospital of Sichuan University); Peng, Xingchen (Sichuan University; West China Hospital of Sichuan University); Xiao, Jianghong (Sichuan University; West China Hospital of Sichuan University); Zhan, Bo (Sichuan University); Zu, Chen (Jingdong (China)); Wu, Xi (Chengdu University of Information Technology); Zhou, Jiliu (Sichuan University; Chengdu University of Information Technology); Wang, Yan (Sichuan University)",23,23,,,,https://app.dimensions.ai/details/publication/pub.1144162891,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
162,pub.1146099388,10.1016/s1936-878x(22)00098-5,,,Full Issue PDF,,,,JACC Cardiovascular Imaging,,,2022-03,2022,,2022-03,15,3,i-clxxiv,All OA, Bronze,Article,,,,,0,0,,,https://doi.org/10.1016/s1936-878x(22)00098-5,https://app.dimensions.ai/details/publication/pub.1146099388,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
862,pub.1145979358,10.48550/arxiv.2203.00131,,,"A Data-scalable Transformer for Medical Image Segmentation:  Architecture, Model Efficiency, and Benchmark","Transformer, as a new generation of neural architecture, has demonstrated
remarkable performance in natural language processing and computer vision.
However, existing vision Transformers struggle to learn with limited medical
data and are unable to generalize on diverse medical image tasks. To tackle
these challenges, we present MedFormer as a data-scalable Transformer towards
generalizable medical image segmentation. The key designs incorporate desirable
inductive bias, hierarchical modeling with linear-complexity attention, and
multi-scale feature fusion in a spatially and semantically global manner.
MedFormer can learn across tiny- to large-scale data without pre-training.
Extensive experiments demonstrate the potential of MedFormer as a general
segmentation backbone, outperforming CNNs and vision Transformers on three
public datasets with multiple modalities (e.g., CT and MRI) and diverse medical
targets (e.g., healthy organ, diseased tissue, and tumor). We make the models
and evaluation pipeline publicly available, offering solid baselines and
unbiased comparisons for promoting a wide range of downstream clinical
applications.",,,arXiv,,,2022-02-28,2022,,,,,,All OA, Green,Preprint,"Gao, Yunhe; Zhou, Mu; Liu, Di; Yan, Zhennan; Zhang, Shaoting; Metaxas, Dimitris N.","Gao, Yunhe (); Zhou, Mu (); Liu, Di (); Yan, Zhennan (); Zhang, Shaoting (); Metaxas, Dimitris N. ()",,"Gao, Yunhe (); Zhou, Mu (); Liu, Di (); Yan, Zhennan (); Zhang, Shaoting (); Metaxas, Dimitris N. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145979358,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5667,pub.1145860785,10.3389/fcvm.2022.804442,35282363,PMC8914019,Myocardial Segmentation of Cardiac MRI Sequences With Temporal Consistency for Coronary Artery Disease Diagnosis,"Coronary artery disease (CAD) is the most common cause of death globally, and its diagnosis is usually based on manual myocardial (MYO) segmentation of MRI sequences. As manual segmentation is tedious, time-consuming, and with low replicability, automatic MYO segmentation using machine learning techniques has been widely explored recently. However, almost all the existing methods treat the input MRI sequences independently, which fails to capture the temporal information between sequences, e.g., the shape and location information of the myocardium in sequences along time. In this article, we propose a MYO segmentation framework for sequence of cardiac MRI (CMR) scanning images of the left ventricular (LV) cavity, right ventricular (RV) cavity, and myocardium. Specifically, we propose to combine conventional neural networks and recurrent neural networks to incorporate temporal information between sequences to ensure temporal consistency. We evaluated our framework on the automated cardiac diagnosis challenge (ACDC) dataset. The experiment results demonstrate that our framework can improve the segmentation accuracy by up to 2% in the Dice coefficient.",,"This study was supported by the National Key Research and Development Program of China (No. 2018YFC1002600), the Science and Technology Planning Project of Guangdong Province, China (Nos. 2017B090904034, 2017B030314109, 2018B090944002, and 2019B020230003), Guangdong Peak Project (No. DFJH201802), and the National Natural Science Foundation of China (No. 62006050).",Frontiers in Cardiovascular Medicine,,,2022-02-25,2022,2022-02-25,,9,,804442,All OA, Gold,Article,"Chen, Yutian; Xie, Wen; Zhang, Jiawei; Qiu, Hailong; Zeng, Dewen; Shi, Yiyu; Yuan, Haiyun; Zhuang, Jian; Jia, Qianjun; Zhang, Yanchun; Dong, Yuhao; Huang, Meiping; Xu, Xiaowei","Chen, Yutian (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China; Department of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States); Xie, Wen (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China); Zhang, Jiawei (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, China); Qiu, Hailong (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China); Zeng, Dewen (Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, United States); Shi, Yiyu (Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, United States); Yuan, Haiyun (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China); Zhuang, Jian (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China); Jia, Qianjun (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Department of Catheterization Lab, Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China); Zhang, Yanchun (Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, China); Dong, Yuhao (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China; Department of Catheterization Lab, Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China); Huang, Meiping (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China; Department of Catheterization Lab, Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China); Xu, Xiaowei (Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of South China Structural Heart Disease, Guangdong Cardiovascular Institute, Guangzhou, China)","Dong, Yuhao (Guangdong Provincial People's Hospital; Guangdong General Hospital; ); Huang, Meiping (Guangdong Provincial People's Hospital; Guangdong General Hospital; ); Xu, Xiaowei (Guangdong Provincial People's Hospital; Guangdong General Hospital)","Chen, Yutian (Guangdong Provincial People's Hospital; Guangdong General Hospital; Carnegie Mellon University); Xie, Wen (Guangdong Provincial People's Hospital; Guangdong General Hospital); Zhang, Jiawei (Guangdong Provincial People's Hospital; Guangdong General Hospital; Guangzhou University); Qiu, Hailong (Guangdong Provincial People's Hospital; Guangdong General Hospital); Zeng, Dewen (University of Notre Dame); Shi, Yiyu (University of Notre Dame); Yuan, Haiyun (Guangdong Provincial People's Hospital; Guangdong General Hospital); Zhuang, Jian (Guangdong Provincial People's Hospital; Guangdong General Hospital); Jia, Qianjun (Guangdong Provincial People's Hospital); Zhang, Yanchun (Guangzhou University); Dong, Yuhao (Guangdong Provincial People's Hospital; Guangdong General Hospital); Huang, Meiping (Guangdong Provincial People's Hospital; Guangdong General Hospital); Xu, Xiaowei (Guangdong Provincial People's Hospital; Guangdong General Hospital)",1,1,,,https://www.frontiersin.org/articles/10.3389/fcvm.2022.804442/pdf,https://app.dimensions.ai/details/publication/pub.1145860785,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
4548,pub.1145819985,10.1016/j.cmpb.2022.106714,35263659,,Characterization of motion patterns by a spatio-temporal saliency descriptor in cardiac cine MRI,"BACKGROUND AND OBJECTIVE: Abnormalities of the heart motion reveal the presence of a disease. However, a quantitative interpretation of the motion is still a challenge due to the complex dynamics of the heart. This work proposes a quantitative characterization of regional cardiac motion patterns in cine magnetic resonance imaging (MRI) by a novel spatio-temporal saliency descriptor.
METHOD: The strategy starts by dividing the cardiac sequence into a progression of scales which are in due turn mapped to a feature space of regional orientation changes, mimicking the multi-resolution decomposition of oriented primitive changes of visual systems. These changes are estimated as the difference between a particular time and the rest of the sequence. This decomposition is then temporarily and regionally integrated for a particular orientation and then for the set of different orientations. A final spatio-temporal 4D saliency map is obtained as the summation of the previously integrated information for the available scales. The saliency dispersion of this map was computed in standard cardiac locations as a measure of the regional motion pattern and was applied to discriminate control and hypertrophic cardiomyopathy (HCM) subjects during the diastolic phase.
RESULTS: Salient motion patterns were estimated from an experimental set, which consisted of 3D sequences acquired by MRI from 108 subjects (33 control, 35 HCM, 20 dilated cardiomyopathy (DCM), and 20 myocardial infarction (MINF) from heterogeneous datasets). HCM and control subjects were classified by an SVM that learned the salient motion patterns estimated from the presented strategy, by achieving a 94% AUC. In addition, statistical differences (test t-student, p<0.05) were found among groups of disease in the septal and anterior ventricular segments at both the ED and ES, with salient motion characteristics aligned with existing knowledge on the diseases.
CONCLUSIONS: Regional wall motion abnormality in the apical, anterior, basal, and inferior segments was associated with the saliency dispersion in HCM, DCM, and MINF compared to healthy controls during the systolic and diastolic phases. This saliency analysis may be used to detect subtle changes in heart function.","This work was supported by Colciencias-Colombia, Grant No. 647 (2015 call for National PhD studies), and Région Bretagne in the framework of the Investissement d’Avenir Program through Labex CAMI (ANR-11-LABX-0004).",,Computer Methods and Programs in Biomedicine,,"Cardiomyopathy, Hypertrophic; Heart; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Myocardial Infarction",2022-02-25,2022,2022-02-25,2022-05,218,,106714,All OA, Green,Article,"Atehortúa, Angélica; Romero, Eduardo; Garreau, Mireille","Atehortúa, Angélica (Universidad Nacional de Colombia, Bogotá, Colombia; Univ Rennes, Inserm, LTSI UMR 1099, Rennes F-35000, France.); Romero, Eduardo (Universidad Nacional de Colombia, Bogotá, Colombia. Electronic address: edromero@unal.edu.co.); Garreau, Mireille (Univ Rennes, Inserm, LTSI UMR 1099, Rennes F-35000, France.)","Romero, Eduardo (National University of Colombia)","Atehortúa, Angélica (National University of Colombia; University of Rennes 1); Romero, Eduardo (National University of Colombia); Garreau, Mireille (University of Rennes 1)",0,0,,,https://hal.archives-ouvertes.fr/hal-03631174/file/Atehort%C3%BAa%20et%20al-2022-Characterization%20of%20motion%20patterns%20by%20a%20spatio-temporal%20saliency%20descriptor%20in.pdf,https://app.dimensions.ai/details/publication/pub.1145819985,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1255,pub.1145794593,10.21203/rs.3.rs-1378033/v1,,,Performance of Artificial Intelligence for Biventricular Cardiovascular Magnetic Resonance Volumetric Analysis in the Clinical Setting,"Background Cardiovascular magnetic resonance (CMR) derived ventricular volumes and function guide clinical decision-making for various cardiac pathologies. We aimed to evaluate the efficiency and clinical applicability of a commercially available artificial intelligence (AI) method for performing biventricular volumetric analysis.Methods Three-hundred CMR studies (100 with normal CMR findings, 50 dilated cardiomyopathy, 50 hypertrophic cardiomyopathy, 50 ischaemic heart disease and 50 congenital or valvular heart disease) were randomly selected from database. Manual biventricular volumetric analysis (CMRtools) results were derived from clinical reports and automated volumetric analyses were performed using short axis volumetry AI function of CircleCVI42v5.12 software. For 20 studies, a combined method of manually adjusted AI contours was tested and all three methods were timed. Clinicians` confidence in AI method was assessed using an online survey.Results Although agreement was better for left ventricle than right ventricle, AI analysis results were comparable to manual method. Manual adjustment of AI contours further improved agreement: within subject coefficient of variation decreased from 5.0–4.5% for left ventricular ejection fraction (EF) and from 9.9–7.1% for right ventricular EF. Twenty manual analyses were performed in 250min12s whereas same task took 5min48s using AI method. Clinicians were open to adopt AI but concerns about accuracy and validity were raised.Conclusions The AI method provides clinically valid outcomes and saves significant time. To address concerns raised by survey participants and overcome shortcomings of the automated myocardial segmentation, visual assessment of contours and performing manual corrections where necessary appears to be a practical approach.",,,Research Square,,,2022-02-23,2022,2022-02-23,,,,,All OA, Green,Preprint,"Hatipoglu, Suzan; Mohiaddin, Raad H; Gatehouse, Peter; Alpendurada, Francisco; Baksi, A. John; Izgi, Cemil; Prasad, Sanjay K.; Pennell, Dudley J; Krupickova, MD Sylvia","Hatipoglu, Suzan (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Mohiaddin, Raad H (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Gatehouse, Peter (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Alpendurada, Francisco (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Baksi, A. John (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Izgi, Cemil (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Prasad, Sanjay K. (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Pennell, Dudley J (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals); Krupickova, MD Sylvia (Royal Brompton and Harefield NHS Trust: Royal Brompton and Harefield Hospitals)",,"Hatipoglu, Suzan (); Mohiaddin, Raad H (); Gatehouse, Peter (); Alpendurada, Francisco (); Baksi, A. John (); Izgi, Cemil (); Prasad, Sanjay K. (); Pennell, Dudley J (); Krupickova, MD Sylvia ()",0,0,,,https://www.researchsquare.com/article/rs-1378033/latest.pdf,https://app.dimensions.ai/details/publication/pub.1145794593,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
1399,pub.1146173806,10.52547/jist.16121.10.37.61,,,Deep Learning Approach for Cardiac MRI Images,"Deep Learning (DL) is the most widely used image-analysis process, especially in medical image processing. Though DL has entered image processing to solve Machine Learning (ML) problems, identifying the most suitable model based on evaluation of the epochs is still an open question for scholars in the field. There are so many types of function approximators like Decision Tree, Gaussian Processes and Deep Learning, used in multi-layered Neural Networks (NNs), which should be evaluated to determine their effectiveness. Therefore, this study aimed to assess an approach based on DL techniques for modern medical imaging methods according to Magnetic Resonance Imaging (MRI) segmentation. To do so, an experiment with a random sampling approach was conducted. One hundred patient cases were used in this study for training, validation, and testing. The method used in this study was based on full automatic processing of segmentation and disease classification based on MRI images. U-Net structure was used for the segmentation process, with the use of cardiac Right Ventricular Cavity (RVC), Left Ventricular Cavity (LVC), Left Ventricular Myocardium (LVM), and information extracted from the segmentation step. With train and using random forest classifier, and Multilayer Perceptron (MLP), the task of predicting the pathologic target class was conducted. Segmentation extracted information was in the form of comprehensive features handcrafted to reflect demonstrative clinical strategies. Our study suggests 92% test accuracy for cardiac MRI image segmentation and classification. As for the MLP ensemble, and for the random forest, test accuracy was equal to 91% and 90%, respectively. This study has implications for scholars in the field of medical image processing.",,,Journal of Information Systems and Telecommunication (JIST),,,2022-02-19,2022,2022-02-19,,1,37,61,All OA, Gold,Article,"Sandooghdar, Afshin; Yaghmaee, Farzin","Sandooghdar, Afshin (); Yaghmaee, Farzin ()",,"Sandooghdar, Afshin (); Yaghmaee, Farzin ()",1,1,,,http://jist.ir/Article/Download/16121,https://app.dimensions.ai/details/publication/pub.1146173806,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4788,pub.1145701452,10.1016/j.media.2022.102389,35219940,,DeU-Net 2.0: Enhanced deformable U-Net for 3D cardiac cine MRI segmentation,"Automatic segmentation of cardiac magnetic resonance imaging (MRI) facilitates efficient and accurate volume measurement in clinical applications. However, due to anisotropic resolution, ambiguous borders and complicated shapes, existing methods suffer from the degradation of accuracy and robustness in cardiac MRI segmentation. In this paper, we propose an enhanced Deformable U-Net (DeU-Net) for 3D cardiac cine MRI segmentation, composed of three modules, namely Temporal Deformable Aggregation Module (TDAM), Enhanced Deformable Attention Network (EDAN), and Probabilistic Noise Correction Module (PNCM). TDAM first takes consecutive cardiac MR slices (including a target slice and its neighboring reference slices) as input, and extracts spatio-temporal information by an offset prediction network to generate fused features of the target slice. Then the fused features are also fed into EDAN that exploits several flexible deformable convolutional layers and generates clear borders of every segmentation map. A Multi-Scale Attention Module (MSAM) in EDAN is proposed to capture long range dependencies between features of different scales. Meanwhile, PNCM treats the fused features as a distribution to quantify uncertainty. Experimental results show that our DeU-Net achieves the state-of-the-art performance in terms of the commonly used evaluation metrics on the Extended ACDC dataset and competitive performance on other two datasets, validating the robustness and generalization of DeU-Net.","This work was supported by grant from the National Science Foundation of China (No. 62034007 and No. 62141404), the Zhejiang Provincial Innovation Team Project under No. 2020R01001, the Fundamental Research Funds for the Central Universities under Grant 2021FZZX001-20, and the Zhejiang Lab’s International Talent Fund for Young Professionals under No. ZJ2020JS013.",,Medical Image Analysis,,"Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2022-02-18,2022,2022-02-18,2022-05,78,,102389,Closed,Article,"Dong, Shunjie; Pan, Zixuan; Fu, Yu; Yang, Qianqian; Gao, Yuanxue; Yu, Tianbai; Shi, Yiyu; Zhuo, Cheng","Dong, Shunjie (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China.); Pan, Zixuan (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China.); Fu, Yu (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China.); Yang, Qianqian (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China.); Gao, Yuanxue (Department of Radiology, The First Affiliated Hospital of Zhejiang University School of Medicine, Hangzhou, China.); Yu, Tianbai (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China.); Shi, Yiyu (Sustainable Computing Laboratory, University of Notre Dame, Notre Dame, USA.); Zhuo, Cheng (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China. Electronic address: czhuo@zju.edu.cn.)","Zhuo, Cheng (Zhejiang University)","Dong, Shunjie (Zhejiang University); Pan, Zixuan (Zhejiang University); Fu, Yu (Zhejiang University); Yang, Qianqian (Zhejiang University); Gao, Yuanxue (First Affiliated Hospital Zhejiang University); Yu, Tianbai (Zhejiang University); Shi, Yiyu (University of Notre Dame); Zhuo, Cheng (Zhejiang University)",6,6,,,,https://app.dimensions.ai/details/publication/pub.1145701452,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
1066,pub.1148944488,10.1007/978-3-030-03009-4_109-1,,,Variational Models and Their Combinations with Deep Learning in Medical Image Segmentation: A Survey,"Image segmentation means to partition an image into separate meaningful regions. Segmentation in medical images can extract different organs, lesions, and other regions of interest, which helps in subsequent disease diagnosis, surgery planning, and efficacy assessment. However, medical images have many unavoidable interference factors, such as imaging noise, artificial artifacts, and mutual occlusion of organs, which make accurate segmentation highly difficult. Incorporating prior knowledge and image information into segmentation model based on variational methods has proven efficient for more accurate segmentation. In recent years, segmentation based on deep learning has been significantly developed, and the combination of classical variational method-based models with deep learning is a hot topic. In this survey, we briefly review the segmentation methods based on a variational method making use of image information and regularity information. Subsequently, we clarify how the integration of variational methods into the deep learning framework leads to more precise segmentation results.",,,,Handbook of Mathematical Models and Algorithms in Computer Vision and Imaging,,2022-02-18,2022,2022-02-18,2022,,,1-22,Closed,Chapter,"Gui, Luying; Ma, Jun; Yang, Xiaoping","Gui, Luying (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China); Ma, Jun (Department of Mathematics, Nanjing University, Nanjing, China); Yang, Xiaoping (Department of Mathematics, Nanjing University, Nanjing, China)","Yang, Xiaoping (Nanjing University)","Gui, Luying (Nanjing University of Science and Technology); Ma, Jun (Nanjing University); Yang, Xiaoping (Nanjing University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148944488,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
866,pub.1145731010,10.48550/arxiv.2202.09258,,,Autoencoding Low-Resolution MRI for Semantically Smooth Interpolation of  Anisotropic MRI,"High-resolution medical images are beneficial for analysis but their
acquisition may not always be feasible. Alternatively, high-resolution images
can be created from low-resolution acquisitions using conventional upsampling
methods, but such methods cannot exploit high-level contextual information
contained in the images. Recently, better performing deep-learning based
super-resolution methods have been introduced. However, these methods are
limited by their supervised character, i.e. they require high-resolution
examples for training. Instead, we propose an unsupervised deep learning
semantic interpolation approach that synthesizes new intermediate slices from
encoded low-resolution examples. To achieve semantically smooth interpolation
in through-plane direction, the method exploits the latent space generated by
autoencoders. To generate new intermediate slices, latent space encodings of
two spatially adjacent slices are combined using their convex combination.
Subsequently, the combined encoding is decoded to an intermediate slice. To
constrain the model, a notion of semantic similarity is defined for a given
dataset. For this, a new loss is introduced that exploits the spatial
relationship between slices of the same volume. During training, an existing
in-between slice is generated using a convex combination of its neighboring
slice encodings. The method was trained and evaluated using publicly available
cardiac cine, neonatal brain and adult brain MRI scans. In all evaluations, the
new method produces significantly better results in terms of Structural
Similarity Index Measure and Peak Signal-to-Noise Ratio (p< 0.001 using
one-sided Wilcoxon signed-rank test) than a cubic B-spline interpolation
approach. Given the unsupervised nature of the method, high-resolution training
data is not required and hence, the method can be readily applied in clinical
settings.",,,arXiv,,,2022-02-18,2022,,,,,,All OA, Green,Preprint,"Sander, Jörg; de Vos, Bob D.; Išgum, Ivana","Sander, Jörg (); de Vos, Bob D. (); Išgum, Ivana ()",,"Sander, Jörg (); de Vos, Bob D. (); Išgum, Ivana ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145731010,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
6048,pub.1145662339,10.1007/s00330-022-08616-7,35175379,,Fully automated intracardiac 4D flow MRI post-processing using deep learning for biventricular segmentation,"Objectives4D flow MRI allows for a comprehensive assessment of intracardiac blood flow, useful for assessing cardiovascular diseases, but post-processing requires time-consuming ventricular segmentation throughout the cardiac cycle and is prone to subjective errors. Here, we evaluate the use of automatic left and right ventricular (LV and RV) segmentation based on deep learning (DL) network that operates on short-axis cine bSSFP images.MethodsA previously published DL network was fine-tuned via retraining on a local database of 106 subjects scanned at our institution. In 26 test subjects, the ventricles were segmented automatically by the network and manually by 3 human observers on bSSFP MRI. The bSSFP images were then registered to the corresponding 4D flow images to apply the segmentation to 4D flow velocity data. Dice coefficients and the relative deviation between measurements (automatic vs. manual and interobserver manual) of various hemodynamic parameters were assessed.ResultsThe automated segmentation resulted in similar Dice scores (LV: 0.92, RV: 0.86) and lower relative deviations from manual segmentation in left ventricular (LV) average kinetic energy (KE) (8%) and RV KE (15%) than the Dice scores (LV: 0.91, RV: 0.87) and relative deviations between manual segmentation observers (LV KE: 11%, p = 0.01; RV KE: 19%, p = 0.03).ConclusionsThe automated post-processing method using deep learning resulted in hemodynamic measurements that differ from a manual observer’s measurements equally or less than the variation between manual observers. This approach can be used to decrease post-processing time on intraventricular 4D flow data and mitigate interobserver variability.Key Points• Our proposed method allows for fully automated post-processing of intraventricular 4D flow MRI data.• Our method resulted in hemodynamic measurements that matched those derived from manual segmentation equally as well as  interobserver variability.• Our method can be used to greatly accelerate intraventricular 4D flow post-processing and improve interobserver repeatability.",,The authors state that this work has not received any funding.,European Radiology,,"Deep Learning; Heart; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Observer Variation",2022-02-17,2022,2022-02-17,2022-08,32,8,5669-5678,Closed,Article,"Corrado, Philip A.; Wentland, Andrew L.; Starekova, Jitka; Dhyani, Archana; Goss, Kara N.; Wieben, Oliver","Corrado, Philip A. (University of Wisconsin-Madison, 1111 Highland Ave, 53705, Madison, WI, USA); Wentland, Andrew L. (University of Wisconsin-Madison, 1111 Highland Ave, 53705, Madison, WI, USA); Starekova, Jitka (University of Wisconsin-Madison, 1111 Highland Ave, 53705, Madison, WI, USA); Dhyani, Archana (University of Wisconsin-Madison, 1111 Highland Ave, 53705, Madison, WI, USA); Goss, Kara N. (UT Southwestern Medical Center, 5323 Harry Hines Blvd., 75390, Dallas, TX, USA); Wieben, Oliver (University of Wisconsin-Madison, 1111 Highland Ave, 53705, Madison, WI, USA)","Corrado, Philip A. (University of Wisconsin–Madison)","Corrado, Philip A. (University of Wisconsin–Madison); Wentland, Andrew L. (University of Wisconsin–Madison); Starekova, Jitka (University of Wisconsin–Madison); Dhyani, Archana (University of Wisconsin–Madison); Goss, Kara N. (The University of Texas Southwestern Medical Center); Wieben, Oliver (University of Wisconsin–Madison)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1145662339,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,,
5855,pub.1145620873,10.3389/fcvm.2021.816985,35242820,PMC8886212,A Systematic Quality Scoring Analysis to Assess Automated Cardiovascular Magnetic Resonance Segmentation Algorithms,"BACKGROUND: The quantitative measures used to assess the performance of automated methods often do not reflect the clinical acceptability of contouring. A quality-based assessment of automated cardiac magnetic resonance (CMR) segmentation more relevant to clinical practice is therefore needed.
OBJECTIVE: We propose a new method for assessing the quality of machine learning (ML) outputs. We evaluate the clinical utility of the proposed method as it is employed to systematically analyse the quality of an automated contouring algorithm.
METHODS: A dataset of short-axis (SAX) cine CMR images from a clinically heterogeneous population (n = 217) were manually contoured by a team of experienced investigators. On the same images we derived automated contours using a ML algorithm. A contour quality scoring application randomly presented manual and automated contours to four blinded clinicians, who were asked to assign a quality score from a predefined rubric. Firstly, we analyzed the distribution of quality scores between the two contouring methods across all clinicians. Secondly, we analyzed the interobserver reliability between the raters. Finally, we examined whether there was a variation in scores based on the type of contour, SAX slice level, and underlying disease.
RESULTS: The overall distribution of scores between the two methods was significantly different, with automated contours scoring better than the manual (OR (95% CI) = 1.17 (1.07-1.28), p = 0.001; n = 9401). There was substantial scoring agreement between raters for each contouring method independently, albeit it was significantly better for automated segmentation (automated: AC2 = 0.940, 95% CI, 0.937-0.943 vs manual: AC2 = 0.934, 95% CI, 0.931-0.937; p = 0.006). Next, the analysis of quality scores based on different factors was performed. Our approach helped identify trends patterns of lower segmentation quality as observed for left ventricle epicardial and basal contours with both methods. Similarly, significant differences in quality between the two methods were also found in dilated cardiomyopathy and hypertension.
CONCLUSIONS: Our results confirm the ability of our systematic scoring analysis to determine the clinical acceptability of automated contours. This approach focused on the contours' clinical utility could ultimately improve clinicians' confidence in artificial intelligence and its acceptability in the clinical workflow.",,"SEP acknowledges support from the National Institute for Health Research (NIHR) Biomedical Research Center at Barts. SEP acknowledges the British Heart Foundation for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5000 CMR scans (www.bhf.org.uk; PG/14/89/31194). SEP acknowledges support from the SmartHeart EPSRC programme grant (www.nihr.ac.uk; EP/P001009/1). SEP and ER also acknowledge support from the London Medical Imaging and Artificial Intelligence Center for Value Based Healthcare (AI4VBH), which is funded from the Data to Early Diagnosis and Precision Medicine strand of the government's Industrial Strategy Challenge Fund, managed and delivered by Innovate UK on behalf of UK Research and Innovation (UKRI). N.A. recognizes the National Institute for Health Research (NIHR) Integrated Academic Training programme which supports his Academic Clinical Lectureship post. DJH is supported by the Duke-NUS Signature Research Programme funded by the Ministry of Health, Singapore Ministry of Health's National Medical Research Council under its Clinician Scientist-Senior Investigator scheme (NMRC/CSA-SI/0011/2017), Centre Grant (CGAug16M006), and Collaborative Centre Grant scheme (NMRC/CGAug16C006).",Frontiers in Cardiovascular Medicine,,,2022-02-15,2022,2022-02-15,,8,,816985,All OA, Gold,Article,"Rauseo, Elisa; Omer, Muhammad; Amir-Khalili, Alborz; Sojoudi, Alireza; Le, Thu-Thao; Cook, Stuart Alexander; Hausenloy, Derek John; Ang, Briana; Toh, Desiree-Faye; Bryant, Jennifer; Chin, Calvin Woon Loong; Paiva, Jose Miguel; Fung, Kenneth; Cooper, Jackie; Khanji, Mohammed Yunus; Aung, Nay; Petersen, Steffen Erhard","Rauseo, Elisa (NIHR Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University, London, United Kingdom; Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, London, United Kingdom); Omer, Muhammad (Circle Cardiovascular Imaging, Calgary, AB, Canada); Amir-Khalili, Alborz (Circle Cardiovascular Imaging, Calgary, AB, Canada); Sojoudi, Alireza (Circle Cardiovascular Imaging, Calgary, AB, Canada); Le, Thu-Thao (National Heart Centre Singapore, Singapore, Singapore); Cook, Stuart Alexander (National Heart Centre Singapore, Singapore, Singapore; Cardiovascular and Metabolic Disorders Program, Duke-National University of Singapore, Singapore, Singapore); Hausenloy, Derek John (National Heart Centre Singapore, Singapore, Singapore; Cardiovascular and Metabolic Disorders Program, Duke-National University of Singapore, Singapore, Singapore; Yong Loo Lin School of Medicine, National University Singapore, Singapore, Singapore; The Hatter Cardiovascular Institute, University College London, London, United Kingdom; Cardiovascular Research Center, College of Medical and Health Sciences, Asia University, Taichung, Taiwan); Ang, Briana (National Heart Centre Singapore, Singapore, Singapore); Toh, Desiree-Faye (National Heart Centre Singapore, Singapore, Singapore); Bryant, Jennifer (National Heart Centre Singapore, Singapore, Singapore); Chin, Calvin Woon Loong (National Heart Centre Singapore, Singapore, Singapore); Paiva, Jose Miguel (Circle Cardiovascular Imaging, Calgary, AB, Canada); Fung, Kenneth (NIHR Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University, London, United Kingdom; Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, London, United Kingdom); Cooper, Jackie (NIHR Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University, London, United Kingdom); Khanji, Mohammed Yunus (NIHR Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University, London, United Kingdom; Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, London, United Kingdom; Department of Cardiology, Newham University Hospital, Barts Health NHS Trust, London, United Kingdom); Aung, Nay (NIHR Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University, London, United Kingdom; Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, London, United Kingdom); Petersen, Steffen Erhard (NIHR Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University, London, United Kingdom; Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, London, United Kingdom; Health Data Research UK, London, United Kingdom; Alan Turing Institute, London, United Kingdom)","Petersen, Steffen Erhard (Queen Mary University of London; St Bartholomew's Hospital; Health Data Research UK; The Alan Turing Institute)","Rauseo, Elisa (Queen Mary University of London; St Bartholomew's Hospital); Omer, Muhammad (Circle Cardiovascular Imaging); Amir-Khalili, Alborz (Circle Cardiovascular Imaging); Sojoudi, Alireza (Circle Cardiovascular Imaging); Le, Thu-Thao (National Heart Centre Singapore); Cook, Stuart Alexander (National Heart Centre Singapore; Duke NUS Graduate Medical School); Hausenloy, Derek John (National Heart Centre Singapore; Duke NUS Graduate Medical School; National University of Singapore; University College London; Asian University); Ang, Briana (National Heart Centre Singapore); Toh, Desiree-Faye (National Heart Centre Singapore); Bryant, Jennifer (National Heart Centre Singapore); Chin, Calvin Woon Loong (National Heart Centre Singapore); Paiva, Jose Miguel (Circle Cardiovascular Imaging); Fung, Kenneth (Queen Mary University of London; St Bartholomew's Hospital); Cooper, Jackie (Queen Mary University of London); Khanji, Mohammed Yunus (Queen Mary University of London; St Bartholomew's Hospital; Newham University Hospital); Aung, Nay (Queen Mary University of London; St Bartholomew's Hospital); Petersen, Steffen Erhard (Queen Mary University of London; St Bartholomew's Hospital; Health Data Research UK; The Alan Turing Institute)",1,1,,,https://www.frontiersin.org/articles/10.3389/fcvm.2021.816985/pdf,https://app.dimensions.ai/details/publication/pub.1145620873,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
4332,pub.1145527042,10.1016/j.media.2022.102393,35228070,,Autoencoding low-resolution MRI for semantically smooth interpolation of anisotropic MRI,"High-resolution medical images are beneficial for analysis but their acquisition may not always be feasible. Alternatively, high-resolution images can be created from low-resolution acquisitions using conventional upsampling methods, but such methods cannot exploit high-level contextual information contained in the images. Recently, better performing deep-learning based super-resolution methods have been introduced. However, these methods are limited by their supervised character, i.e. they require high-resolution examples for training. Instead, we propose an unsupervised deep learning semantic interpolation approach that synthesizes new intermediate slices from encoded low-resolution examples. To achieve semantically smooth interpolation in through-plane direction, the method exploits the latent space generated by autoencoders. To generate new intermediate slices, latent space encodings of two spatially adjacent slices are combined using their convex combination. Subsequently, the combined encoding is decoded to an intermediate slice. To constrain the model, a notion of semantic similarity is defined for a given dataset. For this, a new loss is introduced that exploits the spatial relationship between slices of the same volume. During training, an existing in-between slice is generated using a convex combination of its neighboring slice encodings. The method was trained and evaluated using publicly available cardiac cine, neonatal brain and adult brain MRI scans. In all evaluations, the new method produces significantly better results in terms of Structural Similarity Index Measure and Peak Signal-to-Noise Ratio (p<0.001 using one-sided Wilcoxon signed-rank test) than a cubic B-spline interpolation approach. Given the unsupervised nature of the method, high-resolution training data is not required and hence, the method can be readily applied in clinical settings.",This study was performed within the DLMedIA program (P15-26) funded by Dutch Technology Foundation with participation of Pie Medical Imaging.,,Medical Image Analysis,,"Adult; Anisotropy; Brain; Heart; Humans; Image Processing, Computer-Assisted; Infant, Newborn; Magnetic Resonance Imaging; Signal-To-Noise Ratio",2022-02-15,2022,2022-02-15,2022-05,78,,102393,All OA, Hybrid,Article,"Sander, Jörg; de Vos, Bob D; Išgum, Ivana","Sander, Jörg (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - location AMC, University of Amsterdam, the Netherlands; Informatics Institute, University of Amsterdam, the Netherlands. Electronic address: j.sander1@amsterdamumc.nl.); de Vos, Bob D (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - location AMC, University of Amsterdam, the Netherlands; Amsterdam Cardiovascular Sciences, Amsterdam University Medical Centers - location AMC, University of Amsterdam, the Netherlands; Informatics Institute, University of Amsterdam, the Netherlands.); Išgum, Ivana (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - location AMC, University of Amsterdam, the Netherlands; Amsterdam Cardiovascular Sciences, Amsterdam University Medical Centers - location AMC, University of Amsterdam, the Netherlands; Department of Radiology and Nuclear Medicine, Amsterdam University Medical Centers - location AMC, University of Amsterdam, the Netherlands; Informatics Institute, University of Amsterdam, the Netherlands.)","Sander, Jörg (University of Amsterdam)","Sander, Jörg (University of Amsterdam); de Vos, Bob D (University of Amsterdam); Išgum, Ivana (University of Amsterdam)",1,1,,,https://doi.org/10.1016/j.media.2022.102393,https://app.dimensions.ai/details/publication/pub.1145527042,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
5851,pub.1145515617,10.1038/s41598-022-06315-3,35165324,PMC8844403,Improving robustness of automatic cardiac function quantification from cine magnetic resonance imaging using synthetic image data,"Although having been the subject of intense research over the years, cardiac function quantification from MRI is still not a fully automatic process in the clinical practice. This is partly due to the shortage of training data covering all relevant cardiovascular disease phenotypes. We propose to synthetically generate short axis CINE MRI using a generative adversarial model to expand the available data sets that consist of predominantly healthy subjects to include more cases with reduced ejection fraction. We introduce a deep learning convolutional neural network (CNN) to predict the end-diastolic volume, end-systolic volume, and implicitly the ejection fraction from cardiac MRI without explicit segmentation. The left ventricle volume predictions were compared to the ground truth values, showing superior accuracy compared to state-of-the-art segmentation methods. We show that using synthetic data generated for pre-training a CNN significantly improves the prediction compared to only using the limited amount of available data, when the training set is imbalanced.","This research has been conducted using the UK Biobank Resource (access application 2964). The Data Science Bowl Cardiac Challenge Data was originally provided and publicly released by the National Heart, Lung, and Blood Institute (NHLBI). Special thanks to NHLBI Intramural Investigators Dr. Michael Hansen and Dr. Andrew Arai. We also acknowledge the support of Mr. Indraneel Borgohain for data processing. This work was partly funded by the European Union’s Horizon 2020 research and innovation programme under grant agreement No 825903 (euCanSHare project). SEP and AML acknowledges support from the National Institute for Health Research (NIHR) Biomedical Research Centre at Barts, from the SmartHeart EPSRC programme grant (EP/P001009/1) and the London Medical Imaging and AI Centre for Value-Based Healthcare. SEP acknowledges support from the CAP-AI programme, London’s first AI enabling programme focused on stimulating growth in the capital’s AI sector. SEP, SN and SKP acknowledge the British Heart Foundation for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5000 CMR scans (PG/14/89/31194). This project was enabled through access to the Medical Research Council eMedLab Medical Bioinformatics infrastructure, supported by the Medical Research Council (MR/L016311/1). This work was partially supported by a grant of the Romanian Ministry of Education and Research, CNCS—UEFISCDI, project number PN-III-P1-1.1-TE-2019-1804, within PNCDI III.",,Scientific Reports,,"Deep Learning; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Neural Networks, Computer; Stroke Volume; Ventricular Function, Left",2022-02-14,2022,2022-02-14,,12,1,2391,All OA, Gold,Article,"Gheorghiță, Bogdan A.; Itu, Lucian M.; Sharma, Puneet; Suciu, Constantin; Wetzl, Jens; Geppert, Christian; Ali, Mohamed Ali Asik; Lee, Aaron M.; Piechnik, Stefan K.; Neubauer, Stefan; Petersen, Steffen E.; Schulz-Menger, Jeanette; Chițiboi, Teodora","Gheorghiță, Bogdan A. (Advanta, Siemens SRL, Brașov, Romania; Systems Engineering, Transilvania University of Brașov, Brașov, Romania); Itu, Lucian M. (Advanta, Siemens SRL, Brașov, Romania; Systems Engineering, Transilvania University of Brașov, Brașov, Romania); Sharma, Puneet (Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA); Suciu, Constantin (Advanta, Siemens SRL, Brașov, Romania; Systems Engineering, Transilvania University of Brașov, Brașov, Romania); Wetzl, Jens (Magnetic Resonance, Siemens Healthineers, Erlangen, Germany); Geppert, Christian (Magnetic Resonance, Siemens Healthineers, Erlangen, Germany); Ali, Mohamed Ali Asik (Digital Technology and Innovation, Siemens Healthineers, Bangalore, India); Lee, Aaron M. (William Harvey Research Institute, NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK; Barts Heart Centre, St Bartholomew’s Hospital, Barts Health NHS Trust, West Smithfield, London, UK); Piechnik, Stefan K. (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Neubauer, Stefan (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Petersen, Steffen E. (William Harvey Research Institute, NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK; Barts Heart Centre, St Bartholomew’s Hospital, Barts Health NHS Trust, West Smithfield, London, UK; Health Data Research UK, London, UK; The Alan Turing Institute, London, UK); Schulz-Menger, Jeanette (Charité-Universitätsmedizin Berlin, Experimental and Clinical Research Center, Working Group On CMR and HELIOS Klinikum Berlin Buch, Cardiology Berlin, DZHK partnersite Berlin, Berlin, Germany); Chițiboi, Teodora (Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA)","Gheorghiță, Bogdan A. (; Transylvania University of Brașov)","Gheorghiță, Bogdan A. (Transylvania University of Brașov); Itu, Lucian M. (Transylvania University of Brașov); Sharma, Puneet (Siemens Healthcare (United States)); Suciu, Constantin (Transylvania University of Brașov); Wetzl, Jens (Siemens (Germany)); Geppert, Christian (Siemens (Germany)); Ali, Mohamed Ali Asik (); Lee, Aaron M. (Queen Mary University of London; St Bartholomew's Hospital); Piechnik, Stefan K. (University of Oxford); Neubauer, Stefan (University of Oxford); Petersen, Steffen E. (Queen Mary University of London; St Bartholomew's Hospital; Health Data Research UK; The Alan Turing Institute); Schulz-Menger, Jeanette (Charité - University Medicine Berlin); Chițiboi, Teodora (Siemens Healthcare (United States))",1,1,,,https://www.nature.com/articles/s41598-022-06315-3.pdf,https://app.dimensions.ai/details/publication/pub.1145515617,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
1177,pub.1145475399,10.1109/tetci.2022.3146965,,,Feature Pyramid Network With Level-Aware Attention for Meningioma Segmentation,"Meningiomas are the most common primary intracranial tumors in adults, and they are dangerous and even lethal when they grow and oppress vital organs. In clinical, microsurgical resection is the most widely used treatment for most meningiomas. And tumor segmentation is an essential primary step before applying any therapy. However, due to the various meningioma locations and complicated intracranial structures, it is still challenging to segment the tumor accurately in both boundaries and contour automatically. In this work, a novel method is proposed for the automatic segmentation of meningioma. In general, the proposed method follows a coarse-to-fine strategy. Specifically, the feature pyramid structure is employed to extract multi-level features. Further, a Level-aware Attention is proposed to refine multi-level features by naturally utilizing the complementary features of different levels, thus significantly improving the segmentation performance. Moreover, to validate the proposed method, a realistic dataset of meningioma with fine labels is constructed, and experimental results on the dataset demonstrate the effectiveness of the proposed method.",,This work was supported in part by the National Natural Science Fund for Distinguished Young Scholar under Grant 62025601.,IEEE Transactions on Emerging Topics in Computational Intelligence,,,2022-02-11,2022,2022-02-11,,6,5,1201-1210,Closed,Article,"Huang, Wei; Shu, Xin; Wang, Zizhou; Zhang, Lei; Chen, Chaoyue; Xu, Jianguo; Yi, Zhang","Huang, Wei (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China); Shu, Xin (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China); Wang, Zizhou (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China); Zhang, Lei (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China); Chen, Chaoyue (Department of Neurosurgery, West China Hospital, Sichuan University, Chengdu, 610041, China); Xu, Jianguo (Department of Neurosurgery, West China Hospital, Sichuan University, Chengdu, 610041, China); Yi, Zhang (Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China)","Zhang, Lei (Sichuan University)","Huang, Wei (Sichuan University); Shu, Xin (Sichuan University); Wang, Zizhou (Sichuan University); Zhang, Lei (Sichuan University); Chen, Chaoyue (Sichuan University; West China Hospital of Sichuan University); Xu, Jianguo (Sichuan University; West China Hospital of Sichuan University); Yi, Zhang (Sichuan University)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1145475399,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,,
788,pub.1145395028,10.1142/9781800610941_0002,,,Deep Learning for Medical Imaging,"Deep learning has attracted the attention of researchers in the last few years due to its impressive performance on a plethora of computer vision tasks; and medical image analysis is no exception. In this chapter, we discuss the general deep learning strategies that have been considered in medical imaging; widespread preprocessing, processing, and postprocessing schemes; their targets and applications; and discuss key challenges to address in the future for easing their applicability in clinical practice.",,,,Deep Learning in Biology and Medicine,,2022-02-09,2022,2022-02-09,2022-02,,,11-54,Closed,Chapter,"Bernal, Jose; Kushibar, Kaisar; Clèrigues, Albert; Oliver, Arnau; Lladó, Xavier","Bernal, Jose (Institute of Computer Vision and Robotics, Universitat de Girona, Girona 17003, Spain); Kushibar, Kaisar (Institute of Computer Vision and Robotics, Universitat de Girona, Girona 17003, Spain); Clèrigues, Albert (Institute of Computer Vision and Robotics, Universitat de Girona, Girona 17003, Spain); Oliver, Arnau (Institute of Computer Vision and Robotics, Universitat de Girona, Girona 17003, Spain); Lladó, Xavier (Institute of Computer Vision and Robotics, Universitat de Girona, Girona 17003, Spain)",,"Bernal, Jose (University of Girona); Kushibar, Kaisar (University of Girona); Clèrigues, Albert (University of Girona); Oliver, Arnau (University of Girona); Lladó, Xavier (University of Girona)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145395028,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1400,pub.1145367087,10.1007/s10489-021-03062-2,,,A training-free recursive multiresolution framework for diffeomorphic deformable image registration,"Diffeomorphic deformable image registration is one of the crucial tasks in medical image analysis, which aims to find a unique transformation while preserving the topology and invertibility of the transformation. Deep convolutional neural networks (CNNs) have yielded well-suited approaches for image registration by learning the transformation priors from a large dataset. The improvement in the performance of these methods is related to their ability to learn information from several sample medical images that are difficult to obtain and bias the framework to the specific domain of data. In this paper, we propose a novel diffeomorphic training-free approach; this is built upon the principle of an ordinary differential equation. Our formulation yields an Euler integration type recursive scheme to estimate the changes of spatial transformations between the fixed and the moving image pyramids at different resolutions. The proposed architecture is simple in design. The moving image is warped successively at each resolution and finally aligned to the fixed image; this procedure is recursive in a way that at each resolution, a fully convolutional network (FCN) models a progressive change of deformation for the current warped image. The entire system is end-to-end and optimized for each pair of images from scratch. In comparison to learning-based methods, the proposed method neither requires a dedicated training set nor suffers from any training bias. We evaluate our method on three cardiac image datasets. The evaluation results demonstrate that the proposed method achieves state-of-the-art registration accuracy while maintaining desirable diffeomorphic properties.",,,Applied Intelligence,,,2022-02-08,2022,2022-02-08,2022-09,52,11,12546-12555,All OA, Green,Article,"Sheikhjafari, Ameneh; Noga, Michelle; Punithakumar, Kumaradevan; Ray, Nilanjan","Sheikhjafari, Ameneh (Department of Computing Science, University of Alberta, Edmonton, Canada; Servier Virtual Cardiac Centre, Mazankowski Alberta Heart Institute, Edmonton, Canada); Noga, Michelle (Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Canada; Servier Virtual Cardiac Centre, Mazankowski Alberta Heart Institute, Edmonton, Canada); Punithakumar, Kumaradevan (Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Canada; Servier Virtual Cardiac Centre, Mazankowski Alberta Heart Institute, Edmonton, Canada); Ray, Nilanjan (Department of Computing Science, University of Alberta, Edmonton, Canada)","Sheikhjafari, Ameneh (University of Alberta; Alberta Health Services)","Sheikhjafari, Ameneh (University of Alberta; Alberta Health Services); Noga, Michelle (University of Alberta; Alberta Health Services); Punithakumar, Kumaradevan (University of Alberta; Alberta Health Services); Ray, Nilanjan (University of Alberta)",2,2,,,http://arxiv.org/pdf/2202.00675,https://app.dimensions.ai/details/publication/pub.1145367087,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
827,pub.1145364438,10.48550/arxiv.2202.02952,,,SUD: Supervision by Denoising for Medical Image Segmentation,"Training a fully convolutional network for semantic segmentation typically
requires a large, labeled dataset with little label noise if good
generalization is to be guaranteed. For many segmentation problems, however,
data with pixel- or voxel-level labeling accuracy are scarce due to the cost of
manual labeling. This problem is exacerbated in domains where manual annotation
is difficult, resulting in large amounts of variability in the labeling even
across domain experts. Therefore, training segmentation networks to generalize
better by learning from both labeled and unlabeled images (called
semi-supervised learning) is problem of both practical and theoretical
interest. However, traditional semi-supervised learning methods for
segmentation often necessitate hand-crafting a differentiable regularizer
specific to a given segmentation problem, which can be extremely
time-consuming. In this work, we propose ""supervision by denoising"" (SUD), a
framework that enables us to supervise segmentation models using their denoised
output as targets. SUD unifies temporal ensembling and spatial denoising
techniques under a spatio-temporal denoising framework and alternates denoising
and network weight update in an optimization framework for semi-supervision. We
validate SUD on three tasks-kidney and tumor (3D), and brain (3D) segmentation,
and cortical parcellation (2D)-demonstrating a significant improvement in the
Dice overlap and the Hausdorff distance of segmentations over supervised-only
and temporal ensemble baselines.",,,arXiv,,,2022-02-07,2022,,,,,,All OA, Green,Preprint,"Young, Sean I.; Dalca, Adrian V.; Ferrante, Enzo; Golland, Polina; Fischl, Bruce; Iglesias, Juan Eugenio","Young, Sean I. (); Dalca, Adrian V. (); Ferrante, Enzo (); Golland, Polina (); Fischl, Bruce (); Iglesias, Juan Eugenio ()",,"Young, Sean I. (); Dalca, Adrian V. (); Ferrante, Enzo (); Golland, Polina (); Fischl, Bruce (); Iglesias, Juan Eugenio ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145364438,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,
163,pub.1145344895,10.1201/9781003120902,,,Artificial Intelligence in Healthcare and Medicine,"This book provides a comprehensive overview on the recent developments on clinical decision support systems, precision health and data science in medicine. The book targets clinical researchers and computational scientists seeking to understand the recent advances of artificial intelligence (AI) in health and medicine. Since AI and its applications are believed to have the potential to revolutionize healthcare and medicine, there is a clear need to explore and investigate the state-of the-art advancements in the field. This book provides a detailed description of the advancements, challenges and opportunities of using AI in medical and health applications. Over 10 case studies are included in the book that cover topics related to biomedical image processing, machine learning for healthcare, clinical decision support systems, visualization of high dimensional data, data security and privacy, bioinformatics and biometrics. The book is intended for clinical researchers and computational scientists seeking to understand the recent advances of AI in health and medicine. Many universities may use the book as a secondary training text. Companies in the healthcare sector can greatly benefit from the case studies covered in the book. Provides a comprehensive overview on the recent developments on clinical decision support systems, precision health and data science in medicine Examines the advancements, challenges and opportunities of using AI in medical and health applications Includes 10 cases for practical application and reference It is widely believed that Artificial Intelligence (AI) and its applications will revolutionize healthcare and medicine. This book provides a comprehensive overview on the recent developments on clinical decision support systems, precision health and data science in medicine.",,,,,,2022-02-07,2022,2022-02-07,,,,,Closed,Edited Book,,,,,1,1,,,,https://app.dimensions.ai/details/publication/pub.1145344895,46 Information and Computing Sciences, 4604 Cybersecurity and Privacy,3 Good Health and Well Being,,,,,,,,,,
5334,pub.1145327277,10.3390/diagnostics12020414,35204504,PMC8871002,Automatic Left Ventricle Segmentation from Short-Axis Cardiac MRI Images Based on Fully Convolutional Neural Network,"BACKGROUND: Left ventricle (LV) segmentation using a cardiac magnetic resonance imaging (MRI) dataset is critical for evaluating global and regional cardiac functions and diagnosing cardiovascular diseases. LV clinical metrics such as LV volume, LV mass and ejection fraction (EF) are frequently extracted based on the LV segmentation from short-axis MRI images. Manual segmentation to assess such functions is tedious and time-consuming for medical experts to diagnose cardiac pathologies. Therefore, a fully automated LV segmentation technique is required to assist medical experts in working more efficiently.
METHOD: This paper proposes a fully convolutional network (FCN) architecture for automatic LV segmentation from short-axis MRI images. Several experiments were conducted in the training phase to compare the performance of the network and the U-Net model with various hyper-parameters, including optimization algorithms, epochs, learning rate, and mini-batch size. In addition, a class weighting method was introduced to avoid having a high imbalance of pixels in the classes of image's labels since the number of background pixels was significantly higher than the number of LV and myocardium pixels. Furthermore, effective image conversion with pixel normalization was applied to obtain exact features representing target organs (LV and myocardium). The segmentation models were trained and tested on a public dataset, namely the evaluation of myocardial infarction from the delayed-enhancement cardiac MRI (EMIDEC) dataset.
RESULTS: The dice metric, Jaccard index, sensitivity, and specificity were used to evaluate the network's performance, with values of 0.93, 0.87, 0.98, and 0.94, respectively. Based on the experimental results, the proposed network outperforms the standard U-Net model and is an advanced fully automated method in terms of segmentation performance.
CONCLUSION: This proposed method is applicable in clinical practice for doctors to diagnose cardiac diseases from short-axis MRI images.",,,Diagnostics,,,2022-02-05,2022,2022-02-05,,12,2,414,All OA, Gold,Article,"Shaaf, Zakarya Farea; Jamil, Muhammad Mahadi Abdul; Ambar, Radzi; Alattab, Ahmed Abdu; Yahya, Anwar Ali; Asiri, Yousef","Shaaf, Zakarya Farea (Faculty of Electrical and Electronic Engineering, Universiti Tun Hussein Onn Malaysia, Parit Raja, Batu Pahat 86400, Johor, Malaysia;, aradzi@uthm.edu.my); Jamil, Muhammad Mahadi Abdul (Faculty of Electrical and Electronic Engineering, Universiti Tun Hussein Onn Malaysia, Parit Raja, Batu Pahat 86400, Johor, Malaysia;, aradzi@uthm.edu.my); Ambar, Radzi (Faculty of Electrical and Electronic Engineering, Universiti Tun Hussein Onn Malaysia, Parit Raja, Batu Pahat 86400, Johor, Malaysia;, aradzi@uthm.edu.my); Alattab, Ahmed Abdu (Department of Computer Science, College of Science and Arts, Sharurah, Najran University, Najran 61441, Saudi Arabia;, aaalattab@nu.edu.sa; Department of Computer Science, Faculty of Computer Science and Information Systems, Thamar University, Dhamar 87246, Yemen;, aaesmail@nu.edu.sa); Yahya, Anwar Ali (Department of Computer Science, Faculty of Computer Science and Information Systems, Thamar University, Dhamar 87246, Yemen;, aaesmail@nu.edu.sa; Department of Computer Science, College of Computer Science and Information Systems, Najran University, Najran 61441, Saudi Arabia;, yasiri@nu.edu.sa); Asiri, Yousef (Department of Computer Science, College of Computer Science and Information Systems, Najran University, Najran 61441, Saudi Arabia;, yasiri@nu.edu.sa)","Shaaf, Zakarya Farea (Tun Hussein Onn University of Malaysia); Jamil, Muhammad Mahadi Abdul (Tun Hussein Onn University of Malaysia)","Shaaf, Zakarya Farea (Tun Hussein Onn University of Malaysia); Jamil, Muhammad Mahadi Abdul (Tun Hussein Onn University of Malaysia); Ambar, Radzi (Tun Hussein Onn University of Malaysia); Alattab, Ahmed Abdu (Najran University; Thamar University); Yahya, Anwar Ali (Thamar University; Najran University); Asiri, Yousef (Najran University)",5,5,,,https://www.mdpi.com/2075-4418/12/2/414/pdf?version=1644050811,https://app.dimensions.ai/details/publication/pub.1145327277,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1136,pub.1145334066,10.48550/arxiv.2202.02078,,,Heed the Noise in Performance Evaluations in Neural Architecture Search,"Neural Architecture Search (NAS) has recently become a topic of great
interest. However, there is a potentially impactful issue within NAS that
remains largely unrecognized: noise. Due to stochastic factors in neural
network initialization, training, and the chosen train/validation dataset
split, the performance evaluation of a neural network architecture, which is
often based on a single learning run, is also stochastic. This may have a
particularly large impact if a dataset is small. We therefore propose to reduce
this noise by evaluating architectures based on average performance over
multiple network training runs using different random seeds and
cross-validation. We perform experiments for a combinatorial optimization
formulation of NAS in which we vary noise reduction levels. We use the same
computational budget for each noise level in terms of network training runs,
i.e., we allow less architecture evaluations when averaging over more training
runs. Multiple search algorithms are considered, including evolutionary
algorithms which generally perform well for NAS. We use two publicly available
datasets from the medical image segmentation domain where datasets are often
limited and variability among samples is often high. Our results show that
reducing noise in architecture evaluations enables finding better architectures
by all considered search algorithms.",,,arXiv,,,2022-02-04,2022,,,,,,All OA, Green,Preprint,"Dushatskiy, Arkadiy; Alderliesten, Tanja; Bosman, Peter A. N.","Dushatskiy, Arkadiy (); Alderliesten, Tanja (); Bosman, Peter A. N. ()",,"Dushatskiy, Arkadiy (); Alderliesten, Tanja (); Bosman, Peter A. N. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145334066,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4611 Machine Learning,,,,,,,,,
954,pub.1145363879,10.48550/arxiv.2202.02371,,,Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation,"Unsupervised pre-training has been proven as an effective approach to boost
various downstream tasks given limited labeled data. Among various methods,
contrastive learning learns a discriminative representation by constructing
positive and negative pairs. However, it is not trivial to build reasonable
pairs for a segmentation task in an unsupervised way. In this work, we propose
a novel unsupervised pre-training framework that avoids the drawback of
contrastive learning. Our framework consists of two principles: unsupervised
over-segmentation as a pre-train task using mutual information maximization and
boundary-aware preserving learning. Experimental results on two benchmark
medical segmentation datasets reveal our method's effectiveness in improving
segmentation performance when few annotated images are available.",,,arXiv,,,2022-02-04,2022,,,,,,All OA, Green,Preprint,"Peng, Jizong; Wang, Ping; Pedersoli, Marco; Desrosiers, Christian","Peng, Jizong (); Wang, Ping (); Pedersoli, Marco (); Desrosiers, Christian ()",,"Peng, Jizong (); Wang, Ping (); Pedersoli, Marco (); Desrosiers, Christian ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145363879,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5851,pub.1141619720,10.1109/tmi.2021.3117495,34606450,,LA-Net: A Multi-Task Deep Network for the Segmentation of the Left Atrium,"Although atrial fibrillation (AF) is the most common sustained atrial arrhythmia, treatment success for this condition remains suboptimal. Information from magnetic resonance imaging (MRI) has the potential to improve treatment efficacy, but there are currently few automatic tools for the segmentation of the atria in MR images. In the study, we propose a LA-Net, a multi-task network optimised to simultaneously generate left atrial segmentation and edge masks from MRI. LA-Net includes cross attention modules (CAMs) and enhanced decoder modules (EDMs) to purposefully select the most meaningful edge information for segmentation and smoothly incorporate it into segmentation masks at multiple-scales. We evaluate the performance of LA-Net on two MR sequences: late gadolinium enhanced (LGE) atrial MRI and atrial short axis balanced steady state free precession (bSSFP) MRI. LA-Net gives Hausdorff distances of 12.43 mm and Dice scores of 0.92 on the LGE (STACOM 2018) dataset and Hausdorff distances of 17.41 mm and Dice scores of 0.90 on the bSSFP (in-house) dataset without any post-processing, surpassing previously proposed segmentation networks, including U-Net and SEGANet. Our method allows automatic extraction of information about the LA from MR images, which can play an important role in the management of AF patients.",This work was supported by the British Heart Foundation under Grant RE/18/4/34215. The work of Anil A. Bharath was supported in part by the Rosetrees Trust through the Interdisciplinary Award “Atrial Fibrillation: A Major Clinical Challenge.”,,IEEE Transactions on Medical Imaging,,Atrial Fibrillation, Gadolinium, Heart Atria, Humans, Magnetic Resonance Imaging,2022-02-02,2022,2022-02-02,2022-02,41,2,456-464,All OA, Green,Article,"Uslu, Fatmatülzehra; Varela, Marta; Boniface, Georgia; Mahenthran, Thakshayene; Chubb, Henry; Bharath, Anil A.","Uslu, Fatmatülzehra (Department of Electrical-Electronics Engineering, Bursa Technical University, 16310, Bursa, Turkey); Varela, Marta (National Heart and Lung Institute, Imperial College London, London, W12 0NN, U.K.); Boniface, Georgia (Division of Biomedical Engineering and Imaging Sciences, King’s College London, London, SE1 7EH, U.K.; Department of General Medicine, Darent Valley Hospital, Kent, DA2 8DA, U.K.); Mahenthran, Thakshayene (Division of Biomedical Engineering and Imaging Sciences, King’s College London, London, SE1 7EH, U.K.; Department of Cardiology, King’s College London, London, WC2R 2LS, U.K.); Chubb, Henry (Division of Biomedical Engineering and Imaging Sciences, King’s College London, London, SE1 7EH, U.K.; Department of Pediatrics—Cardiology, Stanford Hospital and Clinics, Lucile Packard Children’s Hospital, Palo Alto, CA, 94304, USA); Bharath, Anil A. (Bioengineering Department, Imperial College London, London, SW7 2AZ, U.K.)","Uslu, Fatmatülzehra (Bursa Technical University)","Uslu, Fatmatülzehra (Bursa Technical University); Varela, Marta (Imperial College London); Boniface, Georgia (King's College London; Darent Valley Hospital); Mahenthran, Thakshayene (King's College London; King's College London); Chubb, Henry (King's College London; Lucile Packard Children's Hospital); Bharath, Anil A. (Imperial College London)",8,8,,,http://spiral.imperial.ac.uk/bitstream/10044/1/92493/2/Clean%20Copy.pdf,https://app.dimensions.ai/details/publication/pub.1141619720,40 Engineering, 4003 Biomedical Engineering,,,,,,
1687,pub.1145273552,10.48550/arxiv.2202.00677,,,An Embarrassingly Simple Consistency Regularization Method for  Semi-Supervised Medical Image Segmentation,"The scarcity of pixel-level annotation is a prevalent problem in medical
image segmentation tasks. In this paper, we introduce a novel regularization
strategy involving interpolation-based mixing for semi-supervised medical image
segmentation. The proposed method is a new consistency regularization strategy
that encourages segmentation of interpolation of two unlabelled data to be
consistent with the interpolation of segmentation maps of those data. This
method represents a specific type of data-adaptive regularization paradigm
which aids to minimize the overfitting of labelled data under high confidence
values. The proposed method is advantageous over adversarial and generative
models as it requires no additional computation. Upon evaluation on two
publicly available MRI datasets: ACDC and MMWHS, experimental results
demonstrate the superiority of the proposed method in comparison to existing
semi-supervised models. Code is available at:
https://github.com/hritam-98/ICT-MedSeg",,,arXiv,,,2022-02-01,2022,,,,,,All OA, Green,Preprint,"Basak, Hritam; Bhattacharya, Rajarshi; Hussain, Rukhshanda; Chatterjee, Agniv","Basak, Hritam (); Bhattacharya, Rajarshi (); Hussain, Rukhshanda (); Chatterjee, Agniv ()",,"Basak, Hritam (); Bhattacharya, Rajarshi (); Hussain, Rukhshanda (); Chatterjee, Agniv ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145273552,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1544,pub.1145138234,10.21203/rs.3.rs-1271768/v1,,,Cardiac MRI Segmentation Using Deep Learning,"Cardiovascular diseases (CVDs) remain the principal cause of all global death and disabilities worldwide. Cardiac MR Images play an important role in diagnosing and treating cardiac ailments in patients. Automatic segmentation of Cardiac Magnetic Resonance Imaging (Cardiac MRI) is an essential application in clinical practice. In this paper, Cardiac MRI segmentation is performed using a convolutional neural network. ACDC Challenge 2017 dataset is used the training and testing purpose. It consists of data of 100 subjects, including the End Systole and End Diastole phase. The model's performance is measured using the Dice coefficient, achieving an accuracy of 0.90. The results for basal as well as with apical slices are pretty encouraging.",,,Research Square,,,2022-02-01,2022,2022-02-01,,,,,All OA, Green,Preprint,"Das, Niharika; Das, Sujoy","Das, Niharika (Maulana Azad National Institute of Technology); Das, Sujoy (Maulana Azad National Institute of Technology)",,"Das, Niharika (Maulana Azad National Institute of Technology); Das, Sujoy (Maulana Azad National Institute of Technology)",0,0,,,https://www.researchsquare.com/article/rs-1271768/latest.pdf,https://app.dimensions.ai/details/publication/pub.1145138234,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering,,,,,,,,
1346,pub.1145233276,10.48550/arxiv.2202.00675,,,A training-free recursive multiresolution framework for diffeomorphic  deformable image registration,"Diffeomorphic deformable image registration is one of the crucial tasks in
medical image analysis, which aims to find a unique transformation while
preserving the topology and invertibility of the transformation. Deep
convolutional neural networks (CNNs) have yielded well-suited approaches for
image registration by learning the transformation priors from a large dataset.
The improvement in the performance of these methods is related to their ability
to learn information from several sample medical images that are difficult to
obtain and bias the framework to the specific domain of data. In this paper, we
propose a novel diffeomorphic training-free approach; this is built upon the
principle of an ordinary differential equation.
  Our formulation yields an Euler integration type recursive scheme to estimate
the changes of spatial transformations between the fixed and the moving image
pyramids at different resolutions. The proposed architecture is simple in
design. The moving image is warped successively at each resolution and finally
aligned to the fixed image; this procedure is recursive in a way that at each
resolution, a fully convolutional network (FCN) models a progressive change of
deformation for the current warped image. The entire system is end-to-end and
optimized for each pair of images from scratch. In comparison to learning-based
methods, the proposed method neither requires a dedicated training set nor
suffers from any training bias. We evaluate our method on three cardiac image
datasets. The evaluation results demonstrate that the proposed method achieves
state-of-the-art registration accuracy while maintaining desirable
diffeomorphic properties.",,,arXiv,,,2022-02-01,2022,,,,,,All OA, Green,Preprint,"Sheikhjafari, Ameneh; Noga, Michelle; Punithakumar, Kumaradevan; Ray, Nilanjan","Sheikhjafari, Ameneh (); Noga, Michelle (); Punithakumar, Kumaradevan (); Ray, Nilanjan ()",,"Sheikhjafari, Ameneh (); Noga, Michelle (); Punithakumar, Kumaradevan (); Ray, Nilanjan ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145233276,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1209,pub.1149437996,10.1166/jmihi.2022.3927,,,Making Semi-Automatic Segmentation Method to be Automatic Using Deep Learning for Biventricular Segmentation,"Ventricular Segmentation or Delineation of Cardiac Magnetic Resonance Imaging (CMRI) is significant in obtaining the cardiac contractile function, which in turn is taken as input for diagnosing Cardio Vascular Diseases (CVD). Many automatic and semi-automatic methods were evolved to meet the constraints of diagnosing CVDs. Among these, semi-automatic methods require user intervention for delineation of ventricles, which consumes time and leads to intra and inter-observability, as with manual delineation. Thus, the automatic method is suggested by most of the researchers to address the above-stated problem. We proposed Saliency-based Active contour U-Net (SACU-Net) for automatic bi-ventricular segmentation which is found to surpass the existing highest developed methods regarding closeness to the gold standard. Three schemes are used by our proposed algorithm, namely 1. Saliency Detection Scheme for Region of Interest (ROI) Localization to concentrate only on Object of Interest, 2. Drop-out embedded U-net for Initial Contour evolution that performs initial segmentation and 3. Local-Global-based Regional active Contour (LGRAC) to fine-tune and avoid leaking, merging of ventricles during Delineation. We used three datasets namely Automatic Cardiac Diagnosing Challenge (ACDC) of MICCAI 2017, Right Ventricular Segmentation Challenge (RVSC) of MICCAI 2012, and Sunny Brook (SB) of MICCAI 2009 dataset to test the adaptability nature of our algorithm over different scanner resolutions and protocols. 100 and 50 CMRI Images of ACDC were used for training and testing respectively which obtained average Dice Coefficient (DC) metric of 0.963, 0.934, and 0.948 for Left Ventricular Cavity (LVC), Left Ventricular Myocardium (LVM), and Right Ventricular Cavity (RVC) respectively. 32 and 16 CMRI Images of RVSC are used for preparing and experimenting respectively, which obtained an average DC metric of 0.95 for RVC.30 and 15 CMRI Images of SB are used for preparing and experimenting respectively, which obtained average DC metric of 0.96 and 0.97 for LVC and LVM, respectively. Hausdorff Distance (HD) Metrics are also calculated to learn the distance of proposed delineated ventricles to reach the gold standard. The above resultant metrics show the robustness of our proposed SACU-Net in the segmentation of ventricles of CMRI than previous methods.",,,Journal of Medical Imaging and Health Informatics,,,2022-02-01,2022,,2022-02-01,12,2,112-122,Closed,Article,"Ciyamala Kushbu, S.; Inbamalar, T. M.","Ciyamala Kushbu, S. (Department of Information and Communication Engineering, Anna University, Chennai 25, Tamilnadu, India); Inbamalar, T. M. (Department of Electronics and Communication Engineering, R.M.K. Engineering College, Tiruvallur 601206, Tamilnadu, India)",,"Ciyamala Kushbu, S. (Anna University, Chennai); Inbamalar, T. M. (Anna University, Chennai)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149437996,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
1296,pub.1128764849,10.1016/j.irbm.2020.06.004,,,Cardiovascular Disorder Severity Detection Using Myocardial Anatomic Features Based Optimized Extreme Learning Machine Approach,"Objectives This study focuses on integration of anatomical left ventricle myocardium features and optimized extreme learning machine (ELM) for discrimination of subjects with normal, mild, moderate and severe abnormal ejection fraction (EF). The physiological alterations in myocardium have diagnostic relevance to the etiology of cardiovascular diseases (CVD) with reduced EF. Materials and Methods This assessment is carried out on cardiovascular magnetic resonance (CMR) images of 104 subjects available in Kaggle Second Annual Data Science Bowl. The Segment CMR framework is used to segment myocardium from cardiac MR images, and it is subdivided into 16 sectors. 86 clinically significant anatomical features are extracted and subjected to ELM framework. Regularization coefficient and hidden neurons influence the prediction accuracy of ELM. The optimal value for these parameters is achieved with the butterfly optimizer (BO). A comparative study of BOELM framework with different activation functions and feature set has been conducted. Results Among the individual feature set, myocardial volume at ED gives a better classification accuracy of 83.3% compared to others. Further, the given BOELM framework is able to provide higher multi-class accuracy of 95.2% with the entire feature set than ELM. Better discrimination of healthy and moderate abnormal subjects is achieved than other sub groups. Conclusion The combined anatomical sector wise myocardial features assisted BOELM is able to predict the severity levels of CVDs. Thus, this study supports the radiologists in the mass diagnosis of cardiac disorder.","This work is financially supported by Department of Science Technology Science and Engineering Research Board (DST-SERB), Government of India, SERB sanction no. EEQ/2016/000351, dated 06.02.2017. The authors would like to thank the Kaggle challenge second Annual datascience bowl database for providing the CMR images. The authors would also like to thank the Medviso AB, for providing technical assistance to work with Segment CMR software.","This work has been supported by: Department of Science Technology Science and Engineering Research Board (DST-SERB), Government of India, SERB sanction no. EEQ/2016/000351, dated 06.02.2017.",IRBM,,,2022-02,2022,,2022-02,43,1,2-12,Closed,Article,"Muthulakshmi, M.; Kavitha, G.","Muthulakshmi, M. (Department of Electronics Engineering, MIT Campus, Anna University, Chromepet, Chennai – 600044, Tamilnadu, India); Kavitha, G. (Department of Electronics Engineering, MIT Campus, Anna University, Chromepet, Chennai – 600044, Tamilnadu, India)","Muthulakshmi, M. (Anna University, Chennai)","Muthulakshmi, M. (Anna University, Chennai); Kavitha, G. (Anna University, Chennai)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1128764849,31 Biological Sciences,,,,,,,,,,,,
160,pub.1139046341,10.1142/q0322,,,Deep Learning in Biology and Medicine,,,,,,,2022-02,2022,2022-06-21,2022-02,,,,Closed,Edited Book,,,,,3,3,,,,https://app.dimensions.ai/details/publication/pub.1139046341,,,,,,,,,,,,,
6259,pub.1145012272,10.1259/bjr.20201060,35084208,,"Artificial intelligence study on left ventricular function among normal individuals, hypertrophic cardiomyopathy and dilated cardiomyopathy patients using 1.5T cardiac cine MR images obtained by SSFP sequence","OBJECTIVES: To evaluate the performance of a deep learning-based method to automatically quantify left ventricular (LV) function from MR images in different cardiomyopathy.
METHODS: This retrospective study included MRI data sets from 2013 to 2020. Data on left ventricular function from patients with hypertrophic cardiomyopathy (HCM), patients with dilated cardiomyopathy (DCM), and healthy participants were analyzed. MRI data from a total of 388 patients were measured manually and automatically.The performance of Convolutional Neural Networks (CNNs) was evaluated based on the manual notes of two experienced observers: (a) LV segmentation accuracy, and (b) LV functional parameter accuracy. Bland-Altman analysis, Receiver operating Characteristic (ROC) curve analysis and Pearson correlation analysis were used to evaluate the consistency between fully automatic and manual diagnosis of HCM and DCM.
RESULTS: The deep-learning CNN performed best in HCM in evaluating LV function and worst in DCM. Compared with manual analysis, four parameters of LV function in the HCM group showed high correlation (r at least >0.901), and the correlation of DCM in all parameters was weaker than that of HCM, especially EF (r2 = 0.776) and SV (r2 = 0.645). ROC curve analysis indicated that at the optimal cut-off value, EF from automatic segmentation identified DCM and HCM patients with sensitivity of 92.31 and 78.05%, specificity of 82.96 and 54.07%, respectively.
CONCLUSION: Among different heart diseases, the analysis of cardiac function based on deep-learning CNN may have different performances, with DCM performing the worst and HCM the best and thus, special attention should be paid to DCM patients when assessing LV function through artificial intelligence method. LV function parameter obtained by artificial intelligence method may play an important role in the future AI diagnosis of HCM and DCM.
ADVANCES IN KNOWLEDGE: These data for the first time objectively evaluate the performance of a commercially available deep learning-based method in cardiac function evaluation of different cardiomyopathy and point out its advantages and disadvantages in different cardiomyopathy. This work did not attempt to design the algorithm itself, but rather applied an already existing method to a test dataset of clinical data and evaluated the results for a limited number of cardiomyopathy.",,,British Journal of Radiology,,"Artificial Intelligence; Cardiomyopathies; Cardiomyopathy, Dilated; Cardiomyopathy, Hypertrophic; Humans; Magnetic Resonance Imaging; Retrospective Studies; Ventricular Function, Left",2022-01-31,2022,2022-01-31,2022-05-01,95,1133,20201060,Closed,Article,"Guo, Jiajun; Lu, HongFei; Chen, Yinyin; Zeng, Mengsu; Jin, Hang","Guo, Jiajun (Department of Radiology, Zhongshan Hospital, Fudan University, and Shanghai Institute of Medical Imaging, Shanghai, China; Department of Medical Imaging, Shanghai Medical school Fudan University, Shanghai, China); Lu, HongFei (Department of Radiology, Zhongshan Hospital, Fudan University, and Shanghai Institute of Medical Imaging, Shanghai, China; Department of Medical Imaging, Shanghai Medical school Fudan University, Shanghai, China); Chen, Yinyin (Department of Radiology, Zhongshan Hospital, Fudan University, and Shanghai Institute of Medical Imaging, Shanghai, China; Department of Medical Imaging, Shanghai Medical school Fudan University, Shanghai, China); Zeng, Mengsu (Department of Radiology, Zhongshan Hospital, Fudan University, and Shanghai Institute of Medical Imaging, Shanghai, China; Department of Medical Imaging, Shanghai Medical school Fudan University, Shanghai, China); Jin, Hang (Department of Radiology, Zhongshan Hospital, Fudan University, and Shanghai Institute of Medical Imaging, Shanghai, China; Department of Medical Imaging, Shanghai Medical school Fudan University, Shanghai, China)","Jin, Hang (Zhongshan Hospital; Fudan University; Shanghai Medical College of Fudan University)","Guo, Jiajun (Zhongshan Hospital; Fudan University; Shanghai Medical College of Fudan University); Lu, HongFei (Zhongshan Hospital; Fudan University; Shanghai Medical College of Fudan University); Chen, Yinyin (Zhongshan Hospital; Fudan University; Shanghai Medical College of Fudan University); Zeng, Mengsu (Zhongshan Hospital; Fudan University; Shanghai Medical College of Fudan University); Jin, Hang (Zhongshan Hospital; Fudan University; Shanghai Medical College of Fudan University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145012272,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,,
1654,pub.1145010661,10.48550/arxiv.2201.10410,,,Comparison of Evaluation Metrics for Landmark Detection in CMR Images,"Cardiac Magnetic Resonance (CMR) images are widely used for cardiac diagnosis
and ventricular assessment. Extracting specific landmarks like the right
ventricular insertion points is of importance for spatial alignment and 3D
modeling. The automatic detection of such landmarks has been tackled by
multiple groups using Deep Learning, but relatively little attention has been
paid to the failure cases of evaluation metrics in this field. In this work, we
extended the public ACDC dataset with additional labels of the right
ventricular insertion points and compare different variants of a heatmap-based
landmark detection pipeline. In this comparison, we demonstrate very likely
pitfalls of apparently simple detection and localisation metrics which
highlights the importance of a clear detection strategy and the definition of
an upper limit for localisation-based metrics. Our preliminary results indicate
that a combination of different metrics is necessary, as they yield different
winners for method comparison. Additionally, they highlight the need of a
comprehensive metric description and evaluation standardisation, especially for
the error cases where no metrics could be computed or where no lower/upper
boundary of a metric exists. Code and labels:
https://github.com/Cardio-AI/rvip_landmark_detection",,,arXiv,,,2022-01-25,2022,,,,,,All OA, Green,Preprint,"Koehler, Sven; Sharan, Lalith; Kuhm, Julian; Ghanaat, Arman; Gordejeva, Jelizaveta; Simon, Nike K.; Grell, Niko M.; André, Florian; Engelhardt, Sandy","Koehler, Sven (); Sharan, Lalith (); Kuhm, Julian (); Ghanaat, Arman (); Gordejeva, Jelizaveta (); Simon, Nike K. (); Grell, Niko M. (); André, Florian (); Engelhardt, Sandy ()",,"Koehler, Sven (); Sharan, Lalith (); Kuhm, Julian (); Ghanaat, Arman (); Gordejeva, Jelizaveta (); Simon, Nike K. (); Grell, Niko M. (); André, Florian (); Engelhardt, Sandy ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145010661,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
1398,pub.1152728617,10.1109/globconpt57482.2022.9938245,,,Cardiac Magnetic Resonance Imaging Segmentation using Ensemble of 2D and 3D Deep Residual U-Net,"The domain of deep learning stimulates medical image analysis, which is a catalyst of scientific research and an essential element of healthcare. Since semantic segmentation techniques empower image processing and quantitative determination in various applications, designing a dedicated solution is challenging and heavily reliant on input data characteristics and hardware constraints. Cardiac magnetic resonance imaging segmentation provides three essential heart structures, left ventricle (LV) cavity, myocardium (MYO), and right ventricle (RV) cavity. In clinical applications, manual contouring is frequently utilized to perform semantic segmentation. A fully automated cardiac magnetic resonance image (CMRI) segmentation technique is becoming more desirable as deep learning-based frameworks advance. Motivated by the power of U-Net, residual network, and deep supervision, this paper proposes a Deep Residual U-Net to achieve better LV, MYO, and RV segmentation in short-axis CMRI. The model is formed with residual connections and has a similar layout to U-Net. It provides three advantages: First, residual connections make deep network training easier. Second, the network's rich skip connections enable feature propagation, allowing for network creation with lower complexity but more remarkable performance. Third, Deep supervision facilitates the loss computation at every feature dimension except at least two, empowering gradients to be implanted more deeply in the network and improving each layer's training in Deep Residual U-Net. Automated Cardiac Diagnosis Challenge (ACDC) 2017 dataset has been used to assess the segmentation efficiency of proposed model. The proposed approach significantly outperformed all other methods, evidencing its supremacy over recent state-of-the-art U-Net-based techniques.","The authors express their gratitude to the Head of the Electrical Engineering department and the Computer Centre at the Indian Institute of Technology, Roorkee, for offering the support required for GPU-based computing.","The authors express their gratitude to the Head of the Electrical Engineering department and the Computer Centre at the Indian Institute of Technology, Roorkee, for offering the support required for GPU-based computing.",,"2022 IEEE Global Conference on Computing, Power and Communication Technologies (GlobConPT)",,2022-01-25,2022,,2022-01-25,0,,1-6,Closed,Proceeding,"Singh, Kamal Raj; Sharma, Ambalika; Singh, G. K.","Singh, Kamal Raj (Electrical Engineering Indian Institute of Technology Roorkee, Roorkee, India); Sharma, Ambalika (Electrical Engineering Indian Institute of Technology Roorkee, Roorkee, India); Singh, G. K. (Electrical Engineering Indian Institute of Technology Roorkee, Roorkee, India)",,"Singh, Kamal Raj (Indian Institute of Technology Roorkee); Sharma, Ambalika (Indian Institute of Technology Roorkee); Singh, G. K. (Indian Institute of Technology Roorkee)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152728617,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,,
4530,pub.1144950119,10.1109/tnnls.2022.3141119,35073271,,Probabilistic Modeling for Image Registration Using Radial Basis Functions: Application to Cardiac Motion Estimation,"Cardiovascular diseases (CVDs) are the leading cause of death, affecting the cardiac dynamics over the cardiac cycle. Estimation of cardiac motion plays an essential role in many medical clinical tasks. This article proposes a probabilistic framework for image registration using compact support radial basis functions (CSRBFs) to estimate cardiac motion. A variational inference-based generative model with convolutional neural networks (CNNs) is proposed to learn the probabilistic coefficients of CSRBFs used in image deformation. We designed two networks to estimate the deformation coefficients of CSRBFs: the first one solves the spatial transformation using given control points, and the second one models the transformation using drifting control points. The given-point-based network estimates the probabilistic coefficients of control points. In contrast, the drifting-point-based model predicts the probabilistic coefficients and spatial distribution of control points simultaneously. To regularize these coefficients, we derive the bending energy (BE) in the variational bound by defining the covariance of coefficients. The proposed framework has been evaluated on the cardiac motion estimation and the calculation of the myocardial strain. In the experiments, 1409 slice pairs of end-diastolic (ED) and end-systolic (ES) phase in 4-D cardiac magnetic resonance (MR) images selected from three public datasets are employed to evaluate our networks. The experimental results show that our framework outperforms the state-of-the-art registration methods concerning the deformation smoothness and registration accuracy.",,,IEEE Transactions on Neural Networks and Learning Systems,,,2022-01-24,2022,2022-01-24,2022-01-24,PP,99,1-15,All OA, Hybrid,Article,"Gan, Ziyu; Sun, Wei; Liao, Kaimin; Yang, Xuan","Gan, Ziyu (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China.); Sun, Wei (Radboud University Medical Center, 6500 Nijmegen, The Netherlands.); Liao, Kaimin (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China.); Yang, Xuan (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China ())",,"Gan, Ziyu (Shenzhen University); Sun, Wei (Radboud University Nijmegen Medical Centre); Liao, Kaimin (Shenzhen University); Yang, Xuan (Shenzhen University)",0,0,,,https://ieeexplore.ieee.org/ielx7/5962385/6104215/09690579.pdf,https://app.dimensions.ai/details/publication/pub.1144950119,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
411,pub.1144976354,10.48550/arxiv.2201.09873,,,Transformers in Medical Imaging: A Survey,"Following unprecedented success on the natural language tasks, Transformers
have been successfully applied to several computer vision problems, achieving
state-of-the-art results and prompting researchers to reconsider the supremacy
of convolutional neural networks (CNNs) as {de facto} operators. Capitalizing
on these advances in computer vision, the medical imaging field has also
witnessed growing interest for Transformers that can capture global context
compared to CNNs with local receptive fields. Inspired from this transition, in
this survey, we attempt to provide a comprehensive review of the applications
of Transformers in medical imaging covering various aspects, ranging from
recently proposed architectural designs to unsolved issues. Specifically, we
survey the use of Transformers in medical image segmentation, detection,
classification, reconstruction, synthesis, registration, clinical report
generation, and other tasks. In particular, for each of these applications, we
develop taxonomy, identify application-specific challenges as well as provide
insights to solve them, and highlight recent trends. Further, we provide a
critical discussion of the field's current state as a whole, including the
identification of key challenges, open problems, and outlining promising future
directions. We hope this survey will ignite further interest in the community
and provide researchers with an up-to-date reference regarding applications of
Transformer models in medical imaging. Finally, to cope with the rapid
development in this field, we intend to regularly update the relevant latest
papers and their open-source implementations at
\url{https://github.com/fahadshamshad/awesome-transformers-in-medical-imaging}.",,,arXiv,,,2022-01-24,2022,,,,,,All OA, Green,Preprint,"Shamshad, Fahad; Khan, Salman; Zamir, Syed Waqas; Khan, Muhammad Haris; Hayat, Munawar; Khan, Fahad Shahbaz; Fu, Huazhu","Shamshad, Fahad (); Khan, Salman (); Zamir, Syed Waqas (); Khan, Muhammad Haris (); Hayat, Munawar (); Khan, Fahad Shahbaz (); Fu, Huazhu ()",,"Shamshad, Fahad (); Khan, Salman (); Zamir, Syed Waqas (); Khan, Muhammad Haris (); Hayat, Munawar (); Khan, Fahad Shahbaz (); Fu, Huazhu ()",1,1,,,,https://app.dimensions.ai/details/publication/pub.1144976354,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1136,pub.1144939953,10.48550/arxiv.2201.08388,,,Steerable Pyramid Transform Enables Robust Left Ventricle Quantification,"Although multifarious variants of convolutional neural networks (CNNs) have
proved successful in cardiac index quantification, they seem vulnerable to mild
input perturbations, e.g., spatial transformations, image distortions, and
adversarial attacks. Such brittleness erodes our trust in CNN-based automated
diagnosis of various cardiovascular diseases. In this work, we describe a
simple and effective method to learn robust CNNs for left ventricle (LV)
quantification, including cavity and myocardium areas, directional dimensions,
and regional wall thicknesses. The key to the success of our approach is the
use of the biologically-inspired steerable pyramid transform (SPT) as fixed
front-end processing, which brings three computational advantages to LV
quantification. First, the basis functions of SPT match the anatomical
structure of the LV as well as the geometric characteristics of the estimated
indices. Second, SPT enables sharing a CNN across different orientations as a
form of parameter regularization, and explicitly captures the scale variations
of the LV in a natural way. Third, the residual highpass subband can be
conveniently discarded to further encourage robust feature learning. A concise
and effective metric, named Robustness Ratio, is proposed to evaluate the
robustness under various input perturbations. Extensive experiments on 145
cardiac sequences show that our SPT-augmented method performs favorably against
state-of-the-art algorithms in terms of prediction accuracy, but is
significantly more robust under input perturbations.",,,arXiv,,,2022-01-20,2022,,,,,,All OA, Green,Preprint,"Zhu, Xiangyang; Ma, Kede; Xue, Wufeng","Zhu, Xiangyang (); Ma, Kede (); Xue, Wufeng ()",,"Zhu, Xiangyang (); Ma, Kede (); Xue, Wufeng ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1144939953,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,
4323,pub.1144690600,10.1016/j.media.2022.102362,35091277,,AWSnet: An auto-weighted supervision attention network for myocardial scar and edema segmentation in multi-sequence cardiac magnetic resonance images,"Multi-sequence cardiac magnetic resonance (CMR) provides essential pathology information (scar and edema) to diagnose myocardial infarction. However, automatic pathology segmentation can be challenging due to the difficulty of effectively exploring the underlying information from the multi-sequence CMR data. This paper aims to tackle the scar and edema segmentation from multi-sequence CMR with a novel auto-weighted supervision framework, where the interactions among different supervised layers are explored under a task-specific objective using reinforcement learning. Furthermore, we design a coarse-to-fine framework to boost the small myocardial pathology region segmentation with shape prior knowledge. The coarse segmentation model identifies the left ventricle myocardial structure as a shape prior, while the fine segmentation model integrates a pixel-wise attention strategy with an auto-weighted supervision model to learn and extract salient pathological structures from the multi-sequence CMR data. Extensive experimental results on a publicly available dataset from Myocardial pathology segmentation combining multi-sequence CMR (MyoPS 2020) demonstrate our method can achieve promising performance compared with other state-of-the-art methods. Our method is promising in advancing the myocardial pathology assessment on multi-sequence CMR data. To motivate the community, we have made our code publicly available via https://github.com/soleilssss/AWSnet/tree/master.","This work was supported by the Fundamental Research Funds for the Central Universities, the National Natural Science Foundation of China (NSFC 61771130 and NSFC 61801296), the National Key RD Program of China (2018YFA0704102) and the Shenzhen Basic Research (JCYJ20190808115419619).",,Medical Image Analysis,,Cicatrix, Edema, Heart, Heart Ventricles, Humans, Magnetic Resonance Imaging,2022-01-15,2022,2022-01-15,2022-04,77,,102362,All OA, Green,Article,"Wang, Kai-Ni; Yang, Xin; Miao, Juzheng; Li, Lei; Yao, Jing; Zhou, Ping; Xue, Wufeng; Zhou, Guang-Quan; Zhuang, Xiahai; Ni, Dong","Wang, Kai-Ni (State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Southeast University, Nanjing, China.); Yang, Xin (Medical UltraSound Image Computing (MUSIC) Lab, School of Biomedical Engineering, Health Center, Shenzhen University, Shenzhen, China.); Miao, Juzheng (State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Southeast University, Nanjing, China.); Li, Lei (School of Data Science, Fudan University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering and Imaging Sciences, Kings College London, London, UK.); Yao, Jing (Department of Ultrasound Medicine, Affiliated Drum Tower Hospital of Nanjing University Medical School, Nanjing, China.); Zhou, Ping (State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Southeast University, Nanjing, China.); Xue, Wufeng (Medical UltraSound Image Computing (MUSIC) Lab, School of Biomedical Engineering, Health Center, Shenzhen University, Shenzhen, China.); Zhou, Guang-Quan (State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Southeast University, Nanjing, China. Electronic address: guangquan.zhou@seu.edu.cn.); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China. Electronic address: zxh@fudan.edu.cn.); Ni, Dong (Medical UltraSound Image Computing (MUSIC) Lab, School of Biomedical Engineering, Health Center, Shenzhen University, Shenzhen, China. Electronic address: nidong@szu.edu.cn.)","Zhou, Guang-Quan (Southeast University); Zhuang, Xiahai (Fudan University); Ni, Dong (Shenzhen University)","Wang, Kai-Ni (Southeast University); Yang, Xin (Shenzhen University); Miao, Juzheng (Southeast University); Li, Lei (Fudan University; Shanghai Jiao Tong University; King's College London); Yao, Jing (Nanjing Drum Tower Hospital); Zhou, Ping (Southeast University); Xue, Wufeng (Shenzhen University); Zhou, Guang-Quan (Southeast University); Zhuang, Xiahai (Fudan University); Ni, Dong (Shenzhen University)",6,6,,,http://arxiv.org/pdf/2201.05344,https://app.dimensions.ai/details/publication/pub.1144690600,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,
1620,pub.1144684969,10.1007/978-3-030-93722-5_36,,,"Multi-disease, Multi-view and Multi-center Right Ventricular Segmentation in Cardiac MRI Using Efficient Late-Ensemble Deep Learning Approach","In many computer vision areas, deep learning-based models achieved state-of-the-art performances and started catching the attention in the context of medical imaging. The emergence of deep learning is a cutting-edge for the state-of-the-art methods of cardiac magnetic resonance (CMR) segmentation. For generalization and better optimization of current deep learning models for CMR segmentation problems, the M&Ms-2 (Multi-Disease, Multi-View & Multi-Center Right Ventricular Segmentation in Cardiac MRI) challenge proposed data that are acquired from three clinical centers of Spain and Germany using three different magnetic resonance scanner vendors (Siemens, General Electric and Philips). To cater to the generalization issue on a multi-Disease dataset, the proposed model used lightweight convolutional layers’ blocks before the proposed residual block which have been used as a skip connection with a series of several layers for boundary and structural information preservation. The residual blocks that are used after every encoder block help bridge the semantic gap between the encoder and decoder. The efficient expansion, depth-wise, and projection block (EDP) is used at each decoder block for efficiently improving the segmentation maps. The proposed 2D-based model is used to segment the right ventricle (RV) in short-axis (SA) images, as well as in long-axis (LA) cardiac MR images without any additional dataset and pretrained weights. The proposed model produced optimal dice coefficients (DC) and Hausdorff distance (HD) scores in validation and testing images and could be useful for the segmentation of the RV and LA in cardiac MRI.",,,Lecture Notes in Computer Science,"Statistical Atlases and Computational Models of the Heart. Multi-Disease, Multi-View, and Multi-Center Right Ventricular Segmentation in Cardiac MRI Challenge",,2022-01-14,2022,2022-01-14,2022,13131,,335-343,Closed,Chapter,"Mazher, Moona; Qayyum, Abdul; Benzinou, Abdesslam; Abdel-Nasser, Mohamed; Puig, Domenec","Mazher, Moona (Department of Computer Engineering and Mathematics, University Rovira I Virgili, Tarragona, Spain); Qayyum, Abdul (ENIB, UMR CNRS 6285 LabSTICC, 29238, Brest, France); Benzinou, Abdesslam (ENIB, UMR CNRS 6285 LabSTICC, 29238, Brest, France); Abdel-Nasser, Mohamed (Department of Computer Engineering and Mathematics, University Rovira I Virgili, Tarragona, Spain; Faculty of Engineering, Department of Electrical Engineering, Aswan University, Aswan, Egypt); Puig, Domenec (Department of Computer Engineering and Mathematics, University Rovira I Virgili, Tarragona, Spain)","Mazher, Moona (Rovira i Virgili University)","Mazher, Moona (Rovira i Virgili University); Qayyum, Abdul (Brest National Engineering School); Benzinou, Abdesslam (Brest National Engineering School); Abdel-Nasser, Mohamed (Rovira i Virgili University; Aswan University); Puig, Domenec (Rovira i Virgili University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1144684969,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1455,pub.1144683508,10.1007/978-3-030-93722-5_30,,,Multi-view SA-LA Net: A Framework for Simultaneous Segmentation of RV on Multi-view Cardiac MR Images,"We proposed a multi-view SA-LA model for simultaneous segmentation of RV on the short-axis (SA) and long-axis (LA) cardiac MR images. The multi-view SA-LA model is a multi-encoder, multi-decoder U-Net architecture based on the U-Net model. One encoder-decoder pair segments the RV on SA images and the other pair on LA images. Multi-view SA-LA model assembles an extremely rich set of synergistic features, at the root of the encoder branch, by combining feature maps learned from matched SA and LA cardiac MR images. Segmentation performance is further enhanced by: (1) incorporating spatial context of LV as a prior and (2) performing deep supervision in the last three layers of the decoder branch. Multi-view SA-LA model was extensively evaluated on the MICCAI 2021 Multi- Disease, Multi-View, and Multi- Centre RV Segmentation Challenge dataset (M&Ms-2021). M&Ms-2021 dataset consists of multi-phase, multi-view cardiac MR images of 360\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$360$$
\end{document} subjects acquired at four clinical centers with three different vendors. On the challenge cohort (160\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$160$$
\end{document} subjects), the proposed multi-view SA-LA model achieved a Dice Score of 91%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$91\%$$
\end{document} and Hausdorff distance of 11.2\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$11.2$$
\end{document} mm on short-axis images and a Dice Score of 89.6%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$89.6\%$$
\end{document} and Hausdorff distance of 8.1\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$8.1$$
\end{document} mm on long-axis images. Moreover, multi-view SA-LA model exhibited strong generalization to unseen RV related pathologies including Dilated Right Ventricle (DSC: SA 91.41%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$91.41\mathrm{\%}$$
\end{document}, LA 89.63%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$89.63\mathrm{\%}$$
\end{document}) and Tricuspidal Regurgitation (DSC: SA 91.40%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$91.40\mathrm{\%}$$
\end{document}, LA 90.40%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$90.40\mathrm{\%}$$
\end{document}) with low variance (σDSC\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$${\sigma }_{\mathrm{DSC}}$$
\end{document}: SA <5%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$<5\mathrm{\%}$$
\end{document}, LA <6%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}
$$<6\mathrm{\%}$$
\end{document}).",,,Lecture Notes in Computer Science,"Statistical Atlases and Computational Models of the Heart. Multi-Disease, Multi-View, and Multi-Center Right Ventricular Segmentation in Cardiac MRI Challenge",,2022-01-14,2022,2022-01-14,2022,13131,,277-286,All OA, Green,Chapter,"Jabbar, Sana; Bukhari, Syed Talha; Mohy-ud-Din, Hassan","Jabbar, Sana (Department of Electrical Engineering, Syed Babar Ali School of Science and Engineering, LUMS, 54792, Lahore, Pakistan); Bukhari, Syed Talha (Department of Electrical Engineering, Syed Babar Ali School of Science and Engineering, LUMS, 54792, Lahore, Pakistan); Mohy-ud-Din, Hassan (Department of Electrical Engineering, Syed Babar Ali School of Science and Engineering, LUMS, 54792, Lahore, Pakistan)","Mohy-ud-Din, Hassan (Lahore University of Management Sciences)","Jabbar, Sana (Lahore University of Management Sciences); Bukhari, Syed Talha (Lahore University of Management Sciences); Mohy-ud-Din, Hassan (Lahore University of Management Sciences)",0,0,,,http://arxiv.org/pdf/2110.00682,https://app.dimensions.ai/details/publication/pub.1144683508,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
863,pub.1144723593,10.48550/arxiv.2201.05344,,,AWSnet: An Auto-weighted Supervision Attention Network for Myocardial  Scar and Edema Segmentation in Multi-sequence Cardiac Magnetic Resonance  Images,"Multi-sequence cardiac magnetic resonance (CMR) provides essential pathology
information (scar and edema) to diagnose myocardial infarction. However,
automatic pathology segmentation can be challenging due to the difficulty of
effectively exploring the underlying information from the multi-sequence CMR
data. This paper aims to tackle the scar and edema segmentation from
multi-sequence CMR with a novel auto-weighted supervision framework, where the
interactions among different supervised layers are explored under a
task-specific objective using reinforcement learning. Furthermore, we design a
coarse-to-fine framework to boost the small myocardial pathology region
segmentation with shape prior knowledge. The coarse segmentation model
identifies the left ventricle myocardial structure as a shape prior, while the
fine segmentation model integrates a pixel-wise attention strategy with an
auto-weighted supervision model to learn and extract salient pathological
structures from the multi-sequence CMR data. Extensive experimental results on
a publicly available dataset from Myocardial pathology segmentation combining
multi-sequence CMR (MyoPS 2020) demonstrate our method can achieve promising
performance compared with other state-of-the-art methods. Our method is
promising in advancing the myocardial pathology assessment on multi-sequence
CMR data. To motivate the community, we have made our code publicly available
via https://github.com/soleilssss/AWSnet/tree/master.",,,arXiv,,,2022-01-14,2022,,,,,,All OA, Green,Preprint,"Wang, Kai-Ni; Yang, Xin; Miao, Juzheng; Li, Lei; Yao, Jing; Zhou, Ping; Xue, Wufeng; Zhou, Guang-Quan; Zhuang, Xiahai; Ni, Dong","Wang, Kai-Ni (); Yang, Xin (); Miao, Juzheng (); Li, Lei (); Yao, Jing (); Zhou, Ping (); Xue, Wufeng (); Zhou, Guang-Quan (); Zhuang, Xiahai (); Ni, Dong ()",,"Wang, Kai-Ni (); Yang, Xin (); Miao, Juzheng (); Li, Lei (); Yao, Jing (); Zhou, Ping (); Xue, Wufeng (); Zhou, Guang-Quan (); Zhuang, Xiahai (); Ni, Dong ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1144723593,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
906,pub.1144584935,10.48550/arxiv.2201.03186,,,MyoPS: A Benchmark of Myocardial Pathology Segmentation Combining  Three-Sequence Cardiac Magnetic Resonance Images,"Assessment of myocardial viability is essential in diagnosis and treatment
management of patients suffering from myocardial infarction, and classification
of pathology on myocardium is the key to this assessment. This work defines a
new task of medical image analysis, i.e., to perform myocardial pathology
segmentation (MyoPS) combining three-sequence cardiac magnetic resonance (CMR)
images, which was first proposed in the MyoPS challenge, in conjunction with
MICCAI 2020. The challenge provided 45 paired and pre-aligned CMR images,
allowing algorithms to combine the complementary information from the three CMR
sequences for pathology segmentation. In this article, we provide details of
the challenge, survey the works from fifteen participants and interpret their
methods according to five aspects, i.e., preprocessing, data augmentation,
learning strategy, model architecture and post-processing. In addition, we
analyze the results with respect to different factors, in order to examine the
key obstacles and explore potential of solutions, as well as to provide a
benchmark for future research. We conclude that while promising results have
been reported, the research is still in the early stage, and more in-depth
exploration is needed before a successful application to the clinics. Note that
MyoPS data and evaluation tool continue to be publicly available upon
registration via its homepage
(www.sdspeople.fudan.edu.cn/zhuangxiahai/0/myops20/).",,,arXiv,,,2022-01-10,2022,,,,,,All OA, Green,Preprint,"Li, Lei; Wu, Fuping; Wang, Sihan; Luo, Xinzhe; Martin-Isla, Carlos; Zhai, Shuwei; Zhang, Jianpeng; Liu7, Yanfei; Zhang, Zhen; Ankenbrand, Markus J.; Jiang, Haochuan; Zhang, Xiaoran; Wang, Linhong; Arega, Tewodros Weldebirhan; Altunok, Elif; Zhao, Zhou; Li, Feiyan; Ma, Jun; Yang, Xiaoping; Puybareau, Elodie; Oksuz, Ilkay; Bricq, Stephanie; Li, Weisheng; Punithakumar, Kumaradevan; Tsaftaris, Sotirios A.; Schreiber, Laura M.; Yang, Mingjing; Liu, Guocai; Xia, Yong; Wang, Guotai; Escalera, Sergio; Zhuang, Xiahai","Li, Lei (); Wu, Fuping (); Wang, Sihan (); Luo, Xinzhe (); Martin-Isla, Carlos (); Zhai, Shuwei (); Zhang, Jianpeng (); Liu7, Yanfei (); Zhang, Zhen (); Ankenbrand, Markus J. (); Jiang, Haochuan (); Zhang, Xiaoran (); Wang, Linhong (); Arega, Tewodros Weldebirhan (); Altunok, Elif (); Zhao, Zhou (); Li, Feiyan (); Ma, Jun (); Yang, Xiaoping (); Puybareau, Elodie (); Oksuz, Ilkay (); Bricq, Stephanie (); Li, Weisheng (); Punithakumar, Kumaradevan (); Tsaftaris, Sotirios A. (); Schreiber, Laura M. (); Yang, Mingjing (); Liu, Guocai (); Xia, Yong (); Wang, Guotai (); Escalera, Sergio (); Zhuang, Xiahai ()",,"Li, Lei (); Wu, Fuping (); Wang, Sihan (); Luo, Xinzhe (); Martin-Isla, Carlos (); Zhai, Shuwei (); Zhang, Jianpeng (); Liu7, Yanfei (); Zhang, Zhen (); Ankenbrand, Markus J. (); Jiang, Haochuan (); Zhang, Xiaoran (); Wang, Linhong (); Arega, Tewodros Weldebirhan (); Altunok, Elif (); Zhao, Zhou (); Li, Feiyan (); Ma, Jun (); Yang, Xiaoping (); Puybareau, Elodie (); Oksuz, Ilkay (); Bricq, Stephanie (); Li, Weisheng (); Punithakumar, Kumaradevan (); Tsaftaris, Sotirios A. (); Schreiber, Laura M. (); Yang, Mingjing (); Liu, Guocai (); Xia, Yong (); Wang, Guotai (); Escalera, Sergio (); Zhuang, Xiahai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1144584935,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
5351,pub.1144437134,10.1002/mrm.29143,34985143,,Cartesian dictionary‐based native T1 and T2 mapping of the myocardium,"PURPOSE: To implement and evaluate a new dictionary-based technique for native myocardial T1 and T2 mapping using Cartesian sampling.
METHODS: The proposed technique (Multimapping) consisted of single-shot Cartesian image acquisitions in 10 consecutive cardiac cycles, with inversion pulses in cycle 1 and 5, and T2 preparation (TE: 30 ms, 50 ms, and 70 ms) in cycles 8-10. Multimapping was simulated for different T1 and T2 , where entries corresponding to the k-space centers were matched to acquired data. Experiments were performed in a phantom, 16 healthy subjects, and 3 patients with cardiovascular disease.
RESULTS: Multimapping phantom measurements showed good agreement with reference values for both T1 and T2 , with no discernable heart-rate dependency for T1 and T2 within the range of myocardium. In vivo mean T1 in healthy subjects was significantly higher using Multimapping (T1 = 1114 ± 14 ms) compared to the reference (T1 = 991 ± 26 ms) (p < 0.01). Mean Multimapping T2 (47.1 ± 1.3 ms) and T2 spatial variability (5.8 ± 1.0 ms) was significantly lower compared to the reference (T2 = 54.7 ± 2.2 ms, p < 0.001; spatial variability = 8.4 ± 2.0 ms, p < 0.01). Increased T1 and T2 was detected in all patients using Multimapping.
CONCLUSIONS: Multimapping allows for simultaneous native myocardial T1 and T2 mapping with a conventional Cartesian trajectory, demonstrating promising in vivo image quality and parameter quantification results.",The author thanks Dr. Anders Tisell for lending the ISMRM/NIST phantom for these experiments.,,Magnetic Resonance in Medicine,,"Heart; Humans; Myocardium; Phantoms, Imaging; Reference Values; Reproducibility of Results",2022-01-05,2022,2022-01-05,2022-05,87,5,2347-2362,All OA, Hybrid,Article,"Henningsson, Markus","Henningsson, Markus (Division of Diagnostics and Specialist Medicine, Department of Health, Medicine and Caring Sciences (HMV), Linköping University, Linköping, Sweden; Center for Medical Image Science and Visualization (CMIV), Linköping University, Linköping, Sweden)","Henningsson, Markus (Linköping University; Linköping University)","Henningsson, Markus (Linköping University; Linköping University)",4,4,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.29143,https://app.dimensions.ai/details/publication/pub.1144437134,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,
754,pub.1146955022,10.1109/access.2022.3165574,,,Skin Disease Analysis With Limited Data in Particular Rosacea: A Review and Recommended Framework,"Recently, the rapid advancements in Deep Learning and Computer Vision technologies have introduced a new and exciting era in the field of skin disease analysis. However, there are certain challenges in the roadmap towards developing such technologies for real-life applications that must be investigated. This study considers one of the key challenges in data acquisition and computation, viz. data scarcity. Data scarcity is a central problem in acquiring medical images and applying machine learning techniques to train Convolutional Neural Networks for disease diagnosis. The main objective of this study is to explore the possible methods to deal with the data scarcity problem and to improve diagnosis with small datasets. The challenges in data acquisition for a few lamentably neglected skin conditions such as rosacea are an excellent instance to explore the possibilities of improving computer-aided skin disease diagnosis. With data scarcity in mind, the possible techniques explored and discussed include Generative Adversarial Networks, Meta-Learning, Few-Shot classification, and 3D face modelling. Furthermore, the existing studies are discussed based on skin conditions considered, data volume and implementation choices. Some future research directions are recommended.",,This work was supported by the Science Foundation Ireland Centre for Research Training in Digitally-Enhanced Reality (d-real) under Grant 18/CRT/6224.,IEEE Access,,,2022-01-01,2022,2022-04-07,2022-01-01,10,,39045-39068,All OA, Gold,Article,"Mohanty, Anwesha; Sutherland, Alistair; Bezbradica, Marija; Javidnia, Hossein","Mohanty, Anwesha (School of Computing, Dublin City University, Dublin 9, D09 V209, Ireland); Sutherland, Alistair (School of Computing, Dublin City University, Dublin 9, D09 V209, Ireland); Bezbradica, Marija (School of Computing, Dublin City University, Dublin 9, D09 V209, Ireland); Javidnia, Hossein (School of Computing, Dublin City University, Dublin 9, D09 V209, Ireland)","Mohanty, Anwesha (Dublin City University)","Mohanty, Anwesha (Dublin City University); Sutherland, Alistair (Dublin City University); Bezbradica, Marija (Dublin City University); Javidnia, Hossein (Dublin City University)",0,0,,,https://ieeexplore.ieee.org/ielx7/6287639/9668973/09751076.pdf,https://app.dimensions.ai/details/publication/pub.1146955022,46 Information and Computing Sciences, 4611 Machine Learning,6 Clean Water and Sanitation,,,,,,,,,
1649,pub.1154882218,10.1007/978-3-031-23443-9_46,,,Automatic Cardiac Magnetic Resonance Respiratory Motions Assessment and Segmentation,"Cardiac magnetic resonance imaging (CMR) is a powerful non-invasive tool for diagnosing a variety of cardiovascular diseases. However, the quality of CMR imaging is susceptible to respiratory motion artifacts. Recently, an extreme cardiac MRI analysis challenge was organized to assess the effects of respiratory motion on CMR imaging quality and develop a robust segmentation framework under different levels of respiratory motion. In this paper, we have presented two different deep learning frameworks for CMR imaging quality assessment and automatic segmentation. First, we have developed 3D-DenseNet to assess the image quality, followed by 3D-deep supervision UNet with the residual module using pseudo labelling for automatic segmentation task. Experiments on the Challenge dataset showed that 3D ResNet with deep supervision using Pseudo Labeling with nnUNet achieved significantly better performance (8.747 LV, 3.787 MYO, and 5.942 RV) HD95 score than 3D-UNet.",,,Lecture Notes in Computer Science,Statistical Atlases and Computational Models of the Heart. Regular and CMRxMotion Challenge Papers,,2022,2022,2023-01-28,2022,13593,,485-493,Closed,Chapter,"Qayyum, Abdul; Mazher, Moona; Niederer, Steven; Meriaudeau, Fabrice; Razzak, Imran","Qayyum, Abdul (ENIB, UMR CNRS 6285 LabSTICC, 29238, Brest, France; Department of Biomedical Engineering, King’s College London, London, UK); Mazher, Moona (Department of Computer Engineering and Mathematics, University Rovira I Virgili, Tarragona, Spain); Niederer, Steven (Department of Biomedical Engineering, King’s College London, London, UK); Meriaudeau, Fabrice (ImViA Laboratory, University of Bourgogne Franche-Comt́e, Dijon, France); Razzak, Imran (University of New South Wales, Sydney, NSW, Australia)","Qayyum, Abdul (Brest National Engineering School; King's College London)","Qayyum, Abdul (Brest National Engineering School; King's College London); Mazher, Moona (Rovira i Virgili University); Niederer, Steven (King's College London); Meriaudeau, Fabrice (Université Bourgogne Franche-Comté); Razzak, Imran (UNSW Sydney)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154882218,46 Information and Computing Sciences,,,,,,,,,,,,
1457,pub.1154882219,10.1007/978-3-031-23443-9_47,,,Robust Cardiac MRI Segmentation with Data-Centric Models to Improve Performance via Intensive Pre-training and Augmentation,"Segmentation of anatomical structures from Cardiac Magnetic Resonance (CMR) is central to the non-invasive quantitative assessment of cardiac function and structure, and deep-learning-based automatic segmentation models prove to have satisfying performance. However, patients’ respiratory motion during the scanning process can greatly degenerate the quality of CMR images, resulting in a serious performance drop for deep learning algorithms. Building a robust cardiac MRI segmentation model is one of the keys to facilitating the use of deep learning in practical clinic scenarios. To this end, we experiment with several network architectures and compare their segmentation accuracy and robustness to respiratory motion. We further pre-train our network on large publicly available CMR datasets and augment our training set with adversarial augmentation, both methods bring significant improvement. We evaluate our methods on the cine MRI dataset of the CMRxMotion challenge and obtain promising performance for the segmentation of the left ventricle, left ventricular myocardium, and right ventricle.",,,Lecture Notes in Computer Science,Statistical Atlases and Computational Models of the Heart. Regular and CMRxMotion Challenge Papers,,2022,2022,2023-01-28,2022,13593,,494-504,Closed,Chapter,"Gong, Shizhan; Lu, Weitao; Xie, Jize; Zhang, Xiaofan; Zhang, Shaoting; Dou, Qi","Gong, Shizhan (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China); Lu, Weitao (School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China); Xie, Jize (School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China); Zhang, Xiaofan (School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China); Zhang, Shaoting (School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China); Dou, Qi (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China)","Gong, Shizhan (Chinese University of Hong Kong)","Gong, Shizhan (Chinese University of Hong Kong); Lu, Weitao (Shanghai Jiao Tong University); Xie, Jize (Shanghai Jiao Tong University); Zhang, Xiaofan (Shanghai Jiao Tong University; Shanghai Artificial Intelligence Laboratory); Zhang, Shaoting (Shanghai Jiao Tong University; Shanghai Artificial Intelligence Laboratory); Dou, Qi (Chinese University of Hong Kong)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154882219,46 Information and Computing Sciences,,,,,,,,,,,,
1299,pub.1154882223,10.1007/978-3-031-23443-9_7,,,Self-supervised Motion Descriptor for Cardiac Phase Detection in 4D CMR Based on Discrete Vector Field Estimations,"Cardiac magnetic resonance (CMR) sequences visualise the cardiac function voxel-wise over time. Simultaneously, deep learning-based deformable image registration is able to estimate discrete vector fields which warp one time step of a CMR sequence to the following in a self-supervised manner. However, despite the rich source of information included in these 3D+t vector fields, a standardised interpretation is challenging and the clinical applications remain limited so far. In this work, we show how to efficiently use a deformable vector field to describe the underlying dynamic process of a cardiac cycle in form of a derived 1D motion descriptor. Additionally, based on the expected cardiovascular physiological properties of a contracting or relaxing ventricle, we define a set of rules that enables the identification of five cardiovascular phases including the end-systole (ES) and end-diastole (ED) without usage of labels. We evaluate the plausibility of the motion descriptor on two challenging multi-disease, -center, -scanner short-axis CMR datasets. First, by reporting quantitative measures such as the periodic frame difference for the extracted phases. Second, by comparing qualitatively the general pattern when we temporally resample and align the motion descriptors of all instances across both datasets. The average periodic frame difference for the ED, ES key phases of our approach is 0.80±0.85\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.80\pm {0.85}$$\end{document}, 0.69±0.79\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.69\pm {0.79}$$\end{document} which is slightly better than the inter-observer variability (1.07±0.86\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1.07\pm {0.86}$$\end{document}, 0.91±1.6\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.91\pm {1.6}$$\end{document}) and the supervised baseline method (1.18±1.91\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1.18\pm {1.91}$$\end{document}, 1.21±1.78\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1.21\pm {1.78}$$\end{document}). Code and labels are available on our GitHub repository. https://github.com/Cardio-AI/cmr-phase-detection.","This work was supported in parts by the Informatics for Life Project through the Klaus Tschira Foundation, by the Competence Network for Congenital Heart Defects (Federal Ministry of Education and Research/grant number 01GI0601) and the National Register for Congenital Heart Defects (Federal Ministry of Education and Research/grant number 01KX2140), by the German Centre for Cardiovascular Research (DZHK) and the SDS@hd service by the MWK Baden-Württemberg and the DFG through grant INST 35/1314-1 FUGG and INST 35/1503-1 FUGG.",,Lecture Notes in Computer Science,Statistical Atlases and Computational Models of the Heart. Regular and CMRxMotion Challenge Papers,,2022,2022,2023-01-28,2022,13593,,65-78,All OA, Green,Chapter,"Koehler, Sven; Hussain, Tarique; Hussain, Hamza; Young, Daniel; Sarikouch, Samir; Pickardt, Thomas; Greil, Gerald; Engelhardt, Sandy","Koehler, Sven (Department of Internal Medicine III, Group Artificial Intelligence in Cardiovascular Medicine, Heidelberg University Hospital, 69120, Heidelberg, Germany; DZHK (German Centre for Cardiovascular Research), Heidelberg, Germany); Hussain, Tarique (Department of Pediatrics, Division of Cardiology; Department of Radiology; Adv. Imaging Research Center, UT Southwestern Medical Center, Dallas, TX, USA); Hussain, Hamza (Department of Internal Medicine III, Group Artificial Intelligence in Cardiovascular Medicine, Heidelberg University Hospital, 69120, Heidelberg, Germany); Young, Daniel (Department of Pediatrics, Division of Cardiology; Department of Radiology; Adv. Imaging Research Center, UT Southwestern Medical Center, Dallas, TX, USA); Sarikouch, Samir (DZHK (German Centre for Cardiovascular Research), Heidelberg, Germany; German Competence Network for Congenital Heart Defects, Berlin, Germany; Department of Cardiothoracic, Transplantation and Vascular Surgery, Hannover Medical School, Hannover, Germany); Pickardt, Thomas (German Competence Network for Congenital Heart Defects, Berlin, Germany); Greil, Gerald (Department of Pediatrics, Division of Cardiology; Department of Radiology; Adv. Imaging Research Center, UT Southwestern Medical Center, Dallas, TX, USA); Engelhardt, Sandy (Department of Internal Medicine III, Group Artificial Intelligence in Cardiovascular Medicine, Heidelberg University Hospital, 69120, Heidelberg, Germany; DZHK (German Centre for Cardiovascular Research), Heidelberg, Germany)","Koehler, Sven (University Hospital Heidelberg; German Centre for Cardiovascular Research)","Koehler, Sven (University Hospital Heidelberg; German Centre for Cardiovascular Research); Hussain, Tarique (The University of Texas Southwestern Medical Center); Hussain, Hamza (University Hospital Heidelberg); Young, Daniel (The University of Texas Southwestern Medical Center); Sarikouch, Samir (German Centre for Cardiovascular Research; Hannover Medical School); Pickardt, Thomas (); Greil, Gerald (The University of Texas Southwestern Medical Center); Engelhardt, Sandy (University Hospital Heidelberg; German Centre for Cardiovascular Research)",0,0,,,http://arxiv.org/pdf/2209.05778,https://app.dimensions.ai/details/publication/pub.1154882223,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1133,pub.1151463713,10.2139/ssrn.4211385,,,A Motion Aware Dnn Model with Edge Focus Loss and Quality Control for Short-Axis Left Ventricle Segmentation of Cine Mr Sequences,"Background and objective: Accurate segmentation of LV myocardium is the key step of automatic assessment of cardiac function. However, the current models mainly focus on the segmentation of the end-diastolic (ED) and end-systolic (ES) frames of cine MR, and lack the attention to myocardium motions in entire cardiac cycle. Methods: In this paper we propose a motion aware DNN model for Short-axis Left ventricle segmentation in entire cardiac cycle. We proposed a new motion attention layer based on time-distributed U-Net model to encode shapes in both temporal directions, and an edge focus loss function to make the segmented boundaries be consistent with the local gradient of the input images. It is important to be able to detect when auto segmentation fails, and thus we proposed a quality control method based on Image Moments to filter abnormal epicardium predictions for further diagnosis manually. Results: We demonstrate the efficacy of the proposed model using cine MR sequences of 147 subjects and compare the performance with 12 state-of-the-art segmentation models. The proposed model has obtained the highest prediction accuracy with DC of 94%, 98%, HD of 8.68, 7.52 for endocardium and epicardium segmentation respectively. On the 17-segment model, the proposed model has obtained the highest Pearson Correlation Coefficient (PCC) at 14 of 17 segments, and the mean PCC of 85% for all segments. Bland-Altman analysis plots show that the motion curves of the segmented endocardium and epicardium are very close to the ground truth. Conclusion: Our method is promising in advancing the segmentation for short-axis left ventricle in cine MR sequences. Keywords: U-Net model; Short-axis Left ventricle segmentation; loss function; quality control.",,,SSRN Electronic Journal,,,2022,2022,,,,,,All OA, Green,Preprint,"Wang, Yu; SUN, ZHENG; LIU, ZHI; Lu, Jie; Zhang, Nan","Wang, Yu (Capital Medical University - Department of Biomedical Engineering); SUN, ZHENG (Capital Medical University); LIU, ZHI (Capital Medical University); Lu, Jie (Capital Medical University - Department of Radiology); Zhang, Nan (Capital Medical University - Department of Biomedical Engineering)",,"Wang, Yu (Capital Medical University); SUN, ZHENG (Capital Medical University); LIU, ZHI (Capital Medical University); Lu, Jie (Capital Medical University); Zhang, Nan (Capital Medical University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151463713,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
1070,pub.1149148749,10.1016/b978-0-12-824349-7.00023-2,,,Chapter 16 Regularizing disentangled representations with anatomical temporal consistency,"Deep neural networks have shown to be promising approaches for medical image analysis. However, their training is most effective when they learn robust data representations using large-scale annotated datasets, which are tedious to acquire in clinical practice. As medical annotations are often limited, there has been an increasing interest in making data representations robust in case of data lack. In particular, a spate of research focuses on constraining the learned representations to be interpretable and able to separate out, or disentangle, the data explanatory factors. This chapter discusses recent disentanglement frameworks, with a special focus on the image segmentation task. We build on a recent approach for disentanglement of cardiac medical images into disjoint patient anatomy and imaging modality dependent representations. We incorporate into the model a purposely designed architecture (which we term “temporal transformer”) which, from a given image and a time gap, can estimate anatomical representations of an image at a future time-point within the cardiac cycle of cine MRI. The transformer's role is to introduce a self-supervised objective to encourage the emergence of temporally coherent data representations. We show that such a regularization improves the quality of disentangled representations, ultimately increasing semi-supervised segmentation performance when annotations are scarce. Finally, we show that predicting future representations can be potentially used for image synthesis tasks.","This work was supported by the Erasmus+ Programme of the European Union, during an exchange between IMT School for Advanced Studies Lucca and the School of Engineering, University of Edinburgh. S.A. Tsaftaris acknowledges the support of the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme. We thank NVIDIA Corporation for donating the Titan Xp GPU used for this research.",,,Biomedical Image Synthesis and Simulation,,2022,2022,,2022,,,325-346,Closed,Chapter,"Valvano, Gabriele; Leo, Andrea; Tsaftaris, Sotirios A.","Valvano, Gabriele (IMT School for Advanced Studies Lucca, Lucca, Italy; School of Engineering, University of Edinburgh, Edinburgh, United Kingdom); Leo, Andrea (Department of Translational Research on New Technologies in Medicine and Surgery, University of Pisa, Pisa, Italy); Tsaftaris, Sotirios A. (School of Engineering, University of Edinburgh, Edinburgh, United Kingdom)",,"Valvano, Gabriele (IMT Institute for Advanced Studies Lucca; University of Edinburgh); Leo, Andrea (University of Pisa); Tsaftaris, Sotirios A. (University of Edinburgh)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149148749,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1066,pub.1145820751,10.1016/j.imu.2022.100884,,,Detect-and-segment: A deep learning approach to automate wound image segmentation,"Chronic wounds significantly impact quality of life. They can rapidly deteriorate and require close monitoring of healing progress. Image-based wound analysis is a way of objectively assessing the wound status by quantifying important features that are related to healing. However, high heterogeneity of the wound types and imaging conditions challenge the robust segmentation of wound images. We present Detect-and-Segment (DS), a deep learning approach to produce wound segmentation maps with high generalization capabilities. In our approach, dedicated deep neural networks detected the wound position, isolated the wound from the perturbing background, and computed a wound segmentation map. We tested this approach on a diabetic foot ulcers data set and compared it to a segmentation method based on the full image. To evaluate its generalizability on out-of-distribution data, we measured the performance of the DS approach on 4 additional independent data sets, with larger variety of wound types from different body locations. The Matthews’ correlation coefficient (MCC) improved from 0.29 (full image) to 0.85 (DS) on the diabetic foot ulcer data set. When the DS was tested on the independent data sets, the mean MCC increased from 0.17 to 0.85 . Furthermore, the DS enabled the training of segmentation models with up to 90% less training data without impacting the segmentation performance. The proposed DS approach is a step towards automating wound analysis and reducing efforts to manage chronic wounds.","We thank J. Toledo, F. Marion, S. Weidmann, L. Halter, and M. Emmenegger for assisting with patients recruitment and data collection, and M. Patwari, D. Chishima, and H. Orefice for technical developments of the wound image acquisition app.",,Informatics in Medicine Unlocked,,,2022,2022,,2022,29,,100884,All OA, Gold,Article,"Scebba, Gaetano; Zhang, Jia; Catanzaro, Sabrina; Mihai, Carina; Distler, Oliver; Berli, Martin; Karlen, Walter","Scebba, Gaetano (Mobile Health Systems Lab, Institute of Robotics and Intelligent Systems, Department of Health Sciences and Technology, ETH Zurich, Switzerland); Zhang, Jia (Mobile Health Systems Lab, Institute of Robotics and Intelligent Systems, Department of Health Sciences and Technology, ETH Zurich, Switzerland); Catanzaro, Sabrina (Unit for Clinical and Applied Research, Balgrist University Hospital, Zurich, Switzerland); Mihai, Carina (Department of Rheumatology, University Hospital Zurich, University of Zurich, Switzerland); Distler, Oliver (Department of Rheumatology, University Hospital Zurich, University of Zurich, Switzerland); Berli, Martin (Division of Technical Orthopedics, Department of Orthopedic Surgery, Balgrist University Hospital, Zurich, Switzerland); Karlen, Walter (Mobile Health Systems Lab, Institute of Robotics and Intelligent Systems, Department of Health Sciences and Technology, ETH Zurich, Switzerland)","Scebba, Gaetano (ETH Zurich)","Scebba, Gaetano (ETH Zurich); Zhang, Jia (ETH Zurich); Catanzaro, Sabrina (Universitätsklinik Balgrist); Mihai, Carina (University Hospital of Zurich; University of Zurich); Distler, Oliver (University Hospital of Zurich; University of Zurich); Berli, Martin (Universitätsklinik Balgrist); Karlen, Walter (ETH Zurich)",6,6,,,https://doi.org/10.1016/j.imu.2022.100884,https://app.dimensions.ai/details/publication/pub.1145820751,42 Health Sciences, 4203 Health Services and Systems,,,,,,,,,,
284,pub.1153410139,10.1007/978-981-19-6649-1,,,Innovative Treatment Strategies for Clinical Electrophysiology,"This book highlights the advancements in different fields of clinical electrophysiology and gives the reader a good background of the established practices. To tackle such a wide topic, the book focuses on two main aspects: ablation and pacing, discussing the novel energy sources and approaches to rhythm restoration and control; devices and signal processing, highlighting the new available technologies and numerical approaches aiding practice and home medicine. It also presents the reader with selected strategies that could be a paradigm shifts for the field: in situ cell reprogramming, exploiting the newly founded achievements in epigenetic modification of somatic cells; artificial intelligence; cardiac digital twinning, which aims to collect the information from imaging, mechanics and electrophysiology and condense it into a patient-specific model for personalized treatment.",,,Lecture Notes in Bioengineering,,,2022,2022,,2022,,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1153410139,40 Engineering, 4006 Communications Engineering,,,,,,,,,,,
278,pub.1154882177,10.1007/978-3-031-23443-9,,,"Statistical Atlases and Computational Models of the Heart. Regular and CMRxMotion Challenge Papers, 13th International Workshop, STACOM 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Revised Selected Papers","This book constitutes the proceedings of the 13th International Workshop on Statistical Atlases and Computational Models of the Heart, STACOM 2022, held in conjunction with the 25th MICCAI conference. The 34 regular workshop papers included in this volume were carefully reviewed and selected after being revised and deal with topics such as: common cardiac segmentation and modelling problems to more advanced generative modelling for ageing hearts, learning cardiac motion using biomechanical networks, physics-informed neural networks for left atrial appendage occlusion, biventricular mechanics for Tetralogy of Fallot, ventricular arrhythmia prediction by using graph convolutional network, and deeper analysis of racial and sex biases from machine learning-based cardiac segmentation. In addition, 14 papers from the CMRxMotion challenge are included in the proceedings which aim to assess the effects of respiratory motion on cardiac MRI (CMR) imaging quality and examine the robustness of segmentation models in face of respiratory motion artefacts. A total of 48 submissions to the workshop was received.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13593,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1154882177,46 Information and Computing Sciences,,,,,,,,,,,,
267,pub.1151155487,10.1007/978-3-031-16980-9,,,"Simulation and Synthesis in Medical Imaging, 7th International Workshop, SASHIMI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Proceedings","This book constitutes the refereed proceedings of the 7th International Workshop on Simulation and Synthesis in Medical Imaging, SASHIMI 2022, held in conjunction with MICCAI 2022, in Singapore, Singapore in September 2022.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13570,,,All OA, Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16980-9%2F1,https://app.dimensions.ai/details/publication/pub.1151155487,46 Information and Computing Sciences,,,,,,,,,,,
99,pub.1153662504,10.1007/978-3-031-21014-3,,,"Machine Learning in Medical Imaging, 13th International Workshop, MLMI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Proceedings","This book constitutes the proceedings of the 13th International Workshop on Machine Learning in Medical Imaging, MLMI 2022, held in conjunction with MICCAI 2022, in Singapore, in September 2022. The 48 full papers presented in this volume were carefully reviewed and selected from 64 submissions. They focus on major trends and challenges in the above-mentioned area, aiming to identify new-cutting-edge techniques and their uses in medical imaging. Topics dealt with are: deep learning, generative adversarial learning, ensemble learning, sparse learning, multi-task learning, multi-view learning, manifold learning, and reinforcement learning, with their applications to medical image analysis, computer-aided detection and diagnosis, multi-modality fusion, image reconstruction, image retrieval, cellular image analysis, molecular imaging, digital pathology, etc.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13583,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1153662504,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
68,pub.1141560550,10.1007/978-981-16-3637-0,,,"Networking, Intelligent Systems and Security, Proceedings of NISS 2021","This book gathers best selected research papers presented at the International Conference on Networking, Intelligent Systems and Security, held in Kenitra, Morocco, during 01–02 April 2021. The book highlights latest research and findings in the field of ICT, and it provides new solutions, efficient tools, and techniques that draw on modern technologies to increase urban services. In addition, it provides a critical overview of the status quo, shares new propositions, and outlines future perspectives in networks, smart systems, security, information technologies, and computer science.",,,"Smart Innovation, Systems and Technologies",,,2022,2022,,2022,237,,,All OA, Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm:978-981-16-3637-0/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1141560550,46 Information and Computing Sciences, 4604 Cybersecurity and Privacy,,,,,,,,,,
61,pub.1150997048,10.1007/978-3-031-16431-6,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2022, 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part I","The eight-volume set LNCS 13431, 13432, 13433, 13434, 13435, 13436, 13437, and 13438 constitutes the refereed proceedings of the 25th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2022, which was held in Singapore in September 2022. The 574 revised full papers presented were carefully reviewed and selected from 1831 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: Brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; heart and lung imaging; dermatology; Part II: Computational (integrative) pathology; computational anatomy and physiology; ophthalmology; fetal imaging; Part III: Breast imaging; colonoscopy; computer aided diagnosis; Part IV: Microscopic image analysis; positron emission tomography; ultrasound imaging; video data analysis; image segmentation I; Part V: Image segmentation II; integration of imaging with non-imaging biomarkers; Part VI: Image registration; image reconstruction; Part VII: Image-Guided interventions and surgery; outcome and disease prediction; surgical data science; surgical planning and simulation; machine learning – domain adaptation and generalization; Part VIII: Machine learning – weakly-supervised learning; machine learning – model interpretation; machine learning – uncertainty; machine learning theory and methodologies.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13431,,,All OA, Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16431-6%2F1,https://app.dimensions.ai/details/publication/pub.1150997048,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
61,pub.1151072692,10.1007/978-3-031-16449-1,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2022, 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part VII","The eight-volume set LNCS 13431, 13432, 13433, 13434, 13435, 13436, 13437, and 13438 constitutes the refereed proceedings of the 25th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2022, which was held in Singapore in September 2022. The 574 revised full papers presented were carefully reviewed and selected from 1831 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: Brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; heart and lung imaging; dermatology; Part II: Computational (integrative) pathology; computational anatomy and physiology; ophthalmology; fetal imaging; Part III: Breast imaging; colonoscopy; computer aided diagnosis; Part IV: Microscopic image analysis; positron emission tomography; ultrasound imaging; video data analysis; image segmentation I; Part V: Image segmentation II; integration of imaging with non-imaging biomarkers; Part VI: Image registration; image reconstruction; Part VII: Image-Guided interventions and surgery; outcome and disease prediction; surgical data science; surgical planning and simulation; machine learning – domain adaptation and generalization; Part VIII: Machine learning – weakly-supervised learning; machine learning – model interpretation; machine learning – uncertainty; machine learning theory and methodologies.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13437,,,All OA, Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16449-1%2F1,https://app.dimensions.ai/details/publication/pub.1151072692,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
50,pub.1147287896,10.1007/978-3-030-92087-6,,,Artificial Intelligence in Cardiothoracic Imaging,"This book provides an overview of current and potential applications of artificial intelligence (AI) for cardiothoracic imaging. Most AI systems used in medical imaging are data-driven and based on supervised machine learning. Clinicians and AI specialists can contribute to the development of an AI system in different ways, focusing on their respective strengths. Unfortunately, communication between these two sides is far from fluent and, from time to time, they speak completely different languages. Mutual understanding and collaboration are imperative because the medical system is based on physicians’ ability to take well-informed decisions and convey their reasoning to colleagues and patients. This book offers unique insights and informative chapters on the use of AI for cardiothoracic imaging from both the technical and clinical perspective. It is also a single comprehensive source that provides a complete overview of the entire process of the development and use of AI in clinical practice for cardiothoracic imaging. The book contains chapters focused on cardiac and thoracic applications as well more general topics on the potentials and pitfalls of AI in medical imaging. Separate chapters will discuss the valorization, regulations surrounding AI, cost-effectiveness, and future perspective for different countries and continents. This book is an ideal guide for clinicians (radiologists, cardiologists etc.) interested in working with AI, whether in a research setting developing new AI applications or in a clinical setting using AI algorithms in clinical practice. The book also provides clinical insights and overviews for AI specialists who want to develop clinically relevant AI applications.",,,Contemporary Medical Imaging,,,2022,2022,,2022,,,,All OA, Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm:978-3-030-92087-6/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1147287896,46 Information and Computing Sciences, 4602 Artificial Intelligence,,,,,,,,,,
4530,pub.1140749313,10.1109/tmi.2021.3108881,34460369,,Learning a Model-Driven Variational Network for Deformable Image Registration,"Data-driven deep learning approaches to image registration can be less accurate than conventional iterative approaches, especially when training data is limited. To address this issue and meanwhile retain the fast inference speed of deep learning, we propose VR-Net, a novel cascaded variational network for unsupervised deformable image registration. Using a variable splitting optimization scheme, we first convert the image registration problem, established in a generic variational framework, into two sub-problems, one with a point-wise, closed-form solution and the other one being a denoising problem. We then propose two neural layers (i.e. warping layer and intensity consistency layer) to model the analytical solution and a residual U-Net (termed generalized denoising layer) to formulate the denoising problem. Finally, we cascade the three neural layers multiple times to form our VR-Net. Extensive experiments on three (two 2D and one 3D) cardiac magnetic resonance imaging datasets show that VR-Net outperforms state-of-the-art deep learning methods on registration accuracy, whilst maintaining the fast inference speed of deep learning and the data-efficiency of variational models.","This work was supported in part by the British Heart Foundation Accelerator Award under Grant AA/18/2/34218; in part by the SmartHeart Engineering and Physical Sciences Research Council (EPSRC) Program Grant EP/P001009/1; in part by the U.K. Medical Research Council under Grant MC-A658-5QEB0; in part by the British Heart Foundation under Grant NH/17/1/32725, Grant RG/19/6/34387, and Grant RE/18/4/34215; in part by the National Natural Science Foundation of China under Grant 91959108; and in part by the U.K. Biobank Resource under Grant 40119. The work of Xi Jia was supported in part by China Scholarship Council.",,IEEE Transactions on Medical Imaging,,"Image Processing, Computer-Assisted; Magnetic Resonance Imaging",2021-12-30,2021,2021-12-30,2022-01,41,1,199-212,All OA, Green,Article,"Jia, Xi; Thorley, Alexander; Chen, Wei; Qiu, Huaqi; Shen, Linlin; Styles, Iain B.; Chang, Hyung Jin; Leonardis, Ales; de Marvao, Antonio; O’Regan, Declan P.; Rueckert, Daniel; Duan, Jinming","Jia, Xi (School of Computer Science, University of Birmingham, Birmingham, B15 2TT, U.K.); Thorley, Alexander (School of Computer Science, University of Birmingham, Birmingham, B15 2TT, U.K.); Chen, Wei (School of Computer Science, University of Birmingham, Birmingham, B15 2TT, U.K.); Qiu, Huaqi (Department of Computing, Imperial College London, London, SW7 2AZ, U.K.); Shen, Linlin (AI Research Center for Medical Image Analysis and Diagnosis, Marshall Laboratory of Biomedical Engineering, School of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, 518000, China); Styles, Iain B. (School of Computer Science, University of Birmingham, Birmingham, B15 2TT, U.K.; Alan Turing Institute, London, NW1 2DB, U.K.); Chang, Hyung Jin (School of Computer Science, University of Birmingham, Birmingham, B15 2TT, U.K.); Leonardis, Ales (School of Computer Science, University of Birmingham, Birmingham, B15 2TT, U.K.; Alan Turing Institute, London, NW1 2DB, U.K.); de Marvao, Antonio (MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); O’Regan, Declan P. (MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Rueckert, Daniel (Department of Computing, Imperial College London, London, SW7 2AZ, U.K.; Klinikum rechts der Isar, Technical University of Munich, 80333, Munich, Germany); Duan, Jinming (School of Computer Science, University of Birmingham, Birmingham, B15 2TT, U.K.; Alan Turing Institute, London, NW1 2DB, U.K.)","Duan, Jinming (University of Birmingham; The Alan Turing Institute)","Jia, Xi (University of Birmingham); Thorley, Alexander (University of Birmingham); Chen, Wei (University of Birmingham); Qiu, Huaqi (Imperial College London); Shen, Linlin (Shenzhen University; Chinese University of Hong Kong, Shenzhen); Styles, Iain B. (University of Birmingham; The Alan Turing Institute); Chang, Hyung Jin (University of Birmingham); Leonardis, Ales (University of Birmingham; The Alan Turing Institute); de Marvao, Antonio (Medical Research Council); O’Regan, Declan P. (Medical Research Council); Rueckert, Daniel (Imperial College London; Rechts der Isar Hospital; Technical University of Munich); Duan, Jinming (University of Birmingham; The Alan Turing Institute)",7,7,,5.76,http://pure-oai.bham.ac.uk/ws/files/148749171/jiax2021learni.pdf,https://app.dimensions.ai/details/publication/pub.1140749313,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,
1459,pub.1147938256,10.1109/it-ela52201.2021.9773601,,,Enhancement and Lightweight Fusion U-Net for Segmentation of Cardiac Structures in MRI,"Magnetic resonance imaging technology and the segmentation process are essential parts in obtaining accurate diagnosis of cardiac diseases. Recently, deep learning networks have shown progress in achieving good accuracy. However, the 2D network may not produce the required accuracy, and the use of 3D networks is restricted because of the computation and storage complexities. In this paper, a lightweight fusion U-Net (LWFU-Net) is proposed to achieve the trade-off between segmentation accuracy and complexities. LWFU-Net is a new variant of U-Net and LVRV-Net. It enhances 2D information by using a propagation flow approach with multipath and multilevel fusion. LWFU-Net operates via three stages. First, the adjacent slices of target slice are fused by using traditional average method, generating context information. Subsequently, the target slice is segmented similar to U-Net network, where the context information is fused with the target slice and the decoding results via concatenation operator and then processes information by using convolutional layers. Finally, the deep supervision generates the final outcome. The proposed networks are evaluated on the public Automated Cardiac Diagnosis Challenge dataset by using fivefold cross validation. LWFU-Net outperforms single-path LWU-Net and agrees with the LVRV-Net. The best performance of LWFU-Net exhibits mean dice similarity scores of 0.939 left ventricular cavity, 0.861 right ventricular cavity, and 0.885 left ventricular myocardium over the subtest of 10% of training set. Results demonstrate that LWFU-Net has an acceptable usage of 51 MB (weight memory), 13,274,252 (trainable parameters), and 20 G flop. It achieves a speedup of 6 for the training and approximately 2 for the testing.",,,,2021 2nd Information Technology To Enhance e-learning and Other Application (IT-ELA),,2021-12-29,2021,,2021-12-29,0,,88-93,Closed,Proceeding,"Salim, Ula T.; Dawwd, Shefa A.; Ali, Fakhrulddin H.","Salim, Ula T. (Computer Engineering Department, University of Mosul, Mosul, Iraq); Dawwd, Shefa A. (Computer Engineering Department, University of Mosul, Mosul, Iraq); Ali, Fakhrulddin H. (Computer Engineering Department, University of Mosul, Mosul, Iraq)",,"Salim, Ula T. (University of Mosul); Dawwd, Shefa A. (University of Mosul); Ali, Fakhrulddin H. (University of Mosul)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1147938256,40 Engineering, 46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
953,pub.1144260468,10.1049/ipr2.12406,,,MFAUNet: Multiscale feature attentive U‐Net for cardiac MRI structural segmentation,"The accurate and robust automatic segmentation of cardiac structures in magnetic resonance imaging (MRI) is significant in calculating cardiac clinical functional indices, and diagnosing heart diseases. Most U‐Net based methods use pooling, transposed convolution, and skip connection operations to integrate the multiscale features for improved segmentation in cardiac MRI. However, this architecture lacks adequate semantic connection between the channel and spatial information, and robustness in segmenting objects with significant shape variations. In this paper, a new multiscale feature attentive U‐Net for cardiac MRI structural segmentation method is proposed. An attention mechanism is adopted after concatenating the multi‐level features to aggregate different scale features and determine on which features to focus. Cascade and parallel dilated convolution is also employed in the decoder blocks and skip connection is employed to enhance the ability of sensing receptive fields for multiscale context information. Furthermore, deep supervision approach with a loss function that combines the dice and cross‐entropy losses to reduce overfitting and ensure better prediction is introduced. The proposed method was evaluated on three public cardiac datasets. The experimental results indicate that the method achieved competitive segmentation performance with the three datasets, which verifies the robustness and generalisability of the proposed network. In comparison with conventional U‐Net methods, the model leverages attention mechanism and dilated convolution block, which increases the semantic connection between the channel and the spatial information, and improves the robustness of the right ventricle segmentation performance. From the view of the Dice scores and segmentation results, the multiscale feature attentive U‐Net method is one of effective methods in segmenting cardiac MRI structures.","This study was supported by the National Natural Science Foundation (61976126), Shandong Natural Science Foundation (ZR2019MF003, ZR2017MF054).",,IET Image Processing,,,2021-12-28,2021,2021-12-28,2022-03,16,4,1227-1242,Closed,Article,"Li, Dapeng; Peng, Yanjun; Guo, Yanfei; Sun, Jindong","Li, Dapeng (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China); Peng, Yanjun (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China; Shandong Province Key Laboratory of Wisdom Mining Information Technology, Shandong University of Science and Technology, Qingdao, Shandong, China); Guo, Yanfei (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China); Sun, Jindong (College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, Shandong, China)","Peng, Yanjun (Shandong University of Science and Technology; Shandong University of Science and Technology)","Li, Dapeng (Shandong University of Science and Technology); Peng, Yanjun (Shandong University of Science and Technology; Shandong University of Science and Technology); Guo, Yanfei (Shandong University of Science and Technology); Sun, Jindong (Shandong University of Science and Technology)",2,2,,1.55,,https://app.dimensions.ai/details/publication/pub.1144260468,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
1459,pub.1145373768,10.1109/nics54270.2021.9701571,,,A modified FCN-based method for Left Ventricle endocardium and epicardium segmentation with new block modules,"Cardiac segmentation of medical magnetic resonance images has been crucial nowadays owing to its necessity for cardiac problems diagnosis. In the increasing demand of advanced procedures for cardiac disease diagnosis and inspired by the structure of receptive field block; in this paper, we propose a new block module then further assembling into a deep fully convolutional neural network to deal with automated left ventricle segmentation. With only one learning stage, our proposed model is trained end-to-end, pixels-to-pixels and validated on two popular cardiac MRI benchmarks, ACDC and SunnyBrook datasets. Several experiments have proved that our new model architecture has a better performance than previous segmentation methods with enhanced feature discriminability and robustness, despite having much less training parameters.","This research is funded by the Hanoi University of Science and Technology (HUST) under project number T2021-PC-005. Minh-Nhat Trinh was funded by Vingroup JSC and supported by the Master, PhD Scholarship Programme of Vingroup Innovation Foundation (VINIF), Institute of Big Data, code VINIF.2021.ThS.33. This research is funded by the Hanoi University of Science and Technology (HUST) under project number T2021-PC-005. Minh-Nhat Trinh was funded by Vingroup JSC and supported by the Master, PhD Scholarship Programme of Vingroup Innovation Foundation (VINIF), Institute of Big Data, code VINIF.2021.ThS.33.",,,2021 8th NAFOSTED Conference on Information and Computer Science (NICS),,2021-12-22,2021,,2021-12-22,0,,392-397,Closed,Proceeding,"Nham, Do-Hai-Ninh; Trinh, Minh-Nhat; Tran, Tien-Thanh; Pham, Van-Truong; Tran, Thi-Thao","Nham, Do-Hai-Ninh (School of Applied Mathematics and Informatics, Hanoi University of Science and Technology); Trinh, Minh-Nhat (School of Applied Mathematics and Informatics, Hanoi University of Science and Technology); Tran, Tien-Thanh (Smart Health Center, Vingroup Big Data Institute); Pham, Van-Truong (School of Applied Mathematics and Informatics, Hanoi University of Science and Technology); Tran, Thi-Thao (School of Applied Mathematics and Informatics, Hanoi University of Science and Technology)","Nham, Do-Hai-Ninh ","Nham, Do-Hai-Ninh (); Trinh, Minh-Nhat (); Tran, Tien-Thanh (); Pham, Van-Truong (); Tran, Thi-Thao ()",1,1,,0.82,,https://app.dimensions.ai/details/publication/pub.1145373768,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
3790,pub.1144038722,10.3389/fcvm.2021.787614,34993240,PMC8724536,The Role of AI in Characterizing the DCM Phenotype,"Dilated Cardiomyopathy is conventionally defined by left ventricular dilatation and dysfunction in the absence of coronary disease. Emerging evidence suggests many patients remain vulnerable to major adverse outcomes despite clear therapeutic success of modern evidence-based heart failure therapy. In this era of personalized medical care, the conventional assessment of left ventricular ejection fraction falls short in fully predicting evolution and risk of outcomes in this heterogenous group of heart muscle disease, as such, a more refined means of phenotyping this disease appears essential. Cardiac MRI (CMR) is well-placed in this respect, not only for its diagnostic utility, but the wealth of information captured in global and regional function assessment with the addition of unique tissue characterization across different disease states and patient cohorts. Advanced tools are needed to leverage these sensitive metrics and integrate with clinical, genetic and biochemical information for personalized, and more clinically useful characterization of the dilated cardiomyopathy phenotype. Recent advances in artificial intelligence offers the unique opportunity to impact clinical decision making through enhanced precision image-analysis tasks, multi-source extraction of relevant features and seamless integration to enhance understanding, improve diagnosis, and subsequently clinical outcomes. Focusing particularly on deep learning, a subfield of artificial intelligence, that has garnered significant interest in the imaging community, this paper reviews the main developments that could offer more robust disease characterization and risk stratification in the Dilated Cardiomyopathy phenotype. Given its promising utility in the non-invasive assessment of cardiac diseases, we firstly highlight the key applications in CMR, set to enable comprehensive quantitative measures of function beyond the standard of care assessment. Concurrently, we revisit the added value of tissue characterization techniques for risk stratification, showcasing the deep learning platforms that overcome limitations in current clinical workflows and discuss how they could be utilized to better differentiate at-risk subgroups of this phenotype. The final section of this paper is dedicated to the allied clinical applications to imaging, that incorporate artificial intelligence and have harnessed the comprehensive abundance of data from genetics and relevant clinical variables to facilitate better classification and enable enhanced risk prediction for relevant outcomes.",We would like to thank our colleague Dr. Rosita Zakeri who assisted with the conception of Figure 3.,"This research was funded in whole, or in part by the Wellcome Trust/EPSRC Center for Medical Engineering at Kings College London (WT 203148/Z/16/Z). EP-A was supported by the EPSRC (EP/R005516/1, EP/P001009/1) and by core funding from the Wellcome/EPSRC Center for Medical Engineering (WT203148/Z/16/Z). BR was supported by the NIHR Cardiovascular MedTech Co-operative award to the Guy's and St Thomas' NHS Foundation Trust. CA and MR are supported by the UKRI London Medical Imaging and Artificial Intelligence Center for Value Based Healthcare (RE15376).",Frontiers in Cardiovascular Medicine,,,2021-12-21,2021,2021-12-21,,8,,787614,All OA, Gold,Article,"Asher, Clint; Puyol-Antón, Esther; Rizvi, Maleeha; Ruijsink, Bram; Chiribiri, Amedeo; Razavi, Reza; Carr-White, Gerry","Asher, Clint (Department of Cardiovascular Imaging, School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Cardiology, Guys and St Thomas' NHS Trust, London, United Kingdom); Puyol-Antón, Esther (Department of Cardiovascular Imaging, School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Rizvi, Maleeha (Department of Cardiovascular Imaging, School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Cardiology, Guys and St Thomas' NHS Trust, London, United Kingdom); Ruijsink, Bram (Department of Cardiovascular Imaging, School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Cardiology, Guys and St Thomas' NHS Trust, London, United Kingdom; Division of Heart and Lungs, Department of Cardiology, University Medical Center Utrecht, Utrecht, Netherlands); Chiribiri, Amedeo (Department of Cardiovascular Imaging, School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Cardiology, Guys and St Thomas' NHS Trust, London, United Kingdom); Razavi, Reza (Department of Cardiovascular Imaging, School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Cardiology, Guys and St Thomas' NHS Trust, London, United Kingdom); Carr-White, Gerry (Department of Cardiovascular Imaging, School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Cardiology, Guys and St Thomas' NHS Trust, London, United Kingdom)","Asher, Clint (King's College London; Guy's and St Thomas' NHS Foundation Trust)","Asher, Clint (King's College London; Guy's and St Thomas' NHS Foundation Trust); Puyol-Antón, Esther (King's College London); Rizvi, Maleeha (King's College London; Guy's and St Thomas' NHS Foundation Trust); Ruijsink, Bram (King's College London; Guy's and St Thomas' NHS Foundation Trust; University Medical Center Utrecht); Chiribiri, Amedeo (King's College London; Guy's and St Thomas' NHS Foundation Trust); Razavi, Reza (King's College London; Guy's and St Thomas' NHS Foundation Trust); Carr-White, Gerry (King's College London; Guy's and St Thomas' NHS Foundation Trust)",2,2,0.19,2.26,https://www.frontiersin.org/articles/10.3389/fcvm.2021.787614/pdf,https://app.dimensions.ai/details/publication/pub.1144038722,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,3 Good Health and Well Being,,,,,,,,,
698,pub.1144061858,10.48550/arxiv.2112.10074,,,QU-BraTS: MICCAI BraTS 2020 Challenge on Quantifying Uncertainty in  Brain Tumor Segmentation - Analysis of Ranking Scores and Benchmarking  Results,"Deep learning (DL) models have provided state-of-the-art performance in
various medical imaging benchmarking challenges, including the Brain Tumor
Segmentation (BraTS) challenges. However, the task of focal pathology
multi-compartment segmentation (e.g., tumor and lesion sub-regions) is
particularly challenging, and potential errors hinder translating DL models
into clinical workflows. Quantifying the reliability of DL model predictions in
the form of uncertainties could enable clinical review of the most uncertain
regions, thereby building trust and paving the way toward clinical translation.
Several uncertainty estimation methods have recently been introduced for DL
medical image segmentation tasks. Developing scores to evaluate and compare the
performance of uncertainty measures will assist the end-user in making more
informed decisions. In this study, we explore and evaluate a score developed
during the BraTS 2019 and BraTS 2020 task on uncertainty quantification
(QU-BraTS) and designed to assess and rank uncertainty estimates for brain
tumor multi-compartment segmentation. This score (1) rewards uncertainty
estimates that produce high confidence in correct assertions and those that
assign low confidence levels at incorrect assertions, and (2) penalizes
uncertainty measures that lead to a higher percentage of under-confident
correct assertions. We further benchmark the segmentation uncertainties
generated by 14 independent participating teams of QU-BraTS 2020, all of which
also participated in the main BraTS segmentation task. Overall, our findings
confirm the importance and complementary value that uncertainty estimates
provide to segmentation algorithms, highlighting the need for uncertainty
quantification in medical image analyses. Finally, in favor of transparency and
reproducibility, our evaluation code is made publicly available at:
https://github.com/RagMeh11/QU-BraTS.",,,arXiv,,,2021-12-19,2021,,,,,,All OA, Green,Preprint,"Mehta, Raghav; Filos, Angelos; Baid, Ujjwal; Sako, Chiharu; McKinley, Richard; Rebsamen, Michael; Datwyler, Katrin; Meier, Raphael; Radojewski, Piotr; Murugesan, Gowtham Krishnan; Nalawade, Sahil; Ganesh, Chandan; Wagner, Ben; Yu, Fang F.; Fei, Baowei; Madhuranthakam, Ananth J.; Maldjian, Joseph A.; Daza, Laura; Gomez, Catalina; Arbelaez, Pablo; Dai, Chengliang; Wang, Shuo; Reynaud, Hadrien; Mo, Yuan-han; Angelini, Elsa; Guo, Yike; Bai, Wenjia; Banerjee, Subhashis; Pei, Lin-min; AK, Murat; Rosas-Gonzalez, Sarahi; Zemmoura, Ilyess; Tauber, Clovis; Vu, Minh H.; Nyholm, Tufve; Lofstedt, Tommy; Ballestar, Laura Mora; Vilaplana, Veronica; McHugh, Hugh; Talou, Gonzalo Maso; Wang, Alan; Patel, Jay; Chang, Ken; Hoebel, Katharina; Gidwani, Mishka; Arun, Nishanth; Gupta, Sharut; Aggarwal, Mehak; Singh, Praveer; Gerstner, Elizabeth R.; Kalpathy-Cramer, Jayashree; Boutry, Nicolas; Huard, Alexis; Vidyaratne, Lasitha; Rahman, Md Monibor; Iftekharuddin, Khan M.; Chazalon, Joseph; Puybareau, Elodie; Tochon, Guillaume; Ma, Jun; Cabezas, Mariano; Llado, Xavier; Oliver, Arnau; Valencia, Liliana; Valverde, Sergi; Amian, Mehdi; Soltaninejad, Mohammadreza; Myronenko, Andriy; Hatamizadeh, Ali; Feng, Xue; Dou, Quan; Tustison, Nicholas; Meyer, Craig; Shah, Nisarg A.; Talbar, Sanjay; Weber, Marc-Andre; Mahajan, Abhishek; Jakab, Andras; Wiest, Roland; Fathallah-Shaykh, Hassan M.; Nazeri, Arash; Milchenko1, Mikhail; Marcus, Daniel; Kotrotsou, Aikaterini; Colen, Rivka; Freymann, John; Kirby, Justin; Davatzikos, Christos; Menze, Bjoern; Bakas, Spyridon; Gal, Yarin; Arbel, Tal","Mehta, Raghav (); Filos, Angelos (); Baid, Ujjwal (); Sako, Chiharu (); McKinley, Richard (); Rebsamen, Michael (); Datwyler, Katrin (); Meier, Raphael (); Radojewski, Piotr (); Murugesan, Gowtham Krishnan (); Nalawade, Sahil (); Ganesh, Chandan (); Wagner, Ben (); Yu, Fang F. (); Fei, Baowei (); Madhuranthakam, Ananth J. (); Maldjian, Joseph A. (); Daza, Laura (); Gomez, Catalina (); Arbelaez, Pablo (); Dai, Chengliang (); Wang, Shuo (); Reynaud, Hadrien (); Mo, Yuan-han (); Angelini, Elsa (); Guo, Yike (); Bai, Wenjia (); Banerjee, Subhashis (); Pei, Lin-min (); AK, Murat (); Rosas-Gonzalez, Sarahi (); Zemmoura, Ilyess (); Tauber, Clovis (); Vu, Minh H. (); Nyholm, Tufve (); Lofstedt, Tommy (); Ballestar, Laura Mora (); Vilaplana, Veronica (); McHugh, Hugh (); Talou, Gonzalo Maso (); Wang, Alan (); Patel, Jay (); Chang, Ken (); Hoebel, Katharina (); Gidwani, Mishka (); Arun, Nishanth (); Gupta, Sharut (); Aggarwal, Mehak (); Singh, Praveer (); Gerstner, Elizabeth R. (); Kalpathy-Cramer, Jayashree (); Boutry, Nicolas (); Huard, Alexis (); Vidyaratne, Lasitha (); Rahman, Md Monibor (); Iftekharuddin, Khan M. (); Chazalon, Joseph (); Puybareau, Elodie (); Tochon, Guillaume (); Ma, Jun (); Cabezas, Mariano (); Llado, Xavier (); Oliver, Arnau (); Valencia, Liliana (); Valverde, Sergi (); Amian, Mehdi (); Soltaninejad, Mohammadreza (); Myronenko, Andriy (); Hatamizadeh, Ali (); Feng, Xue (); Dou, Quan (); Tustison, Nicholas (); Meyer, Craig (); Shah, Nisarg A. (); Talbar, Sanjay (); Weber, Marc-Andre (); Mahajan, Abhishek (); Jakab, Andras (); Wiest, Roland (); Fathallah-Shaykh, Hassan M. (); Nazeri, Arash (); Milchenko1, Mikhail (); Marcus, Daniel (); Kotrotsou, Aikaterini (); Colen, Rivka (); Freymann, John (); Kirby, Justin (); Davatzikos, Christos (); Menze, Bjoern (); Bakas, Spyridon (); Gal, Yarin (); Arbel, Tal ()",,"Mehta, Raghav (); Filos, Angelos (); Baid, Ujjwal (); Sako, Chiharu (); McKinley, Richard (); Rebsamen, Michael (); Datwyler, Katrin (); Meier, Raphael (); Radojewski, Piotr (); Murugesan, Gowtham Krishnan (); Nalawade, Sahil (); Ganesh, Chandan (); Wagner, Ben (); Yu, Fang F. (); Fei, Baowei (); Madhuranthakam, Ananth J. (); Maldjian, Joseph A. (); Daza, Laura (); Gomez, Catalina (); Arbelaez, Pablo (); Dai, Chengliang (); Wang, Shuo (); Reynaud, Hadrien (); Mo, Yuan-han (); Angelini, Elsa (); Guo, Yike (); Bai, Wenjia (); Banerjee, Subhashis (); Pei, Lin-min (); AK, Murat (); Rosas-Gonzalez, Sarahi (); Zemmoura, Ilyess (); Tauber, Clovis (); Vu, Minh H. (); Nyholm, Tufve (); Lofstedt, Tommy (); Ballestar, Laura Mora (); Vilaplana, Veronica (); McHugh, Hugh (); Talou, Gonzalo Maso (); Wang, Alan (); Patel, Jay (); Chang, Ken (); Hoebel, Katharina (); Gidwani, Mishka (); Arun, Nishanth (); Gupta, Sharut (); Aggarwal, Mehak (); Singh, Praveer (); Gerstner, Elizabeth R. (); Kalpathy-Cramer, Jayashree (); Boutry, Nicolas (); Huard, Alexis (); Vidyaratne, Lasitha (); Rahman, Md Monibor (); Iftekharuddin, Khan M. (); Chazalon, Joseph (); Puybareau, Elodie (); Tochon, Guillaume (); Ma, Jun (); Cabezas, Mariano (); Llado, Xavier (); Oliver, Arnau (); Valencia, Liliana (); Valverde, Sergi (); Amian, Mehdi (); Soltaninejad, Mohammadreza (); Myronenko, Andriy (); Hatamizadeh, Ali (); Feng, Xue (); Dou, Quan (); Tustison, Nicholas (); Meyer, Craig (); Shah, Nisarg A. (); Talbar, Sanjay (); Weber, Marc-Andre (); Mahajan, Abhishek (); Jakab, Andras (); Wiest, Roland (); Fathallah-Shaykh, Hassan M. (); Nazeri, Arash (); Milchenko1, Mikhail (); Marcus, Daniel (); Kotrotsou, Aikaterini (); Colen, Rivka (); Freymann, John (); Kirby, Justin (); Davatzikos, Christos (); Menze, Bjoern (); Bakas, Spyridon (); Gal, Yarin (); Arbel, Tal ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1144061858,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,
1251,pub.1144653908,10.1109/bigdata52589.2021.9671847,,,Generalization in Cardiac Image Segmentation,"Deep learning methods have achieved great success in medical imaging applications. Although data is very crucial for deep learning models, the medical imaging domain is restricted by the limited size of datasets and differences between them. This makes it difficult for models to generalize across datasets and achieve robust performance in practical settings. Therefore, knowing how to combine different datasets together to take advantage of new data while retaining performance on previous data becomes an important problem. In this paper, we focus on the task of cardiac image semantic segmentation and synthesize five different real-world scenarios to find the optimal training approach for deep learning models to achieve good generalization across different datasets.","The authors would like to thank Yash Pande his collaboration and valuable insights. The computer resources used for this work were provided in part by National Science Foundation Grants No. 1730158, 2100237, and 2120019. The authors would like to thank Yash Pande his collaboration and valuable insights. The computer resources used for this work were provided in part by National Science Foundation Grants No. 1730158, 2100237, and 2120019.",,,2021 IEEE International Conference on Big Data (Big Data),,2021-12-18,2021,,2021-12-18,0,,2838-2847,Closed,Proceeding,"Xu, Zhengjie; Zhou, Zixiang; Cottrell, Garrison W.; Nguyen, Mai H.","Xu, Zhengjie (Computer Science & Engineering, University of California, San Diego, La Jolla, CA, U.S.A); Zhou, Zixiang (Computer Science & Engineering, University of California, San Diego, La Jolla, CA, U.S.A); Cottrell, Garrison W. (Computer Science & Engineering, University of California, San Diego, La Jolla, CA, U.S.A); Nguyen, Mai H. (San Diego Supercomputer Center, University of California, San Diego, La Jolla, CA, U.S.A)","Nguyen, Mai H. (San Diego Supercomputer Center)","Xu, Zhengjie (University of California, San Diego); Zhou, Zixiang (University of California, San Diego); Cottrell, Garrison W. (University of California, San Diego); Nguyen, Mai H. (San Diego Supercomputer Center)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1144653908,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1651,pub.1148877077,10.1109/csci54926.2021.00322,,,A Fully Convolutional Neural Network Based on 2D-Unet in Cardiac MR Image Segmentation,"Cardiac MRI image segmentation is of great importance for evaluating cardiac function and diagnosing diseases. Manual segmentation is time-consuming and tedious, so automatic segmentation is very popular in practical applications. In this paper, we propose an improved full convolutional neural network based on 2D-Unet for automatic segmentation of the left ventricle, right ventricle and myocardium. Experiments were conducted on the ACDC 2017 Challenge Training dataset. The segmentation results were assessed by means of average vertical distance, Dice coefficient and Hausdorff distance. Our model reduces the amount of parameters, improves the training speed, uses the fusion loss function, and maintains a satisfactory segmentation accuracy of left ventricle, right ventricle and myocardium.",,This work is financially supported by the Nature Science Foundation with No.61862005 and 61762009.,,2021 International Conference on Computational Science and Computational Intelligence (CSCI),,2021-12-17,2021,,2021-12-17,0,,1697-1701,Closed,Proceeding,"Tan, Yifeng; Yang, Lina; Li, Xichun; Meng, Zuqiang","Tan, Yifeng (School of Computer, Electronics and Information, Guangxi University, Guangxi, China); Yang, Lina (School of Computer, Electronics and Information, Guangxi University, Guangxi, China); Li, Xichun (Guangxi Normal University for Nationalities, Chongzuo, China); Meng, Zuqiang (School of Computer, Electronics and Information, Guangxi University, Guangxi, China)","Tan, Yifeng (Guangxi University)","Tan, Yifeng (Guangxi University); Yang, Lina (Guangxi University); Li, Xichun (Guangxi Normal University for Nationalities); Meng, Zuqiang (Guangxi University)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1148877077,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1548,pub.1144685066,10.1109/bibm52615.2021.9669734,,,ECT-NAS: Searching Efficient CNN-Transformers Architecture for Medical Image Segmentation,"The combination of convolution and Transformer applied to medical image segmentation has achieved great success. However, it still cannot reach extremely accurate segmentation on complex and low-contrast anatomical structures under lower calculation. To solve this problem, we propose ECT-NAS method to automatically search Efficient CNN-Transformers architecture for medical image segmentation, which featured with multi-scale search space. To better extract the global context in the search space of ECT-NAS, we carefully design a light transformer with local-global attention. Last, we proposed an efficient resource constrained search strategy that simultaneously optimizes the accuracy and cost (Params/FLOP) of the model. We evaluate ECT-NAS by conducting extensive experiments on synapse multi-organ, Chaos and ACDC datasets, showing that this approach achieves competitive performance over other segmentation methods, with fewer parameters and lower FLOPs.",,,,2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,2021-12-12,2021,,2021-12-12,0,,1601-1604,Closed,Proceeding,"Xu, Shuying; Quan, Hongyan","Xu, Shuying (School of Computer Science and Technology, East China Normal University, Shanghai, China); Quan, Hongyan (School of Computer Science and Technology, East China Normal University, Shanghai, China)","Xu, Shuying (East China Normal University)","Xu, Shuying (East China Normal University); Quan, Hongyan (East China Normal University)",5,5,,3.83,,https://app.dimensions.ai/details/publication/pub.1144685066,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
2676,pub.1143817480,10.1186/s40658-021-00426-y,34897550,PMC8665861,Artificial intelligence with deep learning in nuclear medicine and radiology,"The use of deep learning in medical imaging has increased rapidly over the past few years, finding applications throughout the entire radiology pipeline, from improved scanner performance to automatic disease detection and diagnosis. These advancements have resulted in a wide variety of deep learning approaches being developed, solving unique challenges for various imaging modalities. This paper provides a review on these developments from a technical point of view, categorizing the different methodologies and summarizing their implementation. We provide an introduction to the design of neural networks and their training procedure, after which we take an extended look at their uses in medical imaging. We cover the different sections of the radiology pipeline, highlighting some influential works and discussing the merits and limitations of deep learning approaches compared to other traditional methods. As such, this review is intended to provide a broad yet concise overview for the interested reader, facilitating adoption and interdisciplinary research of deep learning in the field of medical imaging.",The authors would like to thank Roland Hustinx from the University of Liege for reading the manuscript and making useful suggestions for further improvements.,,EJNMMI Physics,,,2021-12-11,2021,2021-12-11,2021-12,8,1,81,All OA, Gold,Article,"Decuyper, Milan; Maebe, Jens; Van Holen, Roel; Vandenberghe, Stefaan","Decuyper, Milan (Department of Electronics and Information Systems, Ghent University, Ghent, Belgium); Maebe, Jens (Department of Electronics and Information Systems, Ghent University, Ghent, Belgium); Van Holen, Roel (Department of Electronics and Information Systems, Ghent University, Ghent, Belgium); Vandenberghe, Stefaan (Department of Electronics and Information Systems, Ghent University, Ghent, Belgium)","Maebe, Jens (Ghent University)","Decuyper, Milan (Ghent University); Maebe, Jens (Ghent University); Van Holen, Roel (Ghent University); Vandenberghe, Stefaan (Ghent University)",10,10,0.85,7.41,https://ejnmmiphys.springeropen.com/counter/pdf/10.1186/s40658-021-00426-y,https://app.dimensions.ai/details/publication/pub.1143817480,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,
1452,pub.1145638845,10.1109/tencon54134.2021.9707278,,,Deep learning model-based segmentation of medical diseases from MRI and CT images,"Medical image segmentation is quite challenging field. Deep Learning (DL) based Unet model is used for medical image segmentation. The Unet architecture is based on encoder and decoder which is the most successful method. Unet based methods still have a drawback that is not able to fully utilize the output features of the node's convolutional units. This paper presented deep learning model-base segmentation of medical diseases from MRI and CT scan images data with the help of 2D-Unet and 3D-Unet model. The model using package nibabel for reading, visualizing (itk, itkweidgets, ipywidgts), and 3D-Unet method for classification and segmentation of MRI and CT scan images. The proposed system has been tested on Medical Segmentation Decathion (MSD) datasets for the data of Brain, Spleen and Heart. The performance metrices has been analysis by F1-score (F1), Intersection over Union (IOU), and Dice Factor coefficient (DFC) on Brain, Spleen and Heart datasets. The proposed model is outperformed as comparison with some recent network model.",,,,TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON),,2021-12-10,2021,,2021-12-10,0,,608-613,Closed,Proceeding,"Murmu, Anita; Kumar, Piyush","Murmu, Anita (Department of Computer Science and Engineering, National Institute of Technology, Patna, 800005, India); Kumar, Piyush (Department of Computer Science and Engineering, National Institute of Technology, Patna, 800005, India)",,"Murmu, Anita (National Institute of Technology Patna); Kumar, Piyush (National Institute of Technology Patna)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1145638845,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,,
1251,pub.1143783259,10.48550/arxiv.2112.04894,,,Semi-Supervised Medical Image Segmentation via Cross Teaching between  CNN and Transformer,"Recently, deep learning with Convolutional Neural Networks (CNNs) and
Transformers has shown encouraging results in fully supervised medical image
segmentation. However, it is still challenging for them to achieve good
performance with limited annotations for training. In this work, we present a
very simple yet efficient framework for semi-supervised medical image
segmentation by introducing the cross teaching between CNN and Transformer.
Specifically, we simplify the classical deep co-training from consistency
regularization to cross teaching, where the prediction of a network is used as
the pseudo label to supervise the other network directly end-to-end.
Considering the difference in learning paradigm between CNN and Transformer, we
introduce the Cross Teaching between CNN and Transformer rather than just using
CNNs. Experiments on a public benchmark show that our method outperforms eight
existing semi-supervised learning methods just with a simpler framework.
Notably, this work may be the first attempt to combine CNN and transformer for
semi-supervised medical image segmentation and achieve promising results on a
public benchmark. The code will be released at:
https://github.com/HiLab-git/SSL4MIS.",,,arXiv,,,2021-12-09,2021,,,,,,All OA, Green,Preprint,"Luo, Xiangde; Hu, Minhao; Song, Tao; Wang, Guotai; Zhang, Shaoting","Luo, Xiangde (); Hu, Minhao (); Song, Tao (); Wang, Guotai (); Zhang, Shaoting ()",,"Luo, Xiangde (); Hu, Minhao (); Song, Tao (); Wang, Guotai (); Zhang, Shaoting ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1143783259,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1138,pub.1143852027,10.48550/arxiv.2112.05149,,,DiffuseMorph: Unsupervised Deformable Image Registration Using Diffusion  Model,"Deformable image registration is one of the fundamental tasks in medical
imaging. Classical registration algorithms usually require a high computational
cost for iterative optimizations. Although deep-learning-based methods have
been developed for fast image registration, it is still challenging to obtain
realistic continuous deformations from a moving image to a fixed image with
less topological folding problem. To address this, here we present a novel
diffusion-model-based image registration method, called DiffuseMorph.
DiffuseMorph not only generates synthetic deformed images through reverse
diffusion but also allows image registration by deformation fields.
Specifically, the deformation fields are generated by the conditional score
function of the deformation between the moving and fixed images, so that the
registration can be performed from continuous deformation by simply scaling the
latent feature of the score. Experimental results on 2D facial and 3D medical
image registration tasks demonstrate that our method provides flexible
deformations with topology preservation capability.",,,arXiv,,,2021-12-09,2021,,,,,,All OA, Green,Preprint,"Kim, Boah; Han, Inhwa; Ye, Jong Chul","Kim, Boah (); Han, Inhwa (); Ye, Jong Chul ()",,"Kim, Boah (); Han, Inhwa (); Ye, Jong Chul ()",1,1,,0.95,,https://app.dimensions.ai/details/publication/pub.1143852027,"46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4607 Graphics, Augmented Reality and Games; 51 Physical Sciences; 5105 Medical and Biological Physics",,,,,,,,,,,
4808,pub.1143713387,10.1016/j.media.2021.102328,34920236,,CyCMIS: Cycle-consistent Cross-domain Medical Image Segmentation via diverse image augmentation,"Domain shift, a phenomenon when there exists distribution discrepancy between training dataset (source domain) and test dataset (target domain), is very common in practical applications and may cause significant performance degradation, which hinders the effective deployment of deep learning models to clinical settings. Adaptation algorithms to improve the model generalizability from source domain to target domain has significant practical value. In this paper, we investigate unsupervised domain adaptation (UDA) technique to train a cross-domain segmentation method which is robust to domain shift, and which does not require any annotations on the test domain. To this end, we propose Cycle-consistent Cross-domain Medical Image Segmentation, referred as CyCMIS, integrating online diverse image translation via disentangled representation learning and semantic consistency regularization into one network. Different from learning one-to-one mapping, our method characterizes the complex relationship between domains as many-to-many mapping. A novel diverse inter-domain semantic consistency loss is then proposed to regularize the cross-domain segmentation process. We additionally introduce an intra-domain semantic consistency loss to encourage the segmentation consistency between the original input and the image after cross-cycle reconstruction. We conduct comprehensive experiments on two publicly available datasets to evaluate the effectiveness of the proposed method. Results demonstrate the efficacy of the present approach.",This study was partially supported by Shanghai Municipal Science and Technology Commission via Project 20511105205 and by the Natural Science Foundation of China via project U20A20199.,,Medical Image Analysis,,"Algorithms; Humans; Image Processing, Computer-Assisted; Semantics",2021-12-08,2021,2021-12-08,2022-02,76,,102328,Closed,Article,"Wang, Runze; Zheng, Guoyan","Wang, Runze (Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, No.800 Dongchuan Road, Shanghai 200240, China.); Zheng, Guoyan (Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, No.800 Dongchuan Road, Shanghai 200240, China. Electronic address: guoyan.zheng@sjtu.edu.cn.)","Zheng, Guoyan (Shanghai Jiao Tong University)","Wang, Runze (Shanghai Jiao Tong University); Zheng, Guoyan (Shanghai Jiao Tong University)",8,8,,,,https://app.dimensions.ai/details/publication/pub.1143713387,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
1512,pub.1144948087,10.1109/dasa53625.2021.9682288,,,Group and Shuffle Convolutions for High-Resolution Semantic Segmentation,"Pterygium is an eye condition in which abnormal tissues grow from the medial canthus region that gradually spread towards the pupil region as the disease becomes more severe. Generally, it is a harmless condition but if the abnormal tissues have encroached onto the pupil region, the patient's vision will be severely affected. It is important to diagnose this condition at the early stage so that remedial steps can be administered to curb the growth of the tissues. Therefore, it is crucial to be able to measure the severity level of this condition accurately, which can be inferred from the size of the infected area. However, manual segmentation of the region of interest is a tedious task and usually results in different segmentation opinions between the health practitioners. Hence, an automated approach using deep convolutional neural networks is proposed to extract the infected region. This work takes a high-resolution approach, in which the deep model utilizes a set of multi-scale feature maps that still retain the highest possible resolution until the last convolutional layers. It is in contrast to the standard approach, whereby the feature map size will be reduced to a compact representation before it is being scale-up to a higher resolution. Furthermore, a set of group and shuffle operations has been embedded into the network to improve model capability in learning diversified feature maps. The networks will have a reduced dependency on a set of global features, whereby it is forced to extract meaningful features from a few separated groups before they are combined through a concatenation operator. The results show that a base HRNet-32 network with four sets of group convolution followed by a shuffle operation returns the best performance in terms of Accuracy, Mean IoU and Jaccard Index with performance values of 0.9369, 0.8707 and 0.8088, respectively. For future work, the optimal placement of the group and shuffle operations can be fine-tuned to increase the segmentation accuracy.",The authors would like to acknowledge funding from Universiti Kebangsaan Malaysia (Geran Universiti Penyelidikan: GUP-2019-008) and Ministry of Education Malaysia (Fundamental Research Grant Scheme: FRGS/1/2019/ICT02/UKM/02/1). The Titan V used for this research was donated by the NVIDIA Corporation (KK-2019-005).,The authors would like to acknowledge funding from Universiti Kebangsaan Malaysia (Geran Universiti Penyelidikan: GUP-2019-008) and Ministry of Education Malaysia (Fundamental Research Grant Scheme: FRGS/1/2019/ICT02/UKM/02/1). The Titan V used for this research was donated by the NVIDIA Corporation (KK-2019-005).,,2021 International Conference on Decision Aid Sciences and Application (DASA),,2021-12-08,2021,,2021-12-08,0,,12-16,Closed,Proceeding,"Abdani, Siti Raihanah; Zulkifley, Mohd Asyraf; Zulkifley, Nuraisyah Hani","Abdani, Siti Raihanah (Department of Electrical, Electronic and Systems Engineering, Universiti Kebangsaan Malaysia, Bangi, Malaysia); Zulkifley, Mohd Asyraf (Department of Electrical, Electronic and Systems Engineering, Universiti Kebangsaan Malaysia, Bangi, Malaysia); Zulkifley, Nuraisyah Hani (Community Health Department, Universiti Putra Malaysia, Serdang, Malaysia)",,"Abdani, Siti Raihanah (National University of Malaysia); Zulkifley, Mohd Asyraf (National University of Malaysia); Zulkifley, Nuraisyah Hani (Universiti Putra Malaysia)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1144948087,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1134,pub.1143667336,10.48550/arxiv.2112.02508,,,Uncertainty-Guided Mutual Consistency Learning for Semi-Supervised  Medical Image Segmentation,"Medical image segmentation is a fundamental and critical step in many
clinical approaches. Semi-supervised learning has been widely applied to
medical image segmentation tasks since it alleviates the heavy burden of
acquiring expert-examined annotations and takes the advantage of unlabeled data
which is much easier to acquire. Although consistency learning has been proven
to be an effective approach by enforcing an invariance of predictions under
different distributions, existing approaches cannot make full use of
region-level shape constraint and boundary-level distance information from
unlabeled data. In this paper, we propose a novel uncertainty-guided mutual
consistency learning framework to effectively exploit unlabeled data by
integrating intra-task consistency learning from up-to-date predictions for
self-ensembling and cross-task consistency learning from task-level
regularization to exploit geometric shape information. The framework is guided
by the estimated segmentation uncertainty of models to select out relatively
certain predictions for consistency learning, so as to effectively exploit more
reliable information from unlabeled data. Experiments on two publicly available
benchmark datasets showed that: 1) Our proposed method can achieve significant
performance improvement by leveraging unlabeled data, with up to 4.13% and
9.82% in Dice coefficient compared to supervised baseline on left atrium
segmentation and brain tumor segmentation, respectively. 2) Compared with other
semi-supervised segmentation methods, our proposed method achieve better
segmentation performance under the same backbone network and task settings on
both datasets, demonstrating the effectiveness and robustness of our method and
potential transferability for other medical image segmentation tasks.",,,arXiv,,,2021-12-05,2021,,,,,,All OA, Green,Preprint,"Zhang, Yichi; Jiao, Rushi; Liao, Qingcheng; Li, Dongyang; Zhang, Jicong","Zhang, Yichi (); Jiao, Rushi (); Liao, Qingcheng (); Li, Dongyang (); Zhang, Jicong ()",,"Zhang, Yichi (); Jiao, Rushi (); Liao, Qingcheng (); Li, Dongyang (); Zhang, Jicong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1143667336,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
4791,pub.1143538461,10.1109/tcyb.2021.3126817,34851845,,Unsupervised Landmark Detection-Based Spatiotemporal Motion Estimation for 4-D Dynamic Medical Images,"Motion estimation is a fundamental step in dynamic medical image processing for the assessment of target organ anatomy and function. However, existing image-based motion estimation methods, which optimize the motion field by evaluating the local image similarity, are prone to produce implausible estimation, especially in the presence of large motion. In addition, the correct anatomical topology is difficult to be preserved as the image global context is not well incorporated into motion estimation. In this study, we provide a novel motion estimation framework of dense-sparse-dense (DSD), which comprises two stages. In the first stage, we process the raw dense image to extract sparse landmarks to represent the target organ's anatomical topology, and discard the redundant information that is unnecessary for motion estimation. For this purpose, we introduce an unsupervised 3-D landmark detection network to extract spatially sparse but representative landmarks for the target organ's motion estimation. In the second stage, we derive the sparse motion displacement from the extracted sparse landmarks of two images of different time points. Then, we present a motion reconstruction network to construct the motion field by projecting the sparse landmarks' displacement back into the dense image domain. Furthermore, we employ the estimated motion field from our two-stage DSD framework as initialization and boost the motion estimation quality in light-weight yet effective iterative optimization. We evaluate our method on two dynamic medical imaging tasks to model cardiac motion and lung respiratory motion, respectively. Our method has produced superior motion estimation accuracy compared to the existing comparative methods. Besides, the extensive experimental results demonstrate that our solution can extract well-representative anatomical landmarks without any requirement of manual annotation. Our code is publicly available online: https://github.com/yyguo-sjtu/DSD-3D-Unsupervised-Landmark-Detection-Based-Motion-Estimation.",,,IEEE Transactions on Cybernetics,,,2021-12-01,2021,2021-12-01,2021-12-01,PP,99,1-14,All OA, Hybrid,Article,"Guo, Yuyu; Bi, Lei; Wei, Dongming; Chen, Liyun; Zhu, Zhengbin; Feng, Dagan; Zhang, Ruiyan; Wang, Qian; Kim, Jinman","Guo, Yuyu (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai 200030, China.); Bi, Lei (School of Computer Science, University of Sydney, Sydney, NSW 2006, Australia ()); Wei, Dongming (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai 200030, China.); Chen, Liyun (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai 200030, China.); Zhu, Zhengbin (Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai 200025, China.); Feng, Dagan (School of Computer Science, University of Sydney, Sydney, NSW 2006, Australia.); Zhang, Ruiyan (Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai 200025, China.); Wang, Qian (School of Biomedical Engineering, ShanghaiTech University, Shanghai 201210, China ().); Kim, Jinman (School of Computer Science, University of Sydney, Sydney, NSW 2006, Australia ())",,"Guo, Yuyu (Shanghai Jiao Tong University); Bi, Lei (The University of Sydney); Wei, Dongming (Shanghai Jiao Tong University); Chen, Liyun (Shanghai Jiao Tong University); Zhu, Zhengbin (Shanghai Jiao Tong University; Ruijin Hospital); Feng, Dagan (The University of Sydney); Zhang, Ruiyan (Shanghai Jiao Tong University; Ruijin Hospital); Wang, Qian (ShanghaiTech University); Kim, Jinman (The University of Sydney)",0,0,,0.0,https://doi.org/10.1109/tcyb.2021.3126817,https://app.dimensions.ai/details/publication/pub.1143538461,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1395,pub.1144506635,10.1166/jmihi.2021.3510,,,A Novel Image Segmentation Method for Cardiac MRI Using Support Vector Machine Algorithm Based on Particle Swarm Optimization,"At present, heart disease not only has a significant impact on the quality of human life but also poses a greater impact on people’s health. Therefore, it is very important to be able to diagnose heart disease as early as possible and give corresponding treatment. Heart image segmentation is the primary operation of intelligent heart disease diagnosis. The quality of segmentation directly determines the effect of intelligent diagnosis. Because the running time of image segmentation is often longer, coupled with the characteristics of cardiac MR imaging technology and the structural characteristics of the cardiac target itself, the rapid segmentation of cardiac MRI images still has challenges. Aiming at the long running time of traditional methods and low segmentation accuracy, a medical image segmentation (MIS) method based on particle swarm optimization (PSO) optimized support vector machine (SVM) is proposed, referred to as PSO-SVM. First, the current iteration number and population number in PSO are added to the control strategy of inertial weight λ to improve the performance of PSO inertial weight λ . Find the optimal penalty coefficient C and γ in the gaussian kernel function by PSO. Then use the SVM method to establish the best classification model and test the data. Compared with traditional methods, this method not only shortens the running time, but also improves the segmentation accuracy. At the same time, comparing the influence of traditional inertial weights on segmentation results, the improved method reduces the average convergence algebra and shortens the optimization time.",,,Journal of Medical Imaging and Health Informatics,,,2021-12-01,2021,,2021-12-01,11,12,3174-3180,Closed,Article,"Wang, Guanghui; Ma, Lihong","Wang, Guanghui (Department of Network Management, Non-Commissioned Officer’s School of the Chinese People’s Armed Police Force, Hangzhou, Zhejiang 310012, China); Ma, Lihong (The High School Attached to Zhejiang University, Hangzhou, Zhejiang 310007, China)",,"Wang, Guanghui (); Ma, Lihong (Zhejiang University)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1144506635,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science,,,,,,,,
1010,pub.1139018739,10.1016/j.mlwa.2021.100078,,,Model-based segmentation using neural network-based boundary detectors: Application to prostate and heart segmentation in MR images,"Model-based segmentation (MBS) is a variant of active surfaces and active shape models that has successfully been used to segment anatomical structures such as the heart or the brain. We propose to integrate neural networks (NNs) into MBS for boundary detection. We formulate boundary detection as a regression task and use a NN to predict the distances between a surface mesh and the corresponding boundary points. The proposed approach has been applied to two tasks — prostate segmentation in MR images and the segmentation of the left and right ventricle in MR images. For the first task, data from the Prostate MR Image Segmentation 2012 (PROMISE12) challenge has been used. For the second task, a diverse database with cardiac MR images from six clinical sites has been used. We compare the results to the popular U-net approaches using the nnU-net implementation that is among the top performing segmentation algorithms in various challenges. In cross-validation experiments, the mean Dice scores are very similar and no statistically significant difference is observed. On the PROMISE12 test set, nnU-net Dice scores are significantly better. This is achieved by using an ensemble of 2D and 3D U-nets to generate the final segmentation, a concept that may also be adapted to NN-based boundary detection in the future. While the U-net provides a voxel labeling, our approach provides a 3D surface mesh with pre-defined mesh topology, establishes correspondences with respect to the reference mesh, avoids isolated falsely segmented regions and ensures proper connectivity of different regions.",,,Machine Learning with Applications,,,2021-12,2021,,2021-12,6,,100078,All OA, Gold,Article,"Brosch, Tom; Peters, Jochen; Groth, Alexandra; Weber, Frank Michael; Weese, Jürgen","Brosch, Tom (Philips GmbH Innovative Technologies, Röntgenstrasse 24, 22335 Hamburg, Germany); Peters, Jochen (Philips GmbH Innovative Technologies, Röntgenstrasse 24, 22335 Hamburg, Germany); Groth, Alexandra (Philips GmbH Innovative Technologies, Röntgenstrasse 24, 22335 Hamburg, Germany); Weber, Frank Michael (Philips GmbH Innovative Technologies, Röntgenstrasse 24, 22335 Hamburg, Germany); Weese, Jürgen (Philips GmbH Innovative Technologies, Röntgenstrasse 24, 22335 Hamburg, Germany)","Weese, Jürgen (Philips (Germany))","Brosch, Tom (Philips (Germany)); Peters, Jochen (Philips (Germany)); Groth, Alexandra (Philips (Germany)); Weber, Frank Michael (Philips (Germany)); Weese, Jürgen (Philips (Germany))",4,4,,3.27,https://doi.org/10.1016/j.mlwa.2021.100078,https://app.dimensions.ai/details/publication/pub.1139018739,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5057,pub.1138955846,10.1109/tmi.2021.3090082,34138702,,"Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation: The M&Ms Challenge","The emergence of deep learning has considerably advanced the state-of-the-art in cardiac magnetic resonance (CMR) segmentation. Many techniques have been proposed over the last few years, bringing the accuracy of automated segmentation close to human performance. However, these models have been all too often trained and validated using cardiac imaging samples from single clinical centres or homogeneous imaging protocols. This has prevented the development and validation of models that are generalizable across different clinical centres, imaging conditions or scanner vendors. To promote further research and scientific benchmarking in the field of generalizable deep learning for cardiac segmentation, this paper presents the results of the Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation (M&Ms) Challenge, which was recently organized as part of the MICCAI 2020 Conference. A total of 14 teams submitted different solutions to the problem, combining various baseline models, data augmentation strategies, and domain adaptation techniques. The obtained results indicate the importance of intensity-driven data augmentation, as well as the need for further research to improve generalizability towards unseen scanner vendors or new imaging protocols. Furthermore, we present a new resource of 375 heterogeneous CMR datasets acquired by using four different scanner vendors in six hospitals and three different countries (Spain, Canada and Germany), which we provide as open-access for the community to enable future research in the field.",This work was supported in part by the European Union’s Horizon 2020 Research and Innovation Program (euCanSHare Project) under Grant 825903. The authors would like to thank NVIDIA and the Barcelona Super Computing (BSC) Centre for providing the necessary computational resources for this work.,,IEEE Transactions on Medical Imaging,,Cardiac Imaging Techniques, Heart, Humans, Magnetic Resonance Imaging,2021-11-30,2021,2021-11-30,2021-12,40,12,3543-3554,All OA, Hybrid,Article,"Campello, Víctor M.; Gkontra, Polyxeni; Izquierdo, Cristian; Martín-Isla, Carlos; Sojoudi, Alireza; Full, Peter M.; Maier-Hein, Klaus; Zhang, Yao; He, Zhiqiang; Ma, Jun; Parreño, Mario; Albiol, Alberto; Kong, Fanwei; Shadden, Shawn C.; Acero, Jorge Corral; Sundaresan, Vaanathi; Saber, Mina; Elattar, Mustafa; Li, Hongwei; Menze, Bjoern; Khader, Firas; Haarburger, Christoph; Scannell, Cian M.; Veta, Mitko; Carscadden, Adam; Punithakumar, Kumaradevan; Liu, Xiao; Tsaftaris, Sotirios A.; Huang, Xiaoqiong; Yang, Xin; Li, Lei; Zhuang, Xiahai; Viladés, David; Descalzo, Martín L.; Guala, Andrea; La Mura, Lucia; Friedrich, Matthias G.; Garg, Ria; Lebel, Julie; Henriques, Filipe; Karakas, Mahir; Çavuş, Ersin; Petersen, Steffen E.; Escalera, Sergio; Seguí, Santi; Rodríguez-Palomares, José F.; Lekadir, Karim","Campello, Víctor M. (Artificial Intelligence in Medicine Laboratory (BCN-AIM), Departament de Matemàtiques i Informàtica, Universitat de Barcelona, 08007, Barcelona, Spain); Gkontra, Polyxeni (Artificial Intelligence in Medicine Laboratory (BCN-AIM), Departament de Matemàtiques i Informàtica, Universitat de Barcelona, 08007, Barcelona, Spain); Izquierdo, Cristian (Artificial Intelligence in Medicine Laboratory (BCN-AIM), Departament de Matemàtiques i Informàtica, Universitat de Barcelona, 08007, Barcelona, Spain); Martín-Isla, Carlos (Artificial Intelligence in Medicine Laboratory (BCN-AIM), Departament de Matemàtiques i Informàtica, Universitat de Barcelona, 08007, Barcelona, Spain); Sojoudi, Alireza (Circle Cardiovascular Imaging Pvt., Ltd., Calgary, AB, T2P 3T6, Canada); Full, Peter M. (Division of Medical Image Computing, German Cancer Research Center, 69120, Heidelberg, Germany); Maier-Hein, Klaus (Division of Medical Image Computing, German Cancer Research Center, 69120, Heidelberg, Germany); Zhang, Yao (Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China); He, Zhiqiang (Lenovo Ltd., Beijing, 100085, China); Ma, Jun (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, 210094, China); Parreño, Mario (PRHLTResearch Center, Universitat Politècnica de València, 46022, Valencia, Spain); Albiol, Alberto (Team Research Institute, Universitat Politècnica de València, 46022, Valencia, Spain); Kong, Fanwei (Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, 94720, USA); Shadden, Shawn C. (Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, 94720, USA); Acero, Jorge Corral (Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, OX3 7DQ, U.K.); Sundaresan, Vaanathi (Centre for the Functional MRI of the Brain, Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, OX3 9DU, U.K.); Saber, Mina (Research and Development Division, Intixel Company S.A.E., Cairo, 11585, Egypt); Elattar, Mustafa (Research and Development Division, Intixel Company S.A.E., Cairo, 11585, Egypt; Medical Imaging and Image Processing Group, Nile University, Giza, 16453, Egypt); Li, Hongwei (Department of Computer Science, Technische Universität München, 80333, Munich, Germany; Orbem GmbH, 85748, Garching, Germany); Menze, Bjoern (Department of Computer Science, Technische Universität München, 80333, Munich, Germany); Khader, Firas (ARISTRA GmbH, 10439, Berlin, Germany); Haarburger, Christoph (ARISTRA GmbH, 10439, Berlin, Germany); Scannell, Cian M. (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, WC2R 2LS, U.K.); Veta, Mitko (Department of Biomedical Engineering, Eindhoven University of Technology, 5612, Eindhoven, The Netherlands); Carscadden, Adam (Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, AB, T6G 2R3, Canada; Servier Virtual Cardiac Centre, Mazankowski Alberta Heart Institute, Edmonton, AB, T6G 2B7, Canada); Punithakumar, Kumaradevan (Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, AB, T6G 2R3, Canada; Servier Virtual Cardiac Centre, Mazankowski Alberta Heart Institute, Edmonton, AB, T6G 2B7, Canada); Liu, Xiao (School of Engineering, The University of Edinburgh, Edinburgh, EH9 3FB, U.K.); Tsaftaris, Sotirios A. (School of Engineering, The University of Edinburgh, Edinburgh, EH9 3FB, U.K.; The Alan Turing Institute, London, NW1 2DB, U.K.); Huang, Xiaoqiong (School of Biomedical Engineering, Shenzhen University, Shenzhen, 518037, China; Medical UltraSound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518037, China); Yang, Xin (School of Biomedical Engineering, Shenzhen University, Shenzhen, 518037, China; Medical UltraSound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518037, China); Li, Lei (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, 200433, China); Viladés, David (Cardiac Imaging Unit, Cardiology Service, Hospital de la Santa Creu i Sant Pau, Universitat Autònoma de Barcelona, 08193, Barcelona, Spain); Descalzo, Martín L. (Cardiac Imaging Unit, Cardiology Service, Hospital de la Santa Creu i Sant Pau, Universitat Autònoma de Barcelona, 08193, Barcelona, Spain); Guala, Andrea (CIBERCV, Department of Cardiology, Vall d’Hebron Institut de Recerca, Hospital Universitari Vall d’Hebron, Universitat Autònoma de Barcelona, 08193, Barcelona, Spain); La Mura, Lucia (Department of Advanced Biomedical Sciences, University of Naples Federico II, 80138, Naples, Italy); Friedrich, Matthias G. (Department of Medicine and Diagnostic Radiology, McGill University, Montreal, QC, H3A 0G4, Canada); Garg, Ria (Department of Medicine and Diagnostic Radiology, McGill University, Montreal, QC, H3A 0G4, Canada); Lebel, Julie (Department of Medicine and Diagnostic Radiology, McGill University, Montreal, QC, H3A 0G4, Canada); Henriques, Filipe (Department of Medicine and Diagnostic Radiology, McGill University, Montreal, QC, H3A 0G4, Canada); Karakas, Mahir (Department of Cardiology, University Heart & Vascular Center Hamburg, 20251, Hamburg, Germany; German Center for Cardiovascular Research (DZHK), 10785, Berlin, Germany); Çavuş, Ersin (Department of Cardiology, University Heart & Vascular Center Hamburg, 20251, Hamburg, Germany; German Center for Cardiovascular Research (DZHK), 10785, Berlin, Germany); Petersen, Steffen E. (Barts Heart Centre, Barts Health NHS Trust, London, E1 1BB, U.K.; NIHR Barts Biomedical Research Centre, The William Harvey Research Institute, Queen Mary University of London, London, E1 4NS, U.K.); Escalera, Sergio (Departament de Matemàtiques i Informàtica, Universitat de Barcelona, 08007, Barcelona, Spain; Computer Vision Center, Universitat Autònoma de Barcelona, 08193, Barcelona, Spain); Seguí, Santi (Departament de Matemàtiques i Informàtica, Universitat de Barcelona, 08007, Barcelona, Spain); Rodríguez-Palomares, José F. (CIBERCV, Department of Cardiology, Vall d’Hebron Institut de Recerca, Hospital Universitari Vall d’Hebron, Universitat Autònoma de Barcelona, 08193, Barcelona, Spain); Lekadir, Karim (Artificial Intelligence in Medicine Laboratory (BCN-AIM), Departament de Matemàtiques i Informàtica, Universitat de Barcelona, 08007, Barcelona, Spain)","Campello, Víctor M. (University of Barcelona)","Campello, Víctor M. (University of Barcelona); Gkontra, Polyxeni (University of Barcelona); Izquierdo, Cristian (University of Barcelona); Martín-Isla, Carlos (University of Barcelona); Sojoudi, Alireza (Circle Cardiovascular Imaging); Full, Peter M. (German Cancer Research Center); Maier-Hein, Klaus (German Cancer Research Center); Zhang, Yao (Institute of Computing Technology); He, Zhiqiang (Lenovo (China)); Ma, Jun (Nanjing University of Science and Technology); Parreño, Mario (Universitat Politècnica de València); Albiol, Alberto (Universitat Politècnica de València); Kong, Fanwei (University of California, Berkeley); Shadden, Shawn C. (University of California, Berkeley); Acero, Jorge Corral (University of Oxford); Sundaresan, Vaanathi (University of Oxford); Saber, Mina (); Elattar, Mustafa (Nile University); Li, Hongwei (Technical University of Munich); Menze, Bjoern (Technical University of Munich); Khader, Firas (); Haarburger, Christoph (); Scannell, Cian M. (King's College London); Veta, Mitko (Eindhoven University of Technology); Carscadden, Adam (University of Alberta; Alberta Health Services); Punithakumar, Kumaradevan (University of Alberta; Alberta Health Services); Liu, Xiao (University of Edinburgh); Tsaftaris, Sotirios A. (University of Edinburgh; The Alan Turing Institute); Huang, Xiaoqiong (Shenzhen University; Shenzhen University); Yang, Xin (Shenzhen University; Shenzhen University); Li, Lei (Shanghai Jiao Tong University); Zhuang, Xiahai (Fudan University); Viladés, David (Hospital de Sant Pau); Descalzo, Martín L. (Hospital de Sant Pau); Guala, Andrea (Vall d'Hebron Hospital Universitari); La Mura, Lucia (University of Naples Federico II); Friedrich, Matthias G. (McGill University); Garg, Ria (McGill University); Lebel, Julie (McGill University); Henriques, Filipe (McGill University); Karakas, Mahir (University Medical Center Hamburg-Eppendorf; German Centre for Cardiovascular Research); Çavuş, Ersin (University Medical Center Hamburg-Eppendorf; German Centre for Cardiovascular Research); Petersen, Steffen E. (St Bartholomew's Hospital; Queen Mary University of London); Escalera, Sergio (University of Barcelona; Autonomous University of Barcelona); Seguí, Santi (University of Barcelona); Rodríguez-Palomares, José F. (Vall d'Hebron Hospital Universitari); Lekadir, Karim (University of Barcelona)",105,105,9.61,,https://ieeexplore.ieee.org/ielx7/42/9629464/09458279.pdf,https://app.dimensions.ai/details/publication/pub.1138955846,46 Information and Computing Sciences,,,,,,,,
4314,pub.1139736089,10.1109/tmi.2021.3097665,34264825,PMC9531053,Lung Nodule Malignancy Prediction in Sequential CT Scans: Summary of ISBI 2018 Challenge,"Lung cancer is by far the leading cause of cancer death in the US. Recent studies have demonstrated the effectiveness of screening using low dose CT (LDCT) in reducing lung cancer related mortality. While lung nodules are detected with a high rate of sensitivity, this exam has a low specificity rate and it is still difficult to separate benign and malignant lesions. The ISBI 2018 Lung Nodule Malignancy Prediction Challenge, developed by a team from the Quantitative Imaging Network of the National Cancer Institute, was focused on the prediction of lung nodule malignancy from two sequential LDCT screening exams using automated (non-manual) algorithms. We curated a cohort of 100 subjects who participated in the National Lung Screening Trial and had established pathological diagnoses. Data from 30 subjects were randomly selected for training and the remaining was used for testing. Participants were evaluated based on the area under the receiver operating characteristic curve (AUC) of nodule-wise malignancy scores generated by their algorithms on the test set. The challenge had 17 participants, with 11 teams submitting reports with method description, mandated by the challenge rules. Participants used quantitative methods, resulting in a reporting test AUC ranging from 0.698 to 0.913. The top five contestants used deep learning approaches, reporting an AUC between 0.87 - 0.91. The team's predictor did not achieve significant differences from each other nor from a volume change estimate (p =.05 with Bonferroni-Holm's correction).","The authors would like to express their appreciation to the reviewers and editors of the IEEE-TMI for their insightful comments, which have helped to significantly improve the article. The authors also wish to acknowledge the contribution rendered by following individuals. Their effort had immensely helped to organize the challenge and contributed to the advancement of imaging methods in the field of quantitative medical imaging. Robert Gillies, Ph.D. (Cancer Physiology), Mathew Schabath, Ph.D., (Epidemiology), Alberto Garcia, B.S., (Cancer Physiology), Mahmoud Abdalah, Ph.D., (IRAT Core), H. Lee. Moffitt Cancer Center (MCC), Tampa, FL, USA. Dmitry Cherezov, University of South Florida (USF). Ying Liu, M.D., Qian Li, M.D., Tianjin Medical Hospital and Cancer Center, Tianjin, China. Justin Kirby, National Cancer Institute. Program Managers and Staff at Quantitative Imaging Network, NCI and Data Managers at The Cancer Data Access System (CDAS). They are thankful to Carolyn Klinger, Fredrick National Laboratory for Cancer Research, for her valuable comments and proofreading the manuscript. They would also like to acknowledge the team members who participated in the challenge and acknowledge their contributions to the individual teams method development. Jae-hun Kim, Ph.D., Department of Radiology, Samsung Medical Center, School of Medicine, Sungkyunkwan University, Seoul,South Korea. Jung Won Moon, M.D., Human Medical Imaging and Intervention Center, Seoul, South Korea. Chin A Yi, M.D, Ph.D., School of Medicine, Sungkyunkwan University, Seoul, South Korea. Nova F. Smedley, Edgar A. Rios Piedra, Medical Imaging Informatics, University of California, Los Angeles. Adrià Barja Romero, Alberto Montes Gómez, Àlex Martín Alay, Carlos González Rotger, Daniel Rodrigo, Enric Cosp Arqué, Eric Valls, Ferran Vidal-Codina, Ivan Parrot Martinez, Javier Maroto Morales, Jon Liberal Huarte, Josep Marc Mingot Hidalgo, Juan Jose Garau Luis, Manuel Sarmiento Calder, Miguel Cidras Senra, Miguel Pérez Sanchis, Pau Batlle Franch, and Sergio Escosa Rodríguez, Alumni Team from the Universitat Politècnica de Catalunya, Barcelona, Spain. Peter O’Halloran, M.D., Department of Radiology, Massachusetts General Hospital.",,IEEE Transactions on Medical Imaging,,"Algorithms; Humans; Lung; Lung Neoplasms; ROC Curve; Solitary Pulmonary Nodule; Tomography, X-Ray Computed",2021-11-30,2021,2021-11-30,2021-12,40,12,3748-3761,All OA, Green,Article,"Balagurunathan, Yoganand; Beers, Andrew; Mcnitt-Gray, Michael; Hadjiiski, Lubomir; Napel, Sandy; Goldgof, Dmitry; Perez, Gustavo; Arbelaez, Pablo; Mehrtash, Alireza; Kapur, Tina; Yang, Ehwa; Moon, Jung Won; Perez, Gabriel Bernardino; Delgado-Gonzalo, Ricard; Farhangi, M. Mehdi; Amini, Amir A.; Ni, Renkun; Feng, Xue; Bagari, Aditya; Vaidhya, Kiran; Veasey, Benjamin; Safta, Wiem; Frigui, Hichem; Enguehard, Joseph; Gholipour, Ali; Castillo, Laura Silvana; Daza, Laura Alexandra; Pinsky, Paul; Kalpathy-Cramer, Jayashree; Farahani, Keyvan","Balagurunathan, Yoganand (Department of Machine Learning, H Lee Moffitt Cancer Center (MCC) and Research Institute, Tampa, FL, 33612, USA); Beers, Andrew (Massachusetts General Hospital (MGH), Boston, MA, 02114, USA); Mcnitt-Gray, Michael (Thoracic Imaging Section, David Geffen School of Medicine, University of California at Los Angeles (UCLA), Los Angeles, CA, 90095, USA); Hadjiiski, Lubomir (Department of Radiology, University of Michigan (UMICH), Ann Arbor, MI, 48109, USA); Napel, Sandy (Department of Radiology, School of Medicine, Stanford University (SU), Stanford, CA, 94305, USA); Goldgof, Dmitry (Department of Computer Science, University of South Florida (USF), Tampa, FL, 33620, USA); Perez, Gustavo (Biomedical Computer Vision Laboratory (BCV), Universidad de Los Andes, Bogota, 111711, Colombia); Arbelaez, Pablo (Biomedical Computer Vision Laboratory (BCV), Universidad de Los Andes, Bogota, 111711, Colombia); Mehrtash, Alireza (Robotics and Control Laboratory (RCL), Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, V6T 1Z4, Canada; Surgical Planning Laboratory (SPL), Department of Radiology, Brigham and Women’s Faulkner Hospital, Boston, MA, 02130, USA); Kapur, Tina (Surgical Planning Laboratory (SPL), Department of Radiology, Brigham and Women’s Faulkner Hospital, Boston, MA, 02130, USA); Yang, Ehwa (School of Medicine, Sungkyunkwan University, Seoul, 06351, South Korea); Moon, Jung Won (Human Medical Imaging and Intervention Center, Seoul, 06524, South Korea); Perez, Gabriel Bernardino (Physense, Department of Information and Communication Technologies, Universitat Pompeu Fabra, 08002, Barcelona, Spain); Delgado-Gonzalo, Ricard (Centre Suisse d’Électronique et de Microtechnique, 2002, Neuchâtel, Switzerland); Farhangi, M. Mehdi (Medical Imaging Laboratory, University of Louisville, Louisville, KY, 40292, USA; Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, 40292, USA); Amini, Amir A. (Medical Imaging Laboratory, University of Louisville, Louisville, KY, 40292, USA; Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, 40292, USA); Ni, Renkun (Springbok Inc., Charlottesville, VA, 22903, USA); Feng, Xue (Springbok Inc., Charlottesville, VA, 22903, USA; Department of Biomedical Engineering, University of Virginia, Charlottesville, VA, 22903, USA); Bagari, Aditya (Predible Health Inc., Bengaluru, 560029, India); Vaidhya, Kiran (Predible Health Inc., Bengaluru, 560029, India); Veasey, Benjamin (Medical Imaging Laboratory, University of Louisville, Louisville, KY, 40292, USA; Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, 40292, USA); Safta, Wiem (Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, 40292, USA); Frigui, Hichem (Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, 40292, USA); Enguehard, Joseph (Department of Radiology, Boston Children’s Hospital, Boston, MA, 02115, USA; Harvard Medical School, Boston, MA, 02115, USA); Gholipour, Ali (Department of Radiology, Boston Children’s Hospital, Boston, MA, 02115, USA; Harvard Medical School, Boston, MA, 02115, USA); Castillo, Laura Silvana (Department of Biomedical Engineering, Universidad de los Andes, Bogota, 110111, Colombia); Daza, Laura Alexandra (Department of Biomedical Engineering, Universidad de los Andes, Bogota, 110111, Colombia); Pinsky, Paul (Division of Cancer Prevention, Bethesda, MD, 20892, USA); Kalpathy-Cramer, Jayashree (Massachusetts General Hospital (MGH), Boston, MA, 02114, USA); Farahani, Keyvan (Center for Biomedical Informatics and Information Technology, National Cancer Institute (NCI), Bethesda, MD, 20892, USA)","Farahani, Keyvan (National Cancer Institute)","Balagurunathan, Yoganand (Moffitt Cancer Center); Beers, Andrew (Massachusetts General Hospital); Mcnitt-Gray, Michael (University of California, Los Angeles); Hadjiiski, Lubomir (University of Michigan–Ann Arbor); Napel, Sandy (Stanford University); Goldgof, Dmitry (University of South Florida); Perez, Gustavo (Universidad de Los Andes); Arbelaez, Pablo (Universidad de Los Andes); Mehrtash, Alireza (University of British Columbia; Brigham and Women's Faulkner Hospital); Kapur, Tina (Brigham and Women's Faulkner Hospital); Yang, Ehwa (Sungkyunkwan University); Moon, Jung Won (); Perez, Gabriel Bernardino (Pompeu Fabra University); Delgado-Gonzalo, Ricard (Swiss Center for Electronics and Microtechnology); Farhangi, M. Mehdi (University of Louisville; University of Louisville); Amini, Amir A. (University of Louisville; University of Louisville); Ni, Renkun (); Feng, Xue (University of Virginia); Bagari, Aditya (); Vaidhya, Kiran (); Veasey, Benjamin (University of Louisville; University of Louisville); Safta, Wiem (University of Louisville); Frigui, Hichem (University of Louisville); Enguehard, Joseph (Boston Children's Hospital; Harvard University); Gholipour, Ali (Boston Children's Hospital; Harvard University); Castillo, Laura Silvana (Universidad de Los Andes); Daza, Laura Alexandra (Universidad de Los Andes); Pinsky, Paul (National Cancer Institute); Kalpathy-Cramer, Jayashree (Massachusetts General Hospital); Farahani, Keyvan (National Cancer Institute)",4,4,0.55,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9531053,https://app.dimensions.ai/details/publication/pub.1139736089,40 Engineering, 46 Information and Computing Sciences,3 Good Health and Well Being,,,,,,,,,
1251,pub.1143700762,10.32604/cmc.2022.017916,,,Optical Flow with Learning Feature for Deformable Medical Image Registration,"Deformable medical image registration plays a vital role in medical image applications, such as placing different temporal images at the same time point or different modality images into the same coordinate system. Various strategies have been developed to satisfy the increasing needs of deformable medical image registration. One popular registration method is estimating the displacement field by computing the optical flow between two images. The motion field (flow field) is computed based on either gray-value or handcrafted descriptors such as the scale-invariant feature transform (SIFT). These methods assume that illumination is constant between images. However, medical images may not always satisfy this assumption. In this study, we propose a metric learning-based motion estimation method called Siamese Flow for deformable medical image registration. We train metric learners using a Siamese network, which produces an image patch descriptor that guarantees a smaller feature distance in two similar anatomical structures and a larger feature distance in two dissimilar anatomical structures. In the proposed registration framework, the flow field is computed based on such features and is close to the real deformation field due to the excellent feature representation ability of the Siamese network. Experimental results demonstrate that the proposed method outperforms the Demons, SIFT Flow, Elastix, and VoxelMorph networks regarding registration accuracy and robustness, particularly with large deformations.",,,Computers Materials & Continua,,,2021-11-29,2021,2021-11-29,2022,71,2,2773-2788,All OA, Gold,Article,"Hu, Jinrong; Li, Lujin; Fu, Ying; Zou, Maoyang; Zhou, Jiliu; Sun, Shanhui","Hu, Jinrong (Department of Computer Science, Chengdu University of Information Technology, Chengdu, 610225, China); Li, Lujin (Department of Computer Science, Chengdu University of Information Technology, Chengdu, 610225, China); Fu, Ying (Department of Computer Science, Chengdu University of Information Technology, Chengdu, 610225, China); Zou, Maoyang (Department of Computer Science, Chengdu University of Information Technology, Chengdu, 610225, China); Zhou, Jiliu (Department of Computer Science, Chengdu University of Information Technology, Chengdu, 610225, China); Sun, Shanhui (Curacloud Corporation, 999 Third Ave, Suite 700 Seattle, WA, 98104, USA)","Sun, Shanhui ","Hu, Jinrong (Chengdu University of Information Technology); Li, Lujin (Chengdu University of Information Technology); Fu, Ying (Chengdu University of Information Technology); Zou, Maoyang (Chengdu University of Information Technology); Zhou, Jiliu (Chengdu University of Information Technology); Sun, Shanhui ()",0,0,,0.0,https://www.techscience.com/cmc/v71n2/45763/pdf,https://app.dimensions.ai/details/publication/pub.1143700762,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science,,,,,,,,
6987,pub.1143324663,10.1007/s13534-021-00212-w,35186361,PMC8825913,A digital cardiac disease biomarker from a generative progressive cardiac cine-MRI representation,"Cardiac cine-MRI is one of the most important diagnostic tools used to assess the morphology and physiology of the heart during the cardiac cycle. Nonetheless, the analysis on cardiac cine-MRI is poorly exploited and remains highly dependent on the observer's expertise. This work introduces an imaging cardiac disease representation, coded as an embedding vector, that fully exploits hidden mapping between the latent space and a generated cine-MRI data distribution. The resultant representation is progressively learned and conditioned by a set of cardiac conditions. A generative cardiac descriptor is achieved from a progressive generative-adversarial network trained to produce MRI synthetic images, conditioned to several heart conditions. The generator model is then used to recover a digital biomarker, coded as an embedding vector, following a backpropagation scheme. Then, an UMAP strategy is applied to build a topological low dimensional embedding space that discriminates among cardiac pathologies. Evaluation of the approach is carried out by using an embedded representation as a potential disease descriptor in 2296 pathological cine-MRI slices. The proposed strategy yields an average accuracy of 0.8 to discriminate among heart conditions. Furthermore, the low dimensional space shows a remarkable grouping of cardiac classes that may suggest its potential use as a tool to support diagnosis. The learned progressive and generative representation, from cine-MRI slices, allows retrieves and coded complex descriptors that results useful to discriminate among heart conditions. The cardiac disease representation expressed as a hidden embedding vector could potentially be used to support cardiac analysis on cine-MRI sequences.",,,Biomedical Engineering Letters,,,2021-11-27,2021,2021-11-27,2022-02,12,1,75-84,All OA, Green,Article,"Gómez, Santiago; Romo-Bucheli, David; Martínez, Fabio","Gómez, Santiago (Biomedical Imaging, Vision and Learning Laboratory (BIVL2ab), Universidad Industrial de Santander (UIS), Santander, Colombia); Romo-Bucheli, David (Biomedical Imaging, Vision and Learning Laboratory (BIVL2ab), Universidad Industrial de Santander (UIS), Santander, Colombia); Martínez, Fabio (Biomedical Imaging, Vision and Learning Laboratory (BIVL2ab), Universidad Industrial de Santander (UIS), Santander, Colombia)","Martínez, Fabio (Industrial University of Santander)","Gómez, Santiago (Industrial University of Santander); Romo-Bucheli, David (Industrial University of Santander); Martínez, Fabio (Industrial University of Santander)",0,0,,0.0,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8825913,https://app.dimensions.ai/details/publication/pub.1143324663,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 46 Information and Computing Sciences,,,,,,,,,
5351,pub.1143203722,10.1016/j.cvdhj.2021.11.007,35265930,PMC8890075,Anatomically informed deep learning on contrast-enhanced cardiac magnetic resonance imaging for scar segmentation and clinical feature extraction,"Background: Visualizing fibrosis on cardiac magnetic resonance (CMR) imaging with contrast enhancement (late gadolinium enhancement; LGE) is paramount in characterizing disease progression and identifying arrhythmia substrates. Segmentation and fibrosis quantification from LGE-CMR is intensive, manual, and prone to interobserver variability. There is an unmet need for automated LGE-CMR image segmentation that ensures anatomical accuracy and seamless extraction of clinical features.
Objective: This study aimed to develop a novel deep learning solution for analysis of contrast-enhanced CMR images that produces anatomically accurate myocardium and scar/fibrosis segmentations and uses these to calculate features of clinical interest.
Methods: Data sources were 155 2-dimensional LGE-CMR patient scans (1124 slices) and 246 synthetic ""LGE-like"" scans (1360 slices) obtained from cine CMR using a novel style-transfer algorithm. We trained and tested a 3-stage neural network that identified the left ventricle (LV) region of interest (ROI), segmented ROI into viable myocardium and regions of enhancement, and postprocessed the segmentation results to enforce conforming to anatomical constraints. The segmentations were used to directly compute clinical features, such as LV volume and scar burden.
Results: Predicted LV and scar segmentations achieved 96% and 75% balanced accuracy, respectively, and 0.93 and 0.57 Dice coefficient when compared to trained expert segmentations. The mean scar burden difference between manual and predicted segmentations was 2%.
Conclusion: We developed and validated a deep neural network for automatic, anatomically accurate expert-level LGE- CMR myocardium and scar/fibrosis segmentation, allowing direct calculation of clinical measures. Given the training set heterogeneity, our approach could be extended to multiple imaging modalities and patient pathologies.","Funding Sources
        NT acknowledges support from NIH (grants R01HL142496, R01HL124893 and U01HL126273), a grant from the Leducq Foundation, and a grant for the Lowenstein Foundation. MM is grateful for support from the Simons Foundation, from NSF 2031985, 1837991, and AFOSR FA9550-20-1-0288. KCW is grateful for support from NIH grant HL103812 and HL132181.
      
      
        Disclosures
        The authors have no conflict to disclose.
      
      
        Authorship
        All authors attest they meet the current ICMJE criteria for authorship.
      
      
        Patient Consent
        All patients provided written informed consent.
      
      
        Ethics Statement
        The research protocol used in this study was reviewed and approved by the Johns Hopkins University Institutional Review Board.
      
      
        Appendix Supplementary data
        Supplementary data associated with this article can be found in the online version at https://doi.org/10.1016/j.cvdhj.2021.11.007.","NT acknowledges support from NIH (grants R01HL142496, R01HL124893 and U01HL126273), a grant from the Leducq Foundation, and a grant for the Lowenstein Foundation. MM is grateful for support from the Simons Foundation, from NSF 2031985, 1837991, and AFOSR FA9550-20-1-0288. KCW is grateful for support from NIH grant HL103812 and HL132181.",Cardiovascular Digital Health Journal,,,2021-11-26,2021,2021-11-26,2022-02,3,1,2-13,All OA, Gold,Article,"Popescu, Dan M.; Abramson, Haley G.; Yu, Rebecca; Lai, Changxin; Shade, Julie K.; Wu, Katherine C.; Maggioni, Mauro; Trayanova, Natalia A.","Popescu, Dan M. (Alliance for Cardiovascular Diagnostic and Treatment Innovation (ADVANCE), Johns Hopkins University, Baltimore, Maryland); Abramson, Haley G. (Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, Maryland); Yu, Rebecca (Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, Maryland); Lai, Changxin (Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, Maryland); Shade, Julie K. (Alliance for Cardiovascular Diagnostic and Treatment Innovation (ADVANCE), Johns Hopkins University, Baltimore, Maryland); Wu, Katherine C. (Alliance for Cardiovascular Diagnostic and Treatment Innovation (ADVANCE), Johns Hopkins University, Baltimore, Maryland; Division of Cardiology, Department of Medicine, Johns Hopkins Hospital, Baltimore, Maryland); Maggioni, Mauro (Alliance for Cardiovascular Diagnostic and Treatment Innovation (ADVANCE), Johns Hopkins University, Baltimore, Maryland; Department of Applied Mathematics and Statistics, Johns Hopkins University, Baltimore, Maryland); Trayanova, Natalia A. (Alliance for Cardiovascular Diagnostic and Treatment Innovation (ADVANCE), Johns Hopkins University, Baltimore, Maryland; Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, Maryland)","Trayanova, Natalia A. (Johns Hopkins University; Johns Hopkins University)","Popescu, Dan M. (Johns Hopkins University); Abramson, Haley G. (Johns Hopkins University); Yu, Rebecca (Johns Hopkins University); Lai, Changxin (Johns Hopkins University); Shade, Julie K. (Johns Hopkins University); Wu, Katherine C. (Johns Hopkins University; Johns Hopkins Hospital); Maggioni, Mauro (Johns Hopkins University; Johns Hopkins University); Trayanova, Natalia A. (Johns Hopkins University; Johns Hopkins University)",7,7,0.52,6.14,http://www.cvdigitalhealthjournal.com/article/S2666693621001316/pdf,https://app.dimensions.ai/details/publication/pub.1143203722,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
6279,pub.1142737191,10.1016/j.cmpb.2021.106548,34861618,,Left ventricular non-compaction cardiomyopathy automatic diagnosis using a deep learning approach,"BACKGROUND AND OBJECTIVE: Left ventricular non-compaction (LVNC) is an uncommon cardiomyopathy characterised by a thick and spongy left ventricle wall caused by the high presence of trabeculae (hyper-trabeculation). Recently, the percentage of the trabecular volume to the total volume of the external wall of the left ventricle (VT%) has been proposed to diagnose this illness.
METHODS: This paper presents the use of a deep learning-based method to measure the (VT%) value and diagnose this rare cardiomyopathy. The population used in this research was composed of 277 patients suffering from hypertrophic cardiomyopathy. 134 patients only suffered hypertrophic cardiomyopathy, and 143 also suffered left ventricular non-compaction. Our deep learning solution is based on a 2D U-Net. This artificial neural network (ANN) was trained on short-axis magnetic resonance imaging to segment the left ventricle's internal cavity, external wall, and trabecular tissue. 5-fold cross-validation was performed to ensure the robustness of the results. The Dice coefficient of the three classes was computed as a measure of the precision of the segmentation. Based on this segmentation, the percentage of the trabecular volume (VT%) was computed. Two specialist cardiologists rated the segmentation produced by the neural network for 25 patients to evaluate the clinical validity of the outputs. The computed VT% was used to automatically diagnose the 277 patients depending on whether or not a given threshold was exceeded. A receiver operating characteristic analysis was also performed.
RESULTS: According to the cross-validation results, the average and standard deviation of the Dice coefficient for the internal cavity, external wall, and trabeculae were 0.96±0.00, 0.89±0.00, and 0.84±0.00, respectively. The cardiologists rated 99.5% of the evaluated segmentations as clinically valid for diagnosis, outperforming existing automatic traditional tools. The area under the ROC curve was 0.94 (95% confidence interval, 0.91-0.96). The accuracy, sensitivity, and specificity values of diagnosis using a threshold of 25% were 0.87, 0.93, and 0.80, respectively.
CONCLUSIONS: The U-Net neural network can achieve excellent results in the delineation of different cardiac structures of short-axis cardiac MRI. The high-quality segmentation allows for the correct measurement of left ventricular hyper-trabeculation and a definitive diagnosis of LVNC illness. Using this kind of solution could lead to more objective and faster analysis, reducing human error and time spent by cardiologists.","This work was partially funded by the AEI (State Research Agency, Spain) and the ERDF (European Regional Development Fund, EU) under the Contract RTI2018-098156-B-C53, (MCI/AEI/FEDER, UE).",,Computer Methods and Programs in Biomedicine,,Cardiomyopathies, Deep Learning, Heart, Heart Ventricles, Humans, Magnetic Resonance Imaging,2021-11-23,2021,2021-11-23,2022-02,214,,106548,Closed,Article,"Rodríguez-de-Vera, Jesús M; Bernabé, Gregorio; García, José M; Saura, Daniel; González-Carrillo, Josefa","Rodríguez-de-Vera, Jesús M (Computer Engineering Department, University of Murcia, Murcia 30071 Spain.); Bernabé, Gregorio (Computer Engineering Department, University of Murcia, Murcia 30071 Spain. Electronic address: gbernabe@um.es.); García, José M (Computer Engineering Department, University of Murcia, Murcia 30071 Spain.); Saura, Daniel (Hospital Virgen de la Arrixaca, Murcia 30080 Spain.); González-Carrillo, Josefa (Hospital Virgen de la Arrixaca, Murcia 30080 Spain.)","Bernabé, Gregorio (University of Murcia)","Rodríguez-de-Vera, Jesús M (University of Murcia); Bernabé, Gregorio (University of Murcia); García, José M (University of Murcia); Saura, Daniel (Hospital Universitario Virgen de la Arrixaca); González-Carrillo, Josefa (Hospital Universitario Virgen de la Arrixaca)",2,2,,1.64,,https://app.dimensions.ai/details/publication/pub.1142737191,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,
1209,pub.1142920748,10.48550/arxiv.2111.11629,,,Uncertainty-Aware Deep Co-training for Semi-supervised Medical Image  Segmentation,"Semi-supervised learning has made significant strides in the medical domain
since it alleviates the heavy burden of collecting abundant pixel-wise
annotated data for semantic segmentation tasks. Existing semi-supervised
approaches enhance the ability to extract features from unlabeled data with
prior knowledge obtained from limited labeled data. However, due to the
scarcity of labeled data, the features extracted by the models are limited in
supervised learning, and the quality of predictions for unlabeled data also
cannot be guaranteed. Both will impede consistency training. To this end, we
proposed a novel uncertainty-aware scheme to make models learn regions
purposefully. Specifically, we employ Monte Carlo Sampling as an estimation
method to attain an uncertainty map, which can serve as a weight for losses to
force the models to focus on the valuable region according to the
characteristics of supervised learning and unsupervised learning.
Simultaneously, in the backward process, we joint unsupervised and supervised
losses to accelerate the convergence of the network via enhancing the gradient
flow between different tasks. Quantitatively, we conduct extensive experiments
on three challenging medical datasets. Experimental results show desirable
improvements to state-of-the-art counterparts.",,,arXiv,,,2021-11-22,2021,,,,,,All OA, Green,Preprint,"Zheng, Xu; Fu, Chong; Xie, Haoyu; Chen, Jialei; Wang, Xingwei; Sham, Chiu-Wing","Zheng, Xu (); Fu, Chong (); Xie, Haoyu (); Chen, Jialei (); Wang, Xingwei (); Sham, Chiu-Wing ()",,"Zheng, Xu (); Fu, Chong (); Xie, Haoyu (); Chen, Jialei (); Wang, Xingwei (); Sham, Chiu-Wing ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142920748,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
4788,pub.1142648024,10.1016/j.compbiomed.2021.105041,34836627,PMC8900530,Native-resolution myocardial principal Eulerian strain mapping using convolutional neural networks and Tagged Magnetic Resonance Imaging,"BACKGROUND: Assessment of regional myocardial function at native pixel-level resolution can play a crucial role in recognizing the early signs of the decline in regional myocardial function. Extensive data processing in existing techniques limits the effective resolution and accuracy of the generated strain maps. The purpose of this study is to compute myocardial principal strain maps εp1 and εp2 from tagged MRI (tMRI) at the native image resolution using deep-learning local patch convolutional neural network (CNN) models (DeepStrain).
METHODS: For network training, validation, and testing, realistic tMRI datasets were generated and consisted of 53,606 cine images simulating the heart, the liver, blood pool, and backgrounds, including ranges of shapes, positions, motion patterns, noise, and strain. In addition, 102 in-vivo image datasets from three healthy subjects, and three Pulmonary Arterial Hypertension patients, were acquired and used to assess the network's in-vivo performance. Four convolutional neural networks were trained for mapping input tagging patterns to corresponding ground-truth principal strains using different cost functions. Strain maps using harmonic phase analysis (HARP) were obtained with various spectral filtering settings for comparison. CNN and HARP strain maps were compared at the pixel level versus the ground-truth and versus the least-loss in-vivo maps using Pearson correlation coefficients (R) and the median error and Inter-Quartile Range (IQR) histograms.
RESULTS: CNN-based local patch DeepStrain maps at a phantom resolution of 1.1mm × 1.1 mm and in-vivo resolution of 2.1mm × 1.6 mm were artifact-free with multiple fold improvement with εp1 ground-truth median error of 0.009(0.007) vs. 0.32(0.385) using HARP and εp2 ground-truth error of 0.016(0.021) vs. 0.181(0.08) using HARP. CNN-based strain maps showed substantially higher agreement with the ground-truth maps with correlation coefficients R > 0.91 for εp1 and εp2 compared to R < 0.21 and R < 0.82 for HARP-generated maps, respectively.
CONCLUSION: CNN-generated Eulerian strain mapping permits artifact-free visualization of myocardial function at the native image resolution.","This work was funded by the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), Intramural Research Program, the National Institutes of Health (NIH), USA, and Projects #729 US C18, and #1041 US C20 of the Science and Technology Fund Institute (STDF), Egypt. Drs Solomon and Elinoff receive research support from the Clinical Center intramural research funds, the National Institutes of Health (NIH), USA. The funding sources had not role in the study design, in the collection, analysis and interpretation of data, in the writing of the manuscript, and in the decision to submit the manuscript for publication.",,Computers in Biology and Medicine,,"Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Myocardium; Neural Networks, Computer; Phantoms, Imaging",2021-11-18,2021,2021-11-18,2022-02,141,,105041,Closed,Article,"Yassine, Inas A; Ghanem, Ahmed M; Metwalli, Nader S; Hamimi, Ahmed; Ouwerkerk, Ronald; Matta, Jatin R; Solomon, Michael A; Elinoff, Jason M; Gharib, Ahmed M; Abd-Elmoniem, Khaled Z","Yassine, Inas A (Systems and Biomedical Engineering Department, Faculty of Engineering, Cairo University, Egypt.); Ghanem, Ahmed M (Biomedical and Metabolic Imaging Branch, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), National Institutes of Health, Bethesda, MD, USA.); Metwalli, Nader S (Biomedical and Metabolic Imaging Branch, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), National Institutes of Health, Bethesda, MD, USA.); Hamimi, Ahmed (Biomedical and Metabolic Imaging Branch, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), National Institutes of Health, Bethesda, MD, USA.); Ouwerkerk, Ronald (Biomedical and Metabolic Imaging Branch, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), National Institutes of Health, Bethesda, MD, USA.); Matta, Jatin R (Biomedical and Metabolic Imaging Branch, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), National Institutes of Health, Bethesda, MD, USA.); Solomon, Michael A (Cardiovascular Branch of the National Heart, Lung, and Blood Institute (NHLBI), NIH, Bethesda, MD, USA; Critical Care Medicine Department, NIH Clinical Center, Bethesda, MD, USA.); Elinoff, Jason M (Critical Care Medicine Department, NIH Clinical Center, Bethesda, MD, USA.); Gharib, Ahmed M (Biomedical and Metabolic Imaging Branch, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), National Institutes of Health, Bethesda, MD, USA.); Abd-Elmoniem, Khaled Z (Biomedical and Metabolic Imaging Branch, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK), National Institutes of Health, Bethesda, MD, USA. Electronic address: abdelmoniemkz@mail.nih.gov.)","Abd-Elmoniem, Khaled Z (National Institute of Diabetes and Digestive and Kidney Diseases)","Yassine, Inas A (Cairo University); Ghanem, Ahmed M (National Institute of Diabetes and Digestive and Kidney Diseases); Metwalli, Nader S (National Institute of Diabetes and Digestive and Kidney Diseases); Hamimi, Ahmed (National Institute of Diabetes and Digestive and Kidney Diseases); Ouwerkerk, Ronald (National Institute of Diabetes and Digestive and Kidney Diseases); Matta, Jatin R (National Institute of Diabetes and Digestive and Kidney Diseases); Solomon, Michael A (National Institutes of Health; National Institutes of Health Clinical Center); Elinoff, Jason M (National Institutes of Health Clinical Center); Gharib, Ahmed M (National Institute of Diabetes and Digestive and Kidney Diseases); Abd-Elmoniem, Khaled Z (National Institute of Diabetes and Digestive and Kidney Diseases)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142648024,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
6720,pub.1142566866,10.1016/j.cjca.2021.11.003,34780990,,Generative Adversarial Networks in Cardiology,"Generative adversarial networks (GANs) are state-of-the-art neural network models used to synthesise images and other data. GANs brought a considerable improvement to the quality of synthetic data, quickly becoming the standard for data-generation tasks. In this work, we summarise the applications of GANs in the field of cardiology, including generation of realistic cardiac images, electrocardiography signals, and synthetic electronic health records. The utility of GAN-generated data is discussed with respect to research, clinical care, and academia. And we present illustrative examples of our GAN-generated cardiac magnetic resonance and echocardiography images, showing the evolution in image quality across 6 different models, which have become almost indistinguishable from real images. Finally, we discuss future applications, such as modality translation or patient trajectory modelling. Moreover, we discuss the pending challenges that GANs need to overcome, namely, their training dynamics, the medical fidelity or the data regulations and ethics questions, to become integrated in cardiology workflows.",,The authors have no funding sources to declare.,Canadian Journal of Cardiology,,"Cardiology; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer",2021-11-13,2021,2021-11-13,2022-02,38,2,196-203,All OA, Bronze,Article,"Skandarani, Youssef; Lalande, Alain; Afilalo, Jonathan; Jodoin, Pierre-Marc","Skandarani, Youssef (Groupe IFTIM, Laboratoire ImViA, UFR Sciences et Techniques, Université de Bourgogne, Dijon, France. Electronic address: youssef_skandarani@etu.u-bourgogne.fr.); Lalande, Alain (Groupe IFTIM, Laboratoire ImViA, UFR Sciences et Techniques, Université de Bourgogne, Dijon, France; Medical Imaging Department, University Hospital of Dijon, Dijon, France.); Afilalo, Jonathan (Jewish General Hospital, McGill University, Montréal, Québec, Canada.); Jodoin, Pierre-Marc (Université de Sherbrooke, Sherbrooke, Québec, Canada.)","Skandarani, Youssef (University of Burgundy)","Skandarani, Youssef (University of Burgundy); Lalande, Alain (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne); Afilalo, Jonathan (McGill University; Jewish General Hospital); Jodoin, Pierre-Marc (Université de Sherbrooke)",10,10,2.99,11.28,http://manuscript.elsevier.com/S0828282X21008606/pdf/S0828282X21008606.pdf,https://app.dimensions.ai/details/publication/pub.1142566866,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
5850,pub.1142513674,10.1186/s12968-021-00791-8,34758821,PMC8582149,Atri-U: assisted image analysis in routine cardiovascular magnetic resonance volumetry of the left atrium,"BackgroundArtificial intelligence can assist in cardiac image interpretation. Here, we achieved a substantial reduction in time required to read a cardiovascular magnetic resonance (CMR) study to estimate left atrial volume without compromising accuracy or reliability. Rather than deploying a fully automatic black-box, we propose to incorporate the automated LA volumetry into a human-centric interactive image-analysis process.Methods and resultsAtri-U, an automated data analysis pipeline for long-axis cardiac cine images, computes the atrial volume by: (i) detecting the end-systolic frame, (ii) outlining the endocardial borders of the LA, (iii) localizing the mitral annular hinge points and constructing the longitudinal atrial diameters, equivalent to the usual workup done by clinicians. In every step human interaction is possible, such that the results provided by the algorithm can be accepted, corrected, or re-done from scratch. Atri-U was trained and evaluated retrospectively on a sample of 300 patients and then applied to a consecutive clinical sample of 150 patients with various heart conditions. The agreement of the indexed LA volume between Atri-U and two experts was similar to the inter-rater agreement between clinicians (average overestimation of 0.8 mL/m2 with upper and lower limits of agreement of − 7.5 and 5.8 mL/m2, respectively). An expert cardiologist blinded to the origin of the annotations rated the outputs produced by Atri-U as acceptable in 97% of cases for step (i), 94% for step (ii) and 95% for step (iii), which was slightly lower than the acceptance rate of the outputs produced by a human expert radiologist in the same cases (92%, 100% and 100%, respectively). The assistance of Atri-U lead to an expected reduction in reading time of 66%—from 105 to 34 s, in our in-house clinical setting.ConclusionsOur proposal enables automated calculation of the maximum LA volume approaching human accuracy and precision. The optional user interaction is possible at each processing step. As such, the assisted process sped up the routine CMR workflow by providing accurate, precise, and validated measurement results.","We want to thank Claudia Rutigliano, Timo van Alst and Professor Michael Kuehne for their contribution and valuable input.",The authors declare that no funding was received for the research reported in this article. The article processing costs were covered by the “publication fund for open access” of the University of Basel.,Journal of Cardiovascular Magnetic Resonance,,"Artificial Intelligence; Heart Atria; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Magnetic Resonance Spectroscopy; Predictive Value of Tests; Reproducibility of Results; Retrospective Studies",2021-11-11,2021,2021-11-11,2021-12,23,1,133,All OA, Gold,Article,"Anastasopoulos, Constantin; Yang, Shan; Pradella, Maurice; Akinci D’Antonoli, Tugba; Knecht, Sven; Cyriac, Joshy; Reisert, Marco; Kellner, Elias; Achermann, Rita; Haaf, Philip; Stieltjes, Bram; Sauter, Alexander W.; Bremerich, Jens; Sommer, Gregor; Abdulkadir, Ahmed","Anastasopoulos, Constantin (Department of Radiology, University Hospital Basel, University of Basel, Basel, Switzerland); Yang, Shan (Department of Research and Analysis, University Hospital Basel, University of Basel, Basel, Switzerland); Pradella, Maurice (Department of Radiology, University Hospital Basel, University of Basel, Basel, Switzerland); Akinci D’Antonoli, Tugba (Department of Radiology, University Hospital Basel, University of Basel, Basel, Switzerland; Department of Radiology, University Children’s Hospital Basel, University of Basel, Basel, Switzerland); Knecht, Sven (Department of Cardiology, University Hospital Basel, University of Basel, Basel, Switzerland); Cyriac, Joshy (Department of Research and Analysis, University Hospital Basel, University of Basel, Basel, Switzerland); Reisert, Marco (Medical Physics, Department of Radiology, University Medical Center Freiburg, Freiburg, Germany); Kellner, Elias (Medical Physics, Department of Radiology, University Medical Center Freiburg, Freiburg, Germany); Achermann, Rita (Department of Research and Analysis, University Hospital Basel, University of Basel, Basel, Switzerland); Haaf, Philip (Department of Cardiology, University Hospital Basel, University of Basel, Basel, Switzerland); Stieltjes, Bram (Department of Radiology, University Hospital Basel, University of Basel, Basel, Switzerland; Department of Research and Analysis, University Hospital Basel, University of Basel, Basel, Switzerland); Sauter, Alexander W. (Department of Radiology, University Hospital Basel, University of Basel, Basel, Switzerland); Bremerich, Jens (Department of Radiology, University Hospital Basel, University of Basel, Basel, Switzerland); Sommer, Gregor (Department of Radiology, University Hospital Basel, University of Basel, Basel, Switzerland); Abdulkadir, Ahmed (University Hospital of Old Age Psychiatry and Psychotherapy, University of Bern, Bern, Switzerland; Center for Biomedical Image Computing and Analytics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA)","Anastasopoulos, Constantin (University Hospital of Basel; University of Basel)","Anastasopoulos, Constantin (University Hospital of Basel; University of Basel); Yang, Shan (University Hospital of Basel; University of Basel); Pradella, Maurice (University Hospital of Basel; University of Basel); Akinci D’Antonoli, Tugba (University Hospital of Basel; University of Basel; University of Basel; University Children’s Hospital Basel); Knecht, Sven (University Hospital of Basel; University of Basel); Cyriac, Joshy (University Hospital of Basel; University of Basel); Reisert, Marco (University Medical Center Freiburg); Kellner, Elias (University Medical Center Freiburg); Achermann, Rita (University Hospital of Basel; University of Basel); Haaf, Philip (University Hospital of Basel; University of Basel); Stieltjes, Bram (University Hospital of Basel; University of Basel; University Hospital of Basel; University of Basel); Sauter, Alexander W. (University Hospital of Basel; University of Basel); Bremerich, Jens (University Hospital of Basel; University of Basel); Sommer, Gregor (University Hospital of Basel; University of Basel); Abdulkadir, Ahmed (University of Bern; University of Pennsylvania; University of Pennsylvania Health System)",4,4,0.59,3.96,https://doi.org/10.1186/s12968-021-00791-8,https://app.dimensions.ai/details/publication/pub.1142513674,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
1344,pub.1142498670,10.48550/arxiv.2111.05055,,,MAC-ReconNet: A Multiple Acquisition Context based Convolutional Neural  Network for MR Image Reconstruction using Dynamic Weight Prediction,"Convolutional Neural network-based MR reconstruction methods have shown to
provide fast and high quality reconstructions. A primary drawback with a
CNN-based model is that it lacks flexibility and can effectively operate only
for a specific acquisition context limiting practical applicability. By
acquisition context, we mean a specific combination of three input settings
considered namely, the anatomy under study, undersampling mask pattern and
acceleration factor for undersampling. The model could be trained jointly on
images combining multiple contexts. However the model does not meet the
performance of context specific models nor extensible to contexts unseen at
train time. This necessitates a modification to the existing architecture in
generating context specific weights so as to incorporate flexibility to
multiple contexts. We propose a multiple acquisition context based network,
called MAC-ReconNet for MRI reconstruction, flexible to multiple acquisition
contexts and generalizable to unseen contexts for applicability in real
scenarios. The proposed network has an MRI reconstruction module and a dynamic
weight prediction (DWP) module. The DWP module takes the corresponding
acquisition context information as input and learns the context-specific
weights of the reconstruction module which changes dynamically with context at
run time. We show that the proposed approach can handle multiple contexts based
on cardiac and brain datasets, Gaussian and Cartesian undersampling patterns
and five acceleration factors. The proposed network outperforms the naive
jointly trained model and gives competitive results with the context-specific
models both quantitatively and qualitatively. We also demonstrate the
generalizability of our model by testing on contexts unseen at train time.",,,arXiv,,,2021-11-09,2021,,,,,,All OA, Green,Preprint,"Ramanarayanan, Sriprabha; Murugesan, Balamurali; Ram, Keerthi; Sivaprakasam, Mohanasankar","Ramanarayanan, Sriprabha (); Murugesan, Balamurali (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",,"Ramanarayanan, Sriprabha (); Murugesan, Balamurali (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142498670,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5074,pub.1142421314,10.3389/fphys.2021.745349,34819872,PMC8606551,Combined In-silico and Machine Learning Approaches Toward Predicting Arrhythmic Risk in Post-infarction Patients,"Background: Remodeling due to myocardial infarction (MI) significantly increases patient arrhythmic risk. Simulations using patient-specific models have shown promise in predicting personalized risk for arrhythmia. However, these are computationally- and time- intensive, hindering translation to clinical practice. Classical machine learning (ML) algorithms (such as K-nearest neighbors, Gaussian support vector machines, and decision trees) as well as neural network techniques, shown to increase prediction accuracy, can be used to predict occurrence of arrhythmia as predicted by simulations based solely on infarct and ventricular geometry. We present an initial combined image-based patient-specific in silico and machine learning methodology to assess risk for dangerous arrhythmia in post-infarct patients. Furthermore, we aim to demonstrate that simulation-supported data augmentation improves prediction models, combining patient data, computational simulation, and advanced statistical modeling, improving overall accuracy for arrhythmia risk assessment. Methods: MRI-based computational models were constructed from 30 patients 5 days post-MI (the ""baseline"" population). In order to assess the utility biophysical model-supported data augmentation for improving arrhythmia prediction, we augmented the virtual baseline patient population. Each patient ventricular and ischemic geometry in the baseline population was used to create a subfamily of geometric models, resulting in an expanded set of patient models (the ""augmented"" population). Arrhythmia induction was attempted via programmed stimulation at 17 sites for each virtual patient corresponding to AHA LV segments and simulation outcome, ""arrhythmia,"" or ""no-arrhythmia,"" were used as ground truth for subsequent statistical prediction (machine learning, ML) models. For each patient geometric model, we measured and used choice data features: the myocardial volume and ischemic volume, as well as the segment-specific myocardial volume and ischemia percentage, as input to ML algorithms. For classical ML techniques (ML), we trained k-nearest neighbors, support vector machine, logistic regression, xgboost, and decision tree models to predict the simulation outcome from these geometric features alone. To explore neural network ML techniques, we trained both a three - and a four-hidden layer multilayer perceptron feed forward neural networks (NN), again predicting simulation outcomes from these geometric features alone. ML and NN models were trained on 70% of randomly selected segments and the remaining 30% was used for validation for both baseline and augmented populations. Results: Stimulation in the baseline population (30 patient models) resulted in reentry in 21.8% of sites tested; in the augmented population (129 total patient models) reentry occurred in 13.0% of sites tested. ML and NN models ranged in mean accuracy from 0.83 to 0.86 for the baseline population, improving to 0.88 to 0.89 in all cases. Conclusion: Machine learning techniques, combined with patient-specific, image-based computational simulations, can provide key clinical insights with high accuracy rapidly and efficiently. In the case of sparse or missing patient data, simulation-supported data augmentation can be employed to further improve predictive results for patient benefit. This work paves the way for using data-driven simulations for prediction of dangerous arrhythmia in MI patients.",The simulations were performed on resources provided by UNINETT Sigma2 - the National Infrastructure for High Performance Computing and Data Storage in Norway.,"HA and MM Simula Research Laboratory, Ministry of Research and Education of Norway, NO. LM and JU Research Council of Norway (303178), European, and/or other funding source. ProCardio Norwegian Center for Research-Based Innovation, Research Council of Norway, NO. MI-RISK Novo Nordisk Interdisciplinary Synergy Grant, Novo Nordisk Fond, DK.",Frontiers in Physiology,,,2021-11-08,2021,2021-11-08,,12,,745349,All OA, Gold,Article,"Maleckar, Mary M.; Myklebust, Lena; Uv, Julie; Florvaag, Per Magne; Strøm, Vilde; Glinge, Charlotte; Jabbari, Reza; Vejlstrup, Niels; Engstrøm, Thomas; Ahtarovski, Kiril; Jespersen, Thomas; Tfelt-Hansen, Jacob; Naumova, Valeriya; Arevalo, Hermenegild","Maleckar, Mary M. (Computational Physiology, Simula Research Laboratory, Oslo, Norway); Myklebust, Lena (Computational Physiology, Simula Research Laboratory, Oslo, Norway); Uv, Julie (Computational Physiology, Simula Research Laboratory, Oslo, Norway); Florvaag, Per Magne (Computational Physiology, Simula Research Laboratory, Oslo, Norway); Strøm, Vilde (Computational Physiology, Simula Research Laboratory, Oslo, Norway); Glinge, Charlotte (Department of Cardiology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, Denmark); Jabbari, Reza (Department of Cardiology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, Denmark); Vejlstrup, Niels (Department of Cardiology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, Denmark); Engstrøm, Thomas (Department of Cardiology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, Denmark); Ahtarovski, Kiril (Department of Cardiology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, Denmark); Jespersen, Thomas (Department of Biomedical Sciences, University of Copenhagen, Copenhagen, Denmark); Tfelt-Hansen, Jacob (Department of Cardiology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, Denmark; Department of Forensic Medicine, Faculty of Medical Sciences, University of Copenhagen, Copenhagen, Denmark); Naumova, Valeriya (Computational Physiology, Simula Research Laboratory, Oslo, Norway); Arevalo, Hermenegild (Computational Physiology, Simula Research Laboratory, Oslo, Norway)","Maleckar, Mary M. (Simula Research Laboratory)","Maleckar, Mary M. (Simula Research Laboratory); Myklebust, Lena (Simula Research Laboratory); Uv, Julie (Simula Research Laboratory); Florvaag, Per Magne (Simula Research Laboratory); Strøm, Vilde (Simula Research Laboratory); Glinge, Charlotte (Rigshospitalet); Jabbari, Reza (Rigshospitalet); Vejlstrup, Niels (Rigshospitalet); Engstrøm, Thomas (Rigshospitalet); Ahtarovski, Kiril (Rigshospitalet); Jespersen, Thomas (University of Copenhagen); Tfelt-Hansen, Jacob (Rigshospitalet; University of Copenhagen); Naumova, Valeriya (Simula Research Laboratory); Arevalo, Hermenegild (Simula Research Laboratory)",3,3,0.27,1.52,https://www.frontiersin.org/articles/10.3389/fphys.2021.745349/pdf,https://app.dimensions.ai/details/publication/pub.1142421314,31 Biological Sciences, 3101 Biochemistry and Cell Biology, 32 Biomedical and Clinical Sciences, 3208 Medical Physiology,,,,,,,,
5690,pub.1140556744,10.1109/jbhi.2021.3106341,34415840,PMC8843066,Exploiting Shared Knowledge From Non-COVID Lesions for Annotation-Efficient COVID-19 CT Lung Infection Segmentation,"The novel Coronavirus disease (COVID-19) is a highly contagious virus and has spread all over the world, posing an extremely serious threat to all countries. Automatic lung infection segmentation from computed tomography (CT) plays an important role in the quantitative analysis of COVID-19. However, the major challenge lies in the inadequacy of annotated COVID-19 datasets. Currently, there are several public non-COVID lung lesion segmentation datasets, providing the potential for generalizing useful information to the related COVID-19 segmentation task. In this paper, we propose a novel relation-driven collaborative learning model to exploit shared knowledge from non-COVID lesions for annotation-efficient COVID-19 CT lung infection segmentation. The model consists of a general encoder to capture general lung lesion features based on multiple non-COVID lesions, and a target encoder to focus on task-specific features based on COVID-19 infections. We develop a collaborative learning scheme to regularize feature-level relation consistency of given input and encourage the model to learn more general and discriminative representation of COVID-19 infections. Extensive experiments demonstrate that trained with limited COVID-19 data, exploiting shared knowledge from non-COVID lesions can further improve state-of-the-art performance with up to 3.0% in dice similarity coefficient and 4.2% in normalized surface dice. In addition, experimental results on large scale 2D dataset with CT slices show that our method significantly outperforms cutting-edge segmentation methods metrics. Our method promotes new insights into annotation-efficient deep learning and illustrates strong potential for real-world applications in the global fight against COVID-19 in the absence of sufficient high-quality annotations.","This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFF0201002, in part by the University Synergy Innovation Program of Anhui Province under Grant GXXT-2019-044, and in part by the National Natural Science Foundation of China under Grant 61301005.","This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFF0201002, in part by the University Synergy Innovation Program of Anhui Province under Grant GXXT-2019-044, and in part by the National Natural Science Foundation of China under Grant 61301005.",IEEE Journal of Biomedical and Health Informatics,,"Benchmarking; COVID-19; Humans; Lung; SARS-CoV-2; Tomography, X-Ray Computed",2021-11-05,2021,2021-11-05,2021-11,25,11,4152-4162,All OA, Bronze,Article,"Zhang, Yichi; Liao, Qingcheng; Yuan, Lin; Zhu, He; Xing, Jiezhen; Zhang, Jicong","Zhang, Yichi (School of Biological Science and Medical Engineering, Beihang University, Beijing, 100191, China); Liao, Qingcheng (School of Biological Science and Medical Engineering, Beihang University, Beijing, 100191, China); Yuan, Lin (College of Biomedical Engineering, Taiyuan University of Technology, Taiyuan, 030600, China); Zhu, He (School of Computer Science and Engineering, Beihang University, Beijing, 100191, China); Xing, Jiezhen (School of Biological Science and Medical Engineering, Beihang University, Beijing, 100191, China); Zhang, Jicong (School of Biological Science and Medical Engineering, Beihang University, Beijing, 100083, China; Hefei Innovation Research Institute, Beihang University, Hefei, 230013, China; Beijing Advanced Innovation Centre for Biomedical Engineering, Beijing, 102402, China; Beijing Advanced Innovation Centre for Big Data-Based Precision Medicine, Beijing, 100191, China)","Zhang, Jicong (Beihang University; Beihang University; ; )","Zhang, Yichi (Beihang University); Liao, Qingcheng (Beihang University); Yuan, Lin (Taiyuan University of Technology); Zhu, He (Beihang University); Xing, Jiezhen (Beihang University); Zhang, Jicong (Beihang University; Beihang University)",13,13,1.56,10.64,https://ieeexplore.ieee.org/ielx7/6221020/9605141/09520286.pdf,https://app.dimensions.ai/details/publication/pub.1140556744,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1066,pub.1142363292,10.48550/arxiv.2111.01590,,,Detect-and-Segment: a Deep Learning Approach to Automate Wound Image  Segmentation,"Chronic wounds significantly impact quality of life. If not properly managed,
they can severely deteriorate. Image-based wound analysis could aid in
objectively assessing the wound status by quantifying important features that
are related to healing. However, the high heterogeneity of the wound types,
image background composition, and capturing conditions challenge the robust
segmentation of wound images. We present Detect-and-Segment (DS), a deep
learning approach to produce wound segmentation maps with high generalization
capabilities. In our approach, dedicated deep neural networks detected the
wound position, isolated the wound from the uninformative background, and
computed the wound segmentation map. We evaluated this approach using one data
set with images of diabetic foot ulcers. For further testing, 4 supplemental
independent data sets with larger variety of wound types from different body
locations were used. The Matthews' correlation coefficient (MCC) improved from
0.29 when computing the segmentation on the full image to 0.85 when combining
detection and segmentation in the same approach. When tested on the wound
images drawn from the supplemental data sets, the DS approach increased the
mean MCC from 0.17 to 0.85. Furthermore, the DS approach enabled the training
of segmentation models with up to 90% less training data while maintaining the
segmentation performance.",,,arXiv,,,2021-11-02,2021,,,,,,All OA, Green,Preprint,"Scebba, Gaetano; Zhang, Jia; Catanzaro, Sabrina; Mihai, Carina; Distler, Oliver; Berli, Martin; Karlen, Walter","Scebba, Gaetano (); Zhang, Jia (); Catanzaro, Sabrina (); Mihai, Carina (); Distler, Oliver (); Berli, Martin (); Karlen, Walter ()",,"Scebba, Gaetano (); Zhang, Jia (); Catanzaro, Sabrina (); Mihai, Carina (); Distler, Oliver (); Berli, Martin (); Karlen, Walter ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142363292,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
7759,pub.1143755606,10.1109/embc46164.2021.9630115,34892386,,Cardiac Disease Representation Conditioned by Spatio-temporal Priors in Cine-MRI Sequences Using Generative Embedding Vectors,"Cardiac cine-MRI is one of the most important diagnostic tools for characterizing heart-related pathologies. This imaging technique allows clinicians to assess the morphology and physiology of the heart during the cardiac cycle. Nonetheless, the analysis on cardiac cine-MRI is highly dependent on the observer expertise and a high inter-reader variability is frequently observed. Alternatively, the ejection fraction, a quantitative heart dynamic measure, is used to identify potential cardiac diseases. Unfortunately, this type of measurement is insufficient to distinguish among different cardiac pathologies. This quantification does not exploit all the heart functional information conveyed by cine-MRI sequences. Automatic image analysis might help to identify visual patterns associated with cardiac diseases in the cine-MRI sequences and highlight potential biomarkers. This paper introduces a conditional generative adversarial network that learns a mapping between the latent space and a generated cine-MRI data distribution involving information from five different cardiac pathologies. This net is guided from the left ventricle segmentation and the velocity field that is computed as prior information to focus on the deep representation of salient cardiac patterns. Once the deep neural networks are trained, a set of validation cine-MRI slices is represented in the embedding space. The associated embedding descriptor, in the latent space, is found by minimizing a reconstruction error in the generator output. We evaluated the obtained embedded representation as a disease marker by using different classification models in 16000 pathological cine-MRI slices. The representation retrieved by using the best conditional generative model configuration was used on the classifier models yielding an average accuracy of 90.04% and an average F1-score of 89.97% in the classification task.Clinical relevance-Construction of a topological embedding space, from generative representation, that fully exploits hidden relationships of cine-MRI and represent cardiac diseases.","The authors acknowledge the Vicerrectoriá de Investigatión y Extensión (VIE) of the Universidad Industrial de Santander for supporting this research work by the project: &quot;Predictión de patologías cardíacas utilizando representa-ciones de aprendizaje profundo en secuencias de resonancia magnética cardíaca (CMR), with SIVIE code 2703. The authors acknowledge the Vicerrectoriá de Investigatión y Extensión (VIE) of the Universidad Industrial de Santander for supporting this research work by the project: &quot;Predictión de patologías cardíacas utilizando representa-ciones de aprendizaje profundo en secuencias de resonancia magnética cardíaca (CMR), with SIVIE code 2703.",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Heart; Heart Diseases; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine",2021-11,2021,,2021-11,0,,5570-5573,Closed,Proceeding,"Peña, Henry; Gómez, Santiago; Romo-Bucheli, David; Martinez, Fabio","Peña, Henry (Biomedical Imaging, Vision and Learning Laboratory (BivL, 2, ab), Universidad Industrial de Santander (UIS), COLOMBIA); Gómez, Santiago (Biomedical Imaging, Vision and Learning Laboratory (BivL, 2, ab), Universidad Industrial de Santander (UIS), COLOMBIA); Romo-Bucheli, David (Biomedical Imaging, Vision and Learning Laboratory (BivL, 2, ab), Universidad Industrial de Santander (UIS), COLOMBIA); Martinez, Fabio (Biomedical Imaging, Vision and Learning Laboratory (BivL, 2, ab), Universidad Industrial de Santander (UIS), COLOMBIA)","Peña, Henry ","Peña, Henry (); Gómez, Santiago (); Romo-Bucheli, David (); Martinez, Fabio ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1143755606,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
7743,pub.1143755261,10.1109/embc46164.2021.9629770,34892002,,Segmentation of Cardiac Structures via Successive Subspace Learning with Saab Transform from Cine MRI,"Assessment of cardiovascular disease (CVD) with cine magnetic resonance imaging (MRI) has been used to non-invasively evaluate detailed cardiac structure and function. Accurate segmentation of cardiac structures from cine MRI is a crucial step for early diagnosis and prognosis of CVD, and has been greatly improved with convolutional neural networks (CNN). There, however, are a number of limitations identified in CNN models, such as limited interpretability and high complexity, thus limiting their use in clinical practice. In this work, to address the limitations, we propose a lightweight and interpretable machine learning model, successive subspace learning with the subspace approximation with adjusted bias (Saab) transform, for accurate and efficient segmentation from cine MRI. Specifically, our segmentation framework is comprised of the following steps: (1) sequential expansion of near-to-far neighborhood at different resolutions; (2) channel-wise subspace approximation using the Saab transform for unsupervised dimension reduction; (3) class-wise entropy guided feature selection for supervised dimension reduction; (4) concatenation of features and pixel-wise classification with gradient boost; and (5) conditional random field for post-processing. Experimental results on the ACDC 2017 segmentation database, showed that our framework performed better than state-of-the-art U-Net models with 200× fewer parameters in delineating the left ventricle, right ventricle, and myocardium, thus showing its potential to be used in clinical practice.Clinical relevance- Delineation of the left ventricular cavity, myocardium, and right ventricle from cardiac MR images is a common clinical task to establish diagnosis and prognosis of CVD.",,,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Heart; Heart Ventricles; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2021-11,2021,,2021-11,0,,3535-3538,All OA, Green,Proceeding,"Liu, Xiaofeng; Xing, Fangxu; Gaggin, Hanna K.; Wang, Weichung; Kuo, C.-C. Jay; Fakhri, Georges El; Woo, Jonghye","Liu, Xiaofeng (Gordon Center for Medical Imaging, Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA); Xing, Fangxu (Gordon Center for Medical Imaging, Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA); Gaggin, Hanna K. (Division of Cardiology, Corrigan Minehan Heart Center, Dept. of Medicine, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA); Wang, Weichung (Institute of Applied Mathematical Sciences, National Taiwan University, Taipei, Taiwan); Kuo, C.-C. Jay (Dept. of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA); Fakhri, Georges El (Gordon Center for Medical Imaging, Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA); Woo, Jonghye (Gordon Center for Medical Imaging, Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA)","Liu, Xiaofeng (Harvard University; Massachusetts General Hospital)","Liu, Xiaofeng (Harvard University; Massachusetts General Hospital); Xing, Fangxu (Harvard University; Massachusetts General Hospital); Gaggin, Hanna K. (Harvard University; Massachusetts General Hospital); Wang, Weichung (National Taiwan University); Kuo, C.-C. Jay (University of Southern California); Fakhri, Georges El (Harvard University; Massachusetts General Hospital); Woo, Jonghye (Harvard University; Massachusetts General Hospital)",5,5,1.32,3.98,http://arxiv.org/pdf/2107.10718,https://app.dimensions.ai/details/publication/pub.1143755261,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,
7581,pub.1143755826,10.1109/embc46164.2021.9630335,34891958,,3D Attention M-net for Short-axis Left Ventricular Myocardium Segmentation in Mice MR cardiac Images,"Small rodent cardiac magnetic resonance imaging (MRI) plays an important role in preclinical models of cardiac disease. Accurate myocardial boundaries delineation is crucial to most morphological and functional analysis in rodent cardiac MRIs. However, rodent cardiac MRIs, due to animal's small cardiac volume and high heart rate, are usually acquired with sub-optimal resolution and low signal-to-noise ratio (SNR). These rodent cardiac MRIs can also suffer from signal loss due to the intra-voxel dephasing. These factors make automatic myocardial segmentation challenging. Manual contouring could be applied to label myocardial boundaries but it is usually laborious, time consuming, and not systematically objective. In this study, we present a deep learning approach based on 3D attention M-net to perform automatic segmentation of left ventricular myocardium. In the deep learning architecture, we use dual spatial-channel attention gates between encoder and decoder along with multi-scale feature fusion path after decoder. Attention gates enable networks to focus on relevant spatial information and channel features to improve segmentation performance. A distance derived loss term, besides general dice loss and binary cross entropy loss, was also introduced to our hybrid loss functions to refine segmentation contours. The proposed model outperforms other generic models, like U-Net and FCN, in major segmentation metrics including the dice score (0.9072), Jaccard index (0.8307) and Hausdorff distance (3.1754 pixels), which are comparable to the results achieved by state-of-the-art models on human cardiac ACDC17 datasets.Clinical relevance Small rodent cardiac MRI is routinely used to probe the effect of individual genes or groups of genes on the etiology of a large number of cardiovascular diseases. An automatic myocardium segmentation algorithm specifically designed for these data can enhance accuracy and reproducibility of cardiac structure and function analysis.","This work was supported by several grants from the National Institutes of Health (HL130292, HL61912, HL63030)",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),Animals, Attention, Heart Ventricles, Magnetic Resonance Imaging, Mice, Myocardium, Reproducibility of Results,2021-11,2021,,2021-11,0,,3353-3357,All OA, Bronze,Proceeding,"Huang, Luojie; Jin, Andrew; Wei, Jinchi; Tipre, Dnyanesh; Liu, Chin-Fu; Weiss, Robert G.; Ardekani, Siamak","Huang, Luojie (The Center for Imaging Science, Johns Hopkins University, Baltimore, MD, 21218, USA); Jin, Andrew (The Center for Imaging Science, Johns Hopkins University, Baltimore, MD, 21218, USA); Wei, Jinchi (The Center for Imaging Science, Johns Hopkins University, Baltimore, MD, 21218, USA); Tipre, Dnyanesh (The Center for Imaging Science, Johns Hopkins University, Baltimore, MD, 21218, USA); Liu, Chin-Fu (The Center for Imaging Science, Johns Hopkins University, Baltimore, MD, 21218, USA); Weiss, Robert G. (The Department of Medicine, Section of Cardiology, Johns Hopkins Medical Institutions, Baltimore, MD, 21218, USA); Ardekani, Siamak (The Center for Imaging Science, Johns Hopkins University, Baltimore, MD, 21218, USA)","Ardekani, Siamak (Johns Hopkins University)","Huang, Luojie (Johns Hopkins University); Jin, Andrew (Johns Hopkins University); Wei, Jinchi (Johns Hopkins University); Tipre, Dnyanesh (Johns Hopkins University); Liu, Chin-Fu (Johns Hopkins University); Weiss, Robert G. (Johns Hopkins University); Ardekani, Siamak (Johns Hopkins University)",0,0,,0.0,https://ieeexplore.ieee.org/ielx7/9629355/9629471/09630335.pdf,https://app.dimensions.ai/details/publication/pub.1143755826,40 Engineering, 4003 Biomedical Engineering,,,,
7576,pub.1143756077,10.1109/embc46164.2021.9630586,34892062,PMC9137928,Motion Extraction of the Right Ventricle from 4D Cardiac Cine MRI Using A Deep Learning-Based Deformable Registration Framework,"Cardiac Cine Magnetic Resonance (CMR) Imaging has made a significant paradigm shift in medical imaging technology, thanks to its capability of acquiring high spatial and temporal resolution images of different structures within the heart that can be used for reconstructing patient-specific ventricular computational models. In this work, we describe the development of dynamic patient-specific right ventricle (RV) models associated with normal subjects and abnormal RV patients to be subsequently used to assess RV function based on motion and kinematic analysis. We first constructed static RV models using segmentation masks of cardiac chambers generated from our accurate, memory-efficient deep neural architecture - CondenseUNet - featuring both a learned group structure and a regularized weight-pruner to estimate the motion of the right ventricle. In our study, we use a deep learning-based deformable network that takes 3D input volumes and outputs a motion field which is then used to generate isosurface meshes of the cardiac geometry at all cardiac frames by propagating the end-diastole (ED) isosurface mesh using the reconstructed motion field. The proposed model was trained and tested on the Automated Cardiac Diagnosis Challenge (ACDC) dataset featuring 150 cine cardiac MRI patient datasets. The isosurface meshes generated using the proposed pipeline were compared to those obtained using motion propagation via traditional non-rigid registration based on several performance metrics, including Dice score and mean absolute distance (MAD).","This work was supported by grants from the National Science Foundation (Award No. OAC 1808530, OAC 1808553 &amp; CCF 1717894) and the National Institutes of Health (Award No. R35GM128877). This work was supported by grants from the National Science Foundation (Award No. OAC 1808530, OAC 1808553 &amp; CCF 1717894) and the National Institutes of Health (Award No. R35GM128877).",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Deep Learning; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2021-11,2021,,2021-11,0,,3795-3799,Closed,Proceeding,"Upendra, Roshan Reddy; Hasan, S. M. Kamrul; Simon, Richard; Wentz, Brian Jamison; Shontz, Suzanne M.; Sacks, Michael S.; Linte, Cristian A.","Upendra, Roshan Reddy (Chester F. Carlson Center for Imaging Science); Hasan, S. M. Kamrul (Chester F. Carlson Center for Imaging Science); Simon, Richard (Department of Biomedical Engineering, Rochester Institute of Technology, Rochester, NY); Wentz, Brian Jamison (Bioengineering Graduate Program; Information and Telecommunication Technology Center, University of Kansas, Lawrence, KS); Shontz, Suzanne M. (Bioengineering Graduate Program; Electrical Engineering and Computer Science; Information and Telecommunication Technology Center, University of Kansas, Lawrence, KS); Sacks, Michael S. (Department of Biomedical Engineering, Center for Cardiovascular Modeling and Simulation, The Oden Institute for Computational Engineering and Sciences, University of Texas at Austin, Austin, TX); Linte, Cristian A. (Chester F. Carlson Center for Imaging Science; Department of Biomedical Engineering, Rochester Institute of Technology, Rochester, NY)","Upendra, Roshan Reddy ","Upendra, Roshan Reddy (); Hasan, S. M. Kamrul (); Simon, Richard (Rochester Institute of Technology); Wentz, Brian Jamison (University of Kansas); Shontz, Suzanne M. (University of Kansas); Sacks, Michael S. (The University of Texas at Austin); Linte, Cristian A. (Rochester Institute of Technology)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1143756077,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,,
1654,pub.1146259908,10.1109/acait53529.2021.9731304,,,Automatic Cardiomyopathy Diagnosis with a Cost-sensitive Ensemble Classifier,"This paper proposed a cost-sensitive ensemble classifier for automatic cardiomyopathy diagnosis using features extracted from cardiac magnetic resonance images. However, with numerous features extracted from images, it is hard for a single classifier to achieve accurate prediction. In contrast, an ensemble classifier combines multiple weak classifiers which could benefit from each others and improve the performance. Therefore, we proposed a cost-sensitive ensemble classifier assembling five heterogeneous classifiers: logistic regression (LR), Gaussian naive bayes (GNB), support vector machine (SVM), multi-layer perception(MLP), and convolutional neural network(CNN). The weight of each classifier was determined according to the special cost-sensitive function. In the experiment, the proposed method was evaluated on a publicly available Automated Cardiac Diagnosis Challenge (ACDC) dataset [1], where the proposed ensemble classifier achieves a considerable improvement.","This work is supported by National Natural Science Foundation of China (No. 62076247, 61701506), and Clinical Research Talents Program (No. 2018XLC3023).","This work is supported by National Natural Science Foundation of China (No. 62076247, 61701506), and Clinical Research Talents Program (No. 2018XLC3023).",,2021 5th Asian Conference on Artificial Intelligence Technology (ACAIT),,2021-10-31,2021,,2021-10-31,0,,775-779,Closed,Proceeding,"Ye, Qiwei; Qiao, Linbo; Chen, Hongyi; Tao, Qian; Xiao, Jingjing","Ye, Qiwei (College of Computer, National University of Defense Technology, Changsha, 410073, China); Qiao, Linbo (College of Computer, National University of Defense Technology, Changsha, 410073, China); Chen, Hongyi (Information Center, National University of Defense Technology, Changsha, 410073, China); Tao, Qian (Department of Medical Engineering, The Second Affiliated Hospital of the Army Medical University, Chongqing, 400037, China); Xiao, Jingjing (Department of Medical Engineering, The Second Affiliated Hospital of the Army Medical University, Chongqing, 400037, China)","Ye, Qiwei (National University of Defense Technology)","Ye, Qiwei (National University of Defense Technology); Qiao, Linbo (National University of Defense Technology); Chen, Hongyi (National University of Defense Technology); Tao, Qian (Army Medical University); Xiao, Jingjing (Army Medical University)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1146259908,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1617,pub.1142288246,10.1007/978-3-030-89128-2_14,,,U-Shaped Densely Connected Convolutions for Left Ventricle Segmentation from CMR Images,"Segmentation of cardiac magnetic resonance images (cMRI) remains a challenging task in the field of scientific research due to its significance in the medical assessment of cardiovascular diseases. Ensuring accurate segmentation of the heart structures, mainly the left ventricle cavity, serves to extract important information and has a major impact on the quantitative analysis of the heart function which helps to conduct the proper diagnosis of doctors. The present paper introduces a simple and efficient U-shaped convolutional neural network aiming to accurately segment the LV from cMR images. We applied our architecture for Left Ventricle (LV) segmentation on cardiac MR images (cMRI), from the Automated Cardiac Diagnosis Challenge (ACDC). Obtained results are promising. This simple model based on CNN has significantly fewer parameters rendering it less demanding in terms of computation. Nevertheless, it has provided accurate segmentation. The tested method achieved LV Dice scores of 0.958 at end-systolic time (ES) and 0.979 at end-diastolic time (ED), which yields a mean Dice score of 0.968 on the ACDC dataset.",,,Lecture Notes in Computer Science,Computer Analysis of Images and Patterns,,2021-10-31,2021,2021-10-31,2021,13052,,145-153,Closed,Chapter,"Boukhris, Khouloud; Mahmoudi, Ramzi; Abdallah, Asma Ben; AbdelAli, Mabrouk; Hmida, Badii; Bedoui, Mohamed Hédi","Boukhris, Khouloud (Faculty of Sciences Monastir, University of Monastir, Monastir, Tunisia; Faculty of Medicine Monastir, Medical Imaging Technology Lab – LTIM-LR12ES06, University of Monastir, Monastir, Tunisia); Mahmoudi, Ramzi (Faculty of Medicine Monastir, Medical Imaging Technology Lab – LTIM-LR12ES06, University of Monastir, Monastir, Tunisia; Gaspard-Monge Computer-Science Laboratory, Paris-Est University, Mixed Unit CNRS-UMLV-ESIEE UMR8049, BP99, ESIEE Paris City Descartes, 93162, Noisy Le Grand, France); Abdallah, Asma Ben (Faculty of Medicine Monastir, Medical Imaging Technology Lab – LTIM-LR12ES06, University of Monastir, Monastir, Tunisia); AbdelAli, Mabrouk (Radiology Service- UR12SP40 CHU Fattouma Bourguiba, 5019, Monastir, Tunisia); Hmida, Badii (Radiology Service- UR12SP40 CHU Fattouma Bourguiba, 5019, Monastir, Tunisia); Bedoui, Mohamed Hédi (Faculty of Medicine Monastir, Medical Imaging Technology Lab – LTIM-LR12ES06, University of Monastir, Monastir, Tunisia)","Boukhris, Khouloud (University of Monastir; University of Monastir)","Boukhris, Khouloud (University of Monastir; University of Monastir); Mahmoudi, Ramzi (University of Monastir); Abdallah, Asma Ben (University of Monastir); AbdelAli, Mabrouk (Hospital Fatuma Bourguiba Monastir); Hmida, Badii (Hospital Fatuma Bourguiba Monastir); Bedoui, Mohamed Hédi (University of Monastir)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1142288246,46 Information and Computing Sciences,,,,,,,,,,,,
5672,pub.1141963175,10.1002/mp.15285,34658035,,Integrating multiple MRI sequences for pelvic organs segmentation via the attention mechanism,"PURPOSE: To create a network which fully utilizes multi-sequence MRI and compares favorably with manual human contouring.
METHODS: We retrospectively collected 89 MRI studies of the pelvic cavity from patients with prostate cancer and cervical cancer. The dataset contained 89 samples from 87 patients with a total of 84 valid samples. MRI was performed with T1-weighted (T1), T2-weighted (T2), and Enhanced Dixon T1-weighted (T1DIXONC) sequences. There were two cohorts. The training cohort contained 55 samples and the testing cohort contained 29 samples. The MRI images in the training cohort contained contouring data from radiotherapist α. The MRI images in the testing cohort contained contouring data from radiotherapist α and contouring data from another radiotherapist: radiotherapist β. The training cohort was used to optimize the convolution neural networks, which included the attention mechanism through the proposed activation module and the blended module into multiple MRI sequences, to perform autodelineation. The testing cohort was used to assess the networks' autodelineation performance. The contoured organs at risk (OAR) were the anal canal, bladder, rectum, femoral head (L), and femoral head (R).
RESULTS: We compared our proposed network with UNet and FuseUNet using our dataset. When T1 was the main sequence, we input three sequences to segment five organs and evaluated the results using four metrics: the DSC (Dice similarity coefficient), the JSC (Jaccard similarity coefficient), the ASD (average mean distance), and the 95% HD (robust Hausdorff distance). The proposed network achieved improved results compared with the baselines among all metrics. The DSC were 0.834±0.029, 0.818±0.037, and 0.808±0.050 for our proposed network, FuseUNet, and UNet, respectively. The 95% HD were 7.256±2.748 mm, 8.404±3.297 mm, and 8.951±4.798 mm for our proposed network, FuseUNet, and UNet, respectively. Our proposed network also had superior performance on the JSC and ASD coefficients.
CONCLUSION: Our proposed activation module and blended module significantly improved the performance of FuseUNet for multi-sequence MRI segmentation. Our proposed network integrated multiple MRI sequences efficiently and autosegmented OAR rapidly and accurately. We also discovered that three-sequence fusion (T1-T1DIXONC-T2) was superior to two-sequence fusion (T1-T2 and T1-T1DIXONC, respectively). We infer that the more MRI sequences fused, the better the automatic segmentation results.","This work was supported by the Youth Innovation Project of Sun Yat‐sen University Cancer Center (PT21020601), the Student&#x27;s Platform for Innovation and Entrepreneurship Training Program (S202113902030 and 202113902116), the Cancer Precision Radiotherapy Summit Plan of Clinical Scientific Research Public Welfare Project (2021‐DF‐009), the Pearl River S&amp;T Nova Program of Guangzhou (201710010162), and the Natural Science Foundation of Guangdong Province (2017A030310217).",,Medical Physics,,"Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Pelvis; Retrospective Studies",2021-10-29,2021,2021-10-29,2021-12,48,12,7930-7945,Closed,Article,"Huang, Sijuan; Cheng, Zesen; Lai, Lijuan; Zheng, Wanjia; He, Mengxue; Li, Junyun; Zeng, Tianyu; Huang, Xiaoyan; Yang, Xin","Huang, Sijuan (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China); Cheng, Zesen (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, Guangdong, 510641, China); Lai, Lijuan (School of Electronic and Information Engineering, South China University of Technology, Guangzhou, Guangdong, 510641, China); Zheng, Wanjia (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China; Department of Radiation Oncology, Southern Theater Air Force Hospital of the People's Liberation Army, Guangzhou, Guangdong, 510050, China); He, Mengxue (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China); Li, Junyun (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China); Zeng, Tianyu (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, Guangdong, 510641, China); Huang, Xiaoyan (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China); Yang, Xin (Department of Radiation Oncology, Sun Yat‐sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, Guangdong, 510060, China)","Yang, Xin (Sun Yat-sen University; Sun Yat-sen University Cancer Center)","Huang, Sijuan (Sun Yat-sen University; Sun Yat-sen University Cancer Center); Cheng, Zesen (Sun Yat-sen University; Sun Yat-sen University Cancer Center; South China University of Technology); Lai, Lijuan (South China University of Technology); Zheng, Wanjia (Sun Yat-sen University; Sun Yat-sen University Cancer Center); He, Mengxue (Sun Yat-sen University; Sun Yat-sen University Cancer Center); Li, Junyun (Sun Yat-sen University; Sun Yat-sen University Cancer Center); Zeng, Tianyu (Sun Yat-sen University; Sun Yat-sen University Cancer Center; South China University of Technology); Huang, Xiaoyan (Sun Yat-sen University; Sun Yat-sen University Cancer Center); Yang, Xin (Sun Yat-sen University; Sun Yat-sen University Cancer Center)",2,2,0.5,1.37,,https://app.dimensions.ai/details/publication/pub.1141963175,40 Engineering, 4003 Biomedical Engineering, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
4772,pub.1142139405,10.1016/j.mri.2021.10.005,34710558,,Anatomical knowledge based level set segmentation of cardiac ventricles from MRI,"This paper represents a novel level set framework for segmentation of cardiac left ventricle (LV) and right ventricle (RV) from magnetic resonance images based on anatomical structures of the heart. We first propose a level set approach to recover the endocardium and epicardium of LV by using a bi-layer level set (BILLS) formulation, in which the endocardium and epicardium are represented by the 0-level set and k-level set of a level set function. Furthermore, the recovery of LV endocardium and epicardium is achieved by a level set evolution process, called convexity preserving bi-layer level set (CP-BILLS). During the CP-BILLS evolution, the 0-level set and k-level set simultaneously evolve and move toward the true endocardium and epicardium under the guidance of image information and the impact of the convexity preserving mechanism as well. To eliminate the manual selection of the k-level, we develop an algorithm for automatic selection of an optimal k-level. As a result, the obtained endocardial and epicardial contours are convex and consistent with the anatomy of cardiac ventricles. For segmentation of the whole ventricle, we extend this method to the segmentation of RV and myocardium of both left and right ventricles by using a convex shape decomposition (CSD) structure of cardiac ventricles based on anatomical knowledge. Experimental results demonstrate promising performance of our method. Compared with some traditional methods, our method exhibits superior performance in terms of segmentation accuracy and algorithm stability. Our method is comparable with the state-of-the-art deep learning-based method in terms of segmentation accuracy and algorithm stability, but our method has no need for training and the manual segmentation of the training data.",,,Magnetic Resonance Imaging,,Algorithms, Endocardium, Heart Ventricles, Magnetic Resonance Imaging, Pericardium,2021-10-25,2021,2021-10-25,2022-02,86,,135-148,Closed,Article,"Shi, Xue; Li, Chunming","Shi, Xue (University of Electronic Science and Technology of China, Chengdu 611731, China. Electronic address: xueshi@ieee.org.); Li, Chunming (University of Electronic Science and Technology of China, Chengdu 611731, China. Electronic address: cmli@ieee.org.)","Li, Chunming (University of Electronic Science and Technology of China)","Shi, Xue (University of Electronic Science and Technology of China); Li, Chunming (University of Electronic Science and Technology of China)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142139405,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,
4788,pub.1142030751,10.1016/j.media.2021.102273,34731773,,Curriculum learning for improved femur fracture classification: Scheduling data with prior knowledge and uncertainty,"An adequate classification of proximal femur fractures from X-ray images is crucial for the treatment choice and the patients' clinical outcome. We rely on the commonly used AO system, which describes a hierarchical knowledge tree classifying the images into types and subtypes according to the fracture's location and complexity. In this paper, we propose a method for the automatic classification of proximal femur fractures into 3 and 7 AO classes based on a Convolutional Neural Network (CNN). As it is known, CNNs need large and representative datasets with reliable labels, which are hard to collect for the application at hand. In this paper, we design a curriculum learning (CL) approach that improves over the basic CNNs performance under such conditions. Our novel formulation reunites three curriculum strategies: individually weighting training samples, reordering the training set, and sampling subsets of data. The core of these strategies is a scoring function ranking the training samples. We define two novel scoring functions: one from domain-specific prior knowledge and an original self-paced uncertainty score. We perform experiments on a clinical dataset of proximal femur radiographs. The curriculum improves proximal femur fracture classification up to the performance of experienced trauma surgeons. The best curriculum method reorders the training set based on prior knowledge resulting into a classification improvement of 15%. Using the publicly available MNIST dataset, we further discuss and demonstrate the benefits of our unified CL formulation for three controlled and challenging digit recognition scenarios: with limited amounts of data, under class-imbalance, and in the presence of label noise. The code of our work is available at: https://github.com/ameliajimenez/curriculum-learning-prior-uncertainty.",,"This project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No. 713673 and by the Spanish Ministry of Economy [MDM-2015-0502]. A. Jiménez-Sánchez has received financial support through the “la Caixa” Foundation (ID Q5850017D), fellowship code: LCF/BQ/IN17/11620013. D. Mateus has received funding from Nantes Métropole and the European Regional Development, Pays de la Loire, under the Connect Talent scheme. Authors thank NVidia for the donation of a GPU.",Medical Image Analysis,,"Curriculum; Deep Learning; Femur; Humans; Neural Networks, Computer; Uncertainty",2021-10-21,2021,2021-10-21,2022-01,75,,102273,All OA, Green,Article,"Jiménez-Sánchez, Amelia; Mateus, Diana; Kirchhoff, Sonja; Kirchhoff, Chlodwig; Biberthaler, Peter; Navab, Nassir; González Ballester, Miguel A; Piella, Gemma","Jiménez-Sánchez, Amelia (BCN MedTech, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain. Electronic address: amelia.jimenez@upf.edu.); Mateus, Diana (LS2N, UMR CNRS 6004, Ecole Centrale de Nantes, Nantes, France.); Kirchhoff, Sonja (Institute of Clinical Radiology, LMU München, Munich, Germany; Department of Trauma Surgery, Klinikum rechts der Isar, Technische Universität München, Munich, Germany.); Kirchhoff, Chlodwig (Department of Trauma Surgery, Klinikum rechts der Isar, Technische Universität München, Munich, Germany.); Biberthaler, Peter (Department of Trauma Surgery, Klinikum rechts der Isar, Technische Universität München, Munich, Germany.); Navab, Nassir (Computer Aided Medical Procedures, Technische Universität München, Munich, Germany; Johns Hopkins University, Baltimore, USA.); González Ballester, Miguel A (BCN MedTech, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; ICREA, Barcelona, Spain.); Piella, Gemma (BCN MedTech, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain.)","Jiménez-Sánchez, Amelia (Pompeu Fabra University)","Jiménez-Sánchez, Amelia (Pompeu Fabra University); Mateus, Diana (Laboratoire des Sciences du Numérique de Nantes); Kirchhoff, Sonja (Ludwig-Maximilians-Universität München; Technical University of Munich; Rechts der Isar Hospital); Kirchhoff, Chlodwig (Technical University of Munich; Rechts der Isar Hospital); Biberthaler, Peter (Technical University of Munich; Rechts der Isar Hospital); Navab, Nassir (Technical University of Munich; Johns Hopkins University); González Ballester, Miguel A (Pompeu Fabra University; Institució Catalana de Recerca i Estudis Avançats); Piella, Gemma (Pompeu Fabra University)",4,4,,,http://arxiv.org/pdf/2007.16102,https://app.dimensions.ai/details/publication/pub.1142030751,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
5889,pub.1141877580,10.3389/fcvm.2021.742640,34722674,PMC8551568,Deep Learning for Classification and Selection of Cine CMR Images to Achieve Fully Automated Quality-Controlled CMR Analysis From Scanner to Report,"Introduction: Deep learning demonstrates great promise for automated analysis of CMR. However, existing limitations, such as insufficient quality control and selection of target acquisitions from the full CMR exam, are holding back the introduction of deep learning tools in the clinical environment. This study aimed to develop a framework for automated detection and quality-controlled selection of standard cine sequences images from clinical CMR exams, prior to analysis of cardiac function. Materials and Methods: Retrospective study of 3,827 subjects that underwent CMR imaging. We used a total of 119,285 CMR acquisitions, acquired with scanners of different magnetic field strengths and from different vendors (1.5T Siemens and 1.5T and 3.0T Phillips). We developed a framework to select one good acquisition for each conventional cine class. The framework consisted of a first pre-processing step to exclude still acquisitions; two sequential convolutional neural networks (CNN), the first (CNNclass) to classify acquisitions in standard cine views (2/3/4-chamber and short axis), the second (CNNQC) to classify acquisitions according to image quality and orientation; a final algorithm to select one good acquisition of each class. For each CNN component, 7 state-of-the-art architectures were trained for 200 epochs, with cross entropy loss and data augmentation. Data were divided into 80% for training, 10% for validation, and 10% for testing. Results: CNNclass selected cine CMR acquisitions with accuracy ranging from 0.989 to 0.998. Accuracy of CNNQC reached 0.861 for 2-chamber, 0.806 for 3-chamber, and 0.859 for 4-chamber. The complete framework was presented with 379 new full CMR studies, not used for CNN training/validation/testing, and selected one good 2-, 3-, and 4-chamber acquisition from each study with sensitivity to detect erroneous cases of 89.7, 93.2, and 93.9%, respectively. Conclusions: We developed an accurate quality-controlled framework for automated selection of cine acquisitions prior to image analysis. This framework is robust and generalizable as it was developed on multivendor data and could be used at the beginning of a pipeline for automated cine CMR analysis to obtain full automatization from scanner to report.",This research has been conducted using the UK Biobank Resource under Application Number 17806. The authors wish to thank all participants and staff from UK Biobank and GSTFT.,"This work was supported by the Wellcome/EPSRC Center for Medical Engineering at Kings College London (WT203148/Z/16/Z). EP-A was supported by the EPSRC (EP/R005516/1 and EP/P001009/1) and by core funding from the Wellcome/EPSRC Center for Medical Engineering (WT203148/Z/16/Z) and BR was supported by the NIHR Cardiovascular MedTech Co-operative award to the Guy's and St. Thomas' NHS Foundation Trust. This research was funded in whole, or in part, by the Wellcome Trust WT203148/Z/16/Z. For the purpose of open access, the author has applied a CC BY public copyright license to any author accepted manuscript version arising from this submission. The authors acknowledge financial support from the Department of Health through the National Institute for Health Research (NIHR) comprehensive Biomedical Research Center award to Guy's and St. Thomas' NHS Foundation Trust in partnership with King's College London.",Frontiers in Cardiovascular Medicine,,,2021-10-14,2021,2021-10-14,,8,,742640,All OA, Gold,Article,"Vergani, Vittoria; Razavi, Reza; Puyol-Antón, Esther; Ruijsink, Bram","Vergani, Vittoria (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Razavi, Reza (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Adult and Paediatric Cardiology, Guy's and St. Thomas' NHS Foundation Trust, London, United Kingdom); Puyol-Antón, Esther (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Ruijsink, Bram (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Cardiology, Division of Heart and Lungs, University Medical Centre Utrecht, Utrecht, Netherlands)","Vergani, Vittoria (King's College London); Ruijsink, Bram (King's College London; University Medical Center Utrecht)","Vergani, Vittoria (King's College London); Razavi, Reza (King's College London; Guy's and St Thomas' NHS Foundation Trust); Puyol-Antón, Esther (King's College London); Ruijsink, Bram (King's College London; University Medical Center Utrecht)",6,6,0.81,6.77,https://www.frontiersin.org/articles/10.3389/fcvm.2021.742640/pdf,https://app.dimensions.ai/details/publication/pub.1141877580,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
5351,pub.1141876874,10.1016/j.jcmg.2021.08.011,34656471,PMC8917993,AI Based CMR Assessment of Biventricular Function Clinical Significance of Intervendor Variability and Measurement Errors,"OBJECTIVES: The aim of this study was to determine whether left ventricular ejection fraction (LVEF) and right ventricular ejection fraction (RVEF) and left ventricular mass (LVM) measurements made using 3 fully automated deep learning (DL) algorithms are accurate and interchangeable and can be used to classify ventricular function and risk-stratify patients as accurately as an expert.
BACKGROUND: Artificial intelligence is increasingly used to assess cardiac function and LVM from cardiac magnetic resonance images.
METHODS: Two hundred patients were identified from a registry of individuals who underwent vasodilator stress cardiac magnetic resonance. LVEF, LVM, and RVEF were determined using 3 fully automated commercial DL algorithms and by a clinical expert (CLIN) using conventional methodology. Additionally, LVEF values were classified according to clinically important ranges: <35%, 35% to 50%, and ≥50%. Both ejection fraction values and classifications made by the DL ejection fraction approaches were compared against CLIN ejection fraction reference. Receiver-operating characteristic curve analysis was performed to evaluate the ability of CLIN and each of the DL classifications to predict major adverse cardiovascular events.
RESULTS: Excellent correlations were seen for each DL-LVEF compared with CLIN-LVEF (r = 0.83-0.93). Good correlations were present between DL-LVM and CLIN-LVM (r = 0.75-0.85). Modest correlations were observed between DL-RVEF and CLIN-RVEF (r = 0.59-0.68). A >10% error between CLIN and DL ejection fraction was present in 5% to 18% of cases for the left ventricle and 23% to 43% for the right ventricle. LVEF classification agreed with CLIN-LVEF classification in 86%, 80%, and 85% cases for the 3 DL-LVEF approaches. There were no differences among the 4 approaches in associations with major adverse cardiovascular events for LVEF, LVM, and RVEF.
CONCLUSIONS: This study revealed good agreement between automated and expert-derived LVEF and similarly strong associations with outcomes, compared with an expert. However, the ability of these automated measurements to accurately classify left ventricular function for treatment decision remains limited. DL-LVM showed good agreement with CLIN-LVM. DL-RVEF approaches need further refinements.",,,JACC Cardiovascular Imaging,,"Artificial Intelligence; Cardiovascular Diseases; Heart Ventricles; Humans; Predictive Value of Tests; Stroke Volume; Ventricular Function, Left; Ventricular Function, Right",2021-10-13,2021,2021-10-13,2022-03,15,3,413-427,Closed,Article,"Wang, Shuo; Patel, Hena; Miller, Tamari; Ameyaw, Keith; Narang, Akhil; Chauhan, Daksh; Anand, Simran; Anyanwu, Emeka; Besser, Stephanie A; Kawaji, Keigo; Liu, Xing-Peng; Lang, Roberto M; Mor-Avi, Victor; Patel, Amit R","Wang, Shuo (University of Chicago, Chicago, Illinois, USA; Beijing Chao-Yang Hospital, Capital Medical University, Beijing, China.); Patel, Hena (University of Chicago, Chicago, Illinois, USA.); Miller, Tamari (University of Chicago, Chicago, Illinois, USA.); Ameyaw, Keith (University of Chicago, Chicago, Illinois, USA.); Narang, Akhil (University of Chicago, Chicago, Illinois, USA.); Chauhan, Daksh (University of Chicago, Chicago, Illinois, USA.); Anand, Simran (University of Chicago, Chicago, Illinois, USA.); Anyanwu, Emeka (University of Chicago, Chicago, Illinois, USA.); Besser, Stephanie A (University of Chicago, Chicago, Illinois, USA.); Kawaji, Keigo (University of Chicago, Chicago, Illinois, USA; Illinois Institute of Technology, Chicago, Illinois, USA.); Liu, Xing-Peng (Beijing Chao-Yang Hospital, Capital Medical University, Beijing, China.); Lang, Roberto M (University of Chicago, Chicago, Illinois, USA.); Mor-Avi, Victor (University of Chicago, Chicago, Illinois, USA.); Patel, Amit R (University of Chicago, Chicago, Illinois, USA. Electronic address: amitpatel@uchicago.edu.)","Patel, Amit R (University of Chicago)","Wang, Shuo (University of Chicago; Beijing Chao-Yang Hospital); Patel, Hena (University of Chicago); Miller, Tamari (University of Chicago); Ameyaw, Keith (University of Chicago); Narang, Akhil (University of Chicago); Chauhan, Daksh (University of Chicago); Anand, Simran (University of Chicago); Anyanwu, Emeka (University of Chicago); Besser, Stephanie A (University of Chicago); Kawaji, Keigo (University of Chicago; Illinois Institute of Technology); Liu, Xing-Peng (Beijing Chao-Yang Hospital); Lang, Roberto M (University of Chicago); Mor-Avi, Victor (University of Chicago); Patel, Amit R (University of Chicago)",7,7,3.49,6.14,,https://app.dimensions.ai/details/publication/pub.1141876874,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,,
1251,pub.1142332013,10.48550/arxiv.2111.00873,,,Probabilistic prediction of the heave motions of a semi-submersible by a  deep learning problem model,"The real-time motion prediction of a floating offshore platform refers to
forecasting its motions in the following one- or two-wave cycles, which helps
improve the performance of a motion compensation system and provides useful
early warning information. In this study, we extend a deep learning (DL) model,
which could predict the heave and surge motions of a floating semi-submersible
20 to 50 seconds ahead with good accuracy, to quantify its uncertainty of the
predictive time series with the help of the dropout technique. By repeating the
inference several times, it is found that the collection of the predictive time
series is a Gaussian process (GP). The DL model with dropout learned a kernel
inside, and the learning procedure was similar to GP regression. Adding noise
into training data could help the model to learn more robust features from the
training data, thereby leading to a better performance on test data with a wide
noise level range. This study extends the understanding of the DL model to
predict the wave excited motions of an offshore platform.",,,arXiv,,,2021-10-09,2021,,,,,,All OA, Green,Preprint,"Guo, Xiaoxian; Zhang, Xiantao; Tian, Xinliang; Lu, Wenyue; Li, Xin","Guo, Xiaoxian (); Zhang, Xiantao (); Tian, Xinliang (); Lu, Wenyue (); Li, Xin ()",,"Guo, Xiaoxian (); Zhang, Xiantao (); Tian, Xinliang (); Lu, Wenyue (); Li, Xin ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142332013,40 Engineering, 4015 Maritime Engineering, 46 Information and Computing Sciences,,,,,,,,,
1006,pub.1141693369,10.48550/arxiv.2110.02317,,,Cartesian dictionary-based native T1 and T2 mapping of the myocardium,"Purpose: To implement and evaluate a new dictionary-based technique for
native myocardial T1 and T2 mapping using Cartesian sampling. Methods: The
proposed technique (Multimapping) consisted of single-shot Cartesian image
acquisitions in 10 consecutive cardiac cycles, with inversion pulses in cycle 1
and 5, and T2 preparation (TE: 30ms, 50ms and 70ms) in cycles 8-10.
Multimapping was simulated for different T1 and T2, where entries corresponding
to the k-space centers were matched to acquired data. Experiments were
performed in a phantom, 16 healthy subjects and three patients with
cardiovascular disease. Results: Multimapping phantom measurements showed good
agreement with reference values for both T1 and T2, with no discernable
heart-rate dependency for T1 and T2 within the range of myocardium. In vivo
mean T1 in healthy subjects was significantly higher using Multimapping
(T1=1114+/-14ms) compared to the reference (T1=991+/-26ms) (p<0.01). Mean
Multimapping T2 (47.1+/-1.3ms) and T2 spatial variability (5.8+/-1.0ms) was
significantly lower compared to the reference (T2=54.7+/-2.2ms, p<0.001;
spatial variability=8.4+/-2.0ms, p<0.01). Increased T1 and T2 was detected in
all patients using Multimapping. Conclusions: Multimapping allows for
simultaneous native myocardial T1 and T2 mapping with a conventional Cartesian
trajectory, demonstrating promising in vivo image quality and parameter
quantification results.",,,arXiv,,,2021-10-05,2021,,,,,,All OA, Green,Preprint,"Henningsson, Markus","Henningsson, Markus ()",,"Henningsson, Markus ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1141693369,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
5350,pub.1141602692,10.1016/j.cjca.2021.09.030,34619340,,The Evolving Role of Artificial Intelligence in Cardiac Image Analysis,"Research in artificial intelligence (AI) has progressed over the past decade. The field of cardiac imaging has seen significant developments using newly developed deep learning methods for automated image analysis and AI tools for disease detection and prognostication. This review is aimed at those without special background in AI. We review AI concepts and survey the growing contemporary applications of AI for image analysis in echocardiography, nuclear cardiology, cardiac computed tomography, cardiac magnetic resonance, and invasive angiography.",,Dr Chow holds the Saul and Edna Goldfarb Chair in Cardiac Imaging Research. The authors have no other funding sources to declare.,Canadian Journal of Cardiology,,"Artificial Intelligence; Cardiac Imaging Techniques; Cardiology; Cardiovascular Diseases; Humans; Image Processing, Computer-Assisted; Machine Learning",2021-10-04,2021,2021-10-04,2022-02,38,2,214-224,Closed,Article,"Lauzier, Pascal Theriault; Avram, Robert; Dey, Damini; Slomka, Piotr; Afilalo, Jonathan; Chow, Benjamin J W","Lauzier, Pascal Theriault (Departments of Medicine (Cardiology and Nuclear Medicine) and Radiology, University of Ottawa Heart Institute, Ottawa, Ontario, Canada.); Avram, Robert (Departments of Medicine (Cardiology and Nuclear Medicine) and Radiology, University of Ottawa Heart Institute, Ottawa, Ontario, Canada; Department of Medicine (Cardiology), Montréal Heart Institute, Montréal, Québec, Canada.); Dey, Damini (Departments of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, California, USA.); Slomka, Piotr (Departments of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, California, USA.); Afilalo, Jonathan (Division of Cardiology and Experimental Medicine, Department of Medicine, Jewish General Hospital, Montréal, Québec, Canada.); Chow, Benjamin J W (Departments of Medicine (Cardiology and Nuclear Medicine) and Radiology, University of Ottawa Heart Institute, Ottawa, Ontario, Canada. Electronic address: bchow@ottawaheart.ca.)","Chow, Benjamin J W (University of Ottawa)","Lauzier, Pascal Theriault (University of Ottawa); Avram, Robert (University of Ottawa; Montreal Heart Institute); Dey, Damini (Cedars-Sinai Medical Center); Slomka, Piotr (Cedars-Sinai Medical Center); Afilalo, Jonathan (Jewish General Hospital); Chow, Benjamin J W (University of Ottawa)",4,4,,4.51,,https://app.dimensions.ai/details/publication/pub.1141602692,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,,
1459,pub.1141560595,10.1007/978-981-16-3637-0_5,,,Automatic Spatio-Temporal Deep Learning-Based Approach for Cardiac Cine MRI Segmentation,"In the present paper, we suggest an automatic spatio-temporal aware, deep learning-based method for cardiac segmentation from short-axis cine magnetic resonance imaging MRI. This aims to help in automatically quantifying cardiac clinical indices as an essential step towards cardiovascular diseases diagnosis. Our method is based on a lightweight Unet variant with the incorporation of a 2D convolutional long short-term memory (LSTM) recurrent neural network based layer. The 2D convolutional LSTM-based layer is a good fit for dealing with the sequential aspect of cine MRI 3D spatial volumes, by capturing potential correlations between consecutive slices along the long-axis. Experiments have been conducted on a dataset publically available from the ACDC-2017 challenge. The challenge’s segmentation contest focuses on the evaluation of segmentation performances for three main cardiac structures: left, right ventricles cavities (LVC and RVC respectively) as well as left ventricle myocardium (LVM). The suggested segmentation network is fed with cardiac cine MRI sequences with variable spatial dimensions, leveraging a multi-scale context. With less overhead on preprocessing and no postprocessing steps, our model has accomplished near state-of-the-art performances, with an average dice overlap of 0.914 for the three cardiac structures on the test set, alongside good correlation coefficients and limits of agreement for clinical indices compared to their ground truth counterparts.Ammar, AbderazzakBouattane, OmarYoussfi, Mohamed",,,"Smart Innovation, Systems and Technologies","Networking, Intelligent Systems and Security",,2021-10-02,2021,2021-10-02,2022,237,,59-73,Closed,Chapter,"Ammar, Abderazzak; Bouattane, Omar; Youssfi, Mohamed","Ammar, Abderazzak (ENSET Mohamedia, Hassan II University, Casablanca, Morocco); Bouattane, Omar (ENSET Mohamedia, Hassan II University, Casablanca, Morocco); Youssfi, Mohamed (ENSET Mohamedia, Hassan II University, Casablanca, Morocco)","Ammar, Abderazzak (University of Hassan II Casablanca)","Ammar, Abderazzak (University of Hassan II Casablanca); Bouattane, Omar (University of Hassan II Casablanca); Youssfi, Mohamed (University of Hassan II Casablanca)",1,1,,0.42,,https://app.dimensions.ai/details/publication/pub.1141560595,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,,
352,pub.1147927273,10.11606/d.100.2021.tde-14122021-203305,,,Segmentação do ventrículo esquerdo em exames de ressonância magnética cardíaca com aprendizado profundo e modelos deformáveis contendo restrições de forma,Imagens provenientes de exames de ressonância magnética cardíaca são reconhecidas como padrão-ouro para o diagnóstico de diversas doenças cardíacas. Biomarcadores estimados a partir da segmentação e análise...,,,,,,2021-10,2021,,,,,,All OA, Gold,Article,"de Oliveira Ribeiro, Matheus Alberto","de Oliveira Ribeiro, Matheus Alberto ()",,"de Oliveira Ribeiro, Matheus Alberto ()",0,0,,,http://www.teses.usp.br/teses/disponiveis/100/100131/tde-14122021-203305/publico/Dissertacao_Matheus_versao_corrigida.pdf,https://app.dimensions.ai/details/publication/pub.1147927273,,,,,,,,,,,,
4533,pub.1134740667,10.1109/tmi.2021.3052972,33471750,PMC9817008,Unsupervised Domain Adaptation From Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks,"Anisotropic multi-slice Cardiac Magnetic Resonance (CMR) Images are conventionally acquired in patient-specific short-axis (SAX) orientation. In specific cardiovascular diseases that affect right ventricular (RV) morphology, acquisitions in standard axial (AX) orientation are preferred by some investigators, due to potential superiority in RV volume measurement for treatment planning. Unfortunately, due to the rare occurrence of these diseases, data in this domain is scarce. Recent research in deep learning-based methods mainly focused on SAX CMR images and they had proven to be very successful. In this work, we show that there is a considerable domain shift between AX and SAX images, and therefore, direct application of existing models yield sub-optimal results on AX samples. We propose a novel unsupervised domain adaptation approach, which uses task-related probabilities in an attention mechanism. Beyond that, cycle consistency is imposed on the learned patient-individual 3D rigid transformation to improve stability when automatically re-sampling the AX images to SAX orientations. The network was trained on 122 registered 3D AX-SAX CMR volume pairs from a multi-centric patient cohort. A mean 3D Dice of 0.86 ± 0.06 for the left ventricle, 0.65 ± 0.08 for the myocardium, and 0.77 ± 0.10 for the right ventricle could be achieved. This is an improvement of 25% in Dice for RV in comparison to direct application on axial slices. To conclude, our pre-trained task module has neither seen CMR images nor labels from the target domain, but is able to segment them after the domain gap is reduced. Code: https://github.com/Cardio-AI/3d-mri-domain-adaptation.","This work was supported in part by the Informatics for Life Project through the Klaus Tschira Foundation, in part by the Competence Network for Congenital Heart Defects through the Federal Ministry of Education and Research under Grant 01GI0601, and in part by the German Centre for Cardiovascular Research (DZHK).",,IEEE Transactions on Medical Imaging,,"Heart; Heart Diseases; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine",2021-09-30,2021,2021-09-30,2021-10,40,10,2939-2953,All OA, Green,Article,"Koehler, Sven; Hussain, Tarique; Blair, Zach; Huffaker, Tyler; Ritzmann, Florian; Tandon, Animesh; Pickardt, Thomas; Sarikouch, Samir; Latus, Heiner; Greil, Gerald; Wolf, Ivo; Engelhardt, Sandy","Koehler, Sven (Artificial Intelligence in Cardiovascular Medicine Group, Department of Internal Medicine III, Heidelberg University Hospital, D-69120, Heidelberg, Germany; German Centre for Cardiovascular Research (DZHK), 68167, Heidelberg, Germany); Hussain, Tarique (Department of Pediatrics, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Division of Cardiology, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Department of Radiology, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Advanced Imaging Research Center, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA); Blair, Zach (Department of Pediatrics, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA); Huffaker, Tyler (Department of Pediatrics, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA); Ritzmann, Florian (Artificial Intelligence in Cardiovascular Medicine Group, Department of Internal Medicine III, Heidelberg University Hospital, D-69120, Heidelberg, Germany; German Centre for Cardiovascular Research (DZHK), 68167, Heidelberg, Germany); Tandon, Animesh (Department of Pediatrics, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Division of Cardiology, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Department of Radiology, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Advanced Imaging Research Center, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA); Pickardt, Thomas (German Competence Network for Congenital Heart Defects, 13353, Berlin, Germany; German Centre for Cardiovascular Research (DZHK), 68167, Berlin, Germany); Sarikouch, Samir (German Competence Network for Congenital Heart Defects, 13353, Berlin, Germany; German Centre for Cardiovascular Research (DZHK), 68167, Berlin, Germany; Department of Cardiothoracic, Transplantation and Vascular Surgery, Hannover Medical School, 30625, Hannover, Germany); Latus, Heiner (German Heart Centre Munich, Department of Paediatric Cardiology and Congenital Heart Defects, Technical University Munich, 80636, Munich, Germany); Greil, Gerald (Department of Pediatrics, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Division of Cardiology, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Department of Radiology, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA; Advanced Imaging Research Center, University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA); Wolf, Ivo (Department of Computer Science, Mannheim University of Applied Science, 68163, Mannheim, Germany); Engelhardt, Sandy (Artificial Intelligence in Cardiovascular Medicine Group, Department of Internal Medicine III, Heidelberg University Hospital, D-69120, Heidelberg, Germany; German Centre for Cardiovascular Research (DZHK), 68167, Heidelberg, Germany)","Engelhardt, Sandy (University Hospital Heidelberg; German Centre for Cardiovascular Research)","Koehler, Sven (University Hospital Heidelberg; German Centre for Cardiovascular Research); Hussain, Tarique (The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center); Blair, Zach (The University of Texas Southwestern Medical Center); Huffaker, Tyler (The University of Texas Southwestern Medical Center); Ritzmann, Florian (University Hospital Heidelberg; German Centre for Cardiovascular Research); Tandon, Animesh (The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center); Pickardt, Thomas (German Centre for Cardiovascular Research); Sarikouch, Samir (German Centre for Cardiovascular Research; Hannover Medical School); Latus, Heiner (Technical University of Munich); Greil, Gerald (The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center; The University of Texas Southwestern Medical Center); Wolf, Ivo (Mannheim University of Applied Sciences); Engelhardt, Sandy (University Hospital Heidelberg; German Centre for Cardiovascular Research)",7,7,1.01,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9817008,https://app.dimensions.ai/details/publication/pub.1134740667,46 Information and Computing Sciences,,,,,,,,,,,
957,pub.1141558090,10.48550/arxiv.2109.14805,,,Unsupervised Landmark Detection Based Spatiotemporal Motion Estimation  for 4D Dynamic Medical Images,"Motion estimation is a fundamental step in dynamic medical image processing
for the assessment of target organ anatomy and function. However, existing
image-based motion estimation methods, which optimize the motion field by
evaluating the local image similarity, are prone to produce implausible
estimation, especially in the presence of large motion. In this study, we
provide a novel motion estimation framework of Dense-Sparse-Dense (DSD), which
comprises two stages. In the first stage, we process the raw dense image to
extract sparse landmarks to represent the target organ anatomical topology and
discard the redundant information that is unnecessary for motion estimation.
For this purpose, we introduce an unsupervised 3D landmark detection network to
extract spatially sparse but representative landmarks for the target organ
motion estimation. In the second stage, we derive the sparse motion
displacement from the extracted sparse landmarks of two images of different
time points. Then, we present a motion reconstruction network to construct the
motion field by projecting the sparse landmarks displacement back into the
dense image domain. Furthermore, we employ the estimated motion field from our
two-stage DSD framework as initialization and boost the motion estimation
quality in light-weight yet effective iterative optimization. We evaluate our
method on two dynamic medical imaging tasks to model cardiac motion and lung
respiratory motion, respectively. Our method has produced superior motion
estimation accuracy compared to existing comparative methods. Besides, the
extensive experimental results demonstrate that our solution can extract well
representative anatomical landmarks without any requirement of manual
annotation. Our code is publicly available online.",,,arXiv,,,2021-09-29,2021,,,,,,All OA, Green,Preprint,"Guo, Yuyu; Bi, Lei; Wei, Dongming; Chen, Liyun; Zhu, Zhengbin; Feng, Dagan; Zhang, Ruiyan; Wang, Qian; Kim, Jinman","Guo, Yuyu (); Bi, Lei (); Wei, Dongming (); Chen, Liyun (); Zhu, Zhengbin (); Feng, Dagan (); Zhang, Ruiyan (); Wang, Qian (); Kim, Jinman ()",,"Guo, Yuyu (); Bi, Lei (); Wei, Dongming (); Chen, Liyun (); Zhu, Zhengbin (); Feng, Dagan (); Zhang, Ruiyan (); Wang, Qian (); Kim, Jinman ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1141558090,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
1516,pub.1141487441,10.48550/arxiv.2109.13230,,,The Impact of Domain Shift on Left and Right Ventricle Segmentation in  Short Axis Cardiac MR Images,"Domain shift refers to the difference in the data distribution of two
datasets, normally between the training set and the test set for machine
learning algorithms. Domain shift is a serious problem for generalization of
machine learning models and it is well-established that a domain shift between
the training and test sets may cause a drastic drop in the model's performance.
In medical imaging, there can be many sources of domain shift such as different
scanners or scan protocols, different pathologies in the patient population,
anatomical differences in the patient population (e.g. men vs women) etc.
Therefore, in order to train models that have good generalization performance,
it is important to be aware of the domain shift problem, its potential causes
and to devise ways to address it. In this paper, we study the effect of domain
shift on left and right ventricle blood pool segmentation in short axis cardiac
MR images. Our dataset contains short axis images from 4 different MR scanners
and 3 different pathology groups. The training is performed with nnUNet. The
results show that scanner differences cause a greater drop in performance
compared to changing the pathology group, and that the impact of domain shift
is greater on right ventricle segmentation compared to left ventricle
segmentation. Increasing the number of training subjects increased
cross-scanner performance more than in-scanner performance at small training
set sizes, but this difference in improvement decreased with larger training
set sizes. Training models using data from multiple scanners improved
cross-domain performance.",,,arXiv,,,2021-09-22,2021,,,,,,All OA, Green,Preprint,"Ugurlu, Devran; Puyol-Anton, Esther; Ruijsink, Bram; Young, Alistair; Machado, Ines; Hammernik, Kerstin; King, Andrew P.; Schnabel, Julia A.","Ugurlu, Devran (); Puyol-Anton, Esther (); Ruijsink, Bram (); Young, Alistair (); Machado, Ines (); Hammernik, Kerstin (); King, Andrew P. (); Schnabel, Julia A. ()",,"Ugurlu, Devran (); Puyol-Anton, Esther (); Ruijsink, Bram (); Young, Alistair (); Machado, Ines (); Hammernik, Kerstin (); King, Andrew P. (); Schnabel, Julia A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1141487441,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
1459,pub.1141322316,10.1007/978-3-030-87231-1_21,,,Universal Undersampled MRI Reconstruction,"Deep neural networks have been extensively studied for undersampled MRI reconstruction. While achieving state-of-the-art performance, they are trained and deployed specifically for one anatomy with limited generalization ability to another anatomy. Rather than building multiple models, a universal model that reconstructs images across different anatomies is highly desirable for efficient deployment and better generalization. Simply mixing images from multiple anatomies for training a single network does not lead to an ideal universal model due to the statistical shift among datasets of various anatomies, the need to retrain from scratch on all datasets with the addition of a new dataset, and the difficulty in dealing with imbalanced sampling when the new dataset is further of a smaller size. In this paper, for the first time, we propose a framework to learn a universal deep neural network for undersampled MRI reconstruction. Specifically, anatomy-specific instance normalization is proposed to compensate for statistical shift and allow easy generalization to new datasets. Moreover, the universal model is trained by distilling knowledge from available independent models to further exploit representations across anatomies. Experimental results show the proposed universal model can reconstruct both brain and knee images from NYU fastMRI dataset with high image quality. Also, it is easy to adapt the trained model to new datasets of smaller size, i.e., abdomen, cardiac and prostate, with little effort and superior performance.",,,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12906,,211-221,All OA, Green,Chapter,"Liu, Xinwen; Wang, Jing; Liu, Feng; Zhou, S. Kevin","Liu, Xinwen (School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, Australia); Wang, Jing (The Commonwealth Scientific and Industrial Research Organisation, Canberra, Australia); Liu, Feng (School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, Australia); Zhou, S. Kevin (Medical Imaging, Robotics, and Analytic Computing Laboratory and Engineering (MIRACLE), School of Biomedical Engineering and Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China)","Liu, Xinwen (University of Queensland)","Liu, Xinwen (University of Queensland); Wang, Jing (Commonwealth Scientific and Industrial Research Organisation); Liu, Feng (University of Queensland); Zhou, S. Kevin (University of Science and Technology of China; Institute of Computing Technology)",2,2,,1.64,http://arxiv.org/pdf/2103.05214,https://app.dimensions.ai/details/publication/pub.1141322316,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1457,pub.1141301963,10.1007/978-3-030-87193-2_29,,,Context-Aware Virtual Adversarial Training for Anatomically-Plausible Segmentation,"Despite their outstanding accuracy, semi-supervised segmentation methods based on deep neural networks can still yield predictions that are considered anatomically impossible by clinicians, for instance, containing holes or disconnected regions. To solve this problem, we present a Context-aware Virtual Adversarial Training (CaVAT) method for generating anatomically plausible segmentation. Unlike approaches focusing solely on accuracy, our method also considers complex topological constraints like connectivity which cannot be easily modeled in a differentiable loss function. We use adversarial training to generate examples violating the constraints, so the network can learn to avoid making such incorrect predictions on new examples, and employ the Reinforce algorithm to handle non-differentiable segmentation constraints. The proposed method offers a generic and efficient way to add any constraint on top of any segmentation network. Experiments on two clinically-relevant datasets show our method to produce segmentations that are both accurate and anatomically-plausible in terms of region connectivity.",,,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12901,,304-314,All OA, Green,Chapter,"Wang, Ping; Peng, Jizong; Pedersoli, Marco; Zhou, Yuanfeng; Zhang, Caiming; Desrosiers, Christian","Wang, Ping (Department of Software and IT Engineering, ETS, Montreal, Canada); Peng, Jizong (Department of Software and IT Engineering, ETS, Montreal, Canada); Pedersoli, Marco (Department of Software and IT Engineering, ETS, Montreal, Canada); Zhou, Yuanfeng (School of Software, Shandong University, Jinan, China); Zhang, Caiming (School of Software, Shandong University, Jinan, China); Desrosiers, Christian (Department of Software and IT Engineering, ETS, Montreal, Canada)","Wang, Ping ","Wang, Ping (); Peng, Jizong (); Pedersoli, Marco (); Zhou, Yuanfeng (Shandong University); Zhang, Caiming (Shandong University); Desrosiers, Christian ()",2,2,,1.64,http://arxiv.org/pdf/2107.05532,https://app.dimensions.ai/details/publication/pub.1141301963,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1398,pub.1141326802,10.1007/978-3-030-87199-4_15,,,Controllable Cardiac Synthesis via Disentangled Anatomy Arithmetic,"Acquiring annotated data at scale with rare diseases or conditions remains a challenge. It would be extremely useful to have a method that controllably synthesizes images that can correct such underrepresentation. Assuming a proper latent representation, the idea of a “latent vector arithmetic” could offer the means of achieving such synthesis. A proper representation must encode the fidelity of the input data, preserve invariance and equivariance, and permit arithmetic operations. Motivated by the ability to disentangle images into spatial anatomy (tensor) factors and accompanying imaging (vector) representations, we propose a framework termed “disentangled anatomy arithmetic”, in which a generative model learns to combine anatomical factors of different input images such that when they are re-entangled with the desired imaging modality (e.g. MRI), plausible new cardiac images are created with the target characteristics. To encourage a realistic combination of anatomy factors after the arithmetic step, we propose a localized noise injection network that precedes the generator. Our model is used to generate realistic images, pathology labels, and segmentation masks that are used to augment the existing datasets and subsequently improve post-hoc classification and segmentation tasks. Code is publicly available at https://github.com/vios-s/DAA-GAN.","This work was supported by the University of Edinburgh, the Royal Academy of Engineering and Canon Medical Research Europe. This work was partially supported by the Alan Turing Institute under the EPSRC grant EP/N510129/1. We thank Nvidia for donating a Titan-X GPU. S. A. Tsaftaris acknowledges the support of Canon Medical and the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme (grant RCSRF1819 8 25).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12903,,160-170,All OA, Green,Chapter,"Thermos, Spyridon; Liu, Xiao; O’Neil, Alison; Tsaftaris, Sotirios A.","Thermos, Spyridon (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK); Liu, Xiao (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK); O’Neil, Alison (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; Canon Medical Research Europe, EH6 5NP, Edinburgh, UK); Tsaftaris, Sotirios A. (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; The Alan Turing Institute, NW1 2DB, London, UK)","Thermos, Spyridon (University of Edinburgh)","Thermos, Spyridon (University of Edinburgh); Liu, Xiao (University of Edinburgh); O’Neil, Alison (University of Edinburgh); Tsaftaris, Sotirios A. (University of Edinburgh; The Alan Turing Institute)",8,8,,6.55,http://arxiv.org/pdf/2107.01748,https://app.dimensions.ai/details/publication/pub.1141326802,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1396,pub.1141326771,10.1007/978-3-030-87196-3_42,,,Tripled-Uncertainty Guided Mean Teacher Model for Semi-supervised Medical Image Segmentation,"Due to the difficulty in accessing a large amount of labeled data, semi-supervised learning is becoming an attractive solution in medical image segmentation. To make use of unlabeled data, current popular semi-supervised methods (e.g., temporal ensembling, mean teacher) mainly impose data-level and model-level consistency on unlabeled data. In this paper, we argue that in addition to these strategies, we could further utilize auxiliary tasks and consider task-level consistency to better leverage unlabeled data for segmentation. Specifically, we introduce two auxiliary tasks, i.e., a foreground and background reconstruction task for capturing semantic information and a signed distance field (SDF) prediction task for imposing shape constraint, and explore the mutual promotion effect between the two auxiliary and the segmentation tasks based on mean teacher architecture. Moreover, to handle the potential bias of the teacher model caused by annotation scarcity, we develop a tripled-uncertainty guided framework to encourage the three tasks in the teacher model to generate more reliable pseudo labels. When calculating uncertainty, we propose an uncertainty weighted integration (UWI) strategy for yielding the segmentation predictions of the teacher. Extensive experiments on public 2017 ACDC dataset and PROMISE12 dataset have demostrated the effectiveness of our method. Code is available at https://github.com/DeepMedLab/Tri-U-MT.","This work is supported by National Natural Science Foundation of China (NFSC 62071314) and Sichuan Science and Technology Program (2021YFG0326, 2020YFG0079).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12902,,450-460,Closed,Chapter,"Wang, Kaiping; Zhan, Bo; Zu, Chen; Wu, Xi; Zhou, Jiliu; Zhou, Luping; Wang, Yan","Wang, Kaiping (School of Computer Science, Sichuan University, Chengdu, China); Zhan, Bo (School of Computer Science, Sichuan University, Chengdu, China); Zu, Chen (Department of Risk Controlling Research, JD.COM, Chengdu, China); Wu, Xi (School of Computer Science, Chengdu University of Information Technology, Chengdu, China); Zhou, Jiliu (School of Computer Science, Sichuan University, Chengdu, China; School of Computer Science, Chengdu University of Information Technology, Chengdu, China); Zhou, Luping (School of Electrical and Information Engineering, University of Sydney, Sydney, Australia); Wang, Yan (School of Computer Science, Sichuan University, Chengdu, China)","Wang, Yan (Sichuan University)","Wang, Kaiping (Sichuan University); Zhan, Bo (Sichuan University); Zu, Chen (Jingdong (China)); Wu, Xi (Chengdu University of Information Technology); Zhou, Jiliu (Sichuan University; Chengdu University of Information Technology); Zhou, Luping (The University of Sydney); Wang, Yan (Sichuan University)",22,22,,18.01,,https://app.dimensions.ai/details/publication/pub.1141326771,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1395,pub.1141326756,10.1007/978-3-030-87196-3_29,,,Semi-supervised Meta-learning with Disentanglement for Domain-Generalised Medical Image Segmentation,"Generalising deep models to new data from new centres (termed here domains) remains a challenge. This is largely attributed to shifts in data statistics (domain shifts) between source and unseen domains. Recently, gradient-based meta-learning approaches where the training data are split into meta-train and meta-test sets to simulate and handle the domain shifts during training have shown improved generalisation performance. However, the current fully supervised meta-learning approaches are not scalable for medical image segmentation, where large effort is required to create pixel-wise annotations. Meanwhile, in a low data regime, the simulated domain shifts may not approximate the true domain shifts well across source and unseen domains. To address this problem, we propose a novel semi-supervised meta-learning framework with disentanglement. We explicitly model the representations related to domain shifts. Disentangling the representations and combining them to reconstruct the input image allows unlabeled data to be used to better approximate the true domain shifts for meta-learning. Hence, the model can achieve better generalisation performance, especially when there is a limited amount of labeled data. Experiments show that the proposed method is robust on different segmentation tasks and achieves state-of-the-art generalisation performance on two public benchmarks. Code is publicly available at: https://github.com/vios-s/DGNet.","This work was supported by the University of Edinburgh, the Royal Academy of Engineering and Canon Medical Research Europe by a PhD studentship to Xiao Liu. This work was partially supported by the Alan Turing Institute under the EPSRC grant EP/N510129/1. We thank Nvidia for donating a Titan-X GPU. S.A. Tsaftaris acknowledges the support of Canon Medical and the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme (grant RCSRF1819\8\25).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12902,,307-317,All OA, Green,Chapter,"Liu, Xiao; Thermos, Spyridon; O’Neil, Alison; Tsaftaris, Sotirios A.","Liu, Xiao (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK); Thermos, Spyridon (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK); O’Neil, Alison (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; Canon Medical Research Europe Ltd., Edinburgh, UK); Tsaftaris, Sotirios A. (School of Engineering, University of Edinburgh, EH9 3FB, Edinburgh, UK; The Alan Turing Institute, London, UK)","Liu, Xiao (University of Edinburgh)","Liu, Xiao (University of Edinburgh); Thermos, Spyridon (University of Edinburgh); O’Neil, Alison (University of Edinburgh); Tsaftaris, Sotirios A. (University of Edinburgh; The Alan Turing Institute)",15,15,,11.94,https://www.pure.ed.ac.uk/ws/files/242179727/liu2021semi.pdf,https://app.dimensions.ai/details/publication/pub.1141326756,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1066,pub.1141300244,10.48550/arxiv.2109.09960,,,Mutual Consistency Learning for Semi-supervised Medical Image  Segmentation,"In this paper, we propose a novel mutual consistency network (MC-Net+) to
effectively exploit the unlabeled data for semi-supervised medical image
segmentation. The MC-Net+ model is motivated by the observation that deep
models trained with limited annotations are prone to output highly uncertain
and easily mis-classified predictions in the ambiguous regions (e.g., adhesive
edges or thin branches) for medical image segmentation. Leveraging these
challenging samples can make the semi-supervised segmentation model training
more effective. Therefore, our proposed MC-Net+ model consists of two new
designs. First, the model contains one shared encoder and multiple slightly
different decoders (i.e., using different up-sampling strategies). The
statistical discrepancy of multiple decoders' outputs is computed to denote the
model's uncertainty, which indicates the unlabeled hard regions. Second, we
apply a novel mutual consistency constraint between one decoder's probability
output and other decoders' soft pseudo labels. In this way, we minimize the
discrepancy of multiple outputs (i.e., the model uncertainty) during training
and force the model to generate invariant results in such challenging regions,
aiming at regularizing the model training. We compared the segmentation results
of our MC-Net+ model with five state-of-the-art semi-supervised approaches on
three public medical datasets. Extension experiments with two standard
semi-supervised settings demonstrate the superior performance of our model over
other methods, which sets a new state of the art for semi-supervised medical
image segmentation. Our code is released publicly at
https://github.com/ycwu1997/MC-Net.",,,arXiv,,,2021-09-21,2021,,,,,,All OA, Green,Preprint,"Wu, Yicheng; Ge, Zongyuan; Zhang, Donghao; Xu, Minfeng; Zhang, Lei; Xia, Yong; Cai, Jianfei","Wu, Yicheng (); Ge, Zongyuan (); Zhang, Donghao (); Xu, Minfeng (); Zhang, Lei (); Xia, Yong (); Cai, Jianfei ()",,"Wu, Yicheng (); Ge, Zongyuan (); Zhang, Donghao (); Xu, Minfeng (); Zhang, Lei (); Xia, Yong (); Cai, Jianfei ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1141300244,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
6279,pub.1141235009,10.1016/j.ijrobp.2021.09.009,34547373,,AI-Based Quantification of Planned Radiation Therapy Dose to Cardiac Structures and Coronary Arteries in Patients With Breast Cancer,"PURPOSE: The purpose of this work is to develop and evaluate an automatic deep learning method for segmentation of cardiac chambers and large arteries, and localization of the 3 main coronary arteries in radiation therapy planning on computed tomography (CT). In addition, a second purpose is to determine the planned radiation therapy dose to cardiac structures for breast cancer therapy.
METHODS AND MATERIALS: Eighteen contrast-enhanced cardiac scans acquired with a dual-layer-detector CT scanner were included for method development. Manual reference annotations of cardiac chambers, large arteries, and coronary artery locations were made in the contrast scans and transferred to virtual noncontrast images, mimicking noncontrast-enhanced CT. In addition, 31 noncontrast-enhanced radiation therapy treatment planning CTs with corresponding dose-distribution maps of breast cancer cases were included for evaluation. For reference, cardiac chambers and large vessels were manually annotated in two 2-dimensional (2D) slices per scan (26 scans, totaling 52 slices) and in 3-dimensional (3D) scan volumes in 5 scans. Coronary artery locations were annotated on 3D imaging. The method uses an ensemble of convolutional neural networks with 2 output branches that perform 2 distinct tasks: (1) segmentation of the cardiac chambers and large arteries and (2) localization of coronary arteries. Training was performed using reference annotations and virtual noncontrast cardiac scans. Automatic segmentation of the cardiac chambers and large vessels and the coronary artery locations was evaluated in radiation therapy planning CT with Dice score (DSC) and average symmetrical surface distance (ASSD). The correlation between dosimetric parameters derived from the automatic and reference segmentations was evaluated with R2.
RESULTS: For cardiac chambers and large arteries, median DSC was 0.76 to 0.88, and the median ASSD was 0.17 to 0.27 cm in 2D slice evaluation. 3D evaluation found a DSC of 0.87 to 0.93 and an ASSD of 0.07 to 0.10 cm. Median DSC of the coronary artery locations ranged from 0.80 to 0.91. R2 values of dosimetric parameters were 0.77 to 1.00 for the cardiac chambers and large vessels, and 0.76 to 0.95 for the coronary arteries.
CONCLUSIONS: The developed and evaluated method can automatically obtain accurate estimates of planned radiation dose and dosimetric parameters for the cardiac chambers, large arteries, and coronary arteries.",,,International Journal of Radiation Oncology • Biology • Physics,,"Breast Neoplasms; Coronary Vessels; Female; Heart; Humans; Neural Networks, Computer; Tomography, X-Ray Computed",2021-09-20,2021,2021-09-20,2022-03,112,3,611-620,All OA, Green,Article,"van Velzen, Sanne G M; Bruns, Steffen; Wolterink, Jelmer M; Leiner, Tim; Viergever, Max A; Verkooijen, Helena M; Išgum, Ivana","van Velzen, Sanne G M (Image Sciences Institute, University Medical Center Utrecht, Utrecht, the Netherlands; Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - Location Academic Medical Center, University of Amsterdam, Amsterdam, the Netherlands. Electronic address: s.g.m.vanvelzen@amsterdamumc.nl.); Bruns, Steffen (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - Location Academic Medical Center, University of Amsterdam, Amsterdam, the Netherlands.); Wolterink, Jelmer M (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - Location Academic Medical Center, University of Amsterdam, Amsterdam, the Netherlands; Department of Applied Mathematics and Technical Medicine Center, University of Twente, Enschede, the Netherlands.); Leiner, Tim (Department of Radiology, Utrecht University Medical Center, University of Utrecht, Utrecht, the Netherlands.); Viergever, Max A (Image Sciences Institute, University Medical Center Utrecht, Utrecht, the Netherlands.); Verkooijen, Helena M (Division of Imaging and Oncology, University Medical Center Utrecht, University of Utrecht, Utrecht, the Netherlands.); Išgum, Ivana (Image Sciences Institute, University Medical Center Utrecht, Utrecht, the Netherlands; Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - Location Academic Medical Center, University of Amsterdam, Amsterdam, the Netherlands; Department of Radiology and Nuclear Medicine, Amsterdam University Medical Centers - Location Academic Medical Center, University of Amsterdam, Amsterdam, the Netherlands; Amsterdam Cardiovascular Sciences, Amsterdam University Medical Centers - location Academic Medical Center, University of Amsterdam, Amsterdam, the Netherlands.)","van Velzen, Sanne G M (University Medical Center Utrecht; University of Amsterdam)","van Velzen, Sanne G M (University Medical Center Utrecht; University of Amsterdam); Bruns, Steffen (University of Amsterdam); Wolterink, Jelmer M (University of Amsterdam; University of Twente); Leiner, Tim (Utrecht University; University Medical Center Utrecht); Viergever, Max A (University Medical Center Utrecht); Verkooijen, Helena M (University Medical Center Utrecht; Utrecht University); Išgum, Ivana (University Medical Center Utrecht; University of Amsterdam)",7,7,,5.92,https://ris.utwente.nl/ws/files/277366746/1_s2.0_S0360301621027929_main.pdf,https://app.dimensions.ai/details/publication/pub.1141235009,32 Biomedical and Clinical Sciences, 3211 Oncology and Carcinogenesis, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
4154,pub.1141179812,10.3389/fphys.2021.716597,34603077,PMC8481785,An Implementation of Patient-Specific Biventricular Mechanics Simulations With a Deep Learning and Computational Pipeline,"Parameterised patient-specific models of the heart enable quantitative analysis of cardiac function as well as estimation of regional stress and intrinsic tissue stiffness. However, the development of personalised models and subsequent simulations have often required lengthy manual setup, from image labelling through to generating the finite element model and assigning boundary conditions. Recently, rapid patient-specific finite element modelling has been made possible through the use of machine learning techniques. In this paper, utilising multiple neural networks for image labelling and detection of valve landmarks, together with streamlined data integration, a pipeline for generating patient-specific biventricular models is applied to clinically-acquired data from a diverse cohort of individuals, including hypertrophic and dilated cardiomyopathy patients and healthy volunteers. Valve motion from tracked landmarks as well as cavity volumes measured from labelled images are used to drive realistic motion and estimate passive tissue stiffness values. The neural networks are shown to accurately label cardiac regions and features for these diverse morphologies. Furthermore, differences in global intrinsic parameters, such as tissue anisotropy and normalised active tension, between groups illustrate respective underlying changes in tissue composition and/or structure as a result of pathology. This study shows the successful application of a generic pipeline for biventricular modelling, incorporating artificial intelligence solutions, within a diverse cohort.",,"DN would like to acknowledge funding from Engineering and Physical Sciences Research Council (EP/N011554/1 and EP/R003866/1). This work was also supported by the Wellcome ESPRC Centre for Medical Engineering at King's College London (WT 203148/Z/16/Z) and the British Heart Foundation (TG/17/3/33406). AY would like to acknowledge funding from the National Heart, Lung and Blood Institute (NIH R01HL121754).",Frontiers in Physiology,,,2021-09-16,2021,2021-09-16,,12,,716597,All OA, Gold,Article,"Miller, Renee; Kerfoot, Eric; Mauger, Charlène; Ismail, Tevfik F.; Young, Alistair A.; Nordsletten, David A.","Miller, Renee (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Kerfoot, Eric (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Mauger, Charlène (Auckland MR Research Group, University of Auckland, Auckland, New Zealand); Ismail, Tevfik F. (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); Young, Alistair A. (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Auckland MR Research Group, University of Auckland, Auckland, New Zealand); Nordsletten, David A. (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom; Department of Biomedical Engineering and Cardiac Surgery, University of Michigan, Ann Arbor, MI, United States)","Miller, Renee (King's College London); Kerfoot, Eric (King's College London)","Miller, Renee (King's College London); Kerfoot, Eric (King's College London); Mauger, Charlène (University of Auckland); Ismail, Tevfik F. (King's College London); Young, Alistair A. (King's College London; University of Auckland); Nordsletten, David A. (King's College London; University of Michigan–Ann Arbor)",7,7,1.46,4.81,https://www.frontiersin.org/articles/10.3389/fphys.2021.716597/pdf,https://app.dimensions.ai/details/publication/pub.1141179812,32 Biomedical and Clinical Sciences, 3208 Medical Physiology,,,,,,,,,,
6479,pub.1141032249,10.1016/j.media.2021.102223,34555661,PMC8560564,Using synthetic data generation to train a cardiac motion tag tracking neural network,"A CNN based method for cardiac MRI tag tracking was developed and validated. A synthetic data simulator was created to generate large amounts of training data using natural images, a Bloch equation simulation, a broad range of tissue properties, and programmed ground-truth motion. The method was validated using both an analytical deforming cardiac phantom and in vivo data with manually tracked reference motion paths. In the analytical phantom, error was investigated relative to SNR, and accurate results were seen for SNR>10 (displacement error <0.3 mm). Excellent agreement was seen in vivo for tag locations (mean displacement difference = -0.02 pixels, 95% CI [-0.73, 0.69]) and calculated cardiac circumferential strain (mean difference = 0.006, 95% CI [-0.012, 0.024]). Automated tag tracking with a CNN trained on synthetic data is both accurate and precise.","This project was supported by NIH/NHLBI R01 HL131823, NIH/NHLBI R01 HL131975, and NIH/NHLBI R01 HL152256. The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.",,Medical Image Analysis,,"Computer Simulation; Heart; Humans; Magnetic Resonance Imaging; Motion; Neural Networks, Computer; Phantoms, Imaging",2021-09-10,2021,2021-09-10,2021-12,74,,102223,All OA, Bronze,Article,"Loecher, Michael; Perotti, Luigi E; Ennis, Daniel B","Loecher, Michael (Department of Radiology, Stanford University, USA. Electronic address: mloecher@stanford.edu.); Perotti, Luigi E (Department of Mechanical and Aerospace Engineering, University of Central Florida, USA.); Ennis, Daniel B (Department of Radiology, Stanford University, USA; Cardiovascular Institute, Stanford University, USA; Center for Artificial Intelligence in Medicine & Imaging, Stanford University, USA.)","Loecher, Michael (Stanford University)","Loecher, Michael (Stanford University); Perotti, Luigi E (University of Central Florida); Ennis, Daniel B (Stanford University)",10,10,1.27,,https://www.sciencedirect.com/science/article/am/pii/S1361841521002681,https://app.dimensions.ai/details/publication/pub.1141032249,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
913,pub.1141035444,10.48550/arxiv.2109.04188,,,Towards Fully Automated Segmentation of Rat Cardiac MRI by Leveraging  Deep Learning Frameworks,"Automated segmentation of human cardiac magnetic resonance datasets has been
steadily improving during recent years. However, these methods are not directly
applicable in preclinical context due to limited datasets and lower image
resolution. Successful application of deep architectures for rat cardiac
segmentation, although of critical importance for preclinical evaluation of
cardiac function, has to our knowledge not yet been reported. We developed
segmentation models that expand on the standard U-Net architecture and
evaluated separate models for systole and diastole phases, 2MSA, and one model
for all timepoints, 1MSA. Furthermore, we calibrated model outputs using a
Gaussian Process (GP)-based prior to improve phase selection. Resulting models
approach human performance in terms of left ventricular segmentation quality
and ejection fraction (EF) estimation in both 1MSA and 2MSA settings
(Sørensen-Dice score 0.91 +/- 0.072 and 0.93 +/- 0.032, respectively). 2MSA
achieved a mean absolute difference between estimated and reference EF of 3.5
+/- 2.5 %, while 1MSA resulted in 4.1 +/- 3.0 %. Applying Gaussian Processes to
1MSA allows to automate the selection of systole and diastole phases. Combined
with a novel cardiac phase selection strategy, our work presents an important
first step towards a fully automated segmentation pipeline in the context of
rat cardiac analysis.",,,arXiv,,,2021-09-09,2021,,,,,,All OA, Green,Preprint,"Fernandez-Llaneza, Daniel; Gondova, Andrea; Vince, Harris; Patra, Arijit; Zurek, Magdalena; Konings, Peter; Kagelid, Patrik; Hultin, Leif","Fernandez-Llaneza, Daniel (); Gondova, Andrea (); Vince, Harris (); Patra, Arijit (); Zurek, Magdalena (); Konings, Peter (); Kagelid, Patrik (); Hultin, Leif ()",,"Fernandez-Llaneza, Daniel (); Gondova, Andrea (); Vince, Harris (); Patra, Arijit (); Zurek, Magdalena (); Konings, Peter (); Kagelid, Patrik (); Hultin, Leif ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1141035444,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1251,pub.1141035050,10.48550/arxiv.2109.03201,,,nnFormer: Interleaved Transformer for Volumetric Segmentation,"Transformer, the model of choice for natural language processing, has drawn
scant attention from the medical imaging community. Given the ability to
exploit long-term dependencies, transformers are promising to help atypical
convolutional neural networks to overcome their inherent shortcomings of
spatial inductive bias. However, most of recently proposed transformer-based
segmentation approaches simply treated transformers as assisted modules to help
encode global context into convolutional representations. To address this
issue, we introduce nnFormer, a 3D transformer for volumetric medical image
segmentation. nnFormer not only exploits the combination of interleaved
convolution and self-attention operations, but also introduces local and global
volume-based self-attention mechanism to learn volume representations.
Moreover, nnFormer proposes to use skip attention to replace the traditional
concatenation/summation operations in skip connections in U-Net like
architecture. Experiments show that nnFormer significantly outperforms previous
transformer-based counterparts by large margins on three public datasets.
Compared to nnUNet, nnFormer produces significantly lower HD95 and comparable
DSC results. Furthermore, we show that nnFormer and nnUNet are highly
complementary to each other in model ensembling.",,,arXiv,,,2021-09-07,2021,,,,,,All OA, Green,Preprint,"Zhou, Hong-Yu; Guo, Jiansen; Zhang, Yinghao; Yu, Lequan; Wang, Liansheng; Yu, Yizhou","Zhou, Hong-Yu (); Guo, Jiansen (); Zhang, Yinghao (); Yu, Lequan (); Wang, Liansheng (); Yu, Yizhou ()",,"Zhou, Hong-Yu (); Guo, Jiansen (); Zhang, Yinghao (); Yu, Lequan (); Wang, Liansheng (); Yu, Yizhou ()",3,3,,2.46,,https://app.dimensions.ai/details/publication/pub.1141035050,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4808,pub.1136235916,10.1109/jbhi.2021.3064353,33684050,PMC7611810,Left Ventricle Quantification Challenge: A Comprehensive Comparison and Evaluation of Segmentation and Regression for Mid-Ventricular Short-Axis Cardiac MR Data,"Automatic quantification of the left ventricle (LV) from cardiac magnetic resonance (CMR) images plays an important role in making the diagnosis procedure efficient, reliable, and alleviating the laborious reading work for physicians. Considerable efforts have been devoted to LV quantification using different strategies that include segmentation-based (SG) methods and the recent direct regression (DR) methods. Although both SG and DR methods have obtained great success for the task, a systematic platform to benchmark them remains absent because of differences in label information during model learning. In this paper, we conducted an unbiased evaluation and comparison of cardiac LV quantification methods that were submitted to the Left Ventricle Quantification (LVQuan) challenge, which was held in conjunction with the Statistical Atlases and Computational Modeling of the Heart (STACOM) workshop at the MICCAI 2018. The challenge was targeted at the quantification of 1) areas of LV cavity and myocardium, 2) dimensions of the LV cavity, 3) regional wall thicknesses (RWT), and 4) the cardiac phase, from mid-ventricle short-axis CMR images. First, we constructed a public quantification dataset Cardiac-DIG with ground truth labels for both the myocardium mask and these quantification targets across the entire cardiac cycle. Then, the key techniques employed by each submission were described. Next, quantitative validation of these submissions were conducted with the constructed dataset. The evaluation results revealed that both SG and DR methods can offer good LV quantification performance, even though DR methods do not require densely labeled masks for supervision. Among the 12 submissions, the DR method LDAMT offered the best performance, with a mean estimation error of 301 mm 2 for the two areas, 2.15 mm for the cavity dimensions, 2.03 mm for RWTs, and a 9.5% error rate for the cardiac phase classification. Three of the SG methods also delivered comparable performances. Finally, we discussed the advantages and disadvantages of SG and DR methods, as well as the unsolved problems in automatic cardiac quantification for clinical practice applications.","This work was supported in part by the Natural Science Foundation of China under Grant 61801296. The work of Eric Kerfoot was supported in part by an EPSRC programme Grant EP/P001009/1 and in part by the Wellcome EPSRC Centre for Medical Engineering at the School of Biomedical Engineering and Imaging Sciences, Kings College London WT 203148/Z/16/Z. The work of Anglica Atehorta was supported in part by Colciencias-Colombia, Grant 647 (2015 call for National Ph.D. studies) and in part by Universit de Rennes 1. The work of Alejandro Debus was supported by the Santa Fe Science, Technology and Innovation Agency (AS ACTEI), Government of the Province of Santa Fe, through Project AC-00010-18, Resolution N 117/14.",,IEEE Journal of Biomedical and Health Informatics,,"Heart; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine",2021-09-03,2021,2021-09-03,2021-09,25,9,3541-3553,All OA, Green,Article,"Xue, Wufeng; Li, Jiahui; Hu, Zhiqiang; Kerfoot, Eric; Clough, James; Oksuz, Ilkay; Xu, Hao; Grau, Vicente; Guo, Fumin; Ng, Matthew; Li, Xiang; Li, Quanzheng; Liu, Lihong; Ma, Jin; Grinias, Elias; Tziritas, Georgios; Yan, Wenjun; Atehorta, Anglica; Garreau, Mireille; Jang, Yeonggul; Debus, Alejandro; Ferrante, Enzo; Yang, Guanyu; Hua, Tiancong; Li, Shuo","Xue, Wufeng (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, 518060, China; Department of Medical Imaging, Western University, London, N6A 3K7, ON, Canada); Li, Jiahui (Beijing University of Post and Telecommunication, Beijing, 100876, China); Hu, Zhiqiang (Peking University, Beijing, 100871, China); Kerfoot, Eric (School of Biomedical Engineering & Imaging Sciences, King's College London, London, SE5 9NU, U.K.); Clough, James (School of Biomedical Engineering & Imaging Sciences, King's College London, London, SE5 9NU, U.K.); Oksuz, Ilkay (School of Biomedical Engineering and Imaging Sciences, King's College London, London, SE59NU, U.K.; Computer Engineering Department, Istanbul Technical University, Turkey); Xu, Hao (Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, OX13QG, U.K.); Grau, Vicente (Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, OX13QG, U.K.); Guo, Fumin (Sunnybrook Research Institute, Department of Medical Biophysics, University of Toronto, Toronto, M5S 1A1, Canada); Ng, Matthew (Sunnybrook Research Institute, Department of Medical Biophysics, University of Toronto, Toronto, M5S 1A1, Canada); Li, Xiang (Department of Radiology, Massachusetts General Hospital, Boston, MA 02114, USA); Li, Quanzheng (Department of Radiology, Massachusetts General Hospital, Boston, MA 02114, USA); Liu, Lihong (Pingan Technology (Shenzhen) Company Ltd., Shenzhen, 518057, China); Ma, Jin (Pingan Technology (Shenzhen) Company Ltd., Shenzhen, 518057, China); Grinias, Elias (Department of Computer Science, University of Crete, Heraklion, 710 03, Greece); Tziritas, Georgios (Department of Computer Science, University of Crete, Heraklion, 710 03, Greece); Yan, Wenjun (Department of Electrical Engineering, Fudan University, Shanghai, 200433, China); Atehorta, Anglica (LTSI UMR 1099, Rennes, F-35000, France; Universidad Nacional de Colombia, Bogot, Colombia); Garreau, Mireille (LTSI UMR 1099, Rennes, F-35000, France); Jang, Yeonggul (Brain Korea 21 PLUS Project for Medical Science, Yonsei University, Seoul, Korea); Debus, Alejandro (Research Institute for Signals, Systems and Computational Intelligence, sinc(i), FICH-UNL/CONICET, Santa Fe, Argentina); Ferrante, Enzo (Brain Korea 21 PLUS Project for Medical Science, Yonsei University, Seoul, Korea); Yang, Guanyu (Centre de Recherche en Information Biom, dicale Sino-Fran, ais (CRIBs), Southeast University, Nanjing, China; LIST, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China); Hua, Tiancong (Centre de Recherche en Information Biom, dicale Sino-Fran, ais (CRIBs), Southeast University, Nanjing, China); Li, Shuo (Department of Medical Imaging, Western University, London, N6A 3K7, ON, Canada)","Xue, Wufeng (; Western University)","Xue, Wufeng (Western University); Li, Jiahui (Peking University); Hu, Zhiqiang (Peking University); Kerfoot, Eric (King's College London); Clough, James (King's College London); Oksuz, Ilkay (King's College London; Istanbul Technical University); Xu, Hao (University of Oxford); Grau, Vicente (University of Oxford); Guo, Fumin (University of Toronto); Ng, Matthew (University of Toronto); Li, Xiang (Massachusetts General Hospital); Li, Quanzheng (Massachusetts General Hospital); Liu, Lihong (); Ma, Jin (); Grinias, Elias (University of Crete); Tziritas, Georgios (University of Crete); Yan, Wenjun (Fudan University); Atehorta, Anglica (National University of Colombia); Garreau, Mireille (); Jang, Yeonggul (Yonsei University); Debus, Alejandro (); Ferrante, Enzo (Yonsei University); Yang, Guanyu (Southeast University; Southeast University); Hua, Tiancong (Southeast University); Li, Shuo (Western University)",6,6,0.96,5.62,https://hal.archives-ouvertes.fr/hal-03229066/file/Xue%20et%20al-2021-Left%20Ventricle%20Quantification%20Challenge.pdf,https://app.dimensions.ai/details/publication/pub.1136235916,42 Health Sciences, 4203 Health Services and Systems, 46 Information and Computing Sciences, 4601 Applied Computing,,,,,,,,
4788,pub.1140889029,10.3389/fcvm.2021.730316,34540923,PMC8446607,DeepStrain: A Deep Learning Workflow for the Automated Characterization of Cardiac Mechanics,"Myocardial strain analysis from cinematic magnetic resonance imaging (cine-MRI) data provides a more thorough characterization of cardiac mechanics than volumetric parameters such as left-ventricular ejection fraction, but sources of variation including segmentation and motion estimation have limited its wider clinical use. We designed and validated a fast, fully-automatic deep learning (DL) workflow to generate both volumetric parameters and strain measures from cine-MRI data consisting of segmentation and motion estimation convolutional neural networks. The final motion network design, loss function, and associated hyperparameters are the result of a thorough ad hoc implementation that we carefully planned specific for strain quantification, tested, and compared to other potential alternatives. The optimal configuration was trained using healthy and cardiovascular disease (CVD) subjects (n = 150). DL-based volumetric parameters were correlated (>0.98) and without significant bias relative to parameters derived from manual segmentations in 50 healthy and CVD test subjects. Compared to landmarks manually-tracked on tagging-MRI images from 15 healthy subjects, landmark deformation using DL-based motion estimates from paired cine-MRI data resulted in an end-point-error of 2.9 ± 1.5 mm. Measures of end-systolic global strain from these cine-MRI data showed no significant biases relative to a tagging-MRI reference method. On 10 healthy subjects, intraclass correlation coefficient for intra-scanner repeatability was good to excellent (>0.75) for all global measures and most polar map segments. In conclusion, we developed and evaluated the first end-to-end learning-based workflow for automated strain analysis from cine-MRI data to quantitatively characterize cardiac mechanics of healthy and CVD subjects.",We acknowledge the support of NVIDIA Corporation with the donation of the Titan X Pascal GPU used for this research.,,Frontiers in Cardiovascular Medicine,,,2021-09-03,2021,2021-09-03,,8,,730316,All OA, Gold,Article,"Morales, Manuel A.; van den Boomen, Maaike; Nguyen, Christopher; Kalpathy-Cramer, Jayashree; Rosen, Bruce R.; Stultz, Collin M.; Izquierdo-Garcia, David; Catana, Ciprian","Morales, Manuel A. (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA, United States); van den Boomen, Maaike (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Department of Radiology, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Cardiovascular Research Center, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States); Nguyen, Christopher (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Cardiovascular Research Center, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States); Kalpathy-Cramer, Jayashree (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States); Rosen, Bruce R. (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA, United States); Stultz, Collin M. (Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA, United States; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, United States; Division of Cardiology, Massachusetts General Hospital, Boston, MA, United States); Izquierdo-Garcia, David (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States; Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA, United States); Catana, Ciprian (Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States)","Catana, Ciprian (Harvard University; Massachusetts General Hospital)","Morales, Manuel A. (Harvard University; Massachusetts General Hospital; Harvard–MIT Division of Health Sciences and Technology); van den Boomen, Maaike (Harvard University; Massachusetts General Hospital; University Medical Center Groningen; University of Groningen; Harvard University; Massachusetts General Hospital); Nguyen, Christopher (Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital); Kalpathy-Cramer, Jayashree (Harvard University; Massachusetts General Hospital); Rosen, Bruce R. (Harvard University; Massachusetts General Hospital; Harvard–MIT Division of Health Sciences and Technology); Stultz, Collin M. (Harvard–MIT Division of Health Sciences and Technology; Massachusetts Institute of Technology; Massachusetts General Hospital); Izquierdo-Garcia, David (Harvard University; Massachusetts General Hospital; Harvard–MIT Division of Health Sciences and Technology); Catana, Ciprian (Harvard University; Massachusetts General Hospital)",8,8,2.0,7.01,https://www.frontiersin.org/articles/10.3389/fcvm.2021.730316/pdf,https://app.dimensions.ai/details/publication/pub.1140889029,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1011,pub.1140866840,10.48550/arxiv.2109.00903,,,Effect of the output activation function on the probabilities and errors  in medical image segmentation,"The sigmoid activation is the standard output activation function in binary
classification and segmentation with neural networks. Still, there exist a
variety of other potential output activation functions, which may lead to
improved results in medical image segmentation. In this work, we consider how
the asymptotic behavior of different output activation and loss functions
affects the prediction probabilities and the corresponding segmentation errors.
For cross entropy, we show that a faster rate of change of the activation
function correlates with better predictions, while a slower rate of change can
improve the calibration of probabilities. For dice loss, we found that the
arctangent activation function is superior to the sigmoid function.
Furthermore, we provide a test space for arbitrary output activation functions
in the area of medical image segmentation. We tested seven activation functions
in combination with three loss functions on four different medical image
segmentation tasks to provide a classification of which function is best suited
in this application scenario.",,,arXiv,,,2021-09-02,2021,,,,,,All OA, Green,Preprint,"Nieradzik, Lars; Scheuermann, Gerik; Saur, Dorothee; Gillmann, Christina","Nieradzik, Lars (); Scheuermann, Gerik (); Saur, Dorothee (); Gillmann, Christina ()",,"Nieradzik, Lars (); Scheuermann, Gerik (); Saur, Dorothee (); Gillmann, Christina ()",1,1,,0.82,,https://app.dimensions.ai/details/publication/pub.1140866840,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
866,pub.1139833159,10.1016/j.cviu.2021.103248,,,High-level prior-based loss functions for medical image segmentation: A survey,"Today, deep convolutional neural networks (CNNs) have demonstrated state of the art performance for supervised medical image segmentation, across various imaging modalities and tasks. Despite early success, segmentation networks may still generate anatomically aberrant segmentations, with holes or inaccuracies near the object boundaries. To mitigate this effect, recent research works have focused on incorporating spatial information or prior knowledge to enforce anatomically plausible segmentation. If the integration of prior knowledge in image segmentation is not a new topic in classical optimization approaches, it is today an increasing trend in CNN based image segmentation, as shown by the growing literature on the topic. In this survey, we focus on high level prior, embedded at the loss function level. We categorize the articles according to the nature of the prior: the object shape, size, topology, and the inter-regions constraints. We highlight strengths and limitations of current approaches, discuss the challenge related to the design and the integration of prior-based losses, and the optimization strategies, and draw future research directions.","The authors would like to acknowledge the National Council for Scientific Research of Lebanon (CNRS-L) and the Agence Française de la Francophonie (AUF) for granting a doctoral fellowship to Rosana El Jurdi, as well as the ANR (project APi, grant ANR-18-CE23-0014). This work is part of the DAISI project, co-financed by the European Union with the European Regional Development Fund (ERDF) and by the Normandy Region. This research was conducted as part of a collaboration with the Eindhoven university of Technology under the support of the PHC Van Gogh project WeSmile.",,Computer Vision and Image Understanding,,,2021-09,2021,,2021-09,210,,103248,All OA, Bronze,Article,"Jurdi, Rosana El; Petitjean, Caroline; Honeine, Paul; Cheplygina, Veronika; Abdallah, Fahed","Jurdi, Rosana El (Normandie Univ, INSA Rouen, UNIROUEN, UNIHAVRE, LITIS, Rouen, France; Université Libanaise, Hadath, Beyrouth, Lebanon); Petitjean, Caroline (Normandie Univ, INSA Rouen, UNIROUEN, UNIHAVRE, LITIS, Rouen, France); Honeine, Paul (Normandie Univ, INSA Rouen, UNIROUEN, UNIHAVRE, LITIS, Rouen, France); Cheplygina, Veronika (Computer Science Department, IT University of Copenhagen, Denmark; Medical Image Analysis group, Eindhoven University of Technology, Eindhoven, The Netherlands); Abdallah, Fahed (Université Libanaise, Hadath, Beyrouth, Lebanon; ICD, M2S, Université de technologie de Troyes, Troyes, France)","Jurdi, Rosana El (; Lebanese University)","Jurdi, Rosana El (Lebanese University); Petitjean, Caroline (); Honeine, Paul (); Cheplygina, Veronika (IT University of Copenhagen; Eindhoven University of Technology); Abdallah, Fahed (Lebanese University; University of Technology of Troyes)",18,18,,13.95,https://www.sciencedirect.com/science/article/am/pii/S1077314221000928,https://app.dimensions.ai/details/publication/pub.1139833159,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
5690,pub.1140771017,10.1016/j.cmpb.2021.106373,34562717,,A multiphase texture-based model of active contours assisted by a convolutional neural network for automatic CT and MRI heart ventricle segmentation,"BACKGROUND: Left and right ventricle automatic segmentation remains one of the more important tasks in computed aided diagnosis. Active contours have shown to be efficient for this task, however they often require user interaction to provide the initial position, which drives the tool substantially dependent on a prior knowledge and a manual process.
METHODS: We propose to overcome this limitation with a Convolutional Neural Network (CNN) to reach the assumed target locations. This is followed by a novel multiphase active contour method based on texture that enhances whole heart patterns leading to an accurate identification of distinct regions, mainly left (LV) and right ventricle (RV) for the purposes of this work.
RESULTS: Experiments reveal that the initial location and estimated shape provided by the CNN are of great concern for the subsequent active contour stage. We assessed our method on two short data sets with Dice scores of 93% (LV-CT), 91% (LV-MRI), 0.86% (RV-CT) and 0.85% (RV-MRI).
CONCLUSION: Our approach overcomes the performance of other techniques by means of a multiregion segmentation assisted by a CNN trained with a limited data set, a typical issue in medical imaging.","This work has been sponsored by UNAM grant PAPIIT IA103119, PAPIIT IV100420 and SECTEI grant 202/2019. Erik Carbajal-Degante thanks Consejo Nacional de Ciencia y Tecnologia (CONACYT) and FENOMEC 2021 for financial support.",,Computer Methods and Programs in Biomedicine,,"Heart Ventricles; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Radiography; Tomography, X-Ray Computed",2021-08-31,2021,2021-08-31,2021-11,211,,106373,Closed,Article,"Carbajal-Degante, Erik; Avendaño, Steve; Ledesma, Leonardo; Olveres, Jimena; Vallejo, Enrique; Escalante-Ramirez, Boris","Carbajal-Degante, Erik (Posgrado en Ciencia e Ingenieria de la Computación, Universidad Nacional Autónoma de Mexico, Mexico City, Mexico. Electronic address: eydgant@comunidad.unam.mx.); Avendaño, Steve (Facultad de Ciencias, Universidad Nacional Autónoma de Mexico, Mexico City, Mexico.); Ledesma, Leonardo (Posgrado en Ciencia e Ingenieria de la Computación, Universidad Nacional Autónoma de Mexico, Mexico City, Mexico.); Olveres, Jimena (Departamento de Procesamiento de Señales, Facultad de Ingenieria, Universidad Nacional Autónoma de Mexico, Mexico City, Mexico.); Vallejo, Enrique (Departamento de Cardiologia, Centro Medico ABC, Mexico City, Mexico.); Escalante-Ramirez, Boris (Departamento de Procesamiento de Señales, Facultad de Ingenieria, Universidad Nacional Autónoma de Mexico, Mexico City, Mexico. Electronic address: boris@unam.mx.)","Carbajal-Degante, Erik (National Autonomous University of Mexico)","Carbajal-Degante, Erik (National Autonomous University of Mexico); Avendaño, Steve (National Autonomous University of Mexico); Ledesma, Leonardo (National Autonomous University of Mexico); Olveres, Jimena (National Autonomous University of Mexico); Vallejo, Enrique (Centro Médico ABC); Escalante-Ramirez, Boris (National Autonomous University of Mexico)",1,1,0.36,0.67,,https://app.dimensions.ai/details/publication/pub.1140771017,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences, 4601 Applied Computing, 4603 Computer Vision and Multimedia Computation,,,,,,,,
1396,pub.1140742857,10.48550/arxiv.2108.12280,,,Stop Throwing Away Discriminators! Re-using Adversaries for Test-Time  Training,"Thanks to their ability to learn data distributions without requiring paired
data, Generative Adversarial Networks (GANs) have become an integral part of
many computer vision methods, including those developed for medical image
segmentation. These methods jointly train a segmentor and an adversarial mask
discriminator, which provides a data-driven shape prior. At inference, the
discriminator is discarded, and only the segmentor is used to predict label
maps on test images. But should we discard the discriminator? Here, we argue
that the life cycle of adversarial discriminators should not end after
training. On the contrary, training stable GANs produces powerful shape priors
that we can use to correct segmentor mistakes at inference. To achieve this, we
develop stable mask discriminators that do not overfit or catastrophically
forget. At test time, we fine-tune the segmentor on each individual test
instance until it satisfies the learned shape prior. Our method is simple to
implement and increases model performance. Moreover, it opens new directions
for re-using mask discriminators at inference. We release the code used for the
experiments at https://vios-s.github.io/adversarial-test-time-training.",,,arXiv,,,2021-08-26,2021,,,,,,All OA, Green,Preprint,"Valvano, Gabriele; Leo, Andrea; Tsaftaris, Sotirios A.","Valvano, Gabriele (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",,"Valvano, Gabriele (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140742857,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1007,pub.1140706110,10.48550/arxiv.2108.11926,,,Re-using Adversarial Mask Discriminators for Test-time Training under  Distribution Shifts,"Thanks to their ability to learn flexible data-driven losses, Generative
Adversarial Networks (GANs) are an integral part of many semi- and
weakly-supervised methods for medical image segmentation. GANs jointly optimise
a generator and an adversarial discriminator on a set of training data. After
training is complete, the discriminator is usually discarded, and only the
generator is used for inference. But should we discard discriminators? In this
work, we argue that training stable discriminators produces expressive loss
functions that we can re-use at inference to detect and \textit{correct}
segmentation mistakes. First, we identify key challenges and suggest possible
solutions to make discriminators re-usable at inference. Then, we show that we
can combine discriminators with image reconstruction costs (via decoders) to
endow a causal perspective to test-time training and further improve the model.
Our method is simple and improves the test-time performance of pre-trained
GANs. Moreover, we show that it is compatible with standard post-processing
techniques and it has the potential to be used for Online Continual Learning.
With our work, we open new research avenues for re-using adversarial
discriminators at inference. Our code is available at
https://vios-s.github.io/adversarial-test-time-training.",,,arXiv,,,2021-08-26,2021,,,,,,All OA, Green,Preprint,"Valvano, Gabriele; Leo, Andrea; Tsaftaris, Sotirios A.","Valvano, Gabriele (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",,"Valvano, Gabriele (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140706110,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
606,pub.1140773751,10.48550/arxiv.2108.12043,,,Learning Disentangled Representations in the Imaging Domain,"Disentangled representation learning has been proposed as an approach to
learning general representations even in the absence of, or with limited,
supervision. A good general representation can be fine-tuned for new target
tasks using modest amounts of data, or used directly in unseen domains
achieving remarkable performance in the corresponding task. This alleviation of
the data and annotation requirements offers tantalising prospects for
applications in computer vision and healthcare. In this tutorial paper, we
motivate the need for disentangled representations, revisit key concepts, and
describe practical building blocks and criteria for learning such
representations. We survey applications in medical imaging emphasising choices
made in exemplar key works, and then discuss links to computer vision
applications. We conclude by presenting limitations, challenges, and
opportunities.",,,arXiv,,,2021-08-26,2021,,,,,,All OA, Green,Preprint,"Liu, Xiao; Sanchez, Pedro; Thermos, Spyridon; O'Neil, Alison Q.; Tsaftaris, Sotirios A.","Liu, Xiao (); Sanchez, Pedro (); Thermos, Spyridon (); O'Neil, Alison Q. (); Tsaftaris, Sotirios A. ()",,"Liu, Xiao (); Sanchez, Pedro (); Thermos, Spyridon (); O'Neil, Alison Q. (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140773751,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
3492,pub.1140592380,10.1016/j.artmed.2021.102154,34531013,,EMONAS-Net: Efficient multiobjective neural architecture search using surrogate-assisted evolutionary algorithm for 3D medical image segmentation,"Deep learning plays a critical role in medical image segmentation. Nevertheless, manually designing a neural network for a specific segmentation problem is a very difficult and time-consuming task due to the massive hyperparameter search space, long training time and large volumetric data. Therefore, most designed networks are highly complex, task specific and over-parametrized. Recently, multiobjective neural architecture search (NAS) methods have been proposed to automate the design of accurate and efficient segmentation architectures. However, they only search for either the micro- or macro-structure of the architecture, do not use the information produced during the optimization process to increase the efficiency of the search, or do not consider the volumetric nature of medical images. In this work, we present EMONAS-Net, an Efficient MultiObjective NAS framework for 3D medical image segmentation that optimizes both the segmentation accuracy and size of the network. EMONAS-Net has two key components, a novel search space that considers the configuration of the micro- and macro-structure of the architecture and a Surrogate-assisted Multiobjective Evolutionary based Algorithm (SaMEA algorithm) that efficiently searches for the best hyperparameter values. The SaMEA algorithm uses the information collected during the initial generations of the evolutionary process to identify the most promising subproblems and select the best performing hyperparameter values during mutation to improve the convergence speed. Furthermore, a Random Forest surrogate model is incorporated to accelerate the fitness evaluation of the candidate architectures. EMONAS-Net is tested on the tasks of prostate segmentation from the MICCAI PROMISE12 challenge, hippocampus segmentation from the Medical Segmentation Decathlon challenge, and cardiac segmentation from the MICCAI ACDC challenge. In all the benchmarks, the proposed framework finds architectures that perform better or comparable with competing state-of-the-art NAS methods while being considerably smaller and reducing the architecture search time by more than 50%.",,"This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.",Artificial Intelligence in Medicine,,"Algorithms; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Male; Neural Networks, Computer",2021-08-24,2021,2021-08-24,2021-09,119,,102154,Closed,Article,"Baldeon Calisto, Maria; Lai-Yuen, Susana K","Baldeon Calisto, Maria (Departamento de Ingeniería Industrial, Instituto de Innovación en Productividad y Logística CATENA-USFQ, Colegio de Ciencias e Ingeniería, Universidad San Francisco de Quito, Diego de Robles s/n y Vía Interoceánica, Quito 170901, Ecuador.); Lai-Yuen, Susana K (Department of Industrial and Management Systems Engineering, University of South Florida, 4202 E. Fowler Avenue, Tampa, FL 33620, USA. Electronic address: laiyuen@usf.edu.)","Lai-Yuen, Susana K (University of South Florida)","Baldeon Calisto, Maria (Universidad San Francisco de Quito); Lai-Yuen, Susana K (University of South Florida)",11,11,0.17,8.71,,https://app.dimensions.ai/details/publication/pub.1140592380,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,,
1398,pub.1140520981,10.48550/arxiv.2108.07979,,,A New Bidirectional Unsupervised Domain Adaptation Segmentation  Framework,"Domain shift happens in cross-domain scenarios commonly because of the wide
gaps between different domains: when applying a deep learning model
well-trained in one domain to another target domain, the model usually performs
poorly. To tackle this problem, unsupervised domain adaptation (UDA) techniques
are proposed to bridge the gap between different domains, for the purpose of
improving model performance without annotation in the target domain.
Particularly, UDA has a great value for multimodal medical image analysis,
where annotation difficulty is a practical concern. However, most existing UDA
methods can only achieve satisfactory improvements in one adaptation direction
(e.g., MRI to CT), but often perform poorly in the other (CT to MRI), limiting
their practical usage. In this paper, we propose a bidirectional UDA (BiUDA)
framework based on disentangled representation learning for equally competent
two-way UDA performances. This framework employs a unified domain-aware pattern
encoder which not only can adaptively encode images in different domains
through a domain controller, but also improve model efficiency by eliminating
redundant parameters. Furthermore, to avoid distortion of contents and patterns
of input images during the adaptation process, a content-pattern consistency
loss is introduced. Additionally, for better UDA segmentation performance, a
label consistency strategy is proposed to provide extra supervision by
recomposing target-domain-styled images and corresponding source-domain
annotations. Comparison experiments and ablation studies conducted on two
public datasets demonstrate the superiority of our BiUDA framework to current
state-of-the-art UDA methods and the effectiveness of its novel designs. By
successfully addressing two-way adaptations, our BiUDA framework offers a
flexible solution of UDA techniques to the real-world scenario.",,,arXiv,,,2021-08-18,2021,,,,,,All OA, Green,Preprint,"Ning, Munan; Bian, Cheng; Wei, Dong; Yuan, Chenglang; Wang, Yaohua; Guo, Yang; Ma, Kai; Zheng, Yefeng","Ning, Munan (); Bian, Cheng (); Wei, Dong (); Yuan, Chenglang (); Wang, Yaohua (); Guo, Yang (); Ma, Kai (); Zheng, Yefeng ()",,"Ning, Munan (); Bian, Cheng (); Wei, Dong (); Yuan, Chenglang (); Wang, Yaohua (); Guo, Yang (); Ma, Kai (); Zheng, Yefeng ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140520981,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,
3938,pub.1140347072,10.1016/j.artmed.2021.102140,34531009,,Neural network-based left ventricle geometry prediction from CMR images with application in biomechanics,"Combining biomechanical modelling of left ventricular (LV) function and dysfunction with cardiac magnetic resonance (CMR) imaging has the potential to improve the prognosis of patient-specific cardiovascular disease risks. Biomechanical studies of LV function in three dimensions usually rely on a computerized representation of the LV geometry based on finite element discretization, which is essential for numerically simulating in vivo cardiac dynamics. Detailed knowledge of the LV geometry is also relevant for various other clinical applications, such as assessing the LV cavity volume and wall thickness. Accurately and automatically reconstructing personalized LV geometries from conventional CMR images with minimal manual intervention is still a challenging task, which is a pre-requisite for any subsequent automated biomechanical analysis. We propose a deep learning-based automatic pipeline for predicting the three-dimensional LV geometry directly from routinely-available CMR cine images, without the need to manually annotate the ventricular wall. Our framework takes advantage of a low-dimensional representation of the high-dimensional LV geometry based on principal component analysis. We analyze how the inference of myocardial passive stiffness is affected by using our automatically generated LV geometries instead of manually generated ones. These insights will inform the development of statistical emulators of LV dynamics to avoid computationally expensive biomechanical simulations. Our proposed framework enables accurate LV geometry reconstruction, outperforming previous approaches by delivering a reconstruction error 50% lower than reported in the literature. We further demonstrate that for a nonlinear cardiac mechanics model, using our reconstructed LV geometries instead of manually extracted ones only moderately affects the inference of passive myocardial stiffness described by an anisotropic hyperelastic constitutive law. The developed methodological framework has the potential to make an important step towards personalized medicine by eliminating the need for time consuming and costly manual operations. In addition, our method automatically maps the CMR scan into a low-dimensional representation of the LV geometry, which constitutes an important stepping stone towards the development of an LV geometry-heterogeneous emulator.",,"We would like to thank the funding from EPSRC (EP/S030875/1, EP/S020950/1, EP/N014642/1, EP/R018634/1, EP/T017899/1). DH is supported by a grant from the Royal Society of Edinburgh, award no. 62335. CB acknowledges a grant from the British Heart Foundation (RE/18/6134217).",Artificial Intelligence in Medicine,,"Biomechanical Phenomena; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Neural Networks, Computer; Ventricular Function, Left",2021-08-11,2021,2021-08-11,2021-09,119,,102140,All OA, Hybrid,Article,"Romaszko, Lukasz; Borowska, Agnieszka; Lazarus, Alan; Dalton, David; Berry, Colin; Luo, Xiaoyu; Husmeier, Dirk; Gao, Hao","Romaszko, Lukasz (School of Mathematics and Statistics, Univeristy of Glasgow, Glasgow, UK.); Borowska, Agnieszka (School of Mathematics and Statistics, Univeristy of Glasgow, Glasgow, UK.); Lazarus, Alan (School of Mathematics and Statistics, Univeristy of Glasgow, Glasgow, UK.); Dalton, David (School of Mathematics and Statistics, Univeristy of Glasgow, Glasgow, UK.); Berry, Colin (British Heart Foundation Glasgow Cardiovascular Research Centre, Institute of Cardiovascular and Medical Sciences, University of Glasgow, Glasgow, UK.); Luo, Xiaoyu (School of Mathematics and Statistics, Univeristy of Glasgow, Glasgow, UK.); Husmeier, Dirk (School of Mathematics and Statistics, Univeristy of Glasgow, Glasgow, UK.); Gao, Hao (School of Mathematics and Statistics, Univeristy of Glasgow, Glasgow, UK. Electronic address: hao.gao@glasgow.ac.uk.)","Gao, Hao (University of Glasgow)","Romaszko, Lukasz (University of Glasgow); Borowska, Agnieszka (University of Glasgow); Lazarus, Alan (University of Glasgow); Dalton, David (University of Glasgow); Berry, Colin (University of Glasgow); Luo, Xiaoyu (University of Glasgow); Husmeier, Dirk (University of Glasgow); Gao, Hao (University of Glasgow)",6,6,0.76,,https://doi.org/10.1016/j.artmed.2021.102140,https://app.dimensions.ai/details/publication/pub.1140347072,46 Information and Computing Sciences,,,,,,,,,,,
1133,pub.1140379300,10.48550/arxiv.2108.04914,,,Optimal MRI Undersampling Patterns for Ultimate Benefit of Medical  Vision Tasks,"To accelerate MRI, the field of compressed sensing is traditionally concerned
with optimizing the image quality after a partial undersampling of the
measurable $\textit{k}$-space. In our work, we propose to change the focus from
the quality of the reconstructed image to the quality of the downstream image
analysis outcome. Specifically, we propose to optimize the patterns according
to how well a sought-after pathology could be detected or localized in the
reconstructed images. We find the optimal undersampling patterns in
$\textit{k}$-space that maximize target value functions of interest in
commonplace medical vision problems (reconstruction, segmentation, and
classification) and propose a new iterative gradient sampling routine
universally suitable for these tasks. We validate the proposed MRI acceleration
paradigm on three classical medical datasets, demonstrating a noticeable
improvement of the target metrics at the high acceleration factors (for the
segmentation problem at $\times$16 acceleration, we report up to 12%
improvement in Dice score over the other undersampling patterns).",,,arXiv,,,2021-08-10,2021,,,,,,All OA, Green,Preprint,"Razumov, Artem; Rogov, Oleg Y.; Dylov, Dmitry V.","Razumov, Artem (); Rogov, Oleg Y. (); Dylov, Dmitry V. ()",,"Razumov, Artem (); Rogov, Oleg Y. (); Dylov, Dmitry V. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140379300,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,
1574,pub.1140246728,10.1007/s10489-021-02720-9,,,MMNet: A multi-scale deep learning network for the left ventricular segmentation of cardiac MRI images,"With the development of deep learning network models, the automatic segmentation of medical images is becoming increasingly popular. Left ventricular cavity segmentation is an important step in the diagnosis of cardiac disease, but post-processing segmentation is a time-consuming and challenging task. That is why a fully automated segmentation method can assist specialists in increasing their efficiency. Inspired by the power of deep neural networks, a multi-scale multi-skip connection network (MMNet) model is proposed to fully automate the left ventricular segmentation of cardiac magnetic resonance imaging (MRI) images; this model is simple and efficient and has high segmentation accuracy without pre-detecting left ventricular localization. MMNet redesigns the classic encoder and decoder to take advantage of multi-scale feature information, effectively solving the problem of difficult segmentation due to blurred left ventricular edge information and the low accuracy of end-systolic segmentation of the cardiac area. In the model encoding stage, a multi-scale feature fusion module applying dilated convolution is proposed to obtain richer semantic information from different perceptual fields. The decoding stage reconstructs the full-size skip connection structure to make full use of the feature information obtained from different layers for contextual semantic information fusion. At the same time, a pre-activation module is used before each weighting layer to prevent overfitting phenomena from arising. The experimental results demonstrate that the proposed model has better segmentation performance than advanced benchmark models. Ablation experiments show that the proposed modules are effective at improving segmentation results. Therefore, MMNet is a promising approach for the left ventricular fully automated segmentation.",,"This work was supported in part by the National Natural Science Foundation of China[Grant No. 61976126], Shandong Nature Science Foundation of China [Grant No. ZR2017MF054, ZR2019MF003, ZR2020MF044].",Applied Intelligence,,,2021-08-06,2021,2021-08-06,2022-03,52,5,5225-5240,Closed,Article,"Wang, Ziyue; Peng, Yanjun; Li, Dapeng; Guo, Yanfei; Zhang, Bin","Wang, Ziyue (College of Computer Science and Engineering, Shandong University of Science and Technology, 266590, Qingdao, Shandong, China); Peng, Yanjun (College of Computer Science and Engineering, Shandong University of Science and Technology, 266590, Qingdao, Shandong, China; Shandong Province Key Laboratory of Wisdom Mining Information Technology, Shandong University of Science and Technology, 266590, Qingdao, Shandong, China); Li, Dapeng (College of Computer Science and Engineering, Shandong University of Science and Technology, 266590, Qingdao, Shandong, China); Guo, Yanfei (College of Computer Science and Engineering, Shandong University of Science and Technology, 266590, Qingdao, Shandong, China); Zhang, Bin (College of Computer Science and Engineering, Shandong University of Science and Technology, 266590, Qingdao, Shandong, China)","Peng, Yanjun (Shandong University of Science and Technology; Shandong University of Science and Technology)","Wang, Ziyue (Shandong University of Science and Technology); Peng, Yanjun (Shandong University of Science and Technology; Shandong University of Science and Technology); Li, Dapeng (Shandong University of Science and Technology); Guo, Yanfei (Shandong University of Science and Technology); Zhang, Bin (Shandong University of Science and Technology)",9,9,,7.12,,https://app.dimensions.ai/details/publication/pub.1140246728,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,,
1173,pub.1140188553,10.1080/02564602.2021.1955760,,,Encoder Modified U-Net and Feature Pyramid Network for Multi-class Segmentation of Cardiac Magnetic Resonance Images,"Cardiovascular diseases are leading cause of death worldwide. Timely and accurate detection of disease is required to reduce load on healthcare system and number of deaths. For this, accurate and fast segmentation of Cardiac Magnetic Resonance Images is required. In this study, we propose to develop a transfer learning-based end-to-end trainable method to segment left ventricle, myocardium, and right ventricle of heart. In the presented work, Feature Pyramid Network and U-Net architecture are used where encoder is modified with networks like DenseNet, ResNet, and VGG. Performance evaluation is done using dice score, Jaccard index, and Hausdorff distance according to which U-Net with VGG encoder gives best results. The mean dice score obtained is 0.958, 0.914, and 93.4 for LV, MYO, and RV respectively. Also, Hausdorff distance for the proposed methods is 1.69, 2.28, and 1.90 for LV, MYO, and RV respectively. The p-value for the obtained results is less than 0.05 (=0.0313) which shows the statistical significance of the proposed method. This automatic end-to-end trainable computer-based method requires less time and resources while giving better results than state-of-art methods. It can save the time of medical practitioners in analyzing cardiac diseases.",,,IETE Technical Review,,,2021-08-04,2021,2021-08-04,2022-09-03,39,5,1092-1104,Closed,Article,"Sharan, Taresh Sarvesh; Tripathi, Sumit; Sharma, Shiru; Sharma, Neeraj","Sharan, Taresh Sarvesh (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India); Tripathi, Sumit (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India; Graphic Era Deemed to be University, Dehradun, Uttarakhand, 248 002, India); Sharma, Shiru (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India); Sharma, Neeraj (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India)","Tripathi, Sumit (Indian Institute of Technology BHU; Graphic Era University)","Sharan, Taresh Sarvesh (Indian Institute of Technology BHU); Tripathi, Sumit (Indian Institute of Technology BHU; Graphic Era University); Sharma, Shiru (Indian Institute of Technology BHU); Sharma, Neeraj (Indian Institute of Technology BHU)",15,15,,11.49,,https://app.dimensions.ai/details/publication/pub.1140188553,46 Information and Computing Sciences, 4605 Data Management and Data Science,3 Good Health and Well Being,,,,,,,,,,
6757,pub.1140166146,10.1155/2021/1678123,34394333,PMC8355973,Sports Action Recognition Based on GB-BP Neural Network and Big Data Analysis,"In recent years, the application of the gradient boosting-back propagation (GB-BP) neural network algorithm in many industries has brought huge benefits, so how to combine the GB-BP neural network algorithm with sports has become a research hotspot. Based on this, this paper studies the application of the GB-BP neural network algorithm in wrestling, designs the sports athletes action recognition and classification model based on the GB-BP neural network algorithm, first analyzes the research status of wrestling action recognition, and then optimizes and improves the shortcomings of action recognition and big data analysis technology. The GB-BP neural network algorithm can realize the accurate recognition and classification of wrestlers' training actions and carry out big data mining analysis with known action recognition, so as to achieve accurate classification. The experimental results show that the model can play a good role in wrestling and effectively improve the efficiency of wrestlers in training.",This work was supported by the University Philosophy and Social Science Research Project in Jiangsu Province (2019SJA0081).,,Computational Intelligence and Neuroscience,,"Athletes; Data Analysis; Humans; Neural Networks, Computer; Sports; Wrestling",2021-08-02,2021,2021-08-02,2021-08-02,2021,,1678123,All OA, Gold,Article,"Wang, Lidong; Qiu, Kai; Li, Wang","Wang, Lidong (School of Physical Education, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu 210023, China, njupt.edu.cn); Qiu, Kai (School of Physical Education, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu 210023, China, njupt.edu.cn); Li, Wang (School of Physical Education, Huaiyin Institute of Technology, Huai’an, Jiangsu 223003, China, hyit.edu.cn)","Wang, Lidong (Nanjing University of Posts and Telecommunications)","Wang, Lidong (Nanjing University of Posts and Telecommunications); Qiu, Kai (Nanjing University of Posts and Telecommunications); Li, Wang (Huaiyin Institute of Technology)",3,3,,2.37,https://downloads.hindawi.com/journals/cin/2021/1678123.pdf,https://app.dimensions.ai/details/publication/pub.1140166146,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
1213,pub.1137701971,10.1016/j.image.2021.116303,,,Automatic segmentation of left and right ventricles in cardiac MRI using 3D-ASM and deep learning,"Segmentation of the left and right ventricles in cardiac MRI (Magnetic Resonance Imaging) is a prerequisite step for evaluating global and regional cardiac function. This work presents a novel and robust schema for MRI segmentation by combining the advantages of deep learning localization and 3D-ASM (3D Active Shape Model) restriction without any user interaction. Three fundamental techniques are exploited: (1) manual 2D contours are used to build distance maps to get 3D ground truth shape, (2) derived right ventricle points are employed to rotate the coarse initial shape for a refined bi-ventricle initial estimation, (3) segmentation results from deep learning are utilised to build distance maps for the 3D-ASM matching process to help image intensity modelling. The datasets used for experimenting the cine MRI data are 1000 cases from UK Biobank, 500 subjects are selected to train CNN (Convolution Neural Network) parameters, and the remaining 500 cases are adopted for validation. Specifically, cases are used to rebuild point distribution and image intensity models, and also utilized to train CNN. In addition, the left 500 cases are used to perform the validation experiments. For the segmentation of the RV (Right Ventricle) endocardial contour, LV (Left Ventricle) endo- and epicardial contours, overlap, Jaccard similarity index, Point-to-surface errors and cardiac functional parameters are calculated. Experimental results show that the proposed method has advantages over the previous approaches.","This research has been conducted using the UK Biobank Resource under Applications 11350. The authors are grateful to all UK Biobank participants and staff. AFF acknowledges support from the Royal Academy of Engineering Chair in Emerging Technologies Scheme (INSILEX, CiET1819/19), Royal Society International Exchanges Programme (CROSSLINK, IEC/NSFC/201380) and EPSRC-funded Grow MedTech (CardioX, POC041) and Pengcheng Visiting Scholars Programme from the Shenzhen Government. The National Natural Science Foundation of China supported this study (No. 62076257, 61773409 and 61976227), China Scholarship Council (No. 201508420005), Fundamental Research Funds for the Central Universities (No. CZY20039), and Applied Basic Research Programme of Wuhan (No. 2020020601012239). The authors thank Dr M Pereanez, Dr R Attar, and M Hoz from Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB) at the University of Leeds throughout this work.",,Signal Processing Image Communication,,,2021-08,2021,,2021-08,96,,116303,All OA, Green,Article,"Hu, Huaifei; Pan, Ning; Liu, Haihua; Liu, Liman; Yin, Tailang; Tu, Zhigang; Frangi, Alejandro F.","Hu, Huaifei (College of Biomedical Engineering, South Central University for Nationalities, Wuhan 430074, China; Hubei Key Laboratory of Medical Information Analysis and Tumor Diagnosis Treatment, Wuhan 430074, China; Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan 430074, China); Pan, Ning (College of Biomedical Engineering, South Central University for Nationalities, Wuhan 430074, China; Hubei Key Laboratory of Medical Information Analysis and Tumor Diagnosis Treatment, Wuhan 430074, China; Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan 430074, China); Liu, Haihua (College of Biomedical Engineering, South Central University for Nationalities, Wuhan 430074, China; Hubei Key Laboratory of Medical Information Analysis and Tumor Diagnosis Treatment, Wuhan 430074, China; Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan 430074, China); Liu, Liman (College of Biomedical Engineering, South Central University for Nationalities, Wuhan 430074, China; Hubei Key Laboratory of Medical Information Analysis and Tumor Diagnosis Treatment, Wuhan 430074, China; Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan 430074, China); Yin, Tailang (Reproductive Medicine Center, Renmin Hospital of Wuhan University, Wuhan, Hubei 430060, China); Tu, Zhigang (State Key Laboratory of Information Engineering in Surveying, Mapping and Remote sensing, Wuhan University, 430079, Wuhan, China); Frangi, Alejandro F. (Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, UK; Biomedical Imaging Sciences Department, Leeds Institute for Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, UK; Medical Imaging Research Centre, Cardiovascular Sciences Department, KU Leuven, Leuven, Belgium; Medical Imaging Research Centre, Electrical Engineering Department, KU Leuven, Leuven, Belgium)","Liu, Haihua (South Central University for Nationalities; ; State Ethnic Affairs Commission); Yin, Tailang (Renmin Hospital of Wuhan University); Tu, Zhigang (Wuhan University); Frangi, Alejandro F. (University of Leeds; University of Leeds; KU Leuven; KU Leuven)","Hu, Huaifei (South Central University for Nationalities; State Ethnic Affairs Commission); Pan, Ning (South Central University for Nationalities; State Ethnic Affairs Commission); Liu, Haihua (South Central University for Nationalities; State Ethnic Affairs Commission); Liu, Liman (South Central University for Nationalities; State Ethnic Affairs Commission); Yin, Tailang (Renmin Hospital of Wuhan University); Tu, Zhigang (Wuhan University); Frangi, Alejandro F. (University of Leeds; University of Leeds; KU Leuven; KU Leuven)",3,3,,2.48,https://eprints.whiterose.ac.uk/178618/1/Seg%20L%20R%20V%20in%20cardiac%20MRI%20using%203D%20ASM%20and%20DL%20Manuscript-05-13-2021_last.pdf,https://app.dimensions.ai/details/publication/pub.1137701971,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,
5332,pub.1137256031,10.1109/tmi.2021.3073381,33856986,PMC8376223,Cine Cardiac MRI Motion Artifact Reduction Using a Recurrent Neural Network,"Cine cardiac magnetic resonance imaging (MRI) is widely used for the diagnosis of cardiac diseases thanks to its ability to present cardiovascular features in excellent contrast. As compared to computed tomography (CT), MRI, however, requires a long scan time, which inevitably induces motion artifacts and causes patients' discomfort. Thus, there has been a strong clinical motivation to develop techniques to reduce both the scan time and motion artifacts. Given its successful applications in other medical imaging tasks such as MRI super-resolution and CT metal artifact reduction, deep learning is a promising approach for cardiac MRI motion artifact reduction. In this paper, we propose a novel recurrent generative adversarial network model for cardiac MRI motion artifact reduction. This model utilizes bi-directional convolutional long short-term memory (ConvLSTM) and multi-scale convolutions to improve the performance of the proposed network, in which bi-directional ConvLSTMs handle long-range temporal features while multi-scale convolutions gather both local and global features. We demonstrate a decent generalizability of the proposed method thanks to the novel architecture of our deep network that captures the essential relationship of cardiovascular dynamics. Indeed, our extensive experiments show that our method achieves better image quality for cine cardiac MRI images than existing state-of-the-art methods. In addition, our method can generate reliable missing intermediate frames based on their adjacent frames, improving the temporal resolution of cine cardiac MRI sequences.","This work was supported in part by the National Institutes of Health under Award R01EB026646 and Award CA233888, and National heart, lung, and blood institute of the National Institutes of Health under Award R01HL151561, and in part by Shanghai Sailing Program (No. 21YF1402800), Shanghai Municipal of Science and Technology Project (No. 20JC1419500), Shanghai Municipal Science and Technology Major Project (No. 2018SHZDZX01), and ZhangJiang Lab",,IEEE Transactions on Medical Imaging,,"Artifacts; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Motion; Neural Networks, Computer",2021-07-30,2021,2021-07-30,2021-08,40,8,2170-2181,All OA, Green,Article,"Lyu, Qing; Shan, Hongming; Xie, Yibin; Kwan, Alan C.; Otaki, Yuka; Kuronuma, Keiichiro; Li, Debiao; Wang, Ge","Lyu, Qing (Biomedical Imaging Center, Department of Biomedical Engineering, School of Engineering, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA; Center for Biotechnology and Interdisciplinary Studies, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA); Shan, Hongming (Biomedical Imaging Center, Department of Biomedical Engineering, School of Engineering, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA; Center for Biotechnology and Interdisciplinary Studies, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA; Institute of Science and Technology for Brain-inspired Intelligence, Fudan University, Shanghai, 200433, China; MOE Frontiers Center for Brain Science, Fudan University, Shanghai, 200433, China; Shanghai Center for Brain Science and Brain-Inspired Technology, Fudan University, Shanghai, 201210, China); Xie, Yibin (Biomedical Imaging Research Institute, Cedars-Sinai Medical Center, Los Angeles, CA, 90048, USA); Kwan, Alan C. (Department of Cardiology, Smidt Heart Institute, Los Angeles, CA, 90048, USA; Department of Biomedical Sciences, Biomedical Imaging Research Institute, Los Angeles, CA, 90048, USA; Department of Imaging, Cedars Sinai Medical Center, Los Angeles, CA, 90048, USA); Otaki, Yuka (Department of Imaging, Cedars Sinai Medical Center, Los Angeles, CA, 90048, USA); Kuronuma, Keiichiro (Department of Imaging, Cedars Sinai Medical Center, Los Angeles, CA, 90048, USA); Li, Debiao (Biomedical Imaging Research Institute, Cedars-Sinai Medical Center, Los Angeles, CA, 90048, USA; Department of Medicine, University of California, Los Angeles, CA, 90095, USA; Department of Bioengineering, University of California, Los Angeles, CA, 90095, USA); Wang, Ge (Biomedical Imaging Center, Department of Biomedical Engineering, School of Engineering, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA; Center for Biotechnology and Interdisciplinary Studies, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA)","Li, Debiao (Cedars-Sinai Medical Center; University of California, Los Angeles; University of California, Los Angeles)","Lyu, Qing (Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute); Shan, Hongming (Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute; Fudan University; Fudan University; Fudan University); Xie, Yibin (Cedars-Sinai Medical Center); Kwan, Alan C. (Cedars-Sinai Medical Center); Otaki, Yuka (Cedars-Sinai Medical Center); Kuronuma, Keiichiro (Cedars-Sinai Medical Center); Li, Debiao (Cedars-Sinai Medical Center; University of California, Los Angeles; University of California, Los Angeles); Wang, Ge (Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute)",18,18,0.96,14.73,http://arxiv.org/pdf/2006.12700,https://app.dimensions.ai/details/publication/pub.1137256031,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4769,pub.1136791509,10.1109/tmi.2021.3069634,33784616,,Learning to Segment From Scribbles Using Multi-Scale Adversarial Attention Gates,"Large, fine-grained image segmentation datasets, annotated at pixel-level, are difficult to obtain, particularly in medical imaging, where annotations also require expert knowledge. Weakly-supervised learning can train models by relying on weaker forms of annotation, such as scribbles. Here, we learn to segment using scribble annotations in an adversarial game. With unpaired segmentation masks, we train a multi-scale GAN to generate realistic segmentation masks at multiple resolutions, while we use scribbles to learn their correct position in the image. Central to the model's success is a novel attention gating mechanism, which we condition with adversarial signals to act as a shape prior, resulting in better object localization at multiple scales. Subject to adversarial conditioning, the segmentor learns attention maps that are semantic, suppress the noisy activations outside the objects, and reduce the vanishing gradient problem in the deeper layers of the segmentor. We evaluated our model on several medical (ACDC, LVSC, CHAOS) and non-medical (PPSS) datasets, and we report performance levels matching those achieved by models trained with fully annotated segmentation masks. We also demonstrate extensions in a variety of settings: semi-supervised learning; combining multiple scribble sources (a crowdsourcing scenario) and multi-task learning (combining scribble and mask supervision). We release expert-made scribble annotations for the ACDC dataset, and the code used for the experiments, at https://vios-s.github.io/multiscale-adversarial-attention-gates.",This work was supported by the Erasmus+ Programme of the European Union. The author Sotirios A. Tsaftaris acknowledges the support of the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme. They also thank NVIDIA for donating the GPU used for this research.,,IEEE Transactions on Medical Imaging,,"Attention; Humans; Image Processing, Computer-Assisted; Semantics; Supervised Machine Learning",2021-07-30,2021,2021-07-30,2021-08,40,8,1990-2001,All OA, Green,Article,"Valvano, Gabriele; Leo, Andrea; Tsaftaris, Sotirios A.","Valvano, Gabriele (IMT School for Advanced Studies Lucca, 55100, Lucca, Italy; School of Engineering, University of Edinburgh, Edinburgh, EH9 3FB, U.K.); Leo, Andrea (IMT School for Advanced Studies Lucca, 55100, Lucca, Italy); Tsaftaris, Sotirios A. (School of Engineering, University of Edinburgh, Edinburgh, EH9 3FB, U.K.)","Valvano, Gabriele (IMT Institute for Advanced Studies Lucca; University of Edinburgh)","Valvano, Gabriele (IMT Institute for Advanced Studies Lucca; University of Edinburgh); Leo, Andrea (IMT Institute for Advanced Studies Lucca); Tsaftaris, Sotirios A. (University of Edinburgh)",28,28,1.43,22.92,https://www.pure.ed.ac.uk/ws/files/206257769/205988210_AFPRM.pdf,https://app.dimensions.ai/details/publication/pub.1136791509,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1133,pub.1140052522,10.48550/arxiv.2107.13741,,,Self-Paced Contrastive Learning for Semi-supervised Medical Image  Segmentation with Meta-labels,"Pre-training a recognition model with contrastive learning on a large dataset
of unlabeled data has shown great potential to boost the performance of a
downstream task, e.g., image classification. However, in domains such as
medical imaging, collecting unlabeled data can be challenging and expensive. In
this work, we propose to adapt contrastive learning to work with meta-label
annotations, for improving the model's performance in medical image
segmentation even when no additional unlabeled data is available. Meta-labels
such as the location of a 2D slice in a 3D MRI scan or the type of device used,
often come for free during the acquisition process. We use the meta-labels for
pre-training the image encoder as well as to regularize a semi-supervised
training, in which a reduced set of annotated data is used for training.
Finally, to fully exploit the weak annotations, a self-paced learning approach
is used to help the learning and discriminate useful labels from noise. Results
on three different medical image segmentation datasets show that our approach:
i) highly boosts the performance of a model trained on a few scans, ii)
outperforms previous contrastive and semi-supervised approaches, and iii)
reaches close to the performance of a model trained on the full data.",,,arXiv,,,2021-07-29,2021,,,,,,All OA, Green,Preprint,"Peng, Jizong; Wang, Ping; Desrosiers, Chrisitian; Pedersoli, Marco","Peng, Jizong (); Wang, Ping (); Desrosiers, Chrisitian (); Pedersoli, Marco ()",,"Peng, Jizong (); Wang, Ping (); Desrosiers, Chrisitian (); Pedersoli, Marco ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140052522,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1512,pub.1140037777,10.48550/arxiv.2107.13542,,,TEDS-Net: Enforcing Diffeomorphisms in Spatial Transformers to Guarantee  Topology Preservation in Segmentations,"Accurate topology is key when performing meaningful anatomical segmentations,
however, it is often overlooked in traditional deep learning methods. In this
work we propose TEDS-Net: a novel segmentation method that guarantees accurate
topology. Our method is built upon a continuous diffeomorphic framework, which
enforces topology preservation. However, in practice, diffeomorphic fields are
represented using a finite number of parameters and sampled using methods such
as linear interpolation, violating the theoretical guarantees. We therefore
introduce additional modifications to more strictly enforce it. Our network
learns how to warp a binary prior, with the desired topological
characteristics, to complete the segmentation task. We tested our method on
myocardium segmentation from an open-source 2D heart dataset. TEDS-Net
preserved topology in 100% of the cases, compared to 90% from the U-Net,
without sacrificing on Hausdorff Distance or Dice performance. Code will be
made available at: www.github.com/mwyburd/TEDS-Net",,,arXiv,,,2021-07-28,2021,,,,,,All OA, Green,Preprint,"Wyburd, Madeleine K.; Dinsdale, Nicola K.; Namburete, Ana I. L.; Jenkinson, Mark","Wyburd, Madeleine K. (); Dinsdale, Nicola K. (); Namburete, Ana I. L. (); Jenkinson, Mark ()",,"Wyburd, Madeleine K. (); Dinsdale, Nicola K. (); Namburete, Ana I. L. (); Jenkinson, Mark ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140037777,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
955,pub.1139989988,10.1007/s11042-021-11155-w,,,Two-stage active contour model for robust left ventricle segmentation in cardiac MRI,"Segmentation of the endocardial and epicardial boundaries on 3D cardiac magnetic resonance images plays a vital role in the assessment of ejection fraction, wall thickness, end-diastolic volume, end-systolic volume, and stroke volume. Accurate segmentation is significantly challenged by intensity inhomogeneity artifacts, low contrast, and ill-defined organ/region boundaries. We propose a two stage hybrid active contour model for robust left ventricle (LV) segmentation accompanied with a new initialization technique based on prior of the LV structure. The proposed approach includes a new level set method using local, spatially-varying, statistical model for image intensity, an edge-based term to capture region boundaries, and regularization functionals for smooth evolution of the segmenting curve and to avoid expensive reinitialization. Moreover, convex hull interpolation is employed to include the papillary muscles within the endocardial boundary for a refined depiction of LV geometry. The accuracy and robustness of the proposed algorithm were assessed using York, Sunnybrook and ACDC datasets (33 + 45 + 100 subjects), with a wide spectrum of normal hearts, congenital heart diseases, and cardiac dysfunction. Experiments showed that the proposed approach significantly outperformed other active contour methods (overall Dice score 0.90), generating accurate segmentations of left ventricular outflow tract (Dice score 0.91), apical slices (Dice score 0.82), systolic and diastolic phases (Dice scores 0.92 and 0.88 respectively). The percentage of good contours was about 92% and the average perpendicular distance was less than 1.8 mm. Automatically generated segmentation yielded superior estimates of ejection fraction with an R2 ≥ 0.937. Furthermore, the proposed method was validated using 100 cine MRI cases consisting of five different cardiac classes from the ACDC MICCAI 2017 challenge. The proposed algorithm yielded superior segmentation performance compared with existing active contour models and other state-of-the-art cardiac segmentation techniques, with extensive validation on three standard cardiac datasets, with different cardiac pathologies and phases.","This work was supported by fellowship, awarded by National University of Computer and Emerging Sciences, Lahore. We are grateful to [8, 9, 17, 23, 60] for sharing their codes.",,Multimedia Tools and Applications,,,2021-07-28,2021,2021-07-28,2021-09,80,21-23,32245-32271,Closed,Article,"Tamoor, Maria; Younas, Irfan; Mohy-ud-Din, Hassan","Tamoor, Maria (Department of Computer Science, National University of Computer and Emerging Sciences, Lahore, Pakistan); Younas, Irfan (Department of Computer Science, National University of Computer and Emerging Sciences, Lahore, Pakistan); Mohy-ud-Din, Hassan (Department of Electrical Engineering, Syed Babar Ali School of Science and Engineering, LUMS, 54792, Lahore, Pakistan)","Mohy-ud-Din, Hassan (Lahore University of Management Sciences)","Tamoor, Maria (National University of Computer and Emerging Sciences); Younas, Irfan (National University of Computer and Emerging Sciences); Mohy-ud-Din, Hassan (Lahore University of Management Sciences)",1,1,,0.72,,https://app.dimensions.ai/details/publication/pub.1139989988,"40 Engineering; 4009 Electronics, Sensors and Digital Hardware; 46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation",,,,,,,,,,,,
1397,pub.1139969484,10.48550/arxiv.2107.11447,,,Deep Learning Based Cardiac MRI Segmentation: Do We Need Experts?,"Deep learning methods are the de-facto solutions to a multitude of medical
image analysis tasks. Cardiac MRI segmentation is one such application which,
like many others, requires a large number of annotated data so a trained
network can generalize well. Unfortunately, the process of having a large
number of manually curated images by medical experts is both slow and utterly
expensive. In this paper, we set out to explore whether expert knowledge is a
strict requirement for the creation of annotated datasets that machine learning
can successfully train on. To do so, we gauged the performance of three
segmentation models, namely U-Net, Attention U-Net, and ENet, trained with
different loss functions on expert and non-expert groundtruth for cardiac
cine-MRI segmentation. Evaluation was done with classic segmentation metrics
(Dice index and Hausdorff distance) as well as clinical measurements, such as
the ventricular ejection fractions and the myocardial mass. Results reveal that
generalization performances of a segmentation neural network trained on
non-expert groundtruth data is, to all practical purposes, as good as on expert
groundtruth data, in particular when the non-expert gets a decent level of
training, highlighting an opportunity for the efficient and cheap creation of
annotations for cardiac datasets.",,,arXiv,,,2021-07-23,2021,,,,,,All OA, Green,Preprint,"Skandarani, Youssef; Jodoin, Pierre-Marc; Lalande, Alain","Skandarani, Youssef (); Jodoin, Pierre-Marc (); Lalande, Alain ()",,"Skandarani, Youssef (); Jodoin, Pierre-Marc (); Lalande, Alain ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139969484,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
1547,pub.1139881981,10.48550/arxiv.2107.10718,,,Segmentation of Cardiac Structures via Successive Subspace Learning with  Saab Transform from Cine MRI,"Assessment of cardiovascular disease (CVD) with cine magnetic resonance
imaging (MRI) has been used to non-invasively evaluate detailed cardiac
structure and function. Accurate segmentation of cardiac structures from cine
MRI is a crucial step for early diagnosis and prognosis of CVD, and has been
greatly improved with convolutional neural networks (CNN). There, however, are
a number of limitations identified in CNN models, such as limited
interpretability and high complexity, thus limiting their use in clinical
practice. In this work, to address the limitations, we propose a lightweight
and interpretable machine learning model, successive subspace learning with the
subspace approximation with adjusted bias (Saab) transform, for accurate and
efficient segmentation from cine MRI. Specifically, our segmentation framework
is comprised of the following steps: (1) sequential expansion of near-to-far
neighborhood at different resolutions; (2) channel-wise subspace approximation
using the Saab transform for unsupervised dimension reduction; (3) class-wise
entropy guided feature selection for supervised dimension reduction; (4)
concatenation of features and pixel-wise classification with gradient boost;
and (5) conditional random field for post-processing. Experimental results on
the ACDC 2017 segmentation database, showed that our framework performed better
than state-of-the-art U-Net models with 200$\times$ fewer parameters in
delineating the left ventricle, right ventricle, and myocardium, thus showing
its potential to be used in clinical practice.",,,arXiv,,,2021-07-22,2021,,,,,,All OA, Green,Preprint,"Liu, Xiaofeng; Xing, Fangxu; Gaggin, Hanna K.; Wang, Weichung; Kuo, C. -C. Jay; Fakhri, Georges El; Woo, Jonghye","Liu, Xiaofeng (); Xing, Fangxu (); Gaggin, Hanna K. (); Wang, Weichung (); Kuo, C. -C. Jay (); Fakhri, Georges El (); Woo, Jonghye ()",,"Liu, Xiaofeng (); Xing, Fangxu (); Gaggin, Hanna K. (); Wang, Weichung (); Kuo, C. -C. Jay (); Fakhri, Georges El (); Woo, Jonghye ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139881981,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,
1209,pub.1139829842,10.48550/arxiv.2107.09134,,,Convolutional module for heart localization and segmentation in MRI,"Magnetic resonance imaging (MRI) is a widely known medical imaging technique
used to assess the heart function. Deep learning (DL) models perform several
tasks in cardiac MRI (CMR) images with good efficacy, such as segmentation,
estimation, and detection of diseases. Many DL models based on convolutional
neural networks (CNN) were improved by detecting regions-of-interest (ROI)
either automatically or by hand. In this paper we describe Visual-Motion-Focus
(VMF), a module that detects the heart motion in the 4D MRI sequence, and
highlights ROIs by focusing a Radial Basis Function (RBF) on the estimated
motion field. We experimented and evaluated VMF on three CMR datasets,
observing that the proposed ROIs cover 99.7% of data labels (Recall score),
improved the CNN segmentation (mean Dice score) by 1.7 (p < .001) after the ROI
extraction, and improved the overall training speed by 2.5 times (+150%).",,,arXiv,,,2021-07-19,2021,,,,,,All OA, Green,Preprint,"Lima, Daniel; Graves, Catharine; Gutierrez, Marco; Brandoli, Bruno; Rodrigues-Jr, Jose","Lima, Daniel (); Graves, Catharine (); Gutierrez, Marco (); Brandoli, Bruno (); Rodrigues-Jr, Jose ()",,"Lima, Daniel (); Graves, Catharine (); Gutierrez, Marco (); Brandoli, Bruno (); Rodrigues-Jr, Jose ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139829842,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5037,pub.1139699487,10.1148/ryai.2021200197,34617022,PMC8489464,Landmark Detection in Cardiac MRI Using a Convolutional Neural Network,"PURPOSE: To develop a convolutional neural network (CNN) solution for landmark detection in cardiac MRI (CMR).
MATERIALS AND METHODS: This retrospective study included cine, late gadolinium enhancement (LGE), and T1 mapping examinations from two hospitals. The training set included 2329 patients (34 089 images; mean age, 54.1 years; 1471 men; December 2017 to March 2020). A hold-out test set included 531 patients (7723 images; mean age, 51.5 years; 323 men; May 2020 to July 2020). CNN models were developed to detect two mitral valve plane and apical points on long-axis images. On short-axis images, anterior and posterior right ventricular (RV) insertion points and left ventricular (LV) center points were detected. Model outputs were compared with manual labels assigned by two readers. The trained model was deployed to MRI scanners.
RESULTS: For the long-axis images, successful detection of cardiac landmarks ranged from 99.7% to 100% for cine images and from 99.2% to 99.5% for LGE images. For the short-axis images, detection rates were 96.6% for cine, 97.6% for LGE, and 98.7% for T1 mapping. The Euclidean distances between model-assigned and manually assigned labels ranged from 2 to 3.5 mm for different landmarks, indicating close agreement between model-derived landmarks and manually assigned labels. For all views and imaging sequences, no differences between the models' assessment of images and the readers' assessment of images were found for the anterior RV insertion angle or LV length. Model inference for a typical cardiac cine series took 610 msec with the graphics processing unit and 5.6 seconds with central processing unit.
CONCLUSION: A CNN was developed for landmark detection on both long- and short-axis CMR images acquired with cine, LGE, and T1 mapping sequences, and the accuracy of the CNN was comparable with the interreader variation.Keywords: Cardiac, Heart, Convolutional Neural Network (CNN), Deep Learning Algorithms, Machine Learning Algorithms, Feature Detection, Quantification, Supervised Learning, MR Imaging Supplemental material is available for this article. Published under a CC BY 4.0 license.","Supported by the National Heart, Lung and Blood Institute, National Institutes of Health by the Division of Intramural Research (grants Z1A-HL006214-05 and Z1A-HL006242-02).",,Radiology Artificial Intelligence,,,2021-07-14,2021,2021-07-14,2021-09-01,3,5,e200197,All OA, Green,Article,"Xue, Hui; Artico, Jessica; Fontana, Marianna; Moon, James C.; Davies, Rhodri H.; Kellman, Peter","Xue, Hui (From the National Heart, Lung, and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, National Health Service, London, England (J.A., J.C.M., R.H.D.); and National Amyloidosis Centre, Royal Free Hospital, London, England (M.F.).); Artico, Jessica (From the National Heart, Lung, and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, National Health Service, London, England (J.A., J.C.M., R.H.D.); and National Amyloidosis Centre, Royal Free Hospital, London, England (M.F.).); Fontana, Marianna (From the National Heart, Lung, and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, National Health Service, London, England (J.A., J.C.M., R.H.D.); and National Amyloidosis Centre, Royal Free Hospital, London, England (M.F.).); Moon, James C. (From the National Heart, Lung, and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, National Health Service, London, England (J.A., J.C.M., R.H.D.); and National Amyloidosis Centre, Royal Free Hospital, London, England (M.F.).); Davies, Rhodri H. (From the National Heart, Lung, and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, National Health Service, London, England (J.A., J.C.M., R.H.D.); and National Amyloidosis Centre, Royal Free Hospital, London, England (M.F.).); Kellman, Peter (From the National Heart, Lung, and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, National Health Service, London, England (J.A., J.C.M., R.H.D.); and National Amyloidosis Centre, Royal Free Hospital, London, England (M.F.).)","Xue, Hui (National Institutes of Health)","Xue, Hui (National Institutes of Health); Artico, Jessica (National Institutes of Health); Fontana, Marianna (National Institutes of Health); Moon, James C. (National Institutes of Health); Davies, Rhodri H. (National Institutes of Health); Kellman, Peter (National Institutes of Health)",14,14,2.47,12.28,https://europepmc.org/articles/pmc8489464?pdf=render,https://app.dimensions.ai/details/publication/pub.1139699487,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1347,pub.1139715788,10.3390/a14070212,,,Deep Learning Based Cardiac MRI Segmentation: Do We Need Experts?,"Deep learning methods are the de facto solutions to a multitude of medical image analysis tasks. Cardiac MRI segmentation is one such application, which, like many others, requires a large number of annotated data so that a trained network can generalize well. Unfortunately, the process of having a large number of manually curated images by medical experts is both slow and utterly expensive. In this paper, we set out to explore whether expert knowledge is a strict requirement for the creation of annotated data sets on which machine learning can successfully be trained. To do so, we gauged the performance of three segmentation models, namely U-Net, Attention U-Net, and ENet, trained with different loss functions on expert and non-expert ground truth for cardiac cine–MRI segmentation. Evaluation was done with classic segmentation metrics (Dice index and Hausdorff distance) as well as clinical measurements, such as the ventricular ejection fractions and the myocardial mass. The results reveal that generalization performances of a segmentation neural network trained on non-expert ground truth data is, to all practical purposes, as good as that trained on expert ground truth data, particularly when the non-expert receives a decent level of training, highlighting an opportunity for the efficient and cost-effective creation of annotations for cardiac data sets.",We would like to acknowledge Ivan Porcherot for the tremendous work in annotating the data sets.,This research received no external funding.,Algorithms,,,2021-07-14,2021,2021-07-14,,14,7,212,All OA, Gold,Article,"Skandarani, Youssef; Jodoin, Pierre-Marc; Lalande, Alain","Skandarani, Youssef (Laboratoire ImVIA, University of Bourgogne Franche-Comte, 21000 Dijon, France;, Alain.Lalande@u-bourgogne.fr; CASIS Inc., 21800 Quetigny, France); Jodoin, Pierre-Marc (Department of Computer Science, University of Sherbrooke, Sherbrooke, QC J1K 2R1, Canada;, pierre-marc.jodoin@usherbrooke.ca); Lalande, Alain (Laboratoire ImVIA, University of Bourgogne Franche-Comte, 21000 Dijon, France;, Alain.Lalande@u-bourgogne.fr; Department of Radiology, University Hospital of Dijon, 21000 Dijon, France)","Skandarani, Youssef (Université Bourgogne Franche-Comté; )","Skandarani, Youssef (Université Bourgogne Franche-Comté); Jodoin, Pierre-Marc (Université de Sherbrooke); Lalande, Alain (Université Bourgogne Franche-Comté; Centre Hospitalier Universitaire Dijon Bourgogne)",1,1,,0.79,https://www.mdpi.com/1999-4893/14/7/212/pdf?version=1626754079,https://app.dimensions.ai/details/publication/pub.1139715788,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
1300,pub.1139701802,10.48550/arxiv.2107.05532,,,Context-aware virtual adversarial training for anatomically-plausible  segmentation,"Despite their outstanding accuracy, semi-supervised segmentation methods
based on deep neural networks can still yield predictions that are considered
anatomically impossible by clinicians, for instance, containing holes or
disconnected regions. To solve this problem, we present a Context-aware Virtual
Adversarial Training (CaVAT) method for generating anatomically plausible
segmentation. Unlike approaches focusing solely on accuracy, our method also
considers complex topological constraints like connectivity which cannot be
easily modeled in a differentiable loss function. We use adversarial training
to generate examples violating the constraints, so the network can learn to
avoid making such incorrect predictions on new examples, and employ the
Reinforce algorithm to handle non-differentiable segmentation constraints. The
proposed method offers a generic and efficient way to add any constraint on top
of any segmentation network. Experiments on two clinically-relevant datasets
show our method to produce segmentations that are both accurate and
anatomically-plausible in terms of region connectivity.",,,arXiv,,,2021-07-12,2021,,,,,,All OA, Green,Preprint,"Wang, Ping; Peng, Jizong; Pedersoli, Marco; Zhou, Yuanfeng; Zhang, Caiming; Desrosiers, Christian","Wang, Ping (); Peng, Jizong (); Pedersoli, Marco (); Zhou, Yuanfeng (); Zhang, Caiming (); Desrosiers, Christian ()",,"Wang, Ping (); Peng, Jizong (); Pedersoli, Marco (); Zhou, Yuanfeng (); Zhang, Caiming (); Desrosiers, Christian ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139701802,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1344,pub.1139661763,10.48550/arxiv.2107.04886,,,Hierarchical Self-Supervised Learning for Medical Image Segmentation  Based on Multi-Domain Data Aggregation,"A large labeled dataset is a key to the success of supervised deep learning,
but for medical image segmentation, it is highly challenging to obtain
sufficient annotated images for model training. In many scenarios, unannotated
images are abundant and easy to acquire. Self-supervised learning (SSL) has
shown great potentials in exploiting raw data information and representation
learning. In this paper, we propose Hierarchical Self-Supervised Learning
(HSSL), a new self-supervised framework that boosts medical image segmentation
by making good use of unannotated data. Unlike the current literature on
task-specific self-supervised pretraining followed by supervised fine-tuning,
we utilize SSL to learn task-agnostic knowledge from heterogeneous data for
various medical image segmentation tasks. Specifically, we first aggregate a
dataset from several medical challenges, then pre-train the network in a
self-supervised manner, and finally fine-tune on labeled data. We develop a new
loss function by combining contrastive loss and classification loss and
pretrain an encoder-decoder architecture for segmentation tasks. Our extensive
experiments show that multi-domain joint pre-training benefits downstream
segmentation tasks and outperforms single-domain pre-training significantly.
Compared to learning from scratch, our new method yields better performance on
various tasks (e.g., +0.69% to +18.60% in Dice scores with 5% of annotated
data). With limited amounts of training data, our method can substantially
bridge the performance gap w.r.t. denser annotations (e.g., 10% vs.~100% of
annotated data).",,,arXiv,,,2021-07-10,2021,,,,,,All OA, Green,Preprint,"Zheng, Hao; Han, Jun; Wang, Hongxiao; Yang, Lin; Zhao, Zhuo; Wang, Chaoli; Chen, Danny Z.","Zheng, Hao (); Han, Jun (); Wang, Hongxiao (); Yang, Lin (); Zhao, Zhuo (); Wang, Chaoli (); Chen, Danny Z. ()",,"Zheng, Hao (); Han, Jun (); Wang, Hongxiao (); Yang, Lin (); Zhao, Zhuo (); Wang, Chaoli (); Chen, Danny Z. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139661763,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
5053,pub.1139548365,10.1016/j.media.2021.102156,34274689,,Incorporating the hybrid deformable model for improving the performance of abdominal CT segmentation via multi-scale feature fusion network,"Automated multi-organ abdominal Computed Tomography (CT) image segmentation can assist the treatment planning, diagnosis, and improve many clinical workflows' efficiency. The 3-D Convolutional Neural Network (CNN) recently attained state-of-the-art accuracy, which typically relies on supervised training with many manual annotated data. Many methods used the data augmentation strategy with a rigid or affine spatial transformation to alleviate the over-fitting problem and improve the network's robustness. However, the rigid or affine spatial transformation fails to capture the complex voxel-based deformation in the abdomen, filled with many soft organs. We developed a novel Hybrid Deformable Model (HDM), which consists of the inter-and intra-patient deformation for more effective data augmentation to tackle this issue. The inter-patient deformations were extracted from the learning-based deformable registration between different patients, while the intra-patient deformations were formed using the random 3-D Thin-Plate-Spline (TPS) transformation. Incorporating the HDM enabled the network to capture many of the subtle deformations of abdominal organs. To find a better solution and achieve faster convergence for network training, we fused the pre-trained multi-scale features into the a 3-D attention U-Net. We directly compared the segmentation accuracy of the proposed method to the previous techniques on several centers' datasets via cross-validation. The proposed method achieves the average Dice Similarity Coefficient (DSC) 0.852, which outperformed the other state-of-the-art on multi-organ abdominal CT segmentation results.","This work is supported in part by grants from the National Key Research and Develop Program of China (2016YFC0105102, 2018YFA0704102), the National Natural Science Foundation of China (62001464, 61871374, 81871433, 62073309, 81827805), the Leading Talent of Special Support Project in Guangdong (2016TX03R139), Shenzhen matching project (GJHS20170314155751703), Fundamental Research Program of Shenzhen (JCYJ20170413162458312), Science Foundation of Guangdong (2017B020229002, 2015B020233011), Basic Research Layout Project of Shenzhen (JCYJ20200109114610201, JCYJ20200109114812361), Project of Shenzhen International Cooperation Foundation (GJHZ20180926165402083) and Shenzhen Interventional Diagnosis and Treatment Integration Key Technology and Engineering Laboratory. CAS Key Laboratory of Health Informatics, Shenzhen Institutes of Advanced Technology, the Key Laboratory of Health Informatics in Chinese Academy of Sciences.",,Medical Image Analysis,,"Abdomen; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Tomography, X-Ray Computed",2021-07-09,2021,2021-07-09,2021-10,73,,102156,All OA, Bronze,Article,"Liang, Xiaokun; Li, Na; Zhang, Zhicheng; Xiong, Jing; Zhou, Shoujun; Xie, Yaoqin","Liang, Xiaokun (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong 518055, China; Shenzhen Colleges of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen, Guangdong 518055, China. Electronic address: xk.liang@qq.com.); Li, Na (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong 518055, China; Shenzhen Colleges of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen, Guangdong 518055, China.); Zhang, Zhicheng (Department of Radiation Oncology, Stanford University, Stanford, CA 94305, USA.); Xiong, Jing (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong 518055, China.); Zhou, Shoujun (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong 518055, China. Electronic address: sj.zhou@siat.ac.cn.); Xie, Yaoqin (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong 518055, China. Electronic address: yq.xie@siat.ac.cn.)","Liang, Xiaokun (Shenzhen Institutes of Advanced Technology; University of Chinese Academy of Sciences)","Liang, Xiaokun (Shenzhen Institutes of Advanced Technology; University of Chinese Academy of Sciences); Li, Na (Shenzhen Institutes of Advanced Technology; University of Chinese Academy of Sciences); Zhang, Zhicheng (Stanford University); Xiong, Jing (Shenzhen Institutes of Advanced Technology); Zhou, Shoujun (Shenzhen Institutes of Advanced Technology); Xie, Yaoqin (Shenzhen Institutes of Advanced Technology)",17,17,1.92,14.91,https://www.sciencedirect.com/science/article/am/pii/S1361841521002024,https://app.dimensions.ai/details/publication/pub.1139548365,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1138,pub.1139566407,10.21203/rs.3.rs-688924/v1,,,Federated Learning for Multi-Center Imaging Diagnostics: A Study in Cardiovascular Disease,"Deep learning models can enable accurate and efficient disease diagnosis, but have thus far been hampered by the data scarcity present in the medical world. Automated diagnosis studies have been constrained by underpowered single-center datasets, and although some results have shown promise, their generalizability to other institutions remains questionable as the data heterogeneity between institutions is not taken into account. By allowing models to be trained in a distributed manner that preserves patients’ privacy, federated learning promises to alleviate these issues, by enabling diligent multi-center studies. We present the first federated learning study on the modality of cardiovascular magnetic resonance (CMR) and use four centers derived from subsets of the M&M and ACDC datasets, focusing on the diagnosis of hypertrophic cardiomyopathy (HCM). We adapt a 3D-CNN network pretrained on action recognition and explore two different ways of incorporating shape prior information to the model, and four different data augmentation setups , systematically analyzing their impact on the different collaborative learning choices. We show that despite the small size of data (180 subjects derived from four centers), the privacy preserving federated learning achieves promising results that are competitive with traditional centralized learning. We further find that federatively trained models exhibit increased robustness and are more sensitive to domain shift effects.",,,Research Square,,,2021-07-09,2021,2021-07-09,,,,,All OA, Green,Preprint,"Linardos, Akis; Kushibar, Kaisar; Walsh, Sean; Gkontra, Polyxeni; Lekadir, Karim","Linardos, Akis (University of Barcelona); Kushibar, Kaisar (University of Barcelona); Walsh, Sean (Radiomics); Gkontra, Polyxeni (University of Barcelona); Lekadir, Karim (University of Barcelona)",,"Linardos, Akis (University of Barcelona); Kushibar, Kaisar (University of Barcelona); Walsh, Sean (); Gkontra, Polyxeni (University of Barcelona); Lekadir, Karim (University of Barcelona)",7,7,,5.73,https://www.researchsquare.com/article/rs-688924/latest.pdf,https://app.dimensions.ai/details/publication/pub.1139566407,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,
1133,pub.1139575818,10.48550/arxiv.2107.03901,,,Federated Learning for Multi-Center Imaging Diagnostics: A Study in  Cardiovascular Disease,"Deep learning models can enable accurate and efficient disease diagnosis, but
have thus far been hampered by the data scarcity present in the medical world.
Automated diagnosis studies have been constrained by underpowered single-center
datasets, and although some results have shown promise, their generalizability
to other institutions remains questionable as the data heterogeneity between
institutions is not taken into account. By allowing models to be trained in a
distributed manner that preserves patients' privacy, federated learning
promises to alleviate these issues, by enabling diligent multi-center studies.
We present the first federated learning study on the modality of cardiovascular
magnetic resonance (CMR) and use four centers derived from subsets of the M\&M
and ACDC datasets, focusing on the diagnosis of hypertrophic cardiomyopathy
(HCM). We adapt a 3D-CNN network pretrained on action recognition and explore
two different ways of incorporating shape prior information to the model, and
four different data augmentation set-ups, systematically analyzing their impact
on the different collaborative learning choices. We show that despite the small
size of data (180 subjects derived from four centers), the privacy preserving
federated learning achieves promising results that are competitive with
traditional centralized learning. We further find that federatively trained
models exhibit increased robustness and are more sensitive to domain shift
effects.",,,arXiv,,,2021-07-07,2021,,,,,,All OA, Green,Preprint,"Linardos, Akis; Kushibar, Kaisar; Walsh, Sean; Gkontra, Polyxeni; Lekadir, Karim","Linardos, Akis (); Kushibar, Kaisar (); Walsh, Sean (); Gkontra, Polyxeni (); Lekadir, Karim ()",,"Linardos, Akis (); Kushibar, Kaisar (); Walsh, Sean (); Gkontra, Polyxeni (); Lekadir, Karim ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139575818,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,
1399,pub.1139424401,10.1007/978-3-030-80432-9_22,,,Ensemble of Deep Convolutional Neural Networks with Monte Carlo Dropout Sampling for Automated Image Segmentation Quality Control and Robust Deep Learning Using Small Datasets,"Recent progress on deep learning (DL)-based medical image segmentation can enable fast extraction of clinical parameters for efficient clinical workflows. However, current DL methods can still fail and require manual visual inspection of outputs, which is time-consuming and diminishes the advantages of automation. For clinical applications, it is essential to develop DL approaches that can not only perform accurate segmentation, but also predict the segmentation quality and flag poor-quality results to avoid errors in diagnosis. To achieve robust performance, DL-based methods often require large datasets, which are not always readily available. It would be highly desirable to be able to train DL models using only small datasets, but this requires a quality prediction method to ensure reliability. We present a novel segmentation framework utilizing an ensemble of deep convolutional neural networks with Monte Carlo sampling. The proposed framework merges the advantages of both state-of-the-art deep ensembles and Bayesian approaches, to provide robust segmentation with inherent quality control. We successfully developed and tested this framework using just a small MRI dataset of 45 subjects. The framework obtained high mean Dice similarity coefficients (DSC) for segmentation of the endocardium (0.922) and the epicardium (0.942); importantly, segmentation DSC can be accurately predicted with low mean absolute errors (≤0.035), in the absence of the manual ground truth. Furthermore, binary classification of segmentation quality achieved a near-perfect accuracy of 99%. The proposed framework can enable fast and reliable medical image analysis with accurate quality control, and training of DL-based methods using even small datasets.",,,Lecture Notes in Computer Science,Medical Image Understanding and Analysis,,2021-07-06,2021,2021-07-06,2021,12722,,280-293,All OA, Green,Chapter,"Hann, Evan; Gonzales, Ricardo A.; Popescu, Iulia A.; Zhang, Qiang; Ferreira, Vanessa M.; Piechnik, Stefan K.","Hann, Evan (Oxford Centre for Clinical Magnetic Resonance Research, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Gonzales, Ricardo A. (Oxford Centre for Clinical Magnetic Resonance Research, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Popescu, Iulia A. (Oxford Centre for Clinical Magnetic Resonance Research, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Zhang, Qiang (Oxford Centre for Clinical Magnetic Resonance Research, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Ferreira, Vanessa M. (Oxford Centre for Clinical Magnetic Resonance Research, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Piechnik, Stefan K. (Oxford Centre for Clinical Magnetic Resonance Research, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK)","Hann, Evan (University of Oxford)","Hann, Evan (University of Oxford); Gonzales, Ricardo A. (University of Oxford); Popescu, Iulia A. (University of Oxford); Zhang, Qiang (University of Oxford); Ferreira, Vanessa M. (University of Oxford); Piechnik, Stefan K. (University of Oxford)",4,4,,3.27,https://ora.ox.ac.uk/objects/uuid:11815c9c-259f-41ed-b120-03e807eb6459/download_file?safe_filename=Hann_et_al_2022_ensemble_of_deep.pdf&file_format=application%2Fpdf&type_of_work=Conference+item,https://app.dimensions.ai/details/publication/pub.1139424401,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1399,pub.1139431533,10.48550/arxiv.2107.01748,,,Controllable cardiac synthesis via disentangled anatomy arithmetic,"Acquiring annotated data at scale with rare diseases or conditions remains a
challenge. It would be extremely useful to have a method that controllably
synthesizes images that can correct such underrepresentation. Assuming a proper
latent representation, the idea of a ""latent vector arithmetic"" could offer the
means of achieving such synthesis. A proper representation must encode the
fidelity of the input data, preserve invariance and equivariance, and permit
arithmetic operations. Motivated by the ability to disentangle images into
spatial anatomy (tensor) factors and accompanying imaging (vector)
representations, we propose a framework termed ""disentangled anatomy
arithmetic"", in which a generative model learns to combine anatomical factors
of different input images such that when they are re-entangled with the desired
imaging modality (e.g. MRI), plausible new cardiac images are created with the
target characteristics. To encourage a realistic combination of anatomy factors
after the arithmetic step, we propose a localized noise injection network that
precedes the generator. Our model is used to generate realistic images,
pathology labels, and segmentation masks that are used to augment the existing
datasets and subsequently improve post-hoc classification and segmentation
tasks. Code is publicly available at https://github.com/vios-s/DAA-GAN.",,,arXiv,,,2021-07-04,2021,,,,,,All OA, Green,Preprint,"Thermos, Spyridon; Liu, Xiao; O'Neil, Alison; Tsaftaris, Sotirios A.","Thermos, Spyridon (); Liu, Xiao (); O'Neil, Alison (); Tsaftaris, Sotirios A. ()",,"Thermos, Spyridon (); Liu, Xiao (); O'Neil, Alison (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139431533,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1459,pub.1139430867,10.48550/arxiv.2107.01079,,,Cooperative Training and Latent Space Data Augmentation for Robust  Medical Image Segmentation,"Deep learning-based segmentation methods are vulnerable to unforeseen data
distribution shifts during deployment, e.g. change of image appearances or
contrasts caused by different scanners, unexpected imaging artifacts etc. In
this paper, we present a cooperative framework for training image segmentation
models and a latent space augmentation method for generating hard examples.
Both contributions improve model generalization and robustness with limited
data. The cooperative training framework consists of a fast-thinking network
(FTN) and a slow-thinking network (STN). The FTN learns decoupled image
features and shape features for image reconstruction and segmentation tasks.
The STN learns shape priors for segmentation correction and refinement. The two
networks are trained in a cooperative manner. The latent space augmentation
generates challenging examples for training by masking the decoupled latent
space in both channel-wise and spatial-wise manners. We performed extensive
experiments on public cardiac imaging datasets. Using only 10 subjects from a
single site for training, we demonstrated improved cross-site segmentation
performance and increased robustness against various unforeseen imaging
artifacts compared to strong baseline methods. Particularly, cooperative
training with latent space data augmentation yields 15% improvement in terms of
average Dice score when compared to a standard training method.",,,arXiv,,,2021-07-02,2021,,,,,,All OA, Green,Preprint,"Chen, Chen; Hammernik, Kerstin; Ouyang, Cheng; Qin, Chen; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (); Hammernik, Kerstin (); Ouyang, Cheng (); Qin, Chen (); Bai, Wenjia (); Rueckert, Daniel ()",,"Chen, Chen (); Hammernik, Kerstin (); Ouyang, Cheng (); Qin, Chen (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139430867,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1344,pub.1139346216,10.1007/s11760-021-01978-3,,,Identification of systolic and diastolic heart failure progression with Krawtchouk moment feature-aided Harris hawks optimized support vector machine,"The systolic and diastolic heart failure (HF) subjects are typically categorized based on clinical indices only. The relationship between different stages of systolic and diastolic heart failure and left ventricle (LV) myocardial tissue variations is presented in this work. The corr-entropy and optimized edge criterion has been incorporated into the level set (CEOELS) for effective segmentation of myocardium in cardiovascular magnetic resonance images to handle noise, intensity inhomogeneity and contour initialization. In order to learn shape and local variations in segmented myocardium, Krawtchouk moment features are computed for ten different moment orders. The relevant extracted features are obtained through Harris hawks optimization algorithm. The optimized features are fed to support vector machine (SVM) that uses fivefold cross-validation approach for classification. Experimental results show that CEOELS has provided better segmentation of LV blood cavity and myocardium with a similarity measure of 0.93 and 0.92, respectively. It is also observed that individual Krawtchouk moment orders greater than 30 have provided better HF prediction performance. Consequently, optimized Krawtchouk moment features produced an increased overall accuracy (80.8%) than individual feature sets. Significant improvement has also been achieved in distinction of hyperdynamic patients from normal and systolic dysfunction subjects that is less explored.",,,"Signal, Image and Video Processing",,,2021-07-02,2021,2021-07-02,2022-02,16,1,127-135,Closed,Article,"Muthunayagam, Muthulakshmi; Ganesan, Kavitha","Muthunayagam, Muthulakshmi (Department of Electronics Engineering, MIT Campus, Anna University, Chromepet, 600044, Chennai, Tamilnadu, India); Ganesan, Kavitha (Department of Electronics Engineering, MIT Campus, Anna University, Chromepet, 600044, Chennai, Tamilnadu, India)","Muthunayagam, Muthulakshmi (Anna University, Chennai)","Muthunayagam, Muthulakshmi (Anna University, Chennai); Ganesan, Kavitha (Anna University, Chennai)",1,1,,0.77,,https://app.dimensions.ai/details/publication/pub.1139346216,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
5339,pub.1138918933,10.1088/1361-6560/ac0bd3,34134101,,Cardiac MRI segmentation with focal loss constrained deep residual networks,"Delineating anatomical structures for cardiac magnetic resonance imaging (CMRI) is crucial for various medical applications such as medical diagnoses, treatment, and pathological studies. CMRI segmentation, which aims to automatically and accurately segment the heart structures, is highly beneficial for cardiologists. However, it is non-trivial to perfectly segment the ventricles, especially for the heart apex slices, considering their small sizes compared to the input images. For example, the endocardium in the Sunnybrook dataset only occupies 4% of the entire image by average. During the training process, these target pixels, or other hard samples, are buried by the massive backgrounds that make the model mostly receive optimization signals from easy samples. In this paper, we propose a focal loss constrained residual network (FR-Net) to tackle the problem. In order to mitigate the fact that the gradients of the hard samples can be easily overwhelmed by the easy samples, we use a pixel-wise re-weighting strategy to balance the gradients. Furthermore, considering focal loss constraints for each pixel independently, we propose an alternative training fashion that trains the model with focal loss and dice loss alternatively. The segmentation model can not only benefit from the pixel-wise focal loss but also from the region-wise dice loss to comprehensively optimize the model. We conducted thorough experiments on the Sunnybrook dataset, CMRI dataset, right ventricle dataset, and ACDC dataset to verify the effectiveness of the proposed method.","This work is supported in part by the National Natural Science Foundation of China (No: U1809204, 61 525 106, 61 701 436), by the National Key Technology Research and Development Program of China (No: 2017YFE0104000, 2016YFC1300302), and by the Key Research and Development Program of Zhejiang Province (No: 2021C03029).",,Physics in Medicine and Biology,,"Heart; Heart Ventricles; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Radiography",2021-07-01,2021,2021-07-01,2021-07-07,66,13,135012,Closed,Article,"Li, Chuchen; Chen, Mingqiang; Zhang, Jinglin; Liu, Huafeng","Li, Chuchen (College of Optical Science and Engineering, Zhejiang University, People’s Republic of China); Chen, Mingqiang (College of Optical Science and Engineering, Zhejiang University, People’s Republic of China); Zhang, Jinglin (School of Atmospheric Science, Nanjing University of Information Science and Technology, People’s Republic of China); Liu, Huafeng (College of Optical Science and Engineering, Zhejiang University, People’s Republic of China)","Li, Chuchen (Zhejiang University)","Li, Chuchen (Zhejiang University); Chen, Mingqiang (Zhejiang University); Zhang, Jinglin (Nanjing University of Information Science and Technology); Liu, Huafeng (Zhejiang University)",6,6,0.5,7.51,,https://app.dimensions.ai/details/publication/pub.1138918933,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,,
4808,pub.1136481879,10.1109/tmi.2021.3066683,33729930,,Adapt Everywhere: Unsupervised Adaptation of Point-Clouds and Entropy Minimization for Multi-Modal Cardiac Image Segmentation,"Deep learning models are sensitive to domain shift phenomena. A model trained on images from one domain cannot generalise well when tested on images from a different domain, despite capturing similar anatomical structures. It is mainly because the data distribution between the two domains is different. Moreover, creating annotation for every new modality is a tedious and time-consuming task, which also suffers from high inter- and intra- observer variability. Unsupervised domain adaptation (UDA) methods intend to reduce the gap between source and target domains by leveraging source domain labelled data to generate labels for the target domain. However, current state-of-the-art (SOTA) UDA methods demonstrate degraded performance when there is insufficient data in source and target domains. In this paper, we present a novel UDA method for multi-modal cardiac image segmentation. The proposed method is based on adversarial learning and adapts network features between source and target domain in different spaces. The paper introduces an end-to-end framework that integrates: a) entropy minimization, b) output feature space alignment and c) a novel point-cloud shape adaptation based on the latent features learned by the segmentation model. We validated our method on two cardiac datasets by adapting from the annotated source domain, bSSFP-MRI (balanced Steady-State Free Procession-MRI), to the unannotated target domain, LGE-MRI (Late-gadolinium enhance-MRI), for the multi-sequence dataset; and from MRI (source) to CT (target) for the cross-modality dataset. The results highlighted that by enforcing adversarial learning in different parts of the network, the proposed method delivered promising performance, compared to other SOTA methods.",This work was supported by the Project EFI-BIG-THERA: Integrative “BigData Modeling” for the development of novel therapeutic approaches for breast cancer. The authors would like to thank NVIDIA for donating a Titan X-Pascal GPU.,,IEEE Transactions on Medical Imaging,,"Entropy; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging",2021-06-30,2021,2021-06-30,2021-07,40,7,1838-1851,All OA, Green,Article,"Vesal, Sulaiman; Gu, Mingxuan; Kosti, Ronak; Maier, Andreas; Ravikumar, Nishant","Vesal, Sulaiman (Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg, 91054, Erlangen, Germany); Gu, Mingxuan (Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg, 91054, Erlangen, Germany); Kosti, Ronak (Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg, 91054, Erlangen, Germany); Maier, Andreas (Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg, 91054, Erlangen, Germany); Ravikumar, Nishant (Center for Computational Imaging & Simulation Technologies in Biomedicine (CISTIB), School of Computing, Leeds Institute of Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, LS2 9JT, U.K.)","Vesal, Sulaiman (University of Erlangen-Nuremberg)","Vesal, Sulaiman (University of Erlangen-Nuremberg); Gu, Mingxuan (University of Erlangen-Nuremberg); Kosti, Ronak (University of Erlangen-Nuremberg); Maier, Andreas (University of Erlangen-Nuremberg); Ravikumar, Nishant (University of Leeds)",10,10,0.91,8.66,https://eprints.whiterose.ac.uk/174516/7/Adapt-everywhere.pdf,https://app.dimensions.ai/details/publication/pub.1136481879,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games; 4611 Machine Learning",,,,,,,,,,,
4788,pub.1139173944,10.1016/j.media.2021.102146,34274692,,Self-paced and self-consistent co-training for semi-supervised image segmentation,"Deep co-training has recently been proposed as an effective approach for image segmentation when annotated data is scarce. In this paper, we improve existing approaches for semi-supervised segmentation with a self-paced and self-consistent co-training method. To help distillate information from unlabeled images, we first design a self-paced learning strategy for co-training that lets jointly-trained neural networks focus on easier-to-segment regions first, and then gradually consider harder ones. This is achieved via an end-to-end differentiable loss in the form of a generalized Jensen Shannon Divergence (JSD). Moreover, to encourage predictions from different networks to be both consistent and confident, we enhance this generalized JSD loss with an uncertainty regularizer based on entropy. The robustness of individual models is further improved using a self-ensembling loss that enforces their prediction to be consistent across different training iterations. We demonstrate the potential of our method on three challenging image segmentation problems with different image modalities, using a small fraction of labeled data. Results show clear advantages in terms of performance compared to the standard co-training baselines and recently proposed state-of-the-art approaches for semi-supervised segmentation.","This work was supported in part by the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grants Program under grant RGPIN-2018-05715;by the NSFC-Zhejiang Joint Fund of the Integration of Informatization and Industrialization under Grant No.U1909210, the National Natural Science Foundation of China under Grant (No.61772312).",,Medical Image Analysis,,"Entropy; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Supervised Machine Learning; Uncertainty",2021-06-26,2021,2021-06-26,2021-10,73,,102146,All OA, Green,Article,"Wang, Ping; Peng, Jizong; Pedersoli, Marco; Zhou, Yuanfeng; Zhang, Caiming; Desrosiers, Christian","Wang, Ping (Department of Software and IT Engineering, Ecole de technologie supérieure, Montreal, H3C1K3, Canada. Electronic address: ping.wang.1@ens.etsmtl.ca.); Peng, Jizong (Department of Software and IT Engineering, Ecole de technologie supérieure, Montreal, H3C1K3, Canada. Electronic address: jizong.peng.1@etsmtl.net.); Pedersoli, Marco (Department of Software and IT Engineering, Ecole de technologie supérieure, Montreal, H3C1K3, Canada. Electronic address: marco.pedersoli@etsmtl.ca.); Zhou, Yuanfeng (School of Software, Shandong University, Jinan, 250101, China. Electronic address: yfzhou@sdu.edu.cn.); Zhang, Caiming (School of Software, Shandong University, Jinan, 250101, China. Electronic address: czhang@sdu.edu.cn.); Desrosiers, Christian (Department of Software and IT Engineering, Ecole de technologie supérieure, Montreal, H3C1K3, Canada. Electronic address: christian.desrosiers@etsmtl.ca.)","Wang, Ping (École de Technologie Supérieure)","Wang, Ping (École de Technologie Supérieure); Peng, Jizong (École de Technologie Supérieure); Pedersoli, Marco (École de Technologie Supérieure); Zhou, Yuanfeng (Shandong University); Zhang, Caiming (Shandong University); Desrosiers, Christian (École de Technologie Supérieure)",19,19,1.94,,http://arxiv.org/pdf/2011.00325,https://app.dimensions.ai/details/publication/pub.1139173944,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
1300,pub.1139219165,10.48550/arxiv.2106.13292,,,Semi-supervised Meta-learning with Disentanglement for  Domain-generalised Medical Image Segmentation,"Generalising deep models to new data from new centres (termed here domains)
remains a challenge. This is largely attributed to shifts in data statistics
(domain shifts) between source and unseen domains. Recently, gradient-based
meta-learning approaches where the training data are split into meta-train and
meta-test sets to simulate and handle the domain shifts during training have
shown improved generalisation performance. However, the current fully
supervised meta-learning approaches are not scalable for medical image
segmentation, where large effort is required to create pixel-wise annotations.
Meanwhile, in a low data regime, the simulated domain shifts may not
approximate the true domain shifts well across source and unseen domains. To
address this problem, we propose a novel semi-supervised meta-learning
framework with disentanglement. We explicitly model the representations related
to domain shifts. Disentangling the representations and combining them to
reconstruct the input image allows unlabeled data to be used to better
approximate the true domain shifts for meta-learning. Hence, the model can
achieve better generalisation performance, especially when there is a limited
amount of labeled data. Experiments show that the proposed method is robust on
different segmentation tasks and achieves state-of-the-art generalisation
performance on two public benchmarks.",,,arXiv,,,2021-06-24,2021,,,,,,All OA, Green,Preprint,"Liu, Xiao; Thermos, Spyridon; O'Neil, Alison; Tsaftaris, Sotirios A.","Liu, Xiao (); Thermos, Spyridon (); O'Neil, Alison (); Tsaftaris, Sotirios A. ()",,"Liu, Xiao (); Thermos, Spyridon (); O'Neil, Alison (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139219165,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
532,pub.1139148412,10.48550/arxiv.2106.12864,,,A Systematic Collection of Medical Image Datasets for Deep Learning,"The astounding success made by artificial intelligence (AI) in healthcare and
other fields proves that AI can achieve human-like performance. However,
success always comes with challenges. Deep learning algorithms are
data-dependent and require large datasets for training. The lack of data in the
medical imaging field creates a bottleneck for the application of deep learning
to medical image analysis. Medical image acquisition, annotation, and analysis
are costly, and their usage is constrained by ethical restrictions. They also
require many resources, such as human expertise and funding. That makes it
difficult for non-medical researchers to have access to useful and large
medical data. Thus, as comprehensive as possible, this paper provides a
collection of medical image datasets with their associated challenges for deep
learning research. We have collected information of around three hundred
datasets and challenges mainly reported between 2013 and 2020 and categorized
them into four categories: head & neck, chest & abdomen, pathology & blood, and
``others''. Our paper has three purposes: 1) to provide a most up to date and
complete list that can be used as a universal reference to easily find the
datasets for clinical image analysis, 2) to guide researchers on the
methodology to test and evaluate their methods' performance and robustness on
relevant datasets, 3) to provide a ``route'' to relevant algorithms for the
relevant medical topics, and challenge leaderboards.",,,arXiv,,,2021-06-24,2021,,,,,,All OA, Green,Preprint,"Li, Johann; Zhu, Guangming; Hua, Cong; Feng, Mingtao; BasheerBennamoun; Li, Ping; Lu, Xiaoyuan; Song, Juan; Shen, Peiyi; Xu, Xu; Mei, Lin; Zhang, Liang; Shah, Syed Afaq Ali; Bennamoun, Mohammed","Li, Johann (); Zhu, Guangming (); Hua, Cong (); Feng, Mingtao (); BasheerBennamoun (); Li, Ping (); Lu, Xiaoyuan (); Song, Juan (); Shen, Peiyi (); Xu, Xu (); Mei, Lin (); Zhang, Liang (); Shah, Syed Afaq Ali (); Bennamoun, Mohammed ()",,"Li, Johann (); Zhu, Guangming (); Hua, Cong (); Feng, Mingtao (); BasheerBennamoun (); Li, Ping (); Lu, Xiaoyuan (); Song, Juan (); Shen, Peiyi (); Xu, Xu (); Mei, Lin (); Zhang, Liang (); Shah, Syed Afaq Ali (); Bennamoun, Mohammed ()",1,1,,0.83,,https://app.dimensions.ai/details/publication/pub.1139148412,46 Information and Computing Sciences, 4602 Artificial Intelligence,3 Good Health and Well Being,,,,,,,,,
1451,pub.1139119983,10.48550/arxiv.2106.12175,,,Deformed2Self: Self-Supervised Denoising for Dynamic Medical Imaging,"Image denoising is of great importance for medical imaging system, since it
can improve image quality for disease diagnosis and downstream image analyses.
In a variety of applications, dynamic imaging techniques are utilized to
capture the time-varying features of the subject, where multiple images are
acquired for the same subject at different time points. Although
signal-to-noise ratio of each time frame is usually limited by the short
acquisition time, the correlation among different time frames can be exploited
to improve denoising results with shared information across time frames. With
the success of neural networks in computer vision, supervised deep learning
methods show prominent performance in single-image denoising, which rely on
large datasets with clean-vs-noisy image pairs. Recently, several
self-supervised deep denoising models have been proposed, achieving promising
results without needing the pairwise ground truth of clean images. In the field
of multi-image denoising, however, very few works have been done on extracting
correlated information from multiple slices for denoising using self-supervised
deep learning methods. In this work, we propose Deformed2Self, an end-to-end
self-supervised deep learning framework for dynamic imaging denoising. It
combines single-image and multi-image denoising to improve image quality and
use a spatial transformer network to model motion between different slices.
Further, it only requires a single noisy image with a few auxiliary
observations at different time frames for training and inference. Evaluations
on phantom and in vivo data with different noise statistics show that our
method has comparable performance to other state-of-the-art unsupervised or
self-supervised denoising methods and outperforms under high noise levels.",,,arXiv,,,2021-06-23,2021,,,,,,All OA, Green,Preprint,"Xu, Junshen; Adalsteinsson, Elfar","Xu, Junshen (); Adalsteinsson, Elfar ()",,"Xu, Junshen (); Adalsteinsson, Elfar ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139119983,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,
1136,pub.1139119962,10.48550/arxiv.2106.12153,,,Bootstrap Representation Learning for Segmentation on Medical Volumes  and Sequences,"In this work, we propose a novel straightforward method for medical volume
and sequence segmentation with limited annotations. To avert laborious
annotating, the recent success of self-supervised learning(SSL) motivates the
pre-training on unlabeled data. Despite its success, it is still challenging to
adapt typical SSL methods to volume/sequence segmentation, due to their lack of
mining on local semantic discrimination and rare exploitation on volume and
sequence structures. Based on the continuity between slices/frames and the
common spatial layout of organs across volumes/sequences, we introduced a novel
bootstrap self-supervised representation learning method by leveraging the
predictable possibility of neighboring slices. At the core of our method is a
simple and straightforward dense self-supervision on the predictions of local
representations and a strategy of predicting locals based on global context,
which enables stable and reliable supervision for both global and local
representation mining among volumes. Specifically, we first proposed an
asymmetric network with an attention-guided predictor to enforce
distance-specific prediction and supervision on slices within and across
volumes/sequences. Secondly, we introduced a novel prototype-based
foreground-background calibration module to enhance representation consistency.
The two parts are trained jointly on labeled and unlabeled data. When evaluated
on three benchmark datasets of medical volumes and sequences, our model
outperforms existing methods with a large margin of 4.5\% DSC on ACDC, 1.7\% on
Prostate, and 2.3\% on CAMUS. Intensive evaluations reveals the effectiveness
and superiority of our method.",,,arXiv,,,2021-06-23,2021,,,,,,All OA, Green,Preprint,"Chen, Zejian; Zhuo, Wei; Wang, Tianfu; Xue, Wufeng; Ni, Dong","Chen, Zejian (); Zhuo, Wei (); Wang, Tianfu (); Xue, Wufeng (); Ni, Dong ()",,"Chen, Zejian (); Zhuo, Wei (); Wang, Tianfu (); Xue, Wufeng (); Ni, Dong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139119962,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1551,pub.1139862102,10.1109/imcec51613.2021.9482216,,,AMO-Net: abdominal multi-organ segmentation in MRI with a extend Unet,"Abdominal organ-related diseases have become one of the main diseases that affect people’s healthy life. MRI is a clinical diagnosis method for abdominal-related diseases. Through MRI, doctors can have a more intuitive observation of the tissue lesions in the human abdomen to make more detailed observations. Accurate diagnosis, therefore, accurate image segmentation of MRI images has very important clinical value. Traditional segmentation methods are relatively inefficient for organ segmentation with large abdominal deformation, small volume and blurry tissue edges. In this paper, we propose a AMO-Net to overcome these limitations. First, we extend the single encoder-decoder architecture to 2 layers to learn richer feature representations. Second, the feature pyramid structure is introduced into the proposed network, which can effectively handle multi-scale changes, is friendly to small target object recognition, and can be associated with remote feature information. Finally, a module called Hierarchical-Split Block is introduced to improve CNN performance. We evaluate our model on the CHAOS challenge dataset, and the final experiment proves that our model achieves better segmentation performance compared with other state-of-the-art segmentation networks.",This research was supported by the characteristic innovation project of guangdong universities (No. 2019KTSCX256) and the special fund of guangdong science and technology innovation strategy (No. pdjh2020b0676).,This research was supported by the characteristic innovation project of guangdong universities (No. 2019KTSCX256) and the special fund of guangdong science and technology innovation strategy (No. pdjh2020b0676).,,"2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)",,2021-06-20,2021,,2021-06-20,4,,1770-1775,Closed,Proceeding,"Jia, Chao; Wei, Jianjing","Jia, Chao (Guang College of Commerce, Guangzhou, China); Wei, Jianjing (Guang College of Commerce, Guangzhou, China)","Wei, Jianjing ","Jia, Chao (); Wei, Jianjing ()",1,1,,0.77,,https://app.dimensions.ai/details/publication/pub.1139862102,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1452,pub.1138949853,10.1007/978-3-030-78710-3_3,,,Shape Constraints in Deep Learning for Robust 2D Echocardiography Analysis,"Abstract2D Echocardiography is a popular and cost-efficient tool for cardiac dysfunction diagnosis. Automatic solutions that could effectively and efficiently analyse cardiac functions are highly desired in clinical situations. Segmentation and motion tracking are two important techniques to extract useful cardiac indexes, such as left ventricle ejection fraction (LVEF), global longitudinal strain (GLS), etc. However, these tasks are non-trivial since ultrasound images usually suffer from poor signal-to-noise ratio, boundary ambiguity and out of view problem. In this paper, we explore how to introduce shape constraints from global, regional and pixel level into a baseline U-Net model for better segmentation and landmark tracking. Our experiments show that all the three propositions perform similarly as the baseline model in terms of geometrical scores, while our pixel-level model, which uses a multi-class contour loss, reduces segmentation outliers and improves the tracking accuracy of 3 landmarks used for GLS computation. With appropriate augmentation techniques, our models also show a good generalisation performance when testing on a larger unseen cohort.",This work has been supported by the French government through the National Research Agency (ANR) Investments in the Future with 3IA Côte d’Azur (ANR-19-P3IA-0002) and by Inria PhD funding.,,Lecture Notes in Computer Science,Functional Imaging and Modeling of the Heart,,2021-06-18,2021,2021-06-18,2021,12738,,22-34,All OA, Green,Chapter,"Yang, Yingyu; Sermesant, Maxime","Yang, Yingyu (Inria, Université Côte d’Azur, Sophia Antipolis, Nice, France); Sermesant, Maxime (Inria, Université Côte d’Azur, Sophia Antipolis, Nice, France)","Sermesant, Maxime (Université Côte d'Azur)","Yang, Yingyu (Université Côte d'Azur); Sermesant, Maxime (Université Côte d'Azur)",1,1,,0.92,https://hal.archives-ouvertes.fr/hal-03371358/file/FIMH_2021_YingyuYANG.pdf,https://app.dimensions.ai/details/publication/pub.1138949853,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1398,pub.1139725610,10.22146/ijitee.62663,,,Image Analysis for MRI-Based Brain Tumor Classification Using Deep Learning,"Tumors are cells that grow abnormally and uncontrollably, whereas brain tumors are abnormally growing cells growing in or near the brain. It is estimated that 23,890 adults (13,590 males and 10,300 females) in the United States and 3,540 children under the age of 15 would be diagnosed with a brain tumor. Meanwhile, there are over 250 cases in Indonesia of patients afflicted with brain tumors, both adults and infants. The doctor or medical personnel usually conducted a radiological test that commonly performed using magnetic resonance image (MRI) to identify the brain tumor. From several studies, each researcher claims that the results of their proposed method can detect brain tumors with high accuracy; however, there are still flaws in their methods. This paper will discuss the classification of MRI-based brain tumors using deep learning and transfer learning. Transfer learning allows for various domains, functions, and distributions used in training and research. This research used a public dataset. The dataset comprises 253 images, divided into 98 tumor-free brain images and 155 tumor images. Residual Network (ResNet), Neural Architecture Search Network (NASNet), Xception, DenseNet, and Visual Geometry Group (VGG) are the techniques that will use in this paper. The results got to show that the ResNet50 model gets 96% for the accuracy, and VGG16 gets 96% for the accuracy. The results obtained indicate that transfer learning can handle medical images.",,,IJITEE (International Journal of Information Technology and Electrical Engineering),,,2021-06-18,2021,2021-06-18,,5,1,21-28,All OA, Green,Article,"Qodri, Krisna Nuresa; Soesanti, Indah; Nugroho, Hanung Adi","Qodri, Krisna Nuresa (Universitas Gadjah Mada); Soesanti, Indah (Universitas Gadjah Mada); Nugroho, Hanung Adi (Universitas Gadjah Mada)",,"Qodri, Krisna Nuresa (Gadjah Mada University); Soesanti, Indah (Gadjah Mada University); Nugroho, Hanung Adi (Gadjah Mada University)",3,3,,2.46,https://jurnal.ugm.ac.id/ijitee/article/download/62663/31493,https://app.dimensions.ai/details/publication/pub.1139725610,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5672,pub.1138967080,10.3390/diagnostics11061104,34204479,PMC8235574,Group and Shuffle Convolutional Neural Networks with Pyramid Pooling Module for Automated Pterygium Segmentation,"Pterygium is an eye condition that is prevalent among workers that are frequently exposed to sunlight radiation. However, most of them are not aware of this condition, which motivates many volunteers to set up health awareness booths to give them free health screening. As a result, a screening tool that can be operated on various platforms is needed to support the automated pterygium assessment. One of the crucial functions of this assessment is to extract the infected regions, which directly correlates with the severity levels. Hence, Group-PPM-Net is proposed by integrating a spatial pyramid pooling module (PPM) and group convolution to the deep learning segmentation network. The system uses a standard mobile phone camera input, which is then fed to a modified encoder-decoder convolutional neural network, inspired by a Fully Convolutional Dense Network that consists of a total of 11 dense blocks. A PPM is integrated into the network because of its multi-scale capability, which is useful for multi-scale tissue extraction. The shape of the tissues remains relatively constant, but the size will differ according to the severity levels. Moreover, group and shuffle convolution modules are also integrated at the decoder side of Group-PPM-Net by placing them at the starting layer of each dense block. The addition of these modules allows better correlation among the filters in each group, while the shuffle process increases channel variation that the filters can learn from. The results show that the proposed method obtains mean accuracy, mean intersection over union, Hausdorff distance, and Jaccard index performances of 0.9330, 0.8640, 11.5474, and 0.7966, respectively.",,This research was funded by Universiti Kebangsaan Malaysia with grant number GUP-2019-008 and Ministry of Higher Education Malaysia with grant number FRGS/1/2019/ICT02/ UKM/02/1.,Diagnostics,,,2021-06-17,2021,2021-06-17,,11,6,1104,All OA, Gold,Article,"Abdani, Siti Raihanah; Zulkifley, Mohd Asyraf; Zulkifley, Nuraisyah Hani","Abdani, Siti Raihanah (Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering and Built Environment, Universiti Kebangsaan Malaysia, Bangi 43600, Malaysia;, raihanah.abdani@siswa.ukm.edu.my); Zulkifley, Mohd Asyraf (Department of Electrical, Electronic and Systems Engineering, Faculty of Engineering and Built Environment, Universiti Kebangsaan Malaysia, Bangi 43600, Malaysia;, raihanah.abdani@siswa.ukm.edu.my); Zulkifley, Nuraisyah Hani (Community Health Department, Faculty of Medicine and Health Sciences, Universiti Putra Malaysia, Serdang 43400, Malaysia;, GS52834@student.upm.edu.my)","Zulkifley, Mohd Asyraf (National University of Malaysia)","Abdani, Siti Raihanah (National University of Malaysia); Zulkifley, Mohd Asyraf (National University of Malaysia); Zulkifley, Nuraisyah Hani (Universiti Putra Malaysia)",10,10,2.19,8.77,https://www.mdpi.com/2075-4418/11/6/1104/pdf?version=1623982952,https://app.dimensions.ai/details/publication/pub.1138967080,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1399,pub.1138981839,10.48550/arxiv.2106.09157,,,Positional Contrastive Learning for Volumetric Medical Image  Segmentation,"The success of deep learning heavily depends on the availability of large
labeled training sets. However, it is hard to get large labeled datasets in
medical image domain because of the strict privacy concern and costly labeling
efforts. Contrastive learning, an unsupervised learning technique, has been
proved powerful in learning image-level representations from unlabeled data.
The learned encoder can then be transferred or fine-tuned to improve the
performance of downstream tasks with limited labels. A critical step in
contrastive learning is the generation of contrastive data pairs, which is
relatively simple for natural image classification but quite challenging for
medical image segmentation due to the existence of the same tissue or organ
across the dataset. As a result, when applied to medical image segmentation,
most state-of-the-art contrastive learning frameworks inevitably introduce a
lot of false-negative pairs and result in degraded segmentation quality. To
address this issue, we propose a novel positional contrastive learning (PCL)
framework to generate contrastive data pairs by leveraging the position
information in volumetric medical images. Experimental results on CT and MRI
datasets demonstrate that the proposed PCL method can substantially improve the
segmentation performance compared to existing methods in both semi-supervised
setting and transfer learning setting.",,,arXiv,,,2021-06-16,2021,,,,,,All OA, Green,Preprint,"Zeng, Dewen; Wu, Yawen; Hu, Xinrong; Xu, Xiaowei; Yuan, Haiyun; Huang, Meiping; Zhuang, Jian; Hu, Jingtong; Shi, Yiyu","Zeng, Dewen (); Wu, Yawen (); Hu, Xinrong (); Xu, Xiaowei (); Yuan, Haiyun (); Huang, Meiping (); Zhuang, Jian (); Hu, Jingtong (); Shi, Yiyu ()",,"Zeng, Dewen (); Wu, Yawen (); Hu, Xinrong (); Xu, Xiaowei (); Yuan, Haiyun (); Huang, Meiping (); Zhuang, Jian (); Hu, Jingtong (); Shi, Yiyu ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138981839,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5684,pub.1138727635,10.1016/j.compmedimag.2021.101952,34144318,,Automatic left ventricular cavity segmentation via deep spatial sequential network in 4D computed tomography,"Automated segmentation of left ventricular cavity (LVC) in temporal cardiac image sequences (consisting of multiple time-points) is a fundamental requirement for quantitative analysis of cardiac structural and functional changes. Deep learning methods for segmentation are the state-of-the-art in performance; however, these methods are generally formulated to work on a single time-point, and thus disregard the complementary information available from the temporal image sequences that can aid in segmentation accuracy and consistency across the time-points. In particular, single time-point segmentation methods perform poorly in segmenting the end-systole (ES) phase image in the cardiac sequence, where the left ventricle deforms to the smallest irregular shape, and the boundary between the blood chamber and the myocardium becomes inconspicuous and ambiguous. To overcome these limitations in automatically segmenting temporal LVCs, we present a spatial sequential network (SS-Net) to learn the deformation and motion characteristics of the LVCs in an unsupervised manner; these characteristics are then integrated with sequential context information derived from bi-directional learning (BL) where both chronological and reverse-chronological directions of the image sequence are used. Our experimental results on a cardiac computed tomography (CT) dataset demonstrate that our spatial-sequential network with bi-directional learning (SS-BL-Net) outperforms existing methods for spatiotemporal LVC segmentation.","This work was supported in part by the University of Sydney – Shanghai Jiao Tong University Joint Research Alliance grant, the Australian Research Council (ARC) (DP200103748 and IC170100022) and the Science and Technology Commission of Shanghai Municipality (19QC1400600). Conflict of interest: None declared.",,Computerized Medical Imaging and Graphics,,"Four-Dimensional Computed Tomography; Heart; Heart Ventricles; Image Processing, Computer-Assisted",2021-06-09,2021,2021-06-09,2021-07,91,,101952,Closed,Article,"Guo, Yuyu; Bi, Lei; Zhu, Zhengbin; Feng, David Dagan; Zhang, Ruiyan; Wang, Qian; Kim, Jinman","Guo, Yuyu (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China; School of Computer Science, University of Sydney, NSW 2006, Australia.); Bi, Lei (School of Computer Science, University of Sydney, NSW 2006, Australia.); Zhu, Zhengbin (Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai 200025, China.); Feng, David Dagan (School of Computer Science, University of Sydney, NSW 2006, Australia.); Zhang, Ruiyan (Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai 200025, China.); Wang, Qian (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China. Electronic address: wang.qian@sjtu.edu.cn.); Kim, Jinman (School of Computer Science, University of Sydney, NSW 2006, Australia. Electronic address: jinman.kim@sydney.edu.au.)","Wang, Qian (Shanghai Jiao Tong University); Kim, Jinman (The University of Sydney)","Guo, Yuyu (Shanghai Jiao Tong University; The University of Sydney); Bi, Lei (The University of Sydney); Zhu, Zhengbin (Ruijin Hospital; Shanghai Jiao Tong University); Feng, David Dagan (The University of Sydney); Zhang, Ruiyan (Ruijin Hospital; Shanghai Jiao Tong University); Wang, Qian (Shanghai Jiao Tong University); Kim, Jinman (The University of Sydney)",6,6,0.38,4.65,,https://app.dimensions.ai/details/publication/pub.1138727635,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
1138,pub.1138734646,10.1080/02564602.2021.1937349,,,An Augmented Deep Learning Network with Noise Suppression Feature for Efficient Segmentation of Magnetic Resonance Images,"The segmentation of cardiac MR images requires extensive attention as it needs a high level of care and analysis for the diagnosis of affected part. The advent of deep learning technology has paved the way for efficient, automatic and reliable segmentation of medical images for proper diagnosis. This manuscript proposes an augmented end to end trainable deep learning architecture for efficient segmentation of various domains of medical images. The model incorporates the depth wise separable convolution and group normalization as basic building blocks. Moreover, a noise stifler block is also induced between the encoder and decoder to counter the noise in the medical images. This path helps in delineating the precise boundary contours as the noise often reduces the boundary segmentation capability of the segmentation network. The network trained once produces exceedingly good results for the images of other datasets. An improvement of above (5 ± 0.03) % and (3.5 ± 0.02) % was observed in the Jaccard index and Dice score for cardiac MR images. The results are statistically validated as p < 0.05. The automatic computer investigated approach can help in reducing the burden on the medical system by producing accurate and reliable results. The algorithmic results were clinically verified by the senior radiologists by comparison with the manually segmented images. The training time of the network was about 30% less than U-net.",,,IETE Technical Review,,,2021-06-09,2021,2021-06-09,2022-07-04,39,4,960-973,Closed,Article,"Tripathi, Sumit; Sharan, Taresh Sarvesh; Sharma, Shiru; Sharma, Neeraj","Tripathi, Sumit (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India); Sharan, Taresh Sarvesh (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India); Sharma, Shiru (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India); Sharma, Neeraj (School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University), Varanasi, U.P., 221 005, India)","Sharan, Taresh Sarvesh (Indian Institute of Technology BHU)","Tripathi, Sumit (Indian Institute of Technology BHU); Sharan, Taresh Sarvesh (Indian Institute of Technology BHU); Sharma, Shiru (Indian Institute of Technology BHU); Sharma, Neeraj (Indian Institute of Technology BHU)",11,11,,9.0,,https://app.dimensions.ai/details/publication/pub.1138734646,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
5850,pub.1131399664,10.1109/jbhi.2020.3028463,33006934,,DBAN: Adversarial Network With Multi-Scale Features for Cardiac MRI Segmentation,"With the development of medical artificial intelligence, automatic magnetic resonance image (MRI) segmentation method is quite desirable. Inspired by the power of deep neural networks, a novel deep adversarial network, dilated block adversarial network (DBAN), is proposed to perform left ventricle, right ventricle, and myocardium segmentation in short-axis cardiac MRI. DBAN contains a segmentor along with a discriminator. In the segmentor, the dilated block (DB) is proposed to capture, and aggregate multi-scale features. The segmentor can produce segmentation probability maps while the discriminator can differentiate the segmentation probability map, and the ground truth at the pixel level. In addition, confidence probability maps generated by the discriminator can guide the segmentor to modify segmentation probability maps. Extensive experiments demonstrate that DBAN has achieved the state-of-the-art performance on the ACDC dataset. Quantitative analyses indicate that cardiac function indices from DBAN are similar to those from clinical experts. Therefore, DBAN can be a potential candidate for short-axis cardiac MRI segmentation in clinical applications.","This work was supported in part by the National Natural Science Foundation of China under Grants 81427803 and 81771940, in part by the National Key Research and Development Program of China under Grant 2017YFC0108000, in part by the Beijing National Science Foundation under Grants 7172122 and L172003, and in part by the Introduced Talent Program of Southwest University under Grant SWU020008.",,IEEE Journal of Biomedical and Health Informatics,,"Artificial Intelligence; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer",2021-06-03,2021,2021-06-03,2021-06,25,6,2018-2028,Closed,Article,"Yang, Xinyu; Zhang, Yuan; Lo, Benny; Wu, Dongrui; Liao, Hongen; Zhang, Yuan-Ting","Yang, Xinyu (Chongqing Key Laboratory of Nonlinear Circuits, and Intelligent Information Processing, College of Electronic and Information Engineering, Southwest University, Chongqing, 400715, China); Zhang, Yuan (Chongqing Key Laboratory of Nonlinear Circuits, and Intelligent Information Processing, College of Electronic and Information Engineering, Southwest University, Chongqing, 400715, China); Lo, Benny (Hamlyn Centre, Imperial College London, London, SW7 2AZ, U.K.); Wu, Dongrui (School of Artificial Intelligence, and Automation, Huazhong University of Science and Technology, Wuhan, 430074, China); Liao, Hongen (Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, 100084, China); Zhang, Yuan-Ting (Department of Mechanical and Biomedical Engineering, City University of Hong Kong, Hong Kong, China)","Zhang, Yuan (Southwest University)","Yang, Xinyu (Southwest University); Zhang, Yuan (Southwest University); Lo, Benny (Imperial College London); Wu, Dongrui (Huazhong University of Science and Technology); Liao, Hongen (Tsinghua University); Zhang, Yuan-Ting (City University of Hong Kong)",13,13,1.09,10.64,,https://app.dimensions.ai/details/publication/pub.1131399664,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
4808,pub.1135473571,10.1109/tmi.2021.3060497,33606627,,Learning With Context Feedback Loop for Robust Medical Image Segmentation,"Deep learning has successfully been leveraged for medical image segmentation. It employs convolutional neural networks (CNN) to learn distinctive image features from a defined pixel-wise objective function. However, this approach can lead to less output pixel interdependence producing incomplete and unrealistic segmentation results. In this paper, we present a fully automatic deep learning method for robust medical image segmentation by formulating the segmentation problem as a recurrent framework using two systems. The first one is a forward system of an encoder-decoder CNN that predicts the segmentation result from the input image. The predicted probabilistic output of the forward system is then encoded by a fully convolutional network (FCN)-based context feedback system. The encoded feature space of the FCN is then integrated back into the forward system's feed-forward learning process. Using the FCN-based context feedback loop allows the forward system to learn and extract more high-level image features and fix previous mistakes, thereby improving prediction accuracy over time. Experimental results, performed on four different clinical datasets, demonstrate our method's potential application for single and multi-structure medical image segmentation by outperforming the state of the art methods. With the feedback loop, deep learning methods can now produce results that are both anatomically plausible and robust to low contrast images. Therefore, formulating image segmentation as a recurrent framework of two interconnected networks via context feedback loop can be a potential method for robust and efficient medical image analysis.",,,IEEE Transactions on Medical Imaging,,"Feedback; Image Processing, Computer-Assisted; Neural Networks, Computer",2021-06-01,2021,2021-06-01,2021-06,40,6,1542-1554,All OA, Green,Article,"Girum, Kibrom Berihu; Créhange, Gilles; Lalande, Alain","Girum, Kibrom Berihu (Imaging and Artificial Vision (ImViA) Research Laboratory, University of Burgundy, 21000, Dijon, France; Department of Radiation Oncology, Centre Georges François Leclerc (CGFL), 21000, Dijon, France); Créhange, Gilles (Imaging and Artificial Vision (ImViA) Research Laboratory, University of Burgundy, 21000, Dijon, France; Department of Radiation Oncology, Centre Georges François Leclerc (CGFL), 21000, Dijon, France; Department of Radiation Oncology, Institute of Curie, 75005, Paris, France); Lalande, Alain (Imaging and Artificial Vision (ImViA) Research Laboratory, University of Burgundy, 21000, Dijon, France; Department of Medical Imaging, University Hospital of Dijon, 2100, Dijon, France)","Girum, Kibrom Berihu (University of Burgundy; Centre Georges François Leclerc)","Girum, Kibrom Berihu (University of Burgundy; Centre Georges François Leclerc); Créhange, Gilles (University of Burgundy; Centre Georges François Leclerc; Institute Curie); Lalande, Alain (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne)",16,16,2.34,12.74,http://arxiv.org/pdf/2103.02844,https://app.dimensions.ai/details/publication/pub.1135473571,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5855,pub.1138882279,10.21037/cdt.2020.03.09,34295713,PMC8261749,Artificial intelligence in personalized cardiovascular medicine and cardiovascular imaging,"The collection of large, heterogeneous electronic datasets and imaging from patients with cardiovascular disease (CVD) has lent itself to the use of sophisticated analysis using artificial intelligence (AI). AI techniques such as machine learning (ML) are able to identify relationships between data points by linking input to output variables using a combination of different functions, such as neural networks. In cardiovascular medicine, this is especially pertinent for classification, diagnosis, risk prediction and treatment guidance. Common cardiovascular data sources from patients include genomic data, cardiovascular imaging, wearable sensors and electronic health records (EHR). Leveraging AI in analysing such data points: (I) for clinicians: more accurate and streamlined image interpretation and diagnosis; (II) for health systems: improved workflow and reductions in medical errors; (III) for patients: promoting health with further education and promoting primary and secondary cardiovascular health prevention. This review addresses the need for AI in cardiovascular medicine by reviewing recent literature in different cardiovascular imaging modalities: electrocardiography, echocardiography, cardiac computed tomography, cardiac nuclear imaging, and cardiac magnetic resonance (CMR) imaging as well as the role of EHR. This review aims to conceptulise these studies in relation to their clinical applications, potential limitations and future opportunities and directions.",,,Cardiovascular Diagnosis and Therapy,,,2021-06,2021,2021-06,2021-06,0,0,0-0,Closed,Article,"Haq, Ikram-Ul; Haq, Iqraa; Xu, Bo","Haq, Ikram-Ul (Imperial College London Faculty of Medicine, London, UK.); Haq, Iqraa (Imperial College London Faculty of Medicine, London, UK.); Xu, Bo (Section of Cardiovascular Imaging, Robert and Suzanne Tomsich Department of Cardiovascular Medicine, Sydell and Arnold Family Heart, Vascular and Thoracic Institute, Cleveland Clinic, Cleveland, OH, USA.)",,"Haq, Ikram-Ul (Imperial College London); Haq, Iqraa (Imperial College London); Xu, Bo (Cleveland Clinic)",8,8,0.63,7.93,,https://app.dimensions.ai/details/publication/pub.1138882279,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,,,,,
1545,pub.1138436416,10.48550/arxiv.2105.12924,,,Self-Ensembling Contrastive Learning for Semi-Supervised Medical Image  Segmentation,"Deep learning has demonstrated significant improvements in medical image
segmentation using a sufficiently large amount of training data with manual
labels. Acquiring well-representative labels requires expert knowledge and
exhaustive labors. In this paper, we aim to boost the performance of
semi-supervised learning for medical image segmentation with limited labels
using a self-ensembling contrastive learning technique. To this end, we propose
to train an encoder-decoder network at image-level with small amounts of
labeled images, and more importantly, we learn latent representations directly
at feature-level by imposing contrastive loss on unlabeled images. This method
strengthens intra-class compactness and inter-class separability, so as to get
a better pixel classifier. Moreover, we devise a student encoder for online
learning and an exponential moving average version of it, called teacher
encoder, to improve the performance iteratively in a self-ensembling manner. To
construct contrastive samples with unlabeled images, two sampling strategies
that exploit structure similarity across medical images and utilize
pseudo-labels for construction, termed region-aware and anatomical-aware
contrastive sampling, are investigated. We conduct extensive experiments on an
MRI and a CT segmentation dataset and demonstrate that in a limited label
setting, the proposed method achieves state-of-the-art performance. Moreover,
the anatomical-aware strategy that prepares contrastive samples on-the-fly
using pseudo-labels realizes better contrastive regularization on feature
representations.",,,arXiv,,,2021-05-26,2021,,,,,,All OA, Green,Preprint,"Xiang, Jinxi; Li, Zhuowei; Wang, Wenji; Xia, Qing; Zhang, Shaoting","Xiang, Jinxi (); Li, Zhuowei (); Wang, Wenji (); Xia, Qing (); Zhang, Shaoting ()",,"Xiang, Jinxi (); Li, Zhuowei (); Wang, Wenji (); Xia, Qing (); Zhang, Shaoting ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138436416,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
866,pub.1138396694,10.48550/arxiv.2105.12227,,,Learning a Model-Driven Variational Network for Deformable Image  Registration,"Data-driven deep learning approaches to image registration can be less
accurate than conventional iterative approaches, especially when training data
is limited. To address this whilst retaining the fast inference speed of deep
learning, we propose VR-Net, a novel cascaded variational network for
unsupervised deformable image registration. Using the variable splitting
optimization scheme, we first convert the image registration problem,
established in a generic variational framework, into two sub-problems, one with
a point-wise, closed-form solution while the other one is a denoising problem.
We then propose two neural layers (i.e. warping layer and intensity consistency
layer) to model the analytical solution and a residual U-Net to formulate the
denoising problem (i.e. generalized denoising layer). Finally, we cascade the
warping layer, intensity consistency layer, and generalized denoising layer to
form the VR-Net. Extensive experiments on three (two 2D and one 3D) cardiac
magnetic resonance imaging datasets show that VR-Net outperforms
state-of-the-art deep learning methods on registration accuracy, while
maintains the fast inference speed of deep learning and the data-efficiency of
variational model.",,,arXiv,,,2021-05-25,2021,,,,,,All OA, Green,Preprint,"Jia, Xi; Thorley, Alexander; Chen, Wei; Qiu, Huaqi; Shen, Linlin; Styles, Iain B; Chang, Hyung Jin; Leonardis, Ales; de Marvao, Antonio; O'Regan, Declan P.; Rueckert, Daniel; Duan, Jinming","Jia, Xi (); Thorley, Alexander (); Chen, Wei (); Qiu, Huaqi (); Shen, Linlin (); Styles, Iain B (); Chang, Hyung Jin (); Leonardis, Ales (); de Marvao, Antonio (); O'Regan, Declan P. (); Rueckert, Daniel (); Duan, Jinming ()",,"Jia, Xi (); Thorley, Alexander (); Chen, Wei (); Qiu, Huaqi (); Shen, Linlin (); Styles, Iain B (); Chang, Hyung Jin (); Leonardis, Ales (); de Marvao, Antonio (); O'Regan, Declan P. (); Rueckert, Daniel (); Duan, Jinming ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138396694,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,
1010,pub.1138329453,10.48550/arxiv.2105.10738,,,MIASSR: An Approach for Medical Image Arbitrary Scale Super-Resolution,"Single image super-resolution (SISR) aims to obtain a high-resolution output
from one low-resolution image. Currently, deep learning-based SISR approaches
have been widely discussed in medical image processing, because of their
potential to achieve high-quality, high spatial resolution images without the
cost of additional scans. However, most existing methods are designed for
scale-specific SR tasks and are unable to generalise over magnification scales.
In this paper, we propose an approach for medical image arbitrary-scale
super-resolution (MIASSR), in which we couple meta-learning with generative
adversarial networks (GANs) to super-resolve medical images at any scale of
magnification in (1, 4]. Compared to state-of-the-art SISR algorithms on
single-modal magnetic resonance (MR) brain images (OASIS-brains) and
multi-modal MR brain images (BraTS), MIASSR achieves comparable fidelity
performance and the best perceptual quality with the smallest model size. We
also employ transfer learning to enable MIASSR to tackle SR tasks of new
medical modalities, such as cardiac MR images (ACDC) and chest computed
tomography images (COVID-CT). The source code of our work is also public. Thus,
MIASSR has the potential to become a new foundational pre-/post-processing step
in clinical image analysis tasks such as reconstruction, image quality
enhancement, and segmentation.",,,arXiv,,,2021-05-22,2021,,,,,,All OA, Green,Preprint,"Zhu, Jin; Tan, Chuan; Yang, Junwei; Yang, Guang; Lio', Pietro","Zhu, Jin (); Tan, Chuan (); Yang, Junwei (); Yang, Guang (); Lio', Pietro ()",,"Zhu, Jin (); Tan, Chuan (); Yang, Junwei (); Yang, Guang (); Lio', Pietro ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138329453,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,
5732,pub.1138213621,10.3389/fnins.2021.652073,34093112,PMC8175846,"Editorial: Recent Developments of Deep Learning in Analyzing, Decoding, and Understanding Neuroimaging Signals",,,,Frontiers in Neuroscience,,,2021-05-21,2021,2021-05-21,,15,,652073,All OA, Gold,Article,"Li, Junhua","Li, Junhua (Laboratory for Brain-Bionic Intelligence and Computational Neuroscience, Wuyi University, Jiangmen, China; School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom)","Li, Junhua (Wuyi University; University of Essex)","Li, Junhua (Wuyi University; University of Essex)",0,0,,0.0,https://www.frontiersin.org/articles/10.3389/fnins.2021.652073/pdf,https://app.dimensions.ai/details/publication/pub.1138213621,52 Psychology, 5204 Cognitive and Computational Psychology,,,,,,,,,,
4549,pub.1138147505,10.1016/j.compbiomed.2021.104472,34023696,,MRI and CT bladder segmentation from classical to deep learning based approaches: Current limitations and lessons,"Precise determination and assessment of bladder cancer (BC) extent of muscle invasion involvement guides proper risk stratification and personalized therapy selection. In this context, segmentation of both bladder walls and cancer are of pivotal importance, as it provides invaluable information to stage the primary tumor. Hence, multiregion segmentation on patients presenting with symptoms of bladder tumors using deep learning heralds a new level of staging accuracy and prediction of the biologic behavior of the tumor. Nevertheless, despite the success of these models in other medical problems, progress in multiregion bladder segmentation, particularly in MRI and CT modalities, is still at a nascent stage, with just a handful of works tackling a multiregion scenario. Furthermore, most existing approaches systematically follow prior literature in other clinical problems, without casting a doubt on the validity of these methods on bladder segmentation, which may present different challenges. Inspired by this, we provide an in-depth look at bladder cancer segmentation using deep learning models. The critical determinants for accurate differentiation of muscle invasive disease, current status of deep learning based bladder segmentation, lessons and limitations of prior work are highlighted.",,,Computers in Biology and Medicine,,"Deep Learning; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Tomography, X-Ray Computed; Urinary Bladder",2021-05-18,2021,2021-05-18,2021-07,134,,104472,Closed,Article,"Bandyk, Mark G.; Gopireddy, Dheeraj R.; Lall, Chandana; Balaji, K.C.; Dolz, Jose","Bandyk, Mark G. (Department of Urology, University of Florida, Jacksonville, FL, USA); Gopireddy, Dheeraj R. (Department of Radiology, University of Florida, Jacksonville, FL, USA); Lall, Chandana (Department of Radiology, University of Florida, Jacksonville, FL, USA); Balaji, K.C. (Department of Urology, University of Florida, Jacksonville, FL, USA); Dolz, Jose (ETS Montreal, QC, Canada)","Bandyk, Mark G. (University of Florida); Dolz, Jose ","Bandyk, Mark G. (University of Florida); Gopireddy, Dheeraj R. (University of Florida); Lall, Chandana (University of Florida); Balaji, K.C. (University of Florida); Dolz, Jose ()",15,15,3.69,10.57,,https://app.dimensions.ai/details/publication/pub.1138147505,31 Biological Sciences, 3102 Bioinformatics and Computational Biology, 42 Health Sciences, 4203 Health Services and Systems, 46 Information and Computing Sciences, 4601 Applied Computing,3 Good Health and Well Being,,,,,,
6517,pub.1138116029,10.1155/2021/9960199,34055042,PMC8143880,LCC-Net: A Lightweight Cross-Consistency Network for Semisupervised Cardiac MR Image Segmentation,"Semantic segmentation plays a crucial role in cardiac magnetic resonance (MR) image analysis. Although supervised deep learning methods have made significant performance improvements, they highly rely on a large amount of pixel-wise annotated data, which are often unavailable in clinical practices. Besides, top-performing methods usually have a vast number of parameters, which result in high computation complexity for model training and testing. This study addresses cardiac image segmentation in scenarios where few labeled data are available with a lightweight cross-consistency network named LCC-Net. Specifically, to reduce the risk of overfitting on small labeled datasets, we substitute computationally intensive standard convolutions with a lightweight module. To leverage plenty of unlabeled data, we introduce extreme consistency learning, which enforces equivariant constraints on the predictions of different perturbed versions of the input image. Cutting and mixing different training images, as an extreme perturbation on both the labeled and unlabeled data, are utilized to enhance the robust representation learning. Extensive comparisons demonstrate that the proposed model shows promising performance with high annotation- and computation-efficiency. With only two annotated subjects for model training, the LCC-Net obtains a performance gain of 14.4% in the mean Dice over the baseline U-Net trained from scratch.","This work was supported in part by the NSFC under Grant 11771160, the Fund of HQU (ZQN-PY411), and by STPF under Grant 2019H0016.",,Computational and Mathematical Methods in Medicine,,"Computational Biology; Databases, Factual; Deep Learning; Heart; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Supervised Machine Learning; Unsupervised Machine Learning",2021-05-17,2021,2021-05-17,2021-05-17,2021,,9960199,All OA, Gold,Article,"Song, Lai; Yi, Jiajin; Peng, Jialin","Song, Lai (College of Computer Science and Technology, Huaqiao University, Xiamen 361021, China, hqu.edu.cn); Yi, Jiajin (College of Computer Science and Technology, Huaqiao University, Xiamen 361021, China, hqu.edu.cn); Peng, Jialin (College of Computer Science and Technology, Huaqiao University, Xiamen 361021, China, hqu.edu.cn; Xiamen Key Laboratory of Computer Vision and Pattern Recognition, Huaqiao University, Xiamen 361021, China, hqu.edu.cn)","Peng, Jialin (Huaqiao University; Huaqiao University)","Song, Lai (Huaqiao University); Yi, Jiajin (Huaqiao University); Peng, Jialin (Huaqiao University; Huaqiao University)",0,0,,0.0,https://downloads.hindawi.com/journals/cmmm/2021/9960199.pdf,https://app.dimensions.ai/details/publication/pub.1138116029,40 Engineering, 4003 Biomedical Engineering, 49 Mathematical Sciences, 4901 Applied Mathematics,,,,,,,,
1844,pub.1138177199,10.48550/arxiv.2105.08157,,,Cardiac Functional Analysis with Cine MRI via Deep Learning  Reconstruction,"Retrospectively gated cine (retro-cine) MRI is the clinical standard for
cardiac functional analysis. Deep learning (DL) based methods have been
proposed for the reconstruction of highly undersampled MRI data and show
superior image quality and magnitude faster reconstruction time than CS-based
methods. Nevertheless, it remains unclear whether DL reconstruction is suitable
for cardiac function analysis. To address this question, in this study we
evaluate and compare the cardiac functional values (EDV, ESV and EF for LV and
RV, respectively) obtained from highly accelerated MRI acquisition using DL
based reconstruction algorithm (DL-cine) with values from CS-cine and
conventional retro-cine. To the best of our knowledge, this is the first work
to evaluate the cine MRI with deep learning reconstruction for cardiac function
analysis and compare it with other conventional methods. The cardiac functional
values obtained from cine MRI with deep learning reconstruction are consistent
with values from clinical standard retro-cine MRI.",,,arXiv,,,2021-05-17,2021,,,,,,All OA, Green,Preprint,"Chen, Eric Z.; Chen, Xiao; Lyu, Jingyuan; Liu, Qi; Zhang, Zhongqi; Ding, Yu; Zhang, Shuheng; Chen, Terrence; Xu, Jian; Sun, Shanhui","Chen, Eric Z. (); Chen, Xiao (); Lyu, Jingyuan (); Liu, Qi (); Zhang, Zhongqi (); Ding, Yu (); Zhang, Shuheng (); Chen, Terrence (); Xu, Jian (); Sun, Shanhui ()",,"Chen, Eric Z. (); Chen, Xiao (); Lyu, Jingyuan (); Liu, Qi (); Zhang, Zhongqi (); Ding, Yu (); Zhang, Shuheng (); Chen, Terrence (); Xu, Jian (); Sun, Shanhui ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138177199,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
4154,pub.1138038004,10.1007/s11517-021-02372-4,33983494,,Parametric-based feature selection via spherical harmonic coefficients for the left ventricle myocardial infarction screening,"Computer-aided diagnosis (CAD) of heart diseases using machine learning techniques has recently received much attention. In this study, we present a novel parametric-based feature selection method using the three-dimensional spherical harmonic (SHs) shape descriptors of the left ventricle (LV) for intelligent myocardial infarction (MI) classification. The main hypothesis is that the SH coefficients of the parameterized endocardial shapes in MI patients are recognizable and distinguishable from healthy subjects. The SH parameterization, expansion, and registration of the LV endocardial shapes were performed, then parametric-based features were extracted. The proposed method performance was investigated by varying considered phases (i.e., the end-systole (ES) or the end-diastole (ED) frames), the spatial alignment procedures based on three modes (i.e., the center of the apical (CoA), the center of mass (CoM), and the center of the basal (CoB)), and considered orders of SH coefficients. After applying principal component analysis (PCA) on the feature vectors, support vector machine (SVM), K-nearest neighbors (K-NN), and random forest (RF) were trained and tested using the leave-one-out cross-validation (LOOCV). The proposed method validation was performed via a dataset containing healthy and MI subjects selected from the automated cardiac diagnosis challenge (ACDC) database. The promising results show the effectiveness of the proposed classification model. SVM reached the best performance with accuracy, sensitivity, specificity, and F-score of 97.50%, 95.00%, 100.00%, and 97.56%, respectively, using the introduced optimum feature set. This study demonstrates the robustness of combining the SH coefficients and machine learning techniques. We also quantify and notably highlight the contribution of different parameters in the classification and finally introduce an optimal feature set with maximum discriminant strength for the MI classification task. Moreover, the obtained results confirm that the proposed method performs more accurately than conventional point-based methods and also the current start-of-the-art, i.e., clinical measures. We showed our method’s generalizability using employing it in dilated cardiomyopathy (DCM) detection and achieving promising results too.Graphical abstractParametric-based feature selection via spherical harmonics coefficients for the left ventricle myocardial infarction screening",,,Medical & Biological Engineering & Computing,,"Algorithms; Diagnosis, Computer-Assisted; Heart Ventricles; Humans; Myocardial Infarction; Support Vector Machine",2021-05-13,2021,2021-05-13,2021-06,59,6,1261-1283,Closed,Article,"Valizadeh, Gelareh; Babapour Mofrad, Farshid; Shalbaf, Ahmad","Valizadeh, Gelareh (Department of Medical Radiation Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran); Babapour Mofrad, Farshid (Department of Medical Radiation Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran); Shalbaf, Ahmad (Department of Biomedical Engineering and Medical Physics, School of Medicine, Shahid Beheshti University of Medical Sciences, Tehran, Iran)","Babapour Mofrad, Farshid (Islamic Azad University, Science and Research Branch)","Valizadeh, Gelareh (Islamic Azad University, Science and Research Branch); Babapour Mofrad, Farshid (Islamic Azad University, Science and Research Branch); Shalbaf, Ahmad (Shahid Beheshti University of Medical Sciences)",4,4,0.62,3.18,,https://app.dimensions.ai/details/publication/pub.1138038004,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,,
4135,pub.1138023865,10.3390/s21103363,34066042,PMC8151599,Multi-Scale Squeeze U-SegNet with Multi Global Attention for Brain MRI Segmentation,"In this paper, we propose a multi-scale feature extraction with novel attention-based convolutional learning using the U-SegNet architecture to achieve segmentation of brain tissue from a magnetic resonance image (MRI). Although convolutional neural networks (CNNs) show enormous growth in medical image segmentation, there are some drawbacks with the conventional CNN models. In particular, the conventional use of encoder-decoder approaches leads to the extraction of similar low-level features multiple times, causing redundant use of information. Moreover, due to inefficient modeling of long-range dependencies, each semantic class is likely to be associated with non-accurate discriminative feature representations, resulting in low accuracy of segmentation. The proposed global attention module refines the feature extraction and improves the representational power of the convolutional neural network. Moreover, the attention-based multi-scale fusion strategy can integrate local features with their corresponding global dependencies. The integration of fire modules in both the encoder and decoder paths can significantly reduce the computational complexity owing to fewer model parameters. The proposed method was evaluated on publicly accessible datasets for brain tissue segmentation. The experimental results show that our proposed model achieves segmentation accuracies of 94.81% for cerebrospinal fluid (CSF), 95.54% for gray matter (GM), and 96.33% for white matter (WM) with a noticeably reduced number of learnable parameters. Our study shows better segmentation performance, improving the prediction accuracy by 2.5% in terms of dice similarity index while achieving a 4.5 times reduction in the number of learnable parameters compared to previously developed U-SegNet based segmentation approaches. This demonstrates that the proposed approach can achieve reliable and precise automatic segmentation of brain MRI images.",Not applicable.,"This work was supported by a research fund from Chosun University, 2018.",Sensors,,"Brain; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Semantics",2021-05-12,2021,2021-05-12,,21,10,3363,All OA, Gold,Article,"Dayananda, Chaitra; Choi, Jae-Young; Lee, Bumshik","Dayananda, Chaitra (Department of Information and Communications Engineering, Chosun University, Gwangju 61452, Korea;, chaitrad@chosun.kr); Choi, Jae-Young (Division of Computer Engineering, Hankuk University of Foreign Studies, Yongin 17035, Korea;, jychoi@hufs.ac.kr); Lee, Bumshik (Department of Information and Communications Engineering, Chosun University, Gwangju 61452, Korea;, chaitrad@chosun.kr)","Lee, Bumshik (Chosun University)","Dayananda, Chaitra (Chosun University); Choi, Jae-Young (Hankuk University of Foreign Studies); Lee, Bumshik (Chosun University)",8,8,0.63,6.33,https://www.mdpi.com/1424-8220/21/10/3363/pdf?version=1620817439,https://app.dimensions.ai/details/publication/pub.1138023865,40 Engineering, 46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,
1170,pub.1138036686,10.48550/arxiv.2105.05318,,,GANs for Medical Image Synthesis: An Empirical Study,"Generative Adversarial Networks (GANs) have become increasingly powerful,
generating mind-blowing photorealistic images that mimic the content of
datasets they were trained to replicate. One recurrent theme in medical imaging
is whether GANs can also be effective at generating workable medical data as
they are for generating realistic RGB images. In this paper, we perform a
multi-GAN and multi-application study to gauge the benefits of GANs in medical
imaging. We tested various GAN architectures from basic DCGAN to more
sophisticated style-based GANs on three medical imaging modalities and organs
namely : cardiac cine-MRI, liver CT and RGB retina images. GANs were trained on
well-known and widely utilized datasets from which their FID score were
computed to measure the visual acuity of their generated images. We further
tested their usefulness by measuring the segmentation accuracy of a U-Net
trained on these generated images.
  Results reveal that GANs are far from being equal as some are ill-suited for
medical imaging applications while others are much better off. The
top-performing GANs are capable of generating realistic-looking medical images
by FID standards that can fool trained experts in a visual Turing test and
comply to some metrics. However, segmentation results suggests that no GAN is
capable of reproducing the full richness of a medical datasets.",,,arXiv,,,2021-05-11,2021,,,,,,All OA, Green,Preprint,"Skandarani, Youssef; Jodoin, Pierre-Marc; Lalande, Alain","Skandarani, Youssef (); Jodoin, Pierre-Marc (); Lalande, Alain ()",,"Skandarani, Youssef (); Jodoin, Pierre-Marc (); Lalande, Alain ()",2,2,,1.64,,https://app.dimensions.ai/details/publication/pub.1138036686,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
8401,pub.1137734569,10.1016/j.cmpb.2021.106142,34004500,,Multiscale attention guided U-Net architecture for cardiac segmentation in short-axis MRI images,"BACKGROUND AND OBJECTIVE: Automatic cardiac segmentation plays an utmost role in the diagnosis and quantification of cardiovascular diseases.
METHODS: This paper proposes a new cardiac segmentation method in short-axis Magnetic Resonance Imaging (MRI) images, called attention U-Net architecture with input image pyramid and deep supervised output layers (AID), which can fully-automatically learn to pay attention to target structures of various sizes and shapes. During each training process, the model continues to learn how to emphasize the desired features and suppress irrelevant areas in the original images, effectively improving the accuracy of cardiac segmentation. At the same time, we introduce the Focal Tversky Loss (FTL), which can effectively solve the problem of high imbalance in the amount of data between the target class and the background class during cardiac image segmentation. In order to obtain a better representation of intermediate features, we add a multi-scale input pyramid to the attention network.
RESULTS: The proposed cardiac segmentation technique is tested on the public Left Ventricle Segmentation Challenge (LVSC) dataset, which is shown to achieve 0.75, 0.87 and 0.92 for Jaccard Index, Sensitivity and Specificity, respectively. Experimental results demonstrate that the proposed method is able to improve the segmentation accuracy compared with the standard U-Net, and achieves comparable performance to the most advanced fully-automated methods.
CONCLUSIONS: Given its effectiveness and advantages, the proposed method can facilitate cardiac segmentation in short-axis MRI images in clinical practice.","The study was supported in part by the National Natural Science Foundation of China under Grant 61801393, in part by the Natural Science Basic Research Project in Shaanxi of China (Program No. 2019JQ-254), and in part by the Fundamental Research Funds for the Central Universities under Grant 3102020QD1001.",,Computer Methods and Programs in Biomedicine,,"Heart; Heart Ventricles; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2021-05-04,2021,2021-05-04,2021-07,206,,106142,Closed,Article,"Cui, Hengfei; Yuwen, Chang; Jiang, Lei; Xia, Yong; Zhang, Yanning","Cui, Hengfei (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China; Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an 710072, China. Electronic address: hfcui@nwpu.edu.cn.); Yuwen, Chang (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China; Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an 710072, China.); Jiang, Lei (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China; Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an 710072, China.); Xia, Yong (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China; Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an 710072, China.); Zhang, Yanning (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China.)","Cui, Hengfei (Northwestern Polytechnical University)","Cui, Hengfei (Northwestern Polytechnical University); Yuwen, Chang (Northwestern Polytechnical University); Jiang, Lei (Northwestern Polytechnical University); Xia, Yong (Northwestern Polytechnical University); Zhang, Yanning (Northwestern Polytechnical University)",27,27,3.0,20.67,,https://app.dimensions.ai/details/publication/pub.1137734569,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1397,pub.1137749297,10.48550/arxiv.2105.00859,,,Beyond pixel-wise supervision for segmentation: A few global shape  descriptors might be surprisingly good!,"Standard losses for training deep segmentation networks could be seen as
individual classifications of pixels, instead of supervising the global shape
of the predicted segmentations. While effective, they require exact knowledge
of the label of each pixel in an image.
  This study investigates how effective global geometric shape descriptors
could be, when used on their own as segmentation losses for training deep
networks. Not only interesting theoretically, there exist deeper motivations to
posing segmentation problems as a reconstruction of shape descriptors:
Annotations to obtain approximations of low-order shape moments could be much
less cumbersome than their full-mask counterparts, and anatomical priors could
be readily encoded into invariant shape descriptions, which might alleviate the
annotation burden. Also, and most importantly, we hypothesize that, given a
task, certain shape descriptions might be invariant across image acquisition
protocols/modalities and subject populations, which might open interesting
research avenues for generalization in medical image segmentation.
  We introduce and formulate a few shape descriptors in the context of deep
segmentation, and evaluate their potential as standalone losses on two
different challenging tasks. Inspired by recent works in constrained
optimization for deep networks, we propose a way to use those descriptors to
supervise segmentation, without any pixel-level label. Very surprisingly, as
little as 4 descriptors values per class can approach the performance of a
segmentation mask with 65k individual discrete labels. We also found that shape
descriptors can be a valid way to encode anatomical priors about the task,
enabling to leverage expert knowledge without additional annotations. Our
implementation is publicly available and can be easily extended to other tasks
and descriptors: https://github.com/hkervadec/shape_descriptors",,,arXiv,,,2021-05-03,2021,,,,,,All OA, Green,Preprint,"Kervadec, Hoel; Bahig, Houda; Letourneau-Guillon, Laurent; Dolz, Jose; Ayed, Ismail Ben","Kervadec, Hoel (); Bahig, Houda (); Letourneau-Guillon, Laurent (); Dolz, Jose (); Ayed, Ismail Ben ()",,"Kervadec, Hoel (); Bahig, Houda (); Letourneau-Guillon, Laurent (); Dolz, Jose (); Ayed, Ismail Ben ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1137749297,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
4777,pub.1136304485,10.21037/qims-20-745,33936963,PMC8047352,Automatic segmentation of the left ventricle in echocardiographic images using convolutional neural networks,"BACKGROUND: Two-dimensional echocardiography (2D echo) is the most widely used non-invasive imaging modality due to its fast acquisition time, low cost, and high temporal resolution. Boundary identification of left ventricle (LV) in 2D echo, i.e., image segmentation, is the first step to calculate relevant clinical parameters. Currently, LV segmentation in 2D echo is primarily conducted semi-manually. A fully-automatic segmentation of the LV wall needs further development.
METHODS: We evaluated the performance of the state-of-the-art convolutional neural networks (CNNs) for the segmentation of 2D echo images from 6 standard projections of the LV. We used two segmentation algorithms: U-net and segAN. The models were trained using an in-house dataset, which consists of 1,649 porcine images from 6 to 8 different pigs. In addition, a transfer learning approach was used for the segmentation of long-axis projections by training models with our database based on the previously trained weights obtained from Cardiac Acquisitions for Multi-structure Ultrasound Segmentation (CAMUS) dataset. The models were tested on a separate set of images from two other pigs by computing several metrics. The segmentation process was combined with a 3D reconstruction framework to quantify the physiological indices such as LV volumes and ejection fraction (EF).
RESULTS: The average dice metric for the LV cavity was 0.90 and 0.91 for the U-net and segAN, respectively, which was higher than 0.82 for the level-set (P value: 3.31×10-25). The average Hausdorff distance for the LV cavity was 2.71 mm and 2.82 mm for the U-net and segAN, respectively, which was lower than 3.64 mm for the level-set (P value: 4.86×10-16). The LV shapes and volumes obtained using the CNN segmentation models were in good agreement with the results segmented by the experts. In addition, the differences of the calculated physiological parameters between two 3D reconstruction models segmented by the experts and CNNs were less than 15%.
CONCLUSIONS: The results showed that both CNN models achieve higher performance on LV segmentation than the level-set method. The error of the reconstruction from automatic segmentation compared to the expert segmentation is less than 15%, which is within the 20% error of echo compared to the gold standard.",,,Quantitative Imaging in Medicine and Surgery,,,2021-05,2021,2021-05,2021-05,11,5,1763781-1761781,All OA, Gold,Article,"Kim, Taeouk; Hedayat, Mohammadali; Vaitkus, Veronica V; Belohlavek, Marek; Krishnamurthy, Vinayak; Borazjani, Iman","Kim, Taeouk (J. Mike Walker '66, Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA.); Hedayat, Mohammadali (J. Mike Walker '66, Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA.); Vaitkus, Veronica V (Department of Cardiovascular Diseases, Mayo Clinic, Scottsdale, Arizona, USA.); Belohlavek, Marek (Department of Cardiovascular Diseases, Mayo Clinic, Scottsdale, Arizona, USA.); Krishnamurthy, Vinayak (J. Mike Walker '66, Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA.; Department of Computer Science (By Affiliation), Texas A&M University, College Station, Texas, USA.); Borazjani, Iman (J. Mike Walker '66, Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA.)",,"Kim, Taeouk (Texas A&M University); Hedayat, Mohammadali (Texas A&M University); Vaitkus, Veronica V (Mayo Clinic); Belohlavek, Marek (Mayo Clinic); Krishnamurthy, Vinayak (Texas A&M University; Texas A&M University); Borazjani, Iman (Texas A&M University)",13,13,3.04,16.28,https://qims.amegroups.com/article/viewFile/58646/pdf,https://app.dimensions.ai/details/publication/pub.1136304485,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,
5054,pub.1135079726,10.1109/tmi.2021.3056531,33531298,,Learning a Generative Motion Model From Image Sequences Based on a Latent Motion Matrix,"We propose to learn a probabilistic motion model from a sequence of images for spatio-temporal registration. Our model encodes motion in a low-dimensional probabilistic space - the motion matrix - which enables various motion analysis tasks such as simulation and interpolation of realistic motion patterns allowing for faster data acquisition and data augmentation. More precisely, the motion matrix allows to transport the recovered motion from one subject to another simulating for example a pathological motion in a healthy subject without the need for inter-subject registration. The method is based on a conditional latent variable model that is trained using amortized variational inference. This unsupervised generative model follows a novel multivariate Gaussian process prior and is applied within a temporal convolutional network which leads to a diffeomorphic motion model. Temporal consistency and generalizability is further improved by applying a temporal dropout training scheme. Applied to cardiac cine-MRI sequences, we show improved registration accuracy and spatio-temporally smoother deformations compared to three state-of-the-art registration algorithms. Besides, we demonstrate the model's applicability for motion analysis, simulation and super-resolution by an improved motion reconstruction from sequences with missing frames compared to linear and cubic interpolation.","This work was supported in part by the French Government, through the 3IA Côte d’Azur Investments in the Future Project managed by the National Research Agency (ANR), under Grant ANR-19-P3IA-0002 and Grant AAP Santé 06 2017-260 DGA-DSH and in part by the Inria Sophia Antipolis-Méditerranée, NEF Computation Cluster. The used data were obtained from the EU FP7-funded project MD-Paedigree and the ACDC STACOM challenge 2017 [1].",,IEEE Transactions on Medical Imaging,,"Algorithms; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Motion",2021-04-30,2021,2021-04-30,2021-05,40,5,1405-1416,All OA, Green,Article,"Krebs, Julian; Delingette, Hervé; Ayache, Nicholas; Mansi, Tommaso","Krebs, Julian (Inria, Epione Team, Université Côte d’Azur, 06902, Sophia Antipolis, France; Siemens Healthineers, Digital Technology and Innovation, Princeton, NJ, 08540, USA); Delingette, Hervé (Inria, Epione Team, Université Côte d’Azur, 06902, Sophia Antipolis, France); Ayache, Nicholas (Inria, Epione Team, Université Côte d’Azur, 06902, Sophia Antipolis, France); Mansi, Tommaso (Siemens Healthineers, Digital Technology and Innovation, Princeton, NJ, 08540, USA)","Krebs, Julian (; Siemens Healthcare (United States))","Krebs, Julian (Siemens Healthcare (United States)); Delingette, Hervé (); Ayache, Nicholas (); Mansi, Tommaso (Siemens Healthcare (United States))",7,7,0.66,5.42,http://arxiv.org/pdf/2011.01741,https://app.dimensions.ai/details/publication/pub.1135079726,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1133,pub.1137670375,10.21203/rs.3.rs-411209/v1,,,Segmentation of Biventricle in Cardiac Cine MRI via Nested Capsule Dense Network,"Cardiac magnetic resonance image (MRI) has been widely used in diagnosis of cardiovascular diseases because of its noninvasive nature and high image quality. The evaluation standard of physiological indexes in cardiac diagnosis is essentially the accuracy of segmentation of left ventricle (LV) and right ventricle (RV) in cardiac MRI. In this paper, we propose a novel Nested Capsule Dense Network (NCDN) structure based on the FC-DenseNet model and capsule convolution-capsule deconvolution. Different from the traditional symmetric single codec network structure such as U-net, NCDN uses multiple codecs instead of a single codec to achieve multi-resolution, which makes it possible to save more spatial information and improve the robustness of the model. The proposed model is tested on three datasets that includes York University Cardiac MRI dataset, Automated Cardiac Diagnosis Challenge (ACDC-2017), and local dataset. The results show that the proposed NCDN outperforms the state-of-the-art methods.",,,Research Square,,,2021-04-30,2021,2021-04-30,,,,,All OA, Green,Preprint,"Hu, Yuhang; Zhang, Yajuan; Zhang, Hongyang; Shen, Weihao; Zhou, Shoujun; Guo, Shijie; Wang, Yuanquan","Hu, Yuhang (Hebei University of Technology); Zhang, Yajuan (Hebei University of Technology); Zhang, Hongyang (Hebei University of Technology); Shen, Weihao (Hebei University of Technology); Zhou, Shoujun (Shenzhen Institutes of Advanced Technology Chinese Academy of Sciences); Guo, Shijie (Hebei University of Technology); Wang, Yuanquan (Hebei University of Technology)",,"Hu, Yuhang (Hebei University of Technology); Zhang, Yajuan (Hebei University of Technology); Zhang, Hongyang (Hebei University of Technology); Shen, Weihao (Hebei University of Technology); Zhou, Shoujun (Shenzhen Institutes of Advanced Technology); Guo, Shijie (Hebei University of Technology); Wang, Yuanquan (Hebei University of Technology)",0,0,,0.0,https://www.researchsquare.com/article/rs-411209/v1.pdf?c=1631879532000,https://app.dimensions.ai/details/publication/pub.1137670375,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
5869,pub.1137477904,10.1186/s12968-020-00695-z,33896419,PMC8074440,A deep learning pipeline for automatic analysis of multi-scan cardiovascular magnetic resonance,"BackgroundCardiovascular magnetic resonance (CMR) sequences are commonly used to obtain a complete description of the function and structure of the heart, provided that accurate measurements are extracted from images. New methods of extraction of information are being developed, among them, deep neural networks are powerful tools that showed the ability to perform fast and accurate segmentation. Iq1n order to reduce the time spent by reading physicians to process data and minimize intra- and inter-observer variability, we propose a fully automatic multi-scan CMR image analysis pipeline.MethodsSequence specific U-Net 2D models were trained to perform the segmentation of the left ventricle (LV), right ventricle (RV) and aorta in cine short-axis, late gadolinium enhancement (LGE), native T1 map, post-contrast T1, native T2 map and aortic flow sequences depending on the need. The models were trained and tested on a set of data manually segmented by experts using semi-automatic and manual tools. A set of parameters were computed from the resulting segmentations such as the left ventricular and right ventricular ejection fraction (EF), LGE scar percentage, the mean T1, T1 post, T2 values within the myocardium, and aortic flow. The Dice similarity coefficient, Hausdorff distance, mean surface distance, and Pearson correlation coefficient R were used to assess and compare the results of the U-Net based pipeline with intra-observer variability. Additionally, the pipeline was validated on two clinical studies.ResultsThe sequence specific U-Net 2D models trained achieved fast (≤ 0.2 s/image on GPU) and precise segmentation over all the targeted region of interest with high Dice scores (= 0.91 for LV, = 0.92 for RV, = 0.93 for Aorta in average) comparable to intra-observer Dice scores (= 0.86 for LV, = 0.87 for RV, = 0.95 for aorta flow in average). The automatically and manually computed parameters were highly correlated (R = 0.91 in average) showing results superior to the intra-observer variability (R = 0.85 in average) for every sequence presented here.ConclusionThe proposed pipeline allows for fast and robust analysis of large CMR studies while guaranteeing reproducibility, hence potentially improving patient’s diagnosis as well as clinical studies outcome.",Not applicable.,,Journal of Cardiovascular Magnetic Resonance,,"Automation; Case-Control Studies; Deep Learning; Heart Diseases; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Myocardium; Observer Variation; Predictive Value of Tests; Reproducibility of Results; Stroke Volume; Ventricular Function, Left; Ventricular Function, Right",2021-04-26,2021,2021-04-26,2021-12,23,1,47,All OA, Gold,Article,"Fadil, Hakim; Totman, John J.; Hausenloy, Derek J.; Ho, Hee-Hwa; Joseph, Prabath; Low, Adrian Fatt-Hoe; Richards, A. Mark; Chan, Mark Y.; Marchesseau, Stephanie","Fadil, Hakim (Centre for Translational MR Research (TMR), National University of Singapore, 117549, Singapore, Singapore); Totman, John J. (Centre for Translational MR Research (TMR), National University of Singapore, 117549, Singapore, Singapore); Hausenloy, Derek J. (Cardiovascular & Metabolic Disorders Program, Duke-National University of Singapore Medical School, 169857, Singapore, Singapore; National Heart Research Institute Singapore, National Heart Centre, Singapore, Singapore; Department of Medicine, Yong Loo Lin SoM, National University of Singapore, 117597, Singapore, Singapore; The Hatter Cardiovascular Institute, University College London, London, UK; Cardiovascular Research Center, College of Medical and Health Sciences, Asia University, Taichung, Taiwan); Ho, Hee-Hwa (Tan Tock Seng Hospital, 308433, Singapore, Singapore); Joseph, Prabath (Tan Tock Seng Hospital, 308433, Singapore, Singapore); Low, Adrian Fatt-Hoe (National University Heart Centre, 119074, Singapore, Singapore); Richards, A. Mark (Cardiovascular Research Institute, National University of Singapore, 119228, Singapore, Singapore; Christchurch Heart Institute, University of Otago, 8140, Christchurch, New Zealand); Chan, Mark Y. (Department of Medicine, Yong Loo Lin SoM, National University of Singapore, 117597, Singapore, Singapore); Marchesseau, Stephanie (Centre for Translational MR Research (TMR), National University of Singapore, 117549, Singapore, Singapore)","Fadil, Hakim (National University of Singapore)","Fadil, Hakim (National University of Singapore); Totman, John J. (National University of Singapore); Hausenloy, Derek J. (Duke NUS Graduate Medical School; National Heart Centre Singapore; National University of Singapore; University College London; Asian University); Ho, Hee-Hwa (Tan Tock Seng Hospital); Joseph, Prabath (Tan Tock Seng Hospital); Low, Adrian Fatt-Hoe (National University Heart Centre Singapore); Richards, A. Mark (National University of Singapore; University of Otago); Chan, Mark Y. (National University of Singapore); Marchesseau, Stephanie (National University of Singapore)",9,9,1.13,8.92,https://jcmr-online.biomedcentral.com/track/pdf/10.1186/s12968-020-00695-z,https://app.dimensions.ai/details/publication/pub.1137477904,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
4309,pub.1137432019,10.1016/j.artmed.2021.102078,34020754,PMC8164174,Transfer learning in medical image segmentation: New insights from analysis of the dynamics of model parameters and learned representations,"We present a critical assessment of the role of transfer learning in training fully convolutional networks (FCNs) for medical image segmentation. We first show that although transfer learning reduces the training time on the target task, improvements in segmentation accuracy are highly task/data-dependent. Large improvements are observed only when the segmentation task is more challenging and the target training data is smaller. We shed light on these observations by investigating the impact of transfer learning on the evolution of model parameters and learned representations. We observe that convolutional filters change little during training and still look random at convergence. We further show that quite accurate FCNs can be built by freezing the encoder section of the network at random values and only training the decoder section. At least for medical image segmentation, this finding challenges the common belief that the encoder section needs to learn data/task-specific representations. We examine the evolution of FCN representations to gain a deeper insight into the effects of transfer learning on the training dynamics. Our analysis shows that although FCNs trained via transfer learning learn different representations than FCNs trained with random initialization, the variability among FCNs trained via transfer learning can be as high as that among FCNs trained with random initialization. Moreover, feature reuse is not restricted to the early encoder layers; rather, it can be more significant in deeper layers. These findings offer new insights and suggest alternative ways of training FCNs for medical image segmentation.","This study was supported in part by the National Institutes of Health (NIH) grants R01 EB018988, R01 NS106030, and R01 NS079788. D. Karimi, S.K. Warfield, and A. Gholipour are with the Computational Radiology Laboratory of the Department of Radiology at Boston Children’s Hospital, and Harvard Medical School, Boston, MA, USA (email: davood.karimi@childrens.harvard.edu).",,Artificial Intelligence in Medicine,,"Humans; Image Processing, Computer-Assisted; Machine Learning",2021-04-23,2021,2021-04-23,2021-06,116,,102078,All OA, Green,Article,"Karimi, Davood; Warfield, Simon K; Gholipour, Ali","Karimi, Davood (Department of Radiology at Boston Children's Hospital, and Harvard Medical School, Boston, MA, USA. Electronic address: davood.karimi@childrens.harvard.edu.); Warfield, Simon K (Department of Radiology at Boston Children's Hospital, and Harvard Medical School, Boston, MA, USA.); Gholipour, Ali (Department of Radiology at Boston Children's Hospital, and Harvard Medical School, Boston, MA, USA.)","Karimi, Davood (Harvard University; Boston Children's Hospital)","Karimi, Davood (Harvard University; Boston Children's Hospital); Warfield, Simon K (Harvard University; Boston Children's Hospital); Gholipour, Ali (Harvard University; Boston Children's Hospital)",36,36,4.88,29.46,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8164174,https://app.dimensions.ai/details/publication/pub.1137432019,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5054,pub.1137342002,10.1016/j.media.2021.102066,33951597,,Personalising left-ventricular biophysical models of the heart using parametric physics-informed neural networks,"We present a parametric physics-informed neural network for the simulation of personalised left-ventricular biomechanics. The neural network is constrained to the biophysical problem in two ways: (i) the network output is restricted to a subspace built from radial basis functions capturing characteristic deformations of left ventricles and (ii) the cost function used for training is the energy potential functional specifically tailored for hyperelastic, anisotropic, nearly-incompressible active materials. The radial bases are generated from the results of a nonlinear Finite Element model coupled with an anatomical shape model derived from high-resolution cardiac images. We show that, by coupling the neural network with a simplified circulation model, we can efficiently generate computationally inexpensive estimations of cardiac mechanics. Our model is 30 times faster than the reference Finite Element model used, including training time, while yielding satisfactory average errors in the predictions of ejection fraction (-3%), peak systolic pressure (7%), stroke work (4%) and myocardial strains (14%). This physics-informed neural network is well suited to efficiently augment cardiac images with functional data and to generate large sets of synthetic cases for training deep network classifiers while it provides efficient personalization to the specific patient of interest with a high level of detail.","The authors acknowledge the financial support of the Swiss National Science Foundation (SNF ) [Grant CR23I3-166485], and of PHRT SWISSHEART Failure Network of the ETH Domain.",,Medical Image Analysis,,"Finite Element Analysis; Heart Ventricles; Humans; Models, Cardiovascular; Neural Networks, Computer; Physics",2021-04-20,2021,2021-04-20,2021-07,71,,102066,All OA, Hybrid,Article,"Buoso, Stefano; Joyce, Thomas; Kozerke, Sebastian","Buoso, Stefano (Institute for Biomedical Engineering, ETH Zurich and University Zurich, Zurich, Switzerland. Electronic address: buoso@biomed.ee.ethz.ch.); Joyce, Thomas (Institute for Biomedical Engineering, ETH Zurich and University Zurich, Zurich, Switzerland.); Kozerke, Sebastian (Institute for Biomedical Engineering, ETH Zurich and University Zurich, Zurich, Switzerland.)","Buoso, Stefano (Institute for Biomedical Engineering)","Buoso, Stefano (Institute for Biomedical Engineering); Joyce, Thomas (Institute for Biomedical Engineering); Kozerke, Sebastian (Institute for Biomedical Engineering)",20,20,3.24,,https://doi.org/10.1016/j.media.2021.102066,https://app.dimensions.ai/details/publication/pub.1137342002,40 Engineering,,,,,,,,,,,
1617,pub.1138337347,10.1109/isbi48211.2021.9433851,,,Multi-Task Curriculum Learning For Semi-Supervised Medical Image Segmentation,"The lack of annotated data is a common problem in medical image segmentation tasks. In this paper, we present a novel multi-task semi-supervised segmentation algorithm with a curriculum-style learning strategy. The proposed method includes a segmentation task and an auxiliary regression task. Concretely, the auxiliary regression task aims to learn image-level properties such as the size and centroid position of target region to regularize the segmentation network, enforcing the pixel-level segmentation result match the distributions of these regressions. In addition, these regressions are treated as pseudo labels for the learning of unlabeled data. For the purpose of decreasing noise from the deviation of inferred labels, we adopt the inequality constraint for the learning of unlabeled data, which would generate a tolerance interval where the prediction within it would not be published to reduce the impact of prediction deviation of regression network. Experimental results on both 2017 ACDC dataset and PROMISE12 dataset demonstrate the effectiveness of our method.","This work is supported by National Natural Science Foundation of China (NSFC 62071314) and Sichuan Science and Technology Program (2021YFG0326, 2020YFG0079). This work is supported by National Natural Science Foundation of China (NSFC 62071314) and Sichuan Science and Technology Program (2021YFG0326, 2020YFG0079).",,,2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI),,2021-04-16,2021,,2021-04-16,0,,925-928,Closed,Proceeding,"Wang, Kaiping; Zhan, Bo; Luo, Yanmei; Zhou, Jiliu; Wu, Xi; Wang, Yan","Wang, Kaiping (College of Computer Science, Sichuan University, China); Zhan, Bo (College of Computer Science, Sichuan University, China); Luo, Yanmei (College of Computer Science, Sichuan University, China); Zhou, Jiliu (College of Computer Science, Sichuan University, China; College of Computer Science, Chengdu University of Information Technology, China); Wu, Xi (College of Computer Science, Chengdu University of Information Technology, China); Wang, Yan (College of Computer Science, Sichuan University, China)","Wang, Kaiping (Sichuan University)","Wang, Kaiping (Sichuan University); Zhan, Bo (Sichuan University); Luo, Yanmei (Sichuan University); Zhou, Jiliu (Sichuan University; Chengdu University of Information Technology); Wu, Xi (Chengdu University of Information Technology); Wang, Yan (Sichuan University)",2,2,,1.59,,https://app.dimensions.ai/details/publication/pub.1138337347,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,,
1551,pub.1138337379,10.1109/isbi48211.2021.9433883,,,A Novel Weakly Supervised Framework Based On Noisy-Label Learning For Medical Image Segmentation,"Obtaining accurately annotated medical images for training segmentation models is expensive, time-consuming and labor-intensive. Although a variety of approaches based on weak annotations like points, scribbles and bounding boxes have been designed to address this problem, their performance is still limited. Inspired by recent studies on noisy-label learning, we propose a novel two-stage framework where a size-constrained loss is used to directly learn from the weak annotations in the first stage and a noise-robust loss is introduced to learn from pseudo labels in the second stage. The noise-robust loss function, named Edge-Dice, is based on the confidence in the network’s prediction and the pseudo labels. Our approach differs from previous works by taking a natural step towards stronger supervision, in which predictions made by weak supervision methods are incorporated into another round of training using noise-robust methods. Experiments with the ACDC 2017 dataset showed that our method achieved 86.27% Dice for left ventricular segmentation with only 1% of the full annotations, and it outperformed existing methods with the same set of weak annotations.","This work was supported by Glasgow College, University of Electronic Science and Technology of China and the National Natural Science Foundation of China under Grant 81771921 and Grant 61901084. This work was supported by Glasgow College, University of Electronic Science and Technology of China and the National Natural Science Foundation of China under Grant 81771921 and Grant 61901084.",,,2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI),,2021-04-16,2021,,2021-04-16,0,,1768-1772,Closed,Proceeding,"Wu, Haoyang; Wang, Huan; He, Hao; He, Zixiao; Wang, Guotai","Wu, Haoyang (Glasgow College, University of Electronic Science and Technology of China, Chengdu, China); Wang, Huan (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China); He, Hao (Glasgow College, University of Electronic Science and Technology of China, Chengdu, China); He, Zixiao (Glasgow College, University of Electronic Science and Technology of China, Chengdu, China); Wang, Guotai (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China)","Wang, Guotai (University of Electronic Science and Technology of China)","Wu, Haoyang (University of Electronic Science and Technology of China); Wang, Huan (University of Electronic Science and Technology of China); He, Hao (University of Electronic Science and Technology of China); He, Zixiao (University of Electronic Science and Technology of China); Wang, Guotai (University of Electronic Science and Technology of China)",2,2,,1.59,,https://app.dimensions.ai/details/publication/pub.1138337379,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,,
1512,pub.1137162501,10.48550/arxiv.2104.05533,,,Efficient Model Monitoring for Quality Control in Cardiac Image  Segmentation,"Deep learning methods have reached state-of-the-art performance in cardiac
image segmentation. Currently, the main bottleneck towards their effective
translation into clinics requires assuring continuous high model performance
and segmentation results. In this work, we present a novel learning framework
to monitor the performance of heart segmentation models in the absence of
ground truth. Formulated as an anomaly detection problem, the monitoring
framework allows deriving surrogate quality measures for a segmentation and
allows flagging suspicious results. We propose two different types of quality
measures, a global score and a pixel-wise map. We demonstrate their use by
reproducing the final rankings of a cardiac segmentation challenge in the
absence of ground truth. Results show that our framework is accurate, fast, and
scalable, confirming it is a viable option for quality control monitoring in
clinical practice and large population studies.",,,arXiv,,,2021-04-12,2021,,,,,,All OA, Green,Preprint,"Galati, Francesco; Zuluaga, Maria A.","Galati, Francesco (); Zuluaga, Maria A. ()",,"Galati, Francesco (); Zuluaga, Maria A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1137162501,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
6279,pub.1137184258,10.1007/s11390-021-0782-5,33867774,PMC8044657,Seg-CapNet: A Capsule-Based Neural Network for the Segmentation of Left Ventricle from Cardiac Magnetic Resonance Imaging,"Deep neural networks (DNNs) have been extensively studied in medical image segmentation. However, existing DNNs often need to train shape models for each object to be segmented, which may yield results that violate cardiac anatomical structure when segmenting cardiac magnetic resonance imaging (MRI). In this paper, we propose a capsule-based neural network, named Seg-CapNet, to model multiple regions simultaneously within a single training process. The Seg-CapNet model consists of the encoder and the decoder. The encoder transforms the input image into feature vectors that represent objects to be segmented by convolutional layers, capsule layers, and fully-connected layers. And the decoder transforms the feature vectors into segmentation masks by up-sampling. Feature maps of each down-sampling layer in the encoder are connected to the corresponding up-sampling layers, which are conducive to the backpropagation of the model. The output vectors of Seg-CapNet contain low-level image features such as grayscale and texture, as well as semantic features including the position and size of the objects, which is beneficial for improving the segmentation accuracy. The proposed model is validated on the open dataset of the Automated Cardiac Diagnosis Challenge 2017 (ACDC 2017) and the Sunnybrook Cardiac Magnetic Resonance Imaging (MRI) segmentation challenge. Experimental results show that the mean Dice coefficient of Seg-CapNet is increased by 4.7% and the average Hausdorff distance is reduced by 22%. The proposed model also reduces the model parameters and improves the training speed while obtaining the accurate segmentation of multiple regions.",,,Journal of Computer Science and Technology,,,2021-03-31,2021,2021-03-31,2021-04,36,2,323-333,All OA, Bronze,Article,"Cao, Yang-Jie; Wu, Shuang; Liu, Chang; Lin, Nan; Wang, Yuan; Yang, Cong; Li, Jie","Cao, Yang-Jie (School of Software, Zhengzhou University, 450000, Zhengzhou, China); Wu, Shuang (School of Software, Zhengzhou University, 450000, Zhengzhou, China); Liu, Chang (School of Software, Zhengzhou University, 450000, Zhengzhou, China); Lin, Nan (School of Software, Zhengzhou University, 450000, Zhengzhou, China); Wang, Yuan (Center of Modern Analysis and Gene Sequencing, Zhengzhou University, 450000, Zhengzhou, China); Yang, Cong (School of Software, Zhengzhou University, 450000, Zhengzhou, China); Li, Jie (School of Software, Zhengzhou University, 450000, Zhengzhou, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, 200000, Shanghai, China)","Yang, Cong (Zhengzhou University)","Cao, Yang-Jie (Zhengzhou University); Wu, Shuang (Zhengzhou University); Liu, Chang (Zhengzhou University); Lin, Nan (Zhengzhou University); Wang, Yuan (Zhengzhou University); Yang, Cong (Zhengzhou University); Li, Jie (Zhengzhou University; Shanghai Jiao Tong University)",2,2,0.37,1.64,https://link.springer.com/content/pdf/10.1007/s11390-021-0782-5.pdf,https://app.dimensions.ai/details/publication/pub.1137184258,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1581,pub.1136869853,10.48550/arxiv.2103.16695,,,CNN-based Cardiac Motion Extraction to Generate Deformable Geometric  Left Ventricle Myocardial Models from Cine MRI,"Patient-specific left ventricle (LV) myocardial models have the potential to
be used in a variety of clinical scenarios for improved diagnosis and treatment
plans. Cine cardiac magnetic resonance (MR) imaging provides high resolution
images to reconstruct patient-specific geometric models of the LV myocardium.
With the advent of deep learning, accurate segmentation of cardiac chambers
from cine cardiac MR images and unsupervised learning for image registration
for cardiac motion estimation on a large number of image datasets is
attainable. Here, we propose a deep leaning-based framework for the development
of patient-specific geometric models of LV myocardium from cine cardiac MR
images, using the Automated Cardiac Diagnosis Challenge (ACDC) dataset. We use
the deformation field estimated from the VoxelMorph-based convolutional neural
network (CNN) to propagate the isosurface mesh and volume mesh of the
end-diastole (ED) frame to the subsequent frames of the cardiac cycle. We
assess the CNN-based propagated models against segmented models at each cardiac
phase, as well as models propagated using another traditional nonrigid image
registration technique.",,,arXiv,,,2021-03-30,2021,,,,,,All OA, Green,Preprint,"Upendra, Roshan Reddy; Wentz, Brian Jamison; Simon, Richard; Shontz, Suzanne M.; Linte, Cristian A.","Upendra, Roshan Reddy (); Wentz, Brian Jamison (); Simon, Richard (); Shontz, Suzanne M. (); Linte, Cristian A. ()",,"Upendra, Roshan Reddy (); Wentz, Brian Jamison (); Simon, Richard (); Shontz, Suzanne M. (); Linte, Cristian A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136869853,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,
4791,pub.1136766325,10.3390/s21072375,33805558,PMC8037138,Edge-Sensitive Left Ventricle Segmentation Using Deep Reinforcement Learning,"Deep reinforcement learning (DRL) has been utilized in numerous computer vision tasks, such as object detection, autonomous driving, etc. However, relatively few DRL methods have been proposed in the area of image segmentation, particularly in left ventricle segmentation. Reinforcement learning-based methods in earlier works often rely on learning proper thresholds to perform segmentation, and the segmentation results are inaccurate due to the sensitivity of the threshold. To tackle this problem, a novel DRL agent is designed to imitate the human process to perform LV segmentation. For this purpose, we formulate the segmentation problem as a Markov decision process and innovatively optimize it through DRL. The proposed DRL agent consists of two neural networks, i.e., First-P-Net and Next-P-Net. The First-P-Net locates the initial edge point, and the Next-P-Net locates the remaining edge points successively and ultimately obtains a closed segmentation result. The experimental results show that the proposed model has outperformed the previous reinforcement learning methods and achieved comparable performances compared with deep learning baselines on two widely used LV endocardium segmentation datasets, namely Automated Cardiac Diagnosis Challenge (ACDC) 2017 dataset, and Sunnybrook 2009 dataset. Moreover, the proposed model achieves higher F-measure accuracy compared with deep learning methods when training with a very limited number of samples.",We would like to thank our labmate Weifeng Ou for helpful discussions and encouragement.,This research received no external funding.,Sensors,,"Heart; Heart Ventricles; Humans; Neural Networks, Computer",2021-03-29,2021,2021-03-29,,21,7,2375,All OA, Gold,Article,"Xiong, Jingjing; Po, Lai-Man; Cheung, Kwok Wai; Xian, Pengfei; Zhao, Yuzhi; Rehman, Yasar Abbas Ur; Zhang, Yujia","Xiong, Jingjing (Department of Electrical Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong, China;, eelmpo@cityu.edu.hk, (L.-M.P.);, xian.pf@my.cityu.edu.hk, (P.X.);, yzzhao2-c@my.cityu.edu.hk, (Y.Z.);, yzhang2383-c@my.cityu.edu.hk, (Y.Z.)); Po, Lai-Man (Department of Electrical Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong, China;, eelmpo@cityu.edu.hk, (L.-M.P.);, xian.pf@my.cityu.edu.hk, (P.X.);, yzzhao2-c@my.cityu.edu.hk, (Y.Z.);, yzhang2383-c@my.cityu.edu.hk, (Y.Z.)); Cheung, Kwok Wai (School of Communication, The Hang Seng University of Hong Kong, Hang Shin Link, Siu Lek Yuen, Shatin, Hong Kong, China;, keithcheung@hsu.edu.hk); Xian, Pengfei (Department of Electrical Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong, China;, eelmpo@cityu.edu.hk, (L.-M.P.);, xian.pf@my.cityu.edu.hk, (P.X.);, yzzhao2-c@my.cityu.edu.hk, (Y.Z.);, yzhang2383-c@my.cityu.edu.hk, (Y.Z.)); Zhao, Yuzhi (Department of Electrical Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong, China;, eelmpo@cityu.edu.hk, (L.-M.P.);, xian.pf@my.cityu.edu.hk, (P.X.);, yzzhao2-c@my.cityu.edu.hk, (Y.Z.);, yzhang2383-c@my.cityu.edu.hk, (Y.Z.)); Rehman, Yasar Abbas Ur (TCL Corporate Research (HK) Co., Ltd., 22 Science Park East Avenue, Shatin, Hong Kong, China;, yasir.abbas42@gmail.com); Zhang, Yujia (Department of Electrical Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong, China;, eelmpo@cityu.edu.hk, (L.-M.P.);, xian.pf@my.cityu.edu.hk, (P.X.);, yzzhao2-c@my.cityu.edu.hk, (Y.Z.);, yzhang2383-c@my.cityu.edu.hk, (Y.Z.))","Xiong, Jingjing (City University of Hong Kong)","Xiong, Jingjing (City University of Hong Kong); Po, Lai-Man (City University of Hong Kong); Cheung, Kwok Wai (The Hang Seng University of Hong Kong); Xian, Pengfei (City University of Hong Kong); Zhao, Yuzhi (City University of Hong Kong); Rehman, Yasar Abbas Ur (); Zhang, Yujia (City University of Hong Kong)",8,8,1.35,6.59,https://www.mdpi.com/1424-8220/21/7/2375/pdf?version=1617937971,https://app.dimensions.ai/details/publication/pub.1136766325,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4611 Machine Learning,,,,,,,,,
5668,pub.1136574606,10.1093/ehjdh/ztab033,34223176,PMC8242184,Automated Cardiac Volume Assessment and Cardiac Long- and Short-Axis Imaging Plane Prediction from ECG-gated CT Volumes Enabled By Deep Learning,"AIMS: To develop an automated method for bloodpool segmentation and imaging plane re-slicing of cardiac computed tomography (CT) via deep learning (DL) for clinical use in coronary artery disease (CAD) wall motion assessment and reproducible longitudinal imaging.
METHODS AND RESULTS: One hundred patients who underwent clinically indicated cardiac CT scans with manually segmented left ventricle (LV) and left atrial (LA) chambers were used for training. For each patient, long-axis (LAX) and short-axis planes were manually defined by an imaging expert. A DL model was trained to predict bloodpool segmentations and imaging planes. Deep learning bloodpool segmentations showed close agreement with manual LV [median Dice: 0.91, Hausdorff distance (HD): 6.18 mm] and LA (Dice: 0.93, HD: 7.35 mm) segmentations and a strong correlation with manual ejection fraction (Pearson r: 0.95 LV, 0.92 LA). Predicted planes had low median location (6.96 mm) and angular orientation (7.96 ° ) errors which were comparable to inter-reader differences (P > 0.71). 84-97% of DL-prescribed LAX planes correctly intersected American Heart Association segments, which was comparable (P > 0.05) to manual slicing. In a test cohort of 144 patients, we evaluated the ability of the DL approach to provide diagnostic imaging planes. Visual scoring by two blinded experts determined ≥94% of DL-predicted planes to be diagnostically adequate. Further, DL-enabled visualization of LV wall motion abnormalities due to CAD and provided reproducible planes upon repeat imaging.
CONCLUSION: A volumetric, DL approach provides multiple chamber segmentations and can re-slice the imaging volume along standardized cardiac imaging planes for reproducible wall motion abnormality and functional assessment.",,National Institutes of Health (NIH) (NHLBI HL145817 and HL143113 to F.C.). Conflict of interest: none declared.,European Heart Journal - Digital Health,,,2021-03-22,2021,2021-03-22,2021-06-29,2,2,ztab033-,All OA, Gold,Article,"Chen, Zhennong; Rigolli, Marzia; Vigneault, Davis Marc; Kligerman, Seth; Hahn, Lewis; Narezkina, Anna; Craine, Amanda; Lowe, Katherine; Contijoch, Francisco","Chen, Zhennong (Department of Bioengineering, UC San Diego School of Engineering, 9500 Gilman Dr, La Jolla, CA); Rigolli, Marzia (Department of Bioengineering, UC San Diego School of Engineering, 9500 Gilman Dr, La Jolla, CA); Vigneault, Davis Marc (Department of Internal Medicine, Scripps Mercy Hospital, 4077 Fifth Ave, San Diego, CA); Kligerman, Seth (Department of Radiology, UC San Diego School of Medicine, 9500 Gilman Dr, La Jolla, CA); Hahn, Lewis (Department of Radiology, UC San Diego School of Medicine, 9500 Gilman Dr, La Jolla, CA); Narezkina, Anna (Department of Medicine, Division of Cardiology, UC San Diego School of Medicine, 9500 Gilman Dr, La Jolla, CA); Craine, Amanda (Department of Bioengineering, UC San Diego School of Engineering, 9500 Gilman Dr, La Jolla, CA); Lowe, Katherine (Department of Bioengineering, UC San Diego School of Engineering, 9500 Gilman Dr, La Jolla, CA); Contijoch, Francisco (Department of Bioengineering, UC San Diego School of Engineering, 9500 Gilman Dr, La Jolla, CA; Department of Radiology, UC San Diego School of Medicine, 9500 Gilman Dr, La Jolla, CA)","Contijoch, Francisco (University of California, San Diego; University of California, San Diego)","Chen, Zhennong (University of California, San Diego); Rigolli, Marzia (University of California, San Diego); Vigneault, Davis Marc (Scripps Mercy Hospital); Kligerman, Seth (University of California, San Diego); Hahn, Lewis (University of California, San Diego); Narezkina, Anna (University of California, San Diego); Craine, Amanda (University of California, San Diego); Lowe, Katherine (University of California, San Diego); Contijoch, Francisco (University of California, San Diego; University of California, San Diego)",6,6,1.69,6.24,https://doi.org/10.1093/ehjdh/ztab033,https://app.dimensions.ai/details/publication/pub.1136574606,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
4808,pub.1136556113,10.1016/j.cmpb.2021.106059,33812305,,Automated left and right ventricular chamber segmentation in cardiac magnetic resonance images using dense fully convolutional neural network,"BACKGROUND AND OBJECTIVE: Segmentation of the left ventricular (LV) myocardium (Myo) and RV endocardium on cine cardiac magnetic resonance (CMR) images represents an essential step for cardiac-function evaluation and diagnosis. In order to have a common reference for comparing segmentation algorithms, several CMR image datasets were made available, but in general they do not include the most apical and basal slices, and/or gold standard tracing is limited to only one of the two ventricles, thus not fully corresponding to real clinical practice. Our aim was to develop a deep learning (DL) approach for automated segmentation of both RV and LV chambers from short-axis (SAX) CMR images, reporting separately the performance for basal slices, together with the applied criterion of choice.
METHOD: A retrospectively selected database (DB1) of 210 cine sequences (3 pathology groups) was considered: images (GE, 1.5 T) were acquired at Centro Cardiologico Monzino (Milan, Italy), and end-diastolic (ED) and end-systolic frames (ES) were manually segmented (gold standard, GS). Automatic ED and ES RV and LV segmentation were performed with a U-Net inspired architecture, where skip connections were redesigned introducing dense blocks to alleviate the semantic gap between the U-Net encoder and decoder. The proposed architecture was trained including: A) the basal slices where the Myo surrounded the LV for at least the 50% and all the other slice; B) all the slices where the Myo completely surrounded the LV. To evaluate the clinical relevance of the proposed architecture in a practical use case scenario, a graphical user interface was developed to allow clinicians to revise, and correct when needed, the automatic segmentation. Additionally, to assess generalizability, analysis of CMR images obtained in 12 healthy volunteers (DB2) with different equipment (Siemens, 3T) and settings was performed.
RESULTS: The proposed architecture outperformed the original U-Net. Comparing the performance on DB1 between the two criteria, no significant differences were measured when considering all slices together, but were present when only basal slices were examined. Automatic and manually-adjusted segmentation performed similarly compared to the GS (bias±95%LoA): LVEDV -1±12 ml, LVESV -1±14 ml, RVEDV 6±12 ml, RVESV 6±14 ml, ED LV mass 6±26 g, ES LV mass 5±26 g). Also, generalizability showed very similar performance, with Dice scores of 0.944 (LV), 0.908 (RV) and 0.852 (Myo) on DB1, and 0.940 (LV), 0.880 (RV), and 0.856 (Myo) on DB2.
CONCLUSIONS: Our results support the potential of DL methods for accurate LV and RV contours segmentation and the advantages of dense skip connections in alleviating the semantic gap generated when high level features are concatenated with lower level feature. The evaluation on our dataset, considering separately the performance on basal and apical slices, reveals the potential of DL approaches for fast, accurate and reliable automated cardiac segmentation in a real clinical setting.",None.,"This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.",Computer Methods and Programs in Biomedicine,,"Heart Ventricles; Humans; Italy; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Neural Networks, Computer; Retrospective Studies",2021-03-21,2021,2021-03-21,2021-06,204,,106059,Closed,Article,"Penso, Marco; Moccia, Sara; Scafuri, Stefano; Muscogiuri, Giuseppe; Pontone, Gianluca; Pepi, Mauro; Caiani, Enrico Gianluca","Penso, Marco (Department of Cardiovascular Imaging, Centro Cardiologico Monzino IRCCS, Milan, Italy. Electronic address: marco.penso@cardiologicomonzino.it.); Moccia, Sara (Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; The BioRobotics Institute, Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Pisa, Italy. Electronic address: sara.moccia@santannapisa.it.); Scafuri, Stefano (Department of Cardiovascular Imaging, Centro Cardiologico Monzino IRCCS, Milan, Italy. Electronic address: stefano.scafuri@cardiologicomonzino.it.); Muscogiuri, Giuseppe (Department of Cardiovascular Imaging, Centro Cardiologico Monzino IRCCS, Milan, Italy. Electronic address: Giuseppe.Muscogiuri@cardiologicomonzino.it.); Pontone, Gianluca (Department of Cardiovascular Imaging, Centro Cardiologico Monzino IRCCS, Milan, Italy. Electronic address: gianluca.pontone@cardiologicomonzino.it.); Pepi, Mauro (Department of Cardiovascular Imaging, Centro Cardiologico Monzino IRCCS, Milan, Italy. Electronic address: Mauro.Pepi@cardiologicomonzino.it.); Caiani, Enrico Gianluca (Department of Electronics, Information and Biomedical engineering, Politecnico di Milano, Milan, Italy; Consiglio Nazionale delle Ricerche, Istituto di Elettronica e di Ingegneria dell'Informazione e delle Telecomunicazioni, Milan, Italy. Electronic address: enrico.caiani@polimi.it.)","Caiani, Enrico Gianluca (Politecnico di Milano; National Research Council)","Penso, Marco (Centro Cardiologico Monzino); Moccia, Sara (Marche Polytechnic University; Sant'Anna School of Advanced Studies); Scafuri, Stefano (Centro Cardiologico Monzino); Muscogiuri, Giuseppe (Centro Cardiologico Monzino); Pontone, Gianluca (Centro Cardiologico Monzino); Pepi, Mauro (Centro Cardiologico Monzino); Caiani, Enrico Gianluca (Politecnico di Milano; National Research Council)",17,17,4.54,14.95,,https://app.dimensions.ai/details/publication/pub.1136556113,46 Information and Computing Sciences, 4601 Applied Computing, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
4769,pub.1136499061,10.1016/j.media.2021.102035,33813286,,Loss odyssey in medical image segmentation,"The loss function is an important component in deep learning-based segmentation methods. Over the past five years, many loss functions have been proposed for various segmentation tasks. However, a systematic study of the utility of these loss functions is missing. In this paper, we present a comprehensive review of segmentation loss functions in an organized manner. We also conduct the first large-scale analysis of 20 general loss functions on four typical 3D segmentation tasks involving six public datasets from 10+ medical centers. The results show that none of the losses can consistently achieve the best performance on the four segmentation tasks, but compound loss functions (e.g. Dice with TopK loss, focal loss, Hausdorff distance loss, and boundary loss) are the most robust losses. Our code and segmentation results are publicly available and can serve as a loss function benchmark. We hope this work will also provide insights on new loss function development for the community.","This work was supported by the National Natural Science Foundation of China (no. 91630311, no. 11971229), and Nanjing University of Science and Technology PhD International Exchange Fellowship. We gratefully acknowledge Fabian Isensee for the public nnU-Net code and helpful discussions. We also thank Compute Canada (www.computecanada.ca) and Nanjing University High Performance Computing Center for the computational resource support.",,Medical Image Analysis,,"Humans; Image Processing, Computer-Assisted; Neural Networks, Computer",2021-03-19,2021,2021-03-19,2021-07,71,,102035,Closed,Article,"Ma, Jun; Chen, Jianan; Ng, Matthew; Huang, Rui; Li, Yu; Li, Chen; Yang, Xiaoping; Martel, Anne L","Ma, Jun (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China. Electronic address: junma@njust.edu.cn.); Chen, Jianan (Department of Medical Biophysics, University of Toronto, Toronto, Canada.); Ng, Matthew (Department of Medical Biophysics, University of Toronto, Toronto, Canada.); Huang, Rui (Department of Medical Biophysics, University of Toronto, Toronto, Canada.); Li, Yu (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China.); Li, Chen (Department of Mathematics, Nanjing University, Nanjing, China.); Yang, Xiaoping (Department of Mathematics, Nanjing University, Nanjing, China.); Martel, Anne L (Department of Medical Biophysics, University of Toronto, Toronto, Canada; Physical Sciences, Sunnybrook Research Institute, Toronto, Canada.)","Ma, Jun (Nanjing University of Science and Technology)","Ma, Jun (Nanjing University of Science and Technology); Chen, Jianan (University of Toronto); Ng, Matthew (University of Toronto); Huang, Rui (University of Toronto); Li, Yu (Nanjing University of Science and Technology); Li, Chen (Nanjing University); Yang, Xiaoping (Nanjing University); Martel, Anne L (University of Toronto)",118,118,14.09,,,https://app.dimensions.ai/details/publication/pub.1136499061,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
1295,pub.1136426725,10.48550/arxiv.2103.08590,,,Interpretability of a Deep Learning Model in the Application of Cardiac  MRI Segmentation with an ACDC Challenge Dataset,"Cardiac Magnetic Resonance (CMR) is the most effective tool for the
assessment and diagnosis of a heart condition, which malfunction is the world's
leading cause of death. Software tools leveraging Artificial Intelligence
already enhance radiologists and cardiologists in heart condition assessment
but their lack of transparency is a problem. This project investigates if it is
possible to discover concepts representative for different cardiac conditions
from the deep network trained to segment crdiac structures: Left Ventricle
(LV), Right Ventricle (RV) and Myocardium (MYO), using explainability methods
that enhances classification system by providing the score-based values of
qualitative concepts, along with the key performance metrics. With introduction
of a need of explanations in GDPR explainability of AI systems is necessary.
This study applies Discovering and Testing with Concept Activation Vectors
(D-TCAV), an interpretaibilty method to extract underlying features important
for cardiac disease diagnosis from MRI data. The method provides a quantitative
notion of concept importance for disease classified. In previous studies, the
base method is applied to the classification of cardiac disease and provides
clinically meaningful explanations for the predictions of a black-box deep
learning classifier. This study applies a method extending TCAV with a
Discovering phase (D-TCAV) to cardiac MRI analysis. The advantage of the D-TCAV
method over the base method is that it is user-independent. The contribution of
this study is a novel application of the explainability method D-TCAV for
cardiac MRI anlysis. D-TCAV provides a shorter pre-processing time for
clinicians than the base method.",,,arXiv,,,2021-03-15,2021,,,,,,All OA, Green,Preprint,"Janik, Adrianna; Dodd, Jonathan; Ifrim, Georgiana; Sankaran, Kris; Curran, Kathleen","Janik, Adrianna (); Dodd, Jonathan (); Ifrim, Georgiana (); Sankaran, Kris (); Curran, Kathleen ()",,"Janik, Adrianna (); Dodd, Jonathan (); Ifrim, Georgiana (); Sankaran, Kris (); Curran, Kathleen ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136426725,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
906,pub.1136426375,10.48550/arxiv.2103.08219,,,Adapt Everywhere: Unsupervised Adaptation of Point-Clouds and Entropy  Minimisation for Multi-modal Cardiac Image Segmentation,"Deep learning models are sensitive to domain shift phenomena. A model trained
on images from one domain cannot generalise well when tested on images from a
different domain, despite capturing similar anatomical structures. It is mainly
because the data distribution between the two domains is different. Moreover,
creating annotation for every new modality is a tedious and time-consuming
task, which also suffers from high inter- and intra- observer variability.
Unsupervised domain adaptation (UDA) methods intend to reduce the gap between
source and target domains by leveraging source domain labelled data to generate
labels for the target domain. However, current state-of-the-art (SOTA) UDA
methods demonstrate degraded performance when there is insufficient data in
source and target domains. In this paper, we present a novel UDA method for
multi-modal cardiac image segmentation. The proposed method is based on
adversarial learning and adapts network features between source and target
domain in different spaces. The paper introduces an end-to-end framework that
integrates: a) entropy minimisation, b) output feature space alignment and c) a
novel point-cloud shape adaptation based on the latent features learned by the
segmentation model. We validated our method on two cardiac datasets by adapting
from the annotated source domain, bSSFP-MRI (balanced Steady-State Free
Procession-MRI), to the unannotated target domain, LGE-MRI (Late-gadolinium
enhance-MRI), for the multi-sequence dataset; and from MRI (source) to CT
(target) for the cross-modality dataset. The results highlighted that by
enforcing adversarial learning in different parts of the network, the proposed
method delivered promising performance, compared to other SOTA methods.",,,arXiv,,,2021-03-15,2021,,,,,,All OA, Green,Preprint,"Vesal, Sulaiman; Gu, Mingxuan; Kosti, Ronak; Maier, Andreas; Ravikumar, Nishant","Vesal, Sulaiman (); Gu, Mingxuan (); Kosti, Ronak (); Maier, Andreas (); Ravikumar, Nishant ()",,"Vesal, Sulaiman (); Gu, Mingxuan (); Kosti, Ronak (); Maier, Andreas (); Ravikumar, Nishant ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136426375,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5706,pub.1136367336,10.1016/j.ejmp.2021.02.024,33721700,PMC8915137,Requirements and reliability of AI in the medical context,"The digital information age has been a catalyst in creating a renewed interest in Artificial Intelligence (AI) approaches, especially the subclass of computer algorithms that are popularly grouped into Machine Learning (ML). These methods have allowed one to go beyond limited human cognitive ability into understanding the complexity in the high dimensional data. Medical sciences have seen a steady use of these methods but have been slow in adoption to improve patient care. There are some significant impediments that have diluted this effort, which include availability of curated diverse data sets for model building, reliable human-level interpretation of these models, and reliable reproducibility of these methods for routine clinical use. Each of these aspects has several limiting conditions that need to be balanced out, considering the data/model building efforts, clinical implementation, integration cost to translational effort with minimal patient level harm, which may directly impact future clinical adoption. In this review paper, we will assess each aspect of the problem in the context of reliable use of the ML methods in oncology, as a representative study case, with the goal to safeguard utility and improve patient care in medicine in general.",,,Physica Medica,,Algorithms, Artificial Intelligence, Humans, Machine Learning, Medicine, Reproducibility of Results,2021-03-13,2021,2021-03-13,2021-03,83,,72-78,All OA, Green,Article,"Balagurunathan, Yoganand; Mitchell, Ross; El Naqa, Issam","Balagurunathan, Yoganand (Department of Machine Learning, H. Lee. Moffitt Cancer Center, Tampa, FL, USA. Electronic address: yogab@moffitt.org.); Mitchell, Ross (Department of Machine Learning, H. Lee. Moffitt Cancer Center, Tampa, FL, USA; Health Data Services, H. Lee. Moffitt Cancer Center, Tampa, FL, USA. Electronic address: ross.mitchell@moffitt.org.); El Naqa, Issam (Department of Machine Learning, H. Lee. Moffitt Cancer Center, Tampa, FL, USA. Electronic address: issam.elnaqa@moffitt.org.)","El Naqa, Issam (Moffitt Cancer Center)","Balagurunathan, Yoganand (Moffitt Cancer Center); Mitchell, Ross (Moffitt Cancer Center); El Naqa, Issam (Moffitt Cancer Center)",19,19,3.03,14.09,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8915137,https://app.dimensions.ai/details/publication/pub.1136367336,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering, 51 Physical Sciences, 5105 Medical and Biological Physics,3 Good Health and Well Being
4788,pub.1136334108,10.1038/s41569-021-00527-2,33712806,,Applications of artificial intelligence in cardiovascular imaging,"Research into artificial intelligence (AI) has made tremendous progress over the past decade. In particular, the AI-powered analysis of images and signals has reached human-level performance in many applications owing to the efficiency of modern machine learning methods, in particular deep learning using convolutional neural networks. Research into the application of AI to medical imaging is now very active, especially in the field of cardiovascular imaging because of the challenges associated with acquiring and analysing images of this dynamic organ. In this Review, we discuss the clinical questions in cardiovascular imaging that AI can be used to address and the principal methodological AI approaches that have been developed to solve the related image analysis problems. Some approaches are purely data-driven and rely mainly on statistical associations, whereas others integrate anatomical and physiological information through additional statistical, geometric and biophysical models of the human heart. In a structured manner, we provide representative examples of each of these approaches, with particular attention to the underlying computational imaging challenges. Finally, we discuss the remaining limitations of AI approaches in cardiovascular imaging (such as generalizability and explainability) and how they can be overcome.","Part of the authors’ work has been supported by the French Government, through the National Research Agency (ANR): 3IA Côte d’Azur (ANR-19-P3IA-0002), IHU Liryc (ANR-10-IAHU-04) and Equipex MUSIC (ANR-11-EQPX-0030). The research leading to these results has also received European funding from the ERC starting grant ECSTATIC (715093).",,Nature Reviews Cardiology,,Artificial Intelligence, Cardiovascular Diseases, Humans,2021-03-12,2021,2021-03-12,2021-08,18,8,600-609,Closed,Article,"Sermesant, Maxime; Delingette, Hervé; Cochet, Hubert; Jaïs, Pierre; Ayache, Nicholas","Sermesant, Maxime (Inria, Université Côte d’Azur, Sophia Antipolis, France); Delingette, Hervé (Inria, Université Côte d’Azur, Sophia Antipolis, France); Cochet, Hubert (IHU Liryc, CHU Bordeaux, Université Bordeaux, Inserm 1045, Pessac, France); Jaïs, Pierre (IHU Liryc, CHU Bordeaux, Université Bordeaux, Inserm 1045, Pessac, France); Ayache, Nicholas (Inria, Université Côte d’Azur, Sophia Antipolis, France)","Sermesant, Maxime ","Sermesant, Maxime (); Delingette, Hervé (); Cochet, Hubert (); Jaïs, Pierre (); Ayache, Nicholas ()",42,42,7.38,47.39,,https://app.dimensions.ai/details/publication/pub.1136334108,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,
4539,pub.1136304683,10.1016/j.media.2021.102029,33831594,PMC8204226,Deep neural network ensemble for on-the-fly quality control-driven segmentation of cardiac MRI T1 mapping,"Recent developments in artificial intelligence have generated increasing interest to deploy automated image analysis for diagnostic imaging and large-scale clinical applications. However, inaccuracy from automated methods could lead to incorrect conclusions, diagnoses or even harm to patients. Manual inspection for potential inaccuracies is labor-intensive and time-consuming, hampering progress towards fast and accurate clinical reporting in high volumes. To promote reliable fully-automated image analysis, we propose a quality control-driven (QCD) segmentation framework. It is an ensemble of neural networks that integrate image analysis and quality control. The novelty of this framework is the selection of the most optimal segmentation based on predicted segmentation accuracy, on-the-fly. Additionally, this framework visualizes segmentation agreement to provide traceability of the quality control process. In this work, we demonstrated the utility of the framework in cardiovascular magnetic resonance T1-mapping - a quantitative technique for myocardial tissue characterization. The framework achieved near-perfect agreement with expert image analysts in estimating myocardial T1 value (r=0.987,p<.0005; mean absolute error (MAE)=11.3ms), with accurate segmentation quality prediction (Dice coefficient prediction MAE=0.0339) and classification (accuracy=0.99), and a fast average processing time of 0.39 second/image. In summary, the QCD framework can generate high-throughput automated image analysis with speed and accuracy that is highly desirable for large-scale clinical applications.","A patent is filed for this work. EH and RAG acknowledge support for their DPhil studies from the Clarendon Fund, and the Radcliffe Department of Medicine, University of Oxford. EH acknowledges donation of a GPU from NVIDIA for this work. IAP, SKP, VMF and SN acknowledge support from the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre at The Oxford University Hospitals NHS Foundations Trust, University of Oxford, UK. SKP, VMF and SN acknowledge the British Heart Foundation (BHF) Centre of Research Excellence, Oxford. QZ and VMF are supported by the BHF.",,Medical Image Analysis,,"Artificial Intelligence; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Quality Control; Reproducibility of Results",2021-03-11,2021,2021-03-11,2021-07,71,,102029,All OA, Hybrid,Article,"Hann, Evan; Popescu, Iulia A.; Zhang, Qiang; Gonzales, Ricardo A.; Barutçu, Ahmet; Neubauer, Stefan; Ferreira, Vanessa M.; Piechnik, Stefan K.","Hann, Evan (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom); Popescu, Iulia A. (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom); Zhang, Qiang (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom); Gonzales, Ricardo A. (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom); Barutçu, Ahmet (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom; Çanakkale Onsekiz Mart University, Barbaros, 17100 Kepez/Çanakkale Merkez/Çanakkale, Turkey); Neubauer, Stefan (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom); Ferreira, Vanessa M. (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom); Piechnik, Stefan K. (Oxford University Centre for Clinical Magnetic Resonance Research (OCMR), Level 0, John Radcliffe Hospital, Headington, Oxford OX3 9DU, United Kingdom)","Hann, Evan (University of Oxford; John Radcliffe Hospital)","Hann, Evan (University of Oxford; John Radcliffe Hospital); Popescu, Iulia A. (University of Oxford; John Radcliffe Hospital); Zhang, Qiang (University of Oxford; John Radcliffe Hospital); Gonzales, Ricardo A. (University of Oxford; John Radcliffe Hospital); Barutçu, Ahmet (University of Oxford; John Radcliffe Hospital; Çanakkale Onsekiz Mart University); Neubauer, Stefan (University of Oxford; John Radcliffe Hospital); Ferreira, Vanessa M. (University of Oxford; John Radcliffe Hospital); Piechnik, Stefan K. (University of Oxford; John Radcliffe Hospital)",27,27,5.14,23.67,https://doi.org/10.1016/j.media.2021.102029,https://app.dimensions.ai/details/publication/pub.1136304683,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
6720,pub.1134757489,10.1088/1361-6560/abde98,33477123,,Image-level supervised segmentation for human organs with confidence cues,"Image segmentation for human organs is an important task for the diagnosis and treatment of diseases. Current deep learning-based methods are fully supervised and need pixel-level labels. Since the medical images are highly specialized and complex, the work of delineating pixel-level segmentation masks is very time-consuming. Weakly supervised methods are then chosen to lighten the workload, which only needs physicians to determine whether an image contains the organ regions of interest. These weakly supervised methods have a common drawback, in that they do not incorporate prior knowledge that alleviates the lack of pixel-level information for segmentation. In this work, we propose a weakly supervised method based on prior knowledge for the segmentation of human organs. The proposed method was validated on three data sets of human organ segmentation. Experimental results show that the proposed image-level supervised segmentation method outperforms several state-of-the-art methods.","This work was supported in part by NSFC under grant No. 61 876 148, Fundamental Research Funds for the Central Universities No. XJJ2018254, and China Postdoctoral Science Foundation NO. 2018M631164.",,Physics in Medicine and Biology,,"Algorithms; Computer Simulation; Cues; Deep Learning; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Prostate; Prostatic Neoplasms; Radiology; Supervised Machine Learning",2021-03-08,2021,2021-03-08,2021-03-21,66,6,65018,Closed,Article,"Chen, Zhang; Tian, Zhiqiang; Zheng, Yaoyue; Si, Xiangyu; Qin, Xulei; Shi, Zhong; Zheng, Shuai","Chen, Zhang (School of Software Engineering, Xi’an Jiaotong University, Shaanxi, People’s Republic of China); Tian, Zhiqiang (School of Software Engineering, Xi’an Jiaotong University, Shaanxi, People’s Republic of China); Zheng, Yaoyue (School of Software Engineering, Xi’an Jiaotong University, Shaanxi, People’s Republic of China); Si, Xiangyu (School of Software Engineering, Xi’an Jiaotong University, Shaanxi, People’s Republic of China); Qin, Xulei (Cardiovascular Institute Operations, Stanford University, CA, United States of America); Shi, Zhong (Institute of Cancer and Basic Medicine (ICBM), Chinese Academy of Sciences, Zhejiang, People’s Republic of China; Cancer Hospital of the University of Chinese Academy of Sciences, Zhejiang, People’s Republic of China); Zheng, Shuai (School of Software Engineering, Xi’an Jiaotong University, Shaanxi, People’s Republic of China)",,"Chen, Zhang (Xi'an Jiaotong University); Tian, Zhiqiang (Xi'an Jiaotong University); Zheng, Yaoyue (Xi'an Jiaotong University); Si, Xiangyu (Xi'an Jiaotong University); Qin, Xulei (Stanford University); Shi, Zhong (Chinese Academy of Sciences; University of Chinese Academy of Sciences); Zheng, Shuai (Xi'an Jiaotong University)",3,3,0.37,3.76,,https://app.dimensions.ai/details/publication/pub.1134757489,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,,
1459,pub.1136235547,10.48550/arxiv.2103.04708,,,Dual-Task Mutual Learning for Semi-Supervised Medical Image Segmentation,"The success of deep learning methods in medical image segmentation tasks
usually requires a large amount of labeled data. However, obtaining reliable
annotations is expensive and time-consuming. Semi-supervised learning has
attracted much attention in medical image segmentation by taking the advantage
of unlabeled data which is much easier to acquire. In this paper, we propose a
novel dual-task mutual learning framework for semi-supervised medical image
segmentation. Our framework can be formulated as an integration of two
individual segmentation networks based on two tasks: learning region-based
shape constraint and learning boundary-based surface mismatch. Different from
the one-way transfer between teacher and student networks, an ensemble of
dual-task students can learn collaboratively and implicitly explore useful
knowledge from each other during the training process. By jointly learning the
segmentation probability maps and signed distance maps of targets, our
framework can enforce the geometric shape constraint and learn more reliable
information. Experimental results demonstrate that our method achieves
performance gains by leveraging unlabeled data and outperforms the
state-of-the-art semi-supervised segmentation methods.",,,arXiv,,,2021-03-08,2021,,,,,,All OA, Green,Preprint,"Zhang, Yichi; Zhang, Jicong","Zhang, Yichi (); Zhang, Jicong ()",,"Zhang, Yichi (); Zhang, Jicong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136235547,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1454,pub.1136271364,10.48550/arxiv.2103.05214,,,Universal Undersampled MRI Reconstruction,"Deep neural networks have been extensively studied for undersampled MRI
reconstruction. While achieving state-of-the-art performance, they are trained
and deployed specifically for one anatomy with limited generalization ability
to another anatomy. Rather than building multiple models, a universal model
that reconstructs images across different anatomies is highly desirable for
efficient deployment and better generalization. Simply mixing images from
multiple anatomies for training a single network does not lead to an ideal
universal model due to the statistical shift among datasets of various
anatomies, the need to retrain from scratch on all datasets with the addition
of a new dataset, and the difficulty in dealing with imbalanced sampling when
the new dataset is further of a smaller size. In this paper, for the first
time, we propose a framework to learn a universal deep neural network for
undersampled MRI reconstruction. Specifically, anatomy-specific instance
normalization is proposed to compensate for statistical shift and allow easy
generalization to new datasets. Moreover, the universal model is trained by
distilling knowledge from available independent models to further exploit
representations across anatomies. Experimental results show the proposed
universal model can reconstruct both brain and knee images with high image
quality. Also, it is easy to adapt the trained model to new datasets of smaller
size, i.e., abdomen, cardiac and prostate, with little effort and superior
performance.",,,arXiv,,,2021-03-08,2021,,,,,,All OA, Green,Preprint,"Liu, Xinwen; Wang, Jing; Liu, Feng; Zhou, S. Kevin","Liu, Xinwen (); Wang, Jing (); Liu, Feng (); Zhou, S. Kevin ()",,"Liu, Xinwen (); Wang, Jing (); Liu, Feng (); Zhou, S. Kevin ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136271364,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
909,pub.1136235647,10.48550/arxiv.2103.04813,,,Boosting Semi-supervised Image Segmentation with Global and Local Mutual  Information Regularization,"The scarcity of labeled data often impedes the application of deep learning
to the segmentation of medical images. Semi-supervised learning seeks to
overcome this limitation by exploiting unlabeled examples in the learning
process. In this paper, we present a novel semi-supervised segmentation method
that leverages mutual information (MI) on categorical distributions to achieve
both global representation invariance and local smoothness. In this method, we
maximize the MI for intermediate feature embeddings that are taken from both
the encoder and decoder of a segmentation network. We first propose a global MI
loss constraining the encoder to learn an image representation that is
invariant to geometric transformations. Instead of resorting to
computationally-expensive techniques for estimating the MI on continuous
feature embeddings, we use projection heads to map them to a discrete cluster
assignment where MI can be computed efficiently. Our method also includes a
local MI loss to promote spatial consistency in the feature maps of the decoder
and provide a smoother segmentation. Since mutual information does not require
a strict ordering of clusters in two different assignments, we incorporate a
final consistency regularization loss on the output which helps align the
cluster labels throughout the network. We evaluate the method on four
challenging publicly-available datasets for medical image segmentation.
Experimental results show our method to outperform recently-proposed approaches
for semi-supervised segmentation and provide an accuracy near to full
supervision while training with very few annotated images.",,,arXiv,,,2021-03-08,2021,,,,,,All OA, Green,Preprint,"Peng, Jizong; Pedersoli, Marco; Desrosiers, Christian","Peng, Jizong (); Pedersoli, Marco (); Desrosiers, Christian ()",,"Peng, Jizong (); Pedersoli, Marco (); Desrosiers, Christian ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136235647,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5667,pub.1135144602,10.1002/mp.14752,33544895,PMC8251605,SAUN: Stack attention U‐Net for left ventricle segmentation from cardiac cine magnetic resonance imaging,"PURPOSE: Quantification of left ventricular (LV) volume, ejection fraction and myocardial mass from multi-slice multi-phase cine MRI requires accurate segmentation of the LV in many images. We propose a stack attention-based convolutional neural network (CNN) approach for fully automatic segmentation from short-axis cine MR images.
METHODS: To extract the relevant spatiotemporal image features, we introduce two kinds of stack methods, spatial stack model and temporal stack model, combining the target image with its neighboring images as the input of a CNN. A stack attention mechanism is proposed to weigh neighboring image slices in order to extract the relevant features using the target image as a guide. Based on stack attention and standard U-Net, a novel Stack Attention U-Net (SAUN) is proposed and trained to perform the semantic segmentation task. A loss function combining cross-entropy and Dice is used to train SAUN. The performance of the proposed method was evaluated on an internal and a public dataset using technical metrics including Dice, Hausdorff distance (HD), and mean contour distance (MCD), as well as clinical parameters, including left ventricular ejection fraction (LVEF) and myocardial mass (LVM). In addition, the results of SAUN were compared to previously presented CNN methods, including U-Net and SegNet.
RESULTS: The spatial stack attention model resulted in better segmentation results than the temporal stack model. On the internal dataset comprising of 167 post-myocardial infarction patients and 57 healthy volunteers, our method achieved a mean Dice of 0.91, HD of 3.37 mm, and MCD of 1.08 mm. Evaluation on the publicly available ACDC dataset demonstrated good generalization performance, yielding a Dice of 0.92, HD of 9.4 mm, and MCD of 0.74 mm on end-diastolic images, and a Dice of 0.89, HD of 7.1 mm and MCD of 1.03 mm on end-systolic images. The Pearson correlation coefficient of LVEF and LVM between automatically and manually derived results were higher than 0.98 in both datasets.
CONCLUSION: We developed a CNN with a stack attention mechanism to automatically segment the LV chamber and myocardium from the multi-slice short-axis cine MRI. The experimental results demonstrate that the proposed approach exceeds existing state-of-the-art segmentation methods and verify its potential clinical applicability.",Prof. Sven Plein from the University of Leeds is acknowledged for granting access to the image data used in this work. We also would like to acknowledge the organizer of ACDC 2017 challenge to collect and public the dataset. X. Sun is supported by the China Scholarship Council No. 201808110201.,,Medical Physics,,"Heart; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Stroke Volume; Ventricular Function, Left",2021-03-04,2021,2021-03-04,2021-04,48,4,1750-1763,All OA, Hybrid,Article,"Sun, Xiaowu; Garg, Pankaj; Plein, Sven; Geest, Rob J.","Sun, Xiaowu (Division of Image Processing, Department of Radiology, Leiden University Medical Center, PO Box 9600, Leiden, 2300 RC, The Netherlands); Garg, Pankaj (Department of Infection, Immunity & Cardiovascular Disease, University of Sheffield, Sheffield, UK); Plein, Sven (Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine University of Leeds, Leeds, UK); Geest, Rob J. (Division of Image Processing, Department of Radiology, Leiden University Medical Center, PO Box 9600, Leiden, 2300 RC, The Netherlands)","Geest, Rob J. (Leiden University Medical Center)","Sun, Xiaowu (Leiden University Medical Center); Garg, Pankaj (University of Sheffield); Plein, Sven (University of Leeds); Geest, Rob J. (Leiden University Medical Center)",9,9,1.07,11.27,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.14752,https://app.dimensions.ai/details/publication/pub.1135144602,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,
953,pub.1136005717,10.48550/arxiv.2103.02844,,,Learning With Context Feedback Loop for Robust Medical Image  Segmentation,"Deep learning has successfully been leveraged for medical image segmentation.
It employs convolutional neural networks (CNN) to learn distinctive image
features from a defined pixel-wise objective function. However, this approach
can lead to less output pixel interdependence producing incomplete and
unrealistic segmentation results. In this paper, we present a fully automatic
deep learning method for robust medical image segmentation by formulating the
segmentation problem as a recurrent framework using two systems. The first one
is a forward system of an encoder-decoder CNN that predicts the segmentation
result from the input image. The predicted probabilistic output of the forward
system is then encoded by a fully convolutional network (FCN)-based context
feedback system. The encoded feature space of the FCN is then integrated back
into the forward system's feed-forward learning process. Using the FCN-based
context feedback loop allows the forward system to learn and extract more
high-level image features and fix previous mistakes, thereby improving
prediction accuracy over time. Experimental results, performed on four
different clinical datasets, demonstrate our method's potential application for
single and multi-structure medical image segmentation by outperforming the
state of the art methods. With the feedback loop, deep learning methods can now
produce results that are both anatomically plausible and robust to low contrast
images. Therefore, formulating image segmentation as a recurrent framework of
two interconnected networks via context feedback loop can be a potential method
for robust and efficient medical image analysis.",,,arXiv,,,2021-03-04,2021,,,,,,All OA, Green,Preprint,"Girum, Kibrom Berihu; Créhange, Gilles; Lalande, Alain","Girum, Kibrom Berihu (); Créhange, Gilles (); Lalande, Alain ()",,"Girum, Kibrom Berihu (); Créhange, Gilles (); Lalande, Alain ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136005717,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1296,pub.1135915588,10.48550/arxiv.2103.02417,,,Deep Learning-based Automated Aortic Area and Distensibility Assessment:  The Multi-Ethnic Study of Atherosclerosis (MESA),"This study applies convolutional neural network (CNN)-based automatic
segmentation and distensibility measurement of the ascending and descending
aorta from 2D phase-contrast cine magnetic resonance imaging (PC-cine MRI)
within the large MESA cohort with subsequent assessment on an external cohort
of thoracic aortic aneurysm (TAA) patients. 2D PC-cine MRI images of the
ascending and descending aorta at the pulmonary artery bifurcation from the
MESA study were included. Train, validation, and internal test sets consisted
of 1123 studies (24282 images), 374 studies (8067 images), and 375 studies
(8069 images), respectively. An external test set of TAAs consisted of 37
studies (3224 images). A U-Net based CNN was constructed, and performance was
evaluated utilizing dice coefficient (for segmentation) and concordance
correlation coefficients (CCC) of aortic geometric parameters by comparing to
manual segmentation and parameter estimation. Dice coefficients for aorta
segmentation were 97.6% (CI: 97.5%-97.6%) and 93.6% (84.6%-96.7%) on the
internal and external test of TAAs, respectively. CCC for comparison of manual
and CNN maximum and minimum ascending aortic areas were 0.97 and 0.95,
respectively, on the internal test set and 0.997 and 0.995, respectively, for
the external test. CCCs for maximum and minimum descending aortic areas were
0.96 and 0. 98, respectively, on the internal test set and 0.93 and 0.93,
respectively, on the external test set. We successfully developed and validated
a U-Net based ascending and descending aortic segmentation and distensibility
quantification model in a large multi-ethnic database and in an external cohort
of TAA patients.",,,arXiv,,,2021-03-03,2021,,,,,,All OA, Green,Preprint,"Jani, Vivek P.; Kachenoura, Nadjia; Redheuil, Alban; Teixido-Tura, Gisela; Bouaou, Kevin; Bollache, Emilie; Mousseaux, Elie; De Cesare, Alain; Kutty, Shelby; Wu, Colin O.; Bluemke, David A.; Lima, Joao A. C.; Ambale-Venkatesh, Bharath","Jani, Vivek P. (); Kachenoura, Nadjia (); Redheuil, Alban (); Teixido-Tura, Gisela (); Bouaou, Kevin (); Bollache, Emilie (); Mousseaux, Elie (); De Cesare, Alain (); Kutty, Shelby (); Wu, Colin O. (); Bluemke, David A. (); Lima, Joao A. C. (); Ambale-Venkatesh, Bharath ()",,"Jani, Vivek P. (); Kachenoura, Nadjia (); Redheuil, Alban (); Teixido-Tura, Gisela (); Bouaou, Kevin (); Bollache, Emilie (); Mousseaux, Elie (); De Cesare, Alain (); Kutty, Shelby (); Wu, Colin O. (); Bluemke, David A. (); Lima, Joao A. C. (); Ambale-Venkatesh, Bharath ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1135915588,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
5037,pub.1135795611,10.3390/jcm10050921,33652931,PMC7956169,Diagnosis and Risk Prediction of Dilated Cardiomyopathy in the Era of Big Data and Genomics,"Dilated cardiomyopathy (DCM) is a leading cause of heart failure and life-threatening ventricular arrhythmias (LTVA). Work-up and risk stratification of DCM is clinically challenging, as there is great heterogeneity in phenotype and genotype. Throughout the last decade, improved genetic testing of patients has identified genotype-phenotype associations and enhanced evaluation of at-risk relatives leading to better patient prognosis. The field is now ripe to explore opportunities to improve personalised risk assessments. Multivariable risk models presented as ""risk calculators"" can incorporate a multitude of clinical variables and predict outcome (such as heart failure hospitalisations or LTVA). In addition, genetic risk scores derived from genome/exome-wide association studies can estimate an individual's lifetime genetic risk of developing DCM. The use of clinically granular investigations, such as late gadolinium enhancement on cardiac magnetic resonance imaging, is warranted in order to increase predictive performance. To this end, constructing big data infrastructures improves accessibility of data by using electronic health records, existing research databases, and disease registries. By applying methods such as machine and deep learning, we can model complex interactions, identify new phenotype clusters, and perform prognostic modelling. This review aims to provide an overview of the evolution of DCM definitions as well as its clinical work-up and considerations in the era of genomics. In addition, we present exciting examples in the field of big data infrastructures, personalised prognostic assessment, and artificial intelligence.",,"Arjan Sammani is supported by the Alexandre Suerman Stipendium. Anneline te Riele is supported by the Dutch Heart Foundation (2015T058) and the UMC Utrecht Fellowship Clinical Research Talent. Annette Baas is supported by Netherlands Heart Foundation (Dekker 2015T041). Folkert Asselbergs is supported by UCL Hospitals NIHR Biomedical Research Centre. This work is further supported by the Netherlands Cardiovasular Research Initiative, with support of the Dutch Heart Foundation (CVON 2015-12 eDETECT).",Journal of Clinical Medicine,,,2021-02-26,2021,2021-02-26,,10,5,921,All OA, Gold,Article,"Sammani, Arjan; Baas, Annette F.; Asselbergs, Folkert W.; Riele, Anneline S. J. M. te","Sammani, Arjan (Department of Cardiology, Division Heart & Lungs, University Medical Center Utrecht, Utrecht University, 3582 CX Utrecht, The Netherlands;, A.zabihisammani@umcutrecht.nl, (A.S.);, F.W.Asselbergs@umcutrecht.nl, (F.W.A.)); Baas, Annette F. (Department of Genetics, Division Laboratories, Pharmacy and Biomedical Genetics, University Medical Centre Utrecht, University of Utrecht, 3582 CX Utrecht, The Netherlands;, a.f.baas@umcutrecht.nl); Asselbergs, Folkert W. (Department of Cardiology, Division Heart & Lungs, University Medical Center Utrecht, Utrecht University, 3582 CX Utrecht, The Netherlands;, A.zabihisammani@umcutrecht.nl, (A.S.);, F.W.Asselbergs@umcutrecht.nl, (F.W.A.); Institute of Cardiovascular Science, Faculty of Population Health Sciences, University College London, London WC1E 6BT, UK; Health Data Research UK and Institute of Health Informatics, University College London, London WC1E 6BT, UK); Riele, Anneline S. J. M. te (Department of Cardiology, Division Heart & Lungs, University Medical Center Utrecht, Utrecht University, 3582 CX Utrecht, The Netherlands;, A.zabihisammani@umcutrecht.nl, (A.S.);, F.W.Asselbergs@umcutrecht.nl, (F.W.A.))","Riele, Anneline S. J. M. te (University Medical Center Utrecht; Utrecht University; )","Sammani, Arjan (University Medical Center Utrecht; Utrecht University); Baas, Annette F. (University Medical Center Utrecht; Utrecht University); Asselbergs, Folkert W. (University Medical Center Utrecht; Utrecht University; University College London; Health Data Research UK; University College London); Riele, Anneline S. J. M. te (University Medical Center Utrecht; Utrecht University)",9,9,1.71,,https://www.mdpi.com/2077-0383/10/5/921/pdf?version=1615467325,https://app.dimensions.ai/details/publication/pub.1135795611,32 Biomedical and Clinical Sciences,3 Good Health and Well Being,,,,,,,,,,
1451,pub.1135826234,10.48550/arxiv.2102.13645,,,Convolution-Free Medical Image Segmentation using Transformers,"Like other applications in computer vision, medical image segmentation has
been most successfully addressed using deep learning models that rely on the
convolution operation as their main building block. Convolutions enjoy
important properties such as sparse interactions, weight sharing, and
translation equivariance. These properties give convolutional neural networks
(CNNs) a strong and useful inductive bias for vision tasks. In this work we
show that a different method, based entirely on self-attention between
neighboring image patches and without any convolution operations, can achieve
competitive or better results. Given a 3D image block, our network divides it
into $n^3$ 3D patches, where $n=3 \text{ or } 5$ and computes a 1D embedding
for each patch. The network predicts the segmentation map for the center patch
of the block based on the self-attention between these patch embeddings. We
show that the proposed model can achieve segmentation accuracies that are
better than the state of the art CNNs on three datasets. We also propose
methods for pre-training this model on large corpora of unlabeled images. Our
experiments show that with pre-training the advantage of our proposed network
over CNNs can be significant when labeled training data is small.",,,arXiv,,,2021-02-26,2021,,,,,,All OA, Green,Preprint,"Karimi, Davood; Vasylechko, Serge; Gholipour, Ali","Karimi, Davood (); Vasylechko, Serge (); Gholipour, Ali ()",,"Karimi, Davood (); Vasylechko, Serge (); Gholipour, Ali ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1135826234,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1295,pub.1135743708,10.1007/s11227-021-03664-0,,,Deploying deep learning approaches to left ventricular non-compaction measurement,"Left ventricular non-compaction (LVNC) is a rare cardiomyopathy characterized by abnormal trabeculations in the left ventricle cavity. Although traditional computer vision approaches exist for LVNC diagnosis, deep learning-based tools could not be found in the literature. In this paper, a first approach using convolutional neural networks (CNNs) is presented. Four CNNs are trained and tuned to automatically segment the compacted and trabecular areas of the left ventricle for a population of patients diagnosed with hypertrophic cardiomyopathy. We have evaluated them in the learning phase with an NVIDIA Turing GPU and 2 competitive Xeon CPUs. Inference results confirm that deep learning-based approaches can achieve excellent results in the diagnosis and measurement of LVNC. The final proposal enables real-time analysis of 15-slice MRI studies on both GPU and CPU, obtaining noticeable speed-ups with regard to manual, semi-automatic and fully automatic approaches. Additionally, a subjective evaluation of the output images with the identified zones is performed by expert cardiologists, with a perfect visual agreement for all the slices, outperforming already existing automatic tools.","This work was supported by the Spanish MCIU and AEI, as well as European Commission FEDER funds, under Grant RTI2018-098156-B-C53.",,The Journal of Supercomputing,,,2021-02-25,2021,2021-02-25,2021-09,77,9,10138-10151,Closed,Article,"Rodríguez-de-Vera, Jesús M.; González-Carrillo, Josefa; García, José M.; Bernabé, Gregorio","Rodríguez-de-Vera, Jesús M. (Computer Engineering Department, University of Murcia, Murcia, Spain); González-Carrillo, Josefa (Hospital Virgen de la Arrixaca, Murcia, Spain); García, José M. (Computer Engineering Department, University of Murcia, Murcia, Spain); Bernabé, Gregorio (Computer Engineering Department, University of Murcia, Murcia, Spain)","Bernabé, Gregorio (University of Murcia)","Rodríguez-de-Vera, Jesús M. (University of Murcia); González-Carrillo, Josefa (Hospital Universitario Virgen de la Arrixaca); García, José M. (University of Murcia); Bernabé, Gregorio (University of Murcia)",1,1,,0.83,,https://app.dimensions.ai/details/publication/pub.1135743708,46 Information and Computing Sciences, 4602 Artificial Intelligence,,,,,,,,,,,
6279,pub.1135655299,10.1038/s41598-021-83955-x,33623074,PMC7902630,Automatic segmentation of inner ear on CT-scan using auto-context convolutional neural network,"Temporal bone CT-scan is a prerequisite in most surgical procedures concerning the ear such as cochlear implants. The 3D vision of inner ear structures is crucial for diagnostic and surgical preplanning purposes. Since clinical CT-scans are acquired at relatively low resolutions, improved performance can be achieved by registering patient-specific CT images to a high-resolution inner ear model built from accurate 3D segmentations based on micro-CT of human temporal bone specimens. This paper presents a framework based on convolutional neural network for human inner ear segmentation from micro-CT images which can be used to build such a model from an extensive database. The proposed approach employs an auto-context based cascaded 2D U-net architecture with 3D connected component refinement to segment the cochlear scalae, semicircular canals, and the vestibule. The system was formulated on a data set composed of 17 micro-CT from public Hear-EU dataset. A Dice coefficient of 0.90 and Hausdorff distance of 0.74 mm were obtained. The system yielded precise and fast automatic inner-ear segmentations.","Authors acknowledge the financial support of Oticon Medical, France for this project. The authors are also grateful to the NVIDIA GPU grant program for donating the TITAN X processor.",,Scientific Reports,,"Ear, Inner; Humans; Neural Networks, Computer; Temporal Bone; Tomography, X-Ray Computed",2021-02-23,2021,2021-02-23,,11,1,4406,All OA, Gold,Article,"Hussain, Raabid; Lalande, Alain; Girum, Kibrom Berihu; Guigou, Caroline; Bozorg Grayeli, Alexis","Hussain, Raabid (ImViA Laboratory, University of Burgundy Franche Comte, Dijon, France); Lalande, Alain (ImViA Laboratory, University of Burgundy Franche Comte, Dijon, France; Medical Imaging Department, University Hospital of Dijon, Dijon, France); Girum, Kibrom Berihu (ImViA Laboratory, University of Burgundy Franche Comte, Dijon, France); Guigou, Caroline (ImViA Laboratory, University of Burgundy Franche Comte, Dijon, France; Otolaryngology Department, University Hospital of Dijon, Dijon, France); Bozorg Grayeli, Alexis (ImViA Laboratory, University of Burgundy Franche Comte, Dijon, France; Otolaryngology Department, University Hospital of Dijon, Dijon, France)","Hussain, Raabid (University of Burgundy)","Hussain, Raabid (University of Burgundy); Lalande, Alain (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne); Girum, Kibrom Berihu (University of Burgundy); Guigou, Caroline (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne); Bozorg Grayeli, Alexis (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne)",10,10,3.29,10.39,https://www.nature.com/articles/s41598-021-83955-x.pdf,https://app.dimensions.ai/details/publication/pub.1135655299,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
1258,pub.1135699203,10.3390/app11041965,,,Region-of-Interest-Based Cardiac Image Segmentation with Deep Learning,"Despite the promising results obtained by deep learning methods in the field of medical image segmentation, lack of sufficient data always hinders performance to a certain degree. In this work, we explore the feasibility of applying deep learning methods on a pilot dataset. We present a simple and practical approach to perform segmentation in a 2D, slice-by-slice manner, based on region of interest (ROI) localization, applying an optimized training regime to improve segmentation performance from regions of interest. We start from two popular segmentation networks, the preferred model for medical segmentation, U-Net, and a general-purpose model, DeepLabV3+. Furthermore, we show that ensembling of these two fundamentally different architectures brings constant benefits by testing our approach on two different datasets, the publicly available ACDC challenge, and the imATFIB dataset from our in-house conducted clinical study. Results on the imATFIB dataset show that the proposed approach performs well with the provided training volumes, achieving an average Dice Similarity Coefficient of the whole heart of 89.89% on the validation set. Moreover, our algorithm achieved a mean Dice value of 91.87% on the ACDC validation, being comparable to the second best-performing approach on the challenge. Our approach provides an opportunity to serve as a building block of a computer-aided diagnostic system in a clinical setting.","The excellent technical assistance of Mihaela Coman, Cristina Szabo and Silviu Ianc is highly appreciated.","The authors highly acknowledge financial support from the Competitiveness Operational Program 2014-2020 POC-A1-A1.1.4-E-2015, financed under the European Regional Development Fund, project number P37_245.",Applied Sciences,,,2021-02-23,2021,2021-02-23,,11,4,1965,All OA, Gold,Article,"Galea, Raul-Ronald; Diosan, Laura; Andreica, Anca; Popa, Loredana; Manole, Simona; Bálint, Zoltán","Galea, Raul-Ronald (IMOGEN Research Institute, County Clinical Emergency Hospital, Clinicilor, 1-3, Cluj-Napoca, 400008 Cluj, Romania;, lauras@cs.ubbcluj.ro, (L.D.);, anca@cs.ubbcluj.ro, (A.A.);, paplory@yahoo.com, (L.P.);, simona.manole@gmail.com, (S.M.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.)); Diosan, Laura (IMOGEN Research Institute, County Clinical Emergency Hospital, Clinicilor, 1-3, Cluj-Napoca, 400008 Cluj, Romania;, lauras@cs.ubbcluj.ro, (L.D.);, anca@cs.ubbcluj.ro, (A.A.);, paplory@yahoo.com, (L.P.);, simona.manole@gmail.com, (S.M.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.); Faculty of Mathematics and Computer Science, Babes-Bolyai University, Mihail Kogălniceanu 1, Cluj-Napoca, 400084 Cluj, Romania); Andreica, Anca (IMOGEN Research Institute, County Clinical Emergency Hospital, Clinicilor, 1-3, Cluj-Napoca, 400008 Cluj, Romania;, lauras@cs.ubbcluj.ro, (L.D.);, anca@cs.ubbcluj.ro, (A.A.);, paplory@yahoo.com, (L.P.);, simona.manole@gmail.com, (S.M.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.); Faculty of Mathematics and Computer Science, Babes-Bolyai University, Mihail Kogălniceanu 1, Cluj-Napoca, 400084 Cluj, Romania); Popa, Loredana (IMOGEN Research Institute, County Clinical Emergency Hospital, Clinicilor, 1-3, Cluj-Napoca, 400008 Cluj, Romania;, lauras@cs.ubbcluj.ro, (L.D.);, anca@cs.ubbcluj.ro, (A.A.);, paplory@yahoo.com, (L.P.);, simona.manole@gmail.com, (S.M.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.)); Manole, Simona (IMOGEN Research Institute, County Clinical Emergency Hospital, Clinicilor, 1-3, Cluj-Napoca, 400008 Cluj, Romania;, lauras@cs.ubbcluj.ro, (L.D.);, anca@cs.ubbcluj.ro, (A.A.);, paplory@yahoo.com, (L.P.);, simona.manole@gmail.com, (S.M.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.)); Bálint, Zoltán (IMOGEN Research Institute, County Clinical Emergency Hospital, Clinicilor, 1-3, Cluj-Napoca, 400008 Cluj, Romania;, lauras@cs.ubbcluj.ro, (L.D.);, anca@cs.ubbcluj.ro, (A.A.);, paplory@yahoo.com, (L.P.);, simona.manole@gmail.com, (S.M.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.); Faculty of Physics, Babes-Bolyai University, Mihail Kogălniceanu 1, Cluj-Napoca, 400084 Cluj, Romania)","Galea, Raul-Ronald ","Galea, Raul-Ronald (); Diosan, Laura (Babeș-Bolyai University); Andreica, Anca (Babeș-Bolyai University); Popa, Loredana (); Manole, Simona (); Bálint, Zoltán (Babeș-Bolyai University)",8,8,,10.02,https://www.mdpi.com/2076-3417/11/4/1965/pdf?version=1614084313,https://app.dimensions.ai/details/publication/pub.1135699203,46 Information and Computing Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
1649,pub.1135527976,10.1117/12.2580412,,,Unsupervised super-resolution: creating high-resolution medical images from low-resolution anisotropic examples,"Although high resolution isotropic 3D medical images are desired in clinical practice, their acquisition is not always feasible. Instead, lower resolution images are upsampled to higher resolution using conventional interpolation methods. Sophisticated learning-based super-resolution approaches are frequently unavailable in clinical setting, because such methods require training with high-resolution isotropic examples. To address this issue, we propose a learning-based super-resolution approach that can be trained using solely anisotropic images, i.e. without high-resolution ground truth data. The method exploits the latent space, generated by autoencoders trained on anisotropic images, to increase spatial resolution in low-resolution images. The method was trained and evaluated using 100 publicly available cardiac cine MR scans from the Automated Cardiac Diagnosis Challenge (ACDC). The quantitative results show that the proposed method performs better than conventional interpolation methods. Furthermore, the qualitative results indicate that especially finer cardiac structures are synthesized with high quality. The method has the potential to be applied to other anatomies and modalities and can be easily applied to any 3D anisotropic medical image dataset.",,,Progress in Biomedical Optics and Imaging,Medical Imaging 2021: Image Processing,,2021-02-15,2021,,,11596,,115960e-115960e-7,All OA, Green,Proceeding,"Sander, Jörg; de Vos, Bob D.; Išgum, Ivana","Sander, Jörg (Amsterdam Univ. Medical Ctrs., Univ. of Amsterdam (Netherlands)); de Vos, Bob D. (Amsterdam Univ. Medical Ctrs., Univ. of Amsterdam (Netherlands)); Išgum, Ivana (Amsterdam Univ. Medical Ctrs., Univ. of Amsterdam (Netherlands))",,"Sander, Jörg (University of Amsterdam); de Vos, Bob D. (University of Amsterdam); Išgum, Ivana (University of Amsterdam)",9,9,,7.43,http://arxiv.org/pdf/2010.13172,https://app.dimensions.ai/details/publication/pub.1135527976,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,
1347,pub.1135529065,10.1117/12.2582227,,,Interpretability of a deep learning model in the application of cardiac MRI segmentation with an ACDC challenge dataset,"Cardiac Magnetic Resonance (CMR) is the most effective tool for the assessment and diagnosis of a heart condition, which malfunction is the world's leading cause of death. Software tools leveraging Artficial Intelligence already enhance radiologists and cardiologists in heart condition assessment but their lack of transparency is a problem. This project investigates if it is possible to discover concepts representative for different cardiac conditions from the deep network trained to segment cardiac structures: Left Ventricle (LV), Right Ventricle (RV) and Myocardium (MYO), using explainability methods that enhances classification system by providing the score-based values of qualitative concepts, along with the key performance metrics. With introduction of a need of explanations in GDPR explainability of AI systems is necessary. This study applies Discovering and Testing with Concept Activation Vectors (D-TCAV), an interpretaibilty method to extract underlying features important for cardiac disease diagnosis from MRI data. The method provides a quantitative notion of concept importance for disease classified. In previous studies, the base method is applied to the classification of cardiac disease and provides clinically meaningful explanations for the predictions of a black-box deep learning classifier. This study applies a method extending TCAV with a Discovering phase (D-TCAV) to cardiac MRI analysis. The advantage of the D-TCAV method over the base method is that it is user-independent. The contribution of this study is a novel application of the explainability method D-TCAV for cardiac MRI analysis. D-TCAV provides a shorter pre-processing time for clinicians than the base method.",,,Progress in Biomedical Optics and Imaging,Medical Imaging 2021: Image Processing,,2021-02-15,2021,,,11596,,1159636-1159636-12,All OA, Green,Proceeding,"Janik, Adrianna; Dodd, Jonathan; Ifrim, Georgiana; Sankaran, Kris; Curran, Kathleen","Janik, Adrianna (Univ. College Dublin (Ireland)); Dodd, Jonathan (Univ. College Dublin (Ireland)); Ifrim, Georgiana (Univ. College Dublin (Ireland)); Sankaran, Kris (Univ. of Wisconsin-Madison (United States)); Curran, Kathleen (Univ. College Dublin (Ireland))",,"Janik, Adrianna (University College Dublin); Dodd, Jonathan (University College Dublin); Ifrim, Georgiana (University College Dublin); Sankaran, Kris (University of Wisconsin–Madison); Curran, Kathleen (University College Dublin)",14,14,,12.28,http://arxiv.org/pdf/2103.08590,https://app.dimensions.ai/details/publication/pub.1135529065,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
1213,pub.1135527888,10.1117/12.2577088,,,EMONAS: efficient multiobjective neural architecture search framework for 3D medical image segmentation,"Deep learning plays a critical role in medical image segmentation. Nevertheless, manually designing a neural network for a specific segmentation problem is a very difficult and time-consuming task due to the massive hyperparameter search space, long training time and large volumetric data. Therefore, most designed networks are highly complex, task specific and over-parametrized. Recently, multiobjective neural architecture search (NAS) methods have been proposed to automate the design of accurate and efficient segmentation architectures. However, they only search for either the macro- or micro-structure of the architecture, do not use the information produced during the optimization process to increase the efficiency of the search, and do not consider the volumetric nature of medical images. In this work, we propose EMONAS, an Efficient MultiObjective Neural Architecture Search framework for 3D medical image segmentation. EMONAS is composed of a search space that considers both the macro- and micro-structure of the architecture, and a surrogate-assisted multiobjective evolutionary based algorithm that efficiently searches for the best hyperparameters using a Random Forest surrogate and guiding selection probabilities. EMONAS is evaluated on the task of cardiac segmentation from the ACDC MICCAI challenge. The architecture found is ranked within the top 10 submissions in all evaluation metrics, performing better or comparable to other approaches while reducing the search time by more than 50% and having considerably fewer number of parameters.",,,Progress in Biomedical Optics and Imaging,Medical Imaging 2021: Image Processing,,2021-02-15,2021,,,11596,,1159607-1159607-13,Closed,Proceeding,"Calisto, Maria G. Baldeon; Lai-Yuen, Susana K.","Calisto, Maria G. Baldeon (Univ. of South Florida (United States)); Lai-Yuen, Susana K. (Univ. of South Florida (United States))",,"Calisto, Maria G. Baldeon (University of South Florida); Lai-Yuen, Susana K. (University of South Florida)",2,2,,1.58,,https://app.dimensions.ai/details/publication/pub.1135527888,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,,
6069,pub.1135300118,10.1016/j.tcm.2021.02.002,33581255,,Artificial Intelligence and Transcatheter Interventions for Structural Heart Disease: A glance at the (near) future,"With innovations in therapeutic technologies and changes in population demographics, transcatheter interventions for structural heart disease have become the preferred treatment and will keep growing. Yet, a thorough clinical selection and efficient pathway from diagnosis to treatment and follow-up are mandatory. In this review we reflect on how artificial intelligence may help to improve patient selection, pre-procedural planning, procedure execution and follow-up so to establish efficient and high quality health care in an increasing number of patients.",,Funding: The authors received no funding for this work,Trends in Cardiovascular Medicine,,Artificial Intelligence, Heart Diseases, Humans,2021-02-10,2021,2021-02-10,2022-04,32,3,153-159,All OA, Hybrid,Article,"Ribeiro, Joana Maria; Astudillo, Patricio; de Backer, Ole; Budde, Ricardo; Nuis, Rutger Jan; Goudzwaard, Jeanette; Van Mieghem, Nicolas M; Lumens, Joost; Mortier, Peter; Mattace-Raso, Francesco; Boersma, Eric; Cummins, Paul; Bruining, Nico; de Jaegere, Peter Pt","Ribeiro, Joana Maria (Department of Cardiology, Thoraxcenter, Erasmus Medical Center, Rotterdam, the Netherlands; Department of Cardiology, Centro Hospitalar de Entre o Douro e Vouga, Santa Maria da Feira, Portugal; Department of Cardiology, Centro Hospitalar e Universitário de Coimbra, Coimbra, Portugal.); Astudillo, Patricio (FEops NV, Ghent, Belgium.); de Backer, Ole (Department of Cardiology, Rigshospitalet University Hospital, Copenhagen, Denmark.); Budde, Ricardo (Department of Radiology, Erasmus Medical Center, Rotterdam, the Netherlands.); Nuis, Rutger Jan (Department of Cardiology, Thoraxcenter, Erasmus Medical Center, Rotterdam, the Netherlands.); Goudzwaard, Jeanette (Department of Internal Medicine, Erasmus Medical Center, Rotterdam, the Netherlands.); Van Mieghem, Nicolas M (Department of Cardiology, Thoraxcenter, Erasmus Medical Center, Rotterdam, the Netherlands.); Lumens, Joost (CARIM School for Cardiovascular Diseases, Maastricht University Medical Center, Maastricht, the Netherlands.); Mortier, Peter (FEops NV, Ghent, Belgium.); Mattace-Raso, Francesco (Department of Internal Medicine, Erasmus Medical Center, Rotterdam, the Netherlands.); Boersma, Eric (Department of Cardiology, Thoraxcenter, Erasmus Medical Center, Rotterdam, the Netherlands.); Cummins, Paul (Department of Cardiology, Thoraxcenter, Erasmus Medical Center, Rotterdam, the Netherlands.); Bruining, Nico (Department of Cardiology, Thoraxcenter, Erasmus Medical Center, Rotterdam, the Netherlands.); de Jaegere, Peter Pt (Department of Cardiology, Thoraxcenter, Erasmus Medical Center, Rotterdam, the Netherlands. Electronic address: p.dejaegere@erasmusmc.nl.)","de Jaegere, Peter Pt (Erasmus MC)","Ribeiro, Joana Maria (Erasmus MC; Centro Hospitalar de Entre o Douro e Vouga E.P.E.; Hospitais da Universidade de Coimbra); Astudillo, Patricio (); de Backer, Ole (Rigshospitalet); Budde, Ricardo (Erasmus MC); Nuis, Rutger Jan (Erasmus MC); Goudzwaard, Jeanette (Erasmus MC); Van Mieghem, Nicolas M (Erasmus MC); Lumens, Joost (Maastricht University Medical Centre; Maastricht University); Mortier, Peter (); Mattace-Raso, Francesco (Erasmus MC); Boersma, Eric (Erasmus MC); Cummins, Paul (Erasmus MC); Bruining, Nico (Erasmus MC); de Jaegere, Peter Pt (Erasmus MC)",10,10,3.5,11.28,https://doi.org/10.1016/j.tcm.2021.02.002,https://app.dimensions.ai/details/publication/pub.1135300118,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,3 Good Health and Well Being,,,,,,,
5043,pub.1135202879,10.1016/j.mri.2021.01.005,33571634,PMC8103654,A deep-learning semantic segmentation approach to fully automated MRI-based left-ventricular deformation analysis in cardiotoxicity,"Left-ventricular (LV) strain measurements with the Displacement Encoding with Stimulated Echoes (DENSE) MRI sequence provide accurate estimates of cardiotoxicity damage related to breast cancer chemotherapy. This study investigated an automated LV chamber quantification tool via segmentation with a supervised deep convolutional neural network (DCNN) before strain analysis with DENSE images. Segmentation for chamber quantification analysis was conducted with a custom DeepLabV3+ DCNN with ResNet-50 backbone on 42 female breast cancer datasets (22 training-sets, eight validation-sets and 12 independent test-sets). Parameters such as LV end-diastolic diameter (LVEDD) and ejection fraction (LVEF) were quantified, and myocardial strains analyzed with the Radial Point Interpolation Method (RPIM). Myocardial classification was validated against ground-truth with sensitivity-specificity analysis, the metrics of Dice, average perpendicular distance (APD) and Hausdorff-distance. Following segmentation, validation was conducted with the Cronbach's Alpha (C-Alpha) intraclass correlation coefficient between LV chamber quantification results with DENSE and Steady State Free Precession (SSFP) acquisitions and a vendor tool-based method to segment the DENSE data, and similarly for myocardial strain analysis in the chambers. The results of myocardial classification from segmentation of the DENSE data were accuracy = 97%, Dice = 0.89 and APD = 2.4 mm in the test-set. The C-Alpha correlations from comparing chamber quantification results between the segmented DENSE and SSFP data and vendor tool-based method were 0.97 for LVEF (56 ± 7% vs 55 ± 7% vs 55 ± 6%, p = 0.6) and 0.77 for LVEDD (4.6 ± 0.4 cm vs 4.5 ± 0.3 cm vs 4.5 ± 0.3 cm, p = 0.8). The validation metrics against ground-truth and equivalent parameters obtained from the SSFP segmentation and vendor tool-based comparisons show that the DCNN approach is applicable for automated LV chamber quantification and subsequent strain analysis in cardiotoxicity.","We are very appreciative of staff at the Imaging Center, Children&#x27;s and Women&#x27;s Hospital, University of South Alabama toward helping us acquire the MRI data. We greatly appreciate Dr. Suzy Figarola&#x27;s help with setting up cardiac MRI acquisitions in breast cancer patients.",,Magnetic Resonance Imaging,,"Automation; Breast Neoplasms; Cardiotoxicity; Deep Learning; Female; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Semantics; Sensitivity and Specificity",2021-02-08,2021,2021-02-08,2021-05,78,,127-139,All OA, Green,Article,"Kar, By Julia; Cohen, Michael V; McQuiston, Samuel P; Malozzi, Christopher M","Kar, By Julia (Departments of Mechanical Engineering and Pharmacology, University of South Alabama, 150 Jaguar Drive, Mobile, AL 36688, United States of America. Electronic address: jkar@southalabama.edu.); Cohen, Michael V (Department of Cardiology, College of Medicine, University of South Alabama, 1700 Center Street, Mobile, AL 36604, United States of America.); McQuiston, Samuel P (Department of Radiology, University of South Alabama, 2451 USA Medical Center Drive, Mobile, AL 36617, United States of America.); Malozzi, Christopher M (Department of Cardiology, College of Medicine, University of South Alabama, 1700 Center Street, Mobile, AL 36604, United States of America.)","Kar, By Julia (University of South Alabama)","Kar, By Julia (University of South Alabama); Cohen, Michael V (University of South Alabama); McQuiston, Samuel P (University of South Alabama); Malozzi, Christopher M (University of South Alabama)",9,9,2.11,5.45,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8103654,https://app.dimensions.ai/details/publication/pub.1135202879,32 Biomedical and Clinical Sciences, 3211 Oncology and Carcinogenesis,,,,,,,,,,
1454,pub.1135111352,10.48550/arxiv.2102.01549,,,Medical Datasets Collections for Artificial Intelligence-based Medical  Image Analysis,"We collected 32 public datasets, of which 28 for medical imaging and 4 for
natural images, to conduct study. The images of these datasets are captured by
different cameras, thus vary from each other in modality, frame size and
capacity. For data accessibility, we also provide the websites of most datasets
and hope this will help the readers reach the datasets.",,,arXiv,,,2021-02-02,2021,,,,,,All OA, Green,Preprint,"Wen, Yang","Wen, Yang ()",,"Wen, Yang ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1135111352,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1210,pub.1131873811,10.1016/j.bspc.2020.102246,,,A deep learning approach to segmentation of nasopharyngeal carcinoma using computed tomography,"Automated segmentation of Nasopharyngeal carcinoma (NPC) plays a critical role in the radiotherapy or chemo-radiotherapy for this cancer. Despite their improved performance, most deep learning models designed for this segmentation task use either magnetic resonance imaging (MRI) or multimodality data as input. In this paper, we propose a deep learning based algorithm called NPC-Seg for the segmentation of NPC using computed tomography (CT), which is less expensive and more available than MRI. This algorithm uses the location-to-segmentation framework. In the location step, it fine-tunes the pre-trained ResNeXt-50 U-Net with a newly proposed recall preserved loss to roughly segment the gross tumor volume (GTV) of each NPC. In the segmentation step, it fine-tunes the ResNeXt-50 U-Net again, but using the Dice loss, to segment the bounding box region detected in the location step on a patch-by-patch basis. We have evaluated the proposed NPC-Seg algorithm on the StructSeg-NPC dataset. Our algorithm achieves the Dice similarity coefficient (DSC) of 62.88 ± 8.12 % on 50 training data in the ten-fold cross-validation, substantially outperforming three existing deep learning methods, and also achieves an average DSC of 61.81% on the testing dataset in the online validation.","This work was supported in part by the Science and Technology Innovation Committee of Shenzhen Municipality, China, under Grants JCYJ20180306171334997, in part by the National Natural Science Foundation of China under Grants 61771397, and in part by the Project for Graduate Innovation team of Northwestern Polytechnical University. The authors would like to appreciate the efforts devoted to collect and share the StructSeg 2019 NPC dataset for comparing the approaches to the segmentation of NPC on head and neck CT scans.",,Biomedical Signal Processing and Control,,,2021-02,2021,,2021-02,64,,102246,Closed,Article,"Bai, Xiaoyu; Hu, Yan; Gong, Guanzhong; Yin, Yong; Xia, Yong","Bai, Xiaoyu (Research and Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen 518057, China; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an 710072, China); Hu, Yan (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an 710072, China); Gong, Guanzhong (Shandong Cancer Hospital Affiliated to Shandong University, Jinan 250117, PR China); Yin, Yong (Shandong Cancer Hospital Affiliated to Shandong University, Jinan 250117, PR China); Xia, Yong (Research and Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen 518057, China; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an 710072, China)","Xia, Yong (Northwestern Polytechnical University; Northwestern Polytechnical University)","Bai, Xiaoyu (Northwestern Polytechnical University; Northwestern Polytechnical University); Hu, Yan (Northwestern Polytechnical University); Gong, Guanzhong (Shandong Tumor Hospital); Yin, Yong (Shandong Tumor Hospital); Xia, Yong (Northwestern Polytechnical University; Northwestern Polytechnical University)",6,6,,2.66,,https://app.dimensions.ai/details/publication/pub.1131873811,"30 Agricultural, Veterinary and Food Sciences; 3006 Food Sciences; 40 Engineering; 4003 Biomedical Engineering",,,,,,,,,,,,
5334,pub.1134958597,10.1152/ajpheart.00764.2020,33513086,,Artificial intelligence for a personalized diagnosis and treatment of atrial fibrillation,"Although atrial fibrillation (AF) is the most common cardiac arrhythmia, its early identification, diagnosis, and treatment is still challenging. Due to its heterogeneous mechanisms and risk factors, targeting an individualized treatment of AF demands a large amount of patient data to identify specific patterns. Artificial intelligence (AI) algorithms are particularly well suited for treating high-dimensional data, predicting outcomes, and eventually, optimizing strategies for patient management. The analysis of large patient samples combining different sources of information such as blood biomarkers, electrical signals, and medical images opens a new paradigm for improving diagnostic algorithms. In this review, we summarize suitable AI techniques for this purpose. In particular, we describe potential applications for understanding the structural and functional bases of the disease, as well as for improving early noninvasive diagnosis, developing more efficient therapies, and predicting long-term clinical outcomes of patients with AF.",,,AJP Heart and Circulatory Physiology,,"Action Potentials; Artificial Intelligence; Atrial Fibrillation; Clinical Decision-Making; Diagnosis, Computer-Assisted; Heart Conduction System; Heart Function Tests; Heart Rate; Humans; Machine Learning; Neural Networks, Computer; Pattern Recognition, Automated; Predictive Value of Tests; Therapy, Computer-Assisted",2021-01-29,2021,2021-01-29,2021-04-01,320,4,h1337-h1347,Closed,Article,"Sánchez de la Nava, Ana María; Atienza, Felipe; Bermejo, Javier; Fernández-Avilés, Francisco","Sánchez de la Nava, Ana María (Department of Cardiology, Instituto de Investigación Sanitaria Gregorio Marañón (IiSGM), Hospital General Universitario Gregorio Marañón, Madrid, Spain.; CIBERCV, Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares, Instituto de Salud Carlos III, Madrid, Spain.; Universitat Politècnica de València, València, Spain.); Atienza, Felipe (Department of Cardiology, Instituto de Investigación Sanitaria Gregorio Marañón (IiSGM), Hospital General Universitario Gregorio Marañón, Madrid, Spain.; CIBERCV, Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares, Instituto de Salud Carlos III, Madrid, Spain.; Facultad de Medicina, Universidad Complutense de Madrid, Madrid, Spain.); Bermejo, Javier (Department of Cardiology, Instituto de Investigación Sanitaria Gregorio Marañón (IiSGM), Hospital General Universitario Gregorio Marañón, Madrid, Spain.; CIBERCV, Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares, Instituto de Salud Carlos III, Madrid, Spain.; Facultad de Medicina, Universidad Complutense de Madrid, Madrid, Spain.); Fernández-Avilés, Francisco (Department of Cardiology, Instituto de Investigación Sanitaria Gregorio Marañón (IiSGM), Hospital General Universitario Gregorio Marañón, Madrid, Spain.; CIBERCV, Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares, Instituto de Salud Carlos III, Madrid, Spain.; Facultad de Medicina, Universidad Complutense de Madrid, Madrid, Spain.)","Atienza, Felipe (Hospital General Universitario Gregorio Marañón; Centro de Investigación en Red en Enfermedades Cardiovasculares; Complutense University of Madrid)","Sánchez de la Nava, Ana María (Hospital General Universitario Gregorio Marañón; Centro de Investigación en Red en Enfermedades Cardiovasculares; Universitat Politècnica de València); Atienza, Felipe (Hospital General Universitario Gregorio Marañón; Centro de Investigación en Red en Enfermedades Cardiovasculares; Complutense University of Madrid); Bermejo, Javier (Hospital General Universitario Gregorio Marañón; Centro de Investigación en Red en Enfermedades Cardiovasculares; Complutense University of Madrid); Fernández-Avilés, Francisco (Hospital General Universitario Gregorio Marañón; Centro de Investigación en Red en Enfermedades Cardiovasculares; Complutense University of Madrid)",8,8,1.71,6.94,,https://app.dimensions.ai/details/publication/pub.1134958597,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3208 Medical Physiology,3 Good Health and Well Being,,,,,,,,,
1615,pub.1134947314,10.1007/978-3-030-68107-4_32,,,Comparison of a Hybrid Mixture Model and a CNN for the Segmentation of Myocardial Pathologies in Delayed Enhancement MRI,"DE-MRI provides a reliable and accurate imaging technique for the assessment of pathological alterations in myocardial tissue. The clinically applied thresholding techniques enable the assessment of the amount of diseased tissue. To also assess distribution patterns, transmurality and micro-vascular obstruction, more accurate segmentation methods are needed. We compare a hybrid CNN and mixture model approach with a two single-stage U-Net segmentation: one based on the EMIDEC challenge data set, one with additional training data, and could achieve DICE coefficients of 84.8%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$84.8 \% $$\end{document}, 84.08%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$84.08 \%$$\end{document}, and 82.95%\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$82.95 \%$$\end{document}, respectively. We hope to further improve the promising results through an extension of the training set.",,,Lecture Notes in Computer Science,Statistical Atlases and Computational Models of the Heart. M&Ms and EMIDEC Challenges,,2021-01-29,2021,2021-01-29,2021,12592,,319-327,Closed,Chapter,"Huellebrand, Markus; Ivantsits, Matthias; Zhang, Hannu; Kohlmann, Peter; Kuhnigk, Jan-Martin; Kuehne, Titus; Schönberg, Stefan; Hennemuth, Anja","Huellebrand, Markus (Charité – Universitätsmedizin Berlin, Augustenburger Pl. 1, 13353, Berlin, Germany; Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany); Ivantsits, Matthias (Charité – Universitätsmedizin Berlin, Augustenburger Pl. 1, 13353, Berlin, Germany); Zhang, Hannu (Charité – Universitätsmedizin Berlin, Augustenburger Pl. 1, 13353, Berlin, Germany); Kohlmann, Peter (Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany); Kuhnigk, Jan-Martin (Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany); Kuehne, Titus (Charité – Universitätsmedizin Berlin, Augustenburger Pl. 1, 13353, Berlin, Germany; Department of Radiology and Nuclear Medicine, University Medical Center Mannheim, 68167, Mannheim, Germany; German Heart Institute Berlin, Augustenburger Pl. 1, 13353, Berlin, Germany); Schönberg, Stefan (DZHK (German Centre for Cardiovascular Research), Berlin, Germany); Hennemuth, Anja (Charité – Universitätsmedizin Berlin, Augustenburger Pl. 1, 13353, Berlin, Germany; Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany; German Heart Institute Berlin, Augustenburger Pl. 1, 13353, Berlin, Germany)","Huellebrand, Markus (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine)","Huellebrand, Markus (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine); Ivantsits, Matthias (Charité - University Medicine Berlin); Zhang, Hannu (Charité - University Medicine Berlin); Kohlmann, Peter (Fraunhofer Institute for Digital Medicine); Kuhnigk, Jan-Martin (Fraunhofer Institute for Digital Medicine); Kuehne, Titus (Charité - University Medicine Berlin; University Medical Centre Mannheim; Deutsches Herzzentrum Berlin); Schönberg, Stefan (German Centre for Cardiovascular Research); Hennemuth, Anja (Charité - University Medicine Berlin; Fraunhofer Institute for Digital Medicine; Deutsches Herzzentrum Berlin)",5,5,,,,https://app.dimensions.ai/details/publication/pub.1134947314,46 Information and Computing Sciences,,,,,,,,,,,,
1451,pub.1134931207,10.48550/arxiv.2101.10799,,,ImageCHD: A 3D Computed Tomography Image Dataset for Classification of  Congenital Heart Disease,"Congenital heart disease (CHD) is the most common type of birth defect, which
occurs 1 in every 110 births in the United States. CHD usually comes with
severe variations in heart structure and great artery connections that can be
classified into many types. Thus highly specialized domain knowledge and the
time-consuming human process is needed to analyze the associated medical
images. On the other hand, due to the complexity of CHD and the lack of
dataset, little has been explored on the automatic diagnosis (classification)
of CHDs. In this paper, we present ImageCHD, the first medical image dataset
for CHD classification. ImageCHD contains 110 3D Computed Tomography (CT)
images covering most types of CHD, which is of decent size Classification of
CHDs requires the identification of large structural changes without any local
tissue changes, with limited data. It is an example of a larger class of
problems that are quite difficult for current machine-learning-based vision
methods to solve. To demonstrate this, we further present a baseline framework
for the automatic classification of CHD, based on a state-of-the-art CHD
segmentation method. Experimental results show that the baseline framework can
only achieve a classification accuracy of 82.0\% under a selective prediction
scheme with 88.4\% coverage, leaving big room for further improvement. We hope
that ImageCHD can stimulate further research and lead to innovative and generic
solutions that would have an impact in multiple domains. Our dataset is
released to the public compared with existing medical imaging datasets.",,,arXiv,,,2021-01-26,2021,,,,,,All OA, Green,Preprint,"Xu, Xiaowei; Wang, Tianchen; Zhuang, Jian; Yuan, Haiyun; Huang, Meiping; Cen, Jianzheng; Jia, Qianjun; Dong, Yuhao; Shi, Yiyu","Xu, Xiaowei (); Wang, Tianchen (); Zhuang, Jian (); Yuan, Haiyun (); Huang, Meiping (); Cen, Jianzheng (); Jia, Qianjun (); Dong, Yuhao (); Shi, Yiyu ()",,"Xu, Xiaowei (); Wang, Tianchen (); Zhuang, Jian (); Yuan, Haiyun (); Huang, Meiping (); Cen, Jianzheng (); Jia, Qianjun (); Dong, Yuhao (); Shi, Yiyu ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1134931207,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 46 Information and Computing Sciences,,,,,,,,,
1868,pub.1142699323,10.1109/icce-tw52618.2021.9602950,,,An Automated Cardiac Ventricle Segmentation on CMR Images Using Grey-Level Mask R-CNN,"Myocardial fibrosis is a pathological change in the progress of modern heart disease. It is mainly characterized by dysregulation or marked increase of collagen volume in myocardial components. The physiological mechanism of fibrosis in different pathologies is very diverse. It has been proved that the use of MRI for the detection of heart failure patients can provide accurate measurements of left ventricle and right ventricle and assessment of myocardial function, but the accurate segmentation of myocardial contour is still an important prerequisite for the detection of fibrosis. This study uses Mask R-CNN on the ACDC challenge Database to repeatedly adjust the characteristics of the boundary of the Bounding box, and separately divided the left ventricular area and the right ventricular area. The proposed method can achieve up to 95% hit rate with 0.89 IoU.",This work was supported by MOST Foundation with Grant No. MOST 109-2221-E-030-001-MY3 and MOST 109-2628-B-010-018. This work was supported by MOST Foundation with Grant No. MOST 109-2221-E-030-001-MY3 and MOST 109-2628-B-010-018.,,,2021 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW),,2021-01-17,2021,,2021-01-17,0,,1-2,Closed,Proceeding,"Li, Hsiao-Chi; Chen, Kuan-Yu; Sung, Shih-Hsien; Chen, Chun-Ku","Li, Hsiao-Chi (Department of Computer Science and Information Engineering, Fu Jen Catholic University, Taiwan); Chen, Kuan-Yu (Department of Computer Science and Information Engineering, Fu Jen Catholic University, Taiwan); Sung, Shih-Hsien (Taipei Veterans General Hospital, Taiwan); Chen, Chun-Ku (Taipei Veterans General Hospital, Taiwan)","Li, Hsiao-Chi (Fu Jen Catholic University)","Li, Hsiao-Chi (Fu Jen Catholic University); Chen, Kuan-Yu (Fu Jen Catholic University); Sung, Shih-Hsien (Taipei Veterans General Hospital); Chen, Chun-Ku (Taipei Veterans General Hospital)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142699323,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3208 Medical Physiology,,,,,,,,,,
1396,pub.1137774421,10.1109/icpr48806.2021.9412755,,,Do not Treat Boundaries and Regions Differently: An Example on Heart Left Atrial Segmentation,"Atrial fibrillation is the most common heart rhythm disease. Due to a lack of understanding in matter of underlying atrial structures, current treatments are still not satisfying. Recently, with the popularity of deep learning, many segmentation methods based on fully convolutional networks have been proposed to analyze atrial structures, especially from late gadolinium-enhanced magnetic resonance imaging. However, two problems still occur: 1) segmentation results include the atrial-like background; 2) boundaries are very hard to segment. Most segmentation approaches design a specific network that mainly focuses on the regions, to the detriment of the boundaries. Therefore, this paper proposes an attention full convolutional network framework based on the ResNet-101 architecture, which focuses on boundaries as much as on regions. The additional attention module is added to have the network pay more attention on regions and then to reduce the impact of the misleading similarity of neighboring tissues. We also use a hybrid loss composed of a region loss and a boundary loss to treat boundaries and regions at the same time. We demonstrate the efficiency of the proposed approach on the MICCAI 2018 Atrial Segmentation Challenge public dataset.",,,,2020 25th International Conference on Pattern Recognition (ICPR),,2021-01-15,2021,,2021-01-15,0,,7447-7453,Closed,Proceeding,"Zhao, Zhou; Puybareau, Élodie; Boutry, Nicolas; Géraud, Thierry","Zhao, Zhou (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France); Puybareau, Élodie (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France); Boutry, Nicolas (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France); Géraud, Thierry (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France)",,"Zhao, Zhou (Graduate School of Computer Science and Advanced Technologies); Puybareau, Élodie (Graduate School of Computer Science and Advanced Technologies); Boutry, Nicolas (Graduate School of Computer Science and Advanced Technologies); Géraud, Thierry (Graduate School of Computer Science and Advanced Technologies)",4,4,,3.06,,https://app.dimensions.ai/details/publication/pub.1137774421,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1343,pub.1137773682,10.1109/icpr48806.2021.9412016,,,FOANet: A Focus of Attention Network with Application to Myocardium Segmentation,"In myocardium segmentation of cardiac magnetic resonance images, ambiguities often appear near the boundaries of the target domains due to tissue similarities. To address this issue, we propose a new architecture, called FOANet, which can be decomposed in three main steps: a localization step, a Gaussian-based contrast enhancement step, and a segmentation step. This architecture is supplied with a hybrid loss function that guides the FOANet to study the transformation relationship between the input image and the corresponding label in a three-level hierarchy (pixel-, patch- and map-level), which is helpful to improve segmentation and recovery of the boundaries. We demonstrate the efficiency of our approach on two public datasets in terms of regional and boundary segmentations.",,,,2020 25th International Conference on Pattern Recognition (ICPR),,2021-01-15,2021,,2021-01-15,0,,1120-1127,Closed,Proceeding,"Zhao, Zhou; Puybareau, Élodie; Boutry, Nicolas; Géraud, Thierry","Zhao, Zhou (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France); Puybareau, Élodie (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France); Boutry, Nicolas (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France); Géraud, Thierry (EPITA Research and Development Laboratory (LRDE), Le Kremlin-Bicêtre, France)",,"Zhao, Zhou (Graduate School of Computer Science and Advanced Technologies); Puybareau, Élodie (Graduate School of Computer Science and Advanced Technologies); Boutry, Nicolas (Graduate School of Computer Science and Advanced Technologies); Géraud, Thierry (Graduate School of Computer Science and Advanced Technologies)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1137773682,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,,
5684,pub.1126682708,10.1109/jbhi.2020.2986926,32305947,,Multi-Scale Self-Guided Attention for Medical Image Segmentation,"Even though convolutional neural networks (CNNs) are driving progress in medical image segmentation, standard models still have some drawbacks. First, the use of multi-scale approaches, i.e., encoder-decoder architectures, leads to a redundant use of information, where similar low-level features are extracted multiple times at multiple scales. Second, long-range feature dependencies are not efficiently modeled, resulting in non-optimal discriminative feature representations associated with each semantic class. In this paper we attempt to overcome these limitations with the proposed architecture, by capturing richer contextual dependencies based on the use of guided self-attention mechanisms. This approach is able to integrate local features with their corresponding global dependencies, as well as highlight interdependent channel maps in an adaptive manner. Further, the additional loss between different modules guides the attention mechanisms to neglect irrelevant information and focus on more discriminant regions of the image by emphasizing relevant feature associations. We evaluate the proposed model in the context of semantic segmentation on three different datasets: abdominal organs, cardiovascular structures and brain tumors. A series of ablation experiments support the importance of these attention modules in the proposed architecture. In addition, compared to other state-of-the-art segmentation networks our model yields better segmentation performance, increasing the accuracy of the predictions while reducing the standard deviation. This demonstrates the efficiency of our approach to generate precise and reliable automatic segmentations of medical images. Our code is made publicly available at: https://github.com/sinAshish/Multi-Scale-Attention.",This work was supported by the Startup Professor Funding from ETS Montreal. The authors wish to thank NVIDIA for its kind donation of the Titan V GPU used in this work.,,IEEE Journal of Biomedical and Health Informatics,,"Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Semantics",2021-01-05,2021,2021-01-05,2021-01,25,1,121-130,All OA, Green,Article,"Sinha, Ashish; Dolz, Jose","Sinha, Ashish (Indian Institute of Technology Roorkee, Roorkee, 247667, India); Dolz, Jose (Superieure, Montreal, QC, H3C 1K3, Canada)","Dolz, Jose ","Sinha, Ashish (Indian Institute of Technology Roorkee); Dolz, Jose ()",199,190,17.09,162.87,http://arxiv.org/pdf/1906.02849,https://app.dimensions.ai/details/publication/pub.1126682708,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1396,pub.1134394470,10.1088/1742-6596/1714/1/012021,,,Hybrid Learning Model for Metal Artifact Reduction,"In today’s healthcare, the human brain imaging is done for finding the tumors and other disorders of the brain. The Magnetic Resonance Imaging (MRI) plays a significant role throughout the complete clinical procedure starting from diagnostics and treatment planning to surgical processes and follow up studies. The MRI of brain allows the clinical expert for the earliest detection and treatment of brain abnormality or any neurological diseases, which is the most treatable stage that gives patients the greatest chance of survival. An artifact is a feature appearing in an image which is not present in the original imaged object. The types of artifacts are herringbone artifact, zipper artifact, motion artifact, aliasing artifact, chemical shift artifact, magnetic susceptibility artifact, central point artifact, Gibbs ringing artifact and intensity inhomogeneity artifact. After segmentation, the features are extracted using Gray level co-occurrence matrix (GLCM) and an CNN, Deep belief network, Proposed hybrid model (Based on CNN and Deep belief network (DBN)) and Morphological Technique with Segmentation Techniques is implemented to classify the brain MRI images as either normal (without tumor) or abnormal (with tumor). Proposed hybrid model for metal artifact reduction and represent though the experiment our proposed model very effective to existing one. Results in Accuracy (in %) Before artifact removal(92.12%), After artifact removal (95.77%)",,,Journal of Physics Conference Series,,,2021-01-01,2021,,2021-01-01,1714,1,12021,All OA, Gold,Article,"Bedi, Pradeep; Goyal, S B; Yadav, Dileep Kumar; Kumar, Sunil; Sharma, Monika","Bedi, Pradeep (Department of Computer Science and Engineering, Graphic Era Hill University, Dehradun, India); Goyal, S B (Faculty of Information Technology, City University, Malaysia); Yadav, Dileep Kumar (Department of Computer Science and Engineering, Galgotias University, Greater Noida, India); Kumar, Sunil (Department of Mathematics, Graphic Era Hill University, Dehradun, India); Sharma, Monika (Department of Computer Science and Engineering, Galgotias University, Greater Noida, India)",,"Bedi, Pradeep (Graphic Era University); Goyal, S B (City University College of Science and Technology); Yadav, Dileep Kumar (Galgotias University); Kumar, Sunil (Graphic Era University); Sharma, Monika (Galgotias University)",0,0,,,https://doi.org/10.1088/1742-6596/1714/1/012021,https://app.dimensions.ai/details/publication/pub.1134394470,51 Physical Sciences,,,,,,,,,,,
1141,pub.1129477588,10.1016/j.recesp.2020.06.017,,,Big data y nuevas tecnologías de la información: qué necesita saber el cardiólogo,"La continua progresión tecnológica que experimenta la medicina se produce cada vez a mayor velocidad, lo que exige una actualización constante del profesional de la salud. La nueva ola de tecnologías que está abriéndose camino en la práctica clínica incluye: a) salud asistida por el móvil (mHealth) o dispositivos miniaturizados que permiten la detección constante de parámetros biológicos, a cualquier hora y en cualquier lugar, de cientos de miles de pacientes a la vez; b) inteligencia artificial impulsada por nuevas técnicas de aprendizaje profundo que están batiendo a médicos expertos en su propio campo (pruebas de imagen o electrocardiografía); c) impresión tridimensional que permite vislumbrar un mundo de prótesis cardiovasculares adaptadas a cada paciente; d) medicina de sistemas, que apoyándose en el big data abrirá las puertas a la medicina personalizada, aunando en modelos matemáticos de gran complejidad datos genéticos, epigenéticos, ambientales, clínicos y sociales para diseñar tratamientos de precisión. Esta revisión pretende resumir la evidencia sobre los últimos avances tecnológicos basados en tecnologías de la información y ciencias de la computación aplicados a la cardiología y esbozar un mapa que de un solo vistazo permita tener una impresión general del horizonte hacia el que va a progresar la cardiología en los próximos años. Technological progress in medicine is constantly garnering pace, requiring that physicians constantly update their knowledge. The new wave of technologies breaking through into clinical practice includes the following: a) mHealth, which allows constant monitoring of biological parameters, anytime, anyplace, of hundreds of patients at the same time; b) artificial intelligence, which, powered by new deep learning techniques, are starting to beat human experts at their own game: diagnosis by imaging or electrocardiography; c) 3-dimensional printing, which may lead to patient-specific prostheses; d) systems medicine, which has arisen from big data, and which will open the way to personalized medicine by bringing together genetic, epigenetic, environmental, clinical and social data into complex integral mathematical models to design highly personalized therapies. This state-of-the-art review aims to summarize in a single document the most recent and most important technological trends that are being applied to cardiology, and to provide an overall view that will allow readers to discern at a glance the direction of cardiology in the next few years.","Al Dr. Alfredo Redondo, cardiólogo del Hospital Clínico de Valladolid y responsable del VAL 3D Lab por proveer parte de las imágenes que ilustran este artículo.",,Revista Española de Cardiología,,,2021-01,2021,,2021-01,74,1,81-89,Closed,Article,"Baladrón, Carlos; de Diego, José Juan Gómez; Amat-Santos, Ignacio J.","Baladrón, Carlos (Instituto de Ciencias del Corazón (ICICOR), Hospital Clínico Universitario, Valladolid, España; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), España); de Diego, José Juan Gómez (Servicio de Cardiología, Hospital Clínico Universitario San Carlos, Madrid, España); Amat-Santos, Ignacio J. (Instituto de Ciencias del Corazón (ICICOR), Hospital Clínico Universitario, Valladolid, España; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), España)","Amat-Santos, Ignacio J. (Hospital Clínico Universitario de Valladolid; Centro de Investigación Biomédica en Red)","Baladrón, Carlos (Hospital Clínico Universitario de Valladolid; Centro de Investigación Biomédica en Red); de Diego, José Juan Gómez (Hospital Clínico San Carlos); Amat-Santos, Ignacio J. (Hospital Clínico Universitario de Valladolid; Centro de Investigación Biomédica en Red)",6,6,,6.77,,https://app.dimensions.ai/details/publication/pub.1129477588,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,,
98,pub.1134463858,10.1016/s1936-878x(20)31073-1,,,Full Issue PDF,,,,JACC Cardiovascular Imaging,,,2021-01,2021,,2021-01,14,1,i-cccxxiii,All OA, Bronze,Article,,,,,0,0,,0.0,https://doi.org/10.1016/s1936-878x(20)31073-1,https://app.dimensions.ai/details/publication/pub.1134463858,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
1400,pub.1135316342,10.1016/b978-0-12-820273-9.00010-5,,,Chapter 10 Magnetic resonance imaging and artificial intelligence,"Cardiac magnetic resonance (CMR) is the best-suited cardiac imaging modality to provide reliable and reproducible information regarding cardiac volumes, function, and tissue characterization. In clinical practice, artificial intelligence (AI) in CMR can be applied to the whole process, ranging from sequence reconstruction, image analysis, and reporting of findings. In sequence reconstruction, the application of AI is mainly focused on the speed of reconstruction, while in image analysis and reporting AI is primarily aimed at automating the process of segmentation of both ventricles as well as fibrotic tissue. Within the realm of tissue characterization, AI can also be helpful in the depiction of tissue abnormalities from noncontrast images. Finally, AI can be useful for prognostic stratification.",,,,Machine Learning in Cardiovascular Medicine,,2021,2021,,2021,,,241-253,Closed,Chapter,"Muscogiuri, Giuseppe; Guglielmo, Marco; Baggiano, Andrea; Fusini, Laura; Ricci, Francesca; Cicala, Gloria; Rabbat, Mark G.; Guaricci, Andrea I.; Pontone, Gianluca","Muscogiuri, Giuseppe (Centro Cardiologico Monzino, IRCCS, Milan, Italy); Guglielmo, Marco (Centro Cardiologico Monzino, IRCCS, Milan, Italy); Baggiano, Andrea (Centro Cardiologico Monzino, IRCCS, Milan, Italy); Fusini, Laura (Centro Cardiologico Monzino, IRCCS, Milan, Italy); Ricci, Francesca (Department of Biomedicine and Prevention Division of Diagnostic Imaging, University of Rome “Tor Vergata,” Rome, Italy); Cicala, Gloria (Department of Medicine and Surgery, Azienda Ospedaliero-Universitaria di Parma, Università degli Studi, Parma, Italy); Rabbat, Mark G. (Loyola University of Chicago, Chicago, IL, United States; Edward Hines Jr. VA Hospital, Hines, IL, United States); Guaricci, Andrea I. (Institute of Cardiovascular Disease, Department of Emergency and Organ Transplantation, University Hospital Policlinico of Bari, Bari, Italy); Pontone, Gianluca (Centro Cardiologico Monzino, IRCCS, Milan, Italy)",,"Muscogiuri, Giuseppe (Centro Cardiologico Monzino); Guglielmo, Marco (Centro Cardiologico Monzino); Baggiano, Andrea (Centro Cardiologico Monzino); Fusini, Laura (Centro Cardiologico Monzino); Ricci, Francesca (University of Rome Tor Vergata); Cicala, Gloria (University of Parma; Ospedale di Parma); Rabbat, Mark G. (Loyola University Chicago; Edward Hines, Jr. VA Hospital); Guaricci, Andrea I. (Azienda Universitaria Ospedaliera Consorziale - Policlinico Bari); Pontone, Gianluca (Centro Cardiologico Monzino)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1135316342,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,,
1299,pub.1138465579,10.9781/ijimai.2021.05.005,,,Application of Artificial Intelligence Algorithms Within the Medical Context for Non-Specialized Users: the CARTIER-IA Platform,,,,International Journal of Interactive Multimedia and Artificial Intelligence,,,2021,2021,2021,,6,6,46,All OA, Gold,Article,"García-Peñalvo, Francisco; Vázquez-Ingelmo, Andrea; García-Holgado, Alicia; Sampedro-Gómez, Jesús; Sánchez-Puente, Antonio; Vicente-Palacios, Víctor; Dorado-Díaz, P Ignacio; Sánchez, Pedro L","García-Peñalvo, Francisco (); Vázquez-Ingelmo, Andrea (); García-Holgado, Alicia (); Sampedro-Gómez, Jesús (); Sánchez-Puente, Antonio (); Vicente-Palacios, Víctor (); Dorado-Díaz, P Ignacio (); Sánchez, Pedro L ()",,"García-Peñalvo, Francisco (); Vázquez-Ingelmo, Andrea (); García-Holgado, Alicia (); Sampedro-Gómez, Jesús (); Sánchez-Puente, Antonio (); Vicente-Palacios, Víctor (); Dorado-Díaz, P Ignacio (); Sánchez, Pedro L ()",14,14,,11.6,https://doi.org/10.9781/ijimai.2021.05.005,https://app.dimensions.ai/details/publication/pub.1138465579,46 Information and Computing Sciences, 4602 Artificial Intelligence,,,,,,,,,,
1295,pub.1138788461,10.2139/ssrn.3855445,,,Hypertrophic Cardiomyopathy Diagnosis Based on Cardiovascular Magnetic Resonance Using Deep Learning Techniques,"Background: Hypertrophic cardiomyopathy (HCM) can lead to serious cardiac problems. HCM is often diagnosed by an expert using cardiovascular magnetic resonance (CMR) images obtained from patients. In this research, we aimed to develop a deep learning technique to automate HCM diagnosis.Methods: CMR images of 37421 healthy and 21846 HCM patients (53% females, mean age 48.2±19.5 years) were obtained for two years. Three experts inspected the images to determine the presence of HCM. New data augmentation method was used to generate new images by employing colour filtering on the existing ones. To classify the augmented images, we used a deep convolutional neural network (CNN). To the best of our knowledge, this is the first time CNN is used for HCM diagnosis. We designed our CNN from scratch to reach acceptable diagnosis accuracy.Findings: The designed algorithms achieved an accuracy of 95.23%, recall of 97.90%, and specificity of 93.06% on the original dataset compared with expert opinions. The same performance metrics for the designed algorithm on the augmented dataset were 98 . 53%, 98.70%, and 95.21%, respectively. We experimented with different optimizers (e.g. Adadelta and Adagrad) and other data augmentation methods (e.g. height shift and rotation) to further evaluate the proposed method. Using our data augmentation method, 98.53% accuracy was achieved, which is higher than the best accuracy (95.83%) obtained by the other previous data augmentation methods. Interpretation: Our machine learning method could achieve high performance for HCM diagnosis. The advantages of employing the proposed method are eliminating contrast agent and their complications, decreased CMR examination time, lower costs for patients and cardiac imaging centres.Funding Information: None.Declaration of Interests: The authors declare that there is no conflict of interest. Ethics Approval Statement: Ethical approval for this study was obtained by the Omid Hospital Ethics Committee.",,,SSRN Electronic Journal,,,2021,2021,,,,,,All OA, Green,Preprint,"Sharifrazi, Danial; Alizadehsani, Roohallah; Izadi, Navid Hoseini; Roshanzamir, Mohamad; Shoeibi, Afshin; Khozeimeh, Fahime; Sani, Fariba Alizadeh; Sani, Zahra Alizadeh; Harlapur, Chandrashekhar; Khosravi, Abbas; Nahavandi, Saeid; Sarrafzadegan, Nizal; Islam, Mohammed Shariful","Sharifrazi, Danial (Islamic Azad University); Alizadehsani, Roohallah (Deakin University - Institute for Intelligent Systems Research and Innovation (IISRI)); Izadi, Navid Hoseini (Isfahan University of Technology - Department of Electrical and Computer Engineerin); Roshanzamir, Mohamad (Fasa University - Department of Engineering); Shoeibi, Afshin (Ferdowsi University of Mashhad - Computer Engineering Departmen); Khozeimeh, Fahime (Deakin University - Institute for Intelligent Systems Research and Innovation (IISRI)); Sani, Fariba Alizadeh (Mashhad University of Medical Sciences); Sani, Zahra Alizadeh (Mashhad University of Medical Sciences); Harlapur, Chandrashekhar (Deakin University - Institute for Physical Activity and Nutrition (IPAN)); Khosravi, Abbas (Deakin University - Institute for Intelligent Systems Research and Innovation (IISRI)); Nahavandi, Saeid (Deakin University - Institute for Intelligent Systems Research and Innovation (IISRI)); Sarrafzadegan, Nizal (Isfahan University of Medical Sciences - Isfahan Cardiovascular Research Cente); Islam, Mohammed Shariful (Deakin University - Institute for Physical Activity and Nutrition (IPAN))",,"Sharifrazi, Danial (Islamic Azad University, Tehran); Alizadehsani, Roohallah (Deakin University); Izadi, Navid Hoseini (); Roshanzamir, Mohamad (); Shoeibi, Afshin (Ferdowsi University of Mashhad); Khozeimeh, Fahime (Deakin University); Sani, Fariba Alizadeh (Mashhad University of Medical Sciences); Sani, Zahra Alizadeh (Mashhad University of Medical Sciences); Harlapur, Chandrashekhar (Deakin University); Khosravi, Abbas (Deakin University); Nahavandi, Saeid (Deakin University); Sarrafzadegan, Nizal (); Islam, Mohammed Shariful (Deakin University)",2,2,,1.53,https://www.researchsquare.com/article/rs-1005999/latest.pdf,https://app.dimensions.ai/details/publication/pub.1138788461,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
187,pub.1135198814,10.1038/nde/15487091/2021/18/2,,,Nature Methods,,,,Nature Methods,,,2021,2021,,,18,2,,Closed,Article,,,,,1,1,,,,https://app.dimensions.ai/details/publication/pub.1135198814,31 Biological Sciences,,,,,,,,,,,,
133,pub.1141326734,10.1007/978-3-030-87196-3,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2021, 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part II","The eight-volume set LNCS 12901, 12902, 12903, 12904, 12905, 12906, 12907, and 12908 constitutes the refereed proceedings of the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2021, held in Strasbourg, France, in September/October 2021.* The 531 revised full papers presented were carefully reviewed and selected from 1630 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: image segmentation Part II: machine learning - self-supervised learning; machine learning - semi-supervised learning; and machine learning - weakly supervised learning Part III: machine learning - advances in machine learning theory; machine learning - attention models; machine learning - domain adaptation; machine learning - federated learning; machine learning - interpretability / explainability; and machine learning - uncertainty Part IV: image registration; image-guided interventions and surgery; surgical data science; surgical planning and simulation; surgical skill and work flow analysis; and surgical visualization and mixed, augmented and virtual reality Part V: computer aided diagnosis; integration of imaging with non-imaging biomarkers; and outcome/disease prediction Part VI: image reconstruction; clinical applications - cardiac; and clinical applications - vascular Part VII: clinical applications - abdomen; clinical applications - breast; clinical applications - dermatology; clinical applications - fetal imaging; clinical applications - lung; clinical applications - neuroimaging - brain development; clinical applications - neuroimaging - DWI and tractography; clinical applications - neuroimaging - functional brain networks; clinical applications - neuroimaging – others; and clinical applications - oncology Part VIII: clinical applications - ophthalmology; computational (integrative) pathology; modalities - microscopy; modalities - histopathology; and modalities - ultrasound *The conference was held virtually.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12902,,,All OA, Green,Edited Book,,,,,3,3,,2.46,https://link.springer.com/content/pdf/bfm%3A978-3-030-87196-3%2F1,https://app.dimensions.ai/details/publication/pub.1141326734,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
120,pub.1134960455,10.1007/978-3-030-68107-4,,,"Statistical Atlases and Computational Models of the Heart. M&Ms and EMIDEC Challenges, 11th International Workshop, STACOM 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers","This book constitutes the proceedings of the 11th International Workshop on Statistical Atlases and Computational Models of the Heart, STACOM 2020, as well as two challenges: M&Ms - The Multi-Centre, Multi-Vendor, Multi-Disease Segmentation Challenge, and EMIDEC - Automatic Evaluation of Myocardial Infarction from Delayed-Enhancement Cardiac MRI Challenge. The 43 full papers included in this volume were carefully reviewed and selected from 70 submissions. They deal with cardiac imaging and image processing, machine learning applied to cardiac imaging and image analysis, atlas construction, artificial intelligence, statistical modelling of cardiac function across different patient populations, cardiac computational physiology, model customization, atlas based functional analysis, ontological schemata for data and results, integrated functional and structural analyses, as well as the pre-clinical and clinical applicability of these methods.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12592,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1134960455,46 Information and Computing Sciences,,,,,,,,,,,,
98,pub.1142309919,10.1007/978-3-030-89128-2,,,"Computer Analysis of Images and Patterns, 19th International Conference, CAIP 2021, Virtual Event, September 28–30, 2021, Proceedings, Part I","The two volume set LNCS 13052 and 13053 constitutes the refereed proceedings of the 19th International Conference on Computer Analysis of Images and Patterns, CAIP 2021, held virtually, in September 2021. The 87 papers presented were carefully reviewed and selected from 129 submissions. The papers are organized in the following topical sections across the 2 volumes: 3D vision, biomedical image and pattern analysis; machine learning; feature extractions; object recognition; face and gesture, guess the age contest, biometrics, cryptography and security; and segmentation and image restoration.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,13052,,,All OA, Green,Edited Book,,,,,0,0,,0.0,https://link.springer.com/content/pdf/bfm%3A978-3-030-89128-2%2F1,https://app.dimensions.ai/details/publication/pub.1142309919,46 Information and Computing Sciences, 4604 Cybersecurity and Privacy,,,,,,,,,,
91,pub.1132053462,10.1007/978-3-030-62324-1,,,"Computational Intelligence Methods for Green Technology and Sustainable Development, Proceedings of the International Conference GTSD2020","This book is a selected collection of 54 peer-reviewed original scientific research papers of the 5th International Conference on Green Technology and Sustainable Development (GTSD2020) organised in Vietnam in 2020. It highlights the importance of sustainability as well as promotes up-to-date innovation and research for green development in technologies, economics and education among countries. The conference provides an international platform for researchers, practitioners, policymakers and entrepreneurs to present their advances, knowledge and experience on various interdisciplinary topics related to the theme of “Green technology and sustainable development in industrial revolution 4.0”. The book is a valuable resource for researchers, analysts, engineers, practitioners and policymakers who are interested in the latest findings in artificial intelligence, cyber systems, robotics, green energy and power systems, mechanical and computational mechanic models and advanced civil engineering. This book has 05 sessions consisting of both theoretical and practical aspects, and numerical and experimental analyses in various engineering disciplines.",,,Advances in Intelligent Systems and Computing,,,2021,2021,,2021,1284,,,All OA, Green,Edited Book,,,,,1,1,,1.6,https://link.springer.com/content/pdf/bfm%3A978-3-030-62324-1%2F1,https://app.dimensions.ai/details/publication/pub.1132053462,40 Engineering, 48 Law and Legal Studies, 4802 Environmental and Resources Law,7 Affordable and Clean Energy,,,,,,,,
90,pub.1139422550,10.1007/978-3-030-80432-9,,,"Medical Image Understanding and Analysis, 25th Annual Conference, MIUA 2021, Oxford, United Kingdom, July 12–14, 2021, Proceedings","This book constitutes the refereed proceedings of the 25th Conference on Medical Image Understanding and Analysis, MIUA 2021, held in July 2021. Due to COVID-19 pandemic the conference was held virtually. The 32 full papers and 8 short papers presented were carefully reviewed and selected from 77 submissions. They were organized according to following topical sections: biomarker detection; image registration, and reconstruction; image segmentation; generative models, biomedical simulation and modelling; classification; image enhancement, quality assessment, and data privacy; radiomics, predictive models, and quantitative imaging.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12722,,,All OA, Green,Edited Book,,,,,1,1,,0.77,https://link.springer.com/content/pdf/bfm%3A978-3-030-80432-9%2F1,https://app.dimensions.ai/details/publication/pub.1139422550,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
78,pub.1138949830,10.1007/978-3-030-78710-3,,,"Functional Imaging and Modeling of the Heart, 11th International Conference, FIMH 2021, Stanford, CA, USA, June 21-25, 2021, Proceedings","This book constitutes the refereed proceedings of the 11th International Conference on Functional Imaging and Modeling of the Heart, which took place online during June 21-24, 2021, organized by the University of Stanford. The 65 revised full papers were carefully reviewed and selected from 68 submissions. They were organized in topical sections as follows: advanced cardiac and cardiovascular image processing; cardiac microstructure: measures and models; novel approaches to measuring heart deformation; cardiac mechanics: measures and models; translational cardiac mechanics; modeling electrophysiology, ECG, and arrhythmia; cardiovascular flow: measures and models; and atrial microstructure, modeling, and thrombosis prediction.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12738,,,All OA, Green,Edited Book,,,,,4,4,,,https://link.springer.com/content/pdf/bfm%3A978-3-030-78710-3%2F1,https://app.dimensions.ai/details/publication/pub.1138949830,46 Information and Computing Sciences,,,,,,,,,,,
73,pub.1141302076,10.1007/978-3-030-87231-1,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2021, 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part VI","The eight-volume set LNCS 12901, 12902, 12903, 12904, 12905, 12906, 12907, and 12908 constitutes the refereed proceedings of the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2021, held in Strasbourg, France, in September/October 2021.* The 531 revised full papers presented were carefully reviewed and selected from 1630 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: image segmentation Part II: machine learning - self-supervised learning; machine learning - semi-supervised learning; and machine learning - weakly supervised learning Part III: machine learning - advances in machine learning theory; machine learning - attention models; machine learning - domain adaptation; machine learning - federated learning; machine learning - interpretability / explainability; and machine learning - uncertainty Part IV: image registration; image-guided interventions and surgery; surgical data science; surgical planning and simulation; surgical skill and work flow analysis; and surgical visualization and mixed, augmented and virtual reality Part V: computer aided diagnosis; integration of imaging with non-imaging biomarkers; and outcome/disease prediction Part VI: image reconstruction; clinical applications - cardiac; and clinical applications - vascular Part VII: clinical applications - abdomen; clinical applications - breast; clinical applications - dermatology; clinical applications - fetal imaging; clinical applications - lung; clinical applications - neuroimaging - brain development; clinical applications - neuroimaging - DWI and tractography; clinical applications - neuroimaging - functional brain networks; clinical applications - neuroimaging – others; and clinical applications - oncology Part VIII: clinical applications - ophthalmology; computational (integrative) pathology; modalities - microscopy; modalities - histopathology; and modalities - ultrasound *The conference was held virtually.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12906,,,All OA, Green,Edited Book,,,,,1,1,,0.82,https://link.springer.com/content/pdf/bfm%3A978-3-030-87231-1%2F1,https://app.dimensions.ai/details/publication/pub.1141302076,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
68,pub.1141326795,10.1007/978-3-030-87199-4,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2021, 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part III","The eight-volume set LNCS 12901, 12902, 12903, 12904, 12905, 12906, 12907, and 12908 constitutes the refereed proceedings of the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2021, held in Strasbourg, France, in September/October 2021.* The 531 revised full papers presented were carefully reviewed and selected from 1630 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: image segmentation Part II: machine learning - self-supervised learning; machine learning - semi-supervised learning; and machine learning - weakly supervised learning Part III: machine learning - advances in machine learning theory; machine learning - attention models; machine learning - domain adaptation; machine learning - federated learning; machine learning - interpretability / explainability; and machine learning - uncertainty Part IV: image registration; image-guided interventions and surgery; surgical data science; surgical planning and simulation; surgical skill and work flow analysis; and surgical visualization and mixed, augmented and virtual reality Part V: computer aided diagnosis; integration of imaging with non-imaging biomarkers; and outcome/disease prediction Part VI: image reconstruction; clinical applications - cardiac; and clinical applications - vascular Part VII: clinical applications - abdomen; clinical applications - breast; clinical applications - dermatology; clinical applications - fetal imaging; clinical applications - lung; clinical applications - neuroimaging - brain development; clinical applications - neuroimaging - DWI and tractography; clinical applications - neuroimaging - functional brain networks; clinical applications - neuroimaging – others; and clinical applications - oncology Part VIII: clinical applications - ophthalmology; computational (integrative) pathology; modalities - microscopy; modalities - histopathology; and modalities - ultrasound *The conference was held virtually.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12903,,,All OA, Green,Edited Book,,,,,5,5,,4.09,https://link.springer.com/content/pdf/bfm%3A978-3-030-87199-4%2F1,https://app.dimensions.ai/details/publication/pub.1141326795,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
61,pub.1141301941,10.1007/978-3-030-87193-2,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2021, 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part I","The eight-volume set LNCS 12901, 12902, 12903, 12904, 12905, 12906, 12907, and 12908 constitutes the refereed proceedings of the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2021, held in Strasbourg, France, in September/October 2021.* The 531 revised full papers presented were carefully reviewed and selected from 1630 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: image segmentation Part II: machine learning - self-supervised learning; machine learning - semi-supervised learning; and machine learning - weakly supervised learning Part III: machine learning - advances in machine learning theory; machine learning - attention models; machine learning - domain adaptation; machine learning - federated learning; machine learning - interpretability / explainability; and machine learning - uncertainty Part IV: image registration; image-guided interventions and surgery; surgical data science; surgical planning and simulation; surgical skill and work flow analysis; and surgical visualization and mixed, augmented and virtual reality Part V: computer aided diagnosis; integration of imaging with non-imaging biomarkers; and outcome/disease prediction Part VI: image reconstruction; clinical applications - cardiac; and clinical applications - vascular Part VII: clinical applications - abdomen; clinical applications - breast; clinical applications - dermatology; clinical applications - fetal imaging; clinical applications - lung; clinical applications - neuroimaging - brain development; clinical applications - neuroimaging - DWI and tractography; clinical applications - neuroimaging - functional brain networks; clinical applications - neuroimaging – others; and clinical applications - oncology Part VIII: clinical applications - ophthalmology; computational (integrative) pathology; modalities - microscopy; modalities - histopathology; and modalities - ultrasound *The conference was held virtually.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12901,,,All OA, Green,Edited Book,,,,,4,4,,3.27,https://link.springer.com/content/pdf/bfm%3A978-3-030-87193-2%2F1,https://app.dimensions.ai/details/publication/pub.1141301941,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
55,pub.1132291587,10.1007/978-3-030-62743-0,,,"The 2020 International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy, SPIoT-2020, Volume 1","This book presents the proceedings of The 2020 International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT-2020), held in Shanghai, China, on November 6, 2020. Due to the COVID-19 outbreak problem, SPIoT-2020 conference was held online by Tencent Meeting. It provides comprehensive coverage of the latest advances and trends in information technology, science and engineering, addressing a number of broad themes, including novel machine learning and big data analytics methods for IoT security, data mining and statistical modelling for the secure IoT and machine learning-based security detecting protocols, which inspire the development of IoT security and privacy technologies. The contributions cover a wide range of topics: analytics and machine learning applications to IoT security; data-based metrics and risk assessment approaches for IoT; data confidentiality and privacy in IoT; and authentication and access control for data usage in IoT. Outlining promising future research directions, the book is a valuable resource for students, researchers and professionals and provides a useful reference guide for newcomers to the IoT security and privacy field.",,,Advances in Intelligent Systems and Computing,,,2021,2021,,2021,1282,,,All OA, Green,Edited Book,,,,,0,0,,0.0,https://link.springer.com/content/pdf/bfm%3A978-3-030-62743-0%2F1,https://app.dimensions.ai/details/publication/pub.1132291587,46 Information and Computing Sciences, 4604 Cybersecurity and Privacy,,,,,,,,,,
909,pub.1134255911,10.48550/arxiv.2012.15772,,,Estimating Uncertainty in Neural Networks for Cardiac MRI Segmentation:  A Benchmark Study,"Objective: Convolutional neural networks (CNNs) have demonstrated promise in
automated cardiac magnetic resonance image segmentation. However, when using
CNNs in a large real-world dataset, it is important to quantify segmentation
uncertainty and identify segmentations which could be problematic. In this
work, we performed a systematic study of Bayesian and non-Bayesian methods for
estimating uncertainty in segmentation neural networks.
  Methods: We evaluated Bayes by Backprop, Monte Carlo Dropout, Deep Ensembles,
and Stochastic Segmentation Networks in terms of segmentation accuracy,
probability calibration, uncertainty on out-of-distribution images, and
segmentation quality control.
  Results: We observed that Deep Ensembles outperformed the other methods
except for images with heavy noise and blurring distortions. We showed that
Bayes by Backprop is more robust to noise distortions while Stochastic
Segmentation Networks are more resistant to blurring distortions. For
segmentation quality control, we showed that segmentation uncertainty is
correlated with segmentation accuracy for all the methods. With the
incorporation of uncertainty estimates, we were able to reduce the percentage
of poor segmentation to 5% by flagging 31--48% of the most uncertain
segmentations for manual review, substantially lower than random review without
using neural network uncertainty (reviewing 75--78% of all images).
  Conclusion: This work provides a comprehensive evaluation of uncertainty
estimation methods and showed that Deep Ensembles outperformed other methods in
most cases.
  Significance: Neural network uncertainty measures can help identify
potentially inaccurate segmentations and alert users for manual review.",,,arXiv,,,2020-12-31,2020,,,,,,All OA, Green,Preprint,"Ng, Matthew; Guo, Fumin; Biswas, Labonny; Petersen, Steffen E.; Piechnik, Stefan K.; Neubauer, Stefan; Wright, Graham","Ng, Matthew (); Guo, Fumin (); Biswas, Labonny (); Petersen, Steffen E. (); Piechnik, Stefan K. (); Neubauer, Stefan (); Wright, Graham ()",,"Ng, Matthew (); Guo, Fumin (); Biswas, Labonny (); Petersen, Steffen E. (); Piechnik, Stefan K. (); Neubauer, Stefan (); Wright, Graham ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1134255911,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 4611 Machine Learning, 51 Physical Sciences,,,,,,,
5371,pub.1130701450,10.1109/tmi.2020.3022693,32897860,,Learning Geodesic Active Contours for Embedding Object Global Information in Segmentation CNNs,"Most existing CNNs-based segmentation methods rely on local appearances learned on the regular image grid, without consideration of the object global information. This article aims to embed the object global geometric information into a learning framework via the classical geodesic active contours (GAC). We propose a level set function (LSF) regression network, supervised by the segmentation ground truth, LSF ground truth and geodesic active contours, to not only generate the segmentation probabilistic map but also directly minimize the GAC energy functional in an end-to-end manner. With the help of geodesic active contours, the segmentation contour, embedded in the level set function, can be globally driven towards the image boundary to obtain lower energy, and the geodesic constraint can lead the segmentation result to have fewer outliers. Extensive experiments on four public datasets show that (1) compared with state-of-the-art (SOTA) learning active contour methods, our method can achieve significantly better performance; (2) compared with recent SOTA methods that are designed for reducing boundary errors, our method also outperforms them with more accurate boundaries; (3) compared with SOTA methods on two popular multi-class segmentation challenge datasets, our method can still obtain superior or competitive results in both organ and tumor segmentation tasks. Our study demonstrates that introducing global information by GAC can significantly improve segmentation performance, especially on reducing the boundary errors and outliers, which is very useful in applications such as organ transplantation surgical planning and multi-modality image registration where boundary errors can be very harmful.","This work was supported by the National Natural Science Foundation of China under Grant 11153105 and Grant 11971229. The authors highly appreciate the anonymous reviewers for their great suggestions to improve this article. The authors would also like to thank the organization teams of MICCAI 2017 liver tumor segmentation challenge, MICCAI 2018 left atrial segmentation challenge, the National Institutes of Health Clinical Center, MICCAI 2018 medical segmentation decathlon, and MICCAI 2019 kidney tumor segmentation challenge for the publicly available datasets. The experiments in this article have been done on the computing facilities in the High Performance Computing Center of Nanjing University.",,IEEE Transactions on Medical Imaging,,,2020-12-29,2020,2020-12-29,2021-01,40,1,93-104,Closed,Article,"Ma, Jun; He, Jian; Yang, Xiaoping","Ma, Jun (Department of Mathematics, Nanjing University of Science and Technology, Nanjing, 210094, China); He, Jian (Department of Radiology, Nanjing Drum Tower Hospital, The Affiliated Hospital of Nanjing University Medical School, Nanjing, 210093, China); Yang, Xiaoping (Department of Mathematics, Nanjing University, Nanjing, 210093, China)","Yang, Xiaoping (Nanjing University)","Ma, Jun (Nanjing University of Science and Technology); He, Jian (Nanjing Drum Tower Hospital); Yang, Xiaoping (Nanjing University)",16,15,0.73,7.62,,https://app.dimensions.ai/details/publication/pub.1130701450,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
1770,pub.1134254695,10.48550/arxiv.2012.14556,,,Cascaded Framework for Automatic Evaluation of Myocardial Infarction  from Delayed-Enhancement Cardiac MRI,"Automatic evaluation of myocardium and pathology plays an important role in
the quantitative analysis of patients suffering from myocardial infarction. In
this paper, we present a cascaded convolutional neural network framework for
myocardial infarction segmentation and classification in delayed-enhancement
cardiac MRI. Specifically, we first use a 2D U-Net to segment the whole heart,
including the left ventricle and the myocardium. Then, we crop the whole heart
as a region of interest (ROI). Finally, a new 2D U-Net is used to segment the
infraction and no-reflow areas in the whole heart ROI. The segmentation method
can be applied to the classification task where the segmentation results with
the infraction or no-reflow areas are classified as pathological cases. Our
method took second place in the MICCAI 2020 EMIDEC segmentation task with Dice
scores of 86.28%, 62.24%, and 77.76% for myocardium, infraction, and no-reflow
areas, respectively, and first place in the classification task with an
accuracy of 92%.",,,arXiv,,,2020-12-28,2020,,,,,,All OA, Green,Preprint,"Ma, Jun","Ma, Jun ()",,"Ma, Jun ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1134254695,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1296,pub.1134254703,10.48550/arxiv.2012.14564,,,Myocardial Segmentation of Cardiac MRI Sequences with Temporal  Consistency for Coronary Artery Disease Diagnosis,"Coronary artery disease (CAD) is the most common cause of death globally, and
its diagnosis is usually based on manual myocardial segmentation of Magnetic
Resonance Imaging (MRI) sequences. As the manual segmentation is tedious,
time-consuming and with low applicability, automatic myocardial segmentation
using machine learning techniques has been widely explored recently. However,
almost all the existing methods treat the input MRI sequences independently,
which fails to capture the temporal information between sequences, e.g., the
shape and location information of the myocardium in sequences along time. In
this paper, we propose a myocardial segmentation framework for sequence of
cardiac MRI (CMR) scanning images of left ventricular cavity, right ventricular
cavity, and myocardium. Specifically, we propose to combine conventional
networks and recurrent networks to incorporate temporal information between
sequences to ensure temporal consistent. We evaluated our framework on the
Automated Cardiac Diagnosis Challenge (ACDC) dataset. Experiment results
demonstrate that our framework can improve the segmentation accuracy by up to
2% in Dice coefficient.",,,arXiv,,,2020-12-28,2020,,,,,,All OA, Green,Preprint,"Chen, Yutian; Xu, Xiaowei; Zeng, Dewen; Shi, Yiyu; Yuan, Haiyun; Zhuang, Jian; Dong, Yuhao; Jia, Qianjun; Huang, Meiping","Chen, Yutian (); Xu, Xiaowei (); Zeng, Dewen (); Shi, Yiyu (); Yuan, Haiyun (); Zhuang, Jian (); Dong, Yuhao (); Jia, Qianjun (); Huang, Meiping ()",,"Chen, Yutian (); Xu, Xiaowei (); Zeng, Dewen (); Shi, Yiyu (); Yuan, Haiyun (); Zhuang, Jian (); Dong, Yuhao (); Jia, Qianjun (); Huang, Meiping ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1134254703,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1654,pub.1134163203,10.48550/arxiv.2012.13871,,,"Histogram Matching Augmentation for Domain Adaptation with Application  to Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Image Segmentation","Convolutional Neural Networks (CNNs) have achieved high accuracy for cardiac
structure segmentation if training cases and testing cases are from the same
distribution. However, the performance would be degraded if the testing cases
are from a distinct domain (e.g., new MRI scanners, clinical centers). In this
paper, we propose a histogram matching (HM) data augmentation method to
eliminate the domain gap. Specifically, our method generates new training cases
by using HM to transfer the intensity distribution of testing cases to existing
training cases. The proposed method is quite simple and can be used in a
plug-and-play way in many segmentation tasks. The method is evaluated on MICCAI
2020 M\&Ms challenge, and achieves average Dice scores of 0.9051, 0.8405, and
0.8749, and Hausdorff Distances of 9.996, 12.49, and 12.68 for the left
ventricular, myocardium, and right ventricular, respectively. Our results rank
the third place in MICCAI 2020 M\&Ms challenge. The code and trained models are
publicly available at \url{https://github.com/JunMa11/HM_DataAug}.",,,arXiv,,,2020-12-27,2020,,,,,,All OA, Green,Preprint,"Ma, Jun","Ma, Jun ()",,"Ma, Jun ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1134163203,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
3249,pub.1134038207,10.1016/j.compbiomed.2020.104200,33421825,,Deep learning in spatiotemporal cardiac imaging: A review of methodologies and clinical usability,"The use of different cardiac imaging modalities such as MRI, CT or ultrasound enables the visualization and interpretation of altered morphological structures and function of the heart. In recent years, there has been an increasing interest in AI and deep learning that take into account spatial and temporal information in medical image analysis. In particular, deep learning tools using temporal information in image processing have not yet found their way into daily clinical practice, despite its presumed high diagnostic and prognostic value. This review aims to synthesize the most relevant deep learning methods and discuss their clinical usability in dynamic cardiac imaging using for example the complete spatiotemporal image information of the heart cycle. Selected articles were categorized according to the following indicators: clinical applications, quality of datasets, preprocessing and annotation, learning methods and training strategy, and test performance. Clinical usability was evaluated based on these criteria by classifying the selected papers into (i) clinical level, (ii) robust candidate and (iii) proof of concept applications. Interestingly, not a single one of the reviewed papers was classified as a ""clinical level"" study. Almost 39% of the articles achieved a ""robust candidate"" and as many as 61% a ""proof of concept"" status. In summary, deep learning in spatiotemporal cardiac imaging is still strongly research-oriented and its implementation in clinical application still requires considerable efforts. Challenges that need to be addressed are the quality of datasets together with clinical verification and validation of the performance achieved by the used method.",,,Computers in Biology and Medicine,,"Cardiac Imaging Techniques; Deep Learning; Heart; Image Processing, Computer-Assisted; Magnetic Resonance Imaging",2020-12-24,2020,2020-12-24,2021-03,130,,104200,All OA, Hybrid,Article,"Lara Hernandez, Karen Andrea; Rienmüller, Theresa; Baumgartner, Daniela; Baumgartner, Christian","Lara Hernandez, Karen Andrea (Institute of Health Care Engineering with European Testing Center of Medical Devices, Graz University of Technology, Graz, Austria; Department of Biomedical Engineering, Galileo University, Guatemala City, Guatemala.); Rienmüller, Theresa (Institute of Health Care Engineering with European Testing Center of Medical Devices, Graz University of Technology, Graz, Austria.); Baumgartner, Daniela (Devision of Pediatric Cardiology, Medical University of Graz, Graz, Austria.); Baumgartner, Christian (Institute of Health Care Engineering with European Testing Center of Medical Devices, Graz University of Technology, Graz, Austria. Electronic address: christian.baumgartner@tugraz.at.)",,"Lara Hernandez, Karen Andrea (Graz University of Technology; Galileo University); Rienmüller, Theresa (Graz University of Technology); Baumgartner, Daniela (Medical University of Graz); Baumgartner, Christian (Graz University of Technology)",20,20,2.22,15.34,https://doi.org/10.1016/j.compbiomed.2020.104200,https://app.dimensions.ai/details/publication/pub.1134038207,46 Information and Computing Sciences, 4601 Applied Computing,,,,,,,,,,
1395,pub.1135356982,10.1109/bibm49941.2020.9313411,,,A Network of Simultaneous Segmentation and Registration for Right Ventricle MRI,"Short-axis MRI segmentation of the right ventricle plays an important role in assessing the structure and function of the right ventricle. However, RV segmentation is a challenge due to its complex crescent shape. In this paper, we propose a deep learning-based method for segmenting RV using the registration of the right ventricular shape model. The RV shape probability model is constructed using training samples. Next, aU-Net is trained using the shape prior probability by employing the registration technique. The shape model is registered to the network’s predictive results to estimate a shape probability map, and a loss is defined as the Kullback-Leibler divergence between the prediction result and the shape probability map and the Kullback-Leibler divergence between the predictive result and the Ground-truth. The experimental results obtained from the cardiac automatic diagnosis challenge-medical imaging calculation and computer-aided intervention (ACDC-MICCAI) 2017 dataset show that the average 3D dice coefficient is 0.919, and the average 3D Hausdorff distance is 10.71mm. Our network has also been verified in the MICCAI2012 right ventricle segmentation challenge(RVSC) dataset. The average dice coefficient is 0.865, and the Hausdorff distance is 6. 10mm. The evaluation results show that our network outperforms the state-of-art methods in several evaluation indicators.",This papser is supported by the National Natural Science Foundation of China (61871269).,,,2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,2020-12-19,2020,,2020-12-19,0,,657-662,Closed,Proceeding,"Lin, Adan; Li, Zhenzhen; Yang, Xuan","Lin, Adan (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China); Li, Zhenzhen (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China); Yang, Xuan (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China)","Lin, Adan (Shenzhen University)","Lin, Adan (Shenzhen University); Li, Zhenzhen (Shenzhen University); Yang, Xuan (Shenzhen University)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1135356982,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,,
1345,pub.1133543641,10.48550/arxiv.2012.08051,,,Teach me to segment with mixed supervision: Confident students become  masters,"Deep segmentation neural networks require large training datasets with
pixel-wise segmentations, which are expensive to obtain in practice. Mixed
supervision could mitigate this difficulty, with a small fraction of the data
containing complete pixel-wise annotations, while the rest being less
supervised, e.g., only a handful of pixels are labeled. In this work, we
propose a dual-branch architecture, where the upper branch (teacher) receives
strong annotations, while the bottom one (student) is driven by limited
supervision and guided by the upper branch. In conjunction with a standard
cross-entropy over the labeled pixels, our novel formulation integrates two
important terms: (i) a Shannon entropy loss defined over the less-supervised
images, which encourages confident student predictions at the bottom branch;
and (ii) a Kullback-Leibler (KL) divergence, which transfers the knowledge from
the predictions generated by the strongly supervised branch to the
less-supervised branch, and guides the entropy (student-confidence) term to
avoid trivial solutions. Very interestingly, we show that the synergy between
the entropy and KL divergence yields substantial improvements in performances.
Furthermore, we discuss an interesting link between Shannon-entropy
minimization and standard pseudo-mask generation and argue that the former
should be preferred over the latter for leveraging information from unlabeled
pixels. Through a series of quantitative and qualitative experiments, we show
the effectiveness of the proposed formulation in segmenting the left-ventricle
endocardium in MRI images. We demonstrate that our method significantly
outperforms other strategies to tackle semantic segmentation within a
mixed-supervision framework. More interestingly, and in line with recent
observations in classification, we show that the branch trained with reduced
supervision largely outperforms the teacher.",,,arXiv,,,2020-12-14,2020,,,,,,All OA, Green,Preprint,"Dolz, Jose; Desrosiers, Christian; Ayed, Ismail Ben","Dolz, Jose (); Desrosiers, Christian (); Ayed, Ismail Ben ()",,"Dolz, Jose (); Desrosiers, Christian (); Ayed, Ismail Ben ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1133543641,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
3465,pub.1133377548,10.1038/s41598-020-77733-4,33303782,PMC7729401,Automatic segmentation with detection of local segmentation failures in cardiac MRI,"Segmentation of cardiac anatomical structures in cardiac magnetic resonance images (CMRI) is a prerequisite for automatic diagnosis and prognosis of cardiovascular diseases. To increase robustness and performance of segmentation methods this study combines automatic segmentation and assessment of segmentation uncertainty in CMRI to detect image regions containing local segmentation failures. Three existing state-of-the-art convolutional neural networks (CNN) were trained to automatically segment cardiac anatomical structures and obtain two measures of predictive uncertainty: entropy and a measure derived by MC-dropout. Thereafter, using the uncertainties another CNN was trained to detect local segmentation failures that potentially need correction by an expert. Finally, manual correction of the detected regions was simulated in the complete set of scans of 100 patients and manually performed in a random subset of scans of 50 patients. Using publicly available CMR scans from the MICCAI 2017 ACDC challenge, the impact of CNN architecture and loss function for segmentation, and the uncertainty measure was investigated. Performance was evaluated using the Dice coefficient, 3D Hausdorff distance and clinical metrics between manual and (corrected) automatic segmentation. The experiments reveal that combining automatic segmentation with manual correction of detected segmentation failures results in improved segmentation and to 10-fold reduction of expert time compared to manual expert segmentation.",This study was performed within the DLMedIA program (P15-26) funded by Dutch Technology Foundation with participation of PIE Medical Imaging.,,Scientific Reports,,"Cardiovascular Diseases; Heart; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Neural Networks, Computer",2020-12-10,2020,2020-12-10,,10,1,21769,All OA, Gold,Article,"Sander, Jörg; de Vos, Bob D.; Išgum, Ivana","Sander, Jörg (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - location AMC, University of Amsterdam, Amsterdam, The Netherlands; Amsterdam Cardiovascular Sciences, Amsterdam University Medical Centers - location AMC, University of Amsterdam, Amsterdam, The Netherlands; Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands); de Vos, Bob D. (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - location AMC, University of Amsterdam, Amsterdam, The Netherlands; Amsterdam Cardiovascular Sciences, Amsterdam University Medical Centers - location AMC, University of Amsterdam, Amsterdam, The Netherlands); Išgum, Ivana (Department of Biomedical Engineering and Physics, Amsterdam University Medical Centers - location AMC, University of Amsterdam, Amsterdam, The Netherlands; Amsterdam Cardiovascular Sciences, Amsterdam University Medical Centers - location AMC, University of Amsterdam, Amsterdam, The Netherlands; Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands; Department of Radiology and Nuclear Medicine, Amsterdam University Medical Centers - location AMC, University of Amsterdam, Amsterdam, The Netherlands)","Sander, Jörg (University of Amsterdam; University of Amsterdam; University Medical Center Utrecht)","Sander, Jörg (University of Amsterdam; University of Amsterdam; University Medical Center Utrecht); de Vos, Bob D. (University of Amsterdam; University of Amsterdam); Išgum, Ivana (University of Amsterdam; University of Amsterdam; University Medical Center Utrecht; University of Amsterdam)",16,16,1.31,7.84,https://www.nature.com/articles/s41598-020-77733-4.pdf,https://app.dimensions.ai/details/publication/pub.1133377548,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 51 Physical Sciences,,,,,,,,
4772,pub.1133376825,10.1016/j.media.2020.101934,33385699,,Semi-supervised task-driven data augmentation for medical image segmentation,"Supervised learning-based segmentation methods typically require a large number of annotated training data to generalize well at test time. In medical applications, curating such datasets is not a favourable option because acquiring a large number of annotated samples from experts is time-consuming and expensive. Consequently, numerous methods have been proposed in the literature for learning with limited annotated examples. Unfortunately, the proposed approaches in the literature have not yet yielded significant gains over random data augmentation for image segmentation, where random augmentations themselves do not yield high accuracy. In this work, we propose a novel task-driven data augmentation method for learning with limited labeled data where the synthetic data generator, is optimized for the segmentation task. The generator of the proposed method models intensity and shape variations using two sets of transformations, as additive intensity transformations and deformation fields. Both transformations are optimized using labeled as well as unlabeled examples in a semi-supervised framework. Our experiments on three medical datasets, namely cardiac, prostate and pancreas, show that the proposed approach significantly outperforms standard augmentation and semi-supervised approaches for image segmentation in the limited annotation setting. The code is made publicly available at https://github.com/krishnabits001/task_driven_data_augmentation.","The presented work is partially funded by: 1. Swiss Data Science Center (DeepMicroIA), 2. Clinical Research Priority Program Grant (CRPP) on Artificial Intelligence in Oncological Imaging Network, University of Zurich and University Hospital of Zurich, 3. Platform for Advanced Scientific Computing (PASC) - project HCP-Predict, 4. Personalized Health Related Technologies - project number 222, ETH. We thank Nvidia for their GPU donation.",,Medical Image Analysis,,Humans, Male, Prostate, Supervised Machine Learning,2020-12-09,2020,2020-12-09,2021-02,68,,101934,All OA, Hybrid,Article,"Chaitanya, Krishna; Karani, Neerav; Baumgartner, Christian F; Erdil, Ertunc; Becker, Anton; Donati, Olivio; Konukoglu, Ender","Chaitanya, Krishna (Computer Vision Laboratory, ETH Zurich, Sternwartstrasse 7, Zurich- 8092, Switzerland. Electronic address: krishna.chaitanya@vision.ee.ethz.ch.); Karani, Neerav (Computer Vision Laboratory, ETH Zurich, Sternwartstrasse 7, Zurich- 8092, Switzerland.); Baumgartner, Christian F (Computer Vision Laboratory, ETH Zurich, Sternwartstrasse 7, Zurich- 8092, Switzerland.); Erdil, Ertunc (Computer Vision Laboratory, ETH Zurich, Sternwartstrasse 7, Zurich- 8092, Switzerland.); Becker, Anton (University Hospital of Zurich, Ramistrasse 100, Zurich- 8091, Switzerland.); Donati, Olivio (University Hospital of Zurich, Ramistrasse 100, Zurich- 8091, Switzerland.); Konukoglu, Ender (Computer Vision Laboratory, ETH Zurich, Sternwartstrasse 7, Zurich- 8092, Switzerland.)","Chaitanya, Krishna (ETH Zurich)","Chaitanya, Krishna (ETH Zurich); Karani, Neerav (ETH Zurich); Baumgartner, Christian F (ETH Zurich); Erdil, Ertunc (ETH Zurich); Becker, Anton (University Hospital of Zurich); Donati, Olivio (University Hospital of Zurich); Konukoglu, Ender (ETH Zurich)",41,41,4.67,,https://doi.org/10.1016/j.media.2020.101934,https://app.dimensions.ai/details/publication/pub.1133376825,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,
4791,pub.1133288818,10.1038/s41592-020-01008-z,33288961,,nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation,"Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training.","This work was co-funded by the National Center for Tumor Diseases (NCT) in Heidelberg and the Helmholtz Imaging Platform (HIP). We thank our colleagues at DKFZ who were involved in the various challenge contributions, especially A. Klein, D. Zimmerer, J. Wasserthal, G. Koehler, T. Norajitra and S. Wirkert, who contributed to the Decathlon submission. We also thank the MITK team, which supported us in producing all medical dataset visualizations. We are also thankful to all the challenge organizers, who provided an important basis for our work. We want to especially mention N. Heller, who enabled the collection of all the details from the KiTS challenge through excellent challenge design, E. Kavur from the CHAOS team, who generated comprehensive leaderboard information for us, C. Petitjean, who provided detailed leaderboard information of the SegTHOR entries from ISBI 2019 and M. Maška, who patiently supported us during our Cell Tracking Challenge submission. We thank M. Wiesenfarth for his helpful advice concerning the ranking of methods and the visualization of rankings. We further thank C. Pape and T. Wollman for their crucial introductions to the CREMI and Cell Tracking Challenges, respectively. Last but not least, we thank O. Ronneberger and L. Maier-Hein for their important feedback on this manuscript.",,Nature Methods,,"Algorithms; Deep Learning; Image Processing, Computer-Assisted; Neural Networks, Computer",2020-12-07,2020,2020-12-07,2021-02,18,2,203-211,All OA, Green,Article,"Isensee, Fabian; Jaeger, Paul F.; Kohl, Simon A. A.; Petersen, Jens; Maier-Hein, Klaus H.","Isensee, Fabian (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Faculty of Biosciences, University of Heidelberg, Heidelberg, Germany); Jaeger, Paul F. (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany); Kohl, Simon A. A. (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; DeepMind, London, UK); Petersen, Jens (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Faculty of Physics & Astronomy, University of Heidelberg, Heidelberg, Germany); Maier-Hein, Klaus H. (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Pattern Analysis and Learning Group, Department of Radiation Oncology, Heidelberg University Hospital, Heidelberg, Germany)","Maier-Hein, Klaus H. (German Cancer Research Center; University Hospital Heidelberg)","Isensee, Fabian (German Cancer Research Center; Heidelberg University); Jaeger, Paul F. (German Cancer Research Center); Kohl, Simon A. A. (German Cancer Research Center; DeepMind (United Kingdom)); Petersen, Jens (German Cancer Research Center; Heidelberg University); Maier-Hein, Klaus H. (German Cancer Research Center; University Hospital Heidelberg)",1224,1222,142.07,,http://arxiv.org/pdf/1904.08128,https://app.dimensions.ai/details/publication/pub.1133288818,31 Biological Sciences,,,,,,,,,,,
1170,pub.1130415426,10.1016/j.neucom.2020.08.030,,,Automatic cardiac MRI segmentation and permutation-invariant pathology classification using deep neural networks and point clouds,"Segmentation of cardiac MRI images plays a key role in clinical diagnosis. In the traditional diagnostic process, clinical experts manually segment left ventricle (LV), right ventricle (RV) and myocardium (Myo) to get the guideline for cardiopathy diagnosis. However, manual segmentation is time-consuming and labor-intensive. In this paper, we propose automatic cardiac MRI segmentation and cardiopathy classification based on deep neural networks and point clouds. The cardiac MRI segmentation consists of two steps: (i) We use a detector based on you only look once (YOLO) to obtain region of interest (ROI) from the sequential diastolic and systolic MRI. (ii) We obtain the segmentation masks from the ROI automatically by a fully convolutional neural network (FCN). Subsequently, we reconstruct 3D surfaces by a simple linear interpolation method, then randomly sample uniform 3D point clouds from the 3D surfaces. From the cardiac point clouds, we perform cardiopathy classification using a cardiopathy diagnosis network (CDN). Experimental results show that the proposed method successfully segments LV, RV, and Myo from cardiac MRI images and achieves comparable results against several existing ones. Moreover, the CDN successfully classifies heart diseases based on point clouds and achieves 92% accuracy on the testing dataset.",This work was supported by the National Natural Science Foundation of China (No. 61872280) and the International ST Cooperation Program of China (No. 2014DFG12780).,,Neurocomputing,,,2020-12,2020,,2020-12,418,,270-279,Closed,Article,"Chang, Yakun; Jung, Cheolkon","Chang, Yakun (School of Electronic Engineering, Xidian University, Xi’an 710071, China); Jung, Cheolkon (School of Electronic Engineering, Xidian University, Xi’an 710071, China)","Jung, Cheolkon (Xidian University)","Chang, Yakun (Xidian University); Jung, Cheolkon (Xidian University)",10,10,,,,https://app.dimensions.ai/details/publication/pub.1130415426,46 Information and Computing Sciences,,,,,,,,,,,,
1295,pub.1133116425,10.48550/arxiv.2011.14773,,,Deep learning approach to left ventricular non-compaction measurement,"Left ventricular non-compaction (LVNC) is a rare cardiomyopathy characterized
by abnormal trabeculations in the left ventricle cavity. Although traditional
computer vision approaches exist for LVNC diagnosis, deep learning-based tools
could not be found in the literature. In this paper, a first approach using
convolutional neural networks (CNNs) is presented. Four CNNs are trained to
automatically segment the compacted and trabecular areas of the left ventricle
for a population of patients diagnosed with Hypertrophic cardiomyopathy.
Inference results confirm that deep learning-based approaches can achieve
excellent results in the diagnosis and measurement of LVNC. The two best CNNs
(U-Net and Efficient U-Net B1) perform image segmentation in less than 0.2 s on
a CPU and in less than 0.01 s on a GPU. Additionally, a subjective evaluation
of the output images with the identified zones is performed by expert
cardiologists, with a perfect visual agreement for all the slices,
outperforming already existing automatic tools.",,,arXiv,,,2020-11-30,2020,,,,,,All OA, Green,Preprint,"Rodríguez-de-Vera, Jesús M.; González-Carrillo, Josefa; García, José M.; Bernabé, Gregorio","Rodríguez-de-Vera, Jesús M. (); González-Carrillo, Josefa (); García, José M. (); Bernabé, Gregorio ()",,"Rodríguez-de-Vera, Jesús M. (); González-Carrillo, Josefa (); García, José M. (); Bernabé, Gregorio ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1133116425,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4267,pub.1133139715,10.1148/ryai.2020200021,33937851,PMC8082330,Deep Learning–based Automated Segmentation of Left Ventricular Trabeculations and Myocardium on Cardiac MR Images: A Feasibility Study,"PURPOSE: To develop and evaluate a complete deep learning pipeline that allows fully automated end-diastolic left ventricle (LV) cardiac MRI segmentation, including trabeculations and automatic quality control of the predicted segmentation.
MATERIALS AND METHODS: This multicenter retrospective study includes training, validation, and testing datasets of 272, 27, and 150 cardiac MR images, respectively, collected between 2012 and 2018. The reference standard was the manual segmentation of four LV anatomic structures performed on end-diastolic short-axis cine cardiac MRI: LV trabeculations, LV myocardium, LV papillary muscles, and the LV blood cavity. The automatic pipeline was composed of five steps with a DenseNet architecture. Intraobserver agreement, interobserver agreement, and interaction time were recorded. The analysis includes the correlation between the manual and automated segmentation, a reproducibility comparison, and Bland-Altman plots.
RESULTS: The automated method achieved mean Dice coefficients of 0.96 ± 0.01 (standard deviation) for LV blood cavity, 0.89 ± 0.03 for LV myocardium, and 0.62 ± 0.08 for LV trabeculation (mean absolute error, 3.63 g ± 3.4). Automatic quantification of LV end-diastolic volume, LV myocardium mass, LV trabeculation, and trabeculation mass-to-total myocardial mass (TMM) ratio showed a significant correlation with the manual measures (r = 0.99, 0.99, 0.90, and 0.83, respectively; all P < .01). On a subset of 48 patients, the mean Dice value for LV trabeculation was 0.63 ± 0.10 or higher compared with the human interobserver (0.44 ± 0.09; P < .01) and intraobserver measures (0.58 ± 0.09; P < .01). Automatic quantification of the trabeculation mass-to-TMM ratio had a higher correlation (0.92) compared with the intra- and interobserver measures (0.74 and 0.39, respectively; both P < .01).
CONCLUSION: Automated deep learning framework can achieve reproducible and quality-controlled segmentation of cardiac trabeculations, outperforming inter- and intraobserver analyses.Supplemental material is available for this article.© RSNA, 2020.",convolutional neural network dense fully CNN excessive trabeculation cardiomyopathy left ventricle mean absolute error total myocardial mass,,Radiology Artificial Intelligence,,,2020-11-25,2020,2020-11-25,2021-01-01,3,1,e200021,Closed,Article,"Bartoli, Axel; Fournel, Joris; Bentatou, Zakarya; Habib, Gilbert; Lalande, Alain; Bernard, Monique; Boussel, Loïc; Pontana, François; Dacher, Jean-Nicolas; Ghattas, Badih; Jacquier, Alexis","Bartoli, Axel (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Fournel, Joris (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Bentatou, Zakarya (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Habib, Gilbert (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Lalande, Alain (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Bernard, Monique (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Boussel, Loïc (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Pontana, François (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Dacher, Jean-Nicolas (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Ghattas, Badih (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).); Jacquier, Alexis (Departments of Radiology (A.B., A.J.) and Cardiology (G.H.), Hôpital de la Timone Adultes, AP-HM, 264, rue Saint-Pierre 13385 Marseille Cedex 05, France; CRMBM-UMR CNRS 7339, Medical Faculty, Aix-Marseille University, Marseille, France (A.B., J.F., Z.B., M.B., A.J.); I2M-UMR CNRS 7373, Aix-Marseille University, Centrale Marseille, Marseille, France (J.F., B.G.); ImVia Laboratory and University Hospital of Dijon, Bourgogne-Franche Comté University, Dijon, France (A.L.); Department of Radiology, Hôpital de la Croix-Rousse, Hospices Civils de Lyon, Lyon, France (L.B.); Department of Cardiovascular Imaging, Lille University Hospital, Lille, France (F.P.); and Department of Diagnostic Imaging, Rouen University Hospital, Rouen, France (J.N.D.).)",,"Bartoli, Axel (Marseille Public University Hospital System; Aix-Marseille University); Fournel, Joris (Marseille Public University Hospital System; Aix-Marseille University); Bentatou, Zakarya (Marseille Public University Hospital System; Aix-Marseille University); Habib, Gilbert (Marseille Public University Hospital System; Aix-Marseille University); Lalande, Alain (Marseille Public University Hospital System; Aix-Marseille University); Bernard, Monique (Marseille Public University Hospital System; Aix-Marseille University); Boussel, Loïc (Marseille Public University Hospital System; Aix-Marseille University); Pontana, François (Marseille Public University Hospital System; Aix-Marseille University); Dacher, Jean-Nicolas (Marseille Public University Hospital System; Aix-Marseille University); Ghattas, Badih (Marseille Public University Hospital System; Aix-Marseille University); Jacquier, Alexis (Marseille Public University Hospital System; Aix-Marseille University)",4,4,0.2,2.82,,https://app.dimensions.ai/details/publication/pub.1133139715,32 Biomedical and Clinical Sciences, 46 Information and Computing Sciences, 4612 Software Engineering,,,,,,,,,,
5054,pub.1132843234,10.1002/mrm.28596,33226667,,Cine and late gadolinium enhancement MRI registration and automated myocardial infarct heterogeneity quantification,"PURPOSE: To develop an approach for automated quantification of myocardial infarct heterogeneity in late gadolinium enhancement (LGE) cardiac MRI.
METHODS: We acquired 2D short-axis cine and 3D LGE in 10 pigs with myocardial infarct. The 2D cine myocardium was segmented and registered to the LGE images. LGE image signal intensities within the warped cine myocardium masks were analyzed to determine the thresholds of infarct core (IC) and gray zone (GZ) for the standard-deviation (SD) and full-width-at-halfmaximum (FWHM) methods. The initial IC, GZ, and IC + GZ segmentations were postprocessed using a normalized cut approach. Cine segmentation and cine-LGE registration accuracies were evaluated using dice similarity coefficient and average symmetric surface distance. Automated IC, GZ, and IC + GZ volumes were compared with manual results using Pearson correlation coefficient (r), Bland-Altman analyses, and intraclass correlation coefficient.
RESULTS: For n = 87 slices containing scar, we achieved cine segmentation dice similarity coefficient = 0.87 ± 0.12, average symmetric surface distance = 0.94 ± 0.74 mm (epicardium), and 1.03 ± 0.82 mm (endocardium) in the scar region. For cine-LGE registration, dice similarity coefficient was 0.90 ± 0.06 and average symmetric surface distance was 0.72 ± 0.39 mm (epicardium) and 0.86 ± 0.53 mm (endocardium) in the scar region. For both SD and FWHM methods, automated IC, GZ, and IC + GZ volumes were strongly (r > 0.70) correlated with manual measurements, and the correlations were not significantly different from interobserver correlations (P > .05). The agreement between automated and manual scar volumes (intraclass correlation coefficient = 0.85-0.96) was similar to that between two observers (intraclass correlation coefficient = 0.81-0.99); automated scar segmentation errors were not significantly different from interobserver segmentation differences (P > .05).
CONCLUSIONS: Our approach provides fully automated cine-LGE MRI registration and LGE myocardial infarct heterogeneity quantification in preclinical studies.","We acknowledge the use of the facilities of Compute Canada. This work was funded by Canadian Institutes of Health Research (CIHR) MOP: #93531, Ontario Research Fund, and GE Healthcare. F.G. is supported by a Banting postdoctoral fellowship.",Funding informationThis work was funded by Canadian Institutes of Health Research (CIHR) MOP: #93531, Ontario Research Fund, and GE Healthcare. Fumin Guo is supported by a Banting postdoctoral fellowship,Magnetic Resonance in Medicine,,"Animals; Contrast Media; Gadolinium; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Myocardial Infarction; Myocardium; Reproducibility of Results; Swine",2020-11-23,2020,2020-11-23,2021-05,85,5,2842-2855,Closed,Article,"Guo, Fumin; Krahn, Philippa R. P.; Escartin, Terenz; Roifman, Idan; Wright, Graham","Guo, Fumin (Sunnybrook Research Institute, University of Toronto, Toronto, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada); Krahn, Philippa R. P. (Sunnybrook Research Institute, University of Toronto, Toronto, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada); Escartin, Terenz (Sunnybrook Research Institute, University of Toronto, Toronto, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada); Roifman, Idan (Sunnybrook Health Sciences Center, University of Toronto, Toronto, Canada); Wright, Graham (Sunnybrook Research Institute, University of Toronto, Toronto, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada)","Guo, Fumin (University of Toronto; University of Toronto)","Guo, Fumin (University of Toronto; University of Toronto); Krahn, Philippa R. P. (University of Toronto; University of Toronto); Escartin, Terenz (University of Toronto; University of Toronto); Roifman, Idan (University of Toronto; Sunnybrook Health Science Centre); Wright, Graham (University of Toronto; University of Toronto)",5,5,0.66,1.22,,https://app.dimensions.ai/details/publication/pub.1132843234,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,
4126,pub.1132730628,10.1016/j.media.2020.101907,33341496,,Test-time adaptable neural networks for robust medical image segmentation,"Convolutional Neural Networks (CNNs) work very well for supervised learning problems when the training dataset is representative of the variations expected to be encountered at test time. In medical image segmentation, this premise is violated when there is a mismatch between training and test images in terms of their acquisition details, such as the scanner model or the protocol. Remarkable performance degradation of CNNs in this scenario is well documented in the literature. To address this problem, we design the segmentation CNN as a concatenation of two sub-networks: a relatively shallow image normalization CNN, followed by a deep CNN that segments the normalized image. We train both these sub-networks using a training dataset, consisting of annotated images from a particular scanner and protocol setting. Now, at test time, we adapt the image normalization sub-network for each test image, guided by an implicit prior on the predicted segmentation labels. We employ an independently trained denoising autoencoder (DAE) in order to model such an implicit prior on plausible anatomical segmentation labels. We validate the proposed idea on multi-center Magnetic Resonance imaging datasets of three anatomies: brain, heart and prostate. The proposed test-time adaptation consistently provides performance improvement, demonstrating the promise and generality of the approach. Being agnostic to the architecture of the deep CNN, the second sub-network, the proposed design can be utilized with any segmentation network to increase robustness to variations in imaging scanners and protocols. Our code is available at: https://github.com/neerakara/test-time-adaptable-neural-networks-for-domain-generalization.","This work was supported by: 1. The Swiss Platform for Advanced Scientific Computing (PASC), that is coordinated by the Swiss National Supercomputing Centre (CSCS), 2. Clinical Research Priority Program Grant on Artificial Intelligence in Oncological Imaging Network from University of Zurich, and 3. Personalized Health and Related Technologies (PHRT), project number 222, ETH domain. We also thank NVIDIA corporation for their GPU donation.",,Medical Image Analysis,,"Brain; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Prostate",2020-11-19,2020,2020-11-19,2021-02,68,,101907,All OA, Hybrid,Article,"Karani, Neerav; Erdil, Ertunc; Chaitanya, Krishna; Konukoglu, Ender","Karani, Neerav (Biomedical Image Computing Group, ETH Zurich, Zurich 8092, Switzerland. Electronic address: nkarani@vision.ee.ethz.ch.); Erdil, Ertunc (Biomedical Image Computing Group, ETH Zurich, Zurich 8092, Switzerland.); Chaitanya, Krishna (Biomedical Image Computing Group, ETH Zurich, Zurich 8092, Switzerland.); Konukoglu, Ender (Biomedical Image Computing Group, ETH Zurich, Zurich 8092, Switzerland.)","Karani, Neerav (ETH Zurich)","Karani, Neerav (ETH Zurich); Erdil, Ertunc (ETH Zurich); Chaitanya, Krishna (ETH Zurich); Konukoglu, Ender (ETH Zurich)",59,54,3.84,,https://doi.org/10.1016/j.media.2020.101907,https://app.dimensions.ai/details/publication/pub.1132730628,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
1655,pub.1132746414,10.48550/arxiv.2011.08769,,,Anatomy Prior Based U-net for Pathology Segmentation with Attention,"Pathological area segmentation in cardiac magnetic resonance (MR) images
plays a vital role in the clinical diagnosis of cardiovascular diseases.
Because of the irregular shape and small area, pathological segmentation has
always been a challenging task. We propose an anatomy prior based framework,
which combines the U-net segmentation network with the attention technique.
Leveraging the fact that the pathology is inclusive, we propose a neighborhood
penalty strategy to gauge the inclusion relationship between the myocardium and
the myocardial infarction and no-reflow areas. This neighborhood penalty
strategy can be applied to any two labels with inclusive relationships (such as
the whole infarction and myocardium, etc.) to form a neighboring loss. The
proposed framework is evaluated on the EMIDEC dataset. Results show that our
framework is effective in pathological area segmentation.",,,arXiv,,,2020-11-17,2020,,,,,,All OA, Green,Preprint,"Zhou, Yuncheng; Zhang, Ke; Luo, Xinzhe; Wang, Sihan; Zhuang, Xiahai","Zhou, Yuncheng (); Zhang, Ke (); Luo, Xinzhe (); Wang, Sihan (); Zhuang, Xiahai ()",,"Zhou, Yuncheng (); Zhang, Ke (); Luo, Xinzhe (); Wang, Sihan (); Zhuang, Xiahai ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132746414,39 Education, 3904 Specialist Studies In Education, 46 Information and Computing Sciences,,,,,,,,,
1582,pub.1132746406,10.48550/arxiv.2011.08761,,,Recognition and standardization of cardiac MRI orientation via  multi-tasking learning and deep neural networks,"In this paper, we study the problem of imaging orientation in cardiac MRI,
and propose a framework to categorize the orientation for recognition and
standardization via deep neural networks. The method uses a new multi-tasking
strategy, where both the tasks of cardiac segmentation and orientation
recognition are simultaneously achieved. For multiple sequences and modalities
of MRI, we propose a transfer learning strategy, which adapts our proposed
model from a single modality to multiple modalities. We embed the orientation
recognition network in a Cardiac MRI Orientation Adjust Tool, i.e.,
CMRadjustNet. We implemented two versions of CMRadjustNet, including a
user-interface (UI) software, and a command-line tool. The former version
supports MRI image visualization, orientation prediction, adjustment, and
storage operations; and the latter version enables the batch operations. The
source code, neural network models and tools have been released and open via
https://zmiclab.github.io/projects.html.",,,arXiv,,,2020-11-17,2020,,,,,,All OA, Green,Preprint,"Zhang, Ke; Zhuang, Xiahai","Zhang, Ke (); Zhuang, Xiahai ()",,"Zhang, Ke (); Zhuang, Xiahai ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132746406,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1066,pub.1132746557,10.48550/arxiv.2011.08894,,,Contrastive Registration for Unsupervised Medical Image Segmentation,"Medical image segmentation is a relevant task as it serves as the first step
for several diagnosis processes, thus it is indispensable in clinical usage.
Whilst major success has been reported using supervised techniques, they assume
a large and well-representative labelled set. This is a strong assumption in
the medical domain where annotations are expensive, time-consuming, and
inherent to human bias. To address this problem, unsupervised techniques have
been proposed in the literature yet it is still an open problem due to the
difficulty of learning any transformation pattern. In this work, we present a
novel optimisation model framed into a new CNN-based contrastive registration
architecture for unsupervised medical image segmentation. The core of our
approach is to exploit image-level registration and feature-level from a
contrastive learning mechanism, to perform registration-based segmentation.
Firstly, we propose an architecture to capture the image-to-image
transformation pattern via registration for unsupervised medical image
segmentation. Secondly, we embed a contrastive learning mechanism into the
registration architecture to enhance the discriminating capacity of the network
in the feature-level. We show that our proposed technique mitigates the major
drawbacks of existing unsupervised techniques. We demonstrate, through
numerical and visual experiments, that our technique substantially outperforms
the current state-of-the-art unsupervised segmentation methods on two major
medical image datasets.",,,arXiv,,,2020-11-17,2020,,,,,,All OA, Green,Preprint,"Liu, Lihao; Aviles-Rivero, Angelica I; Schönlieb, Carola-Bibiane","Liu, Lihao (); Aviles-Rivero, Angelica I (); Schönlieb, Carola-Bibiane ()",,"Liu, Lihao (); Aviles-Rivero, Angelica I (); Schönlieb, Carola-Bibiane ()",1,1,,0.5,,https://app.dimensions.ai/details/publication/pub.1132746557,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,
1459,pub.1132685655,10.48550/arxiv.2011.07592,,,Studying Robustness of Semantic Segmentation under Domain Shift in  cardiac MRI,"Cardiac magnetic resonance imaging (cMRI) is an integral part of diagnosis in
many heart related diseases. Recently, deep neural networks have demonstrated
successful automatic segmentation, thus alleviating the burden of
time-consuming manual contouring of cardiac structures. Moreover, frameworks
such as nnU-Net provide entirely automatic model configuration to unseen
datasets enabling out-of-the-box application even by non-experts. However,
current studies commonly neglect the clinically realistic scenario, in which a
trained network is applied to data from a different domain such as deviating
scanners or imaging protocols. This potentially leads to unexpected performance
drops of deep learning models in real life applications. In this work, we
systematically study challenges and opportunities of domain transfer across
images from multiple clinical centres and scanner vendors. In order to maintain
out-of-the-box usability, we build upon a fixed U-Net architecture configured
by the nnU-net framework to investigate various data augmentation techniques
and batch normalization layers as an easy-to-customize pipeline component and
provide general guidelines on how to improve domain generalizability abilities
in existing deep learning methods. Our proposed method ranked first at the
Multi-Centre, Multi-Vendor & Multi-Disease Cardiac Image Segmentation Challenge
(M&Ms).",,,arXiv,,,2020-11-15,2020,,,,,,All OA, Green,Preprint,"Full, Peter M.; Isensee, Fabian; Jäger, Paul F.; Maier-Hein, Klaus","Full, Peter M. (); Isensee, Fabian (); Jäger, Paul F. (); Maier-Hein, Klaus ()",,"Full, Peter M. (); Isensee, Fabian (); Jäger, Paul F. (); Maier-Hein, Klaus ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132685655,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5355,pub.1132588571,10.1016/j.media.2020.101901,33285480,,Dynamic MRI reconstruction with end-to-end motion-guided network,"Temporal correlation in dynamic magnetic resonance imaging (MRI), such as cardiac MRI, is informative and important to understand motion mechanisms of body regions. Modeling such information into the MRI reconstruction process produces temporally coherent image sequence and reduces imaging artifacts and blurring. However, existing deep learning based approaches neglect motion information during the reconstruction procedure, while traditional motion-guided methods are hindered by heuristic parameter tuning and long inference time. We propose a novel dynamic MRI reconstruction approach called MODRN and an end-to-end improved version called MODRN(e2e), both of which enhance the reconstruction quality by infusing motion information into the modeling process with deep neural networks. The central idea is to decompose the motion-guided optimization problem of dynamic MRI reconstruction into three components: Dynamic Reconstruction Network, Motion Estimation and Motion Compensation. Extensive experiments have demonstrated the effectiveness of our proposed approach compared to other state-of-the-art approaches.","This work has been supported in part by the National Institutes of Health (NIH) grants 1R01HL127661-01, in part by NSF grants IIS 1703883, CNS-1747778, CCF-1733843, IIS-1763523 and IIS-1849238.",,Medical Image Analysis,,"Algorithms; Artifacts; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Motion; Neural Networks, Computer",2020-11-13,2020,2020-11-13,2021-02,68,,101901,All OA, Bronze,Article,"Huang, Qiaoying; Xian, Yikun; Yang, Dong; Qu, Hui; Yi, Jingru; Wu, Pengxiang; Metaxas, Dimitris N","Huang, Qiaoying (Department of Computer Science, Rutgers University, Piscataway, NJ 08854, USA. Electronic address: qh55@cs.rutgers.edu.); Xian, Yikun (Department of Computer Science, Rutgers University, Piscataway, NJ 08854, USA. Electronic address: yx150@cs.rutgers.edu.); Yang, Dong (NVIDIA, Bethesda, MD 20814, USA. Electronic address: don.yang.mech@gmail.com.); Qu, Hui (Department of Computer Science, Rutgers University, Piscataway, NJ 08854, USA. Electronic address: hui.qu@cs.rutgers.edu.); Yi, Jingru (Department of Computer Science, Rutgers University, Piscataway, NJ 08854, USA. Electronic address: jy486@cs.rutgers.edu.); Wu, Pengxiang (Department of Computer Science, Rutgers University, Piscataway, NJ 08854, USA. Electronic address: pw241@cs.rutgers.edu.); Metaxas, Dimitris N (Department of Computer Science, Rutgers University, Piscataway, NJ 08854, USA. Electronic address: dnm@cs.rutgers.edu.)","Huang, Qiaoying (Rutgers, The State University of New Jersey)","Huang, Qiaoying (Rutgers, The State University of New Jersey); Xian, Yikun (Rutgers, The State University of New Jersey); Yang, Dong (Nvidia (United States)); Qu, Hui (Rutgers, The State University of New Jersey); Yi, Jingru (Rutgers, The State University of New Jersey); Wu, Pengxiang (Rutgers, The State University of New Jersey); Metaxas, Dimitris N (Rutgers, The State University of New Jersey)",17,16,3.9,,https://www.sciencedirect.com/science/article/am/pii/S1361841520302656,https://app.dimensions.ai/details/publication/pub.1132588571,40 Engineering,,,,,,,,,,,
863,pub.1132685085,10.48550/arxiv.2011.07025,,,Automatic segmentation with detection of local segmentation failures in  cardiac MRI,"Segmentation of cardiac anatomical structures in cardiac magnetic resonance
images (CMRI) is a prerequisite for automatic diagnosis and prognosis of
cardiovascular diseases. To increase robustness and performance of segmentation
methods this study combines automatic segmentation and assessment of
segmentation uncertainty in CMRI to detect image regions containing local
segmentation failures. Three state-of-the-art convolutional neural networks
(CNN) were trained to automatically segment cardiac anatomical structures and
obtain two measures of predictive uncertainty: entropy and a measure derived by
MC-dropout. Thereafter, using the uncertainties another CNN was trained to
detect local segmentation failures that potentially need correction by an
expert. Finally, manual correction of the detected regions was simulated. Using
publicly available CMR scans from the MICCAI 2017 ACDC challenge, the impact of
CNN architecture and loss function for segmentation, and the uncertainty
measure was investigated. Performance was evaluated using the Dice coefficient
and 3D Hausdorff distance between manual and automatic segmentation. The
experiments reveal that combining automatic segmentation with simulated manual
correction of detected segmentation failures leads to statistically significant
performance increase.",,,arXiv,,,2020-11-13,2020,,,,,,All OA, Green,Preprint,"Sander, Jörg; de Vos, Bob D.; Išgum, Ivana","Sander, Jörg (); de Vos, Bob D. (); Išgum, Ivana ()",,"Sander, Jörg (); de Vos, Bob D. (); Išgum, Ivana ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132685085,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 51 Physical Sciences,3 Good Health and Well Being,,,,,,,
1547,pub.1133515418,10.1109/ipta50016.2020.9286633,,,Investigating CoordConv for Fully and Weakly Supervised Medical Image Segmentation,"Convolutional neural networks (CNN) have established state-of-the-art performance in computer vision tasks such as object detection and segmentation. One of the major remaining challenges concerns their ability to capture consistent spatial attributes, especially in medical image segmentation. A way to address this issue is through integrating localization prior into system architecture. The CoordConv layers are extensions of convolutional neural network wherein convolution is conditioned on spatial coordinates. This paper investigates CoordConv as a proficient substitute to convolutional layers for organ segmentation in both fully and weakly supervised settings. Experiments are conducted on two public datasets, SegTHOR, which focuses on the segmentation of thoracic organs at risk in computed tomography (CT) images, and ACDC, which addresses ventricular endocardium segmentation of the heart in MR images. We show that if CoordConv does not significantly increase the accuracy with respect to standard convolution, it may interestingly increase model convergence at almost no additional computational cost.",,,,"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)",,2020-11-12,2020,,2020-11-12,0,,1-5,All OA, Green,Proceeding,"Jurdi, Rosana El; Dargent, Thomas; Petitjean, Caroline; Honeine, Paul; Abdallah, Fahed","Jurdi, Rosana El (LITIS Lab, Université de Rouen Normandie, Rouen, France; Lebanese University, Beirut, Lebanon); Dargent, Thomas (LITIS Lab, Université de Rouen Normandie, Rouen, France); Petitjean, Caroline (LITIS Lab, Université de Rouen Normandie, Rouen, France); Honeine, Paul (LITIS Lab, Université de Rouen Normandie, Rouen, France); Abdallah, Fahed (Lebanese University, Beirut, Lebanon)","Jurdi, Rosana El (University of Rouen; Lebanese University)","Jurdi, Rosana El (University of Rouen; Lebanese University); Dargent, Thomas (University of Rouen); Petitjean, Caroline (University of Rouen); Honeine, Paul (University of Rouen); Abdallah, Fahed (Lebanese University)",3,3,,1.55,https://hal-normandie-univ.archives-ouvertes.fr/hal-03088385/file/20.ipta.coordconv.pdf,https://app.dimensions.ai/details/publication/pub.1133515418,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
3833,pub.1132498815,10.1016/j.media.2020.101891,33260108,,Automated left ventricular segmentation from cardiac magnetic resonance images via adversarial learning with multi-stage pose estimation network and co-discriminator,"Left ventricular (LV) segmentation is essential for the early diagnosis of cardiovascular diseases, which has been reported as the leading cause of death all over the world. However, automated LV segmentation from cardiac magnetic resonance images (CMRI) using the traditional convolutional neural networks (CNNs) is still a challenging task due to the limited labeled CMRI data and low tolerances to irregular scales, shapes and deformations of LV. In this paper, we propose an automated LV segmentation method based on adversarial learning by integrating a multi-stage pose estimation network (MSPN) and a co-discrimination network. Different from existing CNNs, we use a MSPN with multi-scale dilated convolution (MDC) modules to enhance the ranges of receptive field for deep feature extraction. To fully utilize both labeled and unlabeled CMRI data, we propose a novel generative adversarial network (GAN) framework for LV segmentation by combining MSPN with co-discrimination networks. Specifically, the labeled CMRI are first used to initialize our segmentation network (MSPN) and co-discrimination network. Our GAN training includes two different kinds of epochs fed with both labeled and unlabeled CMRI data alternatively, which are different from the traditional CNNs only relied on the limited labeled samples to train the segmentation networks. As both ground truth and unlabeled samples are involved in guiding training, our method not only can converge faster but also obtain a better performance in LV segmentation. Our method is evaluated using MICCAI 2009 and 2017 challenge databases. Experimental results show that our method has obtained promising performance in LV segmentation, which also outperforms the state-of-the-art methods in terms of LV segmentation accuracy from the comparison results.","This work was supported partly by National Natural Science Foundation of China (Nos. 61973221, 61871274, 61801305, 61872351 and 62071309), the Natural Science Foundation of Guangdong Province, China (Nos. 2018A030313381 and 2019A1515011165), the Shenzhen Research Foundation for Basic Research, Major Project or Key Lab, China (Nos. JCYJ20160608173051207, JCYJ20180507184647636, ZDSYS201707311550233, KJYY201807031540021294, JCYJ20190808155618806 and JSGG2018 05081520220065), the COVID-19 Prevention Project of Guangdong Province, China (No. 2020KZDZX1174), the Major Project of the New Generation of Artificial Intelligence (No. 2018AAA0102900), International Science and Technology Cooperation Projects of Guangdong (No. 2019A050510030), and Shenzhen Peacock Plan (No. KQTD2016053112051497).",,Medical Image Analysis,,"Heart; Heart Ventricles; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer",2020-11-11,2020,2020-11-11,2021-02,68,,101891,Closed,Article,"Wu, Huisi; Lu, Xuheng; Lei, Baiying; Wen, Zhenkun","Wu, Huisi (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China, 518060.); Lu, Xuheng (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China, 518060.); Lei, Baiying (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China, 518060. Electronic address: leiby@szu.edu.cn.); Wen, Zhenkun (College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China, 518060.)","Lei, Baiying ","Wu, Huisi (Shenzhen University); Lu, Xuheng (Shenzhen University); Lei, Baiying (); Wen, Zhenkun (Shenzhen University)",14,14,2.26,,,https://app.dimensions.ai/details/publication/pub.1132498815,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
1727,pub.1132296161,10.1007/978-3-030-62743-0_9,,,Theoretical Research on College Students’ Professional Literacy Design Based on Deep Learning,"University is a critical period for cultivating college students’ professional qualities, and counselors’ guidance to college students during this period is very important. This article mainly studies the theory of professional literacy design for college students based on deep learning. Based on the status quo of college students’ professional literacy in China, this article analyzes the necessity of cultivating college students’ professional literacy, and proposes some strategies on how counselors can cultivate college students’ professional literacy, with a view to helping college students’ professional literacy improve. The research results in this article show that the average score of “influence” competency is only 2.48, and there is a huge gap between competences with a score of 4 and above, and only 29.41% of students achieve a competency of 4 or more. The average score of “interpersonal insight” competency is 3.79, which is closer to 4 competences, and the proportion of students who reach 4 or above is 79.59%. The “interpersonal competence” professionalism is in the four competence features. The large gap indicates that there is a serious imbalance in the interpersonal communication ability of local college students, that is, the “influence” competence of local college students is seriously insufficient, and the proportion of college students with organizational leadership in professional positions is low.",,,Advances in Intelligent Systems and Computing,The 2020 International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy,,2020-11-04,2020,2020-11-04,2021,1282,,63-68,Closed,Chapter,"Huang, Longquan","Huang, Longquan (Guangdong Polytechnic of Science and Trade, 510430, Guangzhou, Guangdong, China)","Huang, Longquan ","Huang, Longquan ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132296161,39 Education, 3901 Curriculum and Pedagogy, 52 Psychology,,,,,,,,,,
1014,pub.1132298326,10.48550/arxiv.2011.01741,,,Learning a Generative Motion Model from Image Sequences based on a  Latent Motion Matrix,"We propose to learn a probabilistic motion model from a sequence of images
for spatio-temporal registration. Our model encodes motion in a low-dimensional
probabilistic space - the motion matrix - which enables various motion analysis
tasks such as simulation and interpolation of realistic motion patterns
allowing for faster data acquisition and data augmentation. More precisely, the
motion matrix allows to transport the recovered motion from one subject to
another simulating for example a pathological motion in a healthy subject
without the need for inter-subject registration. The method is based on a
conditional latent variable model that is trained using amortized variational
inference. This unsupervised generative model follows a novel multivariate
Gaussian process prior and is applied within a temporal convolutional network
which leads to a diffeomorphic motion model. Temporal consistency and
generalizability is further improved by applying a temporal dropout training
scheme. Applied to cardiac cine-MRI sequences, we show improved registration
accuracy and spatio-temporally smoother deformations compared to three
state-of-the-art registration algorithms. Besides, we demonstrate the model's
applicability for motion analysis, simulation and super-resolution by an
improved motion reconstruction from sequences with missing frames compared to
linear and cubic interpolation.",,,arXiv,,,2020-11-03,2020,,,,,,All OA, Green,Preprint,"Krebs, Julian; Delingette, Hervé; Ayache, Nicholas; Mansi, Tommaso","Krebs, Julian (); Delingette, Hervé (); Ayache, Nicholas (); Mansi, Tommaso ()",,"Krebs, Julian (); Delingette, Hervé (); Ayache, Nicholas (); Mansi, Tommaso ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132298326,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1213,pub.1133595532,10.1145/3400302.3415789,,,Towards cardiac intervention assistance,"Real-time cardiac magnetic resonance imaging (MRI) plays an increasingly important role in guiding various cardiac interventions. In order to provide better visual assistance, the cine MRI frames need to be segmented on-the-fly to avoid noticeable visual lag. In addition, considering reliability and patient data privacy, the computation is preferably done on local hardware. State-of-the-art MRI segmentation methods mostly focus on accuracy only, and can hardly be adopted for real-time application or on local hardware. In this work, we present the first hardware-aware multi-scale neural architecture search (NAS) framework for real-time 3D cardiac cine MRI segmentation. The proposed framework incorporates a latency regularization term into the loss function to handle realtime constraints, with the consideration of underlying hardware. In addition, the formulation is fully differentiable with respect to the architecture parameters, so that stochastic gradient descent (SGD) can be used for optimization to reduce the computation cost while maintaining optimization quality. Experimental results on ACDC MICCAI 2017 dataset demonstrate that our hardware-aware multi-scale NAS framework can reduce the latency by up to 3.5 and satisfy the real-time constraints, while still achieving competitive segmentation accuracy, compared with the state-of-the-art NAS segmentation framework.",,,,Proceedings of the 39th International Conference on Computer-Aided Design,,2020-11-02,2020,2020-12-17,2020-11-02,,,1-8,Closed,Proceeding,"Zeng, Dewen; Jiang, Weiwen; Wang, Tianchen; Xu, Xiaowei; Yuan, Haiyun; Huang, Meiping; Zhuang, Jian; Hu, Jingtong; Shi, Yiyu","Zeng, Dewen (University of Notre Dame); Jiang, Weiwen (University of Notre Dame); Wang, Tianchen (University of Notre Dame); Xu, Xiaowei (Guangdong Cardiovascular Institute); Yuan, Haiyun (Guangdong Cardiovascular Institute); Huang, Meiping (Guangdong Cardiovascular Institute); Zhuang, Jian (Guangdong Cardiovascular Institute); Hu, Jingtong (University of Pittsburgh); Shi, Yiyu (University of Notre Dame)",,"Zeng, Dewen (University of Notre Dame); Jiang, Weiwen (University of Notre Dame); Wang, Tianchen (University of Notre Dame); Xu, Xiaowei (); Yuan, Haiyun (); Huang, Meiping (); Zhuang, Jian (); Hu, Jingtong (University of Pittsburgh); Shi, Yiyu (University of Notre Dame)",5,5,,2.58,,https://app.dimensions.ai/details/publication/pub.1133595532,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
953,pub.1132271368,10.48550/arxiv.2011.00325,,,Self-paced and self-consistent co-training for semi-supervised image  segmentation,"Deep co-training has recently been proposed as an effective approach for
image segmentation when annotated data is scarce. In this paper, we improve
existing approaches for semi-supervised segmentation with a self-paced and
self-consistent co-training method. To help distillate information from
unlabeled images, we first design a self-paced learning strategy for
co-training that lets jointly-trained neural networks focus on
easier-to-segment regions first, and then gradually consider harder ones.This
is achieved via an end-to-end differentiable loss inthe form of a generalized
Jensen Shannon Divergence(JSD). Moreover, to encourage predictions from
different networks to be both consistent and confident, we enhance this
generalized JSD loss with an uncertainty regularizer based on entropy. The
robustness of individual models is further improved using a self-ensembling
loss that enforces their prediction to be consistent across different training
iterations. We demonstrate the potential of our method on three challenging
image segmentation problems with different image modalities, using small
fraction of labeled data. Results show clear advantages in terms of performance
compared to the standard co-training baselines and recently proposed
state-of-the-art approaches for semi-supervised segmentation",,,arXiv,,,2020-10-31,2020,,,,,,All OA, Green,Preprint,"Wang, Ping; Peng, Jizong; Pedersoli, Marco; Zhou, Yuanfeng; Zhang, Caiming; Desrosiers, Christian","Wang, Ping (); Peng, Jizong (); Pedersoli, Marco (); Zhou, Yuanfeng (); Zhang, Caiming (); Desrosiers, Christian ()",,"Wang, Ping (); Peng, Jizong (); Pedersoli, Marco (); Zhou, Yuanfeng (); Zhang, Caiming (); Desrosiers, Christian ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132271368,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5332,pub.1128564796,10.1109/tmi.2020.3003240,32746116,,Cardiac Segmentation With Strong Anatomical Guarantees,"Convolutional neural networks (CNN) have had unprecedented success in medical imaging and, in particular, in medical image segmentation. However, despite the fact that segmentation results are closer than ever to the inter-expert variability, CNNs are not immune to producing anatomically inaccurate segmentations, even when built upon a shape prior. In this paper, we present a framework for producing cardiac image segmentation maps that are guaranteed to respect pre-defined anatomical criteria, while remaining within the inter-expert variability. The idea behind our method is to use a well-trained CNN, have it process cardiac images, identify the anatomically implausible results and warp these results toward the closest anatomically valid cardiac shape. This warping procedure is carried out with a constrained variational autoencoder (cVAE) trained to learn a representation of valid cardiac shapes through a smooth, yet constrained, latent space. With this cVAE, we can project any implausible shape into the cardiac latent space and steer it toward the closest correct shape. We tested our framework on short-axis MRI as well as apical two and four-chamber view ultrasound images, two modalities for which cardiac shapes are drastically different. With our method, CNNs can now produce results that are both within the inter-expert variability and always anatomically plausible without having to rely on a shape prior.","This work was supported in part by the NSERC Discovery Grants’ program, and in part by the NSERC Canada Graduate Scholarships-Master’s program and a CIFRE grant (French National Association of Research and Technology) for CASIS under Grant N 2017/1663. The authors had access to computing resources from Compute Canada.",,IEEE Transactions on Medical Imaging,,"Heart; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Ultrasonography",2020-10-28,2020,2020-10-28,2020-11,39,11,3703-3713,All OA, Green,Article,"Painchaud, Nathan; Skandarani, Youssef; Judge, Thierry; Bernard, Olivier; Lalande, Alain; Jodoin, Pierre-Marc","Painchaud, Nathan (Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, J1K 2R1, Canada); Skandarani, Youssef (ImVIA Laboratory, University Bourgogne Franche-Comté, 21078, Dijon, France; CASIS, 21000, Dijon, France); Judge, Thierry (Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, J1K 2R1, Canada); Bernard, Olivier (Univ Lyon, INSA-Lyon, Université Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1206, 69621, Lyon, France); Lalande, Alain (ImVIA Laboratory, University Bourgogne Franche-Comté, 21078, Dijon, France); Jodoin, Pierre-Marc (Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, J1K 2R1, Canada)","Painchaud, Nathan (Université de Sherbrooke)","Painchaud, Nathan (Université de Sherbrooke); Skandarani, Youssef (Université Bourgogne Franche-Comté); Judge, Thierry (Université de Sherbrooke); Bernard, Olivier (Institut National des Sciences Appliquées de Lyon); Lalande, Alain (Université Bourgogne Franche-Comté); Jodoin, Pierre-Marc (Université de Sherbrooke)",52,50,4.07,31.58,http://arxiv.org/pdf/2006.08825,https://app.dimensions.ai/details/publication/pub.1128564796,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1550,pub.1132062375,10.1007/978-3-030-62324-1_5,,,Segmentation of Left Ventricle in Short-Axis MR Images Based on Fully Convolutional Network and Active Contour Model,"Left ventricle (LV) segmentation from cardiac MRI images plays an important role in clinical diagnosis of the LV function. In this study, we proposed a new approach for left ventricle segmentation based on deep neural network and active contour model (ACM). The paper proposed a coarse-to-fine segmentation framework. In the first step of the framework, the fully convolutional network was employed to achieve coarse segmentation of LV from input cardiac MR images. Especially, instead of using cross entropy loss function, we propose to utilize Tversky loss that is known to be suitable for the unbalance data-an issue in medical images, to train the network. The coarse segmentation in the first step is then used to create initial curves for ACM. Finally, active contour model was performed to further optimize the energy functional in order to get fine segmentation of LV. Comparative experiments with other state of the arts on ACDCA and Sunnybrook challenge databases, in terms of Dice coefficient and Jaccard indexes, show the advantages of the proposed approach.",This research is funded by Vietnam National Foundation for Science and Technology Development (NAFOSTED) under grant number 102.05-2018.302.,,Advances in Intelligent Systems and Computing,Computational Intelligence Methods for Green Technology and Sustainable Development,,2020-10-28,2020,2020-10-28,2021,1284,,49-59,Closed,Chapter,"Tran, Tien Thanh; Tran, Thi-Thao; Ninh, Quoc Cuong; Bui, Minh Duc; Pham, Van-Truong","Tran, Tien Thanh (School of Electrical Engineering, Hanoi University of Science and Technology, No. 1 Dai Co Viet, Hanoi, Vietnam); Tran, Thi-Thao (School of Electrical Engineering, Hanoi University of Science and Technology, No. 1 Dai Co Viet, Hanoi, Vietnam); Ninh, Quoc Cuong (School of Electrical Engineering, Hanoi University of Science and Technology, No. 1 Dai Co Viet, Hanoi, Vietnam); Bui, Minh Duc (School of Electrical Engineering, Hanoi University of Science and Technology, No. 1 Dai Co Viet, Hanoi, Vietnam); Pham, Van-Truong (School of Electrical Engineering, Hanoi University of Science and Technology, No. 1 Dai Co Viet, Hanoi, Vietnam)","Pham, Van-Truong (Hanoi University of Science and Technology)","Tran, Tien Thanh (Hanoi University of Science and Technology); Tran, Thi-Thao (Hanoi University of Science and Technology); Ninh, Quoc Cuong (Hanoi University of Science and Technology); Bui, Minh Duc (Hanoi University of Science and Technology); Pham, Van-Truong (Hanoi University of Science and Technology)",4,4,,0.98,,https://app.dimensions.ai/details/publication/pub.1132062375,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,,
1546,pub.1133592234,10.1109/bibe50027.2020.00177,,,PSPU-Net for Automatic Short Axis Cine MRI Segmentation of Left and Right Ventricles,"Characterization of the heart anatomy and function is mostly done with magnetic resonance image cine series. To achieve a correct characterization, the volume of the right and left ventricle need to be segmented, which is a timeconsuming task. We propose a new convolutional neural network architecture that combines U-net with PSP modules (PSPU-net) for the segmentation of left and right ventricle cavities and left ventricle myocardium in the diastolic frame of short-axis cine MRI images and compare its results against a classic 3D U-net architecture. We used a dataset containing 399 cases in total. The results showed higher quality results in both segmentation and final volume estimation for a test set of 99 cases in the case of the PSPU-net, with global dice metrics of 0.910 and median absolute relative errors in volume estimations of 0.026 and 0.039 for the left ventricle cavity and myocardium and 0.051 for the right ventricles cavity.","Conselleria d’Educaciό, Investigaciό, Cultura i Esport, and Agencia Valenciana de la Innovaciόn, Generalitat Valenciana. Centro para el Desarrollo Tecnolόgico Industrial, Spanish Ministerio de Ciencia, Innovaciόn y Universidades DM acknowledges financial support from the Conselleria d’Educaciό, Investigaciό, Cultura i Esport, Generalitat Valenciana (grants AEST/2019/037 and AEST/2020/029), from the Agencia Valenciana de la Innovaciόn, Generalitat Valenciana (ref. INNCAD00/19/085), and from the Centro para el Desarrollo Tecnolόgico Industrial (Programa Eurostars-2, actuaciόn Interempresas Internacional), Spanish Ministerio de Ciencia, Innovaciόn y Universidades (ref. CIIP- 20192020). We are grateful to Andrés Larroza for his valuable technical assistance in the project.",,,2020 IEEE 20th International Conference on Bioinformatics and Bioengineering (BIBE),,2020-10-28,2020,,2020-10-28,0,,1048-1053,All OA, Green,Proceeding,"Pérez-Pelegrí, Manuel; Monmeneu, José V.; Lόpez-Lereu, María P.; Ruiz-España, Silvia; Del-Canto, Irene; Bodí, Vicente; Moratal, David","Pérez-Pelegrí, Manuel (Center for Biomaterials and Tissue Engineering, Universitat Politècnica de València, Valencia, Spain); Monmeneu, José V. (Unidad de Imagen Cardíaca ERESA-ASCIRES Grupo Biomédico, Valencia, Spain); Lόpez-Lereu, María P. (Unidad de Imagen Cardíaca ERESA-ASCIRES Grupo Biomédico, Valencia, Spain); Ruiz-España, Silvia (Center for Biomaterials and Tissue Engineering, Universitat Politècnica de València, Valencia, Spain); Del-Canto, Irene (Center for Biomaterials and Tissue Engineering, Universitat Politècnica de València, Valencia, Spain); Bodí, Vicente (Department of Medicine, Universitat de València, Valencia, Spain); Moratal, David (Center for Biomaterials and Tissue Engineering, Universitat Politècnica de València, Valencia, Spain)","Pérez-Pelegrí, Manuel (Universitat Politècnica de València)","Pérez-Pelegrí, Manuel (Universitat Politècnica de València); Monmeneu, José V. (); Lόpez-Lereu, María P. (); Ruiz-España, Silvia (Universitat Politècnica de València); Del-Canto, Irene (Universitat Politècnica de València); Bodí, Vicente (University of Valencia); Moratal, David (Universitat Politècnica de València)",4,4,,1.96,https://riunet.upv.es/bitstream/10251/177794/3/Perez-PelegriMonmeneuLopez-Lereu%20-%20PSPU-Net%20for%20Automatic%20Short%20Axis%20Cine%20MRI%20Segmentation%20of%20Lef....pdf,https://app.dimensions.ai/details/publication/pub.1133592234,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1066,pub.1132158618,10.48550/arxiv.2010.14091,,,Triple-view Convolutional Neural Networks for COVID-19 Diagnosis with  Chest X-ray,"The Coronavirus Disease 2019 (COVID-19) is affecting increasingly large
number of people worldwide, posing significant stress to the health care
systems. Early and accurate diagnosis of COVID-19 is critical in screening of
infected patients and breaking the person-to-person transmission. Chest X-ray
(CXR) based computer-aided diagnosis of COVID-19 using deep learning becomes a
promising solution to this end. However, the diverse and various radiographic
features of COVID-19 make it challenging, especially when considering each CXR
scan typically only generates one single image. Data scarcity is another issue
since collecting large-scale medical CXR data set could be difficult at
present. Therefore, how to extract more informative and relevant features from
the limited samples available becomes essential. To address these issues,
unlike traditional methods processing each CXR image from a single view, this
paper proposes triple-view convolutional neural networks for COVID-19 diagnosis
with CXR images. Specifically, the proposed networks extract individual
features from three views of each CXR image, i.e., the left lung view, the
right lung view and the overall view, in three streams and then integrate them
for joint diagnosis. The proposed network structure respects the anatomical
structure of human lungs and is well aligned with clinical diagnosis of
COVID-19 in practice. In addition, the labeling of the views does not require
experts' domain knowledge, which is needed by many existing methods. The
experimental results show that the proposed method achieves state-of-the-art
performance, especially in the more challenging three class classification
task, and admits wide generality and high flexibility.",,,arXiv,,,2020-10-27,2020,,,,,,All OA, Green,Preprint,"Zhang, Jianjia","Zhang, Jianjia ()",,"Zhang, Jianjia ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132158618,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,
1652,pub.1132066534,10.48550/arxiv.2010.13172,,,Unsupervised Super-Resolution: Creating High-Resolution Medical Images  from Low-Resolution Anisotropic Examples,"Although high resolution isotropic 3D medical images are desired in clinical
practice, their acquisition is not always feasible. Instead, lower resolution
images are upsampled to higher resolution using conventional interpolation
methods. Sophisticated learning-based super-resolution approaches are
frequently unavailable in clinical setting, because such methods require
training with high-resolution isotropic examples. To address this issue, we
propose a learning-based super-resolution approach that can be trained using
solely anisotropic images, i.e. without high-resolution ground truth data. The
method exploits the latent space, generated by autoencoders trained on
anisotropic images, to increase spatial resolution in low-resolution images.
The method was trained and evaluated using 100 publicly available cardiac cine
MR scans from the Automated Cardiac Diagnosis Challenge (ACDC). The
quantitative results show that the proposed method performs better than
conventional interpolation methods. Furthermore, the qualitative results
indicate that especially finer cardiac structures are synthesized with high
quality. The method has the potential to be applied to other anatomies and
modalities and can be easily applied to any 3D anisotropic medical image
dataset.",,,arXiv,,,2020-10-25,2020,,,,,,All OA, Green,Preprint,"Sander, Jörg; de Vos, Bob D.; Išgum, Ivana","Sander, Jörg (); de Vos, Bob D. (); Išgum, Ivana ()",,"Sander, Jörg (); de Vos, Bob D. (); Išgum, Ivana ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132066534,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,
5598,pub.1131951382,10.1148/ryai.2020200009,33330849,PMC7706884,Automated Inline Analysis of Myocardial Perfusion MRI with Deep Learning,"PURPOSE: To develop a deep neural network-based computational workflow for inline myocardial perfusion analysis that automatically delineates the myocardium, which improves the clinical workflow and offers a ""one-click"" solution.
MATERIALS AND METHODS: In this retrospective study, consecutive adenosine stress and rest perfusion scans were acquired from three hospitals between October 1, 2018 and February 27, 2019. The training and validation set included 1825 perfusion series from 1034 patients (mean age, 60.6 years ± 14.2 [standard deviation]). The independent test set included 200 scans from 105 patients (mean age, 59.1 years ± 12.5). A convolutional neural network (CNN) model was trained to segment the left ventricular cavity, myocardium, and right ventricle by processing an incoming time series of perfusion images. Model outputs were compared with manual ground truth for accuracy of segmentation and flow measures derived on a global and per-sector basis with t test performed for statistical significance. The trained models were integrated onto MR scanners for effective inference.
RESULTS: The mean Dice ratio of automatic and manual segmentation was 0.93 ± 0.04. The CNN performed similarly to manual segmentation and flow measures for mean stress myocardial blood flow (MBF; 2.25 mL/min/g ± 0.59 vs 2.24 mL/min/g ± 0.59, P = .94) and mean rest MBF (1.08 mL/min/g ± 0.23 vs 1.07 mL/min/g ± 0.23, P = .83). The per-sector MBF values showed no difference between the CNN and manual assessment (P = .92). A central processing unit-based model inference on the MR scanner took less than 1 second for a typical perfusion scan of three slices.
CONCLUSION: The described CNN was capable of cardiac perfusion mapping and integrated an automated inline implementation on the MR scanner, enabling one-click analysis and reporting in a manner comparable to manual assessment. Supplemental material is available for this article. © RSNA, 2020.",American Heart Association confidence interval convolutional neural network left ventricle myocardial blood flow right ventricle two-dimensional,,Radiology Artificial Intelligence,,,2020-10-21,2020,2020-10-21,2020-11-01,2,6,e200009,All OA, Green,Article,"Xue, Hui; Davies, Rhodri H.; Brown, Louise A. E.; Knott, Kristopher D.; Kotecha, Tushar; Fontana, Marianna; Plein, Sven; Moon, James C.; Kellman, Peter","Xue, Hui (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Davies, Rhodri H. (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Brown, Louise A. E. (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Knott, Kristopher D. (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Kotecha, Tushar (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Fontana, Marianna (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Plein, Sven (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Moon, James C. (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).); Kellman, Peter (From the National Heart, Lung and Blood Institute, National Institutes of Health, 10 Center Dr, Bethesda, MD 20892 (H.X., P.K.); Barts Heart Centre, Barts Health NHS Trust, London, England (R.H.D., K.D.K., J.C.M.); Department of Biomedical Imaging Science, Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (L.A.E.B., S.P.); and National Amyloidosis Centre, Royal Free Hospital, London, England (T.K., M.F.).)","Xue, Hui (National Institutes of Health)","Xue, Hui (National Institutes of Health); Davies, Rhodri H. (National Institutes of Health); Brown, Louise A. E. (National Institutes of Health); Knott, Kristopher D. (National Institutes of Health); Kotecha, Tushar (National Institutes of Health); Fontana, Marianna (National Institutes of Health); Plein, Sven (National Institutes of Health); Moon, James C. (National Institutes of Health); Kellman, Peter (National Institutes of Health)",21,18,2.04,10.3,http://arxiv.org/pdf/1911.00625,https://app.dimensions.ai/details/publication/pub.1131951382,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1613,pub.1134788809,10.1145/3434780.3436652,,,A platform for management and visualization of medical data and medical imaging,"The application of artificial intelligence algorithms to medical data has gained relevance over the years. These algorithms can enable disease detection, image segmentation, assessment of organ functions, among other research tasks. However, to effectively apply and benefit from artificial intelligence in this context, it is important to tackle the heterogeneity and diversity of data structures and data sources. For these reasons, it is important to rely on information systems that unify data found in medical domains. This work outlines the features of an online platform that allow different roles to upload, process and research on structured medical data and medical imaging.",,,,Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality,,2020-10-21,2020,2021-01-22,2020-10-21,,,518-522,Closed,Proceeding,"Vázquez-Ingelmo, Andrea; Sampedro-Gómez, Jesús; Sánchez-Puente, Antonio; Vicente-Palacios, Víctor; Dorado-Díaz, P. Ignacio; Sanchez, Pedro L.; García-Peñalvo, Francisco José","Vázquez-Ingelmo, Andrea (University of Salamanca, Spain); Sampedro-Gómez, Jesús (Hospital Universitario de Salamanca - SACyL. IBSAL USAL and CIBERCV (ISCiii), Spain); Sánchez-Puente, Antonio (Hospital Universitario de Salamanca - SACyL. IBSAL USAL and CIBERCV (ISCiii), Spain); Vicente-Palacios, Víctor (Philips Healthcare, Spain); Dorado-Díaz, P. Ignacio (Hospital Universitario de Salamanca - SACyL. IBSAL USAL and CIBERCV (ISCiii), Spain); Sanchez, Pedro L. (Hospital Universitario de Salamanca - SACyL. IBSAL USAL and CIBERCV (ISCiii), Spain); García-Peñalvo, Francisco José (University of Salamanca, Spain)",,"Vázquez-Ingelmo, Andrea (University of Salamanca); Sampedro-Gómez, Jesús (Complejo Hospitalario de Salamanca); Sánchez-Puente, Antonio (Complejo Hospitalario de Salamanca); Vicente-Palacios, Víctor (); Dorado-Díaz, P. Ignacio (Complejo Hospitalario de Salamanca); Sanchez, Pedro L. (Complejo Hospitalario de Salamanca); García-Peñalvo, Francisco José (University of Salamanca)",1,1,,0.46,,https://app.dimensions.ai/details/publication/pub.1134788809,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science,,,,,,,,,,
4028,pub.1131793126,10.1016/j.media.2020.101832,33166776,,A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging,"Segmentation of medical images, particularly late gadolinium-enhanced magnetic resonance imaging (LGE-MRI) used for visualizing diseased atrial structures, is a crucial first step for ablation treatment of atrial fibrillation. However, direct segmentation of LGE-MRIs is challenging due to the varying intensities caused by contrast agents. Since most clinical studies have relied on manual, labor-intensive approaches, automatic methods are of high interest, particularly optimized machine learning approaches. To address this, we organized the 2018 Left Atrium Segmentation Challenge using 154 3D LGE-MRIs, currently the world's largest atrial LGE-MRI dataset, and associated labels of the left atrium segmented by three medical experts, ultimately attracting the participation of 27 international teams. In this paper, extensive analysis of the submitted algorithms using technical and biological metrics was performed by undergoing subgroup analysis and conducting hyper-parameter analysis, offering an overall picture of the major design choices of convolutional neural networks (CNNs) and practical considerations for achieving state-of-the-art left atrium segmentation. Results show that the top method achieved a Dice score of 93.2% and a mean surface to surface distance of 0.7 mm, significantly outperforming prior state-of-the-art. Particularly, our analysis demonstrated that double sequentially used CNNs, in which a first CNN is used for automatic region-of-interest localization and a subsequent CNN is used for refined regional segmentation, achieved superior results than traditional methods and machine learning approaches containing single CNNs. This large-scale benchmarking study makes a significant step towards much-improved segmentation methods for atrial LGE-MRIs, and will serve as an important benchmark for evaluating and comparing the future works in the field. Furthermore, the findings from this study can potentially be extended to other imaging datasets and modalities, having an impact on the wider medical imaging community.","The authors would like to thank Nvidia, MedTech CoRE New Zealand, and Arterys for providing prizes for the winners of the 2018 LA Segmentation Challenge. Z.X. and J.Z. are grateful for Nvidia for donating Titan-X Pascal GPU for algorithm development and testing, and the NIH/NIGMS Center for Integrative Biomedical Computing (CIBC) at the University of Utah for providing the LGE-MRI dataset. This work was funded by the Health Research Council of New Zealand [#16/385].",,Medical Image Analysis,,Algorithms, Benchmarking, Gadolinium, Heart Atria, Humans, Magnetic Resonance Imaging,2020-10-16,2020,2020-10-16,2021-01,67,,101832,All OA, Green,Article,"Xiong, Zhaohan; Xia, Qing; Hu, Zhiqiang; Huang, Ning; Bian, Cheng; Zheng, Yefeng; Vesal, Sulaiman; Ravikumar, Nishant; Maier, Andreas; Yang, Xin; Heng, Pheng-Ann; Ni, Dong; Li, Caizi; Tong, Qianqian; Si, Weixin; Puybareau, Elodie; Khoudli, Younes; Géraud, Thierry; Chen, Chen; Bai, Wenjia; Rueckert, Daniel; Xu, Lingchao; Zhuang, Xiahai; Luo, Xinzhe; Jia, Shuman; Sermesant, Maxime; Liu, Yashu; Wang, Kuanquan; Borra, Davide; Masci, Alessandro; Corsi, Cristiana; de Vente, Coen; Veta, Mitko; Karim, Rashed; Preetha, Chandrakanth Jayachandran; Engelhardt, Sandy; Qiao, Menyun; Wang, Yuanyuan; Tao, Qian; Nuñez-Garcia, Marta; Camara, Oscar; Savioli, Nicolo; Lamata, Pablo; Zhao, Jichao","Xiong, Zhaohan (Auckland Bioengineering Institute, University of Auckland, Auckland, New Zealand.); Xia, Qing (State Key Lab of Virtual Reality Technology and Systems, Beihang University, Beijing, China.); Hu, Zhiqiang (School of Electronics Engineering and Computer Science, Peking University, Beijing, China.); Huang, Ning (SenseTime Inc, Shenzhen, China.); Bian, Cheng (Tencent Jarvis Laboratory, Shenzhen, China.); Zheng, Yefeng (Tencent Jarvis Laboratory, Shenzhen, China.); Vesal, Sulaiman (Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.); Ravikumar, Nishant (Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.); Maier, Andreas (Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.); Yang, Xin (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.); Heng, Pheng-Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.); Ni, Dong (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China.); Li, Caizi (School of Computer Science, Wuhan University, Wuhan, China.); Tong, Qianqian (School of Computer Science, Wuhan University, Wuhan, China.); Si, Weixin (Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China.); Puybareau, Elodie (EPITA Research and Development Laboratory, Paris, France.); Khoudli, Younes (EPITA Research and Development Laboratory, Paris, France.); Géraud, Thierry (EPITA Research and Development Laboratory, Paris, France.); Chen, Chen (Department of Computing, Imperial College London, London, United Kingdom.); Bai, Wenjia (Department of Computing, Imperial College London, London, United Kingdom.); Rueckert, Daniel (Department of Computing, Imperial College London, London, United Kingdom.); Xu, Lingchao (School of Naval Architecture, Ocean & Civil Engineering, Shanghai Jiao Tong University, Shanghai, China.); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China.); Luo, Xinzhe (School of Data Science, Fudan University, Shanghai, China.); Jia, Shuman (Inria, Université Côte d'Azur, Epione team, Sophia Antipolis, France.); Sermesant, Maxime (Inria, Université Côte d'Azur, Epione team, Sophia Antipolis, France.); Liu, Yashu (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Wang, Kuanquan (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Borra, Davide (Department of Electric, Electronic and Information Engineering, University of Bologna, Cesena, Italy.); Masci, Alessandro (Department of Electric, Electronic and Information Engineering, University of Bologna, Cesena, Italy.); Corsi, Cristiana (Department of Electric, Electronic and Information Engineering, University of Bologna, Cesena, Italy.); de Vente, Coen (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, the Netherlands.); Veta, Mitko (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, the Netherlands.); Karim, Rashed (School of Biomedical Engineering & Imaging Sciences, Kings College London, London, United Kingdom.); Preetha, Chandrakanth Jayachandran (Faculty of Electrical Engineering and Information Technology, University of Magdeburg, Magdeburg, Germany.); Engelhardt, Sandy (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Germany.); Qiao, Menyun (Biomedical Engineering Center, Fudan University, Shanghai, China.); Wang, Yuanyuan (Biomedical Engineering Center, Fudan University, Shanghai, China.); Tao, Qian (Department of Radiology, Leiden University Medical Center, Leiden, the Netherlands.); Nuñez-Garcia, Marta (Physense, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain.); Camara, Oscar (Physense, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain.); Savioli, Nicolo (Department of Bioengineering, Kings College London, London, United Kingdom.); Lamata, Pablo (Department of Bioengineering, Kings College London, London, United Kingdom.); Zhao, Jichao (Auckland Bioengineering Institute, University of Auckland, Auckland, New Zealand. Electronic address: j.zhao@auckland.ac.nz.)","Zhao, Jichao (University of Auckland)","Xiong, Zhaohan (University of Auckland); Xia, Qing (Beihang University); Hu, Zhiqiang (Peking University); Huang, Ning (); Bian, Cheng (); Zheng, Yefeng (); Vesal, Sulaiman (University of Erlangen-Nuremberg); Ravikumar, Nishant (University of Erlangen-Nuremberg); Maier, Andreas (University of Erlangen-Nuremberg); Yang, Xin (Chinese University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong); Ni, Dong (Shenzhen University); Li, Caizi (Wuhan University); Tong, Qianqian (Wuhan University); Si, Weixin (Shenzhen Institutes of Advanced Technology); Puybareau, Elodie (Graduate School of Computer Science and Advanced Technologies); Khoudli, Younes (Graduate School of Computer Science and Advanced Technologies); Géraud, Thierry (Graduate School of Computer Science and Advanced Technologies); Chen, Chen (Imperial College London); Bai, Wenjia (Imperial College London); Rueckert, Daniel (Imperial College London); Xu, Lingchao (Shanghai Jiao Tong University); Zhuang, Xiahai (Fudan University); Luo, Xinzhe (Fudan University); Jia, Shuman (); Sermesant, Maxime (); Liu, Yashu (Harbin Institute of Technology); Wang, Kuanquan (Harbin Institute of Technology); Borra, Davide (University of Bologna); Masci, Alessandro (University of Bologna); Corsi, Cristiana (University of Bologna); de Vente, Coen (Eindhoven University of Technology); Veta, Mitko (Eindhoven University of Technology); Karim, Rashed (King's College London); Preetha, Chandrakanth Jayachandran (Otto-von-Guericke University Magdeburg); Engelhardt, Sandy (University Hospital Heidelberg); Qiao, Menyun (Fudan University); Wang, Yuanyuan (Fudan University); Tao, Qian (Leiden University Medical Center); Nuñez-Garcia, Marta (Pompeu Fabra University); Camara, Oscar (Pompeu Fabra University); Savioli, Nicolo (King's College London); Lamata, Pablo (King's College London); Zhao, Jichao (University of Auckland)",77,76,11.17,37.75,https://scholarlypublications.universiteitleiden.nl/access/item%3A3307719/view,https://app.dimensions.ai/details/publication/pub.1131793126,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,
1255,pub.1131674006,10.48550/arxiv.2010.06163,,,Bridging 2D and 3D Segmentation Networks for Computation Efficient  Volumetric Medical Image Segmentation: An Empirical Study of 2.5D Solutions,"Recently, deep convolutional neural networks have achieved great success for
medical image segmentation. However, unlike segmentation of natural images,
most medical images such as MRI and CT are volumetric data. In order to make
full use of volumetric information, 3D CNNs are widely used. However, 3D CNNs
suffer from higher inference time and computation cost, which hinders their
further clinical applications. Additionally, with the increased number of
parameters, the risk of overfitting is higher, especially for medical images
where data and annotations are expensive to acquire. To issue this problem,
many 2.5D segmentation methods have been proposed to make use of volumetric
spatial information with less computation cost. Despite these works lead to
improvements on a variety of segmentation tasks, to the best of our knowledge,
there has not previously been a large-scale empirical comparison of these
methods. In this paper, we aim to present a review of the latest developments
of 2.5D methods for volumetric medical image segmentation. Additionally, to
compare the performance and effectiveness of these methods, we provide an
empirical study of these methods on three representative segmentation tasks
involving different modalities and targets. Our experimental results highlight
that 3D CNNs may not always be the best choice. Despite all these 2.5D methods
can bring performance gains to 2D baseline, not all the methods hold the
benefits on different datasets. We hope the results and conclusions of our
study will prove useful for the community on exploring and developing efficient
volumetric medical image segmentation methods.",,,arXiv,,,2020-10-13,2020,,,,,,All OA, Green,Preprint,"Zhang, Yichi; Liao, Qingcheng; Ding, Le; Zhang, Jicong","Zhang, Yichi (); Liao, Qingcheng (); Ding, Le (); Zhang, Jicong ()",,"Zhang, Yichi (); Liao, Qingcheng (); Ding, Le (); Zhang, Jicong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1131674006,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1649,pub.1133226974,10.1109/icitee49829.2020.9271750,,,Recent Trends of Left and Right Ventricle Segmentation in Cardiac MRI Using Deep Learning,"Clinical indications of heart disease are shown from left ventricle (LV) or right ventricle (RV) volume measurements of cardiac MRI images. LV and RV segmentation of cardiac MRI images can detect and measure image volume. Public dataset MICCAI, ACDC, Kaggle, and SCD provide data on MRI images of cardiac that have been widely used by researchers. The deep learning method approach can optimally solve problems in analyzing heart disease from cardiac MRI images. The aim of this paper is to determine the availability of public datasets that are appropriate for the research objectives. It can support the optimization of the segmentation method for LV and RV images of cardiac as the contribution of this paper. The results of the study are that the public dataset (MICCAI, ACDC, Kaggle, and SCD) provides sufficient data for the identification, classification, and measurement of LV and RV volumes. Furthermore, a deep learning approach with convolutional neural networks can detect and classify heart diseases with high accuracy.",,,,2020 12th International Conference on Information Technology and Electrical Engineering (ICITEE),,2020-10-08,2020,,2020-10-08,0,,380-383,Closed,Proceeding,"Irmawati, Dessy; Wahyunggoro, Oyas; Soesanti, Indah","Irmawati, Dessy (Electrical Engineering Department, Universitas Gadjah Mada, Yogyakarta, Indonesia; Electronics and Informatics Engineering Education, Universitas Negeri Yogyakarta, Yogyakarta, Indonesia); Wahyunggoro, Oyas (Electrical Engineering Department, Universitas Gadjah Mada, Yogyakarta, Indonesia); Soesanti, Indah (Electrical Engineering Department, Universitas Gadjah Mada, Yogyakarta, Indonesia)","Irmawati, Dessy (Gadjah Mada University; Yogyakarta State University)","Irmawati, Dessy (Gadjah Mada University; Yogyakarta State University); Wahyunggoro, Oyas (Gadjah Mada University); Soesanti, Indah (Gadjah Mada University)",3,3,,1.94,,https://app.dimensions.ai/details/publication/pub.1133226974,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 46 Information and Computing Sciences,,,,,,,,,,
4548,pub.1131366074,10.1016/j.media.2020.101812,33129140,,Recovering from missing data in population imaging – Cardiac MR image imputation via conditional generative adversarial nets,"Accurate ventricular volume measurements are the primary indicators of normal/abnor- mal cardiac function and are dependent on the Cardiac Magnetic Resonance (CMR) volumes being complete. However, missing or unusable slices owing to the presence of image artefacts such as respiratory or motion ghosting, aliasing, ringing and signal loss in CMR sequences, significantly hinder accuracy of anatomical and functional cardiac quantification, and recovering from those is insufficiently addressed in population imaging. In this work, we propose a new robust approach, coined Image Imputation Generative Adversarial Network (I2-GAN), to learn key features of cardiac short axis (SAX) slices near missing information, and use them as conditional variables to infer missing slices in the query volumes. In I2-GAN, the slices are first mapped to latent vectors with position features through a regression net. The latent vector corresponding to the desired position is then projected onto the slice manifold, conditioned on intensity features through a generator net. The generator comprises residual blocks with normalisation layers that are modulated with auxiliary slice information, enabling propagation of fine details through the network. In addition, a multi-scale discriminator was implemented, along with a discriminator-based feature matching loss, to further enhance performance and encourage the synthesis of visually realistic slices. Experimental results show that our method achieves significant improvements over the state-of-the-art, in missing slice imputation for CMR, with an average SSIM of 0.872. Linear regression analysis yields good agreement between reference and imputed CMR images for all cardiac measurements, with correlation coefficients of 0.991 for left ventricular volume, 0.977 for left ventricular mass and 0.961 for right ventricular volume.","This research has been conducted using the UK Biobank Resource under Applications 11,350 and 2964. The CMR images presented in Figs. 1,2, 4, 5, 7–9 and 15 in the manuscript were reproduced with the permission of UK Biobank©. The authors are grateful to all UK Biobank participants and staff. AFF acknowledges support from the Royal Academy of Engineering Chair in Emerging Technologies Scheme (CiET1819/19), EPSRC-funded Grow MedTech CardioX (POC041), and the MedIAN Network (EP/N026993/1) funded by the Engineering and Physical Sciences Research Council (EPSRC). SKP and SN acknowledge the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre based at The Oxford University Hospitals Trust at the University of Oxford, and the British Heart Foundation Centre of Research Excellence. SEP acknowledges support from the NIHR Barts Biomedical Research Centre and from the SmartHeart EPSRC Programme Grant (EP/P0010 09/1).",,Medical Image Analysis,,"Artifacts; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging",2020-10-02,2020,2020-10-02,2021-01,67,,101812,All OA, Green,Article,"Xia, Yan; Zhang, Le; Ravikumar, Nishant; Attar, Rahman; Piechnik, Stefan K; Neubauer, Stefan; Petersen, Steffen E; Frangi, Alejandro F","Xia, Yan (Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, UK; Leeds Institute for Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, UK. Electronic address: y.xia@leeds.ac.uk.); Zhang, Le (Queen Square Institute of Neurology, University College London, London, UK; Centre for Medical Image Computing, Department of Computer Science, University College London, London, UK.); Ravikumar, Nishant (Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, UK; Leeds Institute for Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, UK.); Attar, Rahman (Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, UK; Leeds Institute for Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, UK.); Piechnik, Stefan K (Oxford Center for Clinical Magnetic Resonance Research (OCMR), Division of Cardiovascular Medicine, John Radcliffe Hospital, University of Oxford, Oxford, UK.); Neubauer, Stefan (Oxford Center for Clinical Magnetic Resonance Research (OCMR), Division of Cardiovascular Medicine, John Radcliffe Hospital, University of Oxford, Oxford, UK.); Petersen, Steffen E (William Harvey Research Institute, Barts Heart Centre, Barts Health NHS Trust, Queen Mary University of London, London, UK.); Frangi, Alejandro F (Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, UK; Leeds Institute for Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, UK; Medical Imaging Research Center (MIRC), University Hospital Gasthuisberg, and Cardiovascular Science and Electronic Engineering Departments, KU Leuven, Leuven, Belgium. Electronic address: a.frangi@leeds.ac.uk.)","Xia, Yan (University of Leeds)","Xia, Yan (University of Leeds); Zhang, Le (University College London); Ravikumar, Nishant (University of Leeds); Attar, Rahman (University of Leeds); Piechnik, Stefan K (University of Oxford; John Radcliffe Hospital); Neubauer, Stefan (University of Oxford; John Radcliffe Hospital); Petersen, Steffen E (Queen Mary University of London); Frangi, Alejandro F (University of Leeds; Universitair Ziekenhuis Leuven; KU Leuven)",13,13,2.45,,https://eprints.whiterose.ac.uk/176404/1/medima-I2.pdf,https://app.dimensions.ai/details/publication/pub.1131366074,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
3630,pub.1131264175,10.1016/j.rec.2020.06.036,33008773,,Big data and new information technology: what cardiologists need to know,"Technological progress in medicine is constantly garnering pace, requiring that physicians constantly update their knowledge. The new wave of technologies breaking through into clinical practice includes the following: a) mHealth, which allows constant monitoring of biological parameters, anytime, anyplace, of hundreds of patients at the same time; b) artificial intelligence, which, powered by new deep learning techniques, are starting to beat human experts at their own game: diagnosis by imaging or electrocardiography; c) 3-dimensional printing, which may lead to patient-specific prostheses; d) systems medicine, which has arisen from big data, and which will open the way to personalized medicine by bringing together genetic, epigenetic, environmental, clinical and social data into complex integral mathematical models to design highly personalized therapies. This state-of-the-art review aims to summarize in a single document the most recent and most important technological trends that are being applied to cardiology, and to provide an overall view that will allow readers to discern at a glance the direction of cardiology in the next few years.","We would like to acknowledge Dr Alfredo Redondo, cardiologist at the Clinical Hospital of Valladolid and manager of the VAL 3D Lab, for providing some of the images that illustrate this article.",,Revista Española de Cardiología (English Edition),,Artificial Intelligence, Big Data, Cardiologists, Cardiology, Diagnostic Imaging, Humans,2020-09-29,2020,2020-09-29,2021-01,74,1,81-89,Closed,Article,"Baladrón, Carlos; Gómez de Diego, José Juan; Amat-Santos, Ignacio J","Baladrón, Carlos (Instituto de Ciencias del Corazón (ICICOR), Hospital Clínico Universitario, Valladolid, Spain; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Spain.); Gómez de Diego, José Juan (Servicio de Cardiología, Hospital Clínico Universitario San Carlos, Madrid, Spain.); Amat-Santos, Ignacio J (Instituto de Ciencias del Corazón (ICICOR), Hospital Clínico Universitario, Valladolid, Spain; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Spain. Electronic address: ijamat@gmail.com.)","Amat-Santos, Ignacio J (Hospital Clínico Universitario de Valladolid; Centro de Investigación Biomédica en Red)","Baladrón, Carlos (Hospital Clínico Universitario de Valladolid; Centro de Investigación Biomédica en Red); Gómez de Diego, José Juan (Hospital Clínico San Carlos); Amat-Santos, Ignacio J (Hospital Clínico Universitario de Valladolid; Centro de Investigación Biomédica en Red)",9,9,2.12,3.83,,https://app.dimensions.ai/details/publication/pub.1131264175,32 Biomedical and Clinical Sciences, 46 Information and Computing Sciences, 4605 Data Management and Data Science,3 Good Health and Well Being,,,,
1454,pub.1131363019,10.1007/978-3-030-59710-8_65,,,Realistic Adversarial Data Augmentation for MR Image Segmentation,"Neural network-based approaches can achieve high accuracy in various medical image segmentation tasks. However, they generally require large labelled datasets for supervised learning. Acquiring and manually labelling a large medical dataset is expensive and sometimes impractical due to data sharing and privacy issues. In this work, we propose an adversarial data augmentation method for training neural networks for medical image segmentation. Instead of generating pixel-wise adversarial attacks, our model generates plausible and realistic signal corruptions, which models the intensity inhomogeneities caused by a common type of artefacts in MR imaging: bias field. The proposed method does not rely on generative networks, and can be used as a plug-in module for general segmentation networks in both supervised and semi-supervised learning. Using cardiac MR imaging we show that such an approach can improve the generalization ability and robustness of models as well as provide significant improvements in low-data scenarios.",This work was supported by the SmartHeart EPSRC Programme Grant(EP/P001009/1) and the EPSRC Programme Grant (EP/R005982/1).,,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2020,,2020-09-29,2020,2020-09-29,2020,12261,,667-677,All OA, Green,Chapter,"Chen, Chen; Qin, Chen; Qiu, Huaqi; Ouyang, Cheng; Wang, Shuo; Chen, Liang; Tarroni, Giacomo; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Qin, Chen (BioMedIA Group, Department of Computing, Imperial College London, London, UK; Institute for Digital Communications, University of Edinburgh, Edinburgh, UK); Qiu, Huaqi (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Ouyang, Cheng (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Wang, Shuo (Data Science Institute, Imperial College London, London, UK); Chen, Liang (BioMedIA Group, Department of Computing, Imperial College London, London, UK; Department of Brain Sciences, Imperial College London, London, UK); Tarroni, Giacomo (BioMedIA Group, Department of Computing, Imperial College London, London, UK; CitAI Research Centre, Department of Computer Science, City, University of London, London, UK); Bai, Wenjia (Data Science Institute, Imperial College London, London, UK; Department of Brain Sciences, Imperial College London, London, UK); Rueckert, Daniel (BioMedIA Group, Department of Computing, Imperial College London, London, UK)","Chen, Chen (Imperial College London)","Chen, Chen (Imperial College London); Qin, Chen (Imperial College London; University of Edinburgh); Qiu, Huaqi (Imperial College London); Ouyang, Cheng (Imperial College London); Wang, Shuo (Imperial College London); Chen, Liang (Imperial College London; Imperial College London); Tarroni, Giacomo (Imperial College London; University of London); Bai, Wenjia (Imperial College London; Imperial College London); Rueckert, Daniel (Imperial College London)",37,33,,19.07,https://openaccess.city.ac.uk/id/eprint/24425/1/2006.13322v1.pdf,https://app.dimensions.ai/details/publication/pub.1131363019,46 Information and Computing Sciences, 4611 Machine Learning,"16 Peace, Justice and Strong Institutions",,,,,,,,,
1400,pub.1131398366,10.1007/978-3-030-59719-1_13,,,XCAT-GAN for Synthesizing 3D Consistent Labeled Cardiac MR Images on Anatomically Variable XCAT Phantoms,"Generative adversarial networks (GANs) have provided promising data enrichment solutions by synthesizing high-fidelity images. However, generating large sets of labeled images with new anatomical variations remains unexplored. We propose a novel method for synthesizing cardiac magnetic resonance (CMR) images on a population of virtual subjects with a large anatomical variation, introduced using the 4D eXtended Cardiac and Torso (XCAT) computerized human phantom. We investigate two conditional image synthesis approaches grounded on a semantically-consistent mask-guided image generation technique: 4-class and 8-class XCAT-GANs. The 4-class technique relies on only the annotations of the heart; while the 8-class technique employs a predicted multi-tissue label map of the heart-surrounding organs and provides better guidance for our conditional image synthesis. For both techniques, we train our conditional XCAT-GAN with real images paired with corresponding labels and subsequently at the inference time, we substitute the labels with the XCAT derived ones. Therefore, the trained network accurately transfers the tissue-specific textures to the new label maps. By creating 33 virtual subjects of synthetic CMR images at the end-diastolic and end-systolic phases, we evaluate the usefulness of such data in the downstream cardiac cavity segmentation task under different augmentation strategies. Results demonstrate that even with only 20% of real images (40 volumes) seen during training, segmentation performance is retained with the addition of synthetic CMR images. Moreover, the improvement in utilizing synthetic images for augmenting the real data is evident through the reduction of Hausdorff distance up to 28% and an increase in the Dice score up to 5%, indicating a higher similarity to the ground truth in all dimensions.","This research is a part of the openGTN project, supported by the European Union in the Marie Curie Innovative Training Networks (ITN) fellowship program under project No. 764465.",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2020,,2020-09-29,2020,2020-09-29,2020,12264,,128-137,All OA, Green,Chapter,"Amirrajab, Sina; Abbasi-Sureshjani, Samaneh; Al Khalil, Yasmina; Lorenz, Cristian; Weese, Jürgen; Pluim, Josien; Breeuwer, Marcel","Amirrajab, Sina (Eindhoven University of Technology, Eindhoven, The Netherlands); Abbasi-Sureshjani, Samaneh (Eindhoven University of Technology, Eindhoven, The Netherlands); Al Khalil, Yasmina (Eindhoven University of Technology, Eindhoven, The Netherlands); Lorenz, Cristian (Philips Research Laboratories, Hamburg, Germany); Weese, Jürgen (Philips Research Laboratories, Hamburg, Germany); Pluim, Josien (Eindhoven University of Technology, Eindhoven, The Netherlands); Breeuwer, Marcel (Eindhoven University of Technology, Eindhoven, The Netherlands; Philips Healthcare, MR R&D - Clinical Science, Best, The Netherlands)","Amirrajab, Sina (Eindhoven University of Technology)","Amirrajab, Sina (Eindhoven University of Technology); Abbasi-Sureshjani, Samaneh (Eindhoven University of Technology); Al Khalil, Yasmina (Eindhoven University of Technology); Lorenz, Cristian (Philips (Germany)); Weese, Jürgen (Philips (Germany)); Pluim, Josien (Eindhoven University of Technology); Breeuwer, Marcel (Eindhoven University of Technology; Philips (Netherlands))",16,16,,9.72,http://arxiv.org/pdf/2007.13408,https://app.dimensions.ai/details/publication/pub.1131398366,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1396,pub.1131103036,10.1007/978-3-030-59520-3_8,,,Heterogeneous Virtual Population of Simulated CMR Images for Improving the Generalization of Cardiac Segmentation Algorithms,"Simulating a large set of medical images with variability in anatomical representation and image appearance has the potential to provide solutions for addressing the scarcity of properly annotated data in medical image analysis research. However, due to the complexity of modeling the imaging procedure and lack of accuracy and flexibility in anatomical models, available solutions in this area are limited. In this paper, we investigate the feasibility of simulating diversified cardiac magnetic resonance (CMR) images on virtual male and female subjects of the eXtended Cardiac and Torso phantoms (XCAT) with variable anatomical representation. Taking advantage of the flexibility of the XCAT phantoms, we create virtual subjects comprising different body sizes, heart volumes, and orientations to account for natural variability among patients. To resemble inherent image quality and contrast variability in data, we vary acquisition parameters together with MR tissue properties to simulate diverse-looking images. The database includes 3240 CMR images of 30 male and 30 female subjects. To assess the usefulness of such data, we train a segmentation model with the simulated images and fine-tune it on a small subset of real data. Our experiment results show that we can reduce the number of real data by almost 80\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\%$$\end{document} while retaining the accuracy of the prediction using models pre-trained on simulated images, as well as achieve a better performance in terms of generalization to varying contrast. Thus, our simulated database serves as a promising solution to address the current challenges in medical imaging and could aid the inclusion of automated solutions in clinical routines.","This research is a part of the openGTN project, supported by the European Union in the Marie Curie Innovative Training Networks (ITN) fellowship program under project No. 764465.",,Lecture Notes in Computer Science,Simulation and Synthesis in Medical Imaging,,2020-09-23,2020,2020-09-23,2020,12417,,68-79,Closed,Chapter,"Al Khalil, Yasmina; Amirrajab, Sina; Lorenz, Cristian; Weese, Jürgen; Breeuwer, Marcel","Al Khalil, Yasmina (Eindhoven University of Technology, Eindhoven, The Netherlands); Amirrajab, Sina (Eindhoven University of Technology, Eindhoven, The Netherlands); Lorenz, Cristian (Philips Research Laboratories, Hamburg, Germany); Weese, Jürgen (Philips Research Laboratories, Hamburg, Germany); Breeuwer, Marcel (Eindhoven University of Technology, Eindhoven, The Netherlands; Philips Healthcare, MR R&D - Clinical Science, Best, The Netherlands)","Al Khalil, Yasmina (Eindhoven University of Technology)","Al Khalil, Yasmina (Eindhoven University of Technology); Amirrajab, Sina (Eindhoven University of Technology); Lorenz, Cristian (Philips (Germany)); Weese, Jürgen (Philips (Germany)); Breeuwer, Marcel (Eindhoven University of Technology; Philips (Netherlands))",1,1,,0.48,,https://app.dimensions.ai/details/publication/pub.1131103036,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,,
3817,pub.1130931788,10.1007/s11547-020-01277-w,32946002,,Artificial intelligence in cardiac radiology,"Artificial intelligence (AI) is entering the clinical arena, and in the early stage, its implementation will be focused on the automatization tasks, improving diagnostic accuracy and reducing reading time. Many studies investigate the potential role of AI to support cardiac radiologist in their day-to-day tasks, assisting in segmentation, quantification, and reporting tasks. In addition, AI algorithms can be also utilized to optimize image reconstruction and image quality. Since these algorithms will play an important role in the field of cardiac radiology, it is increasingly important for radiologists to be familiar with the potential applications of AI.
The main focus of this article is to provide an overview of cardiac-related AI applications for CT and MRI studies, as well as non-imaging-based applications for reporting and image optimization.",,,La radiologia medica,,"Algorithms; Artificial Intelligence; Coronary Artery Disease; Coronary Stenosis; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Prognosis; Radiology; Vascular Calcification; Workflow",2020-09-18,2020,2020-09-18,2020-11,125,11,1186-1199,Closed,Article,"van Assen, Marly; Muscogiuri, Giuseppe; Caruso, Damiano; Lee, Scott J.; Laghi, Andrea; De Cecco, Carlo N.","van Assen, Marly (Division of Cardiothoracic Imaging, Department of Radiology and Imaging Sciences, Emory University Hospital | Emory Healthcare, Inc., 1365 Clifton Road NE, Suite - AT503, 30322, Atlanta, GA, USA); Muscogiuri, Giuseppe (Department of Imaging, Centro Cardiologico Monzino, IRCCS, Milan, Italy); Caruso, Damiano (Dipartimento di Scienze Medico Chirurgiche e Medicina Traslazionale, Universita degli Studi Roma La Sapienza, Rome, Italy); Lee, Scott J. (Division of Cardiothoracic Imaging, Department of Radiology and Imaging Sciences, Emory University Hospital | Emory Healthcare, Inc., 1365 Clifton Road NE, Suite - AT503, 30322, Atlanta, GA, USA); Laghi, Andrea (Dipartimento di Scienze Medico Chirurgiche e Medicina Traslazionale, Universita degli Studi Roma La Sapienza, Rome, Italy); De Cecco, Carlo N. (Division of Cardiothoracic Imaging, Department of Radiology and Imaging Sciences, Emory University Hospital | Emory Healthcare, Inc., 1365 Clifton Road NE, Suite - AT503, 30322, Atlanta, GA, USA)","De Cecco, Carlo N. (Emory University Hospital)","van Assen, Marly (Emory University Hospital); Muscogiuri, Giuseppe (Centro Cardiologico Monzino); Caruso, Damiano (Sapienza University of Rome); Lee, Scott J. (Emory University Hospital); Laghi, Andrea (Sapienza University of Rome); De Cecco, Carlo N. (Emory University Hospital)",41,40,5.0,20.1,,https://app.dimensions.ai/details/publication/pub.1130931788,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,,
4837,pub.1130757735,10.1007/s11886-020-01402-1,32910325,,Artificial Intelligence and Texture Analysis in Cardiac Imaging,"Purpose of ReviewThe aim of this structured review is to summarize the current research applications and opportunities arising from artificial intelligence (AI) and texture analysis with regard to cardiac imaging.Recent FindingsCurrent research findings suggest tremendous potential for AI in cardiac imaging, especially with regard to objective image analyses, overcoming the limitations of an observer-dependent subjective image interpretation. Researchers have used this technique across multiple imaging modalities, for instance to detect myocardial scars in cardiac MR imaging, to predict contrast enhancement in non-contrast studies, and to improve image acquisition and reconstruction.SummaryAI in medical imaging has the potential to provide novel, much-needed applications for improving patient care pertaining to the cardiovascular system. While several shortcomings are still present in the current methodology, AI may serve as a resourceful assistant to radiologists and clinicians alike.",,,Current Cardiology Reports,,"Artificial Intelligence; Cardiac Imaging Techniques; Heart; Humans; Image Processing, Computer-Assisted; Radiography",2020-09-10,2020,2020-09-10,2020-11,22,11,131,Closed,Article,"Mannil, Manoj; Eberhard, Matthias; von Spiczak, Jochen; Heindel, Walter; Alkadhi, Hatem; Baessler, Bettina","Mannil, Manoj (Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Zurich, Switzerland; University Clinic for Radiology, Westfälische Wilhelms-University Muenster and University Hospital Muenster, Albert-Schweitzer-Campus 1, DE-48149, Muenster, Germany); Eberhard, Matthias (Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Zurich, Switzerland); von Spiczak, Jochen (Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Zurich, Switzerland); Heindel, Walter (University Clinic for Radiology, Westfälische Wilhelms-University Muenster and University Hospital Muenster, Albert-Schweitzer-Campus 1, DE-48149, Muenster, Germany); Alkadhi, Hatem (Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Zurich, Switzerland); Baessler, Bettina (Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Zurich, Switzerland)","Mannil, Manoj (University Hospital of Zurich; University of Zurich; University Hospital Münster; University of Münster)","Mannil, Manoj (University Hospital of Zurich; University of Zurich; University Hospital Münster; University of Münster); Eberhard, Matthias (University Hospital of Zurich; University of Zurich); von Spiczak, Jochen (University Hospital of Zurich; University of Zurich); Heindel, Walter (University Hospital Münster; University of Münster); Alkadhi, Hatem (University Hospital of Zurich; University of Zurich); Baessler, Bettina (University Hospital of Zurich; University of Zurich)",16,16,1.63,7.84,,https://app.dimensions.ai/details/publication/pub.1130757735,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,,
4791,pub.1128666281,10.5603/cj.a2020.0087,32567669,PMC8016001,Artificial intelligence and automation in valvular heart diseases,"Artificial intelligence (AI) is gradually changing every aspect of social life, and healthcare is no exception. The clinical procedures that were supposed to, and could previously only be handled by human experts can now be carried out by machines in a more accurate and efficient way. The coming era of big data and the advent of supercomputers provides great opportunities to the development of AI technology for the enhancement of diagnosis and clinical decision-making. This review provides an introduction to AI and highlights its applications in the clinical flow of diagnosing and treating valvular heart diseases (VHDs). More specifically, this review first introduces some key concepts and subareas in AI. Secondly, it discusses the application of AI in heart sound auscultation and medical image analysis for assistance in diagnosing VHDs. Thirdly, it introduces using AI algorithms to identify risk factors and predict mortality of cardiac surgery. This review also describes the state-of-the-art autonomous surgical robots and their roles in cardiac surgery and intervention.",,,Cardiology Journal,,Algorithms, Artificial Intelligence, Automation, Cardiac Surgical Procedures, Heart Valve Diseases, Humans,2020-09-10,2020,2020-09-10,2020,27,4,404-420,All OA, Gold,Article,"Long, Qiang; Ye, Xiaofeng; Zhao, Qiang","Long, Qiang (Department of Cardiac Surgery,Ruijin Hospital affiliated to School of Medicine, Shanghai Jiao Tong University, China. longqiang@sjtu.edu.cn.); Ye, Xiaofeng (Department of Cardiac Surgery,Ruijin Hospital affiliated to School of Medicine, Shanghai Jiao Tong University, China.); Zhao, Qiang (Department of Cardiac Surgery,Ruijin Hospital affiliated to School of Medicine, Shanghai Jiao Tong University, China.)",,"Long, Qiang (Shanghai Jiao Tong University); Ye, Xiaofeng (Shanghai Jiao Tong University); Zhao, Qiang (Shanghai Jiao Tong University)",3,3,0.26,1.47,https://journals.viamedica.pl/cardiology_journal/article/download/CJ.a2020.0087/51156,https://app.dimensions.ai/details/publication/pub.1128666281,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,3 Good Health and Well Being,,,,
1693,pub.1130574061,10.1007/978-3-030-55789-8_41,,,Left Ventricle Segmentation Using Scale-Independent Multi-Gate UNET in MRI Images,"Left ventricle (LV) segmentation is crucial to assess left ventricle global function. U-Net; a Convolutional Neural Network (CNN); boosted the performance of many biomedical image segmentation tasks. In LV segmentation, U-Net suffered from accurately extracting small objects such as the apical short-axis slices. In this paper, we propose a fully automated left ventricle segmentation method for both short-axis and long-axis views. The proposed model utilizes U-Net architecture and Multi-Gate input block to enhance the performance by aggregating multi-scale features and adding different vision scopes providing a more robust model against scale variance of objects within the images. The proposed approach was validated against left ventricle segmentation challenge (LVSC) and Automated cardiac diagnosis challenge (ACDC). For LV myocardium segmentation, the proposed approach achieved mean dice index 82% on LVSC and 90% and 91% for end-diastole (ED) and end-systole (ES) time frames respectively on ACDC outperforming other published methods measurements at ED. For LV blood pool segmentation, mean dice index was 97% and 92.3% for the ED and ES time frames using ACDC, outperforming other methods’ ED measurements.",,,Lecture Notes in Computer Science,Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices,,2020-09-04,2020,2020-09-04,2020,12144,,470-477,Closed,Chapter,"Saber, Mina; Abdelrauof, Dina; Elattar, Mustafa","Saber, Mina (Research and Development Division, Intixel Co. S.A.E., Cairo, Egypt); Abdelrauof, Dina (Research and Development Division, Intixel Co. S.A.E., Cairo, Egypt); Elattar, Mustafa (Medical Imaging and Image Processing Group, Information Technology and Computer Science School, Nile University, Giza, Egypt)","Saber, Mina ; Abdelrauof, Dina ; Elattar, Mustafa (Nile University)","Saber, Mina (); Abdelrauof, Dina (); Elattar, Mustafa (Nile University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1130574061,46 Information and Computing Sciences,,,,,,,,,,,,
1141,pub.1130631734,10.3390/math8091511,,,Feasibility of Automatic Seed Generation Applied to Cardiac MRI Image Analysis,"We present a method of using interactive image segmentation algorithms to reduce specific image segmentation problems to the task of finding small sets of pixels identifying the regions of interest. To this end, we empirically show the feasibility of automatically generating seeds for GrowCut, a popular interactive image segmentation algorithm. The principal contribution of our paper is the proposal of a method for automating the seed generation method for the task of whole-heart segmentation of MRI scans, which achieves competitive unsupervised results (0.76 Dice on the MMWHS dataset). Moreover, we show that segmentation performance is robust to seeds with imperfect precision, suggesting that GrowCut-like algorithms can be applied to medical imaging tasks with little modeling effort.","We thank Loredana Popa for providing the manual cardiac segmentations for the imATFIB dataset, Simona Manole for validating them, and Silviu Alin Ianc and Cristina Szabo for their technical assistance in imATFIB data acquisition.","The authors highly acknowledge the financial support from the Competitiveness Operational Programme 2014-2020 POC-A1-A1.1.4-E-2015, financed under the European Regional Development Fund, Project Number P37_245.",Mathematics,,,2020-09-04,2020,2020-09-04,,8,9,1511,All OA, Gold,Article,"Mărginean, Radu; Andreica, Anca; Dioşan, Laura; Bálint, Zoltán","Mărginean, Radu (IMOGEN Research Institute, County Clinical Emergency Hospital, 400006 Cluj-Napoca, Romania;, anca@cs.ubbcluj.ro, (A.A.);, lauras@cs.ubbcluj.ro, (L.D.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.)); Andreica, Anca (IMOGEN Research Institute, County Clinical Emergency Hospital, 400006 Cluj-Napoca, Romania;, anca@cs.ubbcluj.ro, (A.A.);, lauras@cs.ubbcluj.ro, (L.D.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.); Faculty of Mathematics and Computer Science, Babeş–Bolyai University, 400084 Cluj-Napoca, Romania); Dioşan, Laura (IMOGEN Research Institute, County Clinical Emergency Hospital, 400006 Cluj-Napoca, Romania;, anca@cs.ubbcluj.ro, (A.A.);, lauras@cs.ubbcluj.ro, (L.D.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.); Faculty of Mathematics and Computer Science, Babeş–Bolyai University, 400084 Cluj-Napoca, Romania); Bálint, Zoltán (IMOGEN Research Institute, County Clinical Emergency Hospital, 400006 Cluj-Napoca, Romania;, anca@cs.ubbcluj.ro, (A.A.);, lauras@cs.ubbcluj.ro, (L.D.);, zoltan.balint@phys.ubbcluj.ro, (Z.B.); Faculty of Physics, Babeş–Bolyai University, 400084 Cluj-Napoca, Romania)","Mărginean, Radu (; )","Mărginean, Radu (); Andreica, Anca (Babeș-Bolyai University); Dioşan, Laura (Babeș-Bolyai University); Bálint, Zoltán (Babeș-Bolyai University)",5,2,,,https://www.mdpi.com/2227-7390/8/9/1511/pdf?version=1599218650,https://app.dimensions.ai/details/publication/pub.1130631734,49 Mathematical Sciences,,,,,,,,,,,
5331,pub.1130512303,10.1161/jaha.120.016612,32873121,PMC7726968,Fully Automated Cardiac Assessment for Diagnostic and Prognostic Stratification Following Myocardial Infarction,"Background Cardiovascular magnetic resonance imaging is considered the reference methodology for cardiac morphology and function but requires manual postprocessing. Whether novel artificial intelligence-based automated analyses deliver similar information for risk stratification is unknown. Therefore, this study aimed to investigate feasibility and prognostic implications of artificial intelligence-based, commercially available software analyses. Methods and Results Cardiovascular magnetic resonance data (n=1017 patients) from 2 myocardial infarction multicenter trials were included. Analyses of biventricular parameters including ejection fraction (EF) were manually and automatically assessed using conventional and artificial intelligence-based software. Obtained parameters entered regression analyses for prediction of major adverse cardiac events, defined as death, reinfarction, or congestive heart failure, within 1 year after the acute event. Both manual and uncorrected automated volumetric assessments showed similar impact on outcome in univariate analyses (left ventricular EF, manual: hazard ratio [HR], 0.93 [95% CI 0.91-0.95]; P<0.001; automated: HR, 0.94 [95% CI, 0.92-0.96]; P<0.001) and multivariable analyses (left ventricular EF, manual: HR, 0.95 [95% CI, 0.92-0.98]; P=0.001; automated: HR, 0.95 [95% CI, 0.92-0.98]; P=0.001). Manual correction of the automated contours did not lead to improved risk prediction (left ventricular EF, area under the curve: 0.67 automated versus 0.68 automated corrected; P=0.49). There was acceptable agreement (left ventricular EF: bias, 2.6%; 95% limits of agreement, -9.1% to 14.2%; intraclass correlation coefficient, 0.88 [95% CI, 0.77-0.93]) of manual and automated volumetric assessments. Conclusions User-independent volumetric analyses performed by fully automated software are feasible, and results are equally predictive of major adverse cardiac events compared with conventional analyses in patients following myocardial infarction. Registration URL: https://www.clinicaltrials.gov; Unique identifiers: NCT00712101 and NCT01612312.","Open access funding enabled and organized by Projekt DEAL [Correction added on September 30, 2020, after first online publication: Projekt DEAL funding statement has been added.]",,Journal of the American Heart Association,,"Aged; Artificial Intelligence; Automation; Feasibility Studies; Female; Heart; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Myocardial Infarction; Myocardium; Prognosis; Risk Assessment; Risk Factors; Software; Stroke Volume",2020-09-02,2020,2020-09-02,2020-09-15,9,18,e016612,All OA, Gold,Article,"Schuster, Andreas; Lange, Torben; Backhaus, Sören J.; Strohmeyer, Carolin; Boom, Patricia C.; Matz, Jonas; Kowallick, Johannes T.; Lotz, Joachim; Steinmetz, Michael; Kutty, Shelby; Bigalke, Boris; Gutberlet, Matthias; de Waha‐Thiele, Suzanne; Desch, Steffen; Hasenfuß, Gerd; Thiele, Holger; Stiermaier, Thomas; Eitel, Ingo","Schuster, Andreas (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany; German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany); Lange, Torben (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany; German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany); Backhaus, Sören J. (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany; German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany); Strohmeyer, Carolin (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany; German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany); Boom, Patricia C. (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany; German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany); Matz, Jonas (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany; German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany); Kowallick, Johannes T. (German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany; Institute for Diagnostic and Interventional Radiology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany); Lotz, Joachim (German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany; Institute for Diagnostic and Interventional Radiology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany); Steinmetz, Michael (German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany; Department of Pediatric Cardiology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany); Kutty, Shelby (Helen B. Taussig Heart Center, The Johns Hopkins Hospital and School of Medicine, Baltimore, MD); Bigalke, Boris (Department of Cardiology, Charité Campus Benjamin Franklin, University Medical Center Berlin, Berlin, Germany); Gutberlet, Matthias (Institute of Diagnostic and Interventional Radiology, Heart Center Leipzig at University of Leipzig, Germany); de Waha‐Thiele, Suzanne (Medical Clinic II (Cardiology/Angiology/Intensive Care Medicine), University Heart Center Lübeck, University Hospital Schleswig‐Holstein, Lübeck, Germany; German Centre for Cardiovascular Research (DZHK), partner site Hamburg/Kiel/Lübeck, Lübeck, Germany); Desch, Steffen (Department of Internal Medicine/Cardiology and Leipzig Heart Institute, Heart Center Leipzig at University of Leipzig, Germany); Hasenfuß, Gerd (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg‐August University, Göttingen, Germany; German Centre for Cardiovascular Research (DZHK), partner site Göttingen, Göttingen, Germany); Thiele, Holger (Department of Internal Medicine/Cardiology and Leipzig Heart Institute, Heart Center Leipzig at University of Leipzig, Germany); Stiermaier, Thomas (Medical Clinic II (Cardiology/Angiology/Intensive Care Medicine), University Heart Center Lübeck, University Hospital Schleswig‐Holstein, Lübeck, Germany; German Centre for Cardiovascular Research (DZHK), partner site Hamburg/Kiel/Lübeck, Lübeck, Germany); Eitel, Ingo (Medical Clinic II (Cardiology/Angiology/Intensive Care Medicine), University Heart Center Lübeck, University Hospital Schleswig‐Holstein, Lübeck, Germany; German Centre for Cardiovascular Research (DZHK), partner site Hamburg/Kiel/Lübeck, Lübeck, Germany)","Schuster, Andreas (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research)","Schuster, Andreas (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Lange, Torben (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Backhaus, Sören J. (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Strohmeyer, Carolin (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Boom, Patricia C. (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Matz, Jonas (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Kowallick, Johannes T. (German Centre for Cardiovascular Research; University of Göttingen; Universitätsmedizin Göttingen); Lotz, Joachim (German Centre for Cardiovascular Research; University of Göttingen; Universitätsmedizin Göttingen); Steinmetz, Michael (German Centre for Cardiovascular Research; University of Göttingen; Universitätsmedizin Göttingen); Kutty, Shelby (Johns Hopkins Hospital); Bigalke, Boris (Charité - University Medicine Berlin); Gutberlet, Matthias (Leipzig University); de Waha‐Thiele, Suzanne (University Hospital Schleswig-Holstein; German Centre for Cardiovascular Research); Desch, Steffen (Leipzig University); Hasenfuß, Gerd (University of Göttingen; Universitätsmedizin Göttingen; German Centre for Cardiovascular Research); Thiele, Holger (Leipzig University); Stiermaier, Thomas (University Hospital Schleswig-Holstein; German Centre for Cardiovascular Research); Eitel, Ingo (University Hospital Schleswig-Holstein; German Centre for Cardiovascular Research)",18,17,1.72,8.82,https://www.ahajournals.org/doi/pdf/10.1161/JAHA.120.016612,https://app.dimensions.ai/details/publication/pub.1130512303,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
8467,pub.1134406061,10.22489/cinc.2020.204,34079839,PMC8168986,A Convolutional Neural Network-based Deformable Image Registration Method for Cardiac Motion Estimation from Cine Cardiac MR Images,"In this work, we describe an unsupervised deep learning framework featuring a Laplacian-based operator as smoothing loss for deformable registration of 3D cine cardiac magnetic resonance (CMR) images. Before registration, the input 3D images are corrected for slice misalignment by segmenting the left ventricle (LV) blood-pool, LV myocardium and right ventricle (RV) blood-pool using a U-Net model and aligning the 2D slices along the center of the LV blood-pool. We conducted experiments using the Automated Cardiac Diagnosis Challenge (ACDC) dataset. We used the registration deformation field to warp the manually segmented LV blood-pool, LV myocardium and RV blood-pool labels from end-diastole (ED) frame to the other frames in the cardiac cycle. We achieved a mean Dice score of 94.84%, 85.22% and 84.36%, and Hausdorff distance (HD) of 2.74 mm, 5.88 mm and 9.04 mm, for the LV blood-pool, LV myocardium and RV blood-pool, respectively. We also introduce a pipeline to estimate patient tractography using the proposed CNN-based cardiac motion estimation.","This work was supported by grants from the National Science Foundation (Award No. OAC 1808530, OAC 1808553 &amp; CCF 1717894) and the National Institutes of Health (Award No. R35GM128877).",,2016 Computing in Cardiology Conference (CinC),2020 Computing in Cardiology Conference (CinC),,2020-09,2020,2020-12-30,2020-09,0,,1-4,All OA, Bronze,Proceeding,"Upendra, Roshan Reddy; Wentz, Brian Jamison; Shontz, Suzanne M; Linte, Cristian A","Upendra, Roshan Reddy (Chester F Carlson Center for Imaging Science); Wentz, Brian Jamison (Bioengineering Graduate Program; Information and Telecommunication Technology Center, University of Kansas, Lawrence, KS, USA); Shontz, Suzanne M (Bioengineering Graduate Program; Electrical Engineering and Computer Science; Information and Telecommunication Technology Center, University of Kansas, Lawrence, KS, USA); Linte, Cristian A (Chester F Carlson Center for Imaging Science; Biomedical Engineering, Rochester Institute of Technology, Rochester, NY, USA)","Upendra, Roshan Reddy ","Upendra, Roshan Reddy (); Wentz, Brian Jamison (University of Kansas); Shontz, Suzanne M (University of Kansas); Linte, Cristian A (Rochester Institute of Technology)",2,2,0.25,1.21,https://doi.org/10.22489/cinc.2020.204,https://app.dimensions.ai/details/publication/pub.1134406061,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,
1649,pub.1130971308,10.1109/is48319.2020.9199844,,,Application of Deep Learning in Cardiovascular Medicine using Multiple Biomedical Data,"Today with the help of emerging technologies scientists can gather data in many sectors which includes the Healthcare sector. The amount of data generated by machines and humans is overwhelming and is growing faster than it has ever had before. Taking advantage of all the power that exist in that data we have come up with a novel idea where we have used the development of machine learning techniques in diagnosing cardiovascular disease. Here, we fit a function to examples and using the function to generalize and make predictions about new diagnosis. In other words, the machine learning models learn from past data to make predictions about a patient diagnosis. This research provides a detailed work with the application of planning techniques is used in order to diagnose CVDs. A combination of biological data and medical imaging has been used. Ultimately, as this is a challenging research area open issues and its possible future works have also been discussed.",,,,2020 IEEE 10th International Conference on Intelligent Systems (IS),,2020-08-30,2020,,2020-08-30,0,,200-204,Closed,Proceeding,"Gogi, Giovanah; Gegov, Alexander; Bader-El-Den, Mohamed; Vatchova, Boriana","Gogi, Giovanah (School of Computing University of Portsmouth, UK); Gegov, Alexander (Reader in Computational Intelligence University of Portsmouth, UK); Bader-El-Den, Mohamed (University of Portsmouth, UK); Vatchova, Boriana (Bulgarian Academy of Sciences Institute of Information and Communication Technologies)","Gogi, Giovanah (University of Portsmouth)","Gogi, Giovanah (University of Portsmouth); Gegov, Alexander (University of Portsmouth); Bader-El-Den, Mohamed (University of Portsmouth); Vatchova, Boriana ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1130971308,46 Information and Computing Sciences, 4602 Artificial Intelligence,3 Good Health and Well Being,,,,,,,,,,
953,pub.1130460589,10.48550/arxiv.2008.12378,,,Measuring the Biases and Effectiveness of Content-Style Disentanglement,"A recent spate of state-of-the-art semi- and un-supervised solutions
disentangle and encode image ""content"" into a spatial tensor and image
appearance or ""style"" into a vector, to achieve good performance in spatially
equivariant tasks (e.g. image-to-image translation). To achieve this, they
employ different model design, learning objective, and data biases. While
considerable effort has been made to measure disentanglement in vector
representations, and assess its impact on task performance, such analysis for
(spatial) content - style disentanglement is lacking. In this paper, we conduct
an empirical study to investigate the role of different biases in content-style
disentanglement settings and unveil the relationship between the degree of
disentanglement and task performance. In particular, we consider the setting
where we: (i) identify key design choices and learning constraints for three
popular content-style disentanglement models; (ii) relax or remove such
constraints in an ablation fashion; and (iii) use two metrics to measure the
degree of disentanglement and assess its effect on each task performance. Our
experiments reveal that there is a ""sweet spot"" between disentanglement, task
performance and - surprisingly - content interpretability, suggesting that
blindly forcing for higher disentanglement can hurt model performance and
content factors semanticness. Our findings, as well as the used
task-independent metrics, can be used to guide the design and selection of new
models for tasks where content-style representations are useful.",,,arXiv,,,2020-08-27,2020,,,,,,All OA, Green,Preprint,"Liu, Xiao; Thermos, Spyridon; Valvano, Gabriele; Chartsias, Agisilaos; O'Neil, Alison; Tsaftaris, Sotirios A.","Liu, Xiao (); Thermos, Spyridon (); Valvano, Gabriele (); Chartsias, Agisilaos (); O'Neil, Alison (); Tsaftaris, Sotirios A. ()",,"Liu, Xiao (); Thermos, Spyridon (); Valvano, Gabriele (); Chartsias, Agisilaos (); O'Neil, Alison (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1130460589,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5035,pub.1130365400,10.1016/j.jcmg.2019.12.022,32861647,,"3D Printing, Computational Modeling, and Artificial Intelligence for Structural Heart Disease","Structural heart disease (SHD) is a new field within cardiovascular medicine. Traditional imaging modalities fall short in supporting the needs of SHD interventions, as they have been constructed around the concept of disease diagnosis. SHD interventions disrupt traditional concepts of imaging in requiring imaging to plan, simulate, and predict intraprocedural outcomes. In transcatheter SHD interventions, the absence of a gold-standard open cavity surgical field deprives physicians of the opportunity for tactile feedback and visual confirmation of cardiac anatomy. Hence, dependency on imaging in periprocedural guidance has led to evolution of a new generation of procedural skillsets, concept of a visual field, and technologies in the periprocedural planning period to accelerate preclinical device development, physician, and patient education. Adaptation of 3-dimensional (3D) printing in clinical care and procedural planning has demonstrated a reduction in early-operator learning curve for transcatheter interventions. Integration of computation modeling to 3D printing has accelerated research and development understanding of fluid mechanics within device testing. Application of 3D printing, computational modeling, and ultimately incorporation of artificial intelligence is changing the landscape of physician training and delivery of patient-centric care. Transcatheter structural heart interventions are requiring in-depth periprocedural understanding of cardiac pathophysiology and device interactions not afforded by traditional imaging metrics.",The authors thank Kati Engelhardt for contributing to the illustration in Figure 14.,,JACC Cardiovascular Imaging,,"Artificial Intelligence; Cardiac Catheterization; Cardiac Surgical Procedures; Heart Diseases; Humans; Predictive Value of Tests; Printing, Three-Dimensional",2020-08-26,2020,2020-08-26,2021-01,14,1,41-60,All OA, Bronze,Article,"Wang, Dee Dee; Qian, Zhen; Vukicevic, Marija; Engelhardt, Sandy; Kheradvar, Arash; Zhang, Chuck; Little, Stephen H; Verjans, Johan; Comaniciu, Dorin; O'Neill, William W; Vannan, Mani A","Wang, Dee Dee (Center for Structural Heart Disease, Division of Cardiology, Henry Ford Health System, Detroit, Michigan, USA. Electronic address: dwang2@hfhs.org.); Qian, Zhen (Hippocrates Research Lab, Tencent America, Palo Alto, California, USA.); Vukicevic, Marija (Department of Cardiology, Methodist DeBakey Heart Center, Houston Methodist Hospital, Houston, Texas, USA.); Engelhardt, Sandy (Artificial Intelligence in Cardiovascular Medicine, Heidelberg University Hospital, Heidelberg, Germany.); Kheradvar, Arash (Department of Biomedical Engineering, Edwards Lifesciences Center for Advanced Cardiovascular Technology, University of California, Irvine, California, USA.); Zhang, Chuck (H. Milton Stewart School of Industrial & Systems Engineering and Georgia Tech Manufacturing Institute, Georgia Institute of Technology, Atlanta Georgia, USA.); Little, Stephen H (Department of Cardiology, Methodist DeBakey Heart Center, Houston Methodist Hospital, Houston, Texas, USA.); Verjans, Johan (Australian Institute for Machine Learning, University of Adelaide, Adelaide South Australia, Australia.); Comaniciu, Dorin (Siemens Healthineers, Medical Imaging Technologies, Princeton, New Jersey, USA.); O'Neill, William W (Center for Structural Heart Disease, Division of Cardiology, Henry Ford Health System, Detroit, Michigan, USA.); Vannan, Mani A (Hippocrates Research Lab, Tencent America, Palo Alto, California, USA.)","Wang, Dee Dee (Henry Ford Health System)","Wang, Dee Dee (Henry Ford Health System); Qian, Zhen (); Vukicevic, Marija (Houston Methodist); Engelhardt, Sandy (University Hospital Heidelberg); Kheradvar, Arash (University of California, Irvine); Zhang, Chuck (Georgia Institute of Technology); Little, Stephen H (Houston Methodist); Verjans, Johan (University of Adelaide); Comaniciu, Dorin (Siemens Healthcare (United States)); O'Neill, William W (Henry Ford Health System); Vannan, Mani A ()",41,40,6.63,26.56,https://doi.org/10.1016/j.jcmg.2019.12.022,https://app.dimensions.ai/details/publication/pub.1130365400,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,3 Good Health and Well Being,,,,,,,,,
1451,pub.1130339370,10.48550/arxiv.2008.11109,,,Measure Anatomical Thickness from Cardiac MRI with Deep Neural Networks,"Accurate estimation of shape thickness from medical images is crucial in
clinical applications. For example, the thickness of myocardium is one of the
key to cardiac disease diagnosis. While mathematical models are available to
obtain accurate dense thickness estimation, they suffer from heavy
computational overhead due to iterative solvers. To this end, we propose novel
methods for dense thickness estimation, including a fast solver that estimates
thickness from binary annular shapes and an end-to-end network that estimates
thickness directly from raw cardiac images.We test the proposed models on three
cardiac datasets and one synthetic dataset, achieving impressive results and
generalizability on all. Thickness estimation is performed without iterative
solvers or manual correction, which is 100 times faster than the mathematical
model. We also analyze thickness patterns on different cardiac pathologies with
a standard clinical model and the results demonstrate the potential clinical
value of our method for thickness based cardiac disease diagnosis.",,,arXiv,,,2020-08-25,2020,,,,,,All OA, Green,Preprint,"Huang, Qiaoying; Chen, Eric Z.; Yu, Hanchao; Guo, Yimo; Chen, Terrence; Metaxas, Dimitris; Sun, Shanhui","Huang, Qiaoying (); Chen, Eric Z. (); Yu, Hanchao (); Guo, Yimo (); Chen, Terrence (); Metaxas, Dimitris (); Sun, Shanhui ()",,"Huang, Qiaoying (); Chen, Eric Z. (); Yu, Hanchao (); Guo, Yimo (); Chen, Terrence (); Metaxas, Dimitris (); Sun, Shanhui ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1130339370,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
5371,pub.1130235033,10.1016/j.compmedimag.2020.101786,32866695,,Fully automatic segmentation of right and left ventricle on short-axis cardiac MRI images,"Cardiac magnetic resonance imaging (CMR) is a widely used non-invasive imaging modality for evaluating cardiovascular diseases. CMR is the gold standard method for left and right ventricular functional assessment due to its ability to characterize myocardial structure and function and low intra- and inter-observer variability. However the post-processing segmentation during the functional evaluation is time-consuming and challenging. A fully automated segmentation method can assist the experts; therefore, they can do more efficient work. In this paper, a regression-based fully automated method is presented for the right- and left ventricle segmentation. For training and evaluation, our dataset contained MRI short-axis scans of 5570 patients, who underwent CMR examinations at Heart and Vascular Center, Semmelweis University Budapest. Our approach is novel and after training the state-of-the-art algorithm on our dataset, our algorithm proved to be superior on both of the ventricles. The evaluation metrics were the Dice index, Hausdorff distance and volume related parameters. We have achieved average Dice index for the left endocardium: 0.927, left epicardium: 0.940 and right endocardium: 0.873 on our dataset. We have also compared the performance of the algorithm to the human-level segmentation on both ventricles and it is similar to experienced readers for the left, and comparable for the right ventricle. We also evaluated the proposed algorithm on the ACDC dataset, which is publicly available, with and without transfer learning. The results on ACDC were also satisfying and similar to human observers. Our method is lightweight, fast to train and does not require more than 2 GB GPU memory for execution and training.","Project no. FIEK16-1-2016-0007 has been implemented with the support provided by the National Research, Development and Innovation Fund of Hungary, financed under the Centre for Higher Education and Industrial Cooperation - Research infrastructure development (FIEK_16) funding scheme. Project no. NVKP_16-1-2016-0017 has been implemented with the support provided by the National Research, Development and Innovation Fund of Hungary , financed under the NVKP_16 funding scheme. This project was also supported by a grant from the National Research, Development and Innovation Office (NKFIH) of Hungary (K 120277).",,Computerized Medical Imaging and Graphics,,Algorithms, Endocardium, Heart Ventricles, Humans, Magnetic Resonance Imaging, Pericardium,2020-08-21,2020,2020-08-21,2020-10,85,,101786,All OA, Hybrid,Article,"Budai, Adam; Suhai, Ferenc I; Csorba, Kristof; Toth, Attila; Szabo, Liliana; Vago, Hajnalka; Merkely, Bela","Budai, Adam (Department of Automation and Applied Informatics, Budapest University of Technology and Economics, Magyar tudósok krt. 2. (Bldg. Q.), Budapest, H-1117, Hungary. Electronic address: budai.adam@aut.bme.hu.); Suhai, Ferenc I (Heart and Vascular Center, Semmelweis University, Városmajor street 68., H-1112, Budapest, Hungary.); Csorba, Kristof (Department of Automation and Applied Informatics, Budapest University of Technology and Economics, Magyar tudósok krt. 2. (Bldg. Q.), Budapest, H-1117, Hungary.); Toth, Attila (Heart and Vascular Center, Semmelweis University, Városmajor street 68., H-1112, Budapest, Hungary.); Szabo, Liliana (Heart and Vascular Center, Semmelweis University, Városmajor street 68., H-1112, Budapest, Hungary.); Vago, Hajnalka (Heart and Vascular Center, Semmelweis University, Városmajor street 68., H-1112, Budapest, Hungary.); Merkely, Bela (Heart and Vascular Center, Semmelweis University, Városmajor street 68., H-1112, Budapest, Hungary.)","Budai, Adam (Budapest University of Technology and Economics)","Budai, Adam (Budapest University of Technology and Economics); Suhai, Ferenc I (Semmelweis University); Csorba, Kristof (Budapest University of Technology and Economics); Toth, Attila (Semmelweis University); Szabo, Liliana (Semmelweis University); Vago, Hajnalka (Semmelweis University); Merkely, Bela (Semmelweis University)",12,12,1.24,6.74,https://doi.org/10.1016/j.compmedimag.2020.101786,https://app.dimensions.ai/details/publication/pub.1130235033,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,
1454,pub.1130313834,10.48550/arxiv.2008.10418,,,INSIDE: Steering Spatial Attention with Non-Imaging Information in CNNs,"We consider the problem of integrating non-imaging information into
segmentation networks to improve performance. Conditioning layers such as FiLM
provide the means to selectively amplify or suppress the contribution of
different feature maps in a linear fashion. However, spatial dependency is
difficult to learn within a convolutional paradigm. In this paper, we propose a
mechanism to allow for spatial localisation conditioned on non-imaging
information, using a feature-wise attention mechanism comprising a
differentiable parametrised function (e.g. Gaussian), prior to applying the
feature-wise modulation. We name our method INstance modulation with SpatIal
DEpendency (INSIDE). The conditioning information might comprise any factors
that relate to spatial or spatio-temporal information such as lesion location,
size, and cardiac cycle phase. Our method can be trained end-to-end and does
not require additional supervision. We evaluate the method on two datasets: a
new CLEVR-Seg dataset where we segment objects based on location, and the ACDC
dataset conditioned on cardiac phase and slice location within the volume. Code
and the CLEVR-Seg dataset are available at https://github.com/jacenkow/inside.",,,arXiv,,,2020-08-21,2020,,,,,,All OA, Green,Preprint,"Jacenków, Grzegorz; O'Neil, Alison Q.; Mohr, Brian; Tsaftaris, Sotirios A.","Jacenków, Grzegorz (); O'Neil, Alison Q. (); Mohr, Brian (); Tsaftaris, Sotirios A. ()",,"Jacenków, Grzegorz (); O'Neil, Alison Q. (); Mohr, Brian (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1130313834,40 Engineering, 4013 Geomatic Engineering, 46 Information and Computing Sciences,,,,,,,,,
1451,pub.1130216330,10.48550/arxiv.2008.08433,,,Unsupervised Cross-domain Image Classification by Distance Metric Guided  Feature Alignment,"Learning deep neural networks that are generalizable across different domains
remains a challenge due to the problem of domain shift. Unsupervised domain
adaptation is a promising avenue which transfers knowledge from a source domain
to a target domain without using any labels in the target domain. Contemporary
techniques focus on extracting domain-invariant features using domain
adversarial training. However, these techniques neglect to learn discriminative
class boundaries in the latent representation space on a target domain and
yield limited adaptation performance. To address this problem, we propose
distance metric guided feature alignment (MetFA) to extract discriminative as
well as domain-invariant features on both source and target domains. The
proposed MetFA method explicitly and directly learns the latent representation
without using domain adversarial training. Our model integrates class
distribution alignment to transfer semantic knowledge from a source domain to a
target domain. We evaluate the proposed method on fetal ultrasound datasets for
cross-device image classification. Experimental results demonstrate that the
proposed method outperforms the state-of-the-art and enables model
generalization.",,,arXiv,,,2020-08-19,2020,,,,,,All OA, Green,Preprint,"Meng, Qingjie; Rueckert, Daniel; Kainz, Bernhard","Meng, Qingjie (); Rueckert, Daniel (); Kainz, Bernhard ()",,"Meng, Qingjie (); Rueckert, Daniel (); Kainz, Bernhard ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1130216330,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1216,pub.1130166278,10.48550/arxiv.2008.07071,,,Towards Cardiac Intervention Assistance: Hardware-aware Neural  Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation,"Real-time cardiac magnetic resonance imaging (MRI) plays an increasingly
important role in guiding various cardiac interventions. In order to provide
better visual assistance, the cine MRI frames need to be segmented on-the-fly
to avoid noticeable visual lag. In addition, considering reliability and
patient data privacy, the computation is preferably done on local hardware.
State-of-the-art MRI segmentation methods mostly focus on accuracy only, and
can hardly be adopted for real-time application or on local hardware. In this
work, we present the first hardware-aware multi-scale neural architecture
search (NAS) framework for real-time 3D cardiac cine MRI segmentation. The
proposed framework incorporates a latency regularization term into the loss
function to handle real-time constraints, with the consideration of underlying
hardware. In addition, the formulation is fully differentiable with respect to
the architecture parameters, so that stochastic gradient descent (SGD) can be
used for optimization to reduce the computation cost while maintaining
optimization quality. Experimental results on ACDC MICCAI 2017 dataset
demonstrate that our hardware-aware multi-scale NAS framework can reduce the
latency by up to 3.5 times and satisfy the real-time constraints, while still
achieving competitive segmentation accuracy, compared with the state-of-the-art
NAS segmentation framework.",,,arXiv,,,2020-08-16,2020,,,,,,All OA, Green,Preprint,"Zeng, Dewen; Jiang, Weiwen; Wang, Tianchen; Xu, Xiaowei; Yuan, Haiyun; Huang, Meiping; Zhuang, Jian; Hu, Jingtong; Shi, Yiyu","Zeng, Dewen (); Jiang, Weiwen (); Wang, Tianchen (); Xu, Xiaowei (); Yuan, Haiyun (); Huang, Meiping (); Zhuang, Jian (); Hu, Jingtong (); Shi, Yiyu ()",,"Zeng, Dewen (); Jiang, Weiwen (); Wang, Tianchen (); Xu, Xiaowei (); Yuan, Haiyun (); Huang, Meiping (); Zhuang, Jian (); Hu, Jingtong (); Shi, Yiyu ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1130166278,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1399,pub.1130025785,10.48550/arxiv.2008.03414,,,Using UNet and PSPNet to explore the reusability principle of CNN  parameters,"How to reduce the requirement on training dataset size is a hot topic in deep
learning community. One straightforward way is to reuse some pre-trained
parameters. Some previous work like Deep transfer learning reuse the model
parameters trained for the first task as the starting point for the second
task, and semi-supervised learning is trained upon a combination of labeled and
unlabeled data. However, the fundamental reason of the success of these methods
is unclear. In this paper, the reusability of parameters in each layer of a
deep convolutional neural network is experimentally quantified by using a
network to do segmentation and auto-encoder task. This paper proves that
network parameters can be reused for two reasons: first, the network features
are general; Second, there is little difference between the pre-trained
parameters and the ideal network parameters. Through the use of parameter
replacement and comparison, we demonstrate that reusability is different in
BN(Batch Normalization)[7] layer and Convolution layer and some observations:
(1)Running mean and running variance plays an important role than Weight and
Bias in BN layer.(2)The weight and bias can be reused in BN layers.( 3) The
network is very sensitive to the weight of convolutional layer.(4) The bias in
Convolution layers are not sensitive, and it can be reused directly.",,,arXiv,,,2020-08-07,2020,,,,,,All OA, Green,Preprint,"Wang, Wei","Wang, Wei ()",,"Wang, Wei ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1130025785,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1689,pub.1129909520,10.48550/arxiv.2008.01216,,,Generalisable Cardiac Structure Segmentation via Attentional and Stacked  Image Adaptation,"Tackling domain shifts in multi-centre and multi-vendor data sets remains
challenging for cardiac image segmentation. In this paper, we propose a
generalisable segmentation framework for cardiac image segmentation in which
multi-centre, multi-vendor, multi-disease datasets are involved. A generative
adversarial networks with an attention loss was proposed to translate the
images from existing source domains to a target domain, thus to generate
good-quality synthetic cardiac structure and enlarge the training set. A stack
of data augmentation techniques was further used to simulate real-world
transformation to boost the segmentation performance for unseen domains.We
achieved an average Dice score of 90.3% for the left ventricle, 85.9% for the
myocardium, and 86.5% for the right ventricle on the hidden validation set
across four vendors. We show that the domain shifts in heterogeneous cardiac
imaging datasets can be drastically reduced by two aspects: 1) good-quality
synthetic data by learning the underlying target domain distribution, and 2)
stacked classical image processing techniques for data augmentation.",,,arXiv,,,2020-08-03,2020,,,,,,All OA, Green,Preprint,"Li, Hongwei; Zhang, Jianguo; Menze, Bjoern","Li, Hongwei (); Zhang, Jianguo (); Menze, Bjoern ()",,"Li, Hongwei (); Zhang, Jianguo (); Menze, Bjoern ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129909520,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1209,pub.1129811799,10.1109/jstsp.2020.3013351,,,Cardiac MRI Segmentation With a Dilated CNN Incorporating Domain-Specific Constraints,"Semantic segmentation of cardiac MR images is a challenging task due to its importance in medical assessment of heart diseases. Having a detailed localization of specific regions of interest such as Right and Left Ventricular Cavities and Myocardium, doctors can infer important information about the presence of cardiovascular diseases, which are today a major cause of death globally. This paper addresses the problem of semantic segmentation in cardiac MR images using a dilated Convolutional Neural Network. Opting for dilated convolutions allowed us to work in full resolution throughout the network's layers, preserving localization accuracy, while maintaining a relatively small number of trainable parameters. To assist the network's training process we designed a custom loss function. Furthermore, we developed new augmentation techniques and also adapted existing ones, to cope for the lack of sufficient training images. Consequently, the training set increases not only by amount, but by substance as well, and the network trains quickly and efficiently without overfitting. Our pre- and post-processing steps are also crucial to the whole process. We apply our methodology for the Right and Left Ventricles (RV, LV) and also the Myocardium (MYO) according to the Automated Cardiac Diagnosis Challenge (ACDC) with promising results. Submitting our algorithm's predictions to the Post-2017-MICCAI-challenge testing phase, we achieved similar scores (average Dice coefficient 0.916) on the test data set compared to the state of the art featured in the ACDC leaderboard, but with significantly fewer parameters than the leading method. Our approach outperforms other methods featuring dilated convolutions in this challenge up until now.",The authors would like to thank the NVidia corporation for providing us with the TITAN V GPU used for this research as part of the NVidia GPU Grant Program.,,IEEE Journal of Selected Topics in Signal Processing,,,2020-07-31,2020,2020-07-31,,14,6,1235-1243,Closed,Article,"Simantiris, Georgios; Tziritas, Georgios","Simantiris, Georgios (Department of Computer Science, University of Crete, 700 13, Heraklion, Greece); Tziritas, Georgios (Department of Computer Science, University of Crete, 700 13, Heraklion, Greece)","Simantiris, Georgios (University of Crete)","Simantiris, Georgios (University of Crete); Tziritas, Georgios (University of Crete)",30,30,,12.76,,https://app.dimensions.ai/details/publication/pub.1129811799,46 Information and Computing Sciences, 4605 Data Management and Data Science,3 Good Health and Well Being,,,,,,,,,,
957,pub.1129835201,10.48550/arxiv.2007.16102,,,Curriculum learning for improved femur fracture classification:  scheduling data with prior knowledge and uncertainty,"An adequate classification of proximal femur fractures from X-ray images is
crucial for the treatment choice and the patients' clinical outcome. We rely on
the commonly used AO system, which describes a hierarchical knowledge tree
classifying the images into types and subtypes according to the fracture's
location and complexity. In this paper, we propose a method for the automatic
classification of proximal femur fractures into 3 and 7 AO classes based on a
Convolutional Neural Network (CNN). As it is known, CNNs need large and
representative datasets with reliable labels, which are hard to collect for the
application at hand. In this paper, we design a curriculum learning (CL)
approach that improves over the basic CNNs performance under such conditions.
Our novel formulation reunites three curriculum strategies: individually
weighting training samples, reordering the training set, and sampling subsets
of data. The core of these strategies is a scoring function ranking the
training samples. We define two novel scoring functions: one from
domain-specific prior knowledge and an original self-paced uncertainty score.
We perform experiments on a clinical dataset of proximal femur radiographs. The
curriculum improves proximal femur fracture classification up to the
performance of experienced trauma surgeons. The best curriculum method reorders
the training set based on prior knowledge resulting into a classification
improvement of 15%. Using the publicly available MNIST dataset, we further
discuss and demonstrate the benefits of our unified CL formulation for three
controlled and challenging digit recognition scenarios: with limited amounts of
data, under class-imbalance, and in the presence of label noise. The code of
our work is available at:
https://github.com/ameliajimenez/curriculum-learning-prior-uncertainty.",,,arXiv,,,2020-07-31,2020,,,,,,All OA, Green,Preprint,"Jiménez-Sánchez, Amelia; Mateus, Diana; Kirchhoff, Sonja; Kirchhoff, Chlodwig; Biberthaler, Peter; Navab, Nassir; Ballester, Miguel A. González; Piella, Gemma","Jiménez-Sánchez, Amelia (); Mateus, Diana (); Kirchhoff, Sonja (); Kirchhoff, Chlodwig (); Biberthaler, Peter (); Navab, Nassir (); Ballester, Miguel A. González (); Piella, Gemma ()",,"Jiménez-Sánchez, Amelia (); Mateus, Diana (); Kirchhoff, Sonja (); Kirchhoff, Chlodwig (); Biberthaler, Peter (); Navab, Nassir (); Ballester, Miguel A. González (); Piella, Gemma ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129835201,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5332,pub.1129071982,10.1002/mp.14377,32638370,,Convolutional neural network‐based pelvic floor structure segmentation using magnetic resonance imaging in pelvic organ prolapse,"PURPOSE: Automated segmentation could improve the efficiency of modeling-based pelvic organ prolapse (POP) evaluations. However, segmentation performance is limited by the blurry soft tissue boundaries. In this study, we aimed to present a hybrid solution for uterus, rectum, bladder, and levator ani muscle segmentation by combining a convolutional neural network (CNN) and a level set method.
METHODS: We used 24 sagittal pelvic floor magnetic resonance (MR) series from six anterior vaginal prolapse and six posterior vaginal prolapse subjects (a total 528 MR images). The stress MR images were performed both at rest and at maximal Valsalva. We assigned 264 images for training, 132 images for validation, and 132 images for testing. A CNN was designed by introducing a multi-resolution features pyramid module (MRFP) into an encoder-decoder model. Depth separable convolution and pretraining were used to improve model convergence. Multiclass cross entropy loss and multiclass Dice loss were used for model training. The dice similarity coefficient (DSC) and average surface distance (ASD) were used for evaluating the segmentation results. To prove the effectiveness of our model, we compared it with advanced segmentation methods including Deeplabv3+, U-Net, and FCN-8s. The ablation study was designed to quantify the contributions of MRFP, the encoder network, and pretraining. Besides, we investigated the working mechanism of MRFP in the segmentation network by comparing our model with three of its variants. Finally, the level set method was used to improve the CNN model further.
RESULTS: Dice loss showed better segmentation performance than multiclass cross entropy loss. MRFP was efficacious for different encoder networks. With MRFP, U-Net and U-Net-X (X represents Xception encoder network) have improved the DSC, on average by 6.8 and 5.3 points. Compared with different CNN models, our model achieved the highest average DSC of 65.6 points and the lowest average ASD of 2.9 mm. With the level set method, the DSC of our model improved to 69.4 points.
CONCLUSIONS: MRFP proved to be effective in addressing the blurry soft tissue boundary problem on pelvic floor MR images. A hybrid solution based on CNN and level set method was presented for pelvic organ segmentation both at rest and at maximal Valsalva; with this method, we achieved state-of-the-art results.","This work was supported by the National Science Foundation of China General Program grant 31870942, US Public Health Service grants R01 HD038665 and P50 HD044406.",,Medical Physics,,"Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Pelvic Floor; Pelvic Organ Prolapse",2020-07-28,2020,2020-07-28,2020-09,47,9,4281-4293,All OA, Green,Article,"Feng, Fei; Ashton‐Miller, James A.; DeLancey, John O. L.; Luo, Jiajia","Feng, Fei (University of Michigan‐Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, 200240, China); Ashton‐Miller, James A. (Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, 48109, USA); DeLancey, John O. L. (Department of Obstetrics and Gynecology, University of Michigan, Ann Arbor, MI, 48109, USA); Luo, Jiajia (Biomedical Engineering Department, Peking University, Beijing, 100191, China)","Luo, Jiajia (Peking University)","Feng, Fei (Shanghai Jiao Tong University); Ashton‐Miller, James A. (University of Michigan–Ann Arbor); DeLancey, John O. L. (University of Michigan–Ann Arbor); Luo, Jiajia (Peking University)",9,9,1.54,6.82,http://deepblue.lib.umich.edu/bitstream/2027.42/162690/2/mp14377.pdf,https://app.dimensions.ai/details/publication/pub.1129071982,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,
1512,pub.1130518291,10.1109/cbms49503.2020.00116,,,Automatic Primary Gross Tumor Volume Segmentation for Nasopharyngeal Carcinoma using ResSE-UNet,"Nasopharyngeal carcinoma (NPC) is an endemic disease within specific regions in the world. Radiotherapy is the standard treatment for NPC and accurate segmentation of primary gross tumor volume (GTV) is a critical process of continue therapy. In this paper we proposed a ResSE-UNet network and a Ternary Cross-Entropy (TCE) loss function for delineation of GTV. ResSE-UNet employed ResSE blocks to replace convolutional blocks in the original UNet to extract better features, and reduced the number of down-sampling processing to keep relatively high resolution of the images. TCE combined dice loss and Binary cross-entropy loss for larger gradient and better stability in training. The experimental results showed that among all combinations of networks and loss functions, the ResSE-UNet with TCE loss achieved the best segmentation performance, i.e. about 0.84 DSC can be obtained.","The work is supported by National Natural Science Foundation of China (Grant No. 61702337, 61672357 and U1713214) and the Science and Technology Funding of Guangdong Province (2018A050501014). Guangzhou Panyu Science and Technology Project, (Grant No. 2019-Z04-48) The work is supported by National Natural Science Foundation of China (Grant No. 61702337, 61672357 and U1713214) and the Science and Technology Funding of Guangdong Province (2018A050501014). Guangzhou Panyu Science and Technology Project, (Grant No. 2019-Z04-48)",,,2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS),,2020-07-28,2020,,2020-07-28,0,,585-590,Closed,Proceeding,"Jin, Zhihao; Li, Xuechen; Shen, Linlin; Lang, Jinyi; Li, Jie; Wu, Junxiang; Xu, Peng; Duan, Jiang","Jin, Zhihao (College of Computer Science and Software Engineering, Shenzhen University); Li, Xuechen (College of Computer Science and Software Engineering, Shenzhen University; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, Guangdong province, PR China); Shen, Linlin (College of Computer Science and Software Engineering, Shenzhen University; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, Guangdong province, PR China); Lang, Jinyi (Sichuan Cancer Hospital & Institute, Sichuan Cancer Center, School of Medicine, University of Electronic Science and Technology of China; Radiation Oncology Key Laboratory Of Sichuan Province, Chengdu, Sichuan province, PR China); Li, Jie (Sichuan Cancer Hospital & Institute, Sichuan Cancer Center, School of Medicine, University of Electronic Science and Technology of China; Radiation Oncology Key Laboratory Of Sichuan Province, Chengdu, Sichuan province, PR China); Wu, Junxiang (Sichuan Cancer Hospital & Institute, Sichuan Cancer Center, School of Medicine, University of Electronic Science and Technology of China; Radiation Oncology Key Laboratory Of Sichuan Province, Chengdu, Sichuan province, PR China); Xu, Peng (Sichuan Cancer Hospital & Institute, Sichuan Cancer Center, School of Medicine, University of Electronic Science and Technology of China; Radiation Oncology Key Laboratory Of Sichuan Province, Chengdu, Sichuan province, PR China); Duan, Jiang (School of economic information engineering, Southwestern university of finance and economics, Chengdu, Sichuan province, PR China)",,"Jin, Zhihao (Shenzhen University); Li, Xuechen (Shenzhen University; Shenzhen University); Shen, Linlin (Shenzhen University; Shenzhen University); Lang, Jinyi (University of Electronic Science and Technology of China); Li, Jie (University of Electronic Science and Technology of China); Wu, Junxiang (University of Electronic Science and Technology of China); Xu, Peng (University of Electronic Science and Technology of China); Duan, Jiang (Southwestern University of Finance and Economics)",3,3,,1.12,,https://app.dimensions.ai/details/publication/pub.1130518291,32 Biomedical and Clinical Sciences, 3211 Oncology and Carcinogenesis, 51 Physical Sciences,,,,,,,,,,
954,pub.1129720755,10.48550/arxiv.2007.14239,,,Handling confounding variables in statistical shape analysis --  application to cardiac remodelling,"Statistical shape analysis is a powerful tool to assess organ morphologies
and find shape changes associated to a particular disease. However, imbalance
in confounding factors, such as demographics might invalidate the analysis if
not taken into consideration. Despite the methodological advances in the field,
providing new methods that are able to capture complex and regional shape
differences, the relationship between non-imaging information and shape
variability has been overlooked. We present a linear statistical shape analysis
framework that finds shape differences unassociated to a controlled set of
confounding variables. It includes two confounding correction methods:
confounding deflation and adjustment. We applied our framework to a cardiac
magnetic resonance imaging dataset, consisting of the cardiac ventricles of 89
triathletes and 77 controls, to identify cardiac remodelling due to the
practice of endurance exercise. To test robustness to confounders, subsets of
this dataset were generated by randomly removing controls with low body mass
index, thus introducing imbalance. The analysis of the whole dataset indicates
an increase of ventricular volumes and myocardial mass in athletes, which is
consistent with the clinical literature. However, when confounders are not
taken into consideration no increase of myocardial mass is found. Using the
downsampled datasets, we find that confounder adjustment methods are needed to
find the real remodelling patterns in imbalanced datasets.",,,arXiv,,,2020-07-28,2020,,,,,,All OA, Green,Preprint,"Bernardino, Gabriel; Benkarim, Oualid; la Garza, María Sanz-de; Prat-Gonzàlez, Susanna; Sepulveda-Martinez, Álvaro; Crispi, Fàtima; Sitges, Marta; De Craene, Mathieu; Bijnens, Bart; Ballester, Miguel Ángel González","Bernardino, Gabriel (); Benkarim, Oualid (); la Garza, María Sanz-de (); Prat-Gonzàlez, Susanna (); Sepulveda-Martinez, Álvaro (); Crispi, Fàtima (); Sitges, Marta (); De Craene, Mathieu (); Bijnens, Bart (); Ballester, Miguel Ángel González ()",,"Bernardino, Gabriel (); Benkarim, Oualid (); la Garza, María Sanz-de (); Prat-Gonzàlez, Susanna (); Sepulveda-Martinez, Álvaro (); Crispi, Fàtima (); Sitges, Marta (); De Craene, Mathieu (); Bijnens, Bart (); Ballester, Miguel Ángel González ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129720755,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 42 Health Sciences,,,,,,,,,
1345,pub.1129695049,10.48550/arxiv.2007.13408,,,XCAT-GAN for Synthesizing 3D Consistent Labeled Cardiac MR Images on  Anatomically Variable XCAT Phantoms,"Generative adversarial networks (GANs) have provided promising data
enrichment solutions by synthesizing high-fidelity images. However, generating
large sets of labeled images with new anatomical variations remains unexplored.
We propose a novel method for synthesizing cardiac magnetic resonance (CMR)
images on a population of virtual subjects with a large anatomical variation,
introduced using the 4D eXtended Cardiac and Torso (XCAT) computerized human
phantom. We investigate two conditional image synthesis approaches grounded on
a semantically-consistent mask-guided image generation technique: 4-class and
8-class XCAT-GANs. The 4-class technique relies on only the annotations of the
heart; while the 8-class technique employs a predicted multi-tissue label map
of the heart-surrounding organs and provides better guidance for our
conditional image synthesis. For both techniques, we train our conditional
XCAT-GAN with real images paired with corresponding labels and subsequently at
the inference time, we substitute the labels with the XCAT derived ones.
Therefore, the trained network accurately transfers the tissue-specific
textures to the new label maps. By creating 33 virtual subjects of synthetic
CMR images at the end-diastolic and end-systolic phases, we evaluate the
usefulness of such data in the downstream cardiac cavity segmentation task
under different augmentation strategies. Results demonstrate that even with
only 20% of real images (40 volumes) seen during training, segmentation
performance is retained with the addition of synthetic CMR images. Moreover,
the improvement in utilizing synthetic images for augmenting the real data is
evident through the reduction of Hausdorff distance up to 28% and an increase
in the Dice score up to 5%, indicating a higher similarity to the ground truth
in all dimensions.",,,arXiv,,,2020-07-27,2020,,,,,,All OA, Green,Preprint,"Amirrajab, Sina; Abbasi-Sureshjani, Samaneh; Khalil, Yasmina Al; Lorenz, Cristian; Weese, Juergen; Pluim, Josien; Breeuwer, Marcel","Amirrajab, Sina (); Abbasi-Sureshjani, Samaneh (); Khalil, Yasmina Al (); Lorenz, Cristian (); Weese, Juergen (); Pluim, Josien (); Breeuwer, Marcel ()",,"Amirrajab, Sina (); Abbasi-Sureshjani, Samaneh (); Khalil, Yasmina Al (); Lorenz, Cristian (); Weese, Juergen (); Pluim, Josien (); Breeuwer, Marcel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129695049,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1403,pub.1129578067,10.48550/arxiv.2007.10665,,,Fully Automated Segmentation of the Left Ventricle in Magnetic Resonance  Images,"Automatic and robust segmentation of the left ventricle (LV) in magnetic
resonance images (MRI) has remained challenging for many decades. With the
great success of deep learning in object detection and classification, the
research focus of LV segmentation has changed to convolutional neural network
(CNN) in recent years. However, LV segmentation is a pixel-level classification
problem and its categories are intractable compared to object detection and
classification. Although lots of CNN based methods have been proposed for LV
segmentation, no robust and reproducible results are achieved yet. In this
paper, we try to reproduce the CNN based LV segmentation methods with their
disclosed codes and trained CNN models. Not surprisingly, the reproduced
results are significantly worse than their claimed accuracies. We also proposed
a fully automated LV segmentation method based on slope difference distribution
(SDD) threshold selection to compare with the reproduced CNN methods. The
proposed method achieved 95.44% DICE score on the test set of automated cardiac
diagnosis challenge (ACDC) while the two compared CNN methods achieved 90.28%
and 87.13% DICE scores. Our achieved accuracy is also higher than the best
accuracy reported in the published literatures. The MATLAB codes of our
proposed method are freely available on line.",,,arXiv,,,2020-07-21,2020,,,,,,All OA, Green,Preprint,"Wang, ZiHao; Wang, ZhenZhou","Wang, ZiHao (); Wang, ZhenZhou ()",,"Wang, ZiHao (); Wang, ZhenZhou ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129578067,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
5043,pub.1129479390,10.1016/j.media.2020.101792,32712526,,Handling confounding variables in statistical shape analysis - application to cardiac remodelling,"Statistical shape analysis is a powerful tool to assess organ morphologies and find shape changes associated to a particular disease. However, imbalance in confounding factors, such as demographics might invalidate the analysis if not taken into consideration. Despite the methodological advances in the field, providing new methods that are able to capture complex and regional shape differences, the relationship between non-imaging information and shape variability has been overlooked. We present a linear statistical shape analysis framework that finds shape differences unassociated to a controlled set of confounding variables. It includes two confounding correction methods: confounding deflation and adjustment. We applied our framework to a cardiac magnetic resonance imaging dataset, consisting of the cardiac ventricles of 89 triathletes and 77 controls, to identify cardiac remodelling due to the practice of endurance exercise. To test robustness to confounders, subsets of this dataset were generated by randomly removing controls with low body mass index, thus introducing imbalance. The analysis of the whole dataset indicates an increase of ventricular volumes and myocardial mass in athletes, which is consistent with the clinical literature. However, when confounders are not taken into consideration no increase of myocardial mass is found. Using the downsampled datasets, we find that confounder adjustment methods are needed to find the real remodelling patterns in imbalanced datasets.",We thank Dr Weese and Dr Groth from Philips Research Hamburg for the segmentation tool and Dr Piella for fruitful discussions.,"This study was partially supported by the Spanish Ministry of Economy and Competitiveness (grant DEP2013-44923-P, TIN2014-52923-R; Maria de Maeztu Units of Excellence Programme - MDM-2015-0502), el Fondo Europeo de Desarrollo Regional (FEDER), the European Union under the Horizon 2020 Programme for Research, Innovation (grant agreement No. 642676 CardioFunXion) and Erasmus+ Programme (Framework Agreement number: 2013-0040), la Caixa Foundation (LCF/PR/GN14/10270005, LCF/PR/GN18/10310003), Instituto de Salud Carlos III (PI14/00226, PI17/00675) integrated in the ’Plan Nacional I+D+I’ and AGAUR 2017 SGR grant n 1531.",Medical Image Analysis,,"Confounding Factors, Epidemiologic; Heart; Heart Ventricles; Humans; Magnetic Resonance Imaging; Ventricular Remodeling",2020-07-19,2020,2020-07-19,2020-10,65,,101792,All OA, Green,Article,"Bernardino, Gabriel; Benkarim, Oualid; Sanz-de la Garza, María; Prat-Gonzàlez, Susanna; Sepulveda-Martinez, Alvaro; Crispi, Fátima; Sitges, Marta; Butakoff, Constantine; De Craene, Mathieu; Bijnens, Bart; González Ballester, Miguel A","Bernardino, Gabriel (BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain. Electronic address: gabriel.bernardino@upf.edu.); Benkarim, Oualid (McGill University, Montreal, Canada.); Sanz-de la Garza, María (Cardiovascular Institute, Hospital Clínic, Barcelona, Spain; IDIBAPS, Barcelona, Spain.); Prat-Gonzàlez, Susanna (Cardiovascular Institute, Hospital Clínic, Barcelona, Spain; IDIBAPS, Barcelona, Spain.); Sepulveda-Martinez, Alvaro (BCNatal, Hospital Clínic and Sant Joan de Déu, Universitat de Barcelona, Barcelona, Spain; Fetal Medicine Unit, Department of Obstetrics and Gynecology, Hospital Clínico de la Universidad de Chile, Santiago de Chile, Chile.); Crispi, Fátima (IDIBAPS, Barcelona, Spain; BCNatal, Hospital Clínic and Sant Joan de Déu, Universitat de Barcelona, Barcelona, Spain; CIBER-ER, Barcelona, Spain.); Sitges, Marta (Cardiovascular Institute, Hospital Clínic, Barcelona, Spain; IDIBAPS, Barcelona, Spain; CIBER-CV, Barcelona, Spain.); Butakoff, Constantine (Barcelona Supercomputing Center, Barcelona, Spain.); De Craene, Mathieu (Philips Research Paris, Paris, France.); Bijnens, Bart (BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; IDIBAPS, Barcelona, Spain; ICREA, Barcelona, Spain.); González Ballester, Miguel A (BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; ICREA, Barcelona, Spain.)","Bernardino, Gabriel (Pompeu Fabra University)","Bernardino, Gabriel (Pompeu Fabra University); Benkarim, Oualid (McGill University); Sanz-de la Garza, María (Hospital Clínic de Barcelona; August Pi i Sunyer Biomedical Research Institute); Prat-Gonzàlez, Susanna (Hospital Clínic de Barcelona; August Pi i Sunyer Biomedical Research Institute); Sepulveda-Martinez, Alvaro (University of Barcelona; Hospital Clínico de la Universidad de Chile); Crispi, Fátima (August Pi i Sunyer Biomedical Research Institute; University of Barcelona; Centro de Investigación Biomédica en Red de Enfermedades Raras); Sitges, Marta (Hospital Clínic de Barcelona; August Pi i Sunyer Biomedical Research Institute); Butakoff, Constantine (Barcelona Supercomputing Center); De Craene, Mathieu (); Bijnens, Bart (Pompeu Fabra University; August Pi i Sunyer Biomedical Research Institute; Institució Catalana de Recerca i Estudis Avançats); González Ballester, Miguel A (Pompeu Fabra University; Institució Catalana de Recerca i Estudis Avançats)",7,7,0.44,3.43,http://repositori.upf.edu/bitstream/10230/45146/1/bernardino_mediman_handl.pdf,https://app.dimensions.ai/details/publication/pub.1129479390,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
5371,pub.1129478814,10.1016/j.neunet.2020.07.011,32721843,,Discretely-constrained deep network for weakly supervised segmentation,"An efficient strategy for weakly-supervised segmentation is to impose constraints or regularization priors on target regions. Recent efforts have focused on incorporating such constraints in the training of convolutional neural networks (CNN), however this has so far been done within a continuous optimization framework. Yet, various segmentation constraints and regularization priors can be modeled and optimized more efficiently in a discrete formulation. This paper proposes a method, based on the alternating direction method of multipliers (ADMM) algorithm, to train a CNN with discrete constraints and regularization priors. This method is applied to the segmentation of medical images with weak annotations, where both size constraints and boundary length regularization are enforced. Experiments on two benchmark datasets for medical image segmentation show our method to provide significant improvements compared to existing approaches in terms of segmentation accuracy, constraint satisfaction and convergence speed.","We acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC), and thank NVIDIA corporation, USA for supporting this work through their GPU grant program.",,Neural Networks,,"Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Pattern Recognition, Automated; Supervised Machine Learning",2020-07-18,2020,2020-07-18,2020-10,130,,297-308,All OA, Green,Article,"Peng, Jizong; Kervadec, Hoel; Dolz, Jose; Ben Ayed, Ismail; Pedersoli, Marco; Desrosiers, Christian","Peng, Jizong (Department of Software and IT Engineering, ETS Montreal, 1100 Notre-Dame W., Montreal, H3C 1K3, Canada. Electronic address: jizong.peng.1@etsmtl.ca.); Kervadec, Hoel (Department of Automated Production, ETS Montreal, 1100 Notre-Dame W., Montreal, H3C 1K3, Canada.); Dolz, Jose (Department of Software and IT Engineering, ETS Montreal, 1100 Notre-Dame W., Montreal, H3C 1K3, Canada.); Ben Ayed, Ismail (Department of Automated Production, ETS Montreal, 1100 Notre-Dame W., Montreal, H3C 1K3, Canada.); Pedersoli, Marco (Department of Automated Production, ETS Montreal, 1100 Notre-Dame W., Montreal, H3C 1K3, Canada.); Desrosiers, Christian (Department of Software and IT Engineering, ETS Montreal, 1100 Notre-Dame W., Montreal, H3C 1K3, Canada. Electronic address: christian.desrosiers@etsmtl.ca.)","Peng, Jizong ","Peng, Jizong (); Kervadec, Hoel (); Dolz, Jose (); Ben Ayed, Ismail (); Pedersoli, Marco (); Desrosiers, Christian ()",19,17,1.02,9.41,http://arxiv.org/pdf/1908.05770,https://app.dimensions.ai/details/publication/pub.1129478814,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5198,pub.1129416212,10.1007/s10554-020-01935-0,32677023,PMC7568707,Fully automated quantification of left ventricular volumes and function in cardiac MRI: clinical evaluation of a deep learning-based algorithm,"To investigate the performance of a deep learning-based algorithm for fully automated quantification of left ventricular (LV) volumes and function in cardiac MRI. We retrospectively analysed MR examinations of 50 patients (74% men, median age 57 years). The most common indications were known or suspected ischemic heart disease, cardiomyopathies or myocarditis. Fully automated analysis of LV volumes and function was performed using a deep learning-based algorithm. The analysis was subsequently corrected by a senior cardiovascular radiologist. Manual volumetric analysis was performed by two radiology trainees. Volumetric results were compared using Bland–Altman statistics and intra-class correlation coefficient. The frequency of clinically relevant differences was analysed using re-classification rates. The fully automated volumetric analysis was completed in a median of 8 s. With expert review and corrections, the analysis required a median of 110 s. Median time required for manual analysis was 3.5 min for a cardiovascular imaging fellow and 9 min for a radiology resident (p < 0.0001 for all comparisons). The correlation between fully automated results and expert-corrected results was very strong with intra-class correlation coefficients of 0.998 for end-diastolic volume, 0.997 for end-systolic volume, 0.899 for stroke volume, 0.972 for ejection fraction and 0.991 for myocardial mass (all p < 0.001). Clinically meaningful differences between fully automated and expert corrected results occurred in 18% of cases, comparable to the rate between the two manual readers (20%). Deep learning-based fully automated analysis of LV volumes and function is feasible, time-efficient and highly accurate. Clinically relevant corrections are required in a minority of cases.",Open Access funding provided by Projekt DEAL.,,The International Journal of Cardiovascular Imaging,,"Adolescent; Adult; Aged; Aged, 80 and over; Automation; Deep Learning; Diagnosis, Computer-Assisted; Feasibility Studies; Female; Heart Diseases; Heart Ventricles; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Predictive Value of Tests; Reproducibility of Results; Retrospective Studies; Ventricular Function, Left; Young Adult",2020-07-16,2020,2020-07-16,2020-11,36,11,2239-2247,All OA, Hybrid,Article,"Böttcher, Benjamin; Beller, Ebba; Busse, Anke; Cantré, Daniel; Yücel, Seyrani; Öner, Alper; Ince, Hüseyin; Weber, Marc-André; Meinel, Felix G.","Böttcher, Benjamin (Institute of Diagnostic and Interventional Radiology, Paediatric Radiology and Neuroradiology, University Medical Centre Rostock, Ernst-Heydemann-Str. 6, 18057, Rostock, Germany); Beller, Ebba (Institute of Diagnostic and Interventional Radiology, Paediatric Radiology and Neuroradiology, University Medical Centre Rostock, Ernst-Heydemann-Str. 6, 18057, Rostock, Germany); Busse, Anke (Institute of Diagnostic and Interventional Radiology, Paediatric Radiology and Neuroradiology, University Medical Centre Rostock, Ernst-Heydemann-Str. 6, 18057, Rostock, Germany); Cantré, Daniel (Institute of Diagnostic and Interventional Radiology, Paediatric Radiology and Neuroradiology, University Medical Centre Rostock, Ernst-Heydemann-Str. 6, 18057, Rostock, Germany); Yücel, Seyrani (Department of Internal Medicine, Divison of Cardiology, University Medical Center Rostock, Rostock, Germany); Öner, Alper (Department of Internal Medicine, Divison of Cardiology, University Medical Center Rostock, Rostock, Germany); Ince, Hüseyin (Department of Internal Medicine, Divison of Cardiology, University Medical Center Rostock, Rostock, Germany); Weber, Marc-André (Institute of Diagnostic and Interventional Radiology, Paediatric Radiology and Neuroradiology, University Medical Centre Rostock, Ernst-Heydemann-Str. 6, 18057, Rostock, Germany); Meinel, Felix G. (Institute of Diagnostic and Interventional Radiology, Paediatric Radiology and Neuroradiology, University Medical Centre Rostock, Ernst-Heydemann-Str. 6, 18057, Rostock, Germany)","Meinel, Felix G. (Universitätsmedizin Rostock)","Böttcher, Benjamin (Universitätsmedizin Rostock); Beller, Ebba (Universitätsmedizin Rostock); Busse, Anke (Universitätsmedizin Rostock); Cantré, Daniel (Universitätsmedizin Rostock); Yücel, Seyrani (Universitätsmedizin Rostock); Öner, Alper (Universitätsmedizin Rostock); Ince, Hüseyin (Universitätsmedizin Rostock); Weber, Marc-André (Universitätsmedizin Rostock); Meinel, Felix G. (Universitätsmedizin Rostock)",12,12,0.93,6.74,https://link.springer.com/content/pdf/10.1007/s10554-020-01935-0.pdf,https://app.dimensions.ai/details/publication/pub.1129416212,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
1515,pub.1129329195,10.48550/arxiv.2007.06341,,,DeU-Net: Deformable U-Net for 3D Cardiac MRI Video Segmentation,"Automatic segmentation of cardiac magnetic resonance imaging (MRI)
facilitates efficient and accurate volume measurement in clinical applications.
However, due to anisotropic resolution and ambiguous border (e.g., right
ventricular endocardium), existing methods suffer from the degradation of
accuracy and robustness in 3D cardiac MRI video segmentation. In this paper, we
propose a novel Deformable U-Net (DeU-Net) to fully exploit spatio-temporal
information from 3D cardiac MRI video, including a Temporal Deformable
Aggregation Module (TDAM) and a Deformable Global Position Attention (DGPA)
network. First, the TDAM takes a cardiac MRI video clip as input with temporal
information extracted by an offset prediction network. Then we fuse extracted
temporal information via a temporal aggregation deformable convolution to
produce fused feature maps. Furthermore, to aggregate meaningful features, we
devise the DGPA network by employing deformable attention U-Net, which can
encode a wider range of multi-dimensional contextual information into global
and local features. Experimental results show that our DeU-Net achieves the
state-of-the-art performance on commonly used evaluation metrics, especially
for cardiac marginal information (ASSD and HD).",,,arXiv,,,2020-07-13,2020,,,,,,All OA, Green,Preprint,"Dong, Shunjie; Zhao, Jinlong; Zhang, Maojun; Shi, Zhengxue; Deng, Jianing; Shi, Yiyu; Tian, Mei; Zhuo, Cheng","Dong, Shunjie (); Zhao, Jinlong (); Zhang, Maojun (); Shi, Zhengxue (); Deng, Jianing (); Shi, Yiyu (); Tian, Mei (); Zhuo, Cheng ()",,"Dong, Shunjie (); Zhao, Jinlong (); Zhang, Maojun (); Shi, Zhengxue (); Deng, Jianing (); Shi, Yiyu (); Tian, Mei (); Zhuo, Cheng ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129329195,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
866,pub.1129147285,10.1007/s10462-020-09871-0,,,Dynamic uncertain causality graph for computer-aided general clinical diagnoses with nasal obstruction as an illustration,"Many AI systems have been developed for clinical diagnoses, in which most of them lack interpretability in both knowledge representation and inference results. The newly developed Dynamic Uncertain Causality Graph (DUCG) is a probabilistic graphical model with strong interpretability. However, existing DUCG is mainly for fault diagnoses of large, complex industrial systems. In this paper, we extend DUCG for better application in general clinical diagnoses. Four extensions are introduced: (1) special logic gate and zoom function event variables to represent and quantify the influences of various risk factors on the morbidities of diseases. (2) Reversal logic gate to model the case that some diseases/causes may result in at least two simultaneous symptoms/consequences. (3) Disease-specific manifestation variable for special inference and easy understanding to diagnose a specific disease. (4) Event attention importance to count contributions of isolated state-abnormal variables in inference. To illustrate and verify the extended DUCG methodology, we performed a case study for diagnosing 25 diseases causing nasal obstruction. We tested 171 cases randomly selected from total 471 cases of discharged patients in the hospital information system of Xuanwu Hospital. The diagnosis precision of the extended DUCG was 100%. The diagnosis precision of the third-party verification performed by Suining Central Hospital was 98.86%, which exhibited the strong generalization ability of the extended DUCG.","This research was fully supported by Beijing Tsingrui Intelligence Technology Co., Ltd.",,Artificial Intelligence Review,,,2020-07-10,2020,2020-07-10,2021-01,54,1,27-61,Closed,Article,"Zhang, Qin; Bu, Xusong; Zhang, Mingxia; Zhang, Zhan; Hu, Jie","Zhang, Qin (School of Computer Science and Engineering, Beihang University, 100191, Beijing, China; Department of Computer Science and Technology, Tsinghua University, 100084, Beijing, China); Bu, Xusong (School of Computer Science and Engineering, Beihang University, 100191, Beijing, China); Zhang, Mingxia (Otorhinolaryngology Head and Neck Surgery, Xuanwu Hospital, Capital Medical University, 100053, Beijing, China); Zhang, Zhan (Institute of Nuclear and New Energy Technology, Tsinghua University, 100084, Beijing, China); Hu, Jie (Department of Medical Administration, Suining Central Hospital, 629000, Suining, China)","Zhang, Qin (Beihang University; Tsinghua University); Zhang, Zhan (Tsinghua University)","Zhang, Qin (Beihang University; Tsinghua University); Bu, Xusong (Beihang University); Zhang, Mingxia (Xuan Wu Hospital of the Capital Medical University; Capital Medical University); Zhang, Zhan (Tsinghua University); Hu, Jie ()",11,9,,5.57,,https://app.dimensions.ai/details/publication/pub.1129147285,46 Information and Computing Sciences, 4602 Artificial Intelligence,3 Good Health and Well Being,,,,,,,,,,
955,pub.1129312482,10.48550/arxiv.2007.05363,,,Semi-supervised Task-driven Data Augmentation for Medical Image  Segmentation,"Supervised learning-based segmentation methods typically require a large
number of annotated training data to generalize well at test time. In medical
applications, curating such datasets is not a favourable option because
acquiring a large number of annotated samples from experts is time-consuming
and expensive. Consequently, numerous methods have been proposed in the
literature for learning with limited annotated examples. Unfortunately, the
proposed approaches in the literature have not yet yielded significant gains
over random data augmentation for image segmentation, where random
augmentations themselves do not yield high accuracy. In this work, we propose a
novel task-driven data augmentation method for learning with limited labeled
data where the synthetic data generator, is optimized for the segmentation
task. The generator of the proposed method models intensity and shape
variations using two sets of transformations, as additive intensity
transformations and deformation fields. Both transformations are optimized
using labeled as well as unlabeled examples in a semi-supervised framework. Our
experiments on three medical datasets, namely cardic, prostate and pancreas,
show that the proposed approach significantly outperforms standard augmentation
and semi-supervised approaches for image segmentation in the limited annotation
setting. The code is made publicly available at
https://github.com/krishnabits001/task$\_$driven$\_$data$\_$augmentation.",,,arXiv,,,2020-07-09,2020,,,,,,All OA, Green,Preprint,"Chaitanya, Krishna; Karani, Neerav; Baumgartner, Christian F.; Erdil, Ertunc; Becker, Anton; Donati, Olivio; Konukoglu, Ender","Chaitanya, Krishna (); Karani, Neerav (); Baumgartner, Christian F. (); Erdil, Ertunc (); Becker, Anton (); Donati, Olivio (); Konukoglu, Ender ()",,"Chaitanya, Krishna (); Karani, Neerav (); Baumgartner, Christian F. (); Erdil, Ertunc (); Becker, Anton (); Donati, Olivio (); Konukoglu, Ender ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129312482,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5057,pub.1129053822,10.3390/jimaging6070065,34460658,PMC8321054,Fully Automated 3D Cardiac MRI Localisation and Segmentation Using Deep Neural Networks,"Cardiac magnetic resonance (CMR) imaging is used widely for morphological assessment and diagnosis of various cardiovascular diseases. Deep learning approaches based on 3D fully convolutional networks (FCNs), have improved state-of-the-art segmentation performance in CMR images. However, previous methods have employed several pre-processing steps and have focused primarily on segmenting low-resolutions images. A crucial step in any automatic segmentation approach is to first localize the cardiac structure of interest within the MRI volume, to reduce false positives and computational complexity. In this paper, we propose two strategies for localizing and segmenting the heart ventricles and myocardium, termed multi-stage and end-to-end, using a 3D convolutional neural network. Our method consists of an encoder-decoder network that is first trained to predict a coarse localized density map of the target structure at a low resolution. Subsequently, a second similar network employs this coarse density map to crop the image at a higher resolution, and consequently, segment the target structure. For the latter, the same two-stage architecture is trained end-to-end. The 3D U-Net with some architectural changes (referred to as 3D DR-UNet) was used as the base architecture in this framework for both the multi-stage and end-to-end strategies. Moreover, we investigate whether the incorporation of coarse features improves the segmentation. We evaluate the two proposed segmentation strategies on two cardiac MRI datasets, namely, the Automatic Cardiac Segmentation Challenge (ACDC) STACOM 2017, and Left Atrium Segmentation Challenge (LASC) STACOM 2018. Extensive experiments and comparisons with other state-of-the-art methods indicate that the proposed multi-stage framework consistently outperforms the rest in terms of several segmentation metrics. The experimental results highlight the robustness of the proposed approach, and its ability to generate accurate high-resolution segmentations, despite the presence of varying degrees of pathology-induced changes to cardiac morphology and image appearance, low contrast, and noise in the CMR volumes.","This work described in this paper was partially supported by the project BIG-THERA: Integrative ‘BigData Modeling’ for the development of novel therapeutic approaches for breast cancer, and the BMBF grant: Using big data to advance breast cancer research. The authors would also like to thank NVIDIA for donating a Titan X-Pascal GPU.",This research received no external funding.,Journal of Imaging,,,2020-07-06,2020,2020-07-06,,6,7,65,All OA, Gold,Article,"Vesal, Sulaiman; Maier, Andreas; Ravikumar, Nishant","Vesal, Sulaiman (Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, 91052 Erlangen, Germany;, andreas.maier@fau.de, (A.M.);, n.ravikumar@leeds.ac.uk, (N.R.)); Maier, Andreas (Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, 91052 Erlangen, Germany;, andreas.maier@fau.de, (A.M.);, n.ravikumar@leeds.ac.uk, (N.R.)); Ravikumar, Nishant (Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg, 91052 Erlangen, Germany;, andreas.maier@fau.de, (A.M.);, n.ravikumar@leeds.ac.uk, (N.R.); Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, LICAMM Leeds Institute of Cardiovascular and Metabolic Medicine, School of Medicine, University of Leeds, Leeds LS2 9JT, UK)","Vesal, Sulaiman (University of Erlangen-Nuremberg; )","Vesal, Sulaiman (University of Erlangen-Nuremberg); Maier, Andreas (University of Erlangen-Nuremberg); Ravikumar, Nishant (University of Erlangen-Nuremberg; University of Leeds)",13,12,1.07,6.7,https://www.mdpi.com/2313-433X/6/7/65/pdf?version=1594791167,https://app.dimensions.ai/details/publication/pub.1129053822,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
913,pub.1128948394,10.48550/arxiv.2007.01152,,,Learning to Segment from Scribbles using Multi-scale Adversarial  Attention Gates,"Large, fine-grained image segmentation datasets, annotated at pixel-level,
are difficult to obtain, particularly in medical imaging, where annotations
also require expert knowledge. Weakly-supervised learning can train models by
relying on weaker forms of annotation, such as scribbles. Here, we learn to
segment using scribble annotations in an adversarial game. With unpaired
segmentation masks, we train a multi-scale GAN to generate realistic
segmentation masks at multiple resolutions, while we use scribbles to learn
their correct position in the image. Central to the model's success is a novel
attention gating mechanism, which we condition with adversarial signals to act
as a shape prior, resulting in better object localization at multiple scales.
Subject to adversarial conditioning, the segmentor learns attention maps that
are semantic, suppress the noisy activations outside the objects, and reduce
the vanishing gradient problem in the deeper layers of the segmentor. We
evaluated our model on several medical (ACDC, LVSC, CHAOS) and non-medical
(PPSS) datasets, and we report performance levels matching those achieved by
models trained with fully annotated segmentation masks. We also demonstrate
extensions in a variety of settings: semi-supervised learning; combining
multiple scribble sources (a crowdsourcing scenario) and multi-task learning
(combining scribble and mask supervision). We release expert-made scribble
annotations for the ACDC dataset, and the code used for the experiments, at
https://vios-s.github.io/multiscale-adversarial-attention-gates",,,arXiv,,,2020-07-02,2020,,,,,,All OA, Green,Preprint,"Valvano, Gabriele; Leo, Andrea; Tsaftaris, Sotirios A.","Valvano, Gabriele (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",,"Valvano, Gabriele (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128948394,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5851,pub.1128922352,10.1016/j.ejrad.2020.109158,32652404,,Early diagnosis of chemotherapy-induced cardiotoxicity by cardiac MRI,"Survival rate in cancer patients has improved over the course of the years. In cancer survivors, cardiovascular disease is the second leading cause of mortality and early detection and serial monitoring of cardiotoxicity are key factors towards the improvement of patients' outcomes. This review article will provide an overview of the existing literature regarding the tools that MRI can offer in the early diagnosis of myocardial damage.",,,European Journal of Radiology,,Antineoplastic Agents, Cardiotoxicity, Female, Heart, Heart Diseases, Humans, Magnetic Resonance Imaging,2020-07-01,2020,2020-07-01,2020-09,130,,109158,Closed,Article,"Cau, Riccardo; Bassareo, Pierpaolo; Cherchi, Valeria; Palmisano, Vitanio; Suri, Jasjit S.; Porcu, Michele; Balestrieri, Antonella; Pontone, Gianluca; Saba, Luca","Cau, Riccardo (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari – Polo di Monserrato, s.s. 554 Monserrato, Cagliari, 09045, Italy); Bassareo, Pierpaolo (University College of Dublin, Mater Misericordiae University Hospital and Our Lady's Children's Hospital, Crumlin, Dublin, Ireland); Cherchi, Valeria (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari – Polo di Monserrato, s.s. 554 Monserrato, Cagliari, 09045, Italy); Palmisano, Vitanio (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari – Polo di Monserrato, s.s. 554 Monserrato, Cagliari, 09045, Italy; Radiology Department, Miulli Hospital, Acquaviva delle Fonti, Italy Strada Prov. 127 Acquaviva – Santeramo Km. 4,100, 70021, Acquaviva delle Fonti, BA, Italy); Suri, Jasjit S. (Diagnostic and Monitoring Division, AtheroPoint™ LLC, Roseville, CA, 95661, United States); Porcu, Michele (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari – Polo di Monserrato, s.s. 554 Monserrato, Cagliari, 09045, Italy); Balestrieri, Antonella (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari – Polo di Monserrato, s.s. 554 Monserrato, Cagliari, 09045, Italy); Pontone, Gianluca (Centro Cardiologico Monzino, IRCCS, Milan, Italy); Saba, Luca (Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), di Cagliari – Polo di Monserrato, s.s. 554 Monserrato, Cagliari, 09045, Italy)","Saba, Luca (Azienda Ospedaliero-Universitaria Cagliari)","Cau, Riccardo (Azienda Ospedaliero-Universitaria Cagliari); Bassareo, Pierpaolo (University College Dublin); Cherchi, Valeria (Azienda Ospedaliero-Universitaria Cagliari); Palmisano, Vitanio (Azienda Ospedaliero-Universitaria Cagliari); Suri, Jasjit S. (); Porcu, Michele (Azienda Ospedaliero-Universitaria Cagliari); Balestrieri, Antonella (Azienda Ospedaliero-Universitaria Cagliari); Pontone, Gianluca (Centro Cardiologico Monzino); Saba, Luca (Azienda Ospedaliero-Universitaria Cagliari)",17,16,1.56,8.33,,https://app.dimensions.ai/details/publication/pub.1128922352,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,3 Good Health and Well Being,,,,
5203,pub.1128927099,10.1148/ryai.2020190195,33937833,PMC8082399,MRI Manufacturer Shift and Adaptation: Increasing the Generalizability of Deep Learning Segmentation for MR Images Acquired with Different Scanners,"PURPOSE: To quantitatively evaluate the generalizability of a deep learning segmentation tool to MRI data from scanners of different MRI manufacturers and to improve the cross-manufacturer performance by using a manufacturer-adaptation strategy.
MATERIALS AND METHODS: This retrospective study included 150 cine MRI datasets from three MRI manufacturers, acquired between 2017 and 2018 (n = 50 for manufacturer 1, manufacturer 2, and manufacturer 3). Three convolutional neural networks (CNNs) were trained to segment the left ventricle (LV), using datasets exclusively from images from a single manufacturer. A generative adversarial network (GAN) was trained to adapt the input image before segmentation. The LV segmentation performance, end-diastolic volume (EDV), end-systolic volume (ESV), LV mass, and LV ejection fraction (LVEF) were evaluated before and after manufacturer adaptation. Paired Wilcoxon signed rank tests were performed.
RESULTS: The segmentation CNNs exhibited a significant performance drop when applied to datasets from different manufacturers (Dice reduced from 89.7% ± 2.3 [standard deviation] to 68.7% ± 10.8, P < .05, from 90.6% ± 2.1 to 59.5% ± 13.3, P < .05, from 89.2% ± 2.3 to 64.1% ± 12.0, P < .05, for manufacturer 1, 2, and 3, respectively). After manufacturer adaptation, the segmentation performance was significantly improved (from 68.7% ± 10.8 to 84.3% ± 6.2, P < .05, from 72.4% ± 10.2 to 85.7% ± 6.5, P < .05, for manufacturer 2 and 3, respectively). Quantitative LV function parameters were also significantly improved. For LVEF, the manufacturer adaptation increased the Pearson correlation from 0.005 to 0.89 for manufacturer 2 and from 0.77 to 0.94 for manufacturer 3.
CONCLUSION: A segmentation CNN well trained on datasets from one MRI manufacturer may not generalize well to datasets from other manufacturers. The proposed manufacturer adaptation can largely improve the generalizability of a deep learning segmentation tool without additional annotation.Supplemental material is available for this article.© RSNA, 2020.",Authors declared no funding for this work. convolutional neural network end-diastolic volume end-systolic volume generative adversarial network left ventricle left ventricular ejection fraction,,Radiology Artificial Intelligence,,,2020-07-01,2020,2020-07-01,2020-07-01,2,4,e190195,All OA, Bronze,Article,"Yan, Wenjun; Huang, Lu; Xia, Liming; Gu, Shengjia; Yan, Fuhua; Wang, Yuanyuan; Tao, Qian","Yan, Wenjun (Biomedical Engineering Center, Fudan University, Shanghai, China (W.Y., Y.W.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, Shanghai, China (S.G., F.Y.); and Division of Image Processing, Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T.).); Huang, Lu (Biomedical Engineering Center, Fudan University, Shanghai, China (W.Y., Y.W.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, Shanghai, China (S.G., F.Y.); and Division of Image Processing, Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T.).); Xia, Liming (Biomedical Engineering Center, Fudan University, Shanghai, China (W.Y., Y.W.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, Shanghai, China (S.G., F.Y.); and Division of Image Processing, Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T.).); Gu, Shengjia (Biomedical Engineering Center, Fudan University, Shanghai, China (W.Y., Y.W.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, Shanghai, China (S.G., F.Y.); and Division of Image Processing, Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T.).); Yan, Fuhua (Biomedical Engineering Center, Fudan University, Shanghai, China (W.Y., Y.W.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, Shanghai, China (S.G., F.Y.); and Division of Image Processing, Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T.).); Wang, Yuanyuan (Biomedical Engineering Center, Fudan University, Shanghai, China (W.Y., Y.W.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, Shanghai, China (S.G., F.Y.); and Division of Image Processing, Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T.).); Tao, Qian (Biomedical Engineering Center, Fudan University, Shanghai, China (W.Y., Y.W.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, Shanghai, China (S.G., F.Y.); and Division of Image Processing, Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T.).)",,"Yan, Wenjun (Fudan University); Huang, Lu (Fudan University); Xia, Liming (Fudan University); Gu, Shengjia (Fudan University); Yan, Fuhua (Fudan University); Wang, Yuanyuan (Fudan University); Tao, Qian (Fudan University)",26,23,1.96,12.75,https://pubs.rsna.org/doi/pdf/10.1148/ryai.2020190195,https://app.dimensions.ai/details/publication/pub.1128927099,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
5016,pub.1129100084,10.1148/ryai.2020190064,32797119,PMC7392063,Clinical Performance and Role of Expert Supervision of Deep Learning for Cardiac Ventricular Volumetry: A Validation Study,"PURPOSE: To evaluate the performance of a deep learning (DL) algorithm for clinical measurement of right and left ventricular volume and function across cardiac MR images obtained for a range of clinical indications and pathologies.
MATERIALS AND METHODS: A retrospective, Health Insurance Portability and Accountability Act-compliant study was conducted using the first 200 noncongenital clinical cardiac MRI examinations from June 2015 to June 2017 for which volumetry was available. Images were analyzed using commercially available software for automated DL-based and manual contouring of biventricular volumes. Fully automated measurements were compared using Pearson correlations, relative volume errors, and Bland-Altman analyses. Manual, automated, and expert revised contours for 50 MR images were examined by comparing regional Dice coefficients at the base, midventricle, and apex to further analyze the contour quality.
RESULTS: Fully automated and manual left ventricular volumes were strongly correlated for end-systolic volume (ESV: Pearson r = 0.99, P < .001), end-diastolic volume (EDV: r = 0.97, P < .001), and ejection fraction (EF: r = 0.94, P < .001). Right ventricular measurements were also correlated for ESV (r = 0.93, P < .001), EDV (r = 0.92, P < .001), and EF (r = 0.73, P < .001). Visual inspection of segmentation quality showed most errors (73%) occurred at the cardiac base. Mean Dice coefficients between manual, automated, and expert revised contours ranged from 0.92 to 0.95, with greatest variance at the base and apex.
CONCLUSION: Fully automated ventricular segmentation by the tested algorithm provides contours and ventricular volumes that could be used to aid expert segmentation, but can benefit from expert supervision, particularly to resolve errors at the basal and apical slices. Supplemental material is available for this article. © RSNA, 2020.","The authors would like to thank Kevin Blansit, Kang Wang, and Naeim Bahrami for their kind support and insightful discussions. deep learning end-diastolic volume end diastole ejection fraction end systole end-systolic volume left ventricular right ventricular",,Radiology Artificial Intelligence,,,2020-07-01,2020,2020-07-08,2020-07-01,2,4,e190064,All OA, Bronze,Article,"Retson, Tara A; Masutani, Evan M; Golden, Daniel; Hsiao, Albert","Retson, Tara A (Department of Radiology, Altman Clinical and Translational Research Institute, University of California, San Diego, 9452 Medical Center Dr, 4th Floor, La Jolla, CA 92037 (T.A.R., A.H.); Department of Bioengineering, University of California San Diego School of Medicine, La Jolla, Calif (E.M.M.); and Arterys, San Francisco, Calif (D.G.).); Masutani, Evan M (Department of Radiology, Altman Clinical and Translational Research Institute, University of California, San Diego, 9452 Medical Center Dr, 4th Floor, La Jolla, CA 92037 (T.A.R., A.H.); Department of Bioengineering, University of California San Diego School of Medicine, La Jolla, Calif (E.M.M.); and Arterys, San Francisco, Calif (D.G.).); Golden, Daniel (Department of Radiology, Altman Clinical and Translational Research Institute, University of California, San Diego, 9452 Medical Center Dr, 4th Floor, La Jolla, CA 92037 (T.A.R., A.H.); Department of Bioengineering, University of California San Diego School of Medicine, La Jolla, Calif (E.M.M.); and Arterys, San Francisco, Calif (D.G.).); Hsiao, Albert (Department of Radiology, Altman Clinical and Translational Research Institute, University of California, San Diego, 9452 Medical Center Dr, 4th Floor, La Jolla, CA 92037 (T.A.R., A.H.); Department of Bioengineering, University of California San Diego School of Medicine, La Jolla, Calif (E.M.M.); and Arterys, San Francisco, Calif (D.G.).)",,"Retson, Tara A (University of California, San Diego); Masutani, Evan M (University of California, San Diego); Golden, Daniel (University of California, San Diego); Hsiao, Albert (University of California, San Diego)",12,11,0.72,7.02,https://pubs.rsna.org/doi/pdf/10.1148/ryai.2020190064,https://app.dimensions.ai/details/publication/pub.1129100084,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences, 4612 Software Engineering,,,,,,,,
8071,pub.1130400296,10.1109/embc44109.2020.9176059,33018239,,Validation of a diffeomorphic registration algorithm using true deformation computed from thin plate spline interpolation,"Despite the inter and intraobserver variabilities, manual contours are commonly used as surrogates for ground truth in the validation process for nonrigid medical image registration. In contrast, this study proposes the use of thin plate spline interpolation to create a true deformation field. A diffeomorphic registration method was compared to the true deformation field along with three other algorithms and was evaluated on simulated cardiac motion deformation over 10 subjects from the Automated Cardiac Diagnosis Challenge (ACDC) dataset. Two sequential registration approaches were undertaken: with respect to the first frame, and with respect to the previous frame. The Dice score was calculated between the simulated and warped contours for the two approaches: diffeomorphic registration method =0.991 and 0.997, RealTITracker (L2L2 method) = 0.971 and 0.977, RealTITracker (L2L1 method) = 0.975 and 0.978, and Elastix = 0.976 and 0.994. The results demonstrate the robust performance of the diffeomorphic registration method.Clinical relevance This establishes a validation of a registration method that can be used for segmentation of chambers of the heart.","The authors would like to thank the following organizations for providing the research funding that supported this work: CIHR/NSERC Collaborative Health Research Projects (CHRP), NSERC Discovery Grant and Servier Canada Inc.",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),Algorithms, Bone Plates, Heart, Reproducibility of Results,2020-07,2020,,2020-07,0,,1351-1354,Closed,Proceeding,"Krishnaswamy, Deepa; Noga, Michelle; Punithakumar, Kumaradevan","Krishnaswamy, Deepa (Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Canada); Noga, Michelle (Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Canada); Punithakumar, Kumaradevan (Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Canada)","Krishnaswamy, Deepa (University of Alberta)","Krishnaswamy, Deepa (University of Alberta); Noga, Michelle (University of Alberta); Punithakumar, Kumaradevan (University of Alberta)",1,1,,0.6,,https://app.dimensions.ai/details/publication/pub.1130400296,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,
7573,pub.1130399574,10.1109/embc44109.2020.9175256,33018203,,Improving the generalization of deep learning methods to segment the left ventricle in short axis MR images,"Cardiovascular disease is one of the major health problems worldwide. In clinical practice, cardiac magnetic resonance imaging (CMR) is considered the gold-standard imaging modality for the evaluation of the function and structure of the left ventricle (LV). More recently, deep learning methods have been used to segment LV with impressive results. On the other hand, this kind of approach is prone to overfit the training data, and it does not generalize well between different data acquisition centers, thus creating constraints to the use in daily routines. In this paper, we explore methods to improve the generalization in the segmentation performed by a convolutional neural network. We applied a U-net based architecture and compared two different pre-processing methods to improve uniformity in the image contrast between five cross-dataset training and testing. Overall, we were able to perform the segmentation of the left ventricle using multiple cross-dataset combinations of train and test, with a mean endocardium dice score of 0.82.Clinical Relevance- This work improves the result between the cross-dataset evaluation of the left ventricle segmentation, reducing the constraints for daily clinical adoption of a fully-automatic segmentation method.",This work was supported by Canon Medical System Corp. and Zerbini Foundation as part of the research &quot,New techniques of acquisition and post-processing in CMR for heart Failure: From Subclinical to Established Myocardial Disease&quot,.,,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),Algorithms, Deep Learning, Heart, Heart Ventricles, Magnetic Resonance Imaging,2020-07,2020,,2020-07,0,,1203-1206,All OA, Bronze,Proceeding,"Graves, Catharine V.; Moreno, Ramon A.; Rebelo, Marina S.; Nomura, Cesar H.; Gutierrez, Marco A.","Graves, Catharine V. (Heart Institute, Clinics Hospital, University of Sao Paulo Medical School, Av. Dr Eneas de Carvalho Aguiar, 44, 0503-900, Sao Paulo, SP, Brazil); Moreno, Ramon A. (Heart Institute, Clinics Hospital, University of Sao Paulo Medical School, Av. Dr Eneas de Carvalho Aguiar, 44, 0503-900, Sao Paulo, SP, Brazil); Rebelo, Marina S. (Heart Institute, Clinics Hospital, University of Sao Paulo Medical School, Av. Dr Eneas de Carvalho Aguiar, 44, 0503-900, Sao Paulo, SP, Brazil); Nomura, Cesar H. (Heart Institute, Clinics Hospital, University of Sao Paulo Medical School, Av. Dr Eneas de Carvalho Aguiar, 44, 0503-900, Sao Paulo, SP, Brazil); Gutierrez, Marco A. (Heart Institute, Clinics Hospital, University of Sao Paulo Medical School, Av. Dr Eneas de Carvalho Aguiar, 44, 0503-900, Sao Paulo, SP, Brazil)","Graves, Catharine V. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo)","Graves, Catharine V. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo); Moreno, Ramon A. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo); Rebelo, Marina S. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo); Nomura, Cesar H. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo); Gutierrez, Marco A. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo)",5,5,0.14,2.45,https://ieeexplore.ieee.org/ielx7/9167168/9175149/09175256.pdf,https://app.dimensions.ai/details/publication/pub.1130399574,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,3 Good Health and Well Being,,
7257,pub.1130399986,10.1109/embc44109.2020.9175749,33018202,,A Semi-Automatic Method To Segment The Left Atrium in MR Volumes With Varying Slice Numbers,"Atrial fibrillation (AF) is the most common sustained arrhythmia and is associated with dramatic increases in mortality and morbidity. Atrial cine MR images are increasingly used in the management of this condition, but there are few specific tools to aid in the segmentation of such data. Some characteristics of atrial cine MR (thick slices, variable number of slices in a volume) preclude the direct use of traditional segmentation tools. When combined with scarcity of labelled data and similarity of the intensity and texture of the left atrium (LA) to other cardiac structures, the segmentation of the LA in CINE MRI becomes a difficult task. To deal with these challenges, we propose a semi-automatic method to segment the left atrium (LA) in MR images, which requires an initial user click per volume. The manually given location information is used to generate a chamber location map to roughly locate the LA, which is then used as an input to a deep network with slightly over 0.5 million parameters. A tracking method is introduced to pass the location information across a volume and to remove unwanted structures in segmentation maps. According to the results of our experiments conducted in an in-house MRI dataset, the proposed method outperforms the U-Net [1] with a margin of 20 mm on Hausdorff distance and 0.17 on Dice score, with limited manual interaction.","This research was supported by the Wellcome/EPSRC Centre for Medical Engineering [WT203148/Z/16/Z], the Medical Imaging Network (MedIAN) [EP/N026993/1] and the British Heart Foundation Centre of Research Excellence at Imperial College London [RE/18/4/34215]. This research was supported by the Wellcome/EPSRC Centre for Medical Engineering [WT203148/Z/16/Z], the Medical Imaging Network (MedIAN) [EP/N026993/1] and the British Heart Foundation Centre of Research Excellence at Imperial College London [RE/18/4/34215].",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Atrial Fibrillation; Heart Atria; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine",2020-07,2020,,2020-07,0,,1198-1202,All OA, Bronze,Proceeding,"Uslu, Fatmatülzehra; Varela, Marta; Bharath, Anil A.","Uslu, Fatmatülzehra (Bursa Technical University, Department of Electrical-Electronics Engineering, Turkey); Varela, Marta (School of Biomedical Engineering Imaging Sciences, King’s College, London, UK; National Heart and Lung Institute, Bioengineering Department, Imperial College, London, UK); Bharath, Anil A. (Imperial College London, Department of Bioengineering, UK)","Uslu, Fatmatülzehra (Bursa Technical University)","Uslu, Fatmatülzehra (Bursa Technical University); Varela, Marta (King's College London; Imperial College London); Bharath, Anil A. (Imperial College London)",2,2,,1.52,https://ieeexplore.ieee.org/ielx7/9167168/9175149/09175749.pdf,https://app.dimensions.ai/details/publication/pub.1130399986,46 Information and Computing Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
6181,pub.1130400728,10.1109/embc44109.2020.9176491,33018206,PMC8169002,L-CO-Net: Learned Condensation-Optimization Network for Segmentation and Clinical Parameter Estimation from Cardiac Cine MRI,"In this work, we implement a fully convolutional segmenter featuring both a learned group structure and a regularized weight-pruner to reduce the high computational cost in volumetric image segmentation. We validated our framework on the ACDC dataset featuring one healthy and four pathology patient groups imaged throughout the cardiac cycle. Our technique achieved Dice scores of 96.8% (LV blood-pool), 93.3% (RV blood-pool), and 90.0% (LV Myocardium) with five-fold cross-validation and yielded similar clinical parameters as those estimated from the ground-truth segmentation data. Based on these results, this technique has the potential to become an efficient and competitive cardiac image segmentation tool that may be used for cardiac computer-aided diagnosis, planning, and guidance applications.","Research reported in this publication was supported by the National Institute of General Medical Sciences Award No. R35GM128877 of the National Institutes of Health, and the Office of Advanced Cyber infrastructure Award No. 1808530 of the National Science Foundation.",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Algorithms; Heart; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2020-07,2020,,2020-07,0,,1217-1220,Closed,Proceeding,"Hasan, S. M. Kamrul; Linte, Cristian A.","Hasan, S. M. Kamrul (Center for Imaging Science, Rochester Institute of Technology, Rochester, NY); Linte, Cristian A. (Center for Imaging Science, Rochester Institute of Technology, Rochester, NY; Biomedical Engineering, Rochester Institute of Technology, Rochester, NY)","Hasan, S. M. Kamrul (Rochester Institute of Technology)","Hasan, S. M. Kamrul (Rochester Institute of Technology); Linte, Cristian A. (Rochester Institute of Technology; Rochester Institute of Technology)",5,5,0.94,2.45,,https://app.dimensions.ai/details/publication/pub.1130400728,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,,
4548,pub.1128843758,10.3389/fcvm.2020.00105,32714943,PMC7344224,Improving the Generalizability of Convolutional Neural Network-Based Segmentation on CMR Images,"Background: Convolutional neural network (CNN) based segmentation methods provide an efficient and automated way for clinicians to assess the structure and function of the heart in cardiac MR images. While CNNs can generally perform the segmentation tasks with high accuracy when training and test images come from the same domain (e.g., same scanner or site), their performance often degrades dramatically on images from different scanners or clinical sites. Methods: We propose a simple yet effective way for improving the network generalization ability by carefully designing data normalization and augmentation strategies to accommodate common scenarios in multi-site, multi-scanner clinical imaging data sets. We demonstrate that a neural network trained on a single-site single-scanner dataset from the UK Biobank can be successfully applied to segmenting cardiac MR images across different sites and different scanners without substantial loss of accuracy. Specifically, the method was trained on a large set of 3,975 subjects from the UK Biobank. It was then directly tested on 600 different subjects from the UK Biobank for intra-domain testing and two other sets for cross-domain testing: the ACDC dataset (100 subjects, 1 site, 2 scanners) and the BSCMR-AS dataset (599 subjects, 6 sites, 9 scanners). Results: The proposed method produces promising segmentation results on the UK Biobank test set which are comparable to previously reported values in the literature, while also performing well on cross-domain test sets, achieving a mean Dice metric of 0.90 for the left ventricle, 0.81 for the myocardium, and 0.82 for the right ventricle on the ACDC dataset; and 0.89 for the left ventricle, 0.83 for the myocardium on the BSCMR-AS dataset. Conclusions: The proposed method offers a potential solution to improve CNN-based model generalizability for the cross-scanner and cross-site cardiac MR image segmentation task.","This research has been conducted mainly using the UK Biobank Resource under Application Number 40119 and 2964. The authors wish to thank all UK Biobank, ACDC, and BSCMR-AS participants and staff.","Funding. This work was supported by the SmartHeart EPSRC Programme Grant (EP/P001009/1). CM was supported directly and indirectly by the University College London Hospitals, NIHR Biomedical Research Centre, and Biomedical Research Unit at Barts Hospital, respectively. SN, EL, and SPi are supported by the Oxford NIHR Biomedical Research Centre. SPe, SPi, and SN acknowledge the British Heart Foundation (BHF) for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5000 CMR scans (PG/14/89/31194). RD was funded through the CAP-AI program by a grant from the European Regional Development Fund and Barts Charity (EDRF 23R17P01765).",Frontiers in Cardiovascular Medicine,,,2020-06-30,2020,2020-06-30,,7,,105,All OA, Gold,Article,"Chen, Chen; Bai, Wenjia; Davies, Rhodri H.; Bhuva, Anish N.; Manisty, Charlotte H.; Augusto, Joao B.; Moon, James C; Aung, Nay; Lee, Aaron M.; Sanghvi, Mihir M.; Fung, Kenneth; Paiva, Jose Miguel; Petersen, Steffen E.; Lukaschuk, Elena; Piechnik, Stefan K.; Neubauer, Stefan; Rueckert, Daniel","Chen, Chen (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom); Bai, Wenjia (Data Science Institute, Imperial College London, London, United Kingdom; Department of Brain Sciences, Imperial College London, London, United Kingdom); Davies, Rhodri H. (Institute of Cardiovascular Science, University College London, London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom); Bhuva, Anish N. (Institute of Cardiovascular Science, University College London, London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom); Manisty, Charlotte H. (Institute of Cardiovascular Science, University College London, London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom); Augusto, Joao B. (Institute of Cardiovascular Science, University College London, London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom); Moon, James C (Institute of Cardiovascular Science, University College London, London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom); Aung, Nay (Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom; NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom); Lee, Aaron M. (Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom; NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom); Sanghvi, Mihir M. (Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom; NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom); Fung, Kenneth (Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom; NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom); Paiva, Jose Miguel (Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom; NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom); Petersen, Steffen E. (Department of Cardiovascular Imaging, Barts Heart Centre, St Bartholomew's Hospital, London, United Kingdom; NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom); Lukaschuk, Elena (NIHR BRC Oxford, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, London, United Kingdom); Piechnik, Stefan K. (NIHR BRC Oxford, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, London, United Kingdom); Neubauer, Stefan (NIHR BRC Oxford, Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, London, United Kingdom); Rueckert, Daniel (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom)","Chen, Chen (Imperial College London)","Chen, Chen (Imperial College London); Bai, Wenjia (Imperial College London; Imperial College London); Davies, Rhodri H. (University College London; St Bartholomew's Hospital); Bhuva, Anish N. (University College London; St Bartholomew's Hospital); Manisty, Charlotte H. (University College London; St Bartholomew's Hospital); Augusto, Joao B. (University College London; St Bartholomew's Hospital); Moon, James C (University College London; St Bartholomew's Hospital); Aung, Nay (St Bartholomew's Hospital; Queen Mary University of London); Lee, Aaron M. (St Bartholomew's Hospital; Queen Mary University of London); Sanghvi, Mihir M. (St Bartholomew's Hospital; Queen Mary University of London); Fung, Kenneth (St Bartholomew's Hospital; Queen Mary University of London); Paiva, Jose Miguel (St Bartholomew's Hospital; Queen Mary University of London); Petersen, Steffen E. (St Bartholomew's Hospital; Queen Mary University of London); Lukaschuk, Elena (University of Oxford); Piechnik, Stefan K. (University of Oxford); Neubauer, Stefan (University of Oxford); Rueckert, Daniel (Imperial College London)",66,55,3.51,32.36,https://www.frontiersin.org/articles/10.3389/fcvm.2020.00105/pdf,https://app.dimensions.ai/details/publication/pub.1128843758,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
5672,pub.1128849277,10.1016/j.compbiomed.2020.103884,32658792,,Semi-supervised generative adversarial networks for the segmentation of the left ventricle in pediatric MRI,"Segmentation of the left ventricle in magnetic resonance imaging (MRI) is important for assessing cardiac function. We present DT-GAN, a generative adversarial network (GAN) segmentation approach for the identification of the left ventricle in pediatric MRI. Segmentation of the left ventricle requires a large amount of annotated data; generating such data can be time-consuming and subject to observer variability. Additionally, it can be difficult to accomplish in a clinical setting. During the training of our GAN, we therefore introduce a semi-supervised semantic segmentation to reduce the number of images required for training, while maintaining a good segmentation accuracy. The GAN generator produces a segmentation label map and its discriminator outputs a confidence map, which gives the probability of a pixel coming from the label or from the generator. Moreover, we propose a new formulation of the GAN loss function based on distance transform and pixel-wise cross-entropy. This new loss function provides a better segmentation of boundary pixels, by favoring the correct classification of those pixels rather than focusing on pixels that are farther away from the boundary between anatomical structures. Our proposed method achieves a mean Hausdorff distance of 2.16 mm ± 0.42 mm (2.28 mm ± 0.21 mm for U-Net) and a Dice score of 0.88 ± 0.08 (0.91 ± 0.12 for U-Net) for the endocardium segmentation, using 50% of the annotated data. For the epicardium segmentation, we achieve a mean Hausdorff distance of 2.23 mm ± 0.35 mm (2.34 mm ± 0.39 mm for U-Net) and a Dice score of 0.93 mm ± 0.04 mm (0.89 ± 0.09 for U-Net). For the myocardium segmentation, we achieve a mean Hausdorff distance of 2.98 mm ± 0.43 mm (3.04 mm ± 0.27 mm for U-Net) and a Dice score of 0.79 mm ± 0.10 mm (0.74 ± 0.04 for U-Net). This new model could be very useful for the automatic analysis of cardiac MRI and for conducting large-scale studies based on MRI readings, with a limited amount of training data.",The Titan Xp used for this research was donated by the NVIDIA Corporation.,,Computers in Biology and Medicine,,"Child; Heart; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging",2020-06-29,2020,2020-06-29,2020-08,123,,103884,All OA, Bronze,Article,"Decourt, Colin; Duong, Luc","Decourt, Colin (Bordeaux INP - ENSEIRB-MATMECA, 1 Avenue du Dr Albert Schweitzer, Talence, France); Duong, Luc (Ecole de technologie superieure, Department of Software and IT Engineering, 1100 Notre-Dame W., Montreal, Canada)","Decourt, Colin (Institut Polytechnique de Bordeaux)","Decourt, Colin (Institut Polytechnique de Bordeaux); Duong, Luc (École de Technologie Supérieure)",17,17,1.64,8.76,https://www.sciencedirect.com/science/article/am/pii/S0010482520302353,https://app.dimensions.ai/details/publication/pub.1128849277,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1459,pub.1128847402,10.48550/arxiv.2006.15710,,,Motion Pyramid Networks for Accurate and Efficient Cardiac Motion  Estimation,"Cardiac motion estimation plays a key role in MRI cardiac feature tracking
and function assessment such as myocardium strain. In this paper, we propose
Motion Pyramid Networks, a novel deep learning-based approach for accurate and
efficient cardiac motion estimation. We predict and fuse a pyramid of motion
fields from multiple scales of feature representations to generate a more
refined motion field. We then use a novel cyclic teacher-student training
strategy to make the inference end-to-end and further improve the tracking
performance. Our teacher model provides more accurate motion estimation as
supervision through progressive motion compensations. Our student model learns
from the teacher model to estimate motion in a single step while maintaining
accuracy. The teacher-student knowledge distillation is performed in a cyclic
way for a further performance boost. Our proposed method outperforms a strong
baseline model on two public available clinical datasets significantly,
evaluated by a variety of metrics and the inference time. New evaluation
metrics are also proposed to represent errors in a clinically meaningful
manner.",,,arXiv,,,2020-06-28,2020,,,,,,All OA, Green,Preprint,"Yu, Hanchao; Chen, Xiao; Shi, Humphrey; Chen, Terrence; Huang, Thomas S.; Sun, Shanhui","Yu, Hanchao (); Chen, Xiao (); Shi, Humphrey (); Chen, Terrence (); Huang, Thomas S. (); Sun, Shanhui ()",,"Yu, Hanchao (); Chen, Xiao (); Shi, Humphrey (); Chen, Terrence (); Huang, Thomas S. (); Sun, Shanhui ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128847402,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
862,pub.1128829772,10.48550/arxiv.2006.14815,,,A Co-Design Framework of Neural Networks and Quantum Circuits Towards  Quantum Advantage,"Despite the pursuit of quantum advantages in various applications, the power
of quantum computers in neural network computations has mostly remained
unknown, primarily due to a missing link that effectively designs a neural
network model suitable for quantum circuit implementation. In this article, we
present the co-design framework, namely QuantumFlow, to provide such a missing
link. QuantumFlow consists of novel quantum-friendly neural networks (QF-Nets),
a mapping tool (QF-Map) to generate the quantum circuit (QF-Circ) for QF-Nets,
and an execution engine (QF-FB). We discover that, in order to make full use of
the strength of quantum representation, it is best to represent data in a
neural network as either random variables or numbers in unitary matrices, such
that they can be directly operated by the basic quantum logical gates. Based on
these data representations, we propose two quantum friendly neural networks,
QF-pNet and QF-hNet in QuantumFlow. QF-pNet using random variables has better
flexibility, and can seamlessly connect two layers without measurement with
more qbits and logical gates than QF-hNet. On the other hand, QF-hNet with
unitary matrices can encode 2^k data into k qbits, and a novel algorithm can
guarantee the cost complexity to be O(k^2). Compared to the cost of O(2^k)in
classical computing, QF-hNet demonstrates the quantum advantages. Evaluation
results show that QF-pNet and QF-hNet can achieve 97.10% and 98.27% accuracy,
respectively. Results further show that for input sizes of neural computation
grow from 16 to 2,048, the cost reduction of QuantumFlow increased from 2.4x to
64x. Furthermore, on MNIST dataset, QF-hNet can achieve accuracy of 94.09%,
while the cost reduction against the classical computer reaches 10.85x. To the
best of our knowledge, QuantumFlow is the first work to demonstrate the
potential quantum advantage on neural network computation.",,,arXiv,,,2020-06-26,2020,,,,,,All OA, Green,Preprint,"Jiang, Weiwen; Xiong, Jinjun; Shi, Yiyu","Jiang, Weiwen (); Xiong, Jinjun (); Shi, Yiyu ()",,"Jiang, Weiwen (); Xiong, Jinjun (); Shi, Yiyu ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128829772,"40 Engineering; 4009 Electronics, Sensors and Digital Hardware; 46 Information and Computing Sciences; 4611 Machine Learning",,,,,,,,,,,
1548,pub.1129891388,10.23919/ilrn47897.2020.9155131,,,Doctoral Colloquium—A Snapshot of the Future: Virtual and Augmented Reality Training for Radiology,"Advances in virtual immersive and augmented reality technology, commercially available for the entertainment and gaming industry, hold potential for education and clinical use in medicine and the field of radiology. Radiology departments have begun exploring the use of these technologies to help with radiology education and training. The purpose of this article is to address how skills have been developed in the gaming world and how these can be adopted for radiology education. Radiology is rapidly evolving with the use of AI for more effective diagnostic and prognostic clinical assessment. Advances in computing technology have enabled widespread availability of simulated reality technologies, including virtual reality (VR) and augmented reality (AR). This work in progress paper describes VR and AR technologies as novel means to communicate and have potential for supplementing radiology training; communicating with colleagues, referring clinicians, and patients; and aiding in interventional radiology procedures.",,,,2020 6th International Conference of the Immersive Learning Research Network (iLRN),,2020-06-25,2020,,2020-06-25,0,,407-410,Closed,Proceeding,"Xu, Xuanhui; Mangina, Eleni; Kilroy, David; Curran, Kathleen M.; Healy, John J.; Campbell, Abraham G.","Xu, Xuanhui (University College, Dublin, Ireland); Mangina, Eleni (University College, Dublin, Ireland); Kilroy, David (University College, Dublin, Ireland); Curran, Kathleen M. (University College, Dublin, Ireland); Healy, John J. (University College, Dublin, Ireland); Campbell, Abraham G. (University College, Dublin, Ireland)","Xu, Xuanhui (University College Dublin)","Xu, Xuanhui (University College Dublin); Mangina, Eleni (University College Dublin); Kilroy, David (University College Dublin); Curran, Kathleen M. (University College Dublin); Healy, John J. (University College Dublin); Campbell, Abraham G. (University College Dublin)",4,4,,2.11,,https://app.dimensions.ai/details/publication/pub.1129891388,46 Information and Computing Sciences, 4608 Human-Centred Computing,4 Quality Education,,,,,,,,,,
1514,pub.1128778449,10.48550/arxiv.2006.14345,,,Collaborative Boundary-aware Context Encoding Networks for Error Map  Prediction,"Medical image segmentation is usually regarded as one of the most important
intermediate steps in clinical situations and medical imaging research. Thus,
accurately assessing the segmentation quality of the automatically generated
predictions is essential for guaranteeing the reliability of the results of the
computer-assisted diagnosis (CAD). Many researchers apply neural networks to
train segmentation quality regression models to estimate the segmentation
quality of a new data cohort without labeled ground truth. Recently, a novel
idea is proposed that transforming the segmentation quality assessment (SQA)
problem intothe pixel-wise error map prediction task in the form of
segmentation. However, the simple application of vanilla segmentation
structures in medical image fails to detect some small and thin error regions
of the auto-generated masks with complex anatomical structures. In this paper,
we propose collaborative boundaryaware context encoding networks called AEP-Net
for error prediction task. Specifically, we propose a collaborative feature
transformation branch for better feature fusion between images and masks, and
precise localization of error regions. Further, we propose a context encoding
module to utilize the global predictor from the error map to enhance the
feature representation and regularize the networks. We perform experiments on
IBSR v2.0 dataset and ACDC dataset. The AEP-Net achieves an average DSC of
0.8358, 0.8164 for error prediction task,and shows a high Pearson correlation
coefficient of 0.9873 between the actual segmentation accuracy and the
predicted accuracy inferred from the predicted error map on IBSR v2.0 dataset,
which verifies the efficacy of our AEP-Net.",,,arXiv,,,2020-06-25,2020,,,,,,All OA, Green,Preprint,"Zhang, Zhenxi; Tian, Chunna; Li, Jie; Zhong, Zhusi; Jiao, Zhicheng; Gao, Xinbo","Zhang, Zhenxi (); Tian, Chunna (); Li, Jie (); Zhong, Zhusi (); Jiao, Zhicheng (); Gao, Xinbo ()",,"Zhang, Zhenxi (); Tian, Chunna (); Li, Jie (); Zhong, Zhusi (); Jiao, Zhicheng (); Gao, Xinbo ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128778449,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,
4777,pub.1128679255,10.1016/j.compbiomed.2020.103877,32658742,,Automatic left ventricle segmentation in short-axis MRI using deep convolutional neural networks and central-line guided level set approach,"In the clinical diagnosis of cardiovascular diseases, left ventricle (LV) segmentation in cardiac magnetic resonance images (MRI) is an indispensable procedure for doctors. To reduce the time needed for diagnosis, we develop an automatic LV segmentation method by integrating the convolutional neural network (CNN) with the level set approach. Firstly, a CNN based myocardial central-line detection algorithm was proposed to replace the manual initialization process for traditional level set approaches. Secondly, we present a novel central-line guided level set approach (CGLS) for delineating the myocardium region. In particular, we incorporate the myocardial central-line into the level set energy formulation as a constraint term. It plays two important roles in the iterative process: restricting the zero-level contour to stay around the myocardial central-line and preserving the anatomical geometry of myocardium segmentation result. In experiments, our method yields results as below: (1) 1.74 mm and 2.06 mm in terms of epicardium and endocardium perpendicular distance on MICCAI 2009 dataset, (2) 0.955 and 0.853 in terms of LV and myocardium Dice metric at the end-diastole on ACDC MICCAI 2017 dataset. The experimental data demonstrate that our method outperforms some state-of-the-art methods and achieves a good agreement with the manual segmentation results.","This work is supported by NSFC, China (Grant numbers G0561671135, G0591630311, M0501020111531005). The authors thank the anonymous reviewers for their valuable comments.",,Computers in Biology and Medicine,,"Algorithms; Heart Ventricles; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Pericardium",2020-06-23,2020,2020-06-23,2020-07,122,,103877,Closed,Article,"Xie, Lipeng; Song, Yi; Chen, Qiang","Xie, Lipeng (School of Information and Communication Engineering, University of Electronic Science and Technology of China, China. Electronic address: xlpflyinsky@foxmail.com.); Song, Yi (Chongqing Three Gorges Central Hospital, China.); Chen, Qiang (School of Electronic and Information Engineering, Chongqing Three Gorges University, China.)","Xie, Lipeng (University of Electronic Science and Technology of China)","Xie, Lipeng (University of Electronic Science and Technology of China); Song, Yi (Chongqing Three Gorges Central Hospital); Chen, Qiang (Chongqing Three Gorges University)",6,6,0.54,4.6,,https://app.dimensions.ai/details/publication/pub.1128679255,46 Information and Computing Sciences, 4601 Applied Computing,,,,,,,,,,,
1512,pub.1128747592,10.48550/arxiv.2006.13379,,,Deep Generative Model-based Quality Control for Cardiac MRI Segmentation,"In recent years, convolutional neural networks have demonstrated promising
performance in a variety of medical image segmentation tasks. However, when a
trained segmentation model is deployed into the real clinical world, the model
may not perform optimally. A major challenge is the potential poor-quality
segmentations generated due to degraded image quality or domain shift issues.
There is a timely need to develop an automated quality control method that can
detect poor segmentations and feedback to clinicians. Here we propose a novel
deep generative model-based framework for quality control of cardiac MRI
segmentation. It first learns a manifold of good-quality image-segmentation
pairs using a generative model. The quality of a given test segmentation is
then assessed by evaluating the difference from its projection onto the
good-quality manifold. In particular, the projection is refined through
iterative search in the latent space. The proposed method achieves high
prediction accuracy on two publicly available cardiac MRI datasets. Moreover,
it shows better generalisation ability than traditional regression-based
methods. Our approach provides a real-time and model-agnostic quality control
for cardiac MRI segmentation, which has the potential to be integrated into
clinical image analysis workflows.",,,arXiv,,,2020-06-23,2020,,,,,,All OA, Green,Preprint,"Wang, Shuo; Tarroni, Giacomo; Qin, Chen; Mo, Yuanhan; Dai, Chengliang; Chen, Chen; Glocker, Ben; Guo, Yike; Rueckert, Daniel; Bai, Wenjia","Wang, Shuo (); Tarroni, Giacomo (); Qin, Chen (); Mo, Yuanhan (); Dai, Chengliang (); Chen, Chen (); Glocker, Ben (); Guo, Yike (); Rueckert, Daniel (); Bai, Wenjia ()",,"Wang, Shuo (); Tarroni, Giacomo (); Qin, Chen (); Mo, Yuanhan (); Dai, Chengliang (); Chen, Chen (); Glocker, Ben (); Guo, Yike (); Rueckert, Daniel (); Bai, Wenjia ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128747592,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
1459,pub.1128747535,10.48550/arxiv.2006.13322,,,Realistic Adversarial Data Augmentation for MR Image Segmentation,"Neural network-based approaches can achieve high accuracy in various medical
image segmentation tasks. However, they generally require large labelled
datasets for supervised learning. Acquiring and manually labelling a large
medical dataset is expensive and sometimes impractical due to data sharing and
privacy issues. In this work, we propose an adversarial data augmentation
method for training neural networks for medical image segmentation. Instead of
generating pixel-wise adversarial attacks, our model generates plausible and
realistic signal corruptions, which models the intensity inhomogeneities caused
by a common type of artefacts in MR imaging: bias field. The proposed method
does not rely on generative networks, and can be used as a plug-in module for
general segmentation networks in both supervised and semi-supervised learning.
Using cardiac MR imaging we show that such an approach can improve the
generalization ability and robustness of models as well as provide significant
improvements in low-data scenarios.",,,arXiv,,,2020-06-23,2020,,,,,,All OA, Green,Preprint,"Chen, Chen; Qin, Chen; Qiu, Huaqi; Ouyang, Cheng; Wang, Shuo; Chen, Liang; Tarroni, Giacomo; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (); Qin, Chen (); Qiu, Huaqi (); Ouyang, Cheng (); Wang, Shuo (); Chen, Liang (); Tarroni, Giacomo (); Bai, Wenjia (); Rueckert, Daniel ()",,"Chen, Chen (); Qin, Chen (); Qiu, Huaqi (); Ouyang, Cheng (); Wang, Shuo (); Chen, Liang (); Tarroni, Giacomo (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128747535,46 Information and Computing Sciences, 4611 Machine Learning,"16 Peace, Justice and Strong Institutions",,,,,,,,,
5355,pub.1128692548,10.1371/journal.pone.0234896,32569290,PMC7307770,Left ventricular geometry during unloading and the end-systolic pressure volume relationship: Measurement with a modified real-time MRI-based method in normal sheep,"The left ventricular (LV) end-systolic (ES) pressure volume relationship (ESPVR) is the cornerstone of systolic LV function analysis. We describe a 2D real-time (RT) MRI-based method (RTPVR) with separate software tools for 1) semi-automatic level set-based shape prior method (LSSPM) of the LV, 2) generation of synchronized pressure area loops and 3) calculation of the ESPVR. We used the RTPVR method to measure ventricular geometry, ES pressure area relationship (ESPAR) and ESPVR during vena cava occlusion (VCO) in normal sheep. 14 adult sheep were anesthetized and underwent measurement of LV systolic function. Ten of the 14 sheep underwent RTMRI and eight of the 14 underwent measurement with conductance catheter; 4 had both RTMRI and conductance measurements. 2D cross sectional RTMRI were performed at apex, mid-ventricle and base levels during separate VCOs. The Dice similarity coefficient was used to compare LSSPM and manual image segmentation and thus determine LSSPM accuracy. LV cross-sectional area, major and minor axis length, axis ratio, major axis orientation angle and ESPAR were measured at each LV level. ESPVR was calculated with a trapezoidal rule. The Dice similarity coefficient between LSSPM and manual segmentation by two readers was 87.31±2.51% and 88.13±3.43%. All cross sections became more elliptical during VCO. The major axis orientation shifted during VCO but remained in the septo-lateral direction. LV chamber obliteration at the apical level occurred during VCO in 7 of 10 sheep that underwent RTMRI. ESPAR was non-linear at all levels. Finally, ESPVR was non-linear because of apical collapse. ESPVR measured by conductance catheter (EES,Index = 2.23±0.66 mmHg/ml/m2) and RT (EES,Index = 2.31±0.31 mmHg/ml/m2) was not significantly different. LSSPM segmentation of 2D RT MRI images is accurate and allows calculation of LV geometry, ESPAR and ESPVR during VCO. In the future, RTPVR will facilitate determination of regional systolic material parameters underlying ESPVR.","This study was supported by National Heart, Lung and Blood Institute Grant R01-HL-084431 (M. Ratcliffe). The authors would like to acknowledge the staff from the animal facility at the San Francisco Veterans Affairs Medical Center for their help facilitating the animal procedures.","This study was supported by National Heart, Lung and Blood Institute Grant R01-HL-084431 (M. Ratcliffe).",PLOS ONE,,"Animals; Blood Pressure; Magnetic Resonance Imaging; Sheep; Stroke Volume; Ventricular Function, Left",2020-06-22,2020,2020-06-22,,15,6,e0234896,All OA, Gold,Article,"Giao, Duc M.; Wang, Yan; Rojas, Renan; Takaba, Kiyoaki; Badathala, Anusha; Spaulding, Kimberly A.; Soon, Gilbert; Zhang, Yue; Wang, Vicky Y.; Haraldsson, Henrik; Liu, Jing; Saloner, David; Guccione, Julius M.; Ge, Liang; Wallace, Arthur W.; Ratcliffe, Mark B.","Giao, Duc M. (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Wang, Yan (Department of Radiology, University of California, San Francisco, CA, United States of America); Rojas, Renan (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Takaba, Kiyoaki (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Badathala, Anusha (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Spaulding, Kimberly A. (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Soon, Gilbert (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Zhang, Yue (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Wang, Vicky Y. (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Haraldsson, Henrik (Department of Radiology, University of California, San Francisco, CA, United States of America); Liu, Jing (Department of Radiology, University of California, San Francisco, CA, United States of America); Saloner, David (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Radiology, University of California, San Francisco, CA, United States of America); Guccione, Julius M. (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Ge, Liang (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America); Wallace, Arthur W. (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Anesthesia, University of California, San Francisco, CA, United States of America); Ratcliffe, Mark B. (Veterans Affairs Medical Center, San Francisco, California, United States of America; Department of Bioengineering, University of California, San Francisco, CA, United States of America; Department of Surgery, University of California, San Francisco, CA, United States of America)","Ratcliffe, Mark B. (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco)","Giao, Duc M. (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Wang, Yan (University of California, San Francisco); Rojas, Renan (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Takaba, Kiyoaki (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Badathala, Anusha (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Spaulding, Kimberly A. (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Soon, Gilbert (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Zhang, Yue (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Wang, Vicky Y. (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Haraldsson, Henrik (University of California, San Francisco); Liu, Jing (University of California, San Francisco); Saloner, David (San Francisco VA Medical Center; University of California, San Francisco); Guccione, Julius M. (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Ge, Liang (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Wallace, Arthur W. (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco); Ratcliffe, Mark B. (San Francisco VA Medical Center; University of California, San Francisco; University of California, San Francisco)",3,3,0.53,2.27,https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0234896&type=printable,https://app.dimensions.ai/details/publication/pub.1128692548,32 Biomedical and Clinical Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
1255,pub.1128719153,10.48550/arxiv.2006.12700,,,Cine Cardiac MRI Motion Artifact Reduction Using a Recurrent Neural  Network,"Cine cardiac magnetic resonance imaging (MRI) is widely used for diagnosis of
cardiac diseases thanks to its ability to present cardiovascular features in
excellent contrast. As compared to computed tomography (CT), MRI, however,
requires a long scan time, which inevitably induces motion artifacts and causes
patients' discomfort. Thus, there has been a strong clinical motivation to
develop techniques to reduce both the scan time and motion artifacts. Given its
successful applications in other medical imaging tasks such as MRI
super-resolution and CT metal artifact reduction, deep learning is a promising
approach for cardiac MRI motion artifact reduction. In this paper, we propose a
recurrent neural network to simultaneously extract both spatial and temporal
features from under-sampled, motion-blurred cine cardiac images for improved
image quality. The experimental results demonstrate substantially improved
image quality on two clinical test datasets. Also, our method enables
data-driven frame interpolation at an enhanced temporal resolution. Compared
with existing methods, our deep learning approach gives a superior performance
in terms of structural similarity (SSIM) and peak signal-to-noise ratio (PSNR).",,,arXiv,,,2020-06-22,2020,,,,,,All OA, Green,Preprint,"Lyu, Qing; Shan, Hongming; Xie, Yibin; Li, Debiao; Wang, Ge","Lyu, Qing (); Shan, Hongming (); Xie, Yibin (); Li, Debiao (); Wang, Ge ()",,"Lyu, Qing (); Shan, Hongming (); Xie, Yibin (); Li, Debiao (); Wang, Ge ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128719153,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
953,pub.1128692081,10.48550/arxiv.2006.12434,,,Cardiac Segmentation on Late Gadolinium Enhancement MRI: A Benchmark  Study from Multi-Sequence Cardiac MR Segmentation Challenge,"Accurate computing, analysis and modeling of the ventricles and myocardium
from medical images are important, especially in the diagnosis and treatment
management for patients suffering from myocardial infarction (MI). Late
gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) provides an
important protocol to visualize MI. However, automated segmentation of LGE CMR
is still challenging, due to the indistinguishable boundaries, heterogeneous
intensity distribution and complex enhancement patterns of pathological
myocardium from LGE CMR. Furthermore, compared with the other sequences LGE CMR
images with gold standard labels are particularly limited, which represents
another obstacle for developing novel algorithms for automatic segmentation of
LGE CMR. This paper presents the selective results from the Multi-Sequence
Cardiac MR (MS-CMR) Segmentation challenge, in conjunction with MICCAI 2019.
The challenge offered a data set of paired MS-CMR images, including auxiliary
CMR sequences as well as LGE CMR, from 45 patients who underwent
cardiomyopathy. It was aimed to develop new algorithms, as well as benchmark
existing ones for LGE CMR segmentation and compare them objectively. In
addition, the paired MS-CMR images could enable algorithms to combine the
complementary information from the other sequences for the segmentation of LGE
CMR. Nine representative works were selected for evaluation and comparisons,
among which three methods are unsupervised methods and the other six are
supervised. The results showed that the average performance of the nine methods
was comparable to the inter-observer variations. The success of these methods
was mainly attributed to the inclusion of the auxiliary sequences from the
MS-CMR images, which provide important label information for the training of
deep neural networks.",,,arXiv,,,2020-06-22,2020,,,,,,All OA, Green,Preprint,"Zhuang, Xiahai; Xu, Jiahang; Luo, Xinzhe; Chen, Chen; Ouyang, Cheng; Rueckert, Daniel; Campello, Victor M.; Lekadir, Karim; Vesal, Sulaiman; RaviKumar, Nishant; Liu, Yashu; Luo, Gongning; Chen, Jingkun; Li, Hongwei; Ly, Buntheng; Sermesant, Maxime; Roth, Holger; Zhu, Wentao; Wang, Jiexiang; Ding, Xinghao; Wang, Xinyue; Yang, Sen; Li, Lei","Zhuang, Xiahai (); Xu, Jiahang (); Luo, Xinzhe (); Chen, Chen (); Ouyang, Cheng (); Rueckert, Daniel (); Campello, Victor M. (); Lekadir, Karim (); Vesal, Sulaiman (); RaviKumar, Nishant (); Liu, Yashu (); Luo, Gongning (); Chen, Jingkun (); Li, Hongwei (); Ly, Buntheng (); Sermesant, Maxime (); Roth, Holger (); Zhu, Wentao (); Wang, Jiexiang (); Ding, Xinghao (); Wang, Xinyue (); Yang, Sen (); Li, Lei ()",,"Zhuang, Xiahai (); Xu, Jiahang (); Luo, Xinzhe (); Chen, Chen (); Ouyang, Cheng (); Rueckert, Daniel (); Campello, Victor M. (); Lekadir, Karim (); Vesal, Sulaiman (); RaviKumar, Nishant (); Liu, Yashu (); Luo, Gongning (); Chen, Jingkun (); Li, Hongwei (); Ly, Buntheng (); Sermesant, Maxime (); Roth, Holger (); Zhu, Wentao (); Wang, Jiexiang (); Ding, Xinghao (); Wang, Xinyue (); Yang, Sen (); Li, Lei ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128692081,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
5686,pub.1128551920,10.1002/mrm.28361,32557819,PMC7540523,Automated mitral valve vortex ring extraction from 4D‐flow MRI,"PURPOSE: To present and validate a method for automated extraction and analysis of the temporal evolution of the mitral valve (MV) vortex ring from MR 4D-flow data.
METHODS: The proposed algorithm uses the divergence-free part of the velocity vector field for Q criterion-based identification and tracking of MV vortex ring core and region within the left ventricle (LV). The 4D-flow data of 20 subjects (10 healthy controls, 10 patients with ischemic heart disease) were used to validate the algorithm against visual analysis as well as to assess the method's sensitivity to manual LV segmentation. Quantitative MV vortex ring parameters were analyzed with respect to both their differences between healthy subjects and patients and their correlation with transmitral peak velocities.
RESULTS: The algorithm successfully extracted MV vortex rings throughout the entire cardiac cycle, which agreed substantially with visual analysis (Cohen's kappa = 0.77). Furthermore, vortex cores and regions were robustly detected even if a static end-diastolic LV segmentation mask was applied to all frames (Dice coefficients 0.82 ± 0.08 and 0.94 ± 0.02 for core and region, respectively). Early diastolic MV vortex ring vorticity, kinetic energy and circularity index differed significantly between healthy controls and patients. In contrast to vortex shape parameters, vorticity and kinetic energy correlated strongly with transmitral peak velocities.
CONCLUSION: An automated method for temporal MV vortex ring extraction demonstrating robustness with respect to LV segmentation strategies is introduced. Quantitative vortex parameter analysis indicates importance of the MV vortex ring for LV diastolic (dys)function.","This work was supported by the OeNB Anniversary Fund (17934), the Generalitat de Catalunya (2019FI_B1_000198), and the ESOR fellowship program 2018/19. The authors thank Ada Muellner, MS and Eugenia Lamont for editing the manuscript.",,Magnetic Resonance in Medicine,,"Algorithms; Blood Flow Velocity; Diastole; Heart Ventricles; Humans; Magnetic Resonance Imaging; Mitral Valve; Ventricular Function, Left",2020-06-18,2020,2020-06-18,2020-12,84,6,3396-3408,All OA, Hybrid,Article,"Kräuter, Corina; Reiter, Ursula; Reiter, Clemens; Nizhnikava, Volha; Masana, Marc; Schmidt, Albrecht; Fuchsjäger, Michael; Stollberger, Rudolf; Reiter, Gert","Kräuter, Corina (Institute of Medical Engineering, Graz University of Technology, Graz, Austria; Division of General Radiology, Department of Radiology, Medical University of Graz, Graz, Austria); Reiter, Ursula (Division of General Radiology, Department of Radiology, Medical University of Graz, Graz, Austria); Reiter, Clemens (Division of General Radiology, Department of Radiology, Medical University of Graz, Graz, Austria); Nizhnikava, Volha (Division of General Radiology, Department of Radiology, Medical University of Graz, Graz, Austria); Masana, Marc (Computer Vision Center, Universitat Autònoma de Barcelona, Barcelona, Spain); Schmidt, Albrecht (Division of Cardiology, Department of Internal Medicine, Medical University of Graz, Graz, Austria); Fuchsjäger, Michael (Division of General Radiology, Department of Radiology, Medical University of Graz, Graz, Austria); Stollberger, Rudolf (Institute of Medical Engineering, Graz University of Technology, Graz, Austria); Reiter, Gert (Division of General Radiology, Department of Radiology, Medical University of Graz, Graz, Austria; Research & Development, Siemens Healthcare Diagnostics, Graz, Austria)","Reiter, Ursula (Medical University of Graz)","Kräuter, Corina (Graz University of Technology; Medical University of Graz); Reiter, Ursula (Medical University of Graz); Reiter, Clemens (Medical University of Graz); Nizhnikava, Volha (Medical University of Graz); Masana, Marc (Autonomous University of Barcelona); Schmidt, Albrecht (Medical University of Graz); Fuchsjäger, Michael (Medical University of Graz); Stollberger, Rudolf (Graz University of Technology); Reiter, Gert (Medical University of Graz)",9,9,1.39,2.74,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.28361,https://app.dimensions.ai/details/publication/pub.1128551920,40 Engineering, 4012 Fluid Mechanics and Thermal Engineering,,,,,,,,,,
953,pub.1128588576,10.48550/arxiv.2006.10511,,,Contrastive learning of global and local features for medical image  segmentation with limited annotations,"A key requirement for the success of supervised deep learning is a large
labeled dataset - a condition that is difficult to meet in medical image
analysis. Self-supervised learning (SSL) can help in this regard by providing a
strategy to pre-train a neural network with unlabeled data, followed by
fine-tuning for a downstream task with limited annotations. Contrastive
learning, a particular variant of SSL, is a powerful technique for learning
image-level representations. In this work, we propose strategies for extending
the contrastive learning framework for segmentation of volumetric medical
images in the semi-supervised setting with limited annotations, by leveraging
domain-specific and problem-specific cues. Specifically, we propose (1) novel
contrasting strategies that leverage structural similarity across volumetric
medical images (domain-specific cue) and (2) a local version of the contrastive
loss to learn distinctive representations of local regions that are useful for
per-pixel segmentation (problem-specific cue). We carry out an extensive
evaluation on three Magnetic Resonance Imaging (MRI) datasets. In the limited
annotation setting, the proposed method yields substantial improvements
compared to other self-supervision and semi-supervised learning techniques.
When combined with a simple data augmentation technique, the proposed method
reaches within 8% of benchmark performance using only two labeled MRI volumes
for training, corresponding to only 4% (for ACDC) of the training data used to
train the benchmark. The code is made public at
https://github.com/krishnabits001/domain_specific_cl.",,,arXiv,,,2020-06-18,2020,,,,,,All OA, Green,Preprint,"Chaitanya, Krishna; Erdil, Ertunc; Karani, Neerav; Konukoglu, Ender","Chaitanya, Krishna (); Erdil, Ertunc (); Karani, Neerav (); Konukoglu, Ender ()",,"Chaitanya, Krishna (); Erdil, Ertunc (); Karani, Neerav (); Konukoglu, Ender ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128588576,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
5387,pub.1128587256,10.1007/978-3-030-50417-5_6,,PMC7302857,A Direct High-Order Curvilinear Triangular Mesh Generation Method Using an Advancing Front Technique,"In this paper, we propose a novel method of generating high-order curvilinear triangular meshes using an advancing front approach. Our method relies on a direct approach to generate meshes on geometries with curved boundaries. Our advancing front method yields high-quality triangular elements in each iteration which omits the need for post-processing steps. We present several numerical examples of second-order curvilinear triangular meshes of patient-specific anatomical models generated using our technique on boundary meshes obtained from biomedical images.",,,Lecture Notes in Computer Science,Computational Science – ICCS 2020,,2020-06-15,2020,2020-06-15,2020,12138,,72-85,All OA, Bronze,Chapter,"Mohammadi, Fariba; Dangi, Shusil; Shontz, Suzanne M.; Linte, Cristian A.","Mohammadi, Fariba (The University of Kansas, 66045, Lawrence, KS, USA); Dangi, Shusil (Rochester Institute of Technology, 14623, Rochester, NY, USA); Shontz, Suzanne M. (The University of Kansas, 66045, Lawrence, KS, USA); Linte, Cristian A. (Rochester Institute of Technology, 14623, Rochester, NY, USA)","Mohammadi, Fariba (University of Kansas)","Mohammadi, Fariba (University of Kansas); Dangi, Shusil (Rochester Institute of Technology); Shontz, Suzanne M. (University of Kansas); Linte, Cristian A. (Rochester Institute of Technology)",2,2,,1.21,https://link.springer.com/content/pdf/10.1007%2F978-3-030-50417-5_6.pdf,https://app.dimensions.ai/details/publication/pub.1128587256,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1070,pub.1128529417,10.48550/arxiv.2006.08825,,,Cardiac Segmentation with Strong Anatomical Guarantees,"Convolutional neural networks (CNN) have had unprecedented success in medical
imaging and, in particular, in medical image segmentation. However, despite the
fact that segmentation results are closer than ever to the inter-expert
variability, CNNs are not immune to producing anatomically inaccurate
segmentations, even when built upon a shape prior. In this paper, we present a
framework for producing cardiac image segmentation maps that are guaranteed to
respect pre-defined anatomical criteria, while remaining within the
inter-expert variability. The idea behind our method is to use a well-trained
CNN, have it process cardiac images, identify the anatomically implausible
results and warp these results toward the closest anatomically valid cardiac
shape. This warping procedure is carried out with a constrained variational
autoencoder (cVAE) trained to learn a representation of valid cardiac shapes
through a smooth, yet constrained, latent space. With this cVAE, we can project
any implausible shape into the cardiac latent space and steer it toward the
closest correct shape. We tested our framework on short-axis MRI as well as
apical two and four-chamber view ultrasound images, two modalities for which
cardiac shapes are drastically different. With our method, CNNs can now produce
results that are both within the inter-expert variability and always
anatomically plausible without having to rely on a shape prior.",,,arXiv,,,2020-06-15,2020,,,,,,All OA, Green,Preprint,"Painchaud, Nathan; Skandarani, Youssef; Judge, Thierry; Bernard, Olivier; Lalande, Alain; Jodoin, Pierre-Marc","Painchaud, Nathan (); Skandarani, Youssef (); Judge, Thierry (); Bernard, Olivier (); Lalande, Alain (); Jodoin, Pierre-Marc ()",,"Painchaud, Nathan (); Skandarani, Youssef (); Judge, Thierry (); Bernard, Olivier (); Lalande, Alain (); Jodoin, Pierre-Marc ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128529417,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1348,pub.1129912974,10.1109/cvpr42600.2020.00478,,,A Spatiotemporal Volumetric Interpolation Network for 4D Dynamic Medical Image,"Dynamic medical images are often limited in its application due to the large radiation doses and longer image scanning and reconstruction times. Existing methods attempt to reduce the volume samples in the dynamic sequence by interpolating the volumes between the acquired samples. However, these methods are limited to either 2D images and/or are unable to support large but periodic variations in the functional motion between the image volume samples. In this paper, we present a spatiotemporal volumetric inter-polation network (SVIN) designed for 4D dynamic medical images. SVIN introduces dual networks: the first is the spatiotemporal motion network that leverages the 3D convolutional neural network (CNN) for unsupervised parametric volumetric registration to derive spatiotemporal motion field from a pair of image volumes; the second is the sequential volumetric interpolation network, which uses the derived motion field to interpolate image volumes, together with a new regression-based module to characterize the periodic motion cycles in functional organ structures. We also introduce an adaptive multi-scale architecture to capture the volumetric large anatomy motions. Experimental results demonstrated that our SVIN outperformed state-of-the-art temporal medical interpolation methods and natural video interpolation method that has been extended to support volumetric images. Code is available at 11https://github.com/guoyu-niubility/SVIN. https://github.com/guoyu-niubility/SVIN",,,,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),,2020-06-13,2020,,2020-06-13,0,,4725-4734,All OA, Green,Proceeding,"Guo, Yuyu; Bi, Lei; Ahn, Euijoon; Feng, Dagan; Wang, Qian; Kim, Jinman","Guo, Yuyu (Institute for Medical Imaging Technology, School of Biomedical Engineering, Shanghai Jiao Tong University, China; School of Computer Science, University of Sydney, Australia); Bi, Lei (School of Computer Science, University of Sydney, Australia); Ahn, Euijoon (School of Computer Science, University of Sydney, Australia); Feng, Dagan (School of Computer Science, University of Sydney, Australia); Wang, Qian (Institute for Medical Imaging Technology, School of Biomedical Engineering, Shanghai Jiao Tong University, China); Kim, Jinman (School of Computer Science, University of Sydney, Australia)",,"Guo, Yuyu (Shanghai Jiao Tong University; The University of Sydney); Bi, Lei (The University of Sydney); Ahn, Euijoon (The University of Sydney); Feng, Dagan (The University of Sydney); Wang, Qian (Shanghai Jiao Tong University); Kim, Jinman (The University of Sydney)",10,10,,5.95,http://arxiv.org/pdf/2002.12680,https://app.dimensions.ai/details/publication/pub.1129912974,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
1171,pub.1129912933,10.1109/cvpr42600.2020.00437,,,FOAL: Fast Online Adaptive Learning for Cardiac Motion Estimation,"Motion estimation of cardiac MRI videos is crucial for the evaluation of human heart anatomy and function. Recent researches show promising results with deep learning-based methods. In clinical deployment, however, they suffer dramatic performance drops due to mismatched distributions between training and testing datasets, commonly encountered in the clinical environment. On the other hand, it is arguably impossible to collect all representative datasets and to train a universal tracker before deployment. In this context, we proposed a novel fast online adaptive learning (FOAL) framework: an online gradient descent based optimizer that is optimized by a meta-learner. The meta-learner enables the online optimizer to perform a fast and robust adaptation. We evaluated our method through extensive experiments on two public clinical datasets. The results showed the superior performance of FOAL in accuracy compared to the offline-trained tracking method. On average, the FOAL took only 0.4 second per video for online optimization.",,,,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),,2020-06-13,2020,,2020-06-13,0,,4312-4322,All OA, Green,Proceeding,"Yu, Hanchao; Sun, Shanhui; Yu, Haichao; Chen, Xiao; Shi, Honghui; Huang, Thomas; Chen, Terrence","Yu, Hanchao (University of Illinois, Urbana-Champaign); Sun, Shanhui (United Imaging Intelligence, Cambridge, MA, 02140); Yu, Haichao (University of Illinois, Urbana-Champaign); Chen, Xiao (United Imaging Intelligence, Cambridge, MA, 02140); Shi, Honghui (University of Oregon); Huang, Thomas (University of Illinois, Urbana-Champaign); Chen, Terrence (United Imaging Intelligence, Cambridge, MA, 02140)",,"Yu, Hanchao (University of Illinois Urbana-Champaign); Sun, Shanhui (); Yu, Haichao (University of Illinois Urbana-Champaign); Chen, Xiao (); Shi, Honghui (University of Oregon); Huang, Thomas (University of Illinois Urbana-Champaign); Chen, Terrence ()",29,25,,13.81,http://arxiv.org/pdf/2003.04492,https://app.dimensions.ai/details/publication/pub.1129912933,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
6761,pub.1128301230,10.1007/978-3-030-50120-4_10,,PMC7279923,Multi-channel Image Registration of Cardiac MR Using Supervised Feature Learning with Convolutional Encoder-Decoder Network,"It is difficult to register the images involving large deformation and intensity inhomogeneity. In this paper, a new multi-channel registration algorithm using modified multi-feature mutual information (α-MI) based on minimal spanning tree (MST) is presented. First, instead of relying on handcrafted features, a convolutional encoder-decoder network is employed to learn the latent feature representation from cardiac MR images. Second, forward computation and backward propagation are performed in a supervised fashion to make the learned features more discriminative. Finally, local features containing appearance information is extracted and integrated into α-MI for achieving multi-channel registration. The proposed method has been evaluated on cardiac cine-MRI data from 100 patients. The experimental results show that features learned from deep network are more effective than handcrafted features in guiding intra-subject registration of cardiac MR images.",,,Lecture Notes in Computer Science,Biomedical Image Registration,,2020-06-09,2020,2020-06-09,2020,12120,,103-110,All OA, Bronze,Chapter,"Lu, Xuesong; Qiao, Yuchuan","Lu, Xuesong (College of Biomedical Engineering, South-Central University for Nationalities, 430074, Wuhan, China); Qiao, Yuchuan (Laboratory of Neuro Imaging, Keck School of Medicine of USC, 90033, Los Angeles, CA, USA)","Lu, Xuesong (South Central University for Nationalities)","Lu, Xuesong (South Central University for Nationalities); Qiao, Yuchuan (University of Southern California)",0,0,,0.0,https://link.springer.com/content/pdf/10.1007%2F978-3-030-50120-4_10.pdf,https://app.dimensions.ai/details/publication/pub.1128301230,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
1454,pub.1128313620,10.48550/arxiv.2006.04725,,,Biomechanics-informed Neural Networks for Myocardial Motion Tracking in  MRI,"Image registration is an ill-posed inverse problem which often requires
regularisation on the solution space. In contrast to most of the current
approaches which impose explicit regularisation terms such as smoothness, in
this paper we propose a novel method that can implicitly learn
biomechanics-informed regularisation. Such an approach can incorporate
application-specific prior knowledge into deep learning based registration.
Particularly, the proposed biomechanics-informed regularisation leverages a
variational autoencoder (VAE) to learn a manifold for biomechanically plausible
deformations and to implicitly capture their underlying properties via
reconstructing biomechanical simulations. The learnt VAE regulariser then can
be coupled with any deep learning based registration network to regularise the
solution space to be biomechanically plausible. The proposed method is
validated in the context of myocardial motion tracking on 2D stacks of cardiac
MRI data from two different datasets. The results show that it can achieve
better performance against other competing methods in terms of motion tracking
accuracy and has the ability to learn biomechanical properties such as
incompressibility and strains. The method has also been shown to have better
generalisability to unseen domains compared with commonly used L2
regularisation schemes.",,,arXiv,,,2020-06-08,2020,,,,,,All OA, Green,Preprint,"Qin, Chen; Wang, Shuo; Chen, Chen; Qiu, Huaqi; Bai, Wenjia; Rueckert, Daniel","Qin, Chen (); Wang, Shuo (); Chen, Chen (); Qiu, Huaqi (); Bai, Wenjia (); Rueckert, Daniel ()",,"Qin, Chen (); Wang, Shuo (); Chen, Chen (); Qiu, Huaqi (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1128313620,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1688,pub.1125372255,10.1049/el.2020.0453,,,Imposing boundary‐aware prior into CNNs‐based medical image segmentation,"While convolutional neural networks (CNNs) have become the first choice for the medical image segmentation, they still lack the critical ingredient of incorporating priors, such as smoothness and boundary shapes. The authors tackle the limitation by developing a novel prior that is boundary‐aware in two ways: promoting smoothness without blurring object boundaries and punishing prediction errors according to boundary shapes. They bring the boundary‐aware property into effect by weighting the prediction gradients and errors with the distance map. Their prior differs from previous approaches that either over‐smooth boundaries or tend to produce rough boundaries. They evaluate their prior alongside the cross‐entropy (CE) on a cardiac MRI dataset. Compared to CE alone, their prior improves the Dice score by 1.5% and Hausdorff distance by 53%. It also yielded a faster and more stable learning process.",This work was supported by the National Nature Science Foundation of China (no. 11675122) and the Natural Science Foundation of Ningbo (no. 2018A610165).,,Electronics Letters,,,2020-06,2020,2020-06,2020-06,56,12,599-601,All OA, Bronze,Article,"Liu, Cong; Ma, Longhua; Jin, Xiance; Si, Wen","Liu, Cong (Faculty of Business Information, Shanghai Business School, Shanghai, People's Republic of China); Ma, Longhua (Ningbo Institute of Technology, Zhejiang University, Ningbo, People's Republic of China); Jin, Xiance (Radiation and Medical Oncology Department, 1st Affiliated Hospital of Wenzhou Medical University, WenZhou, People's Republic of China); Si, Wen (Faculty of Business Information, Shanghai Business School, Shanghai, People's Republic of China)","Si, Wen (Shanghai Business School)","Liu, Cong (Shanghai Business School); Ma, Longhua (Zhejiang University); Jin, Xiance (First Affiliated Hospital of Wenzhou Medical University); Si, Wen (Shanghai Business School)",1,1,,0.44,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/el.2020.0453,https://app.dimensions.ai/details/publication/pub.1125372255,"40 Engineering; 4006 Communications Engineering; 4009 Electronics, Sensors and Digital Hardware",,,,,,,,,,,
5371,pub.1127794782,10.1088/2057-1976/ab9556,33444274,,Left ventricle segmentation using a Bayesian approach with distance dependent shape priors,We propose a method for segmentation of the left ventricle in magnetic resonance cardiac images. The framework consists of an initial Bayesian segmentation of the central slice of the volume. This segmentation is used to locate a shape prior for the LV myocardial tissue. This shape prior is determined using the fact that the myocardium is approximately annular as seen in the short-axis. Then a second Bayesian segmentation is performed to obtain the final result. This procedure is repeated for the rest of the slices. An extrapolation of the area of the LV is used to determine a stopping criterion. The method was evaluated on the databases of the Cardiac Atlas project. Our results demonstrate a suitable accuracy for myocardial segmentation (≈0.8 Dice's coefficient). For the endocardium and the epicardium the Dice's coefficients are 0.94 and 0.9 respectively. The accuracy was also evaluated in terms of the Hausdorff distance and the average distance. For the myocardium we obtain 8 mm and 2 mm respectively. Our results demonstrate the capability and merits of the proposed method to estimate the structure of the LV. The method requires minimal user input and generates results with quality comparable to more complex approaches. This paper suggests a new efficient approach for automatic LV quantification based on a Bayesian technique with shape priors with errors comparable to state-of-the-art techniques.,This work was partially supported by Consejo Nacional de Investigaciones Cientficas y Tcnicas (CONICET) PIP 112 201301 00 256.,,Biomedical Physics & Engineering Express,,"Algorithms; Bayes Theorem; Diastole; Endocardium; Female; Heart Ventricles; Humans; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Male; Myocardium; Pattern Recognition, Automated; Pericardium; Probability; Reproducibility of Results; Respiration; Stroke Volume; Ventricular Function, Left",2020-05-29,2020,2020-05-29,2020-07-01,6,4,45013,Closed,Article,"Cardenas, Rodrigo; Curiale, Ariel H; Mato, German","Cardenas, Rodrigo (Consejo Nacional de Investigaciones Cient, ficas y T, cnicas (CONICET), Argentina; Centro At, mico Bariloche, Av., Bustillo, 9500, R8402AGP S. C. de Bariloche, R, o Negro, Argentina); Curiale, Ariel H (Consejo Nacional de Investigaciones Cient, ficas y T, cnicas (CONICET), Argentina; Centro At, mico Bariloche, Av., Bustillo, 9500, R8402AGP S. C. de Bariloche, R, o Negro, Argentina); Mato, German (Consejo Nacional de Investigaciones Cient, ficas y T, cnicas (CONICET), Argentina; Centro At, mico Bariloche, Av., Bustillo, 9500, R8402AGP S. C. de Bariloche, R, o Negro, Argentina; Comisi, n Nacional de Energ, a At, mica (CNEA), Argentina)",,"Cardenas, Rodrigo (); Curiale, Ariel H (); Mato, German ()",1,1,0.22,0.24,,https://app.dimensions.ai/details/publication/pub.1127794782,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
4788,pub.1127898843,10.3389/fcvm.2020.00086,32528977,PMC7266934,Mini Review: Deep Learning for Atrial Segmentation From Late Gadolinium-Enhanced MRIs,"Segmentation and 3D reconstruction of the human atria is of crucial importance for precise diagnosis and treatment of atrial fibrillation, the most common cardiac arrhythmia. However, the current manual segmentation of the atria from medical images is a time-consuming, labor-intensive, and error-prone process. The recent emergence of artificial intelligence, particularly deep learning, provides an alternative solution to the traditional methods that fail to accurately segment atrial structures from clinical images. This has been illustrated during the recent 2018 Atrial Segmentation Challenge for which most of the challengers developed deep learning approaches for atrial segmentation, reaching high accuracy (>90% Dice score). However, as significant discrepancies exist between the approaches developed, many important questions remain unanswered, such as which deep learning architectures and methods to ensure reliability while achieving the best performance. In this paper, we conduct an in-depth review of the current state-of-the-art of deep learning approaches for atrial segmentation from late gadolinium-enhanced MRIs, and provide critical insights for overcoming the main hindrances faced in this task.","We would like to thank our colleagues: Dr. Nawshin Dastagir, Joseph Ashby, and Christopher Walker for their precious comments and insights that greatly helped to improve the manuscript. We would also like to thank Vincent Guichot who provided great assistance for the creation of the figures.",,Frontiers in Cardiovascular Medicine,,,2020-05-27,2020,2020-05-27,,7,,86,All OA, Gold,Article,"Jamart, Kevin; Xiong, Zhaohan; Talou, Gonzalo D. Maso; Stiles, Martin K.; Zhao, Jichao","Jamart, Kevin (Auckland Bioengineering Institute, The University of Auckland, Auckland, New Zealand); Xiong, Zhaohan (Auckland Bioengineering Institute, The University of Auckland, Auckland, New Zealand); Talou, Gonzalo D. Maso (Auckland Bioengineering Institute, The University of Auckland, Auckland, New Zealand); Stiles, Martin K. (Waikato Clinical School, Faculty of Medical and Health Sciences, The University of Auckland, Auckland, New Zealand); Zhao, Jichao (Auckland Bioengineering Institute, The University of Auckland, Auckland, New Zealand)","Zhao, Jichao (University of Auckland)","Jamart, Kevin (University of Auckland); Xiong, Zhaohan (University of Auckland); Talou, Gonzalo D. Maso (University of Auckland); Stiles, Martin K. (University of Auckland); Zhao, Jichao (University of Auckland)",22,21,1.72,14.25,https://www.frontiersin.org/articles/10.3389/fcvm.2020.00086/pdf,https://app.dimensions.ai/details/publication/pub.1127898843,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
4034,pub.1127756035,10.1038/s41598-020-65153-3,32439884,PMC7242400,Reference Ranges for Left Ventricular Curvedness and Curvedness-Based Functional Indices Using Cardiovascular Magnetic Resonance in Healthy Asian Subjects,"Curvature-based three-dimensional cardiovascular magnetic resonance (CMR) allows regional function characterization without an external spatial frame of reference. However, introduction of this modality into clinical practice is hampered by lack of reference values. We aim to establish normal ranges for 3D left ventricular (LV) regional parameters in relation to age and gender for 171 healthy subjects. LV geometrical reconstruction and automatic calculation of regional parameters were implemented by in-house software (CardioWerkz) using stacks of short-axis cine slices. Parameter normal ranges were stratified by gender and age categories (≤44, 45–64, 65–74 and 75–84 years). Our software had excellent intra- and inter-observer agreement. Ageing was significantly associated with increases in end-systolic (ES) curvedness (CES) and area strain (AS) with higher rates of increase in males, end-diastolic (ED) and ES wall thickness (WTED, WTES) with higher rates of increase in females, and reductions in ED and ES wall stress indices (σi,ED) with higher rates of increase in females. Females exhibited greater ED curvedness, CES, σi,ED and AS than males, but smaller WTED and WTES. Age × gender interaction was not observed for any parameter. This study establishes age and gender specific reference values for 3D LV regional parameters using CMR without additional image acquisition.","The authors thank Bao Ru Leong and Jennifer Ann Bryant (National Heart Centre Singapore) for their help in data collection. This research is supported by the National Medical Research Council Singapore (NMRC/OFIRG/0018/2016, NMRC/TA/0031/2015, MOH-000153, MOH-000351, MOH-000358 and NMRC/BnB/0017/2015), SingHealth Duke-NUS Academic Medicine Research Grant (AM/TP015/2018 (SRDUKAMR1814)), Biomedical Engineering Programme, Agency for Science, Technology and Research, Singapore Project Grant (132 148 0012).",,Scientific Reports,,"Adult; Aged; Aged, 80 and over; Asians; Female; Healthy Volunteers; Heart Ventricles; Humans; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Reference Values; Sex Factors; Ventricular Function, Left; Ventricular Function, Right; Young Adult",2020-05-21,2020,2020-05-21,,10,1,8465,All OA, Gold,Article,"Zhao, Xiaodan; Teo, Soo-Kng; Zhong, Liang; Leng, Shuang; Zhang, Jun-Mei; Low, Ris; Allen, John; Koh, Angela S.; Su, Yi; Tan, Ru-San","Zhao, Xiaodan (National Heart Research Institute Singapore, National Heart Centre Singapore, 5 Hospital Drive, 169609, Singapore, Singapore); Teo, Soo-Kng (Institute of High Performance Computing, Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, #16-16 Connexis, 138632, Singapore, Singapore); Zhong, Liang (National Heart Research Institute Singapore, National Heart Centre Singapore, 5 Hospital Drive, 169609, Singapore, Singapore; Duke-NUS Medical School, 8 College Road, 169857, Singapore, Singapore); Leng, Shuang (National Heart Research Institute Singapore, National Heart Centre Singapore, 5 Hospital Drive, 169609, Singapore, Singapore); Zhang, Jun-Mei (National Heart Research Institute Singapore, National Heart Centre Singapore, 5 Hospital Drive, 169609, Singapore, Singapore; Duke-NUS Medical School, 8 College Road, 169857, Singapore, Singapore); Low, Ris (National Heart Research Institute Singapore, National Heart Centre Singapore, 5 Hospital Drive, 169609, Singapore, Singapore); Allen, John (Duke-NUS Medical School, 8 College Road, 169857, Singapore, Singapore); Koh, Angela S. (National Heart Research Institute Singapore, National Heart Centre Singapore, 5 Hospital Drive, 169609, Singapore, Singapore; Duke-NUS Medical School, 8 College Road, 169857, Singapore, Singapore); Su, Yi (Institute of High Performance Computing, Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, #16-16 Connexis, 138632, Singapore, Singapore); Tan, Ru-San (National Heart Research Institute Singapore, National Heart Centre Singapore, 5 Hospital Drive, 169609, Singapore, Singapore; Duke-NUS Medical School, 8 College Road, 169857, Singapore, Singapore)","Zhong, Liang (National Heart Centre Singapore; Duke NUS Graduate Medical School)","Zhao, Xiaodan (National Heart Centre Singapore); Teo, Soo-Kng (Institute of High Performance Computing); Zhong, Liang (National Heart Centre Singapore; Duke NUS Graduate Medical School); Leng, Shuang (National Heart Centre Singapore); Zhang, Jun-Mei (National Heart Centre Singapore; Duke NUS Graduate Medical School); Low, Ris (National Heart Centre Singapore); Allen, John (Duke NUS Graduate Medical School); Koh, Angela S. (National Heart Centre Singapore; Duke NUS Graduate Medical School); Su, Yi (Institute of High Performance Computing); Tan, Ru-San (National Heart Centre Singapore; Duke NUS Graduate Medical School)",3,3,0.1,1.47,https://www.nature.com/articles/s41598-020-65153-3.pdf,https://app.dimensions.ai/details/publication/pub.1127756035,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1454,pub.1127793731,10.48550/arxiv.2005.10626,,,Efficient and Phase-aware Video Super-resolution for Cardiac MRI,"Cardiac Magnetic Resonance Imaging (CMR) is widely used since it can
illustrate the structure and function of heart in a non-invasive and painless
way. However, it is time-consuming and high-cost to acquire the high-quality
scans due to the hardware limitation. To this end, we propose a novel
end-to-end trainable network to solve CMR video super-resolution problem
without the hardware upgrade and the scanning protocol modifications. We
incorporate the cardiac knowledge into our model to assist in utilizing the
temporal information. Specifically, we formulate the cardiac knowledge as the
periodic function, which is tailored to meet the cyclic characteristic of CMR.
In addition, the proposed residual of residual learning scheme facilitates the
network to learn the LR-HR mapping in a progressive refinement fashion. This
mechanism enables the network to have the adaptive capability by adjusting
refinement iterations depending on the difficulty of the task. Extensive
experimental results on large-scale datasets demonstrate the superiority of the
proposed method compared with numerous state-of-the-art methods.",,,arXiv,,,2020-05-21,2020,,,,,,All OA, Green,Preprint,"Lin, Jhih-Yuan; Chang, Yu-Cheng; Hsu, Winston H.","Lin, Jhih-Yuan (); Chang, Yu-Cheng (); Hsu, Winston H. ()",,"Lin, Jhih-Yuan (); Chang, Yu-Cheng (); Hsu, Winston H. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1127793731,40 Engineering, 4006 Communications Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4605 Data Management and Data Science,,,,,,,
1892,pub.1127740942,10.48550/arxiv.2005.09026,,,On the effectiveness of GAN generated cardiac MRIs for segmentation,"In this work, we propose a Variational Autoencoder (VAE) - Generative
Adversarial Networks (GAN) model that can produce highly realistic MRI together
with its pixel accurate groundtruth for the application of cine-MR image
cardiac segmentation. On one side of our model is a Variational Autoencoder
(VAE) trained to learn the latent representations of cardiac shapes. On the
other side is a GAN that uses ""SPatially-Adaptive (DE)Normalization"" (SPADE)
modules to generate realistic MR images tailored to a given anatomical map. At
test time, the sampling of the VAE latent space allows to generate an arbitrary
large number of cardiac shapes, which are fed to the GAN that subsequently
generates MR images whose cardiac structure fits that of the cardiac shapes. In
other words, our system can generate a large volume of realistic yet labeled
cardiac MR images. We show that segmentation with CNNs trained with our
synthetic annotated images gets competitive results compared to traditional
techniques. We also show that combining data augmentation with our
GAN-generated images lead to an improvement in the Dice score of up to 12
percent while allowing for better generalization capabilities on other
datasets.",,,arXiv,,,2020-05-18,2020,,,,,,All OA, Green,Preprint,"Skandarani, Youssef; Painchaud, Nathan; Jodoin, Pierre-Marc; Lalande, Alain","Skandarani, Youssef (); Painchaud, Nathan (); Jodoin, Pierre-Marc (); Lalande, Alain ()",,"Skandarani, Youssef (); Painchaud, Nathan (); Jodoin, Pierre-Marc (); Lalande, Alain ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1127740942,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games; 4611 Machine Learning",,,,,,,,,,,
4533,pub.1127545194,10.1016/j.media.2020.101723,32622120,,Dynamically constructed network with error correction for accurate ventricle volume estimation,"Automated ventricle volume estimation (AVVE) on cardiac magnetic resonance (CMR) images is very important for clinical cardiac disease diagnosis. However, current AVVE methods ignore the error correction for the estimated volume. This results in clinically intolerable ventricle volume estimation error and further leads to wrong ejection fraction (EF) assessment, which significantly limits the application potential of AVVE methods. The objective of this paper is to address this problem with AVVE and further make it more clinically applicable. We proposed a dynamically constructed network to achieve accurate AVVE. First, we introduced a novel dynamically constructed deep learning framework, that evolves a single model into a bi-model volume estimation network. In this way, the EF correlation can be built directly based on the bi-model network. Second, we proposed an error correction strategy using dynamically created residual nodes, which is based on stochastic configurations with an EF correlation constraint. Finally, we formulated the proposed method into an end-to-end joint optimization framework for accurate ventricle volume estimation with effective error correction. Experiments and comparisons on large-scale cardiac magnetic resonance datasets were carried out. Results show that the proposed method outperforms state-of-the-art methods, and has good potential for clinical application. Besides, the proposed method is the first work to achieve error correction for AVVE and also has the potential to be extended to other medical index estimation tasks.","This work was supported by the National Key RD Program of China under Grant 2017YFC0113000 and by the National Natural Science Foundation of China under Grant 61701135. The authors thank Dr. Olga Shuilovich, Dr. Yue Zhang, and Dr. Ashley Mercado for providing the large amount of labelled data, as well as Nvidia for donating the Titan X.",,Medical Image Analysis,,Heart Ventricles, Humans, Magnetic Resonance Imaging,2020-05-13,2020,2020-05-13,2020-08,64,,101723,Closed,Article,"Luo, Gongning; Wang, Wei; Tam, Clara; Wang, Kuanquan; Cao, Shaodong; Zhang, Henggui; Chen, Bo; Li, Shuo","Luo, Gongning (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China.); Wang, Wei (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China. Electronic address: wangwei2019@hit.edu.cn.); Tam, Clara (The Department of Medical Imaging, Western University, London, Canada; The Digital Imaging Group of London, London, ON N6A 3K7, Canada.); Wang, Kuanquan (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China.); Cao, Shaodong (The Department of Radiology, The Fourth Hospital of Harbin Medical University, Harbin 150001, China.); Zhang, Henggui (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; School of Physics and Astronomy, University of Manchester, Manchester, UK.); Chen, Bo (The Department of Medical Imaging, Western University, London, Canada; The Digital Imaging Group of London, London, ON N6A 3K7, Canada.); Li, Shuo (The Department of Medical Imaging, Western University, London, Canada; The Digital Imaging Group of London, London, ON N6A 3K7, Canada. Electronic address: sli287@uwo.ca.)","Wang, Wei (Harbin Institute of Technology); Li, Shuo (Western University; )","Luo, Gongning (Harbin Institute of Technology); Wang, Wei (Harbin Institute of Technology); Tam, Clara (Western University); Wang, Kuanquan (Harbin Institute of Technology); Cao, Shaodong (Harbin Medical University); Zhang, Henggui (Harbin Institute of Technology; University of Manchester); Chen, Bo (Western University); Li, Shuo (Western University)",8,7,0.51,,,https://app.dimensions.ai/details/publication/pub.1127545194,40 Engineering,,,,,,,,,,
1451,pub.1127711093,10.48550/arxiv.2005.08869,,,Predicting Scores of Medical Imaging Segmentation Methods with  Meta-Learning,"Deep learning has led to state-of-the-art results for many medical imaging
tasks, such as segmentation of different anatomical structures. With the
increased numbers of deep learning publications and openly available code, the
approach to choosing a model for a new task becomes more complicated, while
time and (computational) resources are limited. A possible solution to choosing
a model efficiently is meta-learning, a learning method in which prior
performance of a model is used to predict the performance for new tasks. We
investigate meta-learning for segmentation across ten datasets of different
organs and modalities. We propose four ways to represent each dataset by
meta-features: one based on statistical features of the images and three are
based on deep learning features. We use support vector regression and deep
neural networks to learn the relationship between the meta-features and prior
model performance. On three external test datasets these methods give Dice
scores within 0.10 of the true performance. These results demonstrate the
potential of meta-learning in medical imaging.",,,arXiv,,,2020-05-08,2020,,,,,,All OA, Green,Preprint,"van Sonsbeek, Tom; Cheplygina, Veronika","van Sonsbeek, Tom (); Cheplygina, Veronika ()",,"van Sonsbeek, Tom (); Cheplygina, Veronika ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1127711093,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1344,pub.1127477589,10.48550/arxiv.2005.03463,,,How Can CNNs Use Image Position for Segmentation?,"Convolution is an equivariant operation, and image position does not affect
its result. A recent study shows that the zero-padding employed in
convolutional layers of CNNs provides position information to the CNNs. The
study further claims that the position information enables accurate inference
for several tasks, such as object recognition, segmentation, etc. However,
there is a technical issue with the design of the experiments of the study, and
thus the correctness of the claim is yet to be verified. Moreover, the absolute
image position may not be essential for the segmentation of natural images, in
which target objects will appear at any image position. In this study, we
investigate how positional information is and can be utilized for segmentation
tasks. Toward this end, we consider {\em positional encoding} (PE) that adds
channels embedding image position to the input images and compare PE with
several padding methods. Considering the above nature of natural images, we
choose medical image segmentation tasks, in which the absolute position appears
to be relatively important, as the same organs (of different patients) are
captured in similar sizes and positions. We draw a mixed conclusion from the
experimental results; the positional encoding certainly works in some cases,
but the absolute image position may not be so important for segmentation tasks
as we think.",,,arXiv,,,2020-05-07,2020,,,,,,All OA, Green,Preprint,"Murase, Rito; Suganuma, Masanori; Okatani, Takayuki","Murase, Rito (); Suganuma, Masanori (); Okatani, Takayuki ()",,"Murase, Rito (); Suganuma, Masanori (); Okatani, Takayuki ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1127477589,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1177,pub.1127349163,10.48550/arxiv.2005.00328,,,ACCL: Adversarial constrained-CNN loss for weakly supervised medical  image segmentation,"We propose adversarial constrained-CNN loss, a new paradigm of
constrained-CNN loss methods, for weakly supervised medical image segmentation.
In the new paradigm, prior knowledge is encoded and depicted by reference
masks, and is further employed to impose constraints on segmentation outputs
through adversarial learning with reference masks. Unlike pseudo label methods
for weakly supervised segmentation, such reference masks are used to train a
discriminator rather than a segmentation network, and thus are not required to
be paired with specific images. Our new paradigm not only greatly facilitates
imposing prior knowledge on network's outputs, but also provides stronger and
higher-order constraints, i.e., distribution approximation, through adversarial
learning. Extensive experiments involving different medical modalities,
different anatomical structures, different topologies of the object of
interest, different levels of prior knowledge and weakly supervised annotations
with different annotation ratios is conducted to evaluate our ACCL method.
Consistently superior segmentation results over the size constrained-CNN loss
method have been achieved, some of which are close to the results of full
supervision, thus fully verifying the effectiveness and generalization of our
method. Specifically, we report an average Dice score of 75.4% with an average
annotation ratio of 0.65%, surpassing the prior art, i.e., the size
constrained-CNN loss method, by a large margin of 11.4%. Our codes are made
publicly available at https://github.com/PengyiZhang/ACCL.",,,arXiv,,,2020-05-01,2020,,,,,,All OA, Green,Preprint,"Zhang, Pengyi; Zhong, Yunxin; Li, Xiaoqiong","Zhang, Pengyi (); Zhong, Yunxin (); Li, Xiaoqiong ()",,"Zhang, Pengyi (); Zhong, Yunxin (); Li, Xiaoqiong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1127349163,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1066,pub.1127178894,10.48550/arxiv.2004.12314,,,A Global Benchmark of Algorithms for Segmenting Late Gadolinium-Enhanced  Cardiac Magnetic Resonance Imaging,"Segmentation of cardiac images, particularly late gadolinium-enhanced
magnetic resonance imaging (LGE-MRI) widely used for visualizing diseased
cardiac structures, is a crucial first step for clinical diagnosis and
treatment. However, direct segmentation of LGE-MRIs is challenging due to its
attenuated contrast. Since most clinical studies have relied on manual and
labor-intensive approaches, automatic methods are of high interest,
particularly optimized machine learning approaches. To address this, we
organized the ""2018 Left Atrium Segmentation Challenge"" using 154 3D LGE-MRIs,
currently the world's largest cardiac LGE-MRI dataset, and associated labels of
the left atrium segmented by three medical experts, ultimately attracting the
participation of 27 international teams. In this paper, extensive analysis of
the submitted algorithms using technical and biological metrics was performed
by undergoing subgroup analysis and conducting hyper-parameter analysis,
offering an overall picture of the major design choices of convolutional neural
networks (CNNs) and practical considerations for achieving state-of-the-art
left atrium segmentation. Results show the top method achieved a dice score of
93.2% and a mean surface to a surface distance of 0.7 mm, significantly
outperforming prior state-of-the-art. Particularly, our analysis demonstrated
that double, sequentially used CNNs, in which a first CNN is used for automatic
region-of-interest localization and a subsequent CNN is used for refined
regional segmentation, achieved far superior results than traditional methods
and pipelines containing single CNNs. This large-scale benchmarking study makes
a significant step towards much-improved segmentation methods for cardiac
LGE-MRIs, and will serve as an important benchmark for evaluating and comparing
the future works in the field.",,,arXiv,,,2020-04-26,2020,,,,,,All OA, Green,Preprint,"Xiong, Zhaohan; Xia, Qing; Hu, Zhiqiang; Huang, Ning; Bian, Cheng; Zheng, Yefeng; Vesal, Sulaiman; Ravikumar, Nishant; Maier, Andreas; Yang, Xin; Heng, Pheng-Ann; Ni, Dong; Li, Caizi; Tong, Qianqian; Si, Weixin; Puybareau, Elodie; Khoudli, Younes; Geraud, Thierry; Chen, Chen; Bai, Wenjia; Rueckert, Daniel; Xu, Lingchao; Zhuang, Xiahai; Luo, Xinzhe; Jia, Shuman; Sermesant, Maxime; Liu, Yashu; Wang, Kuanquan; Borra, Davide; Masci, Alessandro; Corsi, Cristiana; de Vente, Coen; Veta, Mitko; Karim, Rashed; Preetha, Chandrakanth Jayachandran; Engelhardt, Sandy; Qiao, Menyun; Wang, Yuanyuan; Tao, Qian; Nunez-Garcia, Marta; Camara, Oscar; Savioli, Nicolo; Lamata, Pablo; Zhao, Jichao","Xiong, Zhaohan (); Xia, Qing (); Hu, Zhiqiang (); Huang, Ning (); Bian, Cheng (); Zheng, Yefeng (); Vesal, Sulaiman (); Ravikumar, Nishant (); Maier, Andreas (); Yang, Xin (); Heng, Pheng-Ann (); Ni, Dong (); Li, Caizi (); Tong, Qianqian (); Si, Weixin (); Puybareau, Elodie (); Khoudli, Younes (); Geraud, Thierry (); Chen, Chen (); Bai, Wenjia (); Rueckert, Daniel (); Xu, Lingchao (); Zhuang, Xiahai (); Luo, Xinzhe (); Jia, Shuman (); Sermesant, Maxime (); Liu, Yashu (); Wang, Kuanquan (); Borra, Davide (); Masci, Alessandro (); Corsi, Cristiana (); de Vente, Coen (); Veta, Mitko (); Karim, Rashed (); Preetha, Chandrakanth Jayachandran (); Engelhardt, Sandy (); Qiao, Menyun (); Wang, Yuanyuan (); Tao, Qian (); Nunez-Garcia, Marta (); Camara, Oscar (); Savioli, Nicolo (); Lamata, Pablo (); Zhao, Jichao ()",,"Xiong, Zhaohan (); Xia, Qing (); Hu, Zhiqiang (); Huang, Ning (); Bian, Cheng (); Zheng, Yefeng (); Vesal, Sulaiman (); Ravikumar, Nishant (); Maier, Andreas (); Yang, Xin (); Heng, Pheng-Ann (); Ni, Dong (); Li, Caizi (); Tong, Qianqian (); Si, Weixin (); Puybareau, Elodie (); Khoudli, Younes (); Geraud, Thierry (); Chen, Chen (); Bai, Wenjia (); Rueckert, Daniel (); Xu, Lingchao (); Zhuang, Xiahai (); Luo, Xinzhe (); Jia, Shuman (); Sermesant, Maxime (); Liu, Yashu (); Wang, Kuanquan (); Borra, Davide (); Masci, Alessandro (); Corsi, Cristiana (); de Vente, Coen (); Veta, Mitko (); Karim, Rashed (); Preetha, Chandrakanth Jayachandran (); Engelhardt, Sandy (); Qiao, Menyun (); Wang, Yuanyuan (); Tao, Qian (); Nunez-Garcia, Marta (); Camara, Oscar (); Savioli, Nicolo (); Lamata, Pablo (); Zhao, Jichao ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1127178894,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
4837,pub.1126916232,10.1002/mrm.28294,32329105,,Automating in vivo cardiac diffusion tensor postprocessing with deep learning–based segmentation,"PURPOSE: In this work we develop and validate a fully automated postprocessing framework for in vivo diffusion tensor cardiac magnetic resonance (DT-CMR) data powered by deep learning.
METHODS: A U-Net based convolutional neural network was developed and trained to segment the heart in short-axis DT-CMR images. This was used as the basis to automate and enhance several stages of the DT-CMR tensor calculation workflow, including image registration and removal of data corrupted with artifacts, and to segment the left ventricle. Previously collected and analyzed scans (348 healthy scans and 144 cardiomyopathy patient scans) were used to train and validate the U-Net. All data were acquired at 3 T with a STEAM-EPI sequence. The DT-CMR postprocessing and U-Net training/testing were performed with MATLAB and Python TensorFlow, respectively.
RESULTS: The U-Net achieved a median Dice coefficient of 0.93 [0.92, 0.94] for the segmentation of the left-ventricular myocardial region. The image registration of diffusion images improved with the U-Net segmentation (P < .0001), and the identification of corrupted images achieved an F1 score of 0.70 when compared with an experienced user. Finally, the resulting tensor measures showed good agreement between an experienced user and the fully automated method.
CONCLUSION: The trained U-Net successfully automated the DT-CMR postprocessing, supporting real-time results and reducing human workload. The automatic segmentation of the heart improved image registration, resulting in improvements of the calculated DT parameters.","This work was supported by the British Heart Foundation (RG/19/1/34160). The NVIDIA Quadro P6000 GPU used for this research was kindly donated by NVIDIA (Santa Clara, California).",,Magnetic Resonance in Medicine,,"Artifacts; Deep Learning; Heart; Humans; Magnetic Resonance Imaging; Neural Networks, Computer",2020-04-23,2020,2020-04-23,2020-11,84,5,2801-2814,All OA, Hybrid,Article,"Ferreira, Pedro F.; Martin, Raquel R.; Scott, Andrew D.; Khalique, Zohya; Yang, Guang; Nielles‐Vallespin, Sonia; Pennell, Dudley J.; Firmin, David N.","Ferreira, Pedro F. (Cardiovascular Magnetic Resonance Unit, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College, London, United Kingdom); Martin, Raquel R. (Department of Bioengineering, Imperial College, London, United Kingdom); Scott, Andrew D. (Cardiovascular Magnetic Resonance Unit, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College, London, United Kingdom); Khalique, Zohya (Cardiovascular Magnetic Resonance Unit, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College, London, United Kingdom); Yang, Guang (Cardiovascular Magnetic Resonance Unit, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College, London, United Kingdom); Nielles‐Vallespin, Sonia (Cardiovascular Magnetic Resonance Unit, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College, London, United Kingdom); Pennell, Dudley J. (Cardiovascular Magnetic Resonance Unit, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College, London, United Kingdom); Firmin, David N. (Cardiovascular Magnetic Resonance Unit, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College, London, United Kingdom)","Ferreira, Pedro F. (Royal Brompton Hospital; Imperial College London)","Ferreira, Pedro F. (Royal Brompton Hospital; Imperial College London); Martin, Raquel R. (Imperial College London); Scott, Andrew D. (Royal Brompton Hospital; Imperial College London); Khalique, Zohya (Royal Brompton Hospital; Imperial College London); Yang, Guang (Royal Brompton Hospital; Imperial College London); Nielles‐Vallespin, Sonia (Royal Brompton Hospital; Imperial College London); Pennell, Dudley J. (Royal Brompton Hospital; Imperial College London); Firmin, David N. (Royal Brompton Hospital; Imperial College London)",15,13,1.23,3.66,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.28294,https://app.dimensions.ai/details/publication/pub.1126916232,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,
1548,pub.1126924990,10.48550/arxiv.2004.11253,,,L-CO-Net: Learned Condensation-Optimization Network for Clinical  Parameter Estimation from Cardiac Cine MRI,"In this work, we implement a fully convolutional segmenter featuring both a
learned group structure and a regularized weight-pruner to reduce the high
computational cost in volumetric image segmentation. We validated our framework
on the ACDC dataset featuring one healthy and four pathology groups imaged
throughout the cardiac cycle. Our technique achieved Dice scores of 96.8% (LV
blood-pool), 93.3% (RV blood-pool) and 90.0% (LV Myocardium) with five-fold
cross-validation and yielded similar clinical parameters as those estimated
from the ground truth segmentation data. Based on these results, this technique
has the potential to become an efficient and competitive cardiac image
segmentation tool that may be used for cardiac computer-aided diagnosis,
planning, and guidance applications.",,,arXiv,,,2020-04-21,2020,,,,,,All OA, Green,Preprint,"Hasan, S. M. Kamrul; Linte, Cristian A.","Hasan, S. M. Kamrul (); Linte, Cristian A. ()",,"Hasan, S. M. Kamrul (); Linte, Cristian A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1126924990,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1396,pub.1126897125,10.48550/arxiv.2004.10129,,,Have you forgotten? A method to assess if machine learning models have  forgotten data,"In the era of deep learning, aggregation of data from several sources is a
common approach to ensuring data diversity. Let us consider a scenario where
several providers contribute data to a consortium for the joint development of
a classification model (hereafter the target model), but, now one of the
providers decides to leave. This provider requests that their data (hereafter
the query dataset) be removed from the databases but also that the model
`forgets' their data. In this paper, for the first time, we want to address the
challenging question of whether data have been forgotten by a model. We assume
knowledge of the query dataset and the distribution of a model's output. We
establish statistical methods that compare the target's outputs with outputs of
models trained with different datasets. We evaluate our approach on several
benchmark datasets (MNIST, CIFAR-10 and SVHN) and on a cardiac pathology
diagnosis task using data from the Automated Cardiac Diagnosis Challenge
(ACDC). We hope to encourage studies on what information a model retains and
inspire extensions in more complex settings.",,,arXiv,,,2020-04-21,2020,,,,,,All OA, Green,Preprint,"Liu, Xiao; Tsaftaris, Sotirios A","Liu, Xiao (); Tsaftaris, Sotirios A ()",,"Liu, Xiao (); Tsaftaris, Sotirios A ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1126897125,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1295,pub.1126668604,10.48550/arxiv.2004.05319,,,KD-MRI: A knowledge distillation framework for image reconstruction and  image restoration in MRI workflow,"Deep learning networks are being developed in every stage of the MRI workflow
and have provided state-of-the-art results. However, this has come at the cost
of increased computation requirement and storage. Hence, replacing the networks
with compact models at various stages in the MRI workflow can significantly
reduce the required storage space and provide considerable speedup. In computer
vision, knowledge distillation is a commonly used method for model compression.
In our work, we propose a knowledge distillation (KD) framework for the image
to image problems in the MRI workflow in order to develop compact,
low-parameter models without a significant drop in performance. We propose a
combination of the attention-based feature distillation method and imitation
loss and demonstrate its effectiveness on the popular MRI reconstruction
architecture, DC-CNN. We conduct extensive experiments using Cardiac, Brain,
and Knee MRI datasets for 4x, 5x and 8x accelerations. We observed that the
student network trained with the assistance of the teacher using our proposed
KD framework provided significant improvement over the student network trained
without assistance across all the datasets and acceleration factors.
Specifically, for the Knee dataset, the student network achieves $65\%$
parameter reduction, 2x faster CPU running time, and 1.5x faster GPU running
time compared to the teacher. Furthermore, we compare our attention-based
feature distillation method with other feature distillation methods. We also
conduct an ablative study to understand the significance of attention-based
distillation and imitation loss. We also extend our KD framework for MRI
super-resolution and show encouraging results.",,,arXiv,,,2020-04-11,2020,,,,,,All OA, Green,Preprint,"Murugesan, Balamurali; Vijayarangan, Sricharan; Sarveswaran, Kaushik; Ram, Keerthi; Sivaprakasam, Mohanasankar","Murugesan, Balamurali (); Vijayarangan, Sricharan (); Sarveswaran, Kaushik (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",,"Murugesan, Balamurali (); Vijayarangan, Sricharan (); Sarveswaran, Kaushik (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1126668604,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
866,pub.1126507887,10.48550/arxiv.2004.04668,,,Test-Time Adaptable Neural Networks for Robust Medical Image  Segmentation,"Convolutional Neural Networks (CNNs) work very well for supervised learning
problems when the training dataset is representative of the variations expected
to be encountered at test time. In medical image segmentation, this premise is
violated when there is a mismatch between training and test images in terms of
their acquisition details, such as the scanner model or the protocol.
Remarkable performance degradation of CNNs in this scenario is well documented
in the literature. To address this problem, we design the segmentation CNN as a
concatenation of two sub-networks: a relatively shallow image normalization
CNN, followed by a deep CNN that segments the normalized image. We train both
these sub-networks using a training dataset, consisting of annotated images
from a particular scanner and protocol setting. Now, at test time, we adapt the
image normalization sub-network for \emph{each test image}, guided by an
implicit prior on the predicted segmentation labels. We employ an independently
trained denoising autoencoder (DAE) in order to model such an implicit prior on
plausible anatomical segmentation labels. We validate the proposed idea on
multi-center Magnetic Resonance imaging datasets of three anatomies: brain,
heart and prostate. The proposed test-time adaptation consistently provides
performance improvement, demonstrating the promise and generality of the
approach. Being agnostic to the architecture of the deep CNN, the second
sub-network, the proposed design can be utilized with any segmentation network
to increase robustness to variations in imaging scanners and protocols. Our
code is available at:
\url{https://github.com/neerakara/test-time-adaptable-neural-networks-for-domain-generalization}.",,,arXiv,,,2020-04-09,2020,,,,,,All OA, Green,Preprint,"Karani, Neerav; Erdil, Ertunc; Chaitanya, Krishna; Konukoglu, Ender","Karani, Neerav (); Erdil, Ertunc (); Chaitanya, Krishna (); Konukoglu, Ender ()",,"Karani, Neerav (); Erdil, Ertunc (); Chaitanya, Krishna (); Konukoglu, Ender ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1126507887,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1546,pub.1126276137,10.48550/arxiv.2004.02249,,,CondenseUNet: A Memory-Efficient Condensely-Connected Architecture for  Bi-ventricular Blood Pool and Myocardium Segmentation,"With the advent of Cardiac Cine Magnetic Resonance (CMR) Imaging, there has
been a paradigm shift in medical technology, thanks to its capability of
imaging different structures within the heart without ionizing radiation.
However, it is very challenging to conduct pre-operative planning of minimally
invasive cardiac procedures without accurate segmentation and identification of
the left ventricle (LV), right ventricle (RV) blood-pool, and LV-myocardium.
Manual segmentation of those structures, nevertheless, is time-consuming and
often prone to error and biased outcomes. Hence, automatic and computationally
efficient segmentation techniques are paramount. In this work, we propose a
novel memory-efficient Convolutional Neural Network (CNN) architecture as a
modification of both CondenseNet, as well as DenseNet for ventricular
blood-pool segmentation by introducing a bottleneck block and an upsampling
path. Our experiments show that the proposed architecture runs on the Automated
Cardiac Diagnosis Challenge (ACDC) dataset using half (50%) the memory
requirement of DenseNet and one-twelfth (~ 8%) of the memory requirements of
U-Net, while still maintaining excellent accuracy of cardiac segmentation. We
validated the framework on the ACDC dataset featuring one healthy and four
pathology groups whose heart images were acquired throughout the cardiac cycle
and achieved the mean dice scores of 96.78% (LV blood-pool), 93.46% (RV
blood-pool) and 90.1% (LV-Myocardium). These results are promising and promote
the proposed methods as a competitive tool for cardiac image segmentation and
clinical parameter estimation that has the potential to provide fast and
accurate results, as needed for pre-procedural planning and/or pre-operative
applications.",,,arXiv,,,2020-04-05,2020,,,,,,All OA, Green,Preprint,"Hasan, S. M. Kamrul; Linte, Cristian A.","Hasan, S. M. Kamrul (); Linte, Cristian A. ()",,"Hasan, S. M. Kamrul (); Linte, Cristian A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1126276137,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences, 40 Engineering,,,,,,,,
1728,pub.1129811768,10.1109/isbiworkshops50223.2020.9153453,,,Dual-Encoder-Unet For Fast Mri Reconstruction,"Deep learning has shown great promise for successful acceleration of MRI data acquisition. A variety of architectures have been proposed to obtain high fidelity image from partially observed kspace or undersampled image. U-Net has demonstrated impressive performance for providing high quality reconstruction from undersampled image data. The recently proposed dAutomap is an innovative approach to directly learn the domain transformation from source kspace to target image domain. However these networks operate only on a single domain where information from the excluded domain is not utilized for reconstruction. This paper provides a deep learning based strategy by simultaneously optimizing both the raw kspace data and undersampled image data for reconstruction. Our experiments demonstrate that, such a hybrid approach can potentially improve reconstruction, compared to deep learning networks that operate solely on a single domain.",,,,2020 IEEE 17th International Symposium on Biomedical Imaging Workshops (ISBI Workshops),,2020-04-04,2020,,2020-04-04,0,,1-4,Closed,Proceeding,"Jethi, Amrit Kumar; Murugesan, Balamurali; Ram, Keerthi; Sivaprakasam, Mohanasankar","Jethi, Amrit Kumar (Indian Institute of Technology-Madras (IITM), India); Murugesan, Balamurali (Indian Institute of Technology-Madras (IITM), India; Healthcare Technology Innovation Centre (HTIC), IITM, India); Ram, Keerthi (Healthcare Technology Innovation Centre (HTIC), IITM, India); Sivaprakasam, Mohanasankar (Indian Institute of Technology-Madras (IITM), India; Healthcare Technology Innovation Centre (HTIC), IITM, India)","Jethi, Amrit Kumar (Indian Institute of Technology Madras)","Jethi, Amrit Kumar (Indian Institute of Technology Madras); Murugesan, Balamurali (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre; Indian Institute of Technology Madras); Ram, Keerthi (Healthcare Technology Innovation Centre; Indian Institute of Technology Madras); Sivaprakasam, Mohanasankar (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre; Indian Institute of Technology Madras)",3,2,,1.43,,https://app.dimensions.ai/details/publication/pub.1129811768,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 51 Physical Sciences,,,,,,,,,,
1649,pub.1127839791,10.1109/isbi45749.2020.9098546,,,Soft-Label Guided Semi-Supervised Learning for Bi-Ventricle Segmentation in Cardiac Cine MRI,"Deep convolutional neural networks have been applied to medical image segmentation tasks successfully in recent years by taking advantage of a large amount of training data with golden standard annotations. However, it is difficult and expensive to obtain good-quality annotations in practice. This work aims to propose a novel semi-supervised learning framework to improve the ventricle segmentation from 2D cine MR images. Our method is efficient and effective by computing soft labels dynamically for the unlabeled data. Specifically, we obtain the soft labels, rather than hard labels, from a teacher model in every learning iteration. The uncertainty of the target label of unlabeled data is intrinsically encoded in the soft label. The soft label can be improved towards the ideal target in training. We use a separate loss to regularize the unlabeled data to produce similar probability distribution as the soft labels in each iteration. Experiments show that our method outperforms a state-of-the-art semi-supervised method.",,,,2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI),,2020-04-03,2020,,2020-04-03,0,,1752-1755,Closed,Proceeding,"Chang, Qi; Yan, Zhennan; Lou, Yixuan; Axel, Leon; Metaxas, Dimitris N.","Chang, Qi (Department of Computer Science, Rutgers University, Piscataway, NJ, USA); Yan, Zhennan (SenseBrain Technology Limited LLC, NJ, USA); Lou, Yixuan (Albany Academy for Girls, Albany, NY, USA); Axel, Leon (Deparment of Radiology, NYU School of Medicine, NY, USA); Metaxas, Dimitris N. (Department of Computer Science, Rutgers University, Piscataway, NJ, USA)",,"Chang, Qi (Rutgers, The State University of New Jersey); Yan, Zhennan (); Lou, Yixuan (); Axel, Leon (New York University); Metaxas, Dimitris N. (Rutgers, The State University of New Jersey)",8,8,,4.12,,https://app.dimensions.ai/details/publication/pub.1127839791,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
1615,pub.1127839842,10.1109/isbi45749.2020.9098597,,,A Context Based Deep Learning Approach for Unbalanced Medical Image Segmentation,"Automated medical image segmentation is an important step in many medical procedures. Recently, deep learning networks have been widely used for various medical image segmentation tasks, with U - Net and generative adversarial nets (GANs) being some of the commonly used ones. Foreground-background class imbalance is a common occurrence in medical images, and U-Net has difficulty in handling class imbalance because of its cross entropy (CE) objective function. Similarly, GAN also suffers from class imbalance because the discriminator looks at the entire image to classify it as real or fake. Since the discriminator is essentially a deep learning classifier, it is incapable of correctly identifying minor changes in small structures. To address these issues, we propose a novel context based CE loss function for U-Net, and a novel architecture Seg-GLGAN. The context based CE is a linear combination of CE obtained over the entire image and its region of interest (ROI). In Seg-GLGAN, we introduce a novel context discriminator to which the entire image and its ROI are fed as input, thus enforcing local context. We conduct extensive experiments using two challenging unbalanced datasets: PROMISE12 and ACDC. We observe that segmentation results obtained from our methods give better segmentation metrics as compared to various baseline methods.",,,,2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI),,2020-04-03,2020,,2020-04-03,0,,1949-1953,All OA, Green,Proceeding,"Murugesan, Balamurali; Sarveswaran, Kaushik; S, Vijaya Raghavan; Shankaranarayana, Sharath M; Ram, Keerthi; Sivaprakasam, Mohanasankar","Murugesan, Balamurali (Indian Institute of Technology Madras (IITM), India; Healthcare Technology Innovation Centre (HTIC), IITM, India); Sarveswaran, Kaushik (Healthcare Technology Innovation Centre (HTIC), IITM, India); S, Vijaya Raghavan (Healthcare Technology Innovation Centre (HTIC), IITM, India); Shankaranarayana, Sharath M (Zasti, India); Ram, Keerthi (Healthcare Technology Innovation Centre (HTIC), IITM, India); Sivaprakasam, Mohanasankar (Indian Institute of Technology Madras (IITM), India; Healthcare Technology Innovation Centre (HTIC), IITM, India)",,"Murugesan, Balamurali (Indian Institute of Technology Madras; Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); Sarveswaran, Kaushik (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); S, Vijaya Raghavan (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); Shankaranarayana, Sharath M (); Ram, Keerthi (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); Sivaprakasam, Mohanasankar (Indian Institute of Technology Madras; Indian Institute of Technology Madras; Healthcare Technology Innovation Centre)",4,4,,2.06,http://arxiv.org/pdf/2001.02387,https://app.dimensions.ai/details/publication/pub.1127839842,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1516,pub.1125773138,10.48550/arxiv.2003.08462,,,Semi-supervised few-shot learning for medical image segmentation,"Recent years have witnessed the great progress of deep neural networks on
semantic segmentation, particularly in medical imaging. Nevertheless, training
high-performing models require large amounts of pixel-level ground truth masks,
which can be prohibitive to obtain in the medical domain. Furthermore, training
such models in a low-data regime highly increases the risk of overfitting.
Recent attempts to alleviate the need for large annotated datasets have
developed training strategies under the few-shot learning paradigm, which
addresses this shortcoming by learning a novel class from only a few labeled
examples. In this context, a segmentation model is trained on episodes, which
represent different segmentation problems, each of them trained with a very
small labeled dataset. In this work, we propose a novel few-shot learning
framework for semantic segmentation, where unlabeled images are also made
available at each episode. To handle this new learning paradigm, we propose to
include surrogate tasks that can leverage very powerful supervisory signals
--derived from the data itself-- for semantic feature learning. We show that
including unlabeled surrogate tasks in the episodic training leads to more
powerful feature representations, which ultimately results in better
generability to unseen tasks. We demonstrate the efficiency of our method in
the task of skin lesion segmentation in two publicly available datasets.
Furthermore, our approach is general and model-agnostic, which can be combined
with different deep architectures.",,,arXiv,,,2020-03-18,2020,,,,,,All OA, Green,Preprint,"Feyjie, Abdur R; Azad, Reza; Pedersoli, Marco; Kauffman, Claude; Ayed, Ismail Ben; Dolz, Jose","Feyjie, Abdur R (); Azad, Reza (); Pedersoli, Marco (); Kauffman, Claude (); Ayed, Ismail Ben (); Dolz, Jose ()",,"Feyjie, Abdur R (); Azad, Reza (); Pedersoli, Marco (); Kauffman, Claude (); Ayed, Ismail Ben (); Dolz, Jose ()",1,1,,0.52,,https://app.dimensions.ai/details/publication/pub.1125773138,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5350,pub.1125558995,10.1016/j.compmedimag.2020.101717,32222684,PMC7232687,A deep learning-based approach for automatic segmentation and quantification of the left ventricle from cardiac cine MR images,"Cardiac MRI has been widely used for noninvasive assessment of cardiac anatomy and function as well as heart diagnosis. The estimation of physiological heart parameters for heart diagnosis essentially require accurate segmentation of the Left ventricle (LV) from cardiac MRI. Therefore, we propose a novel deep learning approach for the automated segmentation and quantification of the LV from cardiac cine MR images. We aim to achieve lower errors for the estimated heart parameters compared to the previous studies by proposing a novel deep learning segmentation method. Our framework starts by an accurate localization of the LV blood pool center-point using a fully convolutional neural network (FCN) architecture called FCN1. Then, a region of interest (ROI) that contains the LV is extracted from all heart sections. The extracted ROIs are used for the segmentation of LV cavity and myocardium via a novel FCN architecture called FCN2. The FCN2 network has several bottleneck layers and uses less memory footprint than conventional architectures such as U-net. Furthermore, a new loss function called radial loss that minimizes the distance between the predicted and true contours of the LV is introduced into our model. Following myocardial segmentation, functional and mass parameters of the LV are estimated. Automated Cardiac Diagnosis Challenge (ACDC-2017) dataset was used to validate our framework, which gave better segmentation, accurate estimation of cardiac parameters, and produced less error compared to other methods applied on the same dataset. Furthermore, we showed that our segmentation approach generalizes well across different datasets by testing its performance on a locally acquired dataset. To sum up, we propose a deep learning approach that can be translated into a clinical tool for heart diagnosis.",This research was funded by the Deanship of Scientific Research at Princess Nourah bint Abdulrahman University through the Fast-track Research Funding Program.,,Computerized Medical Imaging and Graphics,,"Deep Learning; Heart Ventricles; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine",2020-03-12,2020,2020-03-12,2020-04,81,,101717,All OA, Green,Article,"Abdeltawab, Hisham; Khalifa, Fahmi; Taher, Fatma; Alghamdi, Norah Saleh; Ghazal, Mohammed; Beache, Garth; Mohamed, Tamer; Keynton, Robert; El-Baz, Ayman","Abdeltawab, Hisham (Department of Bioengineering, University of Louisville, Louisville, KY 40292, USA.); Khalifa, Fahmi (Department of Bioengineering, University of Louisville, Louisville, KY 40292, USA.); Taher, Fatma (College of Technological Innovation, Zayed University, Dubai, United Arab Emirates.); Alghamdi, Norah Saleh (College of Computer and Information Science, Princess Nourah bint Abdulrahman University, Saudi Arabia.); Ghazal, Mohammed (Department of Bioengineering, University of Louisville, Louisville, KY 40292, USA.); Beache, Garth (Department of Radiology, University of Louisville, Louisville, KY 40202, USA.); Mohamed, Tamer (Institute of Molecular Cardiology, University of Louisville, Louisville, KY 40202, USA.); Keynton, Robert (Department of Bioengineering, University of Louisville, Louisville, KY 40292, USA.); El-Baz, Ayman (Department of Bioengineering, University of Louisville, Louisville, KY 40292, USA. Electronic address: aselba01@louisville.edu.)","El-Baz, Ayman (University of Louisville)","Abdeltawab, Hisham (University of Louisville); Khalifa, Fahmi (University of Louisville); Taher, Fatma (Zayed University); Alghamdi, Norah Saleh (Princess Nourah bint Abdulrahman University); Ghazal, Mohammed (University of Louisville); Beache, Garth (University of Louisville); Mohamed, Tamer (University of Louisville); Keynton, Robert (University of Louisville); El-Baz, Ayman (University of Louisville)",33,32,1.68,17.01,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7232687,https://app.dimensions.ai/details/publication/pub.1125558995,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
3773,pub.1125498262,10.1016/j.neunet.2020.03.007,32203876,,AdaEn-Net: An ensemble of adaptive 2D–3D Fully Convolutional Networks for medical image segmentation,"Fully Convolutional Networks (FCNs) have emerged as powerful segmentation models but are usually designed manually, which requires extensive time and can result in large and complex architectures. There is a growing interest to automatically design efficient architectures that can accurately segment 3D medical images. However, most approaches either do not fully exploit volumetric information or do not optimize the model's size. To address these problems, we propose a self-adaptive 2D-3D ensemble of FCNs called AdaEn-Net for 3D medical image segmentation that incorporates volumetric data and adapts to a particular dataset by optimizing both the model's performance and size. The AdaEn-Net consists of a 2D FCN that extracts intra-slice information and a 3D FCN that exploits inter-slice information. The architecture and hyperparameters of the 2D and 3D architectures are found through a multiobjective evolutionary based algorithm that maximizes the expected segmentation accuracy and minimizes the number of parameters in the network. The main contribution of this work is a model that fully exploits volumetric information and automatically searches for a high-performing and efficient architecture. The AdaEn-Net was evaluated for prostate segmentation on the PROMISE12 Grand Challenge and for cardiac segmentation on the MICCAI ACDC challenge. In the first challenge, the AdaEn-Net ranks 9 out of 297 submissions and surpasses the performance of an automatically-generated segmentation network while producing an architecture with 13× fewer parameters. In the second challenge, the proposed model is ranked within the top 8 submissions and outperforms an architecture designed with reinforcement learning while having 1.25× fewer parameters.",,,Neural Networks,,"Humans; Image Enhancement; Imaging, Three-Dimensional; Neural Networks, Computer",2020-03-10,2020,2020-03-10,2020-06,126,,76-94,Closed,Article,"Baldeon Calisto, Maria; Lai-Yuen, Susana K","Baldeon Calisto, Maria (University of South Florida, 4202 E. Fowler Avenue, Tampa, FL 33620, USA.); Lai-Yuen, Susana K (University of South Florida, 4202 E. Fowler Avenue, Tampa, FL 33620, USA. Electronic address: laiyuen@usf.edu.)",,"Baldeon Calisto, Maria (University of South Florida); Lai-Yuen, Susana K (University of South Florida)",62,58,4.09,26.37,,https://app.dimensions.ai/details/publication/pub.1125498262,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
1173,pub.1125565334,10.48550/arxiv.2003.04492,,,FOAL: Fast Online Adaptive Learning for Cardiac Motion Estimation,"Motion estimation of cardiac MRI videos is crucial for the evaluation of
human heart anatomy and function. Recent researches show promising results with
deep learning-based methods. In clinical deployment, however, they suffer
dramatic performance drops due to mismatched distributions between training and
testing datasets, commonly encountered in the clinical environment. On the
other hand, it is arguably impossible to collect all representative datasets
and to train a universal tracker before deployment. In this context, we
proposed a novel fast online adaptive learning (FOAL) framework: an online
gradient descent based optimizer that is optimized by a meta-learner. The
meta-learner enables the online optimizer to perform a fast and robust
adaptation. We evaluated our method through extensive experiments on two public
clinical datasets. The results showed the superior performance of FOAL in
accuracy compared to the offline-trained tracking method. On average, the FOAL
took only $0.4$ second per video for online optimization.",,,arXiv,,,2020-03-09,2020,,,,,,All OA, Green,Preprint,"Yu, Hanchao; Sun, Shanhui; Yu, Haichao; Chen, Xiao; Shi, Honghui; Huang, Thomas; Chen, Terrence","Yu, Hanchao (); Sun, Shanhui (); Yu, Haichao (); Chen, Xiao (); Shi, Honghui (); Huang, Thomas (); Chen, Terrence ()",,"Yu, Hanchao (); Sun, Shanhui (); Yu, Haichao (); Chen, Xiao (); Shi, Honghui (); Huang, Thomas (); Chen, Terrence ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1125565334,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
2507,pub.1125405270,10.3389/fcvm.2020.00025,32195270,PMC7066212,Deep Learning for Cardiac Image Segmentation: A Review,"Deep learning has become the most widely used approach for cardiac image segmentation in recent years. In this paper, we provide a review of over 100 cardiac image segmentation papers using deep learning, which covers common imaging modalities including magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound and major anatomical structures of interest (ventricles, atria, and vessels). In addition, a summary of publicly available cardiac image datasets and code repositories are included to provide a base for encouraging reproducible research. Finally, we discuss the challenges and limitations with current deep learning-based approaches (scarcity of labels, model generalizability across different domains, interpretability) and suggest potential directions for future research.","We would like to thank our colleagues: Karl Hahn, Qingjie Meng, James Batten, and Jonathan Passerat-Palmbach who provided the insight and expertise that greatly assisted the work, and also constructive and thoughtful comments from Turkay Kart that greatly improved the manuscript.",,Frontiers in Cardiovascular Medicine,,,2020-03-05,2020,2020-03-05,,7,,25,All OA, Gold,Article,"Chen, Chen; Qin, Chen; Qiu, Huaqi; Tarroni, Giacomo; Duan, Jinming; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom); Qin, Chen (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom); Qiu, Huaqi (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom); Tarroni, Giacomo (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; CitAI Research Centre, Department of Computer Science, City University of London, London, United Kingdom); Duan, Jinming (School of Computer Science, University of Birmingham, Birmingham, United Kingdom); Bai, Wenjia (Data Science Institute, Imperial College London, London, United Kingdom; Department of Brain Sciences, Faculty of Medicine, Imperial College London, London, United Kingdom); Rueckert, Daniel (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom)","Chen, Chen (Imperial College London)","Chen, Chen (Imperial College London); Qin, Chen (Imperial College London); Qiu, Huaqi (Imperial College London); Tarroni, Giacomo (Imperial College London; City, University of London); Duan, Jinming (University of Birmingham); Bai, Wenjia (Imperial College London; Imperial College London); Rueckert, Daniel (Imperial College London)",354,315,27.3,229.36,https://www.frontiersin.org/articles/10.3389/fcvm.2020.00025/pdf,https://app.dimensions.ai/details/publication/pub.1125405270,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
6494,pub.1125425797,10.3390/s20051392,32143297,PMC7085718,Semantically Guided Large Deformation Estimation with Deep Networks,"Deformable image registration is still a challenge when the considered images have strong variations in appearance and large initial misalignment. A huge performance gap currently remains for fast-moving regions in videos or strong deformations of natural objects. We present a new semantically guided and two-step deep deformation network that is particularly well suited for the estimation of large deformations. We combine a U-Net architecture that is weakly supervised with segmentation information to extract semantically meaningful features with multiple stages of nonrigid spatial transformer networks parameterized with low-dimensional B-spline deformations. Combining alignment loss and semantic loss functions together with a regularization penalty to obtain smooth and plausible deformations, we achieve superior results in terms of alignment quality compared to previous approaches that have only considered a label-driven alignment loss. Our network model advances the state of the art for inter-subject face part alignment and motion tracking in medical cardiac magnetic resonance imaging (MRI) sequences in comparison to the FlowNet and Label-Reg, two recent deep-learning registration frameworks. The models are compact, very fast in inference, and demonstrate clear potential for a variety of challenging tracking and/or alignment tasks in computer vision and medical image analysis.",,This research was funded by German research funding organization (DFG) grant number HE7364/1-2.,Sensors,,,2020-03-04,2020,2020-03-04,,20,5,1392,All OA, Gold,Article,"Ha, In Young; Wilms, Matthias; Heinrich, Mattias","Ha, In Young (Institute of medical informatics, University of Luebeck, 23558 Luebeck, Germany;, heinrich@imi.uni-luebeck.de); Wilms, Matthias (Department of Radiology, University of Calgary, Calgary, AB T2N 4N1, Canada;, matthias.wilms@ucalgary.ca); Heinrich, Mattias (Institute of medical informatics, University of Luebeck, 23558 Luebeck, Germany;, heinrich@imi.uni-luebeck.de)","Ha, In Young (University of Lübeck)","Ha, In Young (University of Lübeck); Wilms, Matthias (University of Calgary); Heinrich, Mattias (University of Lübeck)",7,4,0.96,3.75,https://www.mdpi.com/1424-8220/20/5/1392/pdf?version=1583317309,https://app.dimensions.ai/details/publication/pub.1125425797,"46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
358,pub.1125321130,10.1016/s1936-878x(20)30146-7,,PMC7119027,Full Issue PDF,,,,JACC Cardiovascular Imaging,,,2020-03-02,2020,2020-03-02,2020-03,13,3,i-cclviii,All OA, Bronze,Article,,,,,0,0,,0.0,https://doi.org/10.1016/s1936-878x(20)30146-7,https://app.dimensions.ai/details/publication/pub.1125321130,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
1346,pub.1125331271,10.48550/arxiv.2002.12680,,,A Spatiotemporal Volumetric Interpolation Network for 4D Dynamic Medical  Image,"Dynamic medical imaging is usually limited in application due to the large
radiation doses and longer image scanning and reconstruction times. Existing
methods attempt to reduce the dynamic sequence by interpolating the volumes
between the acquired image volumes. However, these methods are limited to
either 2D images and/or are unable to support large variations in the motion
between the image volume sequences. In this paper, we present a spatiotemporal
volumetric interpolation network (SVIN) designed for 4D dynamic medical images.
SVIN introduces dual networks: first is the spatiotemporal motion network that
leverages the 3D convolutional neural network (CNN) for unsupervised parametric
volumetric registration to derive spatiotemporal motion field from two-image
volumes; the second is the sequential volumetric interpolation network, which
uses the derived motion field to interpolate image volumes, together with a new
regression-based module to characterize the periodic motion cycles in
functional organ structures. We also introduce an adaptive multi-scale
architecture to capture the volumetric large anatomy motions. Experimental
results demonstrated that our SVIN outperformed state-of-the-art temporal
medical interpolation methods and natural video interpolation methods that have
been extended to support volumetric images. Our ablation study further
exemplified that our motion network was able to better represent the large
functional motion compared with the state-of-the-art unsupervised medical
registration methods.",,,arXiv,,,2020-02-28,2020,,,,,,All OA, Green,Preprint,"Guo, Yuyu; Bi, Lei; Ahn, Euijoon; Feng, Dagan; Wang, Qian; Kim, Jinman","Guo, Yuyu (); Bi, Lei (); Ahn, Euijoon (); Feng, Dagan (); Wang, Qian (); Kim, Jinman ()",,"Guo, Yuyu (); Bi, Lei (); Ahn, Euijoon (); Feng, Dagan (); Wang, Qian (); Kim, Jinman ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1125331271,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
1398,pub.1124939017,10.48550/arxiv.2002.07089,,,4D Semantic Cardiac Magnetic Resonance Image Synthesis on XCAT  Anatomical Model,"We propose a hybrid controllable image generation method to synthesize
anatomically meaningful 3D+t labeled Cardiac Magnetic Resonance (CMR) images.
Our hybrid method takes the mechanistic 4D eXtended CArdiac Torso (XCAT) heart
model as the anatomical ground truth and synthesizes CMR images via a
data-driven Generative Adversarial Network (GAN). We employ the
state-of-the-art SPatially Adaptive De-normalization (SPADE) technique for
conditional image synthesis to preserve the semantic spatial information of
ground truth anatomy. Using the parameterized motion model of the XCAT heart,
we generate labels for 25 time frames of the heart for one cardiac cycle at 18
locations for the short axis view. Subsequently, realistic images are generated
from these labels, with modality-specific features that are learned from real
CMR image data. We demonstrate that style transfer from another cardiac image
can be accomplished by using a style encoder network. Due to the flexibility of
XCAT in creating new heart models, this approach can result in a realistic
virtual population to address different challenges the medical image analysis
research community is facing such as expensive data collection. Our proposed
method has a great potential to synthesize 4D controllable CMR images with
annotations and adaptable styles to be used in various supervised multi-site,
multi-vendor applications in medical image analysis.",,,arXiv,,,2020-02-17,2020,,,,,,All OA, Green,Preprint,"Abbasi-Sureshjani, Samaneh; Amirrajab, Sina; Lorenz, Cristian; Weese, Juergen; Pluim, Josien; Breeuwer, Marcel","Abbasi-Sureshjani, Samaneh (); Amirrajab, Sina (); Lorenz, Cristian (); Weese, Juergen (); Pluim, Josien (); Breeuwer, Marcel ()",,"Abbasi-Sureshjani, Samaneh (); Amirrajab, Sina (); Lorenz, Cristian (); Weese, Juergen (); Pluim, Josien (); Breeuwer, Marcel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1124939017,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1295,pub.1124834733,10.48550/arxiv.2002.04392,,,How well do U-Net-based segmentation trained on adult cardiac magnetic  resonance imaging data generalise to rare congenital heart diseases for  surgical planning?,"Planning the optimal time of intervention for pulmonary valve replacement
surgery in patients with the congenital heart disease Tetralogy of Fallot (TOF)
is mainly based on ventricular volume and function according to current
guidelines. Both of these two biomarkers are most reliably assessed by
segmentation of 3D cardiac magnetic resonance (CMR) images. In several grand
challenges in the last years, U-Net architectures have shown impressive results
on the provided data. However, in clinical practice, data sets are more diverse
considering individual pathologies and image properties derived from different
scanner properties. Additionally, specific training data for complex rare
diseases like TOF is scarce.
  For this work, 1) we assessed the accuracy gap when using a publicly
available labelled data set (the Automatic Cardiac Diagnosis Challenge (ACDC)
data set) for training and subsequent applying it to CMR data of TOF patients
and vice versa and 2) whether we can achieve similar results when applying the
model to a more heterogeneous data base.
  Multiple deep learning models were trained with four-fold cross validation.
Afterwards they were evaluated on the respective unseen CMR images from the
other collection. Our results confirm that current deep learning models can
achieve excellent results (left ventricle dice of
$0.951\pm{0.003}$/$0.941\pm{0.007}$ train/validation) within a single data
collection. But once they are applied to other pathologies, it becomes apparent
how much they overfit to the training pathologies (dice score drops between
$0.072\pm{0.001}$ for the left and $0.165\pm{0.001}$ for the right ventricle).",,,arXiv,,,2020-02-10,2020,,,,,,All OA, Green,Preprint,"Koehler, Sven; Tandon, Animesh; Hussain, Tarique; Latus, Heiner; Pickardt, Thomas; Sarikouch, Samir; Beerbaum, Philipp; Greil, Gerald; Engelhardt, Sandy; Wolf, Ivo","Koehler, Sven (); Tandon, Animesh (); Hussain, Tarique (); Latus, Heiner (); Pickardt, Thomas (); Sarikouch, Samir (); Beerbaum, Philipp (); Greil, Gerald (); Engelhardt, Sandy (); Wolf, Ivo ()",,"Koehler, Sven (); Tandon, Animesh (); Hussain, Tarique (); Latus, Heiner (); Pickardt, Thomas (); Sarikouch, Samir (); Beerbaum, Philipp (); Greil, Gerald (); Engelhardt, Sandy (); Wolf, Ivo ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1124834733,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,
3938,pub.1124284207,10.3389/fcvm.2020.00001,32039241,PMC6992607,Image-Based Cardiac Diagnosis With Machine Learning: A Review,"Cardiac imaging plays an important role in the diagnosis of cardiovascular disease (CVD). Until now, its role has been limited to visual and quantitative assessment of cardiac structure and function. However, with the advent of big data and machine learning, new opportunities are emerging to build artificial intelligence tools that will directly assist the clinician in the diagnosis of CVDs. This paper presents a thorough review of recent works in this field and provide the reader with a detailed presentation of the machine learning methods that can be further exploited to enable more automated, precise and early diagnosis of most CVDs.",,,Frontiers in Cardiovascular Medicine,,,2020-01-24,2020,2020-01-24,,7,,1,All OA, Gold,Article,"Martin-Isla, Carlos; Campello, Victor M.; Izquierdo, Cristian; Raisi-Estabragh, Zahra; Baeßler, Bettina; Petersen, Steffen E.; Lekadir, Karim","Martin-Isla, Carlos (Departament de Matemàtiques & Informàtica, Universitat de Barcelona, Barcelona, Spain); Campello, Victor M. (Departament de Matemàtiques & Informàtica, Universitat de Barcelona, Barcelona, Spain); Izquierdo, Cristian (Departament de Matemàtiques & Informàtica, Universitat de Barcelona, Barcelona, Spain); Raisi-Estabragh, Zahra (Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom; William Harvey Research Institute, Queen Mary University of London, London, United Kingdom); Baeßler, Bettina (Department of Diagnostic & Interventional Radiology, University Hospital Zurich, Zurich, Switzerland); Petersen, Steffen E. (Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom; William Harvey Research Institute, Queen Mary University of London, London, United Kingdom); Lekadir, Karim (Departament de Matemàtiques & Informàtica, Universitat de Barcelona, Barcelona, Spain)","Martin-Isla, Carlos (University of Barcelona)","Martin-Isla, Carlos (University of Barcelona); Campello, Victor M. (University of Barcelona); Izquierdo, Cristian (University of Barcelona); Raisi-Estabragh, Zahra (St Bartholomew's Hospital; Queen Mary University of London); Baeßler, Bettina (University Hospital of Zurich); Petersen, Steffen E. (St Bartholomew's Hospital; Queen Mary University of London); Lekadir, Karim (University of Barcelona)",96,83,6.3,62.2,https://www.frontiersin.org/articles/10.3389/fcvm.2020.00001/pdf,https://app.dimensions.ai/details/publication/pub.1124284207,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,3 Good Health and Well Being,,,,,,,,,
5331,pub.1124205926,10.3389/fcvm.2019.00195,32039240,PMC6985036,Artificial Intelligence for Cardiac Imaging-Genetics Research,"Cardiovascular conditions remain the leading cause of mortality and morbidity worldwide, with genotype being a significant influence on disease risk. Cardiac imaging-genetics aims to identify and characterize the genetic variants that influence functional, physiological, and anatomical phenotypes derived from cardiovascular imaging. High-throughput DNA sequencing and genotyping have greatly accelerated genetic discovery, making variant interpretation one of the key challenges in contemporary clinical genetics. Heterogeneous, low-fidelity phenotyping and difficulties integrating and then analyzing large-scale genetic, imaging and clinical datasets using traditional statistical approaches have impeded process. Artificial intelligence (AI) methods, such as deep learning, are particularly suited to tackle the challenges of scalability and high dimensionality of data and show promise in the field of cardiac imaging-genetics. Here we review the current state of AI as applied to imaging-genetics research and discuss outstanding methodological challenges, as the field moves from pilot studies to mainstream applications, from one dimensional global descriptors to high-resolution models of whole-organ shape and function, from univariate to multivariate analysis and from candidate gene to genome-wide approaches. Finally, we consider the future directions and prospects of AI imaging-genetics for ultimately helping understand the genetic and environmental underpinnings of cardiovascular health and disease.","The authors would like to thank Drs. Wenjia Bai and Carlo Biffi (Department of Computing, Imperial College London, London, UK) for their critical review of this article.",,Frontiers in Cardiovascular Medicine,,,2020-01-21,2020,2020-01-21,,6,,195,All OA, Gold,Article,"de Marvao, Antonio; Dawes, Timothy J. W.; O'Regan, Declan P.","de Marvao, Antonio (MRC London Institute of Medical Sciences, Imperial College London, London, United Kingdom); Dawes, Timothy J. W. (MRC London Institute of Medical Sciences, Imperial College London, London, United Kingdom); O'Regan, Declan P. (MRC London Institute of Medical Sciences, Imperial College London, London, United Kingdom)","O'Regan, Declan P. (Medical Research Council)","de Marvao, Antonio (Medical Research Council); Dawes, Timothy J. W. (Medical Research Council); O'Regan, Declan P. (Medical Research Council)",15,12,0.71,9.72,https://www.frontiersin.org/articles/10.3389/fcvm.2019.00195/pdf,https://app.dimensions.ai/details/publication/pub.1124205926,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,3 Good Health and Well Being,,,,,,,,,
1213,pub.1124237248,10.48550/arxiv.2001.07645,,,SAUNet: Shape Attentive U-Net for Interpretable Medical Image  Segmentation,"Medical image segmentation is a difficult but important task for many
clinical operations such as cardiac bi-ventricular volume estimation. More
recently, there has been a shift to utilizing deep learning and fully
convolutional neural networks (CNNs) to perform image segmentation that has
yielded state-of-the-art results in many public benchmark datasets. Despite the
progress of deep learning in medical image segmentation, standard CNNs are
still not fully adopted in clinical settings as they lack robustness and
interpretability. Shapes are generally more meaningful features than solely
textures of images, which are features regular CNNs learn, causing a lack of
robustness. Likewise, previous works surrounding model interpretability have
been focused on post hoc gradient-based saliency methods. However,
gradient-based saliency methods typically require additional computations post
hoc and have been shown to be unreliable for interpretability. Thus, we present
a new architecture called Shape Attentive U-Net (SAUNet) which focuses on model
interpretability and robustness. The proposed architecture attempts to address
these limitations by the use of a secondary shape stream that captures rich
shape-dependent information in parallel with the regular texture stream.
Furthermore, we suggest multi-resolution saliency maps can be learned using our
dual-attention decoder module which allows for multi-level interpretability and
mitigates the need for additional computations post hoc. Our method also
achieves state-of-the-art results on the two large public cardiac MRI image
segmentation datasets of SUN09 and AC17.",,,arXiv,,,2020-01-21,2020,,,,,,All OA, Green,Preprint,"Sun, Jesse; Darbehani, Fatemeh; Zaidi, Mark; Wang, Bo","Sun, Jesse (); Darbehani, Fatemeh (); Zaidi, Mark (); Wang, Bo ()",,"Sun, Jesse (); Darbehani, Fatemeh (); Zaidi, Mark (); Wang, Bo ()",1,1,,0.5,,https://app.dimensions.ai/details/publication/pub.1124237248,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1692,pub.1134406092,10.22489/cinc.2020.247,,,Automated Left and Right Chamber Segmentation in Cardiac MRI Using Dense Fully Convolutional Neural Network,"Cardiac magnetic resonance (CMR) represents the gold standard for the diagnosis of cardiovascular diseases. We developed a deep learning approach for the automatic detection and segmentation of left and right ventricles and myocardium (Myo) on short-axis cine CMR images, including all clinically relevant slices. A dataset of 210 studies (3 pathology groups) was considered: Images were acquired and manually segmented (gold standard, GS) at Centro Cardiologico Monzino (Milan, Italy). Automatic segmentation was performed with a U-Net inspired architecture were two loss function were used: weighted cross entropy (WCE) and its combination with the Dice loss function (WCE+Dice). Two experiments were conducted: A) all the slices were included; ii) slices where the Myo did not completely surrounded the LV were removed. To evaluate the clinical relevance of our approach, the predicted segmentation was reviewed and corrected by an expert physician. The two loss function performed similarly, with slightly better results for WCE, resulting in a strong correlation with the manually-adjusted segmentation.",,,2016 Computing in Cardiology Conference (CinC),2020 Computing in Cardiology Conference (CinC),,2020-01-16,2020,2020-12-30,2020-01-16,0,,1-4,All OA, Bronze,Proceeding,"Penso, Marco; Moccia, Sara; Scafuri, Stefano; Muscogiuri, Giuseppe; Pontone, Gianluca; Pepi, Mauro; Caiani, Enrico Gianluca","Penso, Marco (Clinical Cardiology Unit and Department of Cardiovascular Imaging, Centro Cardiologico Monzino, IRCCS, Milan, Italy); Moccia, Sara (Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy); Scafuri, Stefano (Clinical Cardiology Unit and Department of Cardiovascular Imaging, Centro Cardiologico Monzino, IRCCS, Milan, Italy); Muscogiuri, Giuseppe (Clinical Cardiology Unit and Department of Cardiovascular Imaging, Centro Cardiologico Monzino, IRCCS, Milan, Italy); Pontone, Gianluca (Clinical Cardiology Unit and Department of Cardiovascular Imaging, Centro Cardiologico Monzino, IRCCS, Milan, Italy); Pepi, Mauro (Clinical Cardiology Unit and Department of Cardiovascular Imaging, Centro Cardiologico Monzino, IRCCS, Milan, Italy); Caiani, Enrico Gianluca (Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; National Council of Research (CNR) IEIIT, Milan, Italy)","Caiani, Enrico Gianluca (Politecnico di Milano; )","Penso, Marco (Centro Cardiologico Monzino); Moccia, Sara (Marche Polytechnic University; Italian Institute of Technology); Scafuri, Stefano (Centro Cardiologico Monzino); Muscogiuri, Giuseppe (Centro Cardiologico Monzino); Pontone, Gianluca (Centro Cardiologico Monzino); Pepi, Mauro (Centro Cardiologico Monzino); Caiani, Enrico Gianluca (Politecnico di Milano)",1,1,,0.49,https://doi.org/10.22489/cinc.2020.247,https://app.dimensions.ai/details/publication/pub.1134406092,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 51 Physical Sciences,,,,,,,,,
3777,pub.1124032955,10.1016/j.media.2020.101636,31972427,,Improving cardiac MRI convolutional neural network segmentation on small training datasets and dataset shift: A continuous kernel cut approach,"Cardiac magnetic resonance imaging (MRI) provides a wealth of imaging biomarkers for cardiovascular disease care and segmentation of cardiac structures is required as a first step in enumerating these biomarkers. Deep convolutional neural networks (CNNs) have demonstrated remarkable success in image segmentation but typically require large training datasets and provide suboptimal results that require further improvements. Here, we developed a way to enhance cardiac MRI multi-class segmentation by combining the strengths of CNN and interpretable machine learning algorithms. We developed a continuous kernel cut segmentation algorithm by integrating normalized cuts and continuous regularization in a unified framework. The high-order formulation was solved through upper bound relaxation and a continuous max-flow algorithm in an iterative manner using CNN predictions as inputs. We applied our approach to two representative cardiac MRI datasets across a wide range of cardiovascular pathologies. We comprehensively evaluated the performance of our approach for two CNNs trained with various small numbers of training cases, tested on the same and different datasets. Experimental results showed that our approach improved baseline CNN segmentation by a large margin, reduced CNN segmentation variability substantially, and achieved excellent segmentation accuracy with minimal extra computational cost. These results suggest that our approach provides a way to enhance the applicability of CNN by enabling the use of smaller training datasets and improving the segmentation accuracy and reproducibility for cardiac MRI segmentation in research and clinical patient care.","We acknowledge the use of the facilities of the Shared Hierarchical Academic Research Computing Network and Compute Canada. We thank Meng Tang and Dr. Yuri Boykov for fruitful discussions and inputs in this work. This work was funded by Canadian Institutes of Health Research (CIHR) MOP: #93531, Ontario Research Fund and GE Healthcare. FG is supported by a postdoctoral fellowship from Natural Sciences and Engineering Research Council of Canada (NSERC-PDF). SEP, SN and SKP acknowledge the British Heart Foundation for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5000 CMR scans (www.bhf.org.uk;PG/14/89/31194). SEP acknowledges support from the National Institute for Health Research (NIHR) Cardiovascular Biomedical Research Centre at Barts and from the ”SmartHeart” EPSRC programme grant (www.nihr.ac.uk; EP/P001009/1). SN and SKP are supported by the Oxford NIHR Biomedical Research Centre and the Oxford British Heart Foundation Centre of Research Excellence. This project was enabled through access to the MRC eMedLab Medical Bioinformatics infrastructure, supported by the Medical Research Council (www.mrc.ac.uk; MR/L016311/1).",,Medical Image Analysis,,"Cardiovascular Diseases; Datasets as Topic; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Reproducibility of Results",2020-01-11,2020,2020-01-11,2020-04,61,,101636,All OA, Green,Article,"Guo, Fumin; Ng, Matthew; Goubran, Maged; Petersen, Steffen E; Piechnik, Stefan K; Neubauer, Stefan; Wright, Graham","Guo, Fumin (Sunnybrook Research Institute, University of Toronto, Toronto M4N 3M5, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada. Electronic address: fumin.guo@sri.utoronto.ca.); Ng, Matthew (Sunnybrook Research Institute, University of Toronto, Toronto M4N 3M5, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada.); Goubran, Maged (Sunnybrook Research Institute, University of Toronto, Toronto M4N 3M5, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada.); Petersen, Steffen E (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK.); Piechnik, Stefan K (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK.); Neubauer, Stefan (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK.); Wright, Graham (Sunnybrook Research Institute, University of Toronto, Toronto M4N 3M5, Canada; Department of Medical Biophysics, University of Toronto, Toronto, Canada.)","Guo, Fumin (University of Toronto)","Guo, Fumin (University of Toronto); Ng, Matthew (University of Toronto); Goubran, Maged (University of Toronto); Petersen, Steffen E (Queen Mary University of London); Piechnik, Stefan K (University of Oxford); Neubauer, Stefan (University of Oxford); Wright, Graham (University of Toronto)",36,30,3.24,,https://qmro.qmul.ac.uk/xmlui/bitstream/123456789/62245/4/Petersen_Improving%20Cardiac%20MRI%20Convolutional%20Neural_2019_Accepted.pdf,https://app.dimensions.ai/details/publication/pub.1124032955,32 Biomedical and Clinical Sciences, 40 Engineering,3 Good Health and Well Being,,,,,,,,,
5668,pub.1123956774,10.3389/fcvm.2019.00190,31998756,PMC6962100,Machine Learning Approaches for Myocardial Motion and Deformation Analysis,"Information about myocardial motion and deformation is key to differentiate normal and abnormal conditions. With the advent of approaches relying on data rather than pre-conceived models, machine learning could either improve the robustness of motion quantification or reveal patterns of motion and deformation (rather than single parameters) that differentiate pathologies. We review machine learning strategies for extracting motion-related descriptors and analyzing such features among populations, keeping in mind constraints specific to the cardiac application.","The articles discussed in this review were selected by querying PubMed over the last 10 years with the terms (myocardial [OR] cardiac) [AND] learning [AND] (motion [OR] deformation), complemented by the authors&#x27; knowledge, and examining the publication profile of the authors of the already selected articles. Papers not using spatial or temporal motion or deformation patterns but single measurements such as peak values or timings, and papers addressing cardiac respiratory motion were removed from this selection, although we acknowledge their importance for the more complete analysis of cardiac function.",,Frontiers in Cardiovascular Medicine,,,2020-01-09,2020,2020-01-09,,6,,190,All OA, Gold,Article,"Duchateau, Nicolas; King, Andrew P.; De Craene, Mathieu","Duchateau, Nicolas (CREATIS, CNRS UMR 5220, INSERM U1206, Université, Lyon, France); King, Andrew P. (School of Biomedical Engineering and Imaging Sciences, King's College London, London, United Kingdom); De Craene, Mathieu (Philips Research Paris, Suresnes, France)","Duchateau, Nicolas (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé)","Duchateau, Nicolas (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé); King, Andrew P. (King's College London); De Craene, Mathieu ()",13,11,1.42,8.42,https://www.frontiersin.org/articles/10.3389/fcvm.2019.00190/pdf,https://app.dimensions.ai/details/publication/pub.1123956774,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
1619,pub.1123958994,10.48550/arxiv.2001.02387,,,A context based deep learning approach for unbalanced medical image  segmentation,"Automated medical image segmentation is an important step in many medical
procedures. Recently, deep learning networks have been widely used for various
medical image segmentation tasks, with U-Net and generative adversarial nets
(GANs) being some of the commonly used ones. Foreground-background class
imbalance is a common occurrence in medical images, and U-Net has difficulty in
handling class imbalance because of its cross entropy (CE) objective function.
Similarly, GAN also suffers from class imbalance because the discriminator
looks at the entire image to classify it as real or fake. Since the
discriminator is essentially a deep learning classifier, it is incapable of
correctly identifying minor changes in small structures. To address these
issues, we propose a novel context based CE loss function for U-Net, and a
novel architecture Seg-GLGAN. The context based CE is a linear combination of
CE obtained over the entire image and its region of interest (ROI). In
Seg-GLGAN, we introduce a novel context discriminator to which the entire image
and its ROI are fed as input, thus enforcing local context. We conduct
extensive experiments using two challenging unbalanced datasets: PROMISE12 and
ACDC. We observe that segmentation results obtained from our methods give
better segmentation metrics as compared to various baseline methods.",,,arXiv,,,2020-01-08,2020,,,,,,All OA, Green,Preprint,"Murugesan, Balamurali; Sarveswaran, Kaushik; S, Vijaya Raghavan; Shankaranarayana, Sharath M; Ram, Keerthi; Sivaprakasam, Mohanasankar","Murugesan, Balamurali (); Sarveswaran, Kaushik (); S, Vijaya Raghavan (); Shankaranarayana, Sharath M (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",,"Murugesan, Balamurali (); Sarveswaran, Kaushik (); S, Vijaya Raghavan (); Shankaranarayana, Sharath M (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1123958994,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5054,pub.1123835529,10.1109/tmi.2020.2964499,31944949,PMC7269693,Explainable Anatomical Shape Analysis Through Deep Hierarchical Generative Models,"Quantification of anatomical shape changes currently relies on scalar global indexes which are largely insensitive to regional or asymmetric modifications. Accurate assessment of pathology-driven anatomical remodeling is a crucial step for the diagnosis and treatment of many conditions. Deep learning approaches have recently achieved wide success in the analysis of medical images, but they lack interpretability in the feature extraction and decision processes. In this work, we propose a new interpretable deep learning model for shape analysis. In particular, we exploit deep generative networks to model a population of anatomical segmentations through a hierarchy of conditional latent variables. At the highest level of this hierarchy, a two-dimensional latent space is simultaneously optimised to discriminate distinct clinical conditions, enabling the direct visualisation of the classification space. Moreover, the anatomical variability encoded by this discriminative latent space can be visualised in the segmentation space thanks to the generative properties of the model, making the classification task transparent. This approach yielded high accuracy in the categorisation of healthy and remodelled left ventricles when tested on unseen segmentations from our own multi-centre dataset as well as in an external validation set, and on hippocampi from healthy controls and patients with Alzheimer's disease when tested on ADNI data. More importantly, it enabled the visualisation in three-dimensions of both global and regional anatomical features which better discriminate between the conditions under exam. The proposed approach scales effectively to large populations, facilitating high-throughput analysis of normal anatomy and pathology in large-scale studies of volumetric imaging.","This work was supported in part by the British Heart Foundation under Grant NH/17/1/32725 and Grant RE/13/4/30184, in part by the Academy of Medical Sciences under Grant SGL015/1006, and in part by the National Institute for Health Research Biomedical Research Centre based at Imperial College Healthcare NHS Trust and Imperial College London.",,IEEE Transactions on Medical Imaging,,Alzheimer Disease, Hippocampus, Humans, Magnetic Resonance Imaging,2020-01-06,2020,2020-01-06,2020-06,39,6,2088-2099,All OA, Green,Article,"Biffi, Carlo; Cerrolaza, Juan J.; Tarroni, Giacomo; Bai, Wenjia; de Marvao, Antonio; Oktay, Ozan; Ledig, Christian; Le Folgoc, Loic; Kamnitsas, Konstantinos; Doumou, Georgia; Duan, Jinming; Prasad, Sanjay K.; Cook, Stuart A.; O’Regan, Declan P.; Rueckert, Daniel","Biffi, Carlo (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Cerrolaza, Juan J. (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Tarroni, Giacomo (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Bai, Wenjia (Department of Computing, Imperial College London, London, SW7 2RH, U.K); de Marvao, Antonio (Faculty of Medicine, MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Oktay, Ozan (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Ledig, Christian (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Le Folgoc, Loic (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Kamnitsas, Konstantinos (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Doumou, Georgia (Faculty of Medicine, MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Duan, Jinming (Department of Computing, Imperial College London, London, SW7 2RH, U.K); Prasad, Sanjay K. (National Heart and Lung Institute, Imperial College London, London, SW3 6LY, U.K); Cook, Stuart A. (Faculty of Medicine, MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); O’Regan, Declan P. (Faculty of Medicine, MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Rueckert, Daniel (Department of Computing, Imperial College London, London, SW7 2RH, U.K)","Biffi, Carlo (Imperial College London)","Biffi, Carlo (Imperial College London); Cerrolaza, Juan J. (Imperial College London); Tarroni, Giacomo (Imperial College London); Bai, Wenjia (Imperial College London); de Marvao, Antonio (Medical Research Council); Oktay, Ozan (Imperial College London); Ledig, Christian (Imperial College London); Le Folgoc, Loic (Imperial College London); Kamnitsas, Konstantinos (Imperial College London); Doumou, Georgia (Medical Research Council); Duan, Jinming (Imperial College London); Prasad, Sanjay K. (Imperial College London); Cook, Stuart A. (Medical Research Council); O’Regan, Declan P. (Medical Research Council); Rueckert, Daniel (Imperial College London)",25,19,1.96,12.88,http://spiral.imperial.ac.uk/bitstream/10044/1/77445/2/1907.00058v2.pdf,https://app.dimensions.ai/details/publication/pub.1123835529,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,
1652,pub.1124013776,10.1117/12.2542580,,,Automatic segmentation of the left ventricle myocardium by a multi-view deformable model,"Nowadays magnetic resonance images (MRI) are being used to calculate important clinical parameters such as ejection fraction (EF), left ventricle myocardium mass (MM), and stroke volume (SV) which are crucial to estimate the cardiac function, surgical planning and create patient-specific heart models, therefore for quantifying accurately these parameters it is also necessary a good delimitation of cardiac structures. The proposed approach presents an automatic segmentation of the left ventricle (LV) and basically is composed by three steps: first, heart structure localization with template matching technique in coronal and sagittal view that is used to restrict axial analysis. Second, ellipsoidal approximation using the axial projection of previous coarse segmentation. Third, a conventional snake algorithm is performed to refine external myocardium boundaries in axial view. The strategy was evaluated using 100 cardiac MRI volumes provided by the ACDC 2017 MICCAI challenge which is composed of 4 different heart diseases, the strategy had an average Dice Score of 0.79.",,,Proceedings of SPIE,15th International Symposium on Medical Information Processing and Analysis,,2020-01-03,2020,2020-01-03,,11330,,113301a-113301a-8,Closed,Proceeding,"Beltran, Miguel A.; Atehortúa, Angélica; Romero, Eduardo","Beltran, Miguel A. (Univ. Nacional de Colombia (Colombia)); Atehortúa, Angélica (Univ. Nacional de Colombia (Colombia)); Romero, Eduardo (Univ. Nacional de Colombia (Colombia))",,"Beltran, Miguel A. (National University of Colombia); Atehortúa, Angélica (National University of Colombia); Romero, Eduardo (National University of Colombia)",1,1,,0.24,,https://app.dimensions.ai/details/publication/pub.1124013776,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
1620,pub.1124013778,10.1117/12.2542584,,,A deblurring model for super-resolution MRI interpolated images,"In the up-sampling process may occur effects like aliasing, blurring or noise addition which mainly affect the edges of the images. For those reasons is necessary to choose a method that preserves images quality so that these problems are minimized. In this paper, we present an alternative method to restore blurred images using linear programming to solve a minimization problem stated in the L1 norm. The model requires the blurred image and some prior knowledge about the blurring function type (Point spread function). In the proposed method we obtain a PSNR of 30 dB overcoming a classic bi-linear method by 4 dB in a set of thirty images from a cardiac MRI data set.",,,Proceedings of SPIE,15th International Symposium on Medical Information Processing and Analysis,,2020-01-03,2020,2020-01-03,,11330,,113300q-113300q-9,Closed,Proceeding,"Fuentes, José; Ruiz, Jorge Mauricio","Fuentes, José (Univ. Nacional de Colombia (Colombia)); Ruiz, Jorge Mauricio (Univ. Nacional de Colombia (Colombia))",,"Fuentes, José (National University of Colombia); Ruiz, Jorge Mauricio (National University of Colombia)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1124013778,40 Engineering, 4006 Communications Engineering,,,,,,,,,,,
1303,pub.1127297332,10.1109/access.2020.2991424,,,Residual Convolutional Neural Network for Cardiac Image Segmentation and Heart Disease Diagnosis,"Deep learning (DL) has been widely used in biomedical image segmentation and automatic disease diagnosis, leading to state-of-the-art performance. However, automated cardiac disease diagnosis heavily relies on cardiac segmentation maps from cardiac magnetic resonance (CMR), most current DL segmentation methods, such as 2D convolution on planes, 3D convolution, are not fully applicable to CMR due to loss of spatial structure information or large gap between slices. To make better exploit spatial aspects of the CMR data to improve cardiac segmentation accuracy, we propose a new DL segmentation structure, which consists of a residual convolution neural network for compressing the intra-slice information, and a bidirectional-convolutional long short term memory (Bi-CLSTM) for leveraging the inter-slice contexts. Moreover, automatic disease diagnosis has been conducted using the segmentation maps. Experimental results of the automatic cardiac diagnosis challenge (ACDC) show that our cardiac segmentation structure and disease diagnosis methods have achieved promising results and it can be widely extended to computer-aided diagnosis.","This work was supported in part by the National Natural Science Foundation of China under Grant 61472042 and Grant 61802020, in part by the Beijing Natural Science Foundation under Grant 4174094, and in part by the Fundamental Research Funds for the Central Universities under Grant 2015KJJCB25.",,IEEE Access,,,2020-01-01,2020,2020-04-30,2020-01-01,8,,82153-82161,All OA, Gold,Article,"Liu, Tao; Tian, Yun; Zhao, Shifeng; Huang, Xiaoying; Wang, Qingjun","Liu, Tao (College of Artificial Intelligence, Beijing Normal University, Beijing, 100875, China); Tian, Yun (College of Artificial Intelligence, Beijing Normal University, Beijing, 100875, China); Zhao, Shifeng (College of Artificial Intelligence, Beijing Normal University, Beijing, 100875, China); Huang, Xiaoying (College of Artificial Intelligence, Beijing Normal University, Beijing, 100875, China); Wang, Qingjun (Sixth Medical Center, Chinese PLA General Hospital, Beijing, 100048, China)","Liu, Tao (Beijing Normal University)","Liu, Tao (Beijing Normal University); Tian, Yun (Beijing Normal University); Zhao, Shifeng (Beijing Normal University); Huang, Xiaoying (Beijing Normal University); Wang, Qingjun (Chinese PLA General Hospital)",17,17,,4.14,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09082648.pdf,https://app.dimensions.ai/details/publication/pub.1127297332,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1134,pub.1124876155,10.1109/access.2020.2974101,,,Feature Extraction and Analysis of Natural Language Processing for Deep Learning English Language,"NLP (Natural Language Processing) is a technology that enables computers to understand human languages. Deep-level grammatical and semantic analysis usually uses words as the basic unit, and word segmentation is usually the primary task of NLP. In order to solve the practical problem of huge structural differences between different data modalities in a multi-modal environment and traditional machine learning methods cannot be directly applied, this paper introduces the feature extraction method of deep learning and applies the ideas of deep learning to multi-modal feature extraction. This paper proposes a multi-modal neural network. For each mode, there is a multilayer sub-neural network with an independent structure corresponding to it. It is used to convert the features in different modes to the same-modal features. In terms of word segmentation processing, in view of the problems that existing word segmentation methods can hardly guarantee long-term dependency of text semantics and long training prediction time, a hybrid network English word segmentation processing method is proposed. This method applies BI-GRU (Bidirectional Gated Recurrent Unit) to English word segmentation, and uses the CRF (Conditional Random Field) model to annotate sentences in sequence, effectively solving the long-distance dependency of text semantics, shortening network training and predicted time. Experiments show that the processing effect of this method on word segmentation is similar to that of BI-LSTM-CRF (Bidirectional- Long Short Term Memory-Conditional Random Field) model, but the average predicted processing speed is 1.94 times that of BI-LSTM-CRF, effectively improving the efficiency of word segmentation processing.",,,IEEE Access,,,2020-01-01,2020,2020-02-14,2020-01-01,8,,46335-46345,All OA, Gold,Article,"Wang, Dongyang; Su, Junli; Yu, Hongbin","Wang, Dongyang (College of Education, Arts and Science, Lyceum of the Philippines University, Batangas City, 4200, Philippines); Su, Junli (Department of Elementary Education, Jiaozuo Teachers College, Jiaozuo, 454002, China); Yu, Hongbin (School of Digital Media, Jiangnan University, Wuxi, 214122, China)","Wang, Dongyang (Lyceum of the Philippines University)","Wang, Dongyang (Lyceum of the Philippines University); Su, Junli (); Yu, Hongbin (Jiangnan University)",43,42,,20.65,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08999624.pdf,https://app.dimensions.ai/details/publication/pub.1124876155,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,
958,pub.1131143377,10.1109/access.2020.3026073,,,Bridge Segmentation Performance Gap Via Evolving Shape Prior,"Deep neural networks are very compelling for medical image segmentation. However, deep models often suffer from notable performance drops in real clinical settings due to the complex appearance shift in daily scannings. Domain adaptation partially addresses the problem between imaging domains. However, it heavily depends on the expensive re-collection and re-training for domain-specific datasets and thus is not applicable to domain-agnostic images. In this paper, we propose a case adaptation strategy aiming to bridge the segmentation performance gap on domain-agnostic images. Our contribution is three-fold. First, we design a general self-supervised learning framework for case adaptation, which exploits its predictions as supervision to drive the adaptation. Without extra annotations and any burden on model complexity, the framework enables trained deep models at-hand to directly segment domain-agnostic testing images. Second, we propose a novel Evolving Shape Prior (ESP) which recursively introduces strong shape knowledge into networks and evolves with the adaptation procedure to provide adaptive supervision. ESP can stabilize self-supervised learning and guide it to move towards model convergence. Third, we perform extensive experiments on 10 datasets with different levels of difficulty and typical appearance shifts blended, proving our framework is a promising solution in reducing segmentation performance degradation. Through this work, we investigate the feasibility of case adaptation as a general strategy in enhancing the robustness of deep segmentation networks, with comprehensive analyses proving its efficacy and efficiency.","This work was supported in part by the National Key Research and Development Program of China under Grant 2019YFC0118300, in part by the Shenzhen Peacock Plan under Grant KQTD2016053112051497 and Grant KQJSCX20180328095606003, in part by the Natural Science Foundation of China under Grant 61801296, and in part by the Shenzhen Basic Research under Grant JCYJ20190808115419619. (Chaoyu Chen and Xin Yang contributed equally to this work.)",,IEEE Access,,,2020-01-01,2020,2020-09-23,2020-01-01,8,,173961-173973,All OA, Gold,Article,"Chen, Chaoyu; Yang, Xin; Dou, Haoran; Huang, Ruobing; Huang, Xiaoqiong; Wang, Xu; Duan, Chong; Li, Shengli; Xue, Wufeng; Heng, Pheng Ann; Ni, Dong","Chen, Chaoyu (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China); Yang, Xin (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China); Dou, Haoran (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China); Huang, Ruobing (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China); Huang, Xiaoqiong (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China); Wang, Xu (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China); Duan, Chong (Department of Early Clinical Development, Pfizer Inc., Cambridge, MA, 02130, USA); Li, Shengli (Department of Ultrasound, Affiliated Shenzhen Maternal and Child Healthcare Hospital, Nanfang Medical University, Guangzhou, China); Xue, Wufeng (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China); Heng, Pheng Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong); Ni, Dong (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Health Science Center, School of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, 518060, China)","Ni, Dong (Shenzhen University; Shenzhen University)","Chen, Chaoyu (Shenzhen University; Shenzhen University); Yang, Xin (Shenzhen University; Shenzhen University); Dou, Haoran (Shenzhen University; Shenzhen University); Huang, Ruobing (Shenzhen University; Shenzhen University); Huang, Xiaoqiong (Shenzhen University; Shenzhen University); Wang, Xu (Shenzhen University; Shenzhen University); Duan, Chong (Pfizer (United States)); Li, Shengli (Southern Medical University); Xue, Wufeng (Shenzhen University; Shenzhen University); Heng, Pheng Ann (Chinese University of Hong Kong); Ni, Dong (Shenzhen University; Shenzhen University)",0,0,,0.0,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09204618.pdf,https://app.dimensions.ai/details/publication/pub.1131143377,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1133,pub.1122096687,10.1016/b978-0-12-816176-0.00017-x,,,"Chapter 12 Deformable models, sparsity and learning-based segmentation for cardiac MRI based analytics","The computational modeling and analysis of cardiac wall motion is a critical step to understand cardiac function and a valuable tool for improved diagnosis of cardiovascular diseases. Although many methods have been developed for cardiac segmentation and wall motion modeling, there are still many unresolved challenges. In this chapter, first we review related techniques for cardiac segmentation and modeling from medical images, mostly CMR. Then, we present a new deep learning method to handle segmentation of multiple structures in cine CMR data. Particularly, we propose a modified deep layer aggregation architecture with channel attention and refinement residual blocks to better fuse appearance information across layers during training and achieve improved results through multiscale analysis of image appearance. The proposed method shows promising results compared to the state-of-the-art approaches for multiple cardiac structures (left ventricle cavity and myocardium, and right ventricle cavity) segmentation in cine CMR data. We also present the methodology for shape refinement and 3D cardiac motion modeling. The shape refinement is achieved by adopting sparse shape composition. Finally, we discuss future research directions and applications of cardiac analytics.",,,,Handbook of Medical Image Computing and Computer Assisted Intervention,,2020,2020,,2020,,,273-292,Closed,Chapter,"Metaxas, Dimitris N.; Yan, Zhennan","Metaxas, Dimitris N. (Rutgers University, Department of Computer Science, Piscataway, NJ, United States); Yan, Zhennan (SenseBrain, Princeton, NJ, United States)",,"Metaxas, Dimitris N. (Rutgers, The State University of New Jersey); Yan, Zhennan ()",6,5,,3.64,,https://app.dimensions.ai/details/publication/pub.1122096687,"40 Engineering; 46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,,
267,pub.1128304273,10.1007/978-3-030-50120-4,,,"Biomedical Image Registration, 9th International Workshop, WBIR 2020, Portorož, Slovenia, December 1–2, 2020, Proceedings","This book constitutes the refereed proceedings of the 9th International Workshop on Biomedical Image Registration, WBIR 2020, which was supposed to be held in Portorož, Slovenia, in June 2020. The conference was postponed until December 2020 due to the COVID-19 pandemic. The 16 full and poster papers included in this volume were carefully reviewed and selected from 22 submitted papers. The papers are organized in the following topical sections: Registration initialization and acceleration, interventional registration, landmark based registration, multi-channel registration, and sliding motion.",,,Lecture Notes in Computer Science,,,2020,2020,,2020,12120,,,All OA, Green,Edited Book,,,,,1,1,,,https://link.springer.com/content/pdf/bfm%3A978-3-030-50120-4%2F1,https://app.dimensions.ai/details/publication/pub.1128304273,46 Information and Computing Sciences,,,,,,,,,,,
227,pub.1131097017,10.1007/978-3-030-59520-3,,,"Simulation and Synthesis in Medical Imaging, 5th International Workshop, SASHIMI 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Proceedings","This book constitutes the refereed proceedings of the 5th International Workshop on Simulation and Synthesis in Medical Imaging, SASHIMI 2020, held in conjunction with MICCAI 2020, in Lima, Peru, in October 2020. The 19 full papers presented were carefully reviewed and selected from 27 submissions. The contributions span the following broad categories in alignment with the initial call-for-papers: methods based on generative models or adversarial learning for MRI/CT/PET/microscopy image synthesis, and several applications of image synthesis and simulation for data augmentation, image enhancement or segmentation.",,,Lecture Notes in Computer Science,,,2020,2020,,2020,12417,,,All OA, Green,Edited Book,,,,,2,2,,,https://link.springer.com/content/pdf/bfm%3A978-3-030-59520-3%2F1,https://app.dimensions.ai/details/publication/pub.1131097017,46 Information and Computing Sciences,,,,,,,,,,,
68,pub.1128583396,10.1007/978-3-030-50417-5,,,"Computational Science – ICCS 2020, 20th International Conference, Amsterdam, The Netherlands, June 3–5, 2020, Proceedings, Part II","The seven-volume set LNCS 12137, 12138, 12139, 12140, 12141, 12142, and 12143 constitutes the proceedings of the 20th International Conference on Computational Science, ICCS 2020, held in Amsterdam, The Netherlands, in June 2020.* The total of 101 papers and 248 workshop papers presented in this book set were carefully reviewed and selected from 719 submissions (230 submissions to the main track and 489 submissions to the workshops). The papers were organized in topical sections named: Part I: ICCS Main Track Part II: ICCS Main Track Part III: Advances in High-Performance Computational Earth Sciences: Applications and Frameworks; Agent-Based Simulations, Adaptive Algorithms and Solvers; Applications of Computational Methods in Artificial Intelligence and Machine Learning; Biomedical and Bioinformatics Challenges for Computer Science Part IV: Classifier Learning from Difficult Data; Complex Social Systems through the Lens of Computational Science; Computational Health; Computational Methods for Emerging Problems in (Dis-)Information Analysis Part V: Computational Optimization, Modelling and Simulation; Computational Science in IoT and Smart Systems; Computer Graphics, Image Processing and Artificial Intelligence Part VI: Data Driven Computational Sciences; Machine Learning and Data Assimilation for Dynamical Systems; Meshfree Methods in Computational Sciences; Multiscale Modelling and Simulation; Quantum Computing Workshop Part VII: Simulations of Flow and Transport: Modeling, Algorithms and Computation; Smart Systems: Bringing Together Computer Vision, Sensor Networks and Machine Learning; Software Engineering for Computational Science; Solving Problems with Uncertainties; Teaching Computational Science; UNcErtainty QUantIficatiOn for ComputationAl modeLs *The conference was canceled due to the COVID-19 pandemic.",,,Lecture Notes in Computer Science,,,2020,2020,,2020,12138,,,All OA, Green,Edited Book,,,,,0,0,,0.0,https://link.springer.com/content/pdf/bfm:978-3-030-50417-5/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1128583396,46 Information and Computing Sciences, 4602 Artificial Intelligence,,,,,,,,,,
55,pub.1131399582,10.1007/978-3-030-59719-1,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2020, 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part IV","The seven-volume set LNCS 12261, 12262, 12263, 12264, 12265, 12266, and 12267 constitutes the refereed proceedings of the 23rd International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2020, held in Lima, Peru, in October 2020. The conference was held virtually due to the COVID-19 pandemic. The 542 revised full papers presented were carefully reviewed and selected from 1809 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: machine learning methodologies Part II: image reconstruction; prediction and diagnosis; cross-domain methods and reconstruction; domain adaptation; machine learning applications; generative adversarial networks Part III: CAI applications; image registration; instrumentation and surgical phase detection; navigation and visualization; ultrasound imaging; video image analysis Part IV: segmentation; shape models and landmark detection Part V: biological, optical, microscopic imaging; cell segmentation and stain normalization; histopathology image analysis; opthalmology Part VI: angiography and vessel analysis; breast imaging; colonoscopy; dermatology; fetal imaging; heart and lung imaging; musculoskeletal imaging Part VI: brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; positron emission tomography",,,Lecture Notes in Computer Science,,,2020,2020,,2020,12264,,,All OA, Green,Edited Book,,,,,6,6,,3.09,https://link.springer.com/content/pdf/bfm:978-3-030-59719-1/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1131399582,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
55,pub.1130568679,10.1007/978-3-030-55789-8,,,"Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices, 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, Kitakyushu, Japan, September 22-25, 2020, Proceedings","This book constitutes the thoroughly refereed proceedings of the 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, held in Kitakyushu, Japan, in September 2020. The 62 full papers and 17 short papers presented were carefully reviewed and selected from 119 submissions. The IEA/AIE 2020 conference will continue the tradition of emphasizing on applications of applied intelligent systems to solve real-life problems in all areas. These areas include are language processing; robotics and drones; knowledge based systems; innovative applications of intelligent systems; industrial applications; networking applications; social network analysis; financial applications and blockchain; medical and health-related applications; anomaly detection and automated diagnosis; decision-support and agent-based systems; multimedia applications; machine learning; data management and data clustering; pattern mining; system control, classification, and fault diagnosis.",,,Lecture Notes in Computer Science,,,2020,2020,,2020,12144,,,All OA, Green,Edited Book,,,,,2,2,,0.93,https://link.springer.com/content/pdf/bfm:978-3-030-55789-8/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1130568679,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science,,,,,,,,,
4046,pub.1123690433,10.1016/j.media.2019.101630,31927474,PMC8260095,Multi-modal latent space inducing ensemble SVM classifier for early dementia diagnosis with neuroimaging data,"Fusing multi-modality data is crucial for accurate identification of brain disorder as different modalities can provide complementary perspectives of complex neurodegenerative disease. However, there are at least four common issues associated with the existing fusion methods. First, many existing fusion methods simply concatenate features from each modality without considering the correlations among different modalities. Second, most existing methods often make prediction based on a single classifier, which might not be able to address the heterogeneity of the Alzheimer's disease (AD) progression. Third, many existing methods often employ feature selection (or reduction) and classifier training in two independent steps, without considering the fact that the two pipelined steps are highly related to each other. Forth, there are missing neuroimaging data for some of the participants (e.g., missing PET data), due to the participants' ""no-show"" or dropout. In this paper, to address the above issues, we propose an early AD diagnosis framework via novel multi-modality latent space inducing ensemble SVM classifier. Specifically, we first project the neuroimaging data from different modalities into a latent space, and then map the learned latent representations into the label space to learn multiple diversified classifiers. Finally, we obtain the more reliable classification results by using an ensemble strategy. More importantly, we present a Complete Multi-modality Latent Space (CMLS) learning model for complete multi-modality data and also an Incomplete Multi-modality Latent Space (IMLS) learning model for incomplete multi-modality data. Extensive experiments using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset have demonstrated that our proposed models outperform other state-of-the-art methods.",This research was supported in part by NIH grant (No. AG041721).,,Medical Image Analysis,,"Aged; Alzheimer Disease; Datasets as Topic; Early Diagnosis; Female; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Neuroimaging; Pattern Recognition, Automated; Positron-Emission Tomography",2019-12-28,2019,2019-12-28,2020-02,60,,101630,All OA, Green,Article,"Zhou, Tao; Thung, Kim-Han; Liu, Mingxia; Shi, Feng; Zhang, Changqing; Shen, Dinggang","Zhou, Tao (Department of Radiology and Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, NC 27599, USA; Inception Institute of Artificial Intelligence, Abu Dhabi 51133, United Arab Emirates. Electronic address: taozhou.dreams@gmail.com.); Thung, Kim-Han (Department of Radiology and Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, NC 27599, USA. Electronic address: henrythung@gmail.com.); Liu, Mingxia (Department of Radiology and Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, NC 27599, USA. Electronic address: mxliu@med.unc.edu.); Shi, Feng (United Imaging Intelligence, Shanghai, China. Electronic address: feng.shi@united-imaging.com.); Zhang, Changqing (School of Computer Science and Technology, Tianjin University, Tianjin 300072, China. Electronic address: zhangchangqing@tju.edu.cn.); Shen, Dinggang (Department of Radiology and Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, NC 27599, USA; Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, Republic of Korea. Electronic address: dgshen@med.unc.edu.)","Shen, Dinggang (University of North Carolina at Chapel Hill; Korea University)","Zhou, Tao (University of North Carolina at Chapel Hill; Inception Institute of Artificial Intelligence); Thung, Kim-Han (University of North Carolina at Chapel Hill); Liu, Mingxia (University of North Carolina at Chapel Hill); Shi, Feng (); Zhang, Changqing (Tianjin University); Shen, Dinggang (University of North Carolina at Chapel Hill; Korea University)",37,32,2.87,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8260095,https://app.dimensions.ai/details/publication/pub.1123690433,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
5590,pub.1123567072,10.1148/ryct.2019190057,33778529,PMC7977801,Left Atrial Volume as a Biomarker of Atrial Fibrillation at Routine Chest CT: Deep Learning Approach,"PURPOSE: To test the performance of a deep learning (DL) model in predicting atrial fibrillation (AF) at routine nongated chest CT.
MATERIALS AND METHODS: A retrospective derivation cohort (mean age, 64 years; 51% female) consisting of 500 consecutive patients who underwent routine chest CT served as the training set for a DL model that was used to measure left atrial volume. The model was then used to measure atrial size for a separate 500-patient validation cohort (mean age, 61 years; 46% female), in which the AF status was determined by performing a chart review. The performance of automated atrial size as a predictor of AF was evaluated by using a receiver operating characteristic analysis.
RESULTS: There was good agreement between manual and model-generated segmentation maps by all measures of overlap and surface distance (mean Dice = 0.87, intersection over union = 0.77, Hausdorff distance = 4.36 mm, average symmetric surface distance = 0.96 mm), and agreement was slightly but significantly greater than that between human observers (mean Dice = 0.85 [automated] vs 0.84 [manual]; P = .004). Atrial volume was a good predictor of AF in the validation cohort (area under the receiver operating characteristic curve = 0.768) and was an independent predictor of AF, with an age-adjusted relative risk of 2.9.
CONCLUSION: Left atrial volume is an independent predictor of the AF status as measured at routine nongated chest CT. Deep learning is a suitable tool for automated measurement.© RSNA, 2019See also the commentary by de Roos and Tao in this issue.",atrial fibrillation confidence interval deep learning left atrium,,Radiology Cardiothoracic Imaging,,,2019-12-01,2019,2019-12-19,2019-12-01,1,5,e190057,All OA, Bronze,Article,"Bratt, Alex; Guenther, Zachary; Hahn, Lewis D; Kadoch, Michael; Adams, Patrick L; Leung, Ann N C; Guo, Haiwei H","Bratt, Alex (Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305 (A.B., Z.G., L.D.H., P.L.A., A.N.C.L., H.H.G.); and Department of Radiology, University of California at Davis, Sacramento, Calif (M.K.).); Guenther, Zachary (Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305 (A.B., Z.G., L.D.H., P.L.A., A.N.C.L., H.H.G.); and Department of Radiology, University of California at Davis, Sacramento, Calif (M.K.).); Hahn, Lewis D (Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305 (A.B., Z.G., L.D.H., P.L.A., A.N.C.L., H.H.G.); and Department of Radiology, University of California at Davis, Sacramento, Calif (M.K.).); Kadoch, Michael (Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305 (A.B., Z.G., L.D.H., P.L.A., A.N.C.L., H.H.G.); and Department of Radiology, University of California at Davis, Sacramento, Calif (M.K.).); Adams, Patrick L (Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305 (A.B., Z.G., L.D.H., P.L.A., A.N.C.L., H.H.G.); and Department of Radiology, University of California at Davis, Sacramento, Calif (M.K.).); Leung, Ann N C (Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305 (A.B., Z.G., L.D.H., P.L.A., A.N.C.L., H.H.G.); and Department of Radiology, University of California at Davis, Sacramento, Calif (M.K.).); Guo, Haiwei H (Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305 (A.B., Z.G., L.D.H., P.L.A., A.N.C.L., H.H.G.); and Department of Radiology, University of California at Davis, Sacramento, Calif (M.K.).)",,"Bratt, Alex (Stanford University); Guenther, Zachary (Stanford University); Hahn, Lewis D (Stanford University); Kadoch, Michael (Stanford University); Adams, Patrick L (Stanford University); Leung, Ann N C (Stanford University); Guo, Haiwei H (Stanford University)",9,8,0.57,3.77,https://pubs.rsna.org/doi/pdf/10.1148/ryct.2019190057,https://app.dimensions.ai/details/publication/pub.1123567072,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1007,pub.1120014997,10.1016/j.recesp.2019.05.016,,,Aplicaciones de la inteligencia artificial en cardiología: el futuro ya está aquí,"Existen pocos temas de actualidad equiparables a la posibilidad de la tecnología actual para desarrollar las mismas capacidades que el ser humano, incluso en medicina. Esta capacidad de simular los procesos de inteligencia humana por parte de máquinas o sistemas informáticos es lo que conocemos hoy en día como inteligencia artificial (IA). Este artículo pretende aclarar diferentes términos que todavía nos resultan lejanos como IA, machine learning (aprendizaje automático, AA), deep learning (aprendizaje profundo, AP), data science o big data; describir en profundidad el concepto de IA y sus tipos, las técnicas de aprendizaje y la metodología que se utiliza en el AA, el análisis en imagen cardiaca con AP, la aportación de esta revolución tecnológica a la estadística clásica, sus limitaciones actuales, sus aspectos legales y, fundamentalmente, sus aplicaciones iniciales en cardiología. En este sentido se ha realizado una búsqueda detallada en PubMed de la evolución en el último lustro de las contribuciones de la IA a las diferentes áreas de aplicación en cardiología, y se ha identificado un total de 673 artículos originales. Se describen en detalle 19 ejemplos de diferentes áreas de la cardiología que utilizando IA han mostrado mejoras diagnósticas y terapéuticas, y que facilitarán la comprensión de la metodología AA y AP. There is currently no other hot topic like the ability of current technology to develop capabilities similar to those of human beings, even in medicine. This ability to simulate the processes of human intelligence with computer systems is known as artificial intelligence (AI). This article aims to clarify the various terms that still sound foreign to us, such as AI, machine learning (ML), deep learning (DL), and big data. It also provides an in-depth description of the concept of AI and its types; the learning techniques and technology used by ML; cardiac imaging analysis with DL; and the contribution of this technological revolution to classical statistics, as well as its current limitations, legal aspects, and initial applications in cardiology. To do this, we conducted a detailed PubMed search on the evolution of original contributions on AI to the various areas of application in cardiology in the last 5 years and identified 673 research articles. We provide 19 detailed examples from distinct areas of cardiology that, by using AI, have shown diagnostic and therapeutic improvements, and which will aid understanding of ML and DL methodology.","Los autores de este artículo queremos agradecer a Antonio Sánchez, Rafael Vidal, Manuel Jiménez-Navarro y Purificación Galindo la revisión del manuscrito previa a su envío para evaluación a Revista Española de Cardiología. Sus comentarios y recomendaciones fueron de gran ayuda y contribuyeron, sin duda, en la elaboración de este artículo.",,Revista Española de Cardiología,,,2019-12,2019,,2019-12,72,12,1065-1075,Closed,Article,"Dorado-Díaz, P. Ignacio; Sampedro-Gómez, Jesús; Vicente-Palacios, Víctor; Sánchez, Pedro L.","Dorado-Díaz, P. Ignacio (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, España; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III, Madrid, España); Sampedro-Gómez, Jesús (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, España; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III, Madrid, España); Vicente-Palacios, Víctor (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, España; Philips Healthcare, Madrid, España); Sánchez, Pedro L. (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, España; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III, Madrid, España)","Sánchez, Pedro L. (University of Salamanca; Instituto de Salud Carlos III)","Dorado-Díaz, P. Ignacio (University of Salamanca; Instituto de Salud Carlos III); Sampedro-Gómez, Jesús (University of Salamanca; Instituto de Salud Carlos III); Vicente-Palacios, Víctor (University of Salamanca); Sánchez, Pedro L. (University of Salamanca; Instituto de Salud Carlos III)",29,20,,16.27,,https://app.dimensions.ai/details/publication/pub.1120014997,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,,
1582,pub.1122525340,10.48550/arxiv.1911.04967,,,Exploiting Clinically Available Delineations for CNN-based Segmentation  in Radiotherapy Treatment Planning,"Convolutional neural networks (CNNs) have been widely and successfully used
for medical image segmentation. However, CNNs are typically considered to
require large numbers of dedicated expert-segmented training volumes, which may
be limiting in practice. This work investigates whether clinically obtained
segmentations which are readily available in picture archiving and
communication systems (PACS) could provide a possible source of data to train a
CNN for segmentation of organs-at-risk (OARs) in radiotherapy treatment
planning. In such data, delineations of structures deemed irrelevant to the
target clinical use may be lacking. To overcome this issue, we use multi-label
instead of multi-class segmentation. We empirically assess how many clinical
delineations would be sufficient to train a CNN for the segmentation of OARs
and find that increasing the training set size beyond a limited number of
images leads to sharply diminishing returns. Moreover, we find that by using
multi-label segmentation, missing structures in the reference standard do not
have a negative effect on overall segmentation accuracy. These results indicate
that segmentations obtained in a clinical workflow can be used to train an
accurate OAR segmentation model.",,,arXiv,,,2019-11-12,2019,,,,,,All OA, Green,Preprint,"van Harten, Louis D.; Wolterink, Jelmer M.; Verhoeff, Joost J. C.; Išgum, Ivana","van Harten, Louis D. (); Wolterink, Jelmer M. (); Verhoeff, Joost J. C. (); Išgum, Ivana ()",,"van Harten, Louis D. (); Wolterink, Jelmer M. (); Verhoeff, Joost J. C. (); Išgum, Ivana ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1122525340,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 3211 Oncology and Carcinogenesis, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,
534,pub.1122524111,10.48550/arxiv.1911.03723,,,Deep learning for cardiac image segmentation: A review,"Deep learning has become the most widely used approach for cardiac image
segmentation in recent years. In this paper, we provide a review of over 100
cardiac image segmentation papers using deep learning, which covers common
imaging modalities including magnetic resonance imaging (MRI), computed
tomography (CT), and ultrasound (US) and major anatomical structures of
interest (ventricles, atria and vessels). In addition, a summary of publicly
available cardiac image datasets and code repositories are included to provide
a base for encouraging reproducible research. Finally, we discuss the
challenges and limitations with current deep learning-based approaches
(scarcity of labels, model generalizability across different domains,
interpretability) and suggest potential directions for future research.",,,arXiv,,,2019-11-09,2019,,,,,,All OA, Green,Preprint,"Chen, Chen; Qin, Chen; Qiu, Huaqi; Tarroni, Giacomo; Duan, Jinming; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (); Qin, Chen (); Qiu, Huaqi (); Tarroni, Giacomo (); Duan, Jinming (); Bai, Wenjia (); Rueckert, Daniel ()",,"Chen, Chen (); Qin, Chen (); Qiu, Huaqi (); Tarroni, Giacomo (); Duan, Jinming (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1122524111,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
5004,pub.1121483182,10.1088/1361-6560/ab4aa9,31581143,,Partial-ring PET image restoration using a deep learning based method,"PET scanners with partial-ring geometry have been proposed for various imaging purposes. The incomplete projection data obtained from this design cause undesirable artifacts in the reconstructed images. In this study, we investigated the performance of a deep learning (DL) based method for the recovery of partial-ring PET images. Twenty digital brain phantoms were used in the Monte Carlo simulation toolkit, SimSET, to simulate 15 min full-ring PET scans. Partial-ring PET data were generated from full-ring PET data by removing coincidence events that hit these specific detector blocks. A convolutional neural network based on the residual U-Net architecture was trained to predict full-ring data from partial-ring data in either the projection or image domain. The performance of the proposed DL-based method was evaluated by comparing with the PET images reconstructed using the full-ring projection data in terms of the mean squared error (MSE), structural similarity (SSIM) index and recovery coefficient (RC). The MSE results showed the superiority of the image-domain approach in reduction of 91.7% in contrast to 14.3% for the projection-domain approach. Therefore, the image-domain approach was used to study the influence of the number of detector block removal. The SSIM results were 0.998, 0.996 and 0.993 for 3, 5 and 7 detector block removals, respectively. The activity of gray and white matters could be fully recovered even with 7 detector block removal, while the RCs of two artificially inserted small lesions (3 pixels in diameter) in the testing data were 94%, 89% and 79% for 3, 5, and 7 detector block removals, respectively. Our simulation results suggest that DL has the potential to recover partial-ring PET images.","This work was supported by MOST 107-2221-E-002-081 from Ministry of Science Technology, Taiwan. The authors have no conflicts to disclose.",,Physics in Medicine and Biology,,"Artifacts; Brain; Deep Learning; Humans; Image Processing, Computer-Assisted; Monte Carlo Method; Phantoms, Imaging; Positron-Emission Tomography",2019-11-01,2019,2019-11-21,2019-11-01,64,22,225014,Closed,Article,"Liu, Chih-Chieh; Huang, Hsuan-Ming","Liu, Chih-Chieh (Department of Biomedical Engineering, University of California, Davis, CA 95616, United States of America); Huang, Hsuan-Ming (Institute of Medical Device and Imaging, College of Medicine, National Taiwan University, No.1, Sec. 1, Jen Ai Rd., Zhongzheng Dist., Taipei City 100, Taiwan; Author to whom any correspondence should be addressed.)",,"Liu, Chih-Chieh (University of California, Davis); Huang, Hsuan-Ming ()",10,10,0.71,6.98,,https://app.dimensions.ai/details/publication/pub.1121483182,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,,
4034,pub.1121714867,10.1002/mp.13859,31605627,,An iterative multi‐path fully convolutional neural network for automatic cardiac segmentation in cine MR images,"PURPOSE: Segmentation of the left ventricle (LV), right ventricle (RV) cavities and the myocardium (MYO) from cine cardiac magnetic resonance (MR) images is an important step for diagnosis and monitoring cardiac diseases. Spatial context information may be highly beneficial for segmentation performance improvement. To this end, this paper proposes an iterative multi-path fully convolutional network (IMFCN) to effectively leverage spatial context for automatic cardiac segmentation in cine MR images.
METHODS: To effectively leverage spatial context information, the proposed IMFCN explicitly models the interslice spatial correlations using a multi-path late fusion strategy. First, the contextual inputs including both the adjacent slices and the already predicted mask of the above adjacent slice are processed by independent feature-extraction paths. Then, an atrous spatial pyramid pooling (ASPP) module is employed at the feature fusion process to combine the extracted high-level contextual features in a more effective way. Finally, deep supervision (DS) and batch-wise class re-weighting mechanism are utilized to enhance the training of the proposed network.
RESULTS: The proposed IMFCN was evaluated and analyzed on the MICCAI 2017 automatic cardiac diagnosis challenge (ACDC) dataset. On the held-out training dataset reserved for testing, our method effectively improved its counterparts that without spatial context and that with spatial context but using an early fusion strategy. On the 50 subjects test dataset, our method achieved Dice similarity coefficient of 0.935, 0.920, and 0.905, and Hausdorff distance of 7.66, 12.10, and 8.80 mm for LV, RV, and MYO, respectively, which are comparable or even better than the state-of-the-art methods of ACDC Challenge. In addition, to explore the applicability to other datasets, the proposed IMFCN was retrained on the Sunnybrook dataset for LV segmentation and also produced comparable performance to the state-of-the-art methods.
CONCLUSIONS: We have presented an automatic end-to-end fully convolutional architecture for accurate cardiac segmentation. The proposed method provides an effective way to leverage spatial context in a two-dimensional manner and results in precise and consistent segmentation results.",This work was support in part by the National Natural Science Foundation of China (grant no. NSFC61701324).,,Medical Physics,,"Automation; Databases, Factual; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2019-11,2019,2019-11,2019-12,46,12,5652-5665,Closed,Article,"Ma, Zongqing; Wu, Xi; Wang, Xin; Song, Qi; Yin, Youbing; Cao, Kunlin; Wang, Yan; Zhou, Jiliu","Ma, Zongqing (College of Computer Science, Sichuan University, Chengdu, Sichuan, 610065, China); Wu, Xi (School of Computer Science, Chengdu University of Information Technology, Chengdu, Sichuan, 610225, China); Wang, Xin (CuraCloud Corporation, Seattle, WA, 98104, USA); Song, Qi (CuraCloud Corporation, Seattle, WA, 98104, USA); Yin, Youbing (CuraCloud Corporation, Seattle, WA, 98104, USA); Cao, Kunlin (CuraCloud Corporation, Seattle, WA, 98104, USA); Wang, Yan (College of Computer Science, Sichuan University, Chengdu, Sichuan, 610065, China); Zhou, Jiliu (College of Computer Science, Sichuan University, Chengdu, Sichuan, 610065, China; School of Computer Science, Chengdu University of Information Technology, Chengdu, Sichuan, 610225, China)","Wang, Yan (Sichuan University); Zhou, Jiliu (Sichuan University; Chengdu University of Information Technology)","Ma, Zongqing (Sichuan University); Wu, Xi (Chengdu University of Information Technology); Wang, Xin (); Song, Qi (); Yin, Youbing (); Cao, Kunlin (); Wang, Yan (Sichuan University); Zhou, Jiliu (Sichuan University; Chengdu University of Information Technology)",7,5,0.33,2.44,,https://app.dimensions.ai/details/publication/pub.1121714867,40 Engineering, 4003 Biomedical Engineering, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,
3846,pub.1121618686,10.1002/mp.13853,31598971,PMC7372294,A distance map regularized CNN for cardiac cine MR image segmentation,"PURPOSE: Cardiac image segmentation is a critical process for generating personalized models of the heart and for quantifying cardiac performance parameters. Fully automatic segmentation of the left ventricle (LV), the right ventricle (RV), and the myocardium from cardiac cine MR images is challenging due to variability of the normal and abnormal anatomy, as well as the imaging protocols. This study proposes a multi-task learning (MTL)-based regularization of a convolutional neural network (CNN) to obtain accurate segmenation of the cardiac structures from cine MR images.
METHODS: We train a CNN network to perform the main task of semantic segmentation, along with the simultaneous, auxiliary task of pixel-wise distance map regression. The network also predicts uncertainties associated with both tasks, such that their losses are weighted by the inverse of their corresponding uncertainties. As a result, during training, the task featuring a higher uncertainty is weighted less and vice versa. The proposed distance map regularizer is a decoder network added to the bottleneck layer of an existing CNN architecture, facilitating the network to learn robust global features. The regularizer block is removed after training, so that the original number of network parameters does not change. The trained network outputs per-pixel segmentation when a new patient cine MR image is provided as an input.
RESULTS: We show that the proposed regularization method improves both binary and multi-class segmentation performance over the corresponding state-of-the-art CNN architectures. The evaluation was conducted on two publicly available cardiac cine MRI datasets, yielding average Dice coefficients of 0.84 ± 0.03 and 0.91 ± 0.04. We also demonstrate improved generalization performance of the distance map regularized network on cross-dataset segmentation, showing as much as 42% improvement in myocardium Dice coefficient from 0.56 ± 0.28 to 0.80 ± 0.14.
CONCLUSIONS: We have presented a method for accurate segmentation of cardiac structures from cine MR images. Our experiments verify that the proposed method exceeds the segmentation performance of three existing state-of-the-art methods. Furthermore, several cardiac indices that often serve as diagnostic biomarkers, specifically blood pool volume, myocardial mass, and ejection fraction, computed using our method are better correlated with the indices computed from the reference, ground truth segmentation. Hence, the proposed method has the potential to become a non-invasive screening and diagnostic tool for the clinical assessment of various cardiac conditions, as well as a reliable aid for generating patient specific models of the cardiac anatomy for therapy planning, simulation, and guidance.",,,Medical Physics,,"Heart; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Neural Networks, Computer",2019-10-31,2019,2019-10-31,2019-12,46,12,5637-5651,All OA, Bronze,Article,"Dangi, Shusil; Linte, Cristian A.; Yaniv, Ziv","Dangi, Shusil (Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, 14623, USA); Linte, Cristian A. (Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, 14623, USA; Biomedical Engineering, Rochester Institute of Technology, Rochester, NY, 14623, USA); Yaniv, Ziv (MSC LLC., Rockville, MD, 20852, USA; National Institute of Allergy and Infectious Diseases, NIH, Bethesda, MD, 20814, USA)","Dangi, Shusil (Rochester Institute of Technology)","Dangi, Shusil (Rochester Institute of Technology); Linte, Cristian A. (Rochester Institute of Technology; Rochester Institute of Technology); Yaniv, Ziv (National Institute of Allergy and Infectious Diseases)",49,28,1.63,34.22,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/mp.13853,https://app.dimensions.ai/details/publication/pub.1121618686,51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,,,
1614,pub.1122795229,10.1109/niles.2019.8909320,,,LVLNET: Lightweight Left Ventricle Localizer using Encoder-Decoder Neural Network,"Automatic localization of the left ventricle (LV) is an important preprocessing step in any further analysis or quantification of LV function. Also, LV localization is usually done manually by MRI operator to plan Cardiac Magnetic Resonance Imaging (Cardiac MR) acquisition which can be standardized and automated to reduce the operator's error. In this study, we propose LVLNET; an automatic left ventricle localization approach; which utilizes a lightweight encoder-decoder-like convolutional neural network (CNN). We evaluated our proposed method using three different and independent datasets. The proposed method has estimated the region of interest of the left ventricle with an accuracy of 88% covering more than 90% of the left ventricle voxels. Also, the median distance between the real and estimated centers was 1.12 [0.61–2.38] mm. With the reported results, it is shown that our proposed method had overcome most of the badly annotated images however, considering dynamic movement through series timeframes would boost the resulted accuracy.",,,,2019 Novel Intelligent and Leading Emerging Sciences Conference (NILES),,2019-10-30,2019,,2019-10-30,1,,235-238,Closed,Proceeding,"Abdelrauof, Dina; Essam, Mina; Elattar, Mustafa","Abdelrauof, Dina (Research and Development Division, Intixel Co. S.A.E., Cairo, Egypt); Essam, Mina (Research and Development Division, Intixel Co. S.A.E., Cairo, Egypt); Elattar, Mustafa (Medical Imaging and Image Processing Group Nile University, Nile University, Giza, Egypt; Research and Development Division, Intixel Co. S.A.E., Cairo, Egypt)","Abdelrauof, Dina ","Abdelrauof, Dina (); Essam, Mina (); Elattar, Mustafa (Nile University)",2,2,,0.68,,https://app.dimensions.ai/details/publication/pub.1122795229,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
376,pub.1122313001,10.48550/arxiv.1911.00400,,,Sparsely Activated Networks: A new method for decomposing and  compressing data,"Recent literature on unsupervised learning focused on designing structural
priors with the aim of learning meaningful features, but without considering
the description length of the representations. In this thesis, first we
introduce the $\varphi$ metric that evaluates unsupervised models based on
their reconstruction accuracy and the degree of compression of their internal
representations. We then present and define two activation functions (Identity,
ReLU) as base of reference and three sparse activation functions (top-k
absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize
the previously defined metric $\varphi$. We lastly present Sparsely Activated
Networks (SANs) that consist of kernels with shared weights that, during
encoding, are convolved with the input and then passed through a sparse
activation function. During decoding, the same weights are convolved with the
sparse activation map and subsequently the partial reconstructions from each
weight are summed to reconstruct the input. We compare SANs using the five
previously defined activation functions on a variety of datasets (Physionet,
UCI-epilepsy, MNIST, FMNIST) and show that models that are selected using
$\varphi$ have small description representation length and consist of
interpretable kernels.",,,arXiv,,,2019-10-30,2019,,,,,,All OA, Green,Preprint,"Bizopoulos, Paschalis","Bizopoulos, Paschalis ()",,"Bizopoulos, Paschalis ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1122313001,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1254,pub.1123202634,10.1109/sibgrapi.2019.00017,,,Long-Range Decoder Skip Connections: Exploiting Multi-Context Information for Cardiac Image Segmentation,"The heart is one of the most important organs in our body and many critical diseases are associated with its malfunctioning. To assess the risk for heart diseases, Magnetic Resonance Imaging (MRI) has become the golden standard imaging technique, as it provides to the clinicians stacks of images for analyzing the heart structures, such as the ventricles, and thus to make a diagnosis of the patient's health. The problem is that examination of these stacks, often based on the delineation of heart structures, is tedious and error prone due to inter-and intra-variability among manual delineations. For this reason, the investigation of fully automated methods to support heart segmentation is paramount. Most of the successful methods proposed to solve this problem are based on deep-learning solutions. Especially, encoder-decoder architectures, such as the U-Net [1], have demonstrated to be very effective architectures for medical image segmentation. In this paper, we propose to use long-range skip connections on the decoder-part to incorporate multi-context information onto the predicted segmentation masks and also to improve the generalization of the models. In addition, our method obtains smoother segmentations through the combination of feature maps from different stages onto the final prediction layer. We evaluate our approach in the ACDC [2] and LVSC [3] heart segmentation challenges. Experiments performed on both datasets demonstrate that our approach leads to an improvement on both the total Dice score and the Ejection Fraction Correlation, when combined with state-of-the-art encoder-decoder architectures.","The authors are grateful to CNPq (grants #307560/2016-3 and #303808/2018-7), São Paulo Research Foundation-FAPESP (grants #2014/12236-1, #2015/24494-8, #2016/50250-1, and #2017/20945-0), the FAPESP-Microsoft Virtual Institute (grants #2013/50155-0 and #2014/50715-9), Swiss National Science Foundation - SNSF (grant # 32003B_159727), a Google Cloud Research Award, and a Titan Xp GPU donation from NVIDIA Corporation. This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001. The present work was also supported by grant 234-2015-FONDECYT (Master Program) from Cienciactiva of the National Council for Science, Technology and Technological Innocation (CONCYTEC-PERU). The authors are grateful to CNPq (grants #307560/2016-3 and #303808/2018-7), São Paulo Research Foundation-FAPESP (grants #2014/12236-1, #2015/24494-8, #2016/50250-1, and #2017/20945-0), the FAPESP-Microsoft Virtual Institute (grants #2013/50155-0 and #2014/50715-9), Swiss National Science Foundation - SNSF (grant # 32003B_159727), a Google Cloud Research Award, and a Titan Xp GPU donation from NVIDIA Corporation. This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001. The present work was also supported by grant 234-2015-FONDECYT (Master Program) from Cienciactiva of the National Council for Science, Technology and Technological Innocation (CONCYTEC-PERU).",,,"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)",,2019-10-28,2019,,2019-10-28,0,,60-67,Closed,Proceeding,"Gutierrez-Castilla, Nicolás; da S. Torres, Ricardo; Falcão, Alexandre X.; Kozerke, Sebastian; Schwitter, Jürg; Masci, Pier-Giorgio; Montoya-Zegarra, Javier A.","Gutierrez-Castilla, Nicolás (Department of Computer Science, Universidad Católica San Pablo, Arequipa, Perú); da S. Torres, Ricardo (Institute of Computing, University of Campinas, Campinas, SP, Brazil); Falcão, Alexandre X. (Institute of Computing, University of Campinas, Campinas, SP, Brazil); Kozerke, Sebastian (Institute for Biomedical Engineering, ETH Zurich, Zurich, Switzerland); Schwitter, Jürg (Center for Cardiac Magnetic Resonance, Lausanne University Hospital, Lausanne, Switzerland); Masci, Pier-Giorgio (Rayne Institute School of Bioengineering and Imaging Sciences, King's College London, London, United Kingdom); Montoya-Zegarra, Javier A. (Institute for Biomedical Engineering, ETH Zurich, Zurich, Switzerland; Department of Computer Science, Universidad Católica San Pablo, Arequipa, Perú)",,"Gutierrez-Castilla, Nicolás (Universidad Católica San Pablo); da S. Torres, Ricardo (State University of Campinas); Falcão, Alexandre X. (State University of Campinas); Kozerke, Sebastian (Institute for Biomedical Engineering); Schwitter, Jürg (University Hospital of Lausanne); Masci, Pier-Giorgio (King's College London); Montoya-Zegarra, Javier A. (Institute for Biomedical Engineering; Universidad Católica San Pablo)",2,2,,0.68,,https://app.dimensions.ai/details/publication/pub.1123202634,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,,
3631,pub.1122097587,10.1016/j.media.2019.101591,31704452,,Commensal correlation network between segmentation and direct area estimation for bi-ventricle quantification,"Accurate and automated cardiac bi-ventricle quantification based on cardiac magnetic resonance (CMR) image is a very crucial procedure for clinical cardiac disease diagnosis. Two traditional and commensal tasks, i.e., bi-ventricle segmentation and direct ventricle function index estimation, are always independently devoting to address ventricle quantification problem. However, because of inherent difficulties from the variable CMR imaging conditions, these two tasks are still open challenging. In this paper, we proposed a unified bi-ventricle quantification framework based on commensal correlation between the bi-ventricle segmentation and direct area estimation. Firstly, we proposed the area commensal correlation between the two traditional cardiac quantification tasks for the first time, and designed a novel deep commensal network (DCN) to join these two commensal tasks into a unified framework based on the proposed commensal correlation loss. Secondly, we proposed an differentiable area operator to model the proposed area commensal correlation and made the proposed model continuously differentiable. Thirdly, we proposed a high-efficiency and novel uncertainty estimation method through one-time inference based on cross-task output variability. And finally DCN achieved end-to-end optimization and fast convergence as well as uncertainty estimation with one-time inference. Experiments on the four open accessible short-axis CMR benchmark datasets (i.e., Sunnybrook, STACOM 2011, RVSC, and ACDC) showed that the proposed method achieves best bi-ventricle quantification accuracy and optimization performance. Hence, the proposed method has big potential to be extended to other medical image analysis tasks and has clinical application value.","Thanks for Olga Shmuilovich and Ashley Mercado for label work on the large numbers of data. This work was supported by the National Key RD Program of China under Grant 2017YFC0113000, and the National Natural Science Foundation of China under Grant 61571165 and Grant 61572152",,Medical Image Analysis,,"Datasets as Topic; Heart Diseases; Heart Ventricles; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Models, Statistical",2019-10-25,2019,2019-10-25,2020-01,59,,101591,Closed,Article,"Luo, Gongning; Dong, Suyu; Wang, Wei; Wang, Kuanquan; Cao, Shaodong; Tam, Clara; Zhang, Henggui; Howey, Joanne; Ohorodnyk, Pavlo; Li, Shuo","Luo, Gongning (Biocomputing Research Center, School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Dong, Suyu (Biocomputing Research Center, School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Wang, Wei (Biocomputing Research Center, School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Wang, Kuanquan (Biocomputing Research Center, School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China. Electronic address: wangkq@hit.edu.cn.); Cao, Shaodong (The Department of Radiology, The Fourth Hospital of Harbin Medical University, China.); Tam, Clara (The Department of Medical Imaging, Western University, London, Canada; The Digital Imaging Group of London, London, ON N6A 3K7, Canada.); Zhang, Henggui (School of Physics and Astronomy, University of Manchester, Manchester, UK.); Howey, Joanne (The Department of Medical Imaging, Western University, London, Canada; The Digital Imaging Group of London, London, ON N6A 3K7, Canada.); Ohorodnyk, Pavlo (The Department of Medical Imaging, Western University, London, Canada; The Digital Imaging Group of London, London, ON N6A 3K7, Canada.); Li, Shuo (The Department of Medical Imaging, Western University, London, Canada; The Digital Imaging Group of London, London, ON N6A 3K7, Canada. Electronic address: slishuo@gmail.com.)","Wang, Kuanquan (Harbin Institute of Technology); Li, Shuo (Western University; )","Luo, Gongning (Harbin Institute of Technology); Dong, Suyu (Harbin Institute of Technology); Wang, Wei (Harbin Institute of Technology); Wang, Kuanquan (Harbin Institute of Technology); Cao, Shaodong (Harbin Medical University); Tam, Clara (Western University); Zhang, Henggui (University of Manchester); Howey, Joanne (Western University); Ohorodnyk, Pavlo (Western University); Li, Shuo (Western University)",22,14,1.66,,,https://app.dimensions.ai/details/publication/pub.1122097587,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,,
1451,pub.1122021939,10.1007/978-3-030-33843-5_1,,,Recon-GLGAN: A Global-Local Context Based Generative Adversarial Network for MRI Reconstruction,"Abstract
Magnetic resonance imaging (MRI) is one of the best medical imaging modalities as it offers excellent spatial resolution and soft-tissue contrast. But, the usage of MRI is limited by its slow acquisition time, which makes it expensive and causes patient discomfort. In order to accelerate the acquisition, multiple deep learning networks have been proposed. Recently, Generative Adversarial Networks (GANs) have shown promising results in MRI reconstruction. The drawback with the proposed GAN based methods is it does not incorporate the prior information about the end goal which could help in better reconstruction. For instance, in the case of cardiac MRI, the physician would be interested in the heart region which is of diagnostic relevance while excluding the peripheral regions. In this work, we show that incorporating prior information about a region of interest in the model would offer better performance. Thereby, we propose a novel GAN based architecture, Reconstruction Global-Local GAN (Recon-GLGAN) for MRI reconstruction. The proposed model contains a generator and a context discriminator which incorporates global and local contextual information from images. Our model offers significant performance improvement over the baseline models. Our experiments show that the concept of a context discriminator can be extended to existing GAN based reconstruction models to offer better performance. We also demonstrate that the reconstructions from the proposed method give segmentation results similar to fully sampled images.",,,Lecture Notes in Computer Science,Machine Learning for Medical Image Reconstruction,,2019-10-24,2019,2019-10-24,2019,11905,,3-15,All OA, Green,Chapter,"Murugesan, Balamurali; Vijaya Raghavan, S.; Sarveswaran, Kaushik; Ram, Keerthi; Sivaprakasam, Mohanasankar","Murugesan, Balamurali (Indian Institute of Technology Madras (IITM), Chennai, India; Healthcare Technology Innovation Centre (HTIC), IITM, Chennai, India); Vijaya Raghavan, S. (Healthcare Technology Innovation Centre (HTIC), IITM, Chennai, India); Sarveswaran, Kaushik (Healthcare Technology Innovation Centre (HTIC), IITM, Chennai, India); Ram, Keerthi (Healthcare Technology Innovation Centre (HTIC), IITM, Chennai, India); Sivaprakasam, Mohanasankar (Indian Institute of Technology Madras (IITM), Chennai, India; Healthcare Technology Innovation Centre (HTIC), IITM, Chennai, India)","Murugesan, Balamurali (Indian Institute of Technology Madras; Indian Institute of Technology Madras; Healthcare Technology Innovation Centre)","Murugesan, Balamurali (Indian Institute of Technology Madras; Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); Vijaya Raghavan, S. (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); Sarveswaran, Kaushik (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); Ram, Keerthi (Indian Institute of Technology Madras; Healthcare Technology Innovation Centre); Sivaprakasam, Mohanasankar (Indian Institute of Technology Madras; Indian Institute of Technology Madras; Healthcare Technology Innovation Centre)",8,7,,,http://arxiv.org/pdf/1908.09262,https://app.dimensions.ai/details/publication/pub.1122021939,46 Information and Computing Sciences,,,,,,,,,,,
5603,pub.1122029429,10.1097/rti.0000000000000459,31651691,,Accuracy and Time-Efficiency of an Automated Software Tool to Assess Left Ventricular Parameters in Cardiac Magnetic Resonance Imaging,"PURPOSE: Routine manual tracing of cardiac contours is time-consuming and subject to variability. A fully automated software tool may improve reading efficiency. This study was performed to assess the accuracy, reliability, and time-efficiency of a fully automated left ventricular (LV) segmentation software tool to calculate LV volumes and function compared with conventional manual contouring.
MATERIALS AND METHODS: Sixty-seven consecutive patients (53 male, mean age 62.5±10.9 y) underwent adenosine stress/rest perfusion cardiac magnetic resonance examination to rule out myocardial ischemia. Double-oblique short-axis 6-mm slice thickness steady-state free precession cine images were acquired to assess LV ejection fraction (EF), end-diastolic volume (EDV), end-systolic volume (ESV), and stroke volume (SV) using manual contour tracing and a recently developed fully automated software tool. The length of time needed to obtain LV volumes with each segmentation method was also compared.
RESULTS: Compared with manual contouring, the fully automated software tool minimally underestimated LV-EF (mean difference of 2.9%±3.9%) and SV (mean difference of 4.4±8.5 mL) and slightly overestimated ESV (mean difference of -6.4±10.8 mL) and LV mass (mean difference of -14±20.4 g). EDV quantification did not statistically differ. Reliability for EF (concordance correlation coefficient [CCC]=0.92, 95% confidence interval [CI], 0.88-0.95), EDV (CCC=0.98, 95% CI, 0.97-0.99), ESV (CCC=0.96, 95% CI, 0.94-0.97), SV (CCC=0.93, 95% CI, 0.89-0.95), and LV mass (CCC=0.84, 95% CI, 0.76-0.89) was very good. The evaluated software allowed to quantify LV parameters with a 79% reduction in the time required for manual contouring (414.7±91 s vs. 85±16.1 s, respectively, P<0.001).
CONCLUSION: Quantification of LV volumes using the evaluated fully automated segmentation software is accurate and time-efficient.",,,Journal of Thoracic Imaging,,"Efficiency; Exercise Test; Female; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Myocardial Ischemia; Reproducibility of Results; Software",2019-10-22,2019,2019-10-22,2020-01,35,1,64-70,Closed,Article,"Bartolomé, Pablo; Caballeros, Meylin; Quílez-Larragan, Almudena; Núñez-Córdoba, Jorge M.; González, Óscar Fernández; Ezponda, Ana; Bastarrika, Gorka","Bartolomé, Pablo (Department of Radiology, Cardiothoracic Imaging Division, Clínica Universidad de Navarra); Caballeros, Meylin (Department of Radiology, Cardiothoracic Imaging Division, Clínica Universidad de Navarra); Quílez-Larragan, Almudena (Department of Radiology, Cardiothoracic Imaging Division, Clínica Universidad de Navarra); Núñez-Córdoba, Jorge M. (Research Support Service, Central Clinical Trials Unit, Clínica Universidad de Navarra; Department of Preventive Medicine and Public Health, School of Medicine, University of Navarra, Pamplona); González, Óscar Fernández (Siemens Healthineers, Madrid, Spain); Ezponda, Ana (Department of Radiology, Cardiothoracic Imaging Division, Clínica Universidad de Navarra); Bastarrika, Gorka (Department of Radiology, Cardiothoracic Imaging Division, Clínica Universidad de Navarra)","Bastarrika, Gorka ","Bartolomé, Pablo (); Caballeros, Meylin (); Quílez-Larragan, Almudena (); Núñez-Córdoba, Jorge M. (University of Navarra); González, Óscar Fernández (); Ezponda, Ana (); Bastarrika, Gorka ()",5,3,0.85,2.1,,https://app.dimensions.ai/details/publication/pub.1122029429,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,,
1582,pub.1121734545,10.1007/978-3-030-33391-1_6,,,Synthesising Images and Labels Between MR Sequence Types with CycleGAN,"Abstract
Real-time (RT) sequences for cardiac magnetic resonance imaging (CMR) have recently been proposed as alternatives to standard cine CMR sequences for subjects unable to hold the breath or suffering from arrhythmia. RT image acquisitions during free breathing produce comparatively poor quality images, a trade-off necessary to achieve the high temporal resolution needed for RT imaging and hence are less suitable in the clinical assessment of cardiac function. We demonstrate the application of a CycleGAN architecture to train autoencoder networks for synthesising cine-like images from RT images and vice versa. Applying this conversion to real-time data produces clearer images with sharper distinctions between myocardial and surrounding tissues, giving clinicians a more precise means of visually inspecting subjects. Furthermore, applying the transformation to segmented cine data to produce pseudo-real-time images allows this label information to be transferred to the real-time image domain. We demonstrate the feasibility of this approach by training a U-net based architecture using these pseudo-real-time images which can effectively segment actual real-time images.","This research was supported by the National Institute for Health Research (NIHR) Biomedical Research Centre (BRC) at Guy’s and St Thomas’ NHS Foundation Trust, and by the Wellcome EPSRC Centre for Medical Engineering at the School of Biomedical Engineering and Imaging Sciences, King’s College London (WT 203148/Z/16/Z). This research has been conducted using the UK Biobank Resource under Application Number 17806.",,Lecture Notes in Computer Science,Domain Adaptation and Representation Transfer and Medical Image Learning with Less Labels and Imperfect Data,,2019-10-13,2019,2019-10-13,2019,11795,,45-53,Closed,Chapter,"Kerfoot, Eric; Puyol-Antón, Esther; Ruijsink, Bram; Ariga, Rina; Zacur, Ernesto; Lamata, Pablo; Schnabel, Julia","Kerfoot, Eric (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, UK); Puyol-Antón, Esther (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, UK); Ruijsink, Bram (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, UK; St Thomas’ Hospital NHS Foundation Trust, London, UK); Ariga, Rina (University of Oxford, Oxford, UK); Zacur, Ernesto (University of Oxford, Oxford, UK); Lamata, Pablo (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, UK); Schnabel, Julia (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, UK)","Kerfoot, Eric (King's College London)","Kerfoot, Eric (King's College London); Puyol-Antón, Esther (King's College London); Ruijsink, Bram (King's College London; St Thomas' Hospital); Ariga, Rina (University of Oxford); Zacur, Ernesto (University of Oxford); Lamata, Pablo (King's College London); Schnabel, Julia (King's College London)",6,5,,,,https://app.dimensions.ai/details/publication/pub.1121734545,46 Information and Computing Sciences,,,,,,,,,,,,
3198,pub.1121723350,10.1016/j.rec.2019.05.014,31611150,,Applications of Artificial Intelligence in Cardiology. The Future is Already Here,"There is currently no other hot topic like the ability of current technology to develop capabilities similar to those of human beings, even in medicine. This ability to simulate the processes of human intelligence with computer systems is known as artificial intelligence (AI). This article aims to clarify the various terms that still sound foreign to us, such as AI, machine learning (ML), deep learning (DL), and big data. It also provides an in-depth description of the concept of AI and its types; the learning techniques and technology used by ML; cardiac imaging analysis with DL; and the contribution of this technological revolution to classical statistics, as well as its current limitations, legal aspects, and initial applications in cardiology. To do this, we conducted a detailed PubMed search on the evolution of original contributions on AI to the various areas of application in cardiology in the last 5 years and identified 673 research articles. We provide 19 detailed examples from distinct areas of cardiology that, by using AI, have shown diagnostic and therapeutic improvements, and which will aid understanding of ML and DL methodology.","The authors of this article would like to thank Antonio Sánchez, Rafael Vidal, Manuel Jiménez-Navarro, and Purificación Galindo for reviewing the manuscript prior to its submission to Revista Española de Cardiología. Their comments and advice were very helpful and no doubt contributed to the drafting of this article.",,Revista Española de Cardiología (English Edition),,Algorithms, Artificial Intelligence, Cardiac Imaging Techniques, Cardiology, Deep Learning, Humans, Machine Learning,2019-10-12,2019,2019-10-12,2019-12,72,12,1065-1075,Closed,Article,"Dorado-Díaz, P Ignacio; Sampedro-Gómez, Jesús; Vicente-Palacios, Víctor; Sánchez, Pedro L","Dorado-Díaz, P Ignacio (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, Spain; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III, Madrid, Spain.); Sampedro-Gómez, Jesús (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, Spain; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III, Madrid, Spain.); Vicente-Palacios, Víctor (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, Spain; Philips Healthcare, Madrid, Spain.); Sánchez, Pedro L (Servicio de Cardiología, Hospital Universitario de Salamanca-Instituto de Investigación Biomédica de Salamanca (IBSAL), Universidad de Salamanca, Salamanca, Spain; Centro de Investigación Biomédica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III, Madrid, Spain. Electronic address: pedrolsanchez@secardiologia.es.)","Sánchez, Pedro L (University of Salamanca; Instituto de Salud Carlos III)","Dorado-Díaz, P Ignacio (University of Salamanca; Instituto de Salud Carlos III); Sampedro-Gómez, Jesús (University of Salamanca; Instituto de Salud Carlos III); Vicente-Palacios, Víctor (University of Salamanca); Sánchez, Pedro L (University of Salamanca; Instituto de Salud Carlos III)",69,47,2.16,27.27,,https://app.dimensions.ai/details/publication/pub.1121723350,46 Information and Computing Sciences, 4602 Artificial Intelligence,,,,,
1551,pub.1121617978,10.1007/978-3-030-32245-8_83,,,Quality Control-Driven Image Segmentation Towards Reliable Automatic Image Analysis in Large-Scale Cardiovascular Magnetic Resonance Aortic Cine Imaging,"Recent progress in fully-automated image segmentation has enabled efficient extraction of clinical parameters in large-scale clinical imaging studies, reducing laborious manual processing. However, the current state-of-the-art automatic image segmentation may still fail, especially when it comes to atypical cases. Visual inspection of segmentation quality is often required, thus diminishing the improvements in efficiency. This drives an increasing need to enhance the overall data processing pipeline with robust automatic quality scoring, especially for clinical applications. We present a novel quality control-driven (QCD) framework to provide reliable segmentation using a set of different neural networks. In contrast to the prior segmentation and quality scoring methods, the proposed framework automatically selects the optimal segmentation on-the-fly from the multiple candidate segmentations available, directly utilizing the inherent Dice similarity coefficient (DSC) predictions. We trained and evaluated the framework on a large-scale cardiovascular magnetic resonance aortic cine image sequences from the UK Biobank Study. The framework achieved segmentation accuracy of mean DSC at 0.966, mean prediction error of DSC within 0.015, and mean error in estimating lumen area ≤17.6 mm2 for both ascending aorta and proximal descending aorta. This novel QCD framework successfully integrates the automatic image segmentation along with detection of critical errors on a per-case basis, paving the way towards reliable fully-automatic extraction of clinical parameters for large-scale imaging studies.","This study was supported by the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre at The Oxford University Hospitals, University of Oxford, UK. Authors acknowledge support from the British Heart Foundation Centre of Research Excellence, and donation of GPU from NVIDIA Corp.",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2019,,2019-10-10,2019,2019-10-10,2019,11765,,750-758,All OA, Green,Chapter,"Hann, Evan; Biasiolli, Luca; Zhang, Qiang; Popescu, Iulia A.; Werys, Konrad; Lukaschuk, Elena; Carapella, Valentina; Paiva, Jose M.; Aung, Nay; Rayner, Jennifer J.; Fung, Kenneth; Puchta, Henrike; Sanghvi, Mihir M.; Moon, Niall O.; Thomas, Katharine E.; Ferreira, Vanessa M.; Petersen, Steffen E.; Neubauer, Stefan; Piechnik, Stefan K.","Hann, Evan (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Biasiolli, Luca (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Zhang, Qiang (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Popescu, Iulia A. (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Werys, Konrad (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Lukaschuk, Elena (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Carapella, Valentina (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Paiva, Jose M. (William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, London, UK); Aung, Nay (William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, London, UK); Rayner, Jennifer J. (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Fung, Kenneth (William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, London, UK); Puchta, Henrike (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Sanghvi, Mihir M. (William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, London, UK); Moon, Niall O. (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Thomas, Katharine E. (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Ferreira, Vanessa M. (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Petersen, Steffen E. (William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, London, UK); Neubauer, Stefan (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Piechnik, Stefan K. (Oxford Centre for Clinical Magnetic Resonance Research (OCMR), Radcliffe Department of Medicine, University of Oxford, Oxford, UK)","Hann, Evan (University of Oxford)","Hann, Evan (University of Oxford); Biasiolli, Luca (University of Oxford); Zhang, Qiang (University of Oxford); Popescu, Iulia A. (University of Oxford); Werys, Konrad (University of Oxford); Lukaschuk, Elena (University of Oxford); Carapella, Valentina (University of Oxford); Paiva, Jose M. (Queen Mary University of London); Aung, Nay (Queen Mary University of London); Rayner, Jennifer J. (University of Oxford); Fung, Kenneth (Queen Mary University of London); Puchta, Henrike (University of Oxford); Sanghvi, Mihir M. (Queen Mary University of London); Moon, Niall O. (University of Oxford); Thomas, Katharine E. (University of Oxford); Ferreira, Vanessa M. (University of Oxford); Petersen, Steffen E. (Queen Mary University of London); Neubauer, Stefan (University of Oxford); Piechnik, Stefan K. (University of Oxford)",14,12,,,https://qmro.qmul.ac.uk/xmlui/bitstream/123456789/63619/2/Petersen_Quality%20Control-Driven%20Image%20Segmentation_Accepted_2019.pdf,https://app.dimensions.ai/details/publication/pub.1121617978,46 Information and Computing Sciences,,,,,,,,,,,
1548,pub.1121617557,10.1007/978-3-030-32245-8_3,,,Unsupervised Quality Control of Image Segmentation Based on Bayesian Learning,"Assessing the quality of segmentations on an image database is required as many downstream clinical applications are based on segmentation results. For large databases, this quality assessment becomes tedious for a human expert and therefore some automation of this task is necessary. In this paper, we introduce a novel unsupervised approach to assist the quality control of image segmentations by measuring their adequacy with segmentations produced by a generic probabilistic model. To this end, we introduce a new segmentation model combining intensity and a spatial prior defined through a combination of spatially smooth kernels. The tractability of the approach is obtained by solving a type-II maximum likelihood which directly estimates hyperparameters. Assessing the quality of the segmentation with respect to the probabilistic model allows to detect the most challenging cases inside a dataset. This approach was evaluated on the BRATS 2017 and ACDC datasets showing its relevance for quality control assessment.","This work was partially funded by the French government, through the UCAJEDI “Investments in the Future” project managed by the National Research Agency (ANR) with the reference number ANR-15-IDEX-01 and supported by the Inria Sophia Antipolis - Méditerranée,“NEF” computation cluster.",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2019,,2019-10-10,2019,2019-10-10,2019,11765,,21-29,All OA, Green,Chapter,"Audelan, Benoît; Delingette, Hervé","Audelan, Benoît (Université Côte d’Azur, Inria, Epione Project-Team, Sophia Antipolis, France); Delingette, Hervé (Université Côte d’Azur, Inria, Epione Project-Team, Sophia Antipolis, France)","Audelan, Benoît ","Audelan, Benoît (); Delingette, Hervé ()",9,6,,3.36,https://hal.inria.fr/hal-02265131/file/paper2106.pdf,https://app.dimensions.ai/details/publication/pub.1121617557,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
4271,pub.1121552140,10.1186/s12968-019-0575-y,31590664,PMC6778980,Machine learning in cardiovascular magnetic resonance: basic concepts and applications,"Machine learning (ML) is making a dramatic impact on cardiovascular magnetic resonance (CMR) in many ways. This review seeks to highlight the major areas in CMR where ML, and deep learning in particular, can assist clinicians and engineers in improving imaging efficiency, quality, image analysis and interpretation, as well as patient evaluation. We discuss recent developments in the field of ML relevant to CMR in the areas of image acquisition & reconstruction, image analysis, diagnostic evaluation and derivation of prognostic information. To date, the main impact of ML in CMR has been to significantly reduce the time required for image segmentation and analysis. Accurate and reproducible fully automated quantification of left and right ventricular mass and volume is now available in commercial products. Active research areas include reduction of image acquisition and reconstruction time, improving spatial and temporal resolution, and analysis of perfusion and myocardial mapping. Although large cohort studies are providing valuable data sets for ML training, care must be taken in extending applications to specific patient groups. Since ML algorithms can fail in unpredictable ways, it is important to mitigate this by open source publication of computational processes and datasets. Furthermore, controlled trials are needed to evaluate methods across multiple centers and patient groups.",Not applicable.,,Journal of Cardiovascular Magnetic Resonance,,"Cardiovascular Diseases; Coronary Circulation; Deep Learning; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging, Cine; Myocardial Perfusion Imaging; Myocardium; Predictive Value of Tests; Reproducibility of Results; Supervised Machine Learning; Unsupervised Machine Learning",2019-10-07,2019,2019-10-07,2019-12,21,1,61,All OA, Gold,Article,"Leiner, Tim; Rueckert, Daniel; Suinesiaputra, Avan; Baeßler, Bettina; Nezafat, Reza; Išgum, Ivana; Young, Alistair A.","Leiner, Tim (Department of Radiology | E.01.132, Utrecht University Medical Center, Heidelberglaan 100, 3584CX, Utrecht, The Netherlands); Rueckert, Daniel (Biomedical Image Analysis Group, Department of Computing, Imperial College, London, UK); Suinesiaputra, Avan (Department of Anatomy and Medical Imaging, University of Auckland, Auckland, New Zealand); Baeßler, Bettina (Department of Radiology, University Hospital of Cologne, Cologne, Germany; Institute of Clinical Radiology and Nuclear Medicine, University Medical Centre Mannheim, Medical Faculty Mannheim, Heidelberg University, Mannheim, Germany); Nezafat, Reza (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Centre, Harvard Medical School, Boston, MA, USA); Išgum, Ivana (Image Sciences Institute, University Medical Center Utrecht, Utrecht, Netherlands); Young, Alistair A. (Department of Anatomy and Medical Imaging, University of Auckland, Auckland, New Zealand; Department of Biomedical Engineering, King’s College London, London, UK)","Leiner, Tim (University Medical Center Utrecht)","Leiner, Tim (University Medical Center Utrecht); Rueckert, Daniel (Imperial College London); Suinesiaputra, Avan (University of Auckland); Baeßler, Bettina (University Hospital Cologne; University Medical Centre Mannheim); Nezafat, Reza (Harvard University); Išgum, Ivana (University Medical Center Utrecht); Young, Alistair A. (University of Auckland; King's College London)",119,98,8.12,49.91,https://jcmr-online.biomedcentral.com/track/pdf/10.1186/s12968-019-0575-y,https://app.dimensions.ai/details/publication/pub.1121552140,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
5915,pub.1121230317,10.1161/circimaging.119.009759,31547690,,"Multicenter, Scan-Rescan, Human and Machine Learning CMR Study to Test Generalizability and Precision in Imaging Biomarker Analysis",,,,Circulation Cardiovascular Imaging,,"Biomarkers; Humans; Machine Learning; Magnetic Resonance Imaging, Cine; Radionuclide Imaging",2019-09-24,2019,2019-09-24,2019-10,12,10,e009759,All OA, Bronze,Article,"Colletti, Patrick M","Colletti, Patrick M (Department of Radiology, Keck School of Medicine of USC, Keck Medical Center of USC, University of Southern California, Los Angeles, CA.)",,"Colletti, Patrick M (University of Southern California)",6,2,0.32,2.9,https://www.ahajournals.org/doi/pdf/10.1161/CIRCIMAGING.119.009759,https://app.dimensions.ai/details/publication/pub.1121230317,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,,,,
4533,pub.1121217379,10.1161/circimaging.119.009214,31547689,,"A Multicenter, Scan-Rescan, Human and Machine Learning CMR Study to Test Generalizability and Precision in Imaging Biomarker Analysis","BACKGROUND: Automated analysis of cardiac structure and function using machine learning (ML) has great potential, but is currently hindered by poor generalizability. Comparison is traditionally against clinicians as a reference, ignoring inherent human inter- and intraobserver error, and ensuring that ML cannot demonstrate superiority. Measuring precision (scan:rescan reproducibility) addresses this. We compared precision of ML and humans using a multicenter, multi-disease, scan:rescan cardiovascular magnetic resonance data set.
METHODS: One hundred ten patients (5 disease categories, 5 institutions, 2 scanner manufacturers, and 2 field strengths) underwent scan:rescan cardiovascular magnetic resonance (96% within one week). After identification of the most precise human technique, left ventricular chamber volumes, mass, and ejection fraction were measured by an expert, a trained junior clinician, and a fully automated convolutional neural network trained on 599 independent multicenter disease cases. Scan:rescan coefficient of variation and 1000 bootstrapped 95% CIs were calculated and compared using mixed linear effects models.
RESULTS: Clinicians can be confident in detecting a 9% change in left ventricular ejection fraction, with greater than half of coefficient of variation attributable to intraobserver variation. Expert, trained junior, and automated scan:rescan precision were similar (for left ventricular ejection fraction, coefficient of variation 6.1 [5.2%-7.1%], P=0.2581; 8.3 [5.6%-10.3%], P=0.3653; 8.8 [6.1%-11.1%], P=0.8620). Automated analysis was 186× faster than humans (0.07 versus 13 minutes).
CONCLUSIONS: Automated ML analysis is faster with similar precision to the most precise human techniques, even when challenged with real-world scan:rescan data. Assessment of multicenter, multi-vendor, multi-field strength scan:rescan data (available at www.thevolumesresource.com) permits a generalizable assessment of ML precision and may facilitate direct translation of ML to clinical practice.",,,Circulation Cardiovascular Imaging,,"Biomarkers; Cardiovascular Diseases; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Reproducibility of Results; Stroke Volume; Ventricular Dysfunction, Left",2019-09-24,2019,2019-09-24,2019-10,12,10,e009214,All OA, Hybrid,Article,"Bhuva, Anish; Bai, Wenjia; Lau, Clement; Davies, Rhodri; Ye, Yang; Bulluck, Heeraj; McAlindon, Elisa; Culotta, Veronica; Swoboda, Peter; Captur, Gabriella; Treibel, Thomas; Augusto, Joao; Knott, Kristopher; Seraphim, Andreas; Cole, Graham; Petersen, Steffen; Edwards, Nicola; Greenwood, John; Bucciarelli-Ducci, Chiara; Hughes, Alun; Rueckert, Daniel; Moon, James; Manisty, Charlotte","Bhuva, Anish (Institute for Cardiovascular Science, University College London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Bai, Wenjia (Institute for Cardiovascular Science, University College London, United Kingdom); Lau, Clement (Institute for Cardiovascular Science, University College London, United Kingdom); Davies, Rhodri (Institute for Cardiovascular Science, University College London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Ye, Yang (Institute for Cardiovascular Science, University College London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Bulluck, Heeraj (Institute for Cardiovascular Science, University College London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); McAlindon, Elisa (Institute for Cardiovascular Science, University College London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Culotta, Veronica (Institute for Cardiovascular Science, University College London, United Kingdom); Swoboda, Peter (Institute for Cardiovascular Science, University College London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Captur, Gabriella (Institute for Cardiovascular Science, University College London, United Kingdom; Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Treibel, Thomas (Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom; Imperial College London, South Kensington Campus, United Kingdom. William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, United Kingdom); Augusto, Joao (Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Knott, Kristopher (Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom; Department of Cardiology, Sir Run Run Shaw Hospital, Zhejiang University, Hangzhou, People's Republic of China); Seraphim, Andreas (Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom); Cole, Graham (Department of Cardiovascular Imaging, Barts Heart Centre, Barts Health NHS Trust, London, United Kingdom; Imperial College London, South Kensington Campus, United Kingdom. William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University of London, United Kingdom); Petersen, Steffen (Data Science Institute and Department of Medicine (W.B.),Department of Computing); Edwards, Nicola (Data Science Institute and Department of Medicine); Greenwood, John (Bristol Heart Institute, Bristol NIHR Biomedical Research Centre, University Hospitals Bristol NHS Trust and Universityof Bristol, United Kingdom; Heart and Lung Centre, New Cross Hospital, Wolverhampton, United Kingdom); Bucciarelli-Ducci, Chiara (Bristol Heart Institute, Bristol NIHR Biomedical Research Centre, University Hospitals Bristol NHS Trust and Universityof Bristol, United Kingdom); Hughes, Alun (Multidisciplinary Cardiovascular Research Centre and Division of Biomedical Imaging, Leeds Institute of Cardiovascularand Metabolic Medicine, University of Leeds, United Kingdom); Rueckert, Daniel (Multidisciplinary Cardiovascular Research Centre and Division of Biomedical Imaging, Leeds Institute of Cardiovascularand Metabolic Medicine, University of Leeds, United Kingdom); Moon, James (Imperial College London, National Heart and Lung Institute, Hammersmith Hospital, United Kingdom); Manisty, Charlotte (Auckland City Hospital, New Zealand and Institute of Cardiovascular Science, University of Birmingham)",,"Bhuva, Anish (University College London; St Bartholomew's Hospital); Bai, Wenjia (University College London); Lau, Clement (University College London); Davies, Rhodri (University College London; St Bartholomew's Hospital); Ye, Yang (University College London; St Bartholomew's Hospital); Bulluck, Heeraj (University College London; St Bartholomew's Hospital); McAlindon, Elisa (University College London; St Bartholomew's Hospital); Culotta, Veronica (University College London); Swoboda, Peter (University College London; St Bartholomew's Hospital); Captur, Gabriella (University College London; St Bartholomew's Hospital); Treibel, Thomas (St Bartholomew's Hospital); Augusto, Joao (St Bartholomew's Hospital); Knott, Kristopher (St Bartholomew's Hospital; Sir Run Run Shaw Hospital; Zhejiang University); Seraphim, Andreas (St Bartholomew's Hospital); Cole, Graham (St Bartholomew's Hospital); Petersen, Steffen (); Edwards, Nicola (); Greenwood, John (NIHR Bristol Biomedical Research Centre; New Cross Hospital); Bucciarelli-Ducci, Chiara (NIHR Bristol Biomedical Research Centre); Hughes, Alun (University of Leeds); Rueckert, Daniel (University of Leeds); Moon, James (Imperial College London; Hammersmith Hospital); Manisty, Charlotte (Auckland City Hospital; University of Birmingham)",61,39,3.76,25.59,https://www.ahajournals.org/doi/pdf/10.1161/CIRCIMAGING.119.009214,https://app.dimensions.ai/details/publication/pub.1121217379,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,3 Good Health and Well Being,,,,,,,,,
1581,pub.1121047434,10.48550/arxiv.1909.06726,,,MSU-Net: Multiscale Statistical U-Net for Real-time 3D Cardiac MRI Video  Segmentation,"Cardiac magnetic resonance imaging (MRI) is an essential tool for MRI-guided
surgery and real-time intervention. The MRI videos are expected to be segmented
on-the-fly in real practice. However, existing segmentation methods would
suffer from drastic accuracy loss when modified for speedup. In this work, we
propose Multiscale Statistical U-Net (MSU-Net) for real-time 3D MRI video
segmentation in cardiac surgical guidance. Our idea is to model the input
samples as multiscale canonical form distributions for speedup, while the
spatio-temporal correlation is still fully utilized. A parallel statistical
U-Net is then designed to efficiently process these distributions. The fast
data sampling and efficient parallel structure of MSU-Net endorse the fast and
accurate inference. Compared with vanilla U-Net and a modified state-of-the-art
method GridNet, our method achieves up to 268% and 237% speedup with 1.6% and
3.6% increased Dice scores.",,,arXiv,,,2019-09-14,2019,,,,,,All OA, Green,Preprint,"Wang, Tianchen; Xiong, Jinjun; Xu, Xiaowei; Jiang, Meng; Shi, Yiyu; Yuan, Haiyun; Huang, Meiping; Zhuang, Jian","Wang, Tianchen (); Xiong, Jinjun (); Xu, Xiaowei (); Jiang, Meng (); Shi, Yiyu (); Yuan, Haiyun (); Huang, Meiping (); Zhuang, Jian ()",,"Wang, Tianchen (); Xiong, Jinjun (); Xu, Xiaowei (); Jiang, Meng (); Shi, Yiyu (); Yuan, Haiyun (); Huang, Meiping (); Zhuang, Jian ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1121047434,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 40 Engineering, 46 Information and Computing Sciences,,,,,,,,
173,pub.1120863607,10.4995/thesis/10251/124973,,,Computational modelling of the human heart and multiscale simulation of its electrophysiological activity aimed at the treatment of cardiac arrhythmias related to ischaemia and Infarction,,,,,,,2019-09,2019,,,,,,Closed,Article,"Pérez, Alejandro Daniel López","Pérez, Alejandro Daniel López ()",,"Pérez, Alejandro Daniel López ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120863607,32 Biomedical and Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,
1348,pub.1120764801,10.48550/arxiv.1908.11569,,,Revisiting CycleGAN for semi-supervised segmentation,"In this work, we study the problem of training deep networks for semantic
image segmentation using only a fraction of annotated images, which may
significantly reduce human annotation efforts. Particularly, we propose a
strategy that exploits the unpaired image style transfer capabilities of
CycleGAN in semi-supervised segmentation. Unlike recent works using adversarial
learning for semi-supervised segmentation, we enforce cycle consistency to
learn a bidirectional mapping between unpaired images and segmentation masks.
This adds an unsupervised regularization effect that boosts the segmentation
performance when annotated data is limited. Experiments on three different
public segmentation benchmarks (PASCAL VOC 2012, Cityscapes and ACDC)
demonstrate the effectiveness of the proposed method. The proposed model
achieves 2-4% of improvement with respect to the baseline and outperforms
recent approaches for this task, particularly in low labeled data regime.",,,arXiv,,,2019-08-30,2019,,,,,,All OA, Green,Preprint,"Mondal, Arnab Kumar; Agarwal, Aniket; Dolz, Jose; Desrosiers, Christian","Mondal, Arnab Kumar (); Agarwal, Aniket (); Dolz, Jose (); Desrosiers, Christian ()",,"Mondal, Arnab Kumar (); Agarwal, Aniket (); Dolz, Jose (); Desrosiers, Christian ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120764801,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1619,pub.1120727262,10.48550/arxiv.1908.11330,,,Temporal Consistency Objectives Regularize the Learning of Disentangled  Representations,"There has been an increasing focus in learning interpretable feature
representations, particularly in applications such as medical image analysis
that require explainability, whilst relying less on annotated data (since
annotations can be tedious and costly). Here we build on recent innovations in
style-content representations to learn anatomy, imaging characteristics
(appearance) and temporal correlations. By introducing a self-supervised
objective of predicting future cardiac phases we improve disentanglement. We
propose a temporal transformer architecture that given an image conditioned on
phase difference, it predicts a future frame. This forces the anatomical
decomposition to be consistent with the temporal cardiac contraction in cine
MRI and to have semantic meaning with less need for annotations. We demonstrate
that using this regularization, we achieve competitive results and improve
semi-supervised segmentation, especially when very few labelled data are
available. Specifically, we show Dice increase of up to 19\% and 7\% compared
to supervised and semi-supervised approaches respectively on the ACDC dataset.
Code is available at: https://github.com/gvalvano/sdtnet .",,,arXiv,,,2019-08-29,2019,,,,,,All OA, Green,Preprint,"Valvano, Gabriele; Chartsias, Agisilaos; Leo, Andrea; Tsaftaris, Sotirios A.","Valvano, Gabriele (); Chartsias, Agisilaos (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",,"Valvano, Gabriele (); Chartsias, Agisilaos (); Leo, Andrea (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120727262,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1457,pub.1120639539,10.48550/arxiv.1908.09262,,,Recon-GLGAN: A Global-Local context based Generative Adversarial Network  for MRI Reconstruction,"Magnetic resonance imaging (MRI) is one of the best medical imaging
modalities as it offers excellent spatial resolution and soft-tissue contrast.
But, the usage of MRI is limited by its slow acquisition time, which makes it
expensive and causes patient discomfort. In order to accelerate the
acquisition, multiple deep learning networks have been proposed. Recently,
Generative Adversarial Networks (GANs) have shown promising results in MRI
reconstruction. The drawback with the proposed GAN based methods is it does not
incorporate the prior information about the end goal which could help in better
reconstruction. For instance, in the case of cardiac MRI, the physician would
be interested in the heart region which is of diagnostic relevance while
excluding the peripheral regions. In this work, we show that incorporating
prior information about a region of interest in the model would offer better
performance. Thereby, we propose a novel GAN based architecture, Reconstruction
Global-Local GAN (Recon-GLGAN) for MRI reconstruction. The proposed model
contains a generator and a context discriminator which incorporates global and
local contextual information from images. Our model offers significant
performance improvement over the baseline models. Our experiments show that the
concept of a context discriminator can be extended to existing GAN based
reconstruction models to offer better performance. We also demonstrate that the
reconstructions from the proposed method give segmentation results similar to
fully sampled images.",,,arXiv,,,2019-08-25,2019,,,,,,All OA, Green,Preprint,"Murugesan, Balamurali; S, Vijaya Raghavan; Sarveswaran, Kaushik; Ram, Keerthi; Sivaprakasam, Mohanasankar","Murugesan, Balamurali (); S, Vijaya Raghavan (); Sarveswaran, Kaushik (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",,"Murugesan, Balamurali (); S, Vijaya Raghavan (); Sarveswaran, Kaushik (); Ram, Keerthi (); Sivaprakasam, Mohanasankar ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120639539,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1620,pub.1123626020,10.1145/3364836.3364860,,,Conditional Convolution Generative Adversarial Network for Bi-ventricle Segmentation in Cardiac MR Images,"Accurate segmentation of bi-ventricle from cardiac magnetic resonance images can provide assistance in estimation of clinical parameters and disease diagnosis for doctors. In this paper, we propose an automated and concurrent bi-ventricle segmentation method. First, we obtain region of interest (ROI) extraction for original cardiac image from large size to small size. Then we employ the conditional convolution generative adversarial network (CCGAN), which takes the extracted ROI as input, to generate mask of segmentation. The discriminator competes with the generator on the condition of the mask source to optimize the segmentation result. Finally, we get the cardiac segmentation similar to the gold standard. The proposed method is trained and tested on the data from automated cardiac diagnosis challenge (ACDC 2017). Experiment result shows our method produce better evaluation metrics compared with other advanced researches and demonstrate the effectiveness.",,,,Proceedings of the Third International Symposium on Image Computing and Digital Medicine,,2019-08-24,2019,2019-08-24,2019-08-24,,,118-122,Closed,Proceeding,"Zhang, Haoran; Cao, Xuehao; Xu, Lisheng; Qi, Lin","Zhang, Haoran (College of Medicine and Biological Information Engineering, Northeastern University, P.R China); Cao, Xuehao (College of Medicine and Biological Information Engineering, Northeastern University, P.R China); Xu, Lisheng (College of Medicine and Biological Information Engineering, Northeastern University, P.R China); Qi, Lin (College of Medicine and Biological Information Engineering, Northeastern University, P.R China)",,"Zhang, Haoran (Northeastern University); Cao, Xuehao (Northeastern University); Xu, Lisheng (Northeastern University); Qi, Lin (Northeastern University)",5,4,,2.1,,https://app.dimensions.ai/details/publication/pub.1123626020,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,,
1516,pub.1120414735,10.48550/arxiv.1908.06498,,,Weakly Supervised Segmentation by A Deep Geodesic Prior,"The performance of the state-of-the-art image segmentation methods heavily
relies on the high-quality annotations, which are not easily affordable,
particularly for medical data. To alleviate this limitation, in this study, we
propose a weakly supervised image segmentation method based on a deep geodesic
prior. We hypothesize that integration of this prior information can reduce the
adverse effects of weak labels in segmentation accuracy. Our proposed algorithm
is based on a prior information, extracted from an auto-encoder, trained to map
objects geodesic maps to their corresponding binary maps. The obtained
information is then used as an extra term in the loss function of the
segmentor. In order to show efficacy of the proposed strategy, we have
experimented segmentation of cardiac substructures with clean and two levels of
noisy labels (L1, L2). Our experiments showed that the proposed algorithm
boosted the performance of baseline deep learning-based segmentation for both
clean and noisy labels by 4.4%, 4.6%(L1), and 6.3%(L2) in dice score,
respectively. We also showed that the proposed method was more robust in the
presence of high-level noise due to the existence of shape priors.",,,arXiv,,,2019-08-18,2019,,,,,,All OA, Green,Preprint,"Mortazi, Aliasghar; Khosravan, Naji; Torigian, Drew A.; Kurugol, Sila; Bagci, Ulas","Mortazi, Aliasghar (); Khosravan, Naji (); Torigian, Drew A. (); Kurugol, Sila (); Bagci, Ulas ()",,"Mortazi, Aliasghar (); Khosravan, Naji (); Torigian, Drew A. (); Kurugol, Sila (); Bagci, Ulas ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120414735,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
754,pub.1120415165,10.48550/arxiv.1908.06948,,,Deep Learning for Segmentation using an Open Large-Scale Dataset in 2D  Echocardiography,"Delineation of the cardiac structures from 2D echocardiographic images is a
common clinical task to establish a diagnosis. Over the past decades, the
automation of this task has been the subject of intense research. In this
paper, we evaluate how far the state-of-the-art encoder-decoder deep
convolutional neural network methods can go at assessing 2D echocardiographic
images, i.e segmenting cardiac structures as well as estimating clinical
indices, on a dataset especially designed to answer this objective. We
therefore introduce the Cardiac Acquisitions for Multi-structure Ultrasound
Segmentation (CAMUS) dataset, the largest publicly-available and
fully-annotated dataset for the purpose of echocardiographic assessment. The
dataset contains two and four-chamber acquisitions from 500 patients with
reference measurements from one cardiologist on the full dataset and from three
cardiologists on a fold of 50 patients. Results show that encoder-decoder based
architectures outperform state-of-the-art non-deep learning methods and
faithfully reproduce the expert analysis for the end-diastolic and end-systolic
left ventricular volumes, with a mean correlation of 0.95 and an absolute mean
error of 9.5 ml. Concerning the ejection fraction of the left ventricle,
results are more contrasted with a mean correlation coefficient of 0.80 and an
absolute mean error of 5.6 %. Although these results are below the
inter-observer scores, they remain slightly worse than the intra-observer's
ones. Based on this observation, areas for improvement are defined, which open
the door for accurate and fully-automatic analysis of 2D echocardiographic
images.",,,arXiv,,,2019-08-16,2019,,,,,,All OA, Green,Preprint,"Leclerc, Sarah; Smistad, Erik; Pedrosa, João; Østvik, Andreas; Cervenansky, Frederic; Espinosa, Florian; Espeland, Torvald; Berg, Erik Andreas Rye; Jodoin, Pierre-Marc; Grenier, Thomas; Lartizien, Carole; D'hooge, Jan; Lovstakken, Lasse; Bernard, Olivier","Leclerc, Sarah (); Smistad, Erik (); Pedrosa, João (); Østvik, Andreas (); Cervenansky, Frederic (); Espinosa, Florian (); Espeland, Torvald (); Berg, Erik Andreas Rye (); Jodoin, Pierre-Marc (); Grenier, Thomas (); Lartizien, Carole (); D'hooge, Jan (); Lovstakken, Lasse (); Bernard, Olivier ()",,"Leclerc, Sarah (); Smistad, Erik (); Pedrosa, João (); Østvik, Andreas (); Cervenansky, Frederic (); Espinosa, Florian (); Espeland, Torvald (); Berg, Erik Andreas Rye (); Jodoin, Pierre-Marc (); Grenier, Thomas (); Lartizien, Carole (); D'hooge, Jan (); Lovstakken, Lasse (); Bernard, Olivier ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120415165,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 46 Information and Computing Sciences,,,,,,,,,
649,pub.1120526991,10.48550/arxiv.1908.07656,,,Survey on Deep Neural Networks in Speech and Vision Systems,"This survey presents a review of state-of-the-art deep neural network
architectures, algorithms, and systems in vision and speech applications.
Recent advances in deep artificial neural network algorithms and architectures
have spurred rapid innovation and development of intelligent vision and speech
systems. With availability of vast amounts of sensor data and cloud computing
for processing and training of deep neural networks, and with increased
sophistication in mobile and embedded technology, the next-generation
intelligent systems are poised to revolutionize personal and commercial
computing. This survey begins by providing background and evolution of some of
the most successful deep learning models for intelligent vision and speech
systems to date. An overview of large-scale industrial research and development
efforts is provided to emphasize future trends and prospects of intelligent
vision and speech systems. Robust and efficient intelligent systems demand
low-latency and high fidelity in resource-constrained hardware platforms such
as mobile devices, robots, and automobiles. Therefore, this survey also
provides a summary of key challenges and recent successes in running deep
neural networks on hardware-restricted platforms, i.e. within limited memory,
battery life, and processing capabilities. Finally, emerging applications of
vision and speech across disciplines such as affective computing, intelligent
transportation, and precision medicine are discussed. To our knowledge, this
paper provides one of the most comprehensive surveys on the latest developments
in intelligent vision and speech applications from the perspectives of both
software and hardware systems. Many of these emerging technologies using deep
neural networks show tremendous promise to revolutionize research and
development for future vision and speech systems.",,,arXiv,,,2019-08-16,2019,,,,,,All OA, Green,Preprint,"Alam, Mahbubul; Samad, Manar D.; Vidyaratne, Lasitha; Glandon, Alexander; Iftekharuddin, Khan M.","Alam, Mahbubul (); Samad, Manar D. (); Vidyaratne, Lasitha (); Glandon, Alexander (); Iftekharuddin, Khan M. ()",,"Alam, Mahbubul (); Samad, Manar D. (); Vidyaratne, Lasitha (); Glandon, Alexander (); Iftekharuddin, Khan M. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120526991,46 Information and Computing Sciences, 4602 Artificial Intelligence, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,
1134,pub.1120398564,10.48550/arxiv.1908.05770,,,Discretely-constrained deep network for weakly supervised segmentation,"An efficient strategy for weakly-supervised segmentation is to impose
constraints or regularization priors on target regions. Recent efforts have
focused on incorporating such constraints in the training of convolutional
neural networks (CNN), however this has so far been done within a continuous
optimization framework. Yet, various segmentation constraints and
regularization can be modeled and optimized more efficiently in a discrete
formulation. This paper proposes a method, based on the alternating direction
method of multipliers (ADMM) algorithm, to train a CNN with discrete
constraints and regularization priors. This method is applied to the
segmentation of medical images with weak annotations, where both size
constraints and boundary length regularization are enforced. Experiments on a
benchmark cardiac segmentation dataset show our method to yield a performance
near to full supervision.",,,arXiv,,,2019-08-15,2019,,,,,,All OA, Green,Preprint,"Peng, Jizong; Kervadec, Hoel; Dolz, Jose; Ayed, Ismail Ben; Pedersoli, Marco; Desrosiers, Christian","Peng, Jizong (); Kervadec, Hoel (); Dolz, Jose (); Ayed, Ismail Ben (); Pedersoli, Marco (); Desrosiers, Christian ()",,"Peng, Jizong (); Kervadec, Hoel (); Dolz, Jose (); Ayed, Ismail Ben (); Pedersoli, Marco (); Desrosiers, Christian ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120398564,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
4297,pub.1117787343,10.1002/mp.13699,31274194,,Knowledge‐based and deep learning‐based automated chest wall segmentation in magnetic resonance images of extremely dense breasts,"PURPOSE: Segmentation of the chest wall, is an important component of methods for automated analysis of breast magnetic resonance imaging (MRI). Methods reported to date show promising results but have difficulties delineating the muscle border correctly in breasts with a large proportion of fibroglandular tissue (i.e., dense breasts). Knowledge-based methods (KBMs) as well as methods based on deep learning have been proposed, but a systematic comparison of these approaches within one cohort of images is currently lacking. Therefore, we developed a KBM and a deep learning method for segmentation of the chest wall in MRI of dense breasts and compared their performances.
METHODS: Two automated methods were developed, an optimized KBM incorporating heuristics aimed at shape, location, and gradient features, and a deep learning-based method (DLM) using a dilated convolution neural network. A data set of 115 T1-weighted MR images was randomly selected from MR images of women with extremely dense breasts (ACR BI-RADS category 4) participating in a screening trial of women (mean age 56.6 yr, range 49.5-75.2 yr) with dense breasts. Manual segmentations of the chest wall, acquired under supervision of an experienced breast radiologist, were available for all data sets. Both methods were optimized using the same randomly selected 36 MRI data sets from a total of 115 data sets. Each MR data set consisted of 179 transversal images with voxel size 0.64 mm3  × 0.64 mm3  × 1.00 mm3 . In the remaining 79 data sets, the results of both segmentation methods were qualitatively evaluated. A radiologist reviewed the segmentation results of both methods in all transversal images (n = 14 141) and determined whether the result would impact the ability to accurately determine the volume of fibroglandular and fatty tissue and whether segmentations masked breast regions that might harbor lesions. When no relevant deviation was detected, the result was considered successful. In addition, all segmentations were quantitatively assessed using the Dice similarity coefficient (DSC) and Hausdorff distance (HD), 95th percentile of the Hausdorff distance (HD95), false positive fraction (FPF), and false negative fraction (FNF) metrics.
RESULTS: According to the radiologist's evaluation, the DLM had a significantly higher success rate than the KBM (81.6% vs 78.4%, P < 0.01). The success rate was further improved to 92.1% by combining both methods. Similarly, the DLM had significantly lower values for FNF (0.003 ± 0.003 vs 0.009 ± 0.011, P < 0.01) and HD95 (2.58 ± 1.78 mm vs 3.37 ± 2.11, P < 0.01). However, the KBM resulted in a significantly lower FPF than the DLM (0.018 ± 0.009 vs 0.030 ± 0.009, P < 0.01).There was no significant difference between the KBM and DLM in terms of DSC (0.982 ± 0.006 vs 0.984 ± 0.008, P = 0.08) or HD (24.14 ± 20.69 mm vs 12.81 ± 27.28 mm, P = 0.05).
CONCLUSION: Both optimized knowledge-based and DLM showed good results to segment the pectoral muscle in women with dense breasts. Qualitatively assessed, the DLM was the most robust method. A quantitative comparison, however, did not indicate a preference for one method over the other.","The authors acknowledge the study participants for their contributions. This study is financially supported by KWF, grant number UU‐2014‐715,1 and used data acquired during the DENSE trial. The DENSE trial was supported by the regional screening organizations, Volpara Solutions, the Dutch Expert Centre for Screening, and the National Institute for Public Health and the Environment. The DENSE trial is financially supported by the University Medical Center Utrecht (Project number: UMCU DENSE), the Netherlands Organization for Health Research and Development (ZonMw, Project numbers: ZONMW‐200320002‐UMCU and ZonMW Preventie 50‐53125‐98‐014), the Dutch Cancer Society (KWF Kankerbestrijding, Project numbers: DCS‐UU‐2009‐4348, UU‐2014‐6859, and UU2014‐7151), the Dutch Pink Ribbon/A Sister&#x27;s Hope (Project number: Pink Ribbon‐10074), Bayer AG Pharmaceuticals, Radiology (Project number: BSP‐DENSE), and Stichting Kankerpreventie Midden‐West.",,Medical Physics,,"Aged; Aged, 80 and over; Automation; Breast; Breast Density; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Middle Aged; Thoracic Wall",2019-08-10,2019,2019-08-10,2019-10,46,10,4405-4416,All OA, Hybrid,Article,"Verburg, Erik; Wolterink, Jelmer M.; Waard, Stephanie N.; Išgum, Ivana; Gils, Carla H.; Veldhuis, Wouter B.; Gilhuijs, Kenneth G. A.","Verburg, Erik (Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584 CX, the Netherlands); Wolterink, Jelmer M. (Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584 CX, the Netherlands); Waard, Stephanie N. (Department of Radiology, University Medical Center Utrecht, Utrecht University, Utrecht, 3584 CX, the Netherlands); Išgum, Ivana (Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584 CX, the Netherlands); Gils, Carla H. (Julius Center for Health Sciences and Primary Care, University Medical Center Utrecht, Utrecht University, Utrecht, 3584 CX, the Netherlands); Veldhuis, Wouter B. (Department of Radiology, University Medical Center Utrecht, Utrecht University, Utrecht, 3584 CX, the Netherlands); Gilhuijs, Kenneth G. A. (Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584 CX, the Netherlands)","Verburg, Erik (Utrecht University; University Medical Center Utrecht); Gilhuijs, Kenneth G. A. (Utrecht University; University Medical Center Utrecht)","Verburg, Erik (Utrecht University; University Medical Center Utrecht); Wolterink, Jelmer M. (Utrecht University; University Medical Center Utrecht); Waard, Stephanie N. (Utrecht University; University Medical Center Utrecht); Išgum, Ivana (Utrecht University; University Medical Center Utrecht); Gils, Carla H. (Utrecht University; University Medical Center Utrecht); Veldhuis, Wouter B. (Utrecht University; University Medical Center Utrecht); Gilhuijs, Kenneth G. A. (Utrecht University; University Medical Center Utrecht)",4,3,0.24,1.4,https://doi.org/10.1002/mp.13699,https://app.dimensions.ai/details/publication/pub.1117787343,40 Engineering, 4003 Biomedical Engineering, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
3451,pub.1120008576,10.1016/j.media.2019.101537,31446280,PMC6839613,Evaluation of algorithms for Multi-Modality Whole Heart Segmentation: An open-access grand challenge,"Knowledge of whole heart anatomy is a prerequisite for many clinical applications. Whole heart segmentation (WHS), which delineates substructures of the heart, can be very valuable for modeling and analysis of the anatomy and functions of the heart. However, automating this segmentation can be challenging due to the large variation of the heart shape, and different image qualities of the clinical data. To achieve this goal, an initial set of training data is generally needed for constructing priors or for training. Furthermore, it is difficult to perform comparisons between different methods, largely due to differences in the datasets and evaluation metrics used. This manuscript presents the methodologies and evaluation results for the WHS algorithms selected from the submissions to the Multi-Modality Whole Heart Segmentation (MM-WHS) challenge, in conjunction with MICCAI 2017. The challenge provided 120 three-dimensional cardiac images covering the whole heart, including 60 CT and 60 MRI volumes, all acquired in clinical environments with manual delineation. Ten algorithms for CT data and eleven algorithms for MRI data, submitted from twelve groups, have been evaluated. The results showed that the performance of CT WHS was generally better than that of MRI WHS. The segmentation of the substructures for different categories of patients could present different levels of challenge due to the difference in imaging and variations of heart shapes. The deep learning (DL)-based methods demonstrated great potential, though several of them reported poor results in the blinded evaluation. Their performance could vary greatly across different network structures and training strategies. The conventional algorithms, mainly based on multi-atlas segmentation, demonstrated good performance, though the accuracy and computational efficiency could be limited. The challenge, including provision of the annotated training data and the blinded evaluation for submitted algorithms on the test data, continues as an ongoing benchmarking resource via its homepage (www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mmwhs/).","This work was funded in part by the National Natural Science Foundation of China (NSFC) grant (61971142), the Science and Technology Commission of Shanghai Municipality grant (17JC1401600) and the British Heart Foundation Project grant (PG/16/78/32402).",,Medical Image Analysis,,"Algorithms; Datasets as Topic; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Tomography, X-Ray Computed",2019-08-01,2019,2019-08-01,2019-12,58,,101537,All OA, Hybrid,Article,"Zhuang, Xiahai; Li, Lei; Payer, Christian; Štern, Darko; Urschler, Martin; Heinrich, Mattias P.; Oster, Julien; Wang, Chunliang; Smedby, Örjan; Bian, Cheng; Yang, Xin; Heng, Pheng-Ann; Mortazi, Aliasghar; Bagci, Ulas; Yang, Guanyu; Sun, Chenchen; Galisot, Gaetan; Ramel, Jean-Yves; Brouard, Thierry; Tong, Qianqian; Si, Weixin; Liao, Xiangyun; Zeng, Guodong; Shi, Zenglin; Zheng, Guoyan; Wang, Chengjia; MacGillivray, Tom; Newby, David; Rhode, Kawal; Ourselin, Sebastien; Mohiaddin, Raad; Keegan, Jennifer; Firmin, David; Yang, Guang","Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, 200433, China; Fudan-Xinzailing Joint Research Center for Big Data, Fudan University, Shanghai, 200433, China); Li, Lei (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China); Payer, Christian (Institute of Computer Graphics and Vision, Graz University of Technology, Graz, 8010, Austria); Štern, Darko (Ludwig Boltzmann Institute for Clinical Forensic Imaging, Graz, 8010, Austria); Urschler, Martin (Ludwig Boltzmann Institute for Clinical Forensic Imaging, Graz, 8010, Austria); Heinrich, Mattias P. (Institute of Medical Informatics, University of Lubeck, Lubeck, 23562, Germany); Oster, Julien (Inserm, Université de Lorraine, IADI, U1254, Nancy, France); Wang, Chunliang (Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Stockholm SE-14152, Sweden); Smedby, Örjan (Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Stockholm SE-14152, Sweden); Bian, Cheng (School of Biomed. Eng., Health Science Centre, Shenzhen University, Shenzhen, 518060, China); Yang, Xin (Dept. of Comp. Sci. and Eng., The Chinese University of Hong Kong, Hong Kong, China); Heng, Pheng-Ann (Dept. of Comp. Sci. and Eng., The Chinese University of Hong Kong, Hong Kong, China); Mortazi, Aliasghar (Center for Research in Computer Vision (CRCV), University of Central Florida, Orlando, 32816, U.S.); Bagci, Ulas (Center for Research in Computer Vision (CRCV), University of Central Florida, Orlando, 32816, U.S.); Yang, Guanyu (School of Computer Science and Engineering, Southeast University, Nanjing, 210096, China); Sun, Chenchen (School of Computer Science and Engineering, Southeast University, Nanjing, 210096, China); Galisot, Gaetan (LIFAT (EA6300), Université de Tours, 64 avenue Jean Portalis, Tours, 37200, France); Ramel, Jean-Yves (LIFAT (EA6300), Université de Tours, 64 avenue Jean Portalis, Tours, 37200, France); Brouard, Thierry (LIFAT (EA6300), Université de Tours, 64 avenue Jean Portalis, Tours, 37200, France); Tong, Qianqian (School of Computer Science, Wuhan University, Wuhan, 430072, China); Si, Weixin (Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, SIAT, Shenzhen, China); Liao, Xiangyun (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China); Zeng, Guodong (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Institute for Surgical Technology & Biomechanics, University of Bern, Bern, 3014, Switzerland); Shi, Zenglin (Institute for Surgical Technology & Biomechanics, University of Bern, Bern, 3014, Switzerland); Zheng, Guoyan (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Institute for Surgical Technology & Biomechanics, University of Bern, Bern, 3014, Switzerland); Wang, Chengjia (BHF Centre for Cardiovascular Science, University of Edinburgh, Edinburgh, U.K.; Edinburgh Imaging Facility QMRI, University of Edinburgh, Edinburgh, U.K.); MacGillivray, Tom (Edinburgh Imaging Facility QMRI, University of Edinburgh, Edinburgh, U.K.); Newby, David (BHF Centre for Cardiovascular Science, University of Edinburgh, Edinburgh, U.K.; Edinburgh Imaging Facility QMRI, University of Edinburgh, Edinburgh, U.K.); Rhode, Kawal (School of Biomedical Engineering and Imaging Sciences, Kings College London, London, U.K.); Ourselin, Sebastien (School of Biomedical Engineering and Imaging Sciences, Kings College London, London, U.K.); Mohiaddin, Raad (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, London, U.K.); Keegan, Jennifer (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, London, U.K.); Firmin, David (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, London, U.K.); Yang, Guang (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, London, U.K.)","Zhuang, Xiahai (Fudan University; Fudan University); Li, Lei (Shanghai Jiao Tong University); Yang, Guang (Royal Brompton Hospital; Imperial College London)","Zhuang, Xiahai (Fudan University; Fudan University); Li, Lei (Shanghai Jiao Tong University); Payer, Christian (Graz University of Technology); Štern, Darko (Ludwig Boltzmann Gesellschaft); Urschler, Martin (Ludwig Boltzmann Gesellschaft); Heinrich, Mattias P. (University of Lübeck); Oster, Julien (University of Lorraine); Wang, Chunliang (Royal Institute of Technology); Smedby, Örjan (Royal Institute of Technology); Bian, Cheng (Shenzhen University); Yang, Xin (Chinese University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong); Mortazi, Aliasghar (University of Central Florida); Bagci, Ulas (University of Central Florida); Yang, Guanyu (Southeast University); Sun, Chenchen (Southeast University); Galisot, Gaetan (); Ramel, Jean-Yves (); Brouard, Thierry (); Tong, Qianqian (Wuhan University); Si, Weixin (Shenzhen Institutes of Advanced Technology); Liao, Xiangyun (Shenzhen Institutes of Advanced Technology); Zeng, Guodong (Shanghai Jiao Tong University; University of Bern); Shi, Zenglin (University of Bern); Zheng, Guoyan (Shanghai Jiao Tong University; University of Bern); Wang, Chengjia (University of Edinburgh; University of Edinburgh); MacGillivray, Tom (University of Edinburgh); Newby, David (University of Edinburgh; University of Edinburgh); Rhode, Kawal (King's College London); Ourselin, Sebastien (King's College London); Mohiaddin, Raad (Royal Brompton Hospital; Imperial College London); Keegan, Jennifer (Royal Brompton Hospital; Imperial College London); Firmin, David (Royal Brompton Hospital; Imperial College London); Yang, Guang (Royal Brompton Hospital; Imperial College London)",151,112,8.46,63.33,https://doi.org/10.1016/j.media.2019.101537,https://app.dimensions.ai/details/publication/pub.1120008576,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
755,pub.1120111807,10.48550/arxiv.1908.00473,,,A Survey on Deep Learning of Small Sample in Biomedical Image Analysis,"The success of deep learning has been witnessed as a promising technique for
computer-aided biomedical image analysis, due to end-to-end learning framework
and availability of large-scale labelled samples. However, in many cases of
biomedical image analysis, deep learning techniques suffer from the small
sample learning (SSL) dilemma caused mainly by lack of annotations. To be more
practical for biomedical image analysis, in this paper we survey the key SSL
techniques that help relieve the suffering of deep learning by combining with
the development of related techniques in computer vision applications. In order
to accelerate the clinical usage of biomedical image analysis based on deep
learning techniques, we intentionally expand this survey to include the
explanation methods for deep models that are important to clinical decision
making. We survey the key SSL techniques by dividing them into five categories:
(1) explanation techniques, (2) weakly supervised learning techniques, (3)
transfer learning techniques, (4) active learning techniques, and (5)
miscellaneous techniques involving data augmentation, domain knowledge,
traditional shallow methods and attention mechanism. These key techniques are
expected to effectively support the application of deep learning in clinical
biomedical image analysis, and furtherly improve the analysis performance,
especially when large-scale annotated samples are not available. We bulid demos
at https://github.com/PengyiZhang/MIADeepSSL.",,,arXiv,,,2019-08-01,2019,,,,,,All OA, Green,Preprint,"Zhang, Pengyi; Zhong, Yunxin; Deng, Yulin; Tang, Xiaoying; Li, Xiaoqiong","Zhang, Pengyi (); Zhong, Yunxin (); Deng, Yulin (); Tang, Xiaoying (); Li, Xiaoqiong ()",,"Zhang, Pengyi (); Zhong, Yunxin (); Deng, Yulin (); Tang, Xiaoying (); Li, Xiaoqiong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120111807,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1515,pub.1120035600,10.48550/arxiv.1907.13524,,,Probabilistic Motion Modeling from Medical Image Sequences: Application  to Cardiac Cine-MRI,"We propose to learn a probabilistic motion model from a sequence of images.
Besides spatio-temporal registration, our method offers to predict motion from
a limited number of frames, useful for temporal super-resolution. The model is
based on a probabilistic latent space and a novel temporal dropout training
scheme. This enables simulation and interpolation of realistic motion patterns
given only one or any subset of frames of a sequence. The encoded motion also
allows to be transported from one subject to another without the need of
inter-subject registration. An unsupervised generative deformation model is
applied within a temporal convolutional network which leads to a diffeomorphic
motion model, encoded as a low-dimensional motion matrix. Applied to cardiac
cine-MRI sequences, we show improved registration accuracy and
spatio-temporally smoother deformations compared to three state-of-the-art
registration algorithms. Besides, we demonstrate the model's applicability to
motion transport by simulating a pathology in a healthy case. Furthermore, we
show an improved motion reconstruction from incomplete sequences compared to
linear and cubic interpolation.",,,arXiv,,,2019-07-31,2019,,,,,,All OA, Green,Preprint,"Krebs, Julian; Mansi, Tommaso; Ayache, Nicholas; Delingette, Hervé","Krebs, Julian (); Mansi, Tommaso (); Ayache, Nicholas (); Delingette, Hervé ()",,"Krebs, Julian (); Mansi, Tommaso (); Ayache, Nicholas (); Delingette, Hervé ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120035600,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,
4838,pub.1119983400,10.1155/2019/5636423,31467898,PMC6699314,A Deep Learning Segmentation Approach in Free-Breathing Real-Time Cardiac Magnetic Resonance Imaging,"OBJECTIVES: The purpose of this study was to segment the left ventricle (LV) blood pool, LV myocardium, and right ventricle (RV) blood pool of end-diastole and end-systole frames in free-breathing cardiac magnetic resonance (CMR) imaging. Automatic and accurate segmentation of cardiac structures could reduce the postprocessing time of cardiac function analysis.
METHOD: We proposed a novel deep learning network using a residual block for the segmentation of the heart and a random data augmentation strategy to reduce the training time and the problem of overfitting. Automated cardiac diagnosis challenge (ACDC) data were used for training, and the free-breathing CMR data were used for validation and testing.
RESULTS: The average Dice was 0.919 (LV), 0.806 (myocardium), and 0.818 (RV). The average IoU was 0.860 (LV), 0.699 (myocardium), and 0.761 (RV).
CONCLUSIONS: The proposed method may aid in the segmentation of cardiac images and improves the postprocessing efficiency of cardiac function analysis.","The authors gratefully thank all the participants and staff of the Affiliated Hospital of Guizhou Medical University. This work was supported partly by the National Natural Science Foundation of China (Grants nos. 81660298, 61661010, and 81760312), the 2011 Collaborative Innovation Program of Guizhou Province (no. 2015-04 to Zhu Zeng), the Nature Science Foundation of Guizhou Province (Qiankehe J No.20152044), the Joint Fund of Guizhou Province Department of Science Technology (NO. LH[2017]7208), and Doctoral Research Initiation Fund of the Affiliated Hospital of Guizhou Medical University.",,BioMed Research International,,"Adult; Algorithms; Deep Learning; Female; Heart; Heart Ventricles; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Respiration; Ventricular Function",2019-07-30,2019,2019-07-30,2019-07-30,2019,,5636423,All OA, Gold,Article,"Yang, Fan; Zhang, Yan; Lei, Pinggui; Wang, Lihui; Miao, Yuehong; Xie, Hong; Zeng, Zhu","Yang, Fan (Key Laboratory of Biology and Medical Engineering, Guizhou Medical University, Guiyang 550025, China; School of Biology & Engineering, Guizhou Medical University, Guiyang 550025, China); Zhang, Yan (Department of Radiology, The Affiliated Hospital of Guizhou Medical University, Guiyang 550004, China); Lei, Pinggui (Department of Radiology, The Affiliated Hospital of Guizhou Medical University, Guiyang 550004, China); Wang, Lihui (Key Laboratory of Intelligent Medical Image Analysis and Precise Diagnosis of Guizhou Province, School of Computer Science and Technology, Guizhou University, Guiyang 550025, China); Miao, Yuehong (Key Laboratory of Biology and Medical Engineering, Guizhou Medical University, Guiyang 550025, China; School of Biology & Engineering, Guizhou Medical University, Guiyang 550025, China); Xie, Hong (Department of Radiology, The Affiliated Hospital of Guizhou Medical University, Guiyang 550004, China); Zeng, Zhu (Key Laboratory of Biology and Medical Engineering, Guizhou Medical University, Guiyang 550025, China)","Lei, Pinggui (Affiliated Hospital of Guizhou Medical University); Wang, Lihui (Guizhou University)","Yang, Fan (Guiyang Medical University; Guiyang Medical University); Zhang, Yan (Affiliated Hospital of Guizhou Medical University); Lei, Pinggui (Affiliated Hospital of Guizhou Medical University); Wang, Lihui (Guizhou University); Miao, Yuehong (Guiyang Medical University; Guiyang Medical University); Xie, Hong (Affiliated Hospital of Guizhou Medical University); Zeng, Zhu (Guiyang Medical University)",20,15,1.14,9.67,https://doi.org/10.1155/2019/5636423,https://app.dimensions.ai/details/publication/pub.1119983400,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
1814,pub.1119960887,10.48550/arxiv.1907.12330,,,Conditioning Convolutional Segmentation Architectures with Non-Imaging  Data,"We compare two conditioning mechanisms based on concatenation and
feature-wise modulation to integrate non-imaging information into convolutional
neural networks for segmentation of anatomical structures. As a
proof-of-concept we provide the distribution of class labels obtained from
ground truth masks to ensure strong correlation between the conditioning data
and the segmentation maps. We evaluate the methods on the ACDC dataset, and
show that conditioning with non-imaging data improves performance of the
segmentation networks. We observed conditioning the U-Net architectures was
challenging, where no method gave significant improvement. However, the same
architecture without skip connections outperforms the baseline with
feature-wise modulation, and the relative performance increases as the training
size decreases.",,,arXiv,,,2019-07-29,2019,,,,,,All OA, Green,Preprint,"Jacenków, Grzegorz; Chartsias, Agisilaos; Mohr, Brian; Tsaftaris, Sotirios A.","Jacenków, Grzegorz (); Chartsias, Agisilaos (); Mohr, Brian (); Tsaftaris, Sotirios A. ()",,"Jacenków, Grzegorz (); Chartsias, Agisilaos (); Mohr, Brian (); Tsaftaris, Sotirios A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119960887,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1519,pub.1119821820,10.48550/arxiv.1907.09983,,,Learning Shape Priors for Robust Cardiac MR Segmentation from Multi-view  Images,"Cardiac MR image segmentation is essential for the morphological and
functional analysis of the heart. Inspired by how experienced clinicians assess
the cardiac morphology and function across multiple standard views (i.e. long-
and short-axis views), we propose a novel approach which learns anatomical
shape priors across different 2D standard views and leverages these priors to
segment the left ventricular (LV) myocardium from short-axis MR image stacks.
The proposed segmentation method has the advantage of being a 2D network but at
the same time incorporates spatial context from multiple, complementary views
that span a 3D space. Our method achieves accurate and robust segmentation of
the myocardium across different short-axis slices (from apex to base),
outperforming baseline models (e.g. 2D U-Net, 3D U-Net) while achieving higher
data efficiency. Compared to the 2D U-Net, the proposed method reduces the mean
Hausdorff distance (mm) from 3.24 to 2.49 on the apical slices, from 2.34 to
2.09 on the middle slices and from 3.62 to 2.76 on the basal slices on the test
set, when only 10% of the training data was used.",,,arXiv,,,2019-07-23,2019,,,,,,All OA, Green,Preprint,"Chen, Chen; Biffi, Carlo; Tarroni, Giacomo; Petersen, Steffen; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (); Biffi, Carlo (); Tarroni, Giacomo (); Petersen, Steffen (); Bai, Wenjia (); Rueckert, Daniel ()",,"Chen, Chen (); Biffi, Carlo (); Tarroni, Giacomo (); Petersen, Steffen (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119821820,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1396,pub.1121393127,10.1109/ijcnn.2019.8852085,,,Spinal Stenosis Detection in MRI using Modular Coordinate Convolutional Attention Networks,"Spinal stenosis is a condition in which a portion of spinal canal narrows and exerts pressure on nerves that travel through it causing pain and numbness that might require surgery. This narrowing can be caused by pathologies in bony structures (vertebrae) or soft tissue structures (intervertebral discs) that comprise the spine. Radiography, particularly Magnetic Resonance Imaging (MRI) is the modality of choice to evaluate stenosis and intervertebral disc pathology. Radiologists examine axial MRI scans at various levels along the spine to detect stenosis. Further, they evaluate the diameters of spinal canal and bulging in nearby discs which can indicate narrowing and compression on nerves. Hence measuring various diameters in a scan is a crucial step in diagnosis. However, affected regions occupy a very small fraction of the scan and there is virtually no room for error as a deviation of few pixels will also lead to discrepancies in measured and original lengths which makes it a very difficult and laborious task to measure the length of such intricate structures accurately. This paper proposes a novel deep learning based solution to tackle this problem. Proposed method attempts to solve it in two independent modules and makes prediction on the enlarged section of the scan which also makes it easier to measure various lengths. Human radiologists focus on certain parts of the scan rather than attending to the entire scan which largely consists of irrelevant background. Proposed modular approach is designed to mimic this attention mechanism. Both modules are built using coordinate convolutional networks, comparisons with baseline method empirically demonstrate superiority of the proposed approach.",We are grateful to the team of radiologists working continuously to tag our datasets. We thank the all the radiology centers who readily agreed to share their valuable data with us. We thank the entire team of Synapsica Technologies for their continuous support throughout the project.,,,2019 International Joint Conference on Neural Networks (IJCNN),,2019-07-19,2019,,2019-07-19,0,,1-8,Closed,Proceeding,"Upadhyay, Uddeshya; Singhal, Badrinath; Singh, Meenakshi","Upadhyay, Uddeshya (Dept. of Computer Science and Engineering, Indian Institute of Technology, Bombay); Singhal, Badrinath (Synapsica Technologies); Singh, Meenakshi (Synapsica Technologies)","Upadhyay, Uddeshya (Indian Institute of Technology Bombay)","Upadhyay, Uddeshya (Indian Institute of Technology Bombay); Singhal, Badrinath (); Singh, Meenakshi ()",2,2,,0.84,,https://app.dimensions.ai/details/publication/pub.1121393127,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 40 Engineering,,,,,,,,,,
3453,pub.1118086782,10.1016/j.media.2019.101535,31351230,PMC6815716,Disentangled representation learning in cardiac image analysis,"Typically, a medical image offers spatial information on the anatomy (and pathology) modulated by imaging specific characteristics. Many imaging modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) can be interpreted in this way. We can venture further and consider that a medical image naturally factors into some spatial factors depicting anatomy and factors that denote the imaging characteristics. Here, we explicitly learn this decomposed (disentangled) representation of imaging data, focusing in particular on cardiac images. We propose Spatial Decomposition Network (SDNet), which factorises 2D medical images into spatial anatomical factors and non-spatial modality factors. We demonstrate that this high-level representation is ideally suited for several medical image analysis tasks, such as semi-supervised segmentation, multi-task segmentation and regression, and image-to-image synthesis. Specifically, we show that our model can match the performance of fully supervised segmentation models, using only a fraction of the labelled images. Critically, we show that our factorised representation also benefits from supervision obtained either when we use auxiliary tasks to train the model in a multi-task setting (e.g. regressing to known cardiac indices), or when aggregating multimodal data from different sources (e.g. pooling together MRI and CT data). To explore the properties of the learned factorisation, we perform latent-space arithmetic and show that we can synthesise CT from MR and vice versa, by swapping the modality factors. We also demonstrate that the factor holding image specific information can be used to predict the input modality with high accuracy. Code will be made available at https://github.com/agis85/anatomy_modality_decomposition.","This work was supported in part by the US National Institutes of Health (1R01HL136578-01) and UK EPSRC (EP/P022928/1), and used resources provided by the Edinburgh Compute and Data Facility (http://www.ecdf.ed.ac.uk/). S.A. Tsaftaris acknowledges the support of the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme.",,Medical Image Analysis,,"Cardiovascular Diseases; Datasets as Topic; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Supervised Machine Learning; Tomography, X-Ray Computed",2019-07-18,2019,2019-07-18,2019-12,58,,101535,All OA, Green,Article,"Chartsias, Agisilaos; Joyce, Thomas; Papanastasiou, Giorgos; Semple, Scott; Williams, Michelle; Newby, David E; Dharmakumar, Rohan; Tsaftaris, Sotirios A","Chartsias, Agisilaos (Institute for Digital Communications, School of Engineering, University of Edinburgh, West Mains Rd, Edinburgh EH9 3FB, UK. Electronic address: agis.chartsias@ed.ac.uk.); Joyce, Thomas (Institute for Digital Communications, School of Engineering, University of Edinburgh, West Mains Rd, Edinburgh EH9 3FB, UK.); Papanastasiou, Giorgos (Edinburgh Imaging Facility QMRI, Edinburgh, EH16 4TJ, UK; Centre for Cardiovascular Science, Edinburgh, EH16 4TJ, UK.); Semple, Scott (Edinburgh Imaging Facility QMRI, Edinburgh, EH16 4TJ, UK; Centre for Cardiovascular Science, Edinburgh, EH16 4TJ, UK.); Williams, Michelle (Edinburgh Imaging Facility QMRI, Edinburgh, EH16 4TJ, UK; Centre for Cardiovascular Science, Edinburgh, EH16 4TJ, UK.); Newby, David E (Edinburgh Imaging Facility QMRI, Edinburgh, EH16 4TJ, UK; Centre for Cardiovascular Science, Edinburgh, EH16 4TJ, UK.); Dharmakumar, Rohan (Cedars Sinai Medical Center Los Angeles CA, USA.); Tsaftaris, Sotirios A (Institute for Digital Communications, School of Engineering, University of Edinburgh, West Mains Rd, Edinburgh EH9 3FB, UK; The Alan Turing Institute, London, UK.)","Chartsias, Agisilaos (University of Edinburgh)","Chartsias, Agisilaos (University of Edinburgh); Joyce, Thomas (University of Edinburgh); Papanastasiou, Giorgos (The Queen's Medical Research Institute); Semple, Scott (The Queen's Medical Research Institute); Williams, Michelle (The Queen's Medical Research Institute); Newby, David E (The Queen's Medical Research Institute); Dharmakumar, Rohan (); Tsaftaris, Sotirios A (University of Edinburgh; The Alan Turing Institute)",110,88,4.0,,http://repository.essex.ac.uk/28146/1/MIA%202019.pdf,https://app.dimensions.ai/details/publication/pub.1118086782,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
4681,pub.1118070115,10.1148/ryai.2019180080,32076659,PMC6677286,Implementation and Validation of a Three-dimensional Cardiac Motion Estimation Network,"PURPOSE: To describe an unsupervised three-dimensional cardiac motion estimation network (CarMEN) for deformable motion estimation from two-dimensional cine MR images.
MATERIALS AND METHODS: A function was implemented using CarMEN, a convolutional neural network that takes two three-dimensional input volumes and outputs a motion field. A smoothness constraint was imposed on the field by regularizing the Frobenius norm of its Jacobian matrix. CarMEN was trained and tested with data from 150 cardiac patients who underwent MRI examinations and was validated on synthetic (n = 100) and pediatric (n = 33) datasets. CarMEN was compared to five state-of-the-art nonrigid body registration methods by using several performance metrics, including Dice similarity coefficient (DSC) and end-point error.
RESULTS: On the synthetic dataset, CarMEN achieved a median DSC of 0.85, which was higher than all five methods (minimum-maximum median [or MMM], 0.67-0.84; P < .001), and a median end-point error of 1.7, which was lower than (MMM, 2.1-2.7; P < .001) or similar to (MMM, 1.6-1.7; P > .05) all other techniques. On the real datasets, CarMEN achieved a median DSC of 0.73 for Automated Cardiac Diagnosis Challenge data, which was higher than (MMM, 0.33; P < .0001) or similar to (MMM, 0.72-0.75; P > .05) all other methods, and a median DSC of 0.77 for pediatric data, which was higher than (MMM, 0.71-0.76; P < .0001) or similar to (MMM, 0.77-0.78; P > .05) all other methods. All P values were derived from pairwise testing. For all other metrics, CarMEN achieved better accuracy on all datasets than all other techniques except for one, which had the worst motion estimation accuracy.
CONCLUSION: The proposed deep learning-based approach for three-dimensional cardiac motion estimation allowed the derivation of a motion model that balances motion characterization and image registration accuracy and achieved motion estimation accuracy comparable to or better than that of several state-of-the-art image registration algorithms.© RSNA, 2019Supplemental material is available for this article.","The authors gratefully acknowledge the support of NVIDIA with the donation of the Titan X Pascal graphics processing unit used for this research. Finally, the authors would like to thank the reviewers for their thoughtful comments and efforts toward improving the manuscript. * M.A.M. and D.I.G. contributed equally to this work. Supported by the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH) (T32 EB001680). I.A. supported by the National Institute of Diabetes and Digestive and Kidney Diseases (K01DK101631) and the BrightFocus Foundation (A2016172S). C.C. and D.I.G. supported by the National Cancer Institute (1R01CA218187–01A1). cardiac motion estimation network Dice similarity coefficient interquartile range",,Radiology Artificial Intelligence,,,2019-07-17,2019,2019-07-17,2019-07,1,4,e180080,All OA, Green,Article,"Morales, Manuel A; Izquierdo-Garcia, David; Aganj, Iman; Kalpathy-Cramer, Jayashree; Rosen, Bruce R; Catana, Ciprian","Morales, Manuel A (Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital and Harvard Medical School, 149 13th St, Charlestown, MA 02129 (M.A.M., D.I.G., I.A., J.K.C., B.R.R., C.C.); Harvard-MIT Division of Health Sciences and Technology (M.A.M.) and Computer Science and Artificial Intelligence Laboratory (I.A.), Massachusetts Institute of Technology, Cambridge, Mass.); Izquierdo-Garcia, David (Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital and Harvard Medical School, 149 13th St, Charlestown, MA 02129 (M.A.M., D.I.G., I.A., J.K.C., B.R.R., C.C.); Harvard-MIT Division of Health Sciences and Technology (M.A.M.) and Computer Science and Artificial Intelligence Laboratory (I.A.), Massachusetts Institute of Technology, Cambridge, Mass.); Aganj, Iman (Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital and Harvard Medical School, 149 13th St, Charlestown, MA 02129 (M.A.M., D.I.G., I.A., J.K.C., B.R.R., C.C.); Harvard-MIT Division of Health Sciences and Technology (M.A.M.) and Computer Science and Artificial Intelligence Laboratory (I.A.), Massachusetts Institute of Technology, Cambridge, Mass.); Kalpathy-Cramer, Jayashree (Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital and Harvard Medical School, 149 13th St, Charlestown, MA 02129 (M.A.M., D.I.G., I.A., J.K.C., B.R.R., C.C.); Harvard-MIT Division of Health Sciences and Technology (M.A.M.) and Computer Science and Artificial Intelligence Laboratory (I.A.), Massachusetts Institute of Technology, Cambridge, Mass.); Rosen, Bruce R (Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital and Harvard Medical School, 149 13th St, Charlestown, MA 02129 (M.A.M., D.I.G., I.A., J.K.C., B.R.R., C.C.); Harvard-MIT Division of Health Sciences and Technology (M.A.M.) and Computer Science and Artificial Intelligence Laboratory (I.A.), Massachusetts Institute of Technology, Cambridge, Mass.); Catana, Ciprian (Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital and Harvard Medical School, 149 13th St, Charlestown, MA 02129 (M.A.M., D.I.G., I.A., J.K.C., B.R.R., C.C.); Harvard-MIT Division of Health Sciences and Technology (M.A.M.) and Computer Science and Artificial Intelligence Laboratory (I.A.), Massachusetts Institute of Technology, Cambridge, Mass.)",,"Morales, Manuel A (); Izquierdo-Garcia, David (); Aganj, Iman (); Kalpathy-Cramer, Jayashree (); Rosen, Bruce R (); Catana, Ciprian ()",24,17,1.39,7.19,https://europepmc.org/articles/pmc6677286?pdf=render,https://app.dimensions.ai/details/publication/pub.1118070115,32 Biomedical and Clinical Sciences, 3211 Oncology and Carcinogenesis,,,,,,,,,,
4548,pub.1118065203,10.1016/j.jcmg.2019.05.030,31326477,PMC7060799,"Fully Automated, Quality-Controlled Cardiac Analysis From CMR Validation and Large-Scale Application to Characterize Cardiac Function","OBJECTIVES: This study sought to develop a fully automated framework for cardiac function analysis from cardiac magnetic resonance (CMR), including comprehensive quality control (QC) algorithms to detect erroneous output.
BACKGROUND: Analysis of cine CMR imaging using deep learning (DL) algorithms could automate ventricular function assessment. However, variable image quality, variability in phenotypes of disease, and unavoidable weaknesses in training of DL algorithms currently prevent their use in clinical practice.
METHODS: The framework consists of a pre-analysis DL image QC, followed by a DL algorithm for biventricular segmentation in long-axis and short-axis views, myocardial feature-tracking (FT), and a post-analysis QC to detect erroneous results. The study validated the framework in healthy subjects and cardiac patients by comparison against manual analysis (n = 100) and evaluation of the QC steps' ability to detect erroneous results (n = 700). Next, this method was used to obtain reference values for cardiac function metrics from the UK Biobank.
RESULTS: Automated analysis correlated highly with manual analysis for left and right ventricular volumes (all r > 0.95), strain (circumferential r = 0.89, longitudinal r > 0.89), and filling and ejection rates (all r ≥ 0.93). There was no significant bias for cardiac volumes and filling and ejection rates, except for right ventricular end-systolic volume (bias +1.80 ml; p = 0.01). The bias for FT strain was <1.3%. The sensitivity of detection of erroneous output was 95% for volume-derived parameters and 93% for FT strain. Finally, reference values were automatically derived from 2,029 CMR exams in healthy subjects.
CONCLUSIONS: The study demonstrates a DL-based framework for automated, quality-controlled characterization of cardiac function from cine CMR, without the need for direct clinician oversight.","This work was supported by the Wellcome EPSRC Centre for Medical Engineering at Kings College London (WT 203148/Z/16/Z), the EPSRC (EP/P001009/1 and EP/R005516/1) and by the NIHR Cardiovascular MedTech Co-operative. The views expressed are those of the author(s) and not necessarily those of the NHS, the NIHR, EPSRC, or the Department of Health. This research has been conducted using the UK Biobank Resource (application 17806) on a GPU generously donated by NVIDIA Corporation. The UK Biobank data are available for approved projects from https://www.ukbiobank.ac.uk/. Dr. Sinclair is an employee of HeartFlow. All other authors have reported that they have no relationships relevant to the contents of this paper to disclose.",,JACC Cardiovascular Imaging,,"Aged; Automation; Deep Learning; Diagnosis, Computer-Assisted; Female; Heart Diseases; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Predictive Value of Tests; Quality Control; Quality Indicators, Health Care; Reproducibility of Results; Stroke Volume; Ventricular Function, Left; Ventricular Function, Right",2019-07-17,2019,2019-07-17,2020-03,13,3,684-695,All OA, Hybrid,Article,"Ruijsink, Bram; Puyol-Antón, Esther; Oksuz, Ilkay; Sinclair, Matthew; Bai, Wenjia; Schnabel, Julia A.; Razavi, Reza; King, Andrew P.","Ruijsink, Bram (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Department of Adult and Paediatric Cardiology, Guy’s and St Thomas’ NHS Foundation Trust, London, London, United Kingdom); Puyol-Antón, Esther (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom); Oksuz, Ilkay (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom); Sinclair, Matthew (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom); Bai, Wenjia (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Department of Medicine, Imperial College London, London, United Kingdom); Schnabel, Julia A. (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom); Razavi, Reza (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Department of Adult and Paediatric Cardiology, Guy’s and St Thomas’ NHS Foundation Trust, London, London, United Kingdom); King, Andrew P. (School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom)","Ruijsink, Bram (King's College London; Guy's and St Thomas' NHS Foundation Trust)","Ruijsink, Bram (King's College London; Guy's and St Thomas' NHS Foundation Trust); Puyol-Antón, Esther (King's College London); Oksuz, Ilkay (King's College London); Sinclair, Matthew (King's College London); Bai, Wenjia (Imperial College London; Imperial College London); Schnabel, Julia A. (King's College London); Razavi, Reza (King's College London; Guy's and St Thomas' NHS Foundation Trust); King, Andrew P. (King's College London)",119,90,9.1,49.91,https://doi.org/10.1016/j.jcmg.2019.05.030,https://app.dimensions.ai/details/publication/pub.1118065203,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1008,pub.1119405192,10.48550/arxiv.1907.01268,,,Improving the generalizability of convolutional neural network-based  segmentation on CMR images,"Convolutional neural network (CNN) based segmentation methods provide an
efficient and automated way for clinicians to assess the structure and function
of the heart in cardiac MR images. While CNNs can generally perform the
segmentation tasks with high accuracy when training and test images come from
the same domain (e.g. same scanner or site), their performance often degrades
dramatically on images from different scanners or clinical sites. We propose a
simple yet effective way for improving the network generalization ability by
carefully designing data normalization and augmentation strategies to
accommodate common scenarios in multi-site, multi-scanner clinical imaging data
sets. We demonstrate that a neural network trained on a single-site
single-scanner dataset from the UK Biobank can be successfully applied to
segmenting cardiac MR images across different sites and different scanners
without substantial loss of accuracy. Specifically, the method was trained on a
large set of 3,975 subjects from the UK Biobank. It was then directly tested on
600 different subjects from the UK Biobank for intra-domain testing and two
other sets for cross-domain testing: the ACDC dataset (100 subjects, 1 site, 2
scanners) and the BSCMR-AS dataset (599 subjects, 6 sites, 9 scanners). The
proposed method produces promising segmentation results on the UK Biobank test
set which are comparable to previously reported values in the literature, while
also performing well on cross-domain test sets, achieving a mean Dice metric of
0.90 for the left ventricle, 0.81 for the myocardium and 0.82 for the right
ventricle on the ACDC dataset; and 0.89 for the left ventricle, 0.83 for the
myocardium on the BSCMR-AS dataset. The proposed method offers a potential
solution to improve CNN-based model generalizability for the cross-scanner and
cross-site cardiac MR image segmentation task.",,,arXiv,,,2019-07-02,2019,,,,,,All OA, Green,Preprint,"Chen, Chen; Bai, Wenjia; Davies, Rhodri H.; Bhuva, Anish N.; Manisty, Charlotte; Moon, James C.; Aung, Nay; Lee, Aaron M.; Sanghvi, Mihir M.; Fung, Kenneth; Paiva, Jose Miguel; Petersen, Steffen E.; Lukaschuk, Elena; Piechnik, Stefan K.; Neubauer, Stefan; Rueckert, Daniel","Chen, Chen (); Bai, Wenjia (); Davies, Rhodri H. (); Bhuva, Anish N. (); Manisty, Charlotte (); Moon, James C. (); Aung, Nay (); Lee, Aaron M. (); Sanghvi, Mihir M. (); Fung, Kenneth (); Paiva, Jose Miguel (); Petersen, Steffen E. (); Lukaschuk, Elena (); Piechnik, Stefan K. (); Neubauer, Stefan (); Rueckert, Daniel ()",,"Chen, Chen (); Bai, Wenjia (); Davies, Rhodri H. (); Bhuva, Anish N. (); Manisty, Charlotte (); Moon, James C. (); Aung, Nay (); Lee, Aaron M. (); Sanghvi, Mihir M. (); Fung, Kenneth (); Paiva, Jose Miguel (); Petersen, Steffen E. (); Lukaschuk, Elena (); Piechnik, Stefan K. (); Neubauer, Stefan (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119405192,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
4043,pub.1113646007,10.1016/j.semradonc.2019.02.001,31027636,,Advances in Auto-Segmentation,"Manual image segmentation is a time-consuming task routinely performed in radiotherapy to identify each patient's targets and anatomical structures. The efficacy and safety of the radiotherapy plan requires accurate segmentations as these regions of interest are generally used to optimize and assess the quality of the plan. However, reports have shown that this process can be subject to significant inter- and intraobserver variability. Furthermore, the quality of the radiotherapy treatment, and subsequent analyses (ie, radiomics, dosimetric), can be subject to the accuracy of these manual segmentations. Automatic segmentation (or auto-segmentation) of targets and normal tissues is, therefore, preferable as it would address these challenges. Previously, auto-segmentation techniques have been clustered into 3 generations of algorithms, with multiatlas based and hybrid techniques (third generation) being considered the state-of-the-art. More recently, however, the field of medical image segmentation has seen accelerated growth driven by advances in computer vision, particularly through the application of deep learning algorithms, suggesting we have entered the fourth generation of auto-segmentation algorithm development. In this paper, the authors review traditional (nondeep learning) algorithms particularly relevant for applications in radiotherapy. Concepts from deep learning are introduced focusing on convolutional neural networks and fully-convolutional networks which are generally used for segmentation tasks. Furthermore, the authors provide a summary of deep learning auto-segmentation radiotherapy applications reported in the literature. Lastly, considerations for clinical deployment (commissioning and QA) of auto-segmentation software are provided.",,,Seminars in Radiation Oncology,,"Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Neoplasms; Neural Networks, Computer; Organs at Risk; Radiotherapy, Computer-Assisted; Radiotherapy, Image-Guided; Software",2019-07,2019,,2019-07,29,3,185-197,Closed,Article,"Cardenas, Carlos E.; Yang, Jinzhong; Anderson, Brian M.; Court, Laurence E.; Brock, Kristy B.","Cardenas, Carlos E. (); Yang, Jinzhong (); Anderson, Brian M. (); Court, Laurence E. (); Brock, Kristy B. ()","Cardenas, Carlos E. ","Cardenas, Carlos E. (); Yang, Jinzhong (); Anderson, Brian M. (); Court, Laurence E. (); Brock, Kristy B. ()",184,134,16.74,55.14,,https://app.dimensions.ai/details/publication/pub.1113646007,32 Biomedical and Clinical Sciences, 3211 Oncology and Carcinogenesis,,,,,,,,,,,
957,pub.1119403546,10.48550/arxiv.1907.00058,,,Explainable Anatomical Shape Analysis through Deep Hierarchical  Generative Models,"Quantification of anatomical shape changes currently relies on scalar global
indexes which are largely insensitive to regional or asymmetric modifications.
Accurate assessment of pathology-driven anatomical remodeling is a crucial step
for the diagnosis and treatment of many conditions. Deep learning approaches
have recently achieved wide success in the analysis of medical images, but they
lack interpretability in the feature extraction and decision processes. In this
work, we propose a new interpretable deep learning model for shape analysis. In
particular, we exploit deep generative networks to model a population of
anatomical segmentations through a hierarchy of conditional latent variables.
At the highest level of this hierarchy, a two-dimensional latent space is
simultaneously optimised to discriminate distinct clinical conditions, enabling
the direct visualisation of the classification space. Moreover, the anatomical
variability encoded by this discriminative latent space can be visualised in
the segmentation space thanks to the generative properties of the model, making
the classification task transparent. This approach yielded high accuracy in the
categorisation of healthy and remodelled left ventricles when tested on unseen
segmentations from our own multi-centre dataset as well as in an external
validation set, and on hippocampi from healthy controls and patients with
Alzheimer's disease when tested on ADNI data. More importantly, it enabled the
visualisation in three-dimensions of both global and regional anatomical
features which better discriminate between the conditions under exam. The
proposed approach scales effectively to large populations, facilitating
high-throughput analysis of normal anatomy and pathology in large-scale studies
of volumetric imaging.",,,arXiv,,,2019-06-28,2019,,,,,,All OA, Green,Preprint,"Biffi, Carlo; Cerrolaza, Juan J.; Tarroni, Giacomo; Bai, Wenjia; de Marvao, Antonio; Oktay, Ozan; Ledig, Christian; Folgoc, Loic Le; Kamnitsas, Konstantinos; Doumou, Georgia; Duan, Jinming; Prasad, Sanjay K.; Cook, Stuart A.; O'Regan, Declan P.; Rueckert, Daniel","Biffi, Carlo (); Cerrolaza, Juan J. (); Tarroni, Giacomo (); Bai, Wenjia (); de Marvao, Antonio (); Oktay, Ozan (); Ledig, Christian (); Folgoc, Loic Le (); Kamnitsas, Konstantinos (); Doumou, Georgia (); Duan, Jinming (); Prasad, Sanjay K. (); Cook, Stuart A. (); O'Regan, Declan P. (); Rueckert, Daniel ()",,"Biffi, Carlo (); Cerrolaza, Juan J. (); Tarroni, Giacomo (); Bai, Wenjia (); de Marvao, Antonio (); Oktay, Ozan (); Ledig, Christian (); Folgoc, Loic Le (); Kamnitsas, Konstantinos (); Doumou, Georgia (); Duan, Jinming (); Prasad, Sanjay K. (); Cook, Stuart A. (); O'Regan, Declan P. (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119403546,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1545,pub.1119397666,10.48550/arxiv.1906.06188,,,Global and Local Interpretability for Cardiac MRI Classification,"Deep learning methods for classifying medical images have demonstrated
impressive accuracy in a wide range of tasks but often these models are hard to
interpret, limiting their applicability in clinical practice. In this work we
introduce a convolutional neural network model for identifying disease in
temporal sequences of cardiac MR segmentations which is interpretable in terms
of clinically familiar measurements. The model is based around a variational
autoencoder, reducing the input into a low-dimensional latent space in which
classification occurs. We then use the recently developed `concept activation
vector' technique to associate concepts which are diagnostically meaningful
(eg. clinical biomarkers such as `low left-ventricular ejection fraction') to
certain vectors in the latent space. These concepts are then qualitatively
inspected by observing the change in the image domain resulting from
interpolations in the latent space in the direction of these vectors. As a
result, when the model classifies images it is also capable of providing
naturally interpretable concepts relevant to that classification and
demonstrating the meaning of those concepts in the image domain. Our approach
is demonstrated on the UK Biobank cardiac MRI dataset where we detect the
presence of coronary artery disease.",,,arXiv,,,2019-06-14,2019,,,,,,All OA, Green,Preprint,"Clough, James R.; Oksuz, Ilkay; Puyol-Anton, Esther; Ruijsink, Bram; King, Andrew P.; Schnabel, Julia A.","Clough, James R. (); Oksuz, Ilkay (); Puyol-Anton, Esther (); Ruijsink, Bram (); King, Andrew P. (); Schnabel, Julia A. ()",,"Clough, James R. (); Oksuz, Ilkay (); Puyol-Anton, Esther (); Ruijsink, Bram (); King, Andrew P. (); Schnabel, Julia A. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119397666,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
3467,pub.1116840732,10.1016/j.media.2019.06.001,31200290,,Explainable cardiac pathology classification on cine MRI with motion characterization by semi-supervised learning of apparent flow,"We propose a method to classify cardiac pathology based on a novel approach to extract image derived features to characterize the shape and motion of the heart. An original semi-supervised learning procedure, which makes efficient use of a large amount of non-segmented images and a small amount of images segmented manually by experts, is developed to generate pixel-wise apparent flow between two time points of a 2D+t cine MRI image sequence. Combining the apparent flow maps and cardiac segmentation masks, we obtain a local apparent flow corresponding to the 2D motion of myocardium and ventricular cavities. This leads to the generation of time series of the radius and thickness of myocardial segments to represent cardiac motion. These time series of motion features are reliable and explainable characteristics of pathological cardiac motion. Furthermore, they are combined with shape-related features to classify cardiac pathologies. Using only nine feature values as input, we propose an explainable, simple and flexible model for pathology classification. On ACDC training set and testing set, the model achieves 95% and 94% respectively as classification accuracy. Its performance is hence comparable to that of the state-of-the-art. Comparison with various other models is performed to outline some advantages of our model.",The authors acknowledge the partial support from the European Research Council (MedYMA ERC-AdG-2011-291080).,,Medical Image Analysis,,"Heart Diseases; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Motion; Supervised Machine Learning",2019-06-06,2019,2019-06-06,2019-08,56,,80-95,All OA, Green,Article,"Zheng, Qiao; Delingette, Hervé; Ayache, Nicholas","Zheng, Qiao (Université Côte d'Azur, Inria, 2004 Route des Lucioles, 06902 Sophia Antipolis, France. Electronic address: qiao.zheng@inria.fr.); Delingette, Hervé (Université Côte d'Azur, Inria, 2004 Route des Lucioles, 06902 Sophia Antipolis, France.); Ayache, Nicholas (Université Côte d'Azur, Inria, 2004 Route des Lucioles, 06902 Sophia Antipolis, France.)","Zheng, Qiao ","Zheng, Qiao (); Delingette, Hervé (); Ayache, Nicholas ()",67,48,2.67,,http://arxiv.org/pdf/1811.03433,https://app.dimensions.ai/details/publication/pub.1116840732,40 Engineering,,,,,,,,,,,
1010,pub.1119413933,10.48550/arxiv.1906.02849,,,Multi-scale self-guided attention for medical image segmentation,"Even though convolutional neural networks (CNNs) are driving progress in
medical image segmentation, standard models still have some drawbacks. First,
the use of multi-scale approaches, i.e., encoder-decoder architectures, leads
to a redundant use of information, where similar low-level features are
extracted multiple times at multiple scales. Second, long-range feature
dependencies are not efficiently modeled, resulting in non-optimal
discriminative feature representations associated with each semantic class. In
this paper we attempt to overcome these limitations with the proposed
architecture, by capturing richer contextual dependencies based on the use of
guided self-attention mechanisms. This approach is able to integrate local
features with their corresponding global dependencies, as well as highlight
interdependent channel maps in an adaptive manner. Further, the additional loss
between different modules guides the attention mechanisms to neglect irrelevant
information and focus on more discriminant regions of the image by emphasizing
relevant feature associations. We evaluate the proposed model in the context of
semantic segmentation on three different datasets: abdominal organs,
cardiovascular structures and brain tumors. A series of ablation experiments
support the importance of these attention modules in the proposed architecture.
In addition, compared to other state-of-the-art segmentation networks our model
yields better segmentation performance, increasing the accuracy of the
predictions while reducing the standard deviation. This demonstrates the
efficiency of our approach to generate precise and reliable automatic
segmentations of medical images. Our code is made publicly available at
https://github.com/sinAshish/Multi-Scale-Attention",,,arXiv,,,2019-06-06,2019,,,,,,All OA, Green,Preprint,"Sinha, Ashish; Dolz, Jose","Sinha, Ashish (); Dolz, Jose ()",,"Sinha, Ashish (); Dolz, Jose ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119413933,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1926,pub.1114224112,10.1016/j.media.2019.04.002,31181343,,Computational anatomy for multi-organ analysis in medical imaging: A review,"The medical image analysis field has traditionally been focused on the development of organ-, and disease-specific methods. Recently, the interest in the development of more comprehensive computational anatomical models has grown, leading to the creation of multi-organ models. Multi-organ approaches, unlike traditional organ-specific strategies, incorporate inter-organ relations into the model, thus leading to a more accurate representation of the complex human anatomy. Inter-organ relations are not only spatial, but also functional and physiological. Over the years, the strategies proposed to efficiently model multi-organ structures have evolved from the simple global modeling, to more sophisticated approaches such as sequential, hierarchical, or machine learning-based models. In this paper, we present a review of the state of the art on multi-organ analysis and associated computation anatomy methodology. The manuscript follows a methodology-based classification of the different techniques available for the analysis of multi-organs and multi-anatomical structures, from techniques using point distribution models to the most recent deep learning-based approaches. With more than 300 papers included in this review, we reflect on the trends and challenges of the field of computational anatomy, the particularities of each anatomical region, and the potential of multi-organ analysis to increase the impact of medical imaging applications on the future of healthcare.",,,Medical Image Analysis,,"Deep Learning; Diagnostic Imaging; Humans; Image Enhancement; Image Processing, Computer-Assisted; Models, Anatomic; Models, Statistical; Pattern Recognition, Automated",2019-05-15,2019,2019-05-15,2019-08,56,,44-67,All OA, Green,Article,"Cerrolaza, Juan J; Picazo, Mirella López; Humbert, Ludovic; Sato, Yoshinobu; Rueckert, Daniel; Ballester, Miguel Ángel González; Linguraru, Marius George","Cerrolaza, Juan J (Biomedical Image Analysis Group, Imperial College London, United Kingdom. Electronic address: jjcerromar@gmail.com.); Picazo, Mirella López (BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Galgo Medical S.L., Spain.); Humbert, Ludovic (Galgo Medical S.L., Spain.); Sato, Yoshinobu (Graduate School of Information Science, Nara Institute of Science and Technology (NAIST), Nara, Japan.); Rueckert, Daniel (Biomedical Image Analysis Group, Imperial College London, United Kingdom.); Ballester, Miguel Ángel González (BCN Medtech, Dept. of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; ICREA, Barcelona, Spain.); Linguraru, Marius George (Sheickh Zayed Institute for Pediatric Surgicaonl Innovation, Children's National Health System, Washington DC, USA; School of Medicine and Health Sciences, George Washington University, Washington DC, USA.)","Cerrolaza, Juan J (Imperial College London)","Cerrolaza, Juan J (Imperial College London); Picazo, Mirella López (Pompeu Fabra University); Humbert, Ludovic (); Sato, Yoshinobu (Nara Institute of Science and Technology); Rueckert, Daniel (Imperial College London); Ballester, Miguel Ángel González (Pompeu Fabra University; Institució Catalana de Recerca i Estudis Avançats); Linguraru, Marius George (Children’s National Health System; George Washington University)",37,28,2.26,,http://arxiv.org/pdf/1812.08577,https://app.dimensions.ai/details/publication/pub.1114224112,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
3621,pub.1113944007,10.1016/j.compbiomed.2019.04.042,31100582,,RIANet: Recurrent interleaved attention network for cardiac MRI segmentation,"BACKGROUND: Segmentation of anatomical structures of the heart from cardiac magnetic resonance images (MRI) has a significant impact on the quantitative analysis of the cardiac contractile function. Although deep convolutional neural networks (ConvNets) have achieved considerable success in medical imaging segmentation, it is still a challenging task for existing deep ConvNets to precisely and automatically segment multiple heart structures from cardiac MRI. This paper presents a novel recurrent interleaved attention network (RIANet) to comprehensively tackle this issue.
METHOD: The proposed RIANet can efficiently reuse parameters to encode richer representative features via introducing a recurrent feedback structure, Clique Block, which incorporates both forward and backward connections between different layers with the same resolution. Further, we integrate a plug-and-play interleaved attention (IA) block to modulate the information passed to the decoding stage of RIANet by effectively fusing multi-level contextual information. In addition, we improve the discrimination capability of our RIANet through a deep supervision mechanism with weighted losses.
RESULTS: The performance of RIANet has been extensively validated in the segmentation contest of the ACDC 2017 challenge held in conjunction with MICCAI 2017, with mean Dice scores of 0.942 (left ventricular), 0.923 (right ventricular) and 0.910 (myocardium) for cardiac MRI segmentation. Besides, we visualize intermediate features of our RIANet using guided backpropagation, which can intuitively depict the effects of our proposed components in feature representation.
CONCLUSION: Experimental results demonstrate that our RIANet have achieved competitive segmentation results with fewer parameters compared with the state-of-the-art approaches, corroborating the effectiveness and robustness of our proposed RIANet.","This work was supported in part by the National Basic Research Program of China, 973 Program (2015CB351706), in part by the National Natural Science Foundation of China (61802385), in part by the Shenzhen Science and Technology Program (No. JCYJ20170413162617606 and JCYJ20160429190300857) and in part by the Research Grants Council of HKSAR (Project No. 14225616). Qianqian Tong and Caizi Li contributed equally to this work. Xiangyun Liao and Zhiyong Yuan are the corresponding authors.",,Computers in Biology and Medicine,,"Heart; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Neural Networks, Computer",2019-05-07,2019,2019-05-07,2019-06,109,,290-302,Closed,Article,"Tong, Qianqian; Li, Caizi; Si, Weixin; Liao, Xiangyun; Tong, Yaliang; Yuan, Zhiyong; Heng, Pheng Ann","Tong, Qianqian (School of Computer Science, Wuhan University, Wuhan, 430072, China; Guangdong Provincial Key Laboratory of Machine Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China.); Li, Caizi (School of Computer Science, Wuhan University, Wuhan, 430072, China.); Si, Weixin (Guangdong Provincial Key Laboratory of Machine Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China.); Liao, Xiangyun (Guangdong Provincial Key Laboratory of Machine Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China. Electronic address: xyunliao@gmail.com.); Tong, Yaliang (Department of Cardiology China-Japan Union Hospital of Jilin University, Changchun, 130000, China.); Yuan, Zhiyong (School of Computer Science, Wuhan University, Wuhan, 430072, China.); Heng, Pheng Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Guangdong Provincial Key Laboratory of Machine Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China.)","Liao, Xiangyun (Shenzhen Institutes of Advanced Technology); Yuan, Zhiyong (Wuhan University)","Tong, Qianqian (Wuhan University; Shenzhen Institutes of Advanced Technology); Li, Caizi (Wuhan University); Si, Weixin (Shenzhen Institutes of Advanced Technology); Liao, Xiangyun (Shenzhen Institutes of Advanced Technology); Tong, Yaliang (Jilin University); Yuan, Zhiyong (Wuhan University); Heng, Pheng Ann (Chinese University of Hong Kong; Shenzhen Institutes of Advanced Technology)",28,19,1.65,18.49,,https://app.dimensions.ai/details/publication/pub.1113944007,46 Information and Computing Sciences, 4601 Applied Computing,,,,,,,,,,,
4849,pub.1113715348,10.1186/s12968-019-0532-9,31023305,PMC8059518,Fully automated quantification of biventricular volumes and function in cardiovascular magnetic resonance: applicability to clinical routine settings,"BackgroundCardiovascular magnetic resonance (CMR) represents the clinical gold standard for the assessment of biventricular morphology and function. Since manual post-processing is time-consuming and prone to observer variability, efforts have been directed towards automated volumetric quantification. In this study, we sought to validate the accuracy of a novel approach providing fully automated quantification of biventricular volumes and function in a “real-world” clinical setting.MethodsThree-hundred CMR examinations were randomly selected from the local data base. Fully automated quantification of left ventricular (LV) mass, LV and right ventricular (RV) end-diastolic and end-systolic volumes (EDV/ESV), stroke volume (SV) and ejection fraction (EF) were performed overnight using commercially available software (suiteHEART®, Neosoft, Pewaukee, Wisconsin, USA). Parameters were compared to manual assessments (QMass®, Medis Medical Imaging Systems, Leiden, Netherlands). Sub-group analyses were further performed according to image quality, scanner field strength, the presence of implanted aortic valves and repaired Tetralogy of Fallot (ToF).ResultsBiventricular automated segmentation was feasible in all 300 cases. Overall agreement between fully automated and manually derived LV parameters was good (LV-EF: intra-class correlation coefficient [ICC] 0.95; bias − 2.5% [SD 5.9%]), whilst RV agreement was lower (RV-EF: ICC 0.72; bias 5.8% [SD 9.6%]). Lowest agreement was observed in case of severely altered anatomy, e.g. marked RV dilation but normal LV dimensions in repaired ToF (LV parameters ICC 0.73–0.91; RV parameters ICC 0.41–0.94) and/or reduced image quality (LV parameters ICC 0.86–0.95; RV parameters ICC 0.56–0.91), which was more common on 3.0 T than on 1.5 T.ConclusionsFully automated assessments of biventricular morphology and function is robust and accurate in a clinical routine setting with good image quality and can be performed without any user interaction. However, in case of demanding anatomy (e.g. repaired ToF, severe LV hypertrophy) or reduced image quality, quality check and manual re-contouring are still required.",We thank Marcus Billing and Nick Scholand for the support in IT applications. We also thank Professor Alistair A. Young and Dr. Avan Suinesiaputra for providing access to the SCMR consensus data.,,Journal of Cardiovascular Magnetic Resonance,,"Adult; Aged; Automation; Databases, Factual; Feasibility Studies; Female; Heart Diseases; Heart Ventricles; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Predictive Value of Tests; Reproducibility of Results; Retrospective Studies; Stroke Volume; Ventricular Function, Left; Ventricular Function, Right",2019-04-25,2019,2019-04-25,2019-12,21,1,24,All OA, Gold,Article,"Backhaus, Sören J.; Staab, Wieland; Steinmetz, Michael; Ritter, Christian O.; Lotz, Joachim; Hasenfuß, Gerd; Schuster, Andreas; Kowallick, Johannes T.","Backhaus, Sören J. (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg-August University, Göttingen, Germany; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany); Staab, Wieland (German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany; Institute for Diagnostic and Interventional Radiology, University Medical Centre Göttingen, Georg-August University, Robert-Koch-Str. 40, 37075, Göttingen, Germany); Steinmetz, Michael (German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany; Department of Pediatric Cardiology and Intensive Care Medicine, University Medical Center Göttingen, Georg-August University, Göttingen, Germany); Ritter, Christian O. (German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany; Institute for Diagnostic and Interventional Radiology, University Medical Centre Göttingen, Georg-August University, Robert-Koch-Str. 40, 37075, Göttingen, Germany); Lotz, Joachim (German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany; Institute for Diagnostic and Interventional Radiology, University Medical Centre Göttingen, Georg-August University, Robert-Koch-Str. 40, 37075, Göttingen, Germany); Hasenfuß, Gerd (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg-August University, Göttingen, Germany; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany); Schuster, Andreas (Department of Cardiology and Pneumology, University Medical Center Göttingen, Georg-August University, Göttingen, Germany; German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany; Department of Cardiology, Royal North Shore Hospital, The Kolling Institute, Nothern Clinical School, University of Sydney, Sydney, Australia); Kowallick, Johannes T. (German Center for Cardiovascular Research (DZHK), Partner Site Göttingen, Göttingen, Germany; Institute for Diagnostic and Interventional Radiology, University Medical Centre Göttingen, Georg-August University, Robert-Koch-Str. 40, 37075, Göttingen, Germany)","Kowallick, Johannes T. (German Centre for Cardiovascular Research; Universitätsmedizin Göttingen; University of Göttingen)","Backhaus, Sören J. (Universitätsmedizin Göttingen; University of Göttingen; German Centre for Cardiovascular Research); Staab, Wieland (German Centre for Cardiovascular Research; Universitätsmedizin Göttingen; University of Göttingen); Steinmetz, Michael (German Centre for Cardiovascular Research; Universitätsmedizin Göttingen; University of Göttingen); Ritter, Christian O. (German Centre for Cardiovascular Research; Universitätsmedizin Göttingen; University of Göttingen); Lotz, Joachim (German Centre for Cardiovascular Research; Universitätsmedizin Göttingen; University of Göttingen); Hasenfuß, Gerd (Universitätsmedizin Göttingen; University of Göttingen; German Centre for Cardiovascular Research); Schuster, Andreas (Universitätsmedizin Göttingen; University of Göttingen; German Centre for Cardiovascular Research; The University of Sydney); Kowallick, Johannes T. (German Centre for Cardiovascular Research; Universitätsmedizin Göttingen; University of Göttingen)",26,16,2.44,12.57,https://jcmr-online.biomedcentral.com/track/pdf/10.1186/s12968-019-0532-9,https://app.dimensions.ai/details/publication/pub.1113715348,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology, 3202 Clinical Sciences,,,,,,,,,
5004,pub.1113620359,10.1002/mrm.27772,31006909,,Conditional generative adversarial network for 3D rigid‐body motion correction in MRI,"PURPOSE: Subject motion in MRI remains an unsolved problem; motion during image acquisition may cause blurring and artifacts that severely degrade image quality. In this work, we approach motion correction as an image-to-image translation problem, which refers to the approach of training a deep neural network to predict an image in 1 domain from an image in another domain. Specifically, the purpose of this work was to develop and train a conditional generative adversarial network to predict artifact-free brain images from motion-corrupted data.
METHODS: An open source MRI data set comprising T2 *-weighted, FLASH magnitude, and phase brain images for 53 patients was used to generate complex image data for motion simulation. To simulate rigid motion, rotations and translations were applied to the image data based on randomly generated motion profiles. A conditional generative adversarial network, comprising a generator and discriminator networks, was trained using the motion-corrupted and corresponding ground truth (original) images as training pairs.
RESULTS: The images predicted by the conditional generative adversarial network have improved image quality compared to the motion-corrupted images. The mean absolute error between the motion-corrupted and ground-truth images of the test set was 16.4% of the image mean value, whereas the mean absolute error between the conditional generative adversarial network-predicted and ground-truth images was 10.8% The network output also demonstrated improved peak SNR and structural similarity index for all test-set images.
CONCLUSION: The images predicted by the conditional generative adversarial network have quantitatively and qualitatively improved image quality compared to the motion-corrupted images.",This research was funded in part by the Natural Sciences and Engineering Research Council of Canada and enabled by support and computing resources provided by WestGrid (www.westgrid.ca) and Compute Canada Calcul Canada (www.computecanada.ca).,Funding information This research was funded in part by the Natural Sciences and Engineering Research Council of Canada (401947‐2011 RGPIN) and enabled by support and computing resources provided by WestGrid (www.westgrid.ca) and Compute Canada Calcul Canada (www.computecanada.ca).,Magnetic Resonance in Medicine,,"Brain; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Movement; Neural Networks, Computer",2019-04-22,2019,2019-04-22,2019-09,82,3,901-910,Closed,Article,"Johnson, Patricia M.; Drangova, Maria","Johnson, Patricia M. (Imaging Research Laboratories, Robarts Research Institute, The University of Western Ontario, London, Ontario, Canada; Department of Medical Biophysics, Schulich School of Medicine & Dentistry, The University of Western Ontario, London, Ontario, Canada); Drangova, Maria (Imaging Research Laboratories, Robarts Research Institute, The University of Western Ontario, London, Ontario, Canada; Department of Medical Biophysics, Schulich School of Medicine & Dentistry, The University of Western Ontario, London, Ontario, Canada)","Drangova, Maria (Western University; Western University)","Johnson, Patricia M. (Western University; Western University); Drangova, Maria (Western University; Western University)",43,37,2.68,8.37,,https://app.dimensions.ai/details/publication/pub.1113620359,40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,,
1581,pub.1117944526,10.1109/isbi.2019.8759276,,,End-To-End Diagnosis And Segmentation Learning From Cardiac Magnetic Resonance Imaging,"Cardiac magnetic resonance (CMR) is used extensively in the diagnosis and management of cardiovascular disease. Deep learning methods have proven to deliver segmentation results comparable to human experts in CMR imaging, but there have been no convincing results for the problem of end-to-end segmentation and diagnosis from CMR. This is in part due to a lack of sufficiently large datasets required to train robust diagnosis models. In this paper, we propose a learning method to train diagnosis models, where our approach is designed to work with relatively small datasets. In particular, the optimization loss is based on multi-task learning that jointly trains for the tasks of segmentation and diagnosis classification. We hypothesize that segmentation has a regularizing effect on the learning of features relevant for diagnosis. Using the 100 training and 50 testing samples available from the Automated Cardiac Diagnosis Challenge (ACDC) dataset, which has a balanced distribution of 5 cardiac diagnoses, we observe a reduction of the classification error from 32% to 22%, and a faster convergence compared to a baseline without segmentation. To the best of our knowledge, this is the best diagnosis results from CMR using an end-to-end diagnosis and segmentation learning method.","This work was partially supported by the Dutch Heart Foundation, Australian Research Council project (DP180103232), and The University of Adelaide’s 2017 Interdisciplinary Research Funding Scheme.",,,2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019),,2019-04-11,2019,,2019-04-11,0,,802-805,All OA, Green,Proceeding,"Snaauw, Gerard; Gong, Dong; Maicas, Gabriel; van den Hengel, Anton; Niessen, Wiro J.; Verjans, Johan; Carneiro, Gustavo","Snaauw, Gerard (AIML, School of Computer Science, The University of Adelaide, Australia; Imaging Physics, Faculty of Applied Sciences, Delft University of Technology, Netherlands); Gong, Dong (AIML, School of Computer Science, The University of Adelaide, Australia); Maicas, Gabriel (AIML, School of Computer Science, The University of Adelaide, Australia); van den Hengel, Anton (AIML, School of Computer Science, The University of Adelaide, Australia); Niessen, Wiro J. (AIML, School of Computer Science, The University of Adelaide, Australia; Department of Radiology & Medical Informatics, Erasmus MC, Rotterdam, Netherlands); Verjans, Johan (AIML, School of Computer Science, The University of Adelaide, Australia; South Australian Health and Medical Research Institute, Adelaide, Australia); Carneiro, Gustavo (AIML, School of Computer Science, The University of Adelaide, Australia)","Snaauw, Gerard (University of Adelaide; Delft University of Technology)","Snaauw, Gerard (University of Adelaide; Delft University of Technology); Gong, Dong (University of Adelaide); Maicas, Gabriel (University of Adelaide); van den Hengel, Anton (University of Adelaide); Niessen, Wiro J. (University of Adelaide; Erasmus MC); Verjans, Johan (University of Adelaide; South Australian Health and Medical Research Institute); Carneiro, Gustavo (University of Adelaide)",21,14,,7.57,https://digital.library.adelaide.edu.au/dspace/bitstream/2440/122500/3/hdl_122500.pdf,https://app.dimensions.ai/details/publication/pub.1117944526,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
1515,pub.1117944727,10.1109/isbi.2019.8759516,,,Fully Automatic Segmentation Of Short-Axis Cardiac MRI Using Modified Deep Layer Aggregation,"Delineation of right ventricular cavity (RVC), left ventricular myocardium (LVM) and left ventricular cavity (LVC) are common tasks in the clinical diagnosis of cardiac related diseases, especially in the basis of advanced magnetic resonance imaging (MRI) techniques. Recently, despite deep learning techniques being widely employed in solving segmentation tasks in a variety of medical images, the sheer volume and complexity of the data in some applications such as cine cardiac MRI pose significant challenges for the accurate and efficient segmentation. In cine cardiac MRI we need to segment both short and long axis 2D images. In this paper, we focus on the automated segmentation of short-axis cardiac MRI images. We first introduce the deep layer aggregation (DLA) method to augment the standard deep learning architecture with deeper aggregation to better fuse information across layers, which is particularly suitable for the cardiac MRI segmentation, due to the complexity of the cardiac boundaries appearance and acquisition resolution during a cardiac cycle. In our solution, we develop a modified DLA framework by embedding Refinement Residual Block (RRB) and Channel Attention Block (CAB). Experimental results validate the superior performance of our proposed method for the cardiac structures segmentation in comparison with state-of-the-art. Moreover, we demonstrate its potential use case in the quantitative analysis of cardiac dyssynchrony.",,,,2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019),,2019-04-11,2019,,2019-04-11,0,,793-797,Closed,Proceeding,"Li, Zhongyu; Lou, Yixuan; Yan, Zhennan; Al’Aref, Subhi; Min, James K; Axel, Leon; Metaxas, Dimitris N.","Li, Zhongyu (Department of Computer Science, Rutgers University, Piscataway, NJ, USA); Lou, Yixuan (Albany Academy for Girls, Albany, NY, US); Yan, Zhennan (Department of Computer Science, Rutgers University, Piscataway, NJ, USA); Al’Aref, Subhi (Weill Cornell Medical School, NY, US); Min, James K (Weill Cornell Medical School, NY, US); Axel, Leon (Department of Radiology, NYU School of Medicine, NY, US); Metaxas, Dimitris N. (Department of Computer Science, Rutgers University, Piscataway, NJ, USA)","Li, Zhongyu (Rutgers, The State University of New Jersey)","Li, Zhongyu (Rutgers, The State University of New Jersey); Lou, Yixuan (); Yan, Zhennan (Rutgers, The State University of New Jersey); Al’Aref, Subhi (Cornell University); Min, James K (Cornell University); Axel, Leon (New York University); Metaxas, Dimitris N. (Rutgers, The State University of New Jersey)",6,4,,1.17,,https://app.dimensions.ai/details/publication/pub.1117944727,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,,
1612,pub.1119416269,10.48550/arxiv.1904.05236,,,Curriculum semi-supervised segmentation,"This study investigates a curriculum-style strategy for semi-supervised CNN
segmentation, which devises a regression network to learn image-level
information such as the size of a target region. These regressions are used to
effectively regularize the segmentation network, constraining softmax
predictions of the unlabeled images to match the inferred label distributions.
Our framework is based on inequality constraints that tolerate uncertainties
with inferred knowledge, e.g., regressed region size, and can be employed for a
large variety of region attributes. We evaluated our proposed strategy for left
ventricle segmentation in magnetic resonance images (MRI), and compared it to
standard proposal-based semi-supervision strategies. Our strategy leverages
unlabeled data in more efficiently, and achieves very competitive results,
approaching the performance of full-supervision.",,,arXiv,,,2019-04-10,2019,,,,,,All OA, Green,Preprint,"Kervadec, Hoel; Dolz, Jose; Granger, Eric; Ayed, Ismail Ben","Kervadec, Hoel (); Dolz, Jose (); Granger, Eric (); Ayed, Ismail Ben ()",,"Kervadec, Hoel (); Dolz, Jose (); Granger, Eric (); Ayed, Ismail Ben ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119416269,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation,,,,,,,,,,
1649,pub.1112830776,10.1117/12.2511610,,,Left ventricle segmentation in LGE-MRI using multiclass learning,"Cardiovascular diseases are the major cause of death worldwide. Magnetic resonance imaging (MRI) is often used for the diagnosis of cardiac diseases because of its good soft tissue contrast. Furthermore, the fibrosis characterization of the myocardium can be important for accurate diagnosis and treatment planning. The clinical gold standard to visualize myocardial scarring is late gadolinium enhanced (LGE) MRI. However, the challenge arises in the accurate segmentation of the endocardial and epicardial border because of the smooth transition between the blood pool and scarred myocardium, as contrast agent accumulates in the damaged tissue and leads to hyper-enhancements. An exact segmentation, is essential for the scar tissue quantification. We propose a deep learning-based method to segment the left ventricle’s endocardium and epicardium in LGE-MRI. To this end, a multi-scale fully convolutional neural network with skip-connections (U-Net) and residual units is applied to solve the multiclass segmentation problem. As a loss function, weighted cross-entropy is used. The network is trained on 70 clinical LGE MRI sequences, validated with 5, and evaluated with 26 data sets. The approach yields a mean Dice coefficient of 0.90 for the endocard and 0.87 for the epicard. The proposed method segments the endocardium and epicardium of the left ventricle fully automatically with a high accuracy.",,,Progress in Biomedical Optics and Imaging,Medical Imaging 2019: Image Processing,,2019-03-15,2019,,,10949,,1094929-1094929-6,Closed,Proceeding,"Kurzendorfer, Tanja; Breininger, Katharina; Steidl, Stefan; Maier, Andreas; Fahrig, Rebecca","Kurzendorfer, Tanja (Siemens Healthcare GmbH (Germany)); Breininger, Katharina (Friedrich-Alexander-Univ. Erlangen-Nürnberg (Germany)); Steidl, Stefan (Friedrich-Alexander-Univ. Erlangen-Nürnberg (Germany)); Maier, Andreas (Friedrich-Alexander-Univ. Erlangen-Nürnberg (Germany)); Fahrig, Rebecca (Siemens Healthcare GmbH (Germany))",,"Kurzendorfer, Tanja (Siemens Healthcare (Germany)); Breininger, Katharina (University of Erlangen-Nuremberg); Steidl, Stefan (University of Erlangen-Nuremberg); Maier, Andreas (University of Erlangen-Nuremberg); Fahrig, Rebecca (Siemens Healthcare (Germany))",1,1,,0.19,,https://app.dimensions.ai/details/publication/pub.1112830776,32 Biomedical and Clinical Sciences, 40 Engineering, 4003 Biomedical Engineering,,,,,,,,,,
1613,pub.1112765185,10.1117/12.2511699,,,Towards increased trustworthiness of deep learning segmentation methods on cardiac MRI,"Current state-of-the-art deep learning segmentation methods have not yet made a broad entrance into the clinical setting in spite of high demand for such automatic methods. One important reason is the lack of reliability caused by models that fail unnoticed and often locally produce anatomically implausible results that medical experts would not make. This paper presents an automatic image segmentation method based on (Bayesian) dilated convolutional networks (DCNN) that generate segmentation masks and spatial uncertainty maps for the input image at hand. The method was trained and evaluated using segmentation of the left ventricle (LV) cavity, right ventricle (RV) endocardium and myocardium (Myo) at end-diastole (ED) and end-systole (ES) in 100 cardiac 2D MR scans from the MICCAI 2017 Challenge (ACDC). Combining segmentations and uncertainty maps and employing a human-in-the-loop setting, we provide evidence that image areas indicated as highly uncertain, regarding the obtained segmentation, almost entirely cover regions of incorrect segmentations. The fused information can be harnessed to increase segmentation performance. Our results reveal that we can obtain valuable spatial uncertainty maps with low computational effort using DCNNs.",,,Progress in Biomedical Optics and Imaging,Medical Imaging 2019: Image Processing,,2019-03-15,2019,,,10949,,1094919-1094919-7,All OA, Green,Proceeding,"Sander, Jörg; de Vos, Bob D.; Wolterink, Jelmer M.; Išgum, Ivana","Sander, Jörg (Univ. Medical Ctr. Utrecht (Netherlands)); de Vos, Bob D. (Univ. Medical Ctr. Utrecht (Netherlands)); Wolterink, Jelmer M. (Univ. Medical Ctr. Utrecht (Netherlands)); Išgum, Ivana (Univ. Medical Ctr. Utrecht (Netherlands))",,"Sander, Jörg (University Medical Center Utrecht); de Vos, Bob D. (University Medical Center Utrecht); Wolterink, Jelmer M. (University Medical Center Utrecht); Išgum, Ivana (University Medical Center Utrecht)",31,19,,6.03,http://arxiv.org/pdf/1809.10430,https://app.dimensions.ai/details/publication/pub.1112765185,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
5206,pub.1112520086,10.1007/s12350-019-01674-3,30834498,,Left ventricle segmentation in the era of deep learning,,,,Journal of Nuclear Cardiology,,"Deep Learning; Feasibility Studies; Heart Ventricles; Image Processing, Computer-Assisted; Tomography, Emission-Computed, Single-Photon",2019-03-04,2019,2019-03-04,2020-06,27,3,988-991,All OA, Bronze,Article,"Wolterink, Jelmer M.","Wolterink, Jelmer M. (Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands)","Wolterink, Jelmer M. (University Medical Center Utrecht)","Wolterink, Jelmer M. (University Medical Center Utrecht)",5,3,0.76,2.8,https://link.springer.com/content/pdf/10.1007/s12350-019-01674-3.pdf,https://app.dimensions.ai/details/publication/pub.1112520086,32 Biomedical and Clinical Sciences, 3201 Cardiovascular Medicine and Haematology,,,,,,,,,,
3833,pub.1112313554,10.1109/tmi.2019.2900516,30802851,,Deep Learning for Segmentation Using an Open Large-Scale Dataset in 2D Echocardiography,"Delineation of the cardiac structures from 2D echocardiographic images is a common clinical task to establish a diagnosis. Over the past decades, the automation of this task has been the subject of intense research. In this paper, we evaluate how far the state-of-the-art encoder-decoder deep convolutional neural network methods can go at assessing 2D echocardiographic images, i.e., segmenting cardiac structures and estimating clinical indices, on a dataset, especially, designed to answer this objective. We, therefore, introduce the cardiac acquisitions for multi-structure ultrasound segmentation dataset, the largest publicly-available and fully-annotated dataset for the purpose of echocardiographic assessment. The dataset contains two and four-chamber acquisitions from 500 patients with reference measurements from one cardiologist on the full dataset and from three cardiologists on a fold of 50 patients. Results show that encoder-decoder-based architectures outperform state-of-the-art non-deep learning methods and faithfully reproduce the expert analysis for the end-diastolic and end-systolic left ventricular volumes, with a mean correlation of 0.95 and an absolute mean error of 9.5 ml. Concerning the ejection fraction of the left ventricle, results are more contrasted with a mean correlation coefficient of 0.80 and an absolute mean error of 5.6%. Although these results are below the inter-observer scores, they remain slightly worse than the intra-observer's ones. Based on this observation, areas for improvement are defined, which open the door for accurate and fully-automatic analysis of 2D echocardiographic images.","This work was supported in part by the framework of the LABEX PRIMES (ANR-11-LABX-0063) of the Université de Lyon, within the program “Investissements d’Avenir” (ANR-11-IDEX-0007) operated by the French National Research Agency (ANR), and the Centre for Innovative Ultrasound Solutions through the Norwegian Research Council under Project 237887.",,IEEE Transactions on Medical Imaging,,"Algorithms; Databases, Factual; Deep Learning; Echocardiography; Heart; Humans; Image Processing, Computer-Assisted",2019-02-22,2019,2019-02-22,2019-09,38,9,2198-2210,All OA, Green,Article,"Leclerc, Sarah; Smistad, Erik; Pedrosa, João; Østvik, Andreas; Cervenansky, Frederic; Espinosa, Florian; Espeland, Torvald; Berg, Erik Andreas Rye; Jodoin, Pierre-Marc; Grenier, Thomas; Lartizien, Carole; D’hooge, Jan; Lovstakken, Lasse; Bernard, Olivier","Leclerc, Sarah (University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, 69100, Villeurbanne, France); Smistad, Erik (Center of Innovative Ultrasound Solutions, Department of Circulation and Medical Imaging, Norwegian University of Science and Technology, 7491, Trondheim, Norway); Pedrosa, João (Department of Cardiovascular Sciences, KU Leuven, 3000, Leuven, Belgium); Østvik, Andreas (Center of Innovative Ultrasound Solutions, Department of Circulation and Medical Imaging, Norwegian University of Science and Technology, 7491, Trondheim, Norway); Cervenansky, Frederic (University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, 69100, Villeurbanne, France); Espinosa, Florian (Cardiovascular Department, Centre Hospitalier Universitaire de Saint-Etienne, 42270, Saint-Etienne, France); Espeland, Torvald (Center of Innovative Ultrasound Solutions and the Clinic of Cardiology, St. Olavs Hospital, 7030, Trondheim, Norway; Computer Science Department, University of Sherbrooke, Sherbrooke, QC, J1K2R1, Canada); Berg, Erik Andreas Rye (Center of Innovative Ultrasound Solutions and the Clinic of Cardiology, St. Olavs Hospital, 7030, Trondheim, Norway); Jodoin, Pierre-Marc (Computer Science Department, University of Sherbrooke, Sherbrooke, QC, J1K2R1, Canada); Grenier, Thomas (University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, 69100, Villeurbanne, France); Lartizien, Carole (University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, 69100, Villeurbanne, France); D’hooge, Jan (Department of Cardiovascular Sciences, KU Leuven, 3000, Leuven, Belgium); Lovstakken, Lasse (Center of Innovative Ultrasound Solutions, Department of Circulation and Medical Imaging, Norwegian University of Science and Technology, 7491, Trondheim, Norway); Bernard, Olivier (University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, 69100, Villeurbanne, France)","Leclerc, Sarah (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé)","Leclerc, Sarah (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé); Smistad, Erik (Norwegian University of Science and Technology); Pedrosa, João (KU Leuven); Østvik, Andreas (Norwegian University of Science and Technology); Cervenansky, Frederic (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé); Espinosa, Florian (Centre Hospitalier Universitaire de Saint-Étienne); Espeland, Torvald (St Olav's University Hospital; Université de Sherbrooke); Berg, Erik Andreas Rye (St Olav's University Hospital); Jodoin, Pierre-Marc (Université de Sherbrooke); Grenier, Thomas (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé); Lartizien, Carole (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé); D’hooge, Jan (KU Leuven); Lovstakken, Lasse (Norwegian University of Science and Technology); Bernard, Olivier (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé)",201,154,10.47,,https://hal.archives-ouvertes.fr/hal-02054458/file/tmi_2019_Leclerc.pdf,https://app.dimensions.ai/details/publication/pub.1112313554,46 Information and Computing Sciences,,,,,,,,,,,
1348,pub.1111810558,10.1109/lra.2019.2896518,,,Normalization in Training U-Net for 2-D Biomedical Semantic Segmentation,"Two-dimensional (2-D) biomedical semantic segmentation is important for robotic vision in surgery. Segmentation methods based on deep convolutional neural network (DCNN) can out-perform conventional methods in terms of both accuracy and levels of automation. One common issue in training a DCNN for biomedical semantic segmentation is the internal covariate shift where the training of convolutional kernels is encumbered by the distribution change of input features, hence both the training speed and performance are decreased. Batch normalization (BN) is the first proposed method for addressing internal covariate shift and is widely used. Instance normalization (IN) and layer normalization (LN) have also been proposed. Group normalization (GN) is proposed more recently and has not yet been applied to 2-D biomedical semantic segmentation (GN was used in 3-D biomedical semantic segmentation in [P.-Y. Kao, T. Ngo, A. Zhang, J. Chen, and B. Manjunath, Brain tumor segmentation and tractographic feature extraction from structural MR images for overall survival prediction 2018, arXiv:1807.07716], however, no specific validations on GN were given). Most DCNNs for biomedical semantic segmentation adopt BN as the normalization method by default, without reviewing its performance. In this letter, four normalization methods—BN, IN, LN, and GN are compared in details, specifically for 2-D biomedical semantic segmentation. U-Net is adopted as the basic DCNN structure. Three datasets regarding the right ventricle, aorta, and left ventricle are used for the validation. The results show that detailed subdivision of the feature map, i.e., GN with a large group number or IN, achieves higher accuracy. This accuracy improvement mainly comes from better model generalization. Codes are uploaded and maintained at Xiao-Yun Zhou's Github.",,,IEEE Robotics and Automation Letters,,,2019-02-22,2019,2019-02-22,,4,2,1792-1799,All OA, Green,Article,"Zhou, Xiao-Yun; Yang, Guang-Zhong","Zhou, Xiao-Yun (Hamlyn Centre for Robotic Surgery, Imperial College London, London, U.K.); Yang, Guang-Zhong (Hamlyn Centre for Robotic Surgery, Imperial College London, London, U.K.)",,"Zhou, Xiao-Yun (Imperial College London); Yang, Guang-Zhong (Imperial College London)",54,35,,20.69,http://arxiv.org/pdf/1809.03783,https://app.dimensions.ai/details/publication/pub.1111810558,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
534,pub.1119427782,10.48550/arxiv.1902.11122,,,Deep Learning in Cardiology,"The medical field is creating large amount of data that physicians are unable
to decipher and use efficiently. Moreover, rule-based expert systems are
inefficient in solving complicated medical tasks or for creating insights using
big data. Deep learning has emerged as a more accurate and effective technology
in a wide range of medical problems such as diagnosis, prediction and
intervention. Deep learning is a representation learning method that consists
of layers that transform the data non-linearly, thus, revealing hierarchical
relationships and structures. In this review we survey deep learning
application papers that use structured data, signal and imaging modalities from
cardiology. We discuss the advantages and limitations of applying deep learning
in cardiology that also apply in medicine in general, while proposing certain
directions as the most viable for clinical use.",,,arXiv,,,2019-02-22,2019,,,,,,All OA, Green,Preprint,"Bizopoulos, Paschalis; Koutsouris, Dimitrios","Bizopoulos, Paschalis (); Koutsouris, Dimitrios ()",,"Bizopoulos, Paschalis (); Koutsouris, Dimitrios ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119427782,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
954,pub.1119417850,10.48550/arxiv.1902.07880,,,Evaluation of Algorithms for Multi-Modality Whole Heart Segmentation: An  Open-Access Grand Challenge,"Knowledge of whole heart anatomy is a prerequisite for many clinical
applications. Whole heart segmentation (WHS), which delineates substructures of
the heart, can be very valuable for modeling and analysis of the anatomy and
functions of the heart. However, automating this segmentation can be arduous
due to the large variation of the heart shape, and different image qualities of
the clinical data. To achieve this goal, a set of training data is generally
needed for constructing priors or for training. In addition, it is difficult to
perform comparisons between different methods, largely due to differences in
the datasets and evaluation metrics used. This manuscript presents the
methodologies and evaluation results for the WHS algorithms selected from the
submissions to the Multi-Modality Whole Heart Segmentation (MM-WHS) challenge,
in conjunction with MICCAI 2017. The challenge provides 120 three-dimensional
cardiac images covering the whole heart, including 60 CT and 60 MRI volumes,
all acquired in clinical environments with manual delineation. Ten algorithms
for CT data and eleven algorithms for MRI data, submitted from twelve groups,
have been evaluated. The results show that many of the deep learning (DL) based
methods achieved high accuracy, even though the number of training datasets was
limited. A number of them also reported poor results in the blinded evaluation,
probably due to overfitting in their training. The conventional algorithms,
mainly based on multi-atlas segmentation, demonstrated robust and stable
performance, even though the accuracy is not as good as the best DL method in
CT segmentation. The challenge, including the provision of the annotated
training data and the blinded evaluation for submitted algorithms on the test
data, continues as an ongoing benchmarking resource via its homepage
(\url{www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mmwhs/}).",,,arXiv,,,2019-02-21,2019,,,,,,All OA, Green,Preprint,"Zhuang, Xiahai; Li, Lei; Payer, Christian; Stern, Darko; Urschler, Martin; Heinrich, Mattias P.; Oster, Julien; Wang, Chunliang; Smedby, Orjan; Bian, Cheng; Yang, Xin; Heng, Pheng-Ann; Mortazi, Aliasghar; Bagci, Ulas; Yang, Guanyu; Sun, Chenchen; Galisot, Gaetan; Ramel, Jean-Yves; Brouard, Thierry; Tong, Qianqian; Si, Weixin; Liao, Xiangyun; Zeng, Guodong; Shi, Zenglin; Zheng, Guoyan; Wang, Chengjia; MacGillivray, Tom; Newby, David; Rhode, Kawal; Ourselin, Sebastien; Mohiaddin, Raad; Keegan, Jennifer; Firmin, David; Yang, Guang","Zhuang, Xiahai (); Li, Lei (); Payer, Christian (); Stern, Darko (); Urschler, Martin (); Heinrich, Mattias P. (); Oster, Julien (); Wang, Chunliang (); Smedby, Orjan (); Bian, Cheng (); Yang, Xin (); Heng, Pheng-Ann (); Mortazi, Aliasghar (); Bagci, Ulas (); Yang, Guanyu (); Sun, Chenchen (); Galisot, Gaetan (); Ramel, Jean-Yves (); Brouard, Thierry (); Tong, Qianqian (); Si, Weixin (); Liao, Xiangyun (); Zeng, Guodong (); Shi, Zenglin (); Zheng, Guoyan (); Wang, Chengjia (); MacGillivray, Tom (); Newby, David (); Rhode, Kawal (); Ourselin, Sebastien (); Mohiaddin, Raad (); Keegan, Jennifer (); Firmin, David (); Yang, Guang ()",,"Zhuang, Xiahai (); Li, Lei (); Payer, Christian (); Stern, Darko (); Urschler, Martin (); Heinrich, Mattias P. (); Oster, Julien (); Wang, Chunliang (); Smedby, Orjan (); Bian, Cheng (); Yang, Xin (); Heng, Pheng-Ann (); Mortazi, Aliasghar (); Bagci, Ulas (); Yang, Guanyu (); Sun, Chenchen (); Galisot, Gaetan (); Ramel, Jean-Yves (); Brouard, Thierry (); Tong, Qianqian (); Si, Weixin (); Liao, Xiangyun (); Zeng, Guodong (); Shi, Zenglin (); Zheng, Guoyan (); Wang, Chengjia (); MacGillivray, Tom (); Newby, David (); Rhode, Kawal (); Ourselin, Sebastien (); Mohiaddin, Raad (); Keegan, Jennifer (); Firmin, David (); Yang, Guang ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119417850,32 Biomedical and Clinical Sciences, 46 Information and Computing Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
1582,pub.1112112083,10.1007/978-3-030-12029-0_26,,,Pyramid Network with Online Hard Example Mining for Accurate Left Atrium Segmentation,"Accurately segmenting left atrium in MR volume can benefit the ablation procedure of atrial fibrillation. Traditional automated solutions often fail in relieving experts from the labor-intensive manual labeling. In this paper, we propose a deep neural network based solution for automated left atrium segmentation in gadolinium-enhanced MR volumes with promising performance. We firstly argue that, for this volumetric segmentation task, networks in 2D fashion can present great superiorities in time efficiency and segmentation accuracy than networks with 3D fashion. Considering the highly varying shape of atrium and the branchy structure of associated pulmonary veins, we propose to adopt a pyramid module to collect semantic cues in feature maps from multiple scales for fine-grained segmentation. Also, to promote our network in classifying the hard examples, we propose an Online Hard Negative Example Mining strategy to identify voxels in slices with low classification certainties and penalize the wrong predictions on them. Finally, we devise a competitive training scheme to further boost the generalization ability of networks. Extensively verified on 20 testing volumes, our proposed framework achieves an average Dice of \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$92.83\%$$\end{document} in segmenting the left atria and pulmonary veins.",The work in this paper was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region (Project no. GRF 14225616).,,Lecture Notes in Computer Science,Statistical Atlases and Computational Models of the Heart. Atrial Segmentation and LV Quantification Challenges,,2019-02-14,2019,2019-02-14,2019,11395,,237-245,All OA, Green,Chapter,"Bian, Cheng; Yang, Xin; Ma, Jianqiang; Zheng, Shen; Liu, Yu-An; Nezafat, Reza; Heng, Pheng-Ann; Zheng, Yefeng","Bian, Cheng (Tencent YouTu Lab, Shenzhen, China); Yang, Xin (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, USA); Ma, Jianqiang (Tencent YouTu Lab, Shenzhen, China); Zheng, Shen (Tencent YouTu Lab, Shenzhen, China); Liu, Yu-An (Tencent YouTu Lab, Shenzhen, China); Nezafat, Reza (Department of Medicine (Cardiovascular Division), Beth Israel Deaconess Medical Center and Harvard Medical School, Boston, USA); Heng, Pheng-Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China); Zheng, Yefeng (Tencent YouTu Lab, Shenzhen, China)","Yang, Xin (Chinese University of Hong Kong; Beth Israel Deaconess Medical Center; Harvard University)","Bian, Cheng (); Yang, Xin (Chinese University of Hong Kong; Beth Israel Deaconess Medical Center; Harvard University); Ma, Jianqiang (); Zheng, Shen (); Liu, Yu-An (); Nezafat, Reza (Beth Israel Deaconess Medical Center; Harvard University); Heng, Pheng-Ann (Chinese University of Hong Kong); Zheng, Yefeng ()",20,8,,7.66,http://arxiv.org/pdf/1812.05802,https://app.dimensions.ai/details/publication/pub.1112112083,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1400,pub.1119384572,10.48550/arxiv.1902.05396,,,Semi-Supervised and Task-Driven Data Augmentation,"Supervised deep learning methods for segmentation require large amounts of
labelled training data, without which they are prone to overfitting, not
generalizing well to unseen images. In practice, obtaining a large number of
annotations from clinical experts is expensive and time-consuming. One way to
address scarcity of annotated examples is data augmentation using random
spatial and intensity transformations. Recently, it has been proposed to use
generative models to synthesize realistic training examples, complementing the
random augmentation. So far, these methods have yielded limited gains over the
random augmentation. However, there is potential to improve the approach by (i)
explicitly modeling deformation fields (non-affine spatial transformation) and
intensity transformations and (ii) leveraging unlabelled data during the
generative process. With this motivation, we propose a novel task-driven data
augmentation method where to synthesize new training examples, a generative
network explicitly models and applies deformation fields and additive intensity
masks on existing labelled data, modeling shape and intensity variations,
respectively. Crucially, the generative model is optimized to be conducive to
the task, in this case segmentation, and constrained to match the distribution
of images observed from labelled and unlabelled samples. Furthermore, explicit
modeling of deformation fields allow synthesizing segmentation masks and images
in exact correspondence by simply applying the generated transformation to an
input image and the corresponding annotation. Our experiments on cardiac
magnetic resonance images (MRI) showed that, for the task of segmentation in
small training data scenarios, the proposed method substantially outperforms
conventional augmentation techniques.",,,arXiv,,,2019-02-11,2019,,,,,,All OA, Green,Preprint,"Chaitanya, Krishna; Karani, Neerav; Baumgartner, Christian; Donati, Olivio; Becker, Anton; Konukoglu, Ender","Chaitanya, Krishna (); Karani, Neerav (); Baumgartner, Christian (); Donati, Olivio (); Becker, Anton (); Konukoglu, Ender ()",,"Chaitanya, Krishna (); Karani, Neerav (); Baumgartner, Christian (); Donati, Olivio (); Becker, Anton (); Konukoglu, Ender ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119384572,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1133,pub.1111949456,10.1007/s11042-019-7305-1,,,Recurrent generative adversarial network for learning imbalanced medical image semantic segmentation,"We propose a new recurrent generative adversarial architecture named RNN-GAN to mitigate imbalance data problem in medical image semantic segmentation where the number of pixels belongs to the desired object are significantly lower than those belonging to the background. A model trained with imbalanced data tends to bias towards healthy data which is not desired in clinical applications and predicted outputs by these networks have high precision and low recall. To mitigate imbalanced training data impact, we train RNN-GAN with proposed complementary segmentation mask, in addition, ordinary segmentation masks. The RNN-GAN consists of two components: a generator and a discriminator. The generator is trained on the sequence of medical images to learn corresponding segmentation label map plus proposed complementary label both at a pixel level, while the discriminator is trained to distinguish a segmentation image coming from the ground truth or from the generator network. Both generator and discriminator substituted with bidirectional LSTM units to enhance temporal consistency and get inter and intra-slice representation of the features. We show evidence that the proposed framework is applicable to different types of medical images of varied sizes. In our experiments on ACDC-2017, HVSMR-2016, and LiTS-2017 benchmarks we find consistently improved results, demonstrating the efficacy of our approach.",,,Multimedia Tools and Applications,,,2019-02-07,2019,2019-02-07,2020-06,79,21-22,15329-15348,Closed,Article,"Rezaei, Mina; Yang, Haojin; Meinel, Christoph","Rezaei, Mina (Hasso Plattner Institute, Prof. Dr. Helmert Street 2-3, Potsdam, Germany); Yang, Haojin (Hasso Plattner Institute, Prof. Dr. Helmert Street 2-3, Potsdam, Germany); Meinel, Christoph (Hasso Plattner Institute, Prof. Dr. Helmert Street 2-3, Potsdam, Germany)","Rezaei, Mina (Hasso Plattner Institute)","Rezaei, Mina (Hasso Plattner Institute); Yang, Haojin (Hasso Plattner Institute); Meinel, Christoph (Hasso Plattner Institute)",37,28,,14.0,,https://app.dimensions.ai/details/publication/pub.1111949456,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,,
4043,pub.1111911323,10.1109/tmi.2019.2897112,30716033,,Learning a Probabilistic Model for Diffeomorphic Registration,"We propose to learn a low-dimensional probabilistic deformation model from data which can be used for the registration and the analysis of deformations. The latent variable model maps similar deformations close to each other in an encoding space. It enables to compare deformations, to generate normal or pathological deformations for any new image, or to transport deformations from one image pair to any other image. Our unsupervised method is based on the variational inference. In particular, we use a conditional variational autoencoder network and constrain transformations to be symmetric and diffeomorphic by applying a differentiable exponentiation layer with a symmetric loss function. We also present a formulation that includes spatial regularization such as the diffusion-based filters. In addition, our framework provides multi-scale velocity field estimations. We evaluated our method on 3-D intra-subject registration using 334 cardiac cine-MRIs. On this dataset, our method showed the state-of-the-art performance with a mean DICE score of 81.2% and a mean Hausdorff distance of 7.3 mm using 32 latent dimensions compared to three state-of-the-art methods while also demonstrating more regular deformation fields. The average time per registration was 0.32 s. Besides, we visualized the learned latent space and showed that the encoded deformations can be used to transport deformations and to cluster diseases with a classification accuracy of 83% after applying a linear projection.","This work was supported in part by AAP Santé under Grant 06 2017-260 DGA-DSH and the INRIA Sophia Antipolis–Méditerranée, “NEF” computation cluster. Data used in preparation of this article were obtained from the EU FP7-funded project MD-Paedigree (Grant Agreement 600932) and the ACDC STACOM challenge 2017 [54]. The authors would like to thank Xavier Pennec for the insightful discussions and Adrian Dalca for the help with the Voxelmorph [27] experiments. Disclaimer: This feature is based on research, and is not commercially available. Due to regulatory reasons its future availability cannot be guaranteed.",,IEEE Transactions on Medical Imaging,,"Algorithms; Deep Learning; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Models, Statistical",2019-02-04,2019,2019-02-04,2019-09,38,9,2165-2176,All OA, Green,Article,"Krebs, Julian; Delingette, Hervé; Mailhé, Boris; Ayache, Nicholas; Mansi, Tommaso","Krebs, Julian (Université Côte d’Azur, Inria, Epione Team, 06902, Sophia Antipolis, France; Siemens Healthineers, Digital Services, Digital Technology and Innovation, Princeton, NJ, 08540, USA); Delingette, Hervé (Université Côte d’Azur, Inria, Epione Team, 06902, Sophia Antipolis, France); Mailhé, Boris (Siemens Healthineers, Digital Services, Digital Technology and Innovation, Princeton, NJ, 08540, USA); Ayache, Nicholas (Université Côte d’Azur, Inria, Epione Team, 06902, Sophia Antipolis, France); Mansi, Tommaso (Siemens Healthineers, Digital Services, Digital Technology and Innovation, Princeton, NJ, 08540, USA)","Krebs, Julian (; Siemens Healthcare (United States))","Krebs, Julian (Siemens Healthcare (United States)); Delingette, Hervé (); Mailhé, Boris (Siemens Healthcare (United States)); Ayache, Nicholas (); Mansi, Tommaso (Siemens Healthcare (United States))",124,78,5.62,46.91,http://arxiv.org/pdf/1812.07460,https://app.dimensions.ai/details/publication/pub.1111911323,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
1011,pub.1111797506,10.1007/978-3-319-94878-2_13,,,Cardiovascular Diseases,"Cross-sectional imaging techniques—echocardiography, CT, MRI and nuclear medicine—are the diagnostic tools of choice for the diagnosis and workup of cardiovascular disease. Machine learning and deep learning in particular will have a fundamental and lasting impact on all of these modalities. Whereas deep learning is mostly discussed in the context of image interpretation, we show that the impact is much broader than this. The entire imaging chain from choosing the appropriate imaging test to acquiring the proper images, reconstruction of images from raw data, image interpretation, reporting and derivation of prognostic information can be improved by application of machine learning and deep learning techniques. Application of machine learning and deep learning algorithms will be an important step towards fulfilling the promise of truly personalized medicine, especially when information from imaging is combined with other data such as the results from laboratory evaluations, genetic analysis, medication use and personal fitness trackers. Nevertheless, the process of bringing the results to physicians is nontrivial, and we also discuss our experience with deployment of developed algorithms in clinical practice.",,,,Artificial Intelligence in Medical Imaging,,2019-01-30,2019,2019-01-30,2019,,,167-185,Closed,Chapter,"Verjans, Johan; Veldhuis, Wouter B.; Carneiro, Gustavo; Wolterink, Jelmer M.; Išgum, Ivana; Leiner, Tim","Verjans, Johan (Department of Cardiology, South Australian Health and Medical Research Institute, University of Adelaide, Adelaide, SA, Australia; Department of Cardiology, Utrecht University Medical Center, Utrecht, The Netherlands); Veldhuis, Wouter B. (Department of Radiology, Utrecht University Medical Center, Utrecht, The Netherlands); Carneiro, Gustavo (Department of Cardiology, South Australian Health and Medical Research Institute, University of Adelaide, Adelaide, SA, Australia); Wolterink, Jelmer M. (Image Sciences Institute, Utrecht University Medical Center, Utrecht, The Netherlands); Išgum, Ivana (Image Sciences Institute, Utrecht University Medical Center, Utrecht, The Netherlands); Leiner, Tim (Department of Radiology, Utrecht University Medical Center, Utrecht, The Netherlands)","Leiner, Tim (University Medical Center Utrecht)","Verjans, Johan (University of Adelaide; University Medical Center Utrecht); Veldhuis, Wouter B. (University Medical Center Utrecht); Carneiro, Gustavo (University of Adelaide); Wolterink, Jelmer M. (University Medical Center Utrecht); Išgum, Ivana (University Medical Center Utrecht); Leiner, Tim (University Medical Center Utrecht)",3,2,,0.64,,https://app.dimensions.ai/details/publication/pub.1111797506,31 Biological Sciences, 3105 Genetics, 32 Biomedical and Clinical Sciences,3 Good Health and Well Being,,,,,,,,,
1544,pub.1120615430,10.1109/icip.2019.8803163,,,Unsupervised Three-Dimensional Image Registration Using a Cycle Convolutional Neural Network,"In this paper, an unsupervised cycle image registration convolutional neural network named CIRNet is developed for 3D medical image registration. Different from most deep learning based registration methods that require known spatial transforms, our proposed method is trained in an unsupervised way and predicts the dense displacement vector field. The CIRNet is composed by two image registration modules which have the same architecture and share the parameters. A cycle identical loss is designed in the CIRNet to provide additional constraints to ensure the accuracy of the predicted dense displacement vector field. The method is evaluated by the registration in 4D (3D+t) cardiac CT and MRI images respectively. Quantitative evaluation results demonstrate that our method performs better than the other two existing image registration algorithms. Especially, compared to the traditional image registration methods, our proposed network can finish 3D image registration in less than one second.","This research was supported by the National Key Research and Development Program of China (2017YFC0107903), the National Natural Science Foundation under grants (31571001, 61828101), the Short-Term Recruitment Program of Foreign Experts (WQ20163200398), and the Science Foundation for The Excellent Youth Scholars of Southeast University. This research was supported by the Nation- al Key Research and Development Program of China (2017YFC0107903), the National Natural Science Foundation under grants (31571001, 61828101), the Short-Term Recruitment Program of Foreign Experts (WQ20163200398), and the Science Foundation for The Excellent Youth Scholars of Southeast University.",,,2019 IEEE International Conference on Image Processing (ICIP),,2019-01-25,2019,,2019-01-25,0,,2174-2178,All OA, Green,Proceeding,"Lu, Ziwei; Yang, Guanyu; Hua, Tiancong; Hu, Liyu; Kong, Youyong; Tang, Lijun; Zhu, Xiaomei; Dillenseger, Jean-Louis; Shu, Huazhong; Coatrieux, Jean-Louis","Lu, Ziwei (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China); Yang, Guanyu (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs)); Hua, Tiancong (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China); Hu, Liyu (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China); Kong, Youyong (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs)); Tang, Lijun (Dept. of Radiology, the First Affiliated Hospital of Nanjing Medical University, Nanjing, China); Zhu, Xiaomei (Dept. of Radiology, the First Affiliated Hospital of Nanjing Medical University, Nanjing, China); Dillenseger, Jean-Louis (Univ Rennes, Inserm, LTSI - UMR1099, Rennes, F-35000, France; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs)); Shu, Huazhong (LIST, Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs)); Coatrieux, Jean-Louis (Univ Rennes, Inserm, LTSI - UMR1099, Rennes, F-35000, France; Centre de Recherche en Information Biomédicale Sino-Français (CRIBs))","Yang, Guanyu (Ministry of Education of the People's Republic of China; )","Lu, Ziwei (Ministry of Education of the People's Republic of China); Yang, Guanyu (Ministry of Education of the People's Republic of China); Hua, Tiancong (Ministry of Education of the People's Republic of China); Hu, Liyu (Ministry of Education of the People's Republic of China); Kong, Youyong (Ministry of Education of the People's Republic of China); Tang, Lijun (Jiangsu Province Hospital); Zhu, Xiaomei (Jiangsu Province Hospital); Dillenseger, Jean-Louis (University of Rennes 1); Shu, Huazhong (Ministry of Education of the People's Republic of China); Coatrieux, Jean-Louis (University of Rennes 1)",4,4,,2.79,https://hal.archives-ouvertes.fr/hal-02281541/file/ziwaiLu-1%20%281%29.pdf,https://app.dimensions.ai/details/publication/pub.1120615430,32 Biomedical and Clinical Sciences, 46 Information and Computing Sciences, 51 Physical Sciences, 5105 Medical and Biological Physics,,,,,,,,
3654,pub.1111636818,10.1109/tmi.2019.2894322,30676949,PMC6728160,Automatic 3D Bi-Ventricular Segmentation of Cardiac Images by a Shape-Refined Multi- Task Deep Learning Approach,"Deep learning approaches have achieved state-of-the-art performance in cardiac magnetic resonance (CMR) image segmentation. However, most approaches have focused on learning image intensity features for segmentation, whereas the incorporation of anatomical shape priors has received less attention. In this paper, we combine a multi-task deep learning approach with atlas propagation to develop a shape-refined bi-ventricular segmentation pipeline for short-axis CMR volumetric images. The pipeline first employs a fully convolutional network (FCN) that learns segmentation and landmark localization tasks simultaneously. The architecture of the proposed FCN uses a 2.5D representation, thus combining the computational advantage of 2D FCNs networks and the capability of addressing 3D spatial consistency without compromising segmentation accuracy. Moreover, a refinement step is designed to explicitly impose shape prior knowledge and improve segmentation quality. This step is effective for overcoming image artifacts (e.g., due to different breath-hold positions and large slice thickness), which preclude the creation of anatomically meaningful 3D cardiac shapes. The pipeline is fully automated, due to network's ability to infer landmarks, which are then used downstream in the pipeline to initialize atlas propagation. We validate the pipeline on 1831 healthy subjects and 649 subjects with pulmonary hypertension. Extensive numerical experiments on the two datasets demonstrate that our proposed method is robust and capable of producing accurate, high-resolution, and anatomically smooth bi-ventricular 3D models, despite the presence of artifacts in input CMR volumes.","This work was supported in part by the British Heart Foundation under Grants NH/17/1/32725 and RE/13/4/30184, the EPSRC Smart-Heart Programme under Grant EP/P001009/1, the National Institute for Health Research Biomedical Research Centre based at the Imperial College Healthcare NHS Trust and the Imperial College London, and the Medical Research Council, U.K. The authors would like to thank Dr Simon Gibbs, Dr Luke Howard and Prof Martin Wilkins for providing the CMR image data. The TITAN Xp GPU used for this research was kindly donated by the NVIDIA Corporation.",,IEEE Transactions on Medical Imaging,,"Algorithms; Cardiac Imaging Techniques; Deep Learning; Heart; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging, Cine",2019-01-23,2019,2019-01-23,2019-09,38,9,2151-2164,All OA, Hybrid,Article,"Duan, Jinming; Bello, Ghalib; Schlemper, Jo; Bai, Wenjia; Dawes, Timothy J. W.; Biffi, Carlo; de Marvao, Antonio; Doumoud, Georgia; O’Regan, Declan P.; Rueckert, Daniel","Duan, Jinming (Biomedical Image Analysis Group, Imperial College London, London, SW7 2AZ, U.K.; MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Bello, Ghalib (MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Schlemper, Jo (Biomedical Image Analysis Group, Imperial College London, London, SW7 2AZ, U.K.); Bai, Wenjia (Biomedical Image Analysis Group, Imperial College London, London, SW7 2AZ, U.K.); Dawes, Timothy J. W. (MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.; National Heart and Lung Institute, Imperial College London, London, SW3 6LY, U.K.); Biffi, Carlo (Biomedical Image Analysis Group, Imperial College London, London, SW7 2AZ, U.K.); de Marvao, Antonio (MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Doumoud, Georgia (MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); O’Regan, Declan P. (MRC London Institute of Medical Sciences, Imperial College London, London, W12 0NN, U.K.); Rueckert, Daniel (Biomedical Image Analysis Group, Imperial College London, London, SW7 2AZ, U.K.)","Duan, Jinming (Imperial College London; Medical Research Council)","Duan, Jinming (Imperial College London; Medical Research Council); Bello, Ghalib (Medical Research Council); Schlemper, Jo (Imperial College London); Bai, Wenjia (Imperial College London); Dawes, Timothy J. W. (Medical Research Council; Imperial College London); Biffi, Carlo (Imperial College London); de Marvao, Antonio (Medical Research Council); Doumoud, Georgia (Medical Research Council); O’Regan, Declan P. (Medical Research Council); Rueckert, Daniel (Imperial College London)",123,81,5.7,54.14,https://ieeexplore.ieee.org/ielx7/42/8821423/08624549.pdf,https://app.dimensions.ai/details/publication/pub.1111636818,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
4837,pub.1111064107,10.1186/s12968-018-0509-0,30612574,PMC6322266,Machine learning derived segmentation of phase velocity encoded cardiovascular magnetic resonance for fully automated aortic flow quantification,"BackgroundPhase contrast (PC) cardiovascular magnetic resonance (CMR) is widely employed for flow quantification, but analysis typically requires time consuming manual segmentation which can require human correction. Advances in machine learning have markedly improved automated processing, but have yet to be applied to PC-CMR. This study tested a novel machine learning model for fully automated analysis of PC-CMR aortic flow.MethodsA machine learning model was designed to track aortic valve borders based on neural network approaches. The model was trained in a derivation cohort encompassing 150 patients who underwent clinical PC-CMR then compared to manual and commercially-available automated segmentation in a prospective validation cohort. Further validation testing was performed in an external cohort acquired from a different site/CMR vendor.ResultsAmong 190 coronary artery disease patients prospectively undergoing CMR on commercial scanners (84% 1.5T, 16% 3T), machine learning segmentation was uniformly successful, requiring no human intervention: Segmentation time was < 0.01 min/case (1.2 min for entire dataset); manual segmentation required 3.96 ± 0.36 min/case (12.5 h for entire dataset). Correlations between machine learning and manual segmentation-derived flow approached unity (r = 0.99, p < 0.001). Machine learning yielded smaller absolute differences with manual segmentation than did commercial automation (1.85 ± 1.80 vs. 3.33 ± 3.18 mL, p < 0.01): Nearly all (98%) of cases differed by ≤5 mL between machine learning and manual methods. Among patients without advanced mitral regurgitation, machine learning correlated well (r = 0.63, p < 0.001) and yielded small differences with cine-CMR stroke volume (∆ 1.3 ± 17.7 mL, p = 0.36). Among advanced mitral regurgitation patients, machine learning yielded lower stroke volume than did volumetric cine-CMR (∆ 12.6 ± 20.9 mL, p = 0.005), further supporting validity of this method. Among the external validation cohort (n = 80) acquired using a different CMR vendor, the algorithm yielded equivalently small differences (∆ 1.39 ± 1.77 mL, p = 0.4) and high correlations (r = 0.99, p < 0.001) with manual segmentation, including similar results in 20 patients with bicuspid or stenotic aortic valve pathology (∆ 1.71 ± 2.25 mL, p = 0.25).ConclusionFully automated machine learning PC-CMR segmentation performs robustly for aortic flow quantification - yielding rapid segmentation, small differences with manual segmentation, and identification of differential forward/left ventricular volumetric stroke volume in context of concomitant mitral regurgitation. Findings support use of machine learning for analysis of large scale CMR datasets.",Not applicable.,,Journal of Cardiovascular Magnetic Resonance,,"Aged; Aorta; Aortic Valve; Automation; Blood Flow Velocity; Female; Heart Diseases; Hemodynamics; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Myocardial Perfusion Imaging; Predictive Value of Tests; Proof of Concept Study; Prospective Studies; Reproducibility of Results; Retrospective Studies; United States",2019-01-07,2019,2019-01-07,2019-12,21,1,1,All OA, Gold,Article,"Bratt, Alex; Kim, Jiwon; Pollie, Meridith; Beecy, Ashley N.; Tehrani, Nathan H.; Codella, Noel; Perez-Johnston, Rocio; Palumbo, Maria Chiara; Alakbarli, Javid; Colizza, Wayne; Drexler, Ian R.; Azevedo, Clerio F.; Kim, Raymond J.; Devereux, Richard B.; Weinsaft, Jonathan W.","Bratt, Alex (Department of Radiology, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Kim, Jiwon (Department of Radiology, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA; Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Pollie, Meridith (Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Beecy, Ashley N. (Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Tehrani, Nathan H. (Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Codella, Noel (IBM TJ Watson Research Center, 1101 Kitchawan Rd, 10598, Yorktown Heights, NY, USA); Perez-Johnston, Rocio (Memorial Sloan Kettering Cancer Center, 1275 York Ave, 10065, New York, NY, USA); Palumbo, Maria Chiara (Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Alakbarli, Javid (Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Colizza, Wayne (Department of Radiology, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Drexler, Ian R. (Department of Radiology, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Azevedo, Clerio F. (Duke Cardiovascular Magnetic Resonance Center, 10 Duke Medicine Circle, 27710, Durham, NC, USA); Kim, Raymond J. (Duke Cardiovascular Magnetic Resonance Center, 10 Duke Medicine Circle, 27710, Durham, NC, USA); Devereux, Richard B. (Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA); Weinsaft, Jonathan W. (Department of Radiology, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA; Greenberg Division of Cardiology, Department of Medicine, Weill Cornell Medicine, 525 E 68th St, 10065, New York, NY, USA; Memorial Sloan Kettering Cancer Center, 1275 York Ave, 10065, New York, NY, USA; Weill Cornell Medical College, 525 East 68th Street, 10021, New York, NY, USA)","Weinsaft, Jonathan W. (Cornell University; Cornell University; Memorial Sloan Kettering Cancer Center; Cornell University)","Bratt, Alex (Cornell University); Kim, Jiwon (Cornell University; Cornell University); Pollie, Meridith (Cornell University); Beecy, Ashley N. (Cornell University); Tehrani, Nathan H. (Cornell University); Codella, Noel (IBM Research - Thomas J. Watson Research Center); Perez-Johnston, Rocio (Memorial Sloan Kettering Cancer Center); Palumbo, Maria Chiara (Cornell University); Alakbarli, Javid (Cornell University); Colizza, Wayne (Cornell University); Drexler, Ian R. (Cornell University); Azevedo, Clerio F. (Duke University Health System); Kim, Raymond J. (Duke University Health System); Devereux, Richard B. (Cornell University); Weinsaft, Jonathan W. (Cornell University; Cornell University; Memorial Sloan Kettering Cancer Center; Cornell University)",55,37,3.29,23.07,https://doi.org/10.1186/s12968-018-0509-0,https://app.dimensions.ai/details/publication/pub.1111064107,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
958,pub.1119346321,10.48550/arxiv.1901.01238,,,A Distance Map Regularized CNN for Cardiac Cine MR Image Segmentation,"Cardiac image segmentation is a critical process for generating personalized
models of the heart and for quantifying cardiac performance parameters. Several
convolutional neural network (CNN) architectures have been proposed to segment
the heart chambers from cardiac cine MR images. Here we propose a multi-task
learning (MTL)-based regularization framework for cardiac MR image
segmentation. The network is trained to perform the main task of semantic
segmentation, along with a simultaneous, auxiliary task of pixel-wise distance
map regression. The proposed distance map regularizer is a decoder network
added to the bottleneck layer of an existing CNN architecture, facilitating the
network to learn robust global features. The regularizer block is removed after
training, so that the original number of network parameters does not change. We
show that the proposed regularization method improves both binary and
multi-class segmentation performance over the corresponding state-of-the-art
CNN architectures on two publicly available cardiac cine MRI datasets,
obtaining average dice coefficient of 0.84$\pm$0.03 and 0.91$\pm$0.04,
respectively. Furthermore, we also demonstrate improved generalization
performance of the distance map regularized network on cross-dataset
segmentation, showing as much as 42% improvement in myocardium Dice coefficient
from 0.56$\pm$0.28 to 0.80$\pm$0.14.",,,arXiv,,,2019-01-04,2019,,,,,,All OA, Green,Preprint,"Dangi, Shusil; Linte, Cristian; Yaniv, Ziv","Dangi, Shusil (); Linte, Cristian (); Yaniv, Ziv ()",,"Dangi, Shusil (); Linte, Cristian (); Yaniv, Ziv ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119346321,40 Engineering, 46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,
1209,pub.1120518443,10.1109/access.2019.2936945,,,Research and Analysis of Sport Medical Data Processing Algorithms Based on Deep Learning and Internet of Things,"With the development of computer and information technology, more and more data and image information are generated in medical field. Sports medicine, as an important branch of medical cause, is responsible for ensuring national sports safety and rehabilitation after injury. How to use a large number of sports medical data and cases to accurately analyze and mine useful data and information has become an important research direction of sports medical data processing and mining. This paper will focus on the information mining and analysis of large sports medical data, focusing on the loss of training mode and the accuracy of convolution algorithm. In order to achieve effective prediction and risk assessment of sports medicine-related diseases, this paper starts with the improved convolutional neural network deep learning algorithm, and adopts the resampling algorithm with self-adjusting function, supplemented by tensor convolution self-coding algorithm. Ural network model assists multi-dimensional data analysis of sports medicine. Finally, in order to build an intelligent medical data platform for sports medicine, this paper innovatively proposes a cloud-based hardware-in-the-loop simulation model. Experiments show that this method provides reference and technical support for the realization of a real cloud-based fusion system.",,,IEEE Access,,,2019-01-01,2019,2019-08-22,2019-01-01,7,,118839-118849,All OA, Gold,Article,"Ma, Hongmei; Pang, Xiaofeng","Ma, Hongmei (School of Sports, Shenyang Sport University, Shenyang, 110102, China); Pang, Xiaofeng (School of Sports, Shenyang Sport University, Shenyang, 110102, China)","Ma, Hongmei (Shenyang Sport University)","Ma, Hongmei (Shenyang Sport University); Pang, Xiaofeng (Shenyang Sport University)",37,28,,12.56,https://ieeexplore.ieee.org/ielx7/6287639/8600701/08809757.pdf,https://app.dimensions.ai/details/publication/pub.1120518443,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
955,pub.1122960455,10.1109/access.2019.2956210,,,Cascaded Conditional Generative Adversarial Networks With Multi-Scale Attention Fusion for Automated Bi-Ventricle Segmentation in Cardiac MRI,"Accurate segmentation of bi-ventricle from cardiac magnetic resonance images (MRI) is a critical step in cardiac function analysis and disease diagnosis. Due to the morphological diversification of the heart and the factors of MRI itself, fully automated and concurrent bi-ventricle segmentation is a well-known challenge. In this paper, we propose cascaded conditional generative adversarial networks (C-cGANs) to divide the problem into two segmentation subtasks: binary segmentation for region of interest (ROI) extraction and bi-ventricle segmentation. In both subtasks, we adopt adversarial training that makes discriminator network to discriminate segmentation maps either from generator network or ground-truth which aims to detect and correct pixel-wise inconsistency between the sources of segmentation maps. For capturing more spatial information with multi-scale semantic features, in the generator network, we insert a multi-scale attention fusion (MSAF) module between the encoder and decoder paths. The experiment on ACDC 2017 dataset shows that the proposed model outperforms other state-of-the-art methods in most metrics. Moreover, we validate the generalization capability of this model on MS-CMRSeg 2019 and RVSC 2012 datasets without fine-tuning, and the results demonstrate the effectiveness and robustness of the proposed method for bi-ventricle segmentation.","This work was supported in part by the National Natural Science Foundation of China under Grant 61773110 and Grant 61374015, the Natural Science Foundation of Liaoning Province (Key Program) under Grant 20170520180, and the Fundamental Research Funds for the Central Universities under Grant N161904002, Grant N171904009, Grant N172008008, and Grant N180719020. The authors would like to thank the editor and reviewers for their valuable advice that have helped to improve the article quality.",,IEEE Access,,,2019-01-01,2019,2019-11-27,2019-01-01,7,,172305-172320,All OA, Gold,Article,"Qi, Lin; Zhang, Haoran; Tan, Wenjun; Qi, Shouliang; Xu, Lisheng; Yao, Yudong; Qian, Wei","Qi, Lin (College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, 110169, China; Engineering Research Center of Medical Imaging and Intelligent Analysis, Ministry of Education, Shenyang, 110169, China); Zhang, Haoran (College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, 110169, China); Tan, Wenjun (Key Laboratory of Medical Image Computing, Ministry of Education, Northeastern University, Shenyang, 110169, China); Qi, Shouliang (College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, 110169, China; Engineering Research Center of Medical Imaging and Intelligent Analysis, Ministry of Education, Shenyang, 110169, China); Xu, Lisheng (College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, 110169, China; Engineering Research Center of Medical Imaging and Intelligent Analysis, Ministry of Education, Shenyang, 110169, China; Key Laboratory of Medical Image Computing, Ministry of Education, Northeastern University, Shenyang, 110169, China); Yao, Yudong (Electrical and Computer Engineering Department, Stevens Institute of Technology, Hoboken, NJ, 07030, USA); Qian, Wei (Department of Electrical and Computer Engineering, College of Engineering, The University of Texas at El Paso, El Paso, TX, 79968, USA)","Xu, Lisheng (Northeastern University; ; Northeastern University)","Qi, Lin (Northeastern University); Zhang, Haoran (Northeastern University); Tan, Wenjun (Northeastern University); Qi, Shouliang (Northeastern University); Xu, Lisheng (Northeastern University; Northeastern University); Yao, Yudong (Stevens Institute of Technology); Qian, Wei (The University of Texas at El Paso)",8,5,,3.07,https://ieeexplore.ieee.org/ielx7/6287639/8600701/08915846.pdf,https://app.dimensions.ai/details/publication/pub.1122960455,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
189,pub.1122014747,10.1007/978-3-030-33843-5,,,"Machine Learning for Medical Image Reconstruction, Second International Workshop, MLMIR 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 17, 2019, Proceedings","This book constitutes the refereed proceedings of the Second International Workshop on Machine Learning for Medical Reconstruction, MLMIR 2019, held in conjunction with MICCAI 2019, in Shenzhen, China, in October 2019. The 24 full papers presented were carefully reviewed and selected from 32 submissions. The papers are organized in the following topical sections: deep learning for magnetic resonance imaging; deep learning for computed tomography; and deep learning for general image reconstruction.",,,Lecture Notes in Computer Science,,,2019,2019,,2019,11905,,,Closed,Edited Book,,,,,4,4,,1.53,,https://app.dimensions.ai/details/publication/pub.1122014747,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
189,pub.1121734520,10.1007/978-3-030-33391-1,,,"Domain Adaptation and Representation Transfer and Medical Image Learning with Less Labels and Imperfect Data, First MICCAI Workshop, DART 2019, and First International Workshop, MIL3ID 2019, Shenzhen, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 13 and 17, 2019, Proceedings","This book constitutes the refereed proceedings of the First MICCAI Workshop on Domain Adaptation and Representation Transfer, DART 2019, and the First International Workshop on Medical Image Learning with Less Labels and Imperfect Data, MIL3ID 2019, held in conjunction with MICCAI 2019, in Shenzhen, China, in October 2019. DART 2019 accepted 12 papers for publication out of 18 submissions. The papers deal with methodological advancements and ideas that can improve the applicability of machine learning and deep learning approaches to clinical settings by making them robust and consistent across different domains. MIL3ID accepted 16 papers out of 43 submissions for publication, dealing with best practices in medical image learning with label scarcity and data imperfection.",,,Lecture Notes in Computer Science,,,2019,2019,,2019,11795,,,All OA, Green,Edited Book,,,,,7,5,,2.68,https://link.springer.com/content/pdf/bfm:978-3-030-33391-1/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1121734520,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
108,pub.1121620256,10.1007/978-3-030-32245-8,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2019, 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings, Part II","The six-volume set LNCS 11764, 11765, 11766, 11767, 11768, and 11769 constitutes the refereed proceedings of the 22nd International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2019, held in Shenzhen, China, in October 2019. The 539 revised full papers presented were carefully reviewed and selected from 1730 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: optical imaging; endoscopy; microscopy. Part II: image segmentation; image registration; cardiovascular imaging; growth, development, atrophy and progression. Part III: neuroimage reconstruction and synthesis; neuroimage segmentation; diffusion weighted magnetic resonance imaging; functional neuroimaging (fMRI); miscellaneous neuroimaging. Part IV: shape; prediction; detection and localization; machine learning; computer-aided diagnosis; image reconstruction and synthesis. Part V: computer assisted interventions; MIC meets CAI. Part VI: computed tomography; X-ray imaging.",,,Lecture Notes in Computer Science,,,2019,2019,,2019,11765,,,All OA, Green,Edited Book,,,,,7,7,,,https://link.springer.com/content/pdf/bfm:978-3-030-32245-8/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1121620256,46 Information and Computing Sciences,,,,,,,,,,,
98,pub.1111797501,10.1007/978-3-319-94878-2,,,"Artificial Intelligence in Medical Imaging, Opportunities, Applications and Risks","This book provides a thorough overview of the ongoing evolution in the application of artificial intelligence (AI) within healthcare and radiology, enabling readers to gain a deeper insight into the technological background of AI and the impacts of new and emerging technologies on medical imaging. After an introduction on game changers in radiology, such as deep learning technology, the technological evolution of AI in computing science and medical image computing is described, with explanation of basic principles and the types and subtypes of AI. Subsequent sections address the use of imaging biomarkers, the development and validation of AI applications, and various aspects and issues relating to the growing role of big data in radiology. Diverse real-life clinical applications of AI are then outlined for different body parts, demonstrating their ability to add value to daily radiology practices. The concluding section focuses on the impact of AI on radiology and the implications for radiologists, for example with respect to training. Written by radiologists and IT professionals, the book will be of high value for radiologists, medical/clinical physicists, IT specialists, and imaging informatics professionals.",,,,,,2019,2019,,2019,,,,All OA, Green,Edited Book,,,,,74,57,,31.04,https://link.springer.com/content/pdf/bfm:978-3-319-94878-2/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1111797501,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
98,pub.1112112064,10.1007/978-3-030-12029-0,,,"Statistical Atlases and Computational Models of the Heart. Atrial Segmentation and LV Quantification Challenges, 9th International Workshop, STACOM 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Revised Selected Papers","This book constitutes the thoroughly refereed post-workshop proceedings of the 9th International Workshop on Statistical Atlases and Computational Models of the Heart: Atrial Segmentation and LV Quantification Challenges, STACOM 2018, held in conjunction with MICCAI 2018, in Granada, Spain, in September 2018. The 52 revised full workshop papers were carefully reviewed and selected from 60 submissions. The topics of the workshop included: cardiac imaging and image processing, machine learning applied to cardiac imaging and image analysis, atlas construction, statistical modelling of cardiac function across different patient populations, cardiac computational physiology, model customization, atlas based functional analysis, ontological schemata for data and results, integrated functional and structural analyses, as well as the pre-clinical and clinical applicability of these methods.",,,Lecture Notes in Computer Science,,,2019,2019,,2019,11395,,,All OA, Green,Edited Book,,,,,20,12,,,https://link.springer.com/content/pdf/bfm%3A978-3-030-12029-0%2F1,https://app.dimensions.ai/details/publication/pub.1112112064,46 Information and Computing Sciences,,,,,,,,,,,
1014,pub.1119425342,10.48550/arxiv.1812.07460,,,Learning a Probabilistic Model for Diffeomorphic Registration,"We propose to learn a low-dimensional probabilistic deformation model from
data which can be used for registration and the analysis of deformations. The
latent variable model maps similar deformations close to each other in an
encoding space. It enables to compare deformations, generate normal or
pathological deformations for any new image or to transport deformations from
one image pair to any other image. Our unsupervised method is based on
variational inference. In particular, we use a conditional variational
autoencoder (CVAE) network and constrain transformations to be symmetric and
diffeomorphic by applying a differentiable exponentiation layer with a
symmetric loss function. We also present a formulation that includes spatial
regularization such as diffusion-based filters. Additionally, our framework
provides multi-scale velocity field estimations. We evaluated our method on 3-D
intra-subject registration using 334 cardiac cine-MRIs. On this dataset, our
method showed state-of-the-art performance with a mean DICE score of 81.2% and
a mean Hausdorff distance of 7.3mm using 32 latent dimensions compared to three
state-of-the-art methods while also demonstrating more regular deformation
fields. The average time per registration was 0.32s. Besides, we visualized the
learned latent space and show that the encoded deformations can be used to
transport deformations and to cluster diseases with a classification accuracy
of 83% after applying a linear projection.",,,arXiv,,,2018-12-18,2018,,,,,,All OA, Green,Preprint,"Krebs, Julian; Delingette, Hervé; Mailhé, Boris; Ayache, Nicholas; Mansi, Tommaso","Krebs, Julian (); Delingette, Hervé (); Mailhé, Boris (); Ayache, Nicholas (); Mansi, Tommaso ()",,"Krebs, Julian (); Delingette, Hervé (); Mailhé, Boris (); Ayache, Nicholas (); Mansi, Tommaso ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119425342,46 Information and Computing Sciences, 4603 Computer Vision and Multimedia Computation, 4611 Machine Learning,,,,,,,,,
2426,pub.1110515574,10.1109/rbme.2018.2885714,30530339,,Deep Learning in Cardiology,"The medical field is creating large amount of data that physicians are unable to decipher and use efficiently. Moreover, rule-based expert systems are inefficient in solving complicated medical tasks or for creating insights using big data. Deep learning has emerged as a more accurate and effective technology in a wide range of medical problems such as diagnosis, prediction, and intervention. Deep learning is a representation learning method that consists of layers that transform data nonlinearly, thus, revealing hierarchical relationships and structures. In this review, we survey deep learning application papers that use structured data, and signal and imaging modalities from cardiology. We discuss the advantages and limitations of applying deep learning in cardiology that also apply in medicine in general, while proposing certain directions as the most viable for clinical use.",This work was supported by the European Union&#x27,s Horizon 2020 research and innovation programme under Grant agreement 727521.,,IEEE Reviews in Biomedical Engineering,,Big Data, Cardiology, Deep Learning, Heart Diseases, Humans, Machine Learning, Physicians,2018-12-10,2018,2018-12-10,2019,12,,168-193,All OA, Green,Article,"Bizopoulos, Paschalis; Koutsouris, Dimitrios","Bizopoulos, Paschalis (Biomedical Engineering Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, Athens, 15780, Greece); Koutsouris, Dimitrios (Biomedical Engineering Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, Athens, 15780, Greece)","Bizopoulos, Paschalis (National Technical University of Athens)","Bizopoulos, Paschalis (National Technical University of Athens); Koutsouris, Dimitrios (National Technical University of Athens)",80,56,3.04,13.0,http://arxiv.org/pdf/1902.11122,https://app.dimensions.ai/details/publication/pub.1110515574,40 Engineering, 4003 Biomedical Engineering,,,
1344,pub.1119402167,10.48550/arxiv.1812.00328,,,End-to-end Learning of Convolutional Neural Net and Dynamic Programming  for Left Ventricle Segmentation,"Differentiable programming is able to combine different functions or programs
in a processing pipeline with the goal of applying end-to-end learning or
optimization. A significant impediment is the non-differentiable nature of some
algorithms. We propose to use synthetic gradients (SG) to overcome this
difficulty. SG uses the universal function approximation property of neural
networks. We apply SG to combine convolutional neural network (CNN) with
dynamic programming (DP) in end-to-end learning for segmenting left ventricle
from short axis view of heart MRI. Our experiments show that end-to-end
combination of CNN and DP requires fewer labeled images to achieve a
significantly better segmentation accuracy than using only CNN.",,,arXiv,,,2018-12-02,2018,,,,,,All OA, Green,Preprint,"Nguyen, Nhat M.; Ray, Nilanjan","Nguyen, Nhat M. (); Ray, Nilanjan ()",,"Nguyen, Nhat M. (); Ray, Nilanjan ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119402167,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1213,pub.1111519654,10.1109/dicta.2018.8615772,,,Generative Adversarial Framework for Learning Multiple Clinical Tasks,"Inspired by the recent success of generative adversarial networks (GANs), we propose a novel adversarial network for learning multiple clinical tasks. We design a conditional generative adversarial network (cGAN) with a new selective weighted loss to mitigate imbalance data problem in medical image analysis. Our proposed method comprises two components: a generator and a discriminator. While the generator is trained on sequential magnetic resonance images (MRI) to learn semantic segmentation and disease classification, the discriminator classifies whether a generated output is real or fake. The generative model and the discriminator model are trained via adversarial loss with two player mini-max game, and with an additional proposed selective weighted loss. The proposed architecture has shown promising performance on the ACDC-2017 benchmark for prediction of cardiac disease beside of semantic segmentation of dual cavities and myocardium vessel. Moreover, we achieved competitive results for brain tumor semantic segmentation and brain disease classification on the BraTS-2017 challenge.",,,,2018 Digital Image Computing: Techniques and Applications (DICTA),,2018-12-01,2018,,2018-12-01,,,1-8,Closed,Proceeding,"Rezaei, Mina; Yang, Haojin; Meinel, Christoph","Rezaei, Mina (Internet Technologies and Systems, Hasso Plattner Institute, Berlin, Germany); Yang, Haojin (Internet Technologies and Systems, Hasso Plattner Institute, Berlin, Germany); Meinel, Christoph (Internet Technologies and Systems, Hasso Plattner Institute, Berlin, Germany)",,"Rezaei, Mina (Hasso Plattner Institute); Yang, Haojin (Hasso Plattner Institute); Meinel, Christoph (Hasso Plattner Institute)",12,11,,3.79,,https://app.dimensions.ai/details/publication/pub.1111519654,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,,
3301,pub.1110274075,10.1016/j.mri.2018.11.014,30503948,PMC6331218,Challenges in diffusion MRI tractography – Lessons learned from international benchmark competitions,"Diffusion MRI (dMRI) fiber tractography has become a pillar of the neuroimaging community due to its ability to noninvasively map the structural connectivity of the brain. Despite widespread use in clinical and research domains, these methods suffer from several potential drawbacks or limitations. Thus, validating the accuracy and reproducibility of techniques is critical for sound scientific conclusions and effective clinical outcomes. Towards this end, a number of international benchmark competitions, or ""challenges"", has been organized by the diffusion MRI community in order to investigate the reliability of the tractography process by providing a platform to compare algorithms and results in a fair manner, and evaluate common and emerging algorithms in an effort to advance the state of the field. In this paper, we summarize the lessons from a decade of challenges in tractography, and give perspective on the past, present, and future ""challenges"" that the field of diffusion tractography faces.",,,Magnetic Resonance Imaging,,Algorithms, Benchmarking, Brain, Diffusion Tensor Imaging, Humans, Internationality, Neuroimaging, Reproducibility of Results,2018-11-29,2018,2018-11-29,2019-04,57,,194-209,All OA, Green,Article,"Schilling, Kurt G; Daducci, Alessandro; Maier-Hein, Klaus; Poupon, Cyril; Houde, Jean-Christophe; Nath, Vishwesh; Anderson, Adam W; Landman, Bennett A; Descoteaux, Maxime","Schilling, Kurt G (Vanderbilt University Institute of Imaging Science, Vanderbilt University, Nashville, TN, United States of America. Electronic address: kurt.g.schilling.1@vumc.org.); Daducci, Alessandro (Computer Science Department, University of Verona, Verona, Italy.); Maier-Hein, Klaus (Division of Medical Image Computing, German Cancer Research Center (DKFZ), Heidelberg 69120, Germany.); Poupon, Cyril (Neurospin, Frédéric Joliot Life Sciences Institute, CEA, Gif-sur-Yvette, France.); Houde, Jean-Christophe (Sherbrooke Connectivity Imaging Lab (SCIL), Computer Science Department, Université de Sherbrooke, Québec, Canada.); Nath, Vishwesh (Electrical Engineering & Computer Science, Vanderbilt University, Nashville, TN, United States of America.); Anderson, Adam W (Vanderbilt University Institute of Imaging Science, Vanderbilt University, Nashville, TN, United States of America; Department of Biomedical Engineering, Vanderbilt University, Nashville, TN, United States of America.); Landman, Bennett A (Vanderbilt University Institute of Imaging Science, Vanderbilt University, Nashville, TN, United States of America; Department of Biomedical Engineering, Vanderbilt University, Nashville, TN, United States of America; Department of Electrical Engineering, Vanderbilt University, Nashville, TN, United States of America.); Descoteaux, Maxime (Sherbrooke Connectivity Imaging Lab (SCIL), Computer Science Department, Université de Sherbrooke, Québec, Canada.)","Schilling, Kurt G (Vanderbilt University)","Schilling, Kurt G (Vanderbilt University); Daducci, Alessandro (University of Verona); Maier-Hein, Klaus (German Cancer Research Center); Poupon, Cyril (); Houde, Jean-Christophe (Université de Sherbrooke); Nath, Vishwesh (Vanderbilt University); Anderson, Adam W (Vanderbilt University); Landman, Bennett A (Vanderbilt University); Descoteaux, Maxime (Université de Sherbrooke)",81,48,4.65,27.89,https://europepmc.org/articles/pmc6331218?pdf=render,https://app.dimensions.ai/details/publication/pub.1110274075,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,
1649,pub.1119392389,10.48550/arxiv.1811.10419,,,Multi-Task Generative Adversarial Network for Handling Imbalanced  Clinical Data,"We propose a new generative adversarial architecture to mitigate imbalance
data problem for the task of medical image semantic segmentation where the
majority of pixels belong to a healthy region and few belong to lesion or
non-health region. A model trained with imbalanced data tends to bias towards
healthy data which is not desired in clinical applications. We design a new
conditional GAN with two components: a generative model and a discriminative
model to mitigate imbalanced data problem through selective weighted loss.
While the generator is trained on sequential magnetic resonance images (MRI) to
learn semantic segmentation and disease classification, the discriminator
classifies whether a generated output is real or fake. The proposed
architecture achieved state-of-the-art results on ACDC-2017 for cardiac
segmentation and diseases classification. We have achieved competitive results
on BraTS-2017 for brain tumor segmentation and brain diseases classification.",,,arXiv,,,2018-11-22,2018,,,,,,All OA, Green,Preprint,"Rezaei, Mina; Yang, Haojin; Meinel, Christoph","Rezaei, Mina (); Yang, Haojin (); Meinel, Christoph ()",,"Rezaei, Mina (); Yang, Haojin (); Meinel, Christoph ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119392389,46 Information and Computing Sciences, 4611 Machine Learning,3 Good Health and Well Being,,,,,,,,,
866,pub.1119334872,10.48550/arxiv.1811.03433,,,Explainable cardiac pathology classification on cine MRI with motion  characterization by semi-supervised learning of apparent flow,"We propose a method to classify cardiac pathology based on a novel approach
to extract image derived features to characterize the shape and motion of the
heart. An original semi-supervised learning procedure, which makes efficient
use of a large amount of non-segmented images and a small amount of images
segmented manually by experts, is developed to generate pixel-wise apparent
flow between two time points of a 2D+t cine MRI image sequence. Combining the
apparent flow maps and cardiac segmentation masks, we obtain a local apparent
flow corresponding to the 2D motion of myocardium and ventricular cavities.
This leads to the generation of time series of the radius and thickness of
myocardial segments to represent cardiac motion. These time series of motion
features are reliable and explainable characteristics of pathological cardiac
motion. Furthermore, they are combined with shape-related features to classify
cardiac pathologies. Using only nine feature values as input, we propose an
explainable, simple and flexible model for pathology classification. On ACDC
training set and testing set, the model achieves 95% and 94% respectively as
classification accuracy. Its performance is hence comparable to that of the
state-of-the-art. Comparison with various other models is performed to outline
some advantages of our model.",,,arXiv,,,2018-11-08,2018,,,,,,All OA, Green,Preprint,"Zheng, Qiao; Delingette, Hervé; Ayache, Nicholas","Zheng, Qiao (); Delingette, Hervé (); Ayache, Nicholas ()",,"Zheng, Qiao (); Delingette, Hervé (); Ayache, Nicholas ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119334872,"40 Engineering; 46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
1613,pub.1119367573,10.48550/arxiv.1810.10117,,,End-to-End Diagnosis and Segmentation Learning from Cardiac Magnetic  Resonance Imaging,"Cardiac magnetic resonance (CMR) is used extensively in the diagnosis and
management of cardiovascular disease. Deep learning methods have proven to
deliver segmentation results comparable to human experts in CMR imaging, but
there have been no convincing results for the problem of end-to-end
segmentation and diagnosis from CMR. This is in part due to a lack of
sufficiently large datasets required to train robust diagnosis models. In this
paper, we propose a learning method to train diagnosis models, where our
approach is designed to work with relatively small datasets. In particular, the
optimisation loss is based on multi-task learning that jointly trains for the
tasks of segmentation and diagnosis classification. We hypothesize that
segmentation has a regularizing effect on the learning of features relevant for
diagnosis. Using the 100 training and 50 testing samples available from the
Automated Cardiac Diagnosis Challenge (ACDC) dataset, which has a balanced
distribution of 5 cardiac diagnoses, we observe a reduction of the
classification error from 32% to 22%, and a faster convergence compared to a
baseline without segmentation. To the best of our knowledge, this is the best
diagnosis results from CMR using an end-to-end diagnosis and segmentation
learning method.",,,arXiv,,,2018-10-23,2018,,,,,,All OA, Green,Preprint,"Snaauw, Gerard; Gong, Dong; Maicas, Gabriel; Hengel, Anton van den; Niessen, Wiro J.; Verjans, Johan; Carneiro, Gustavo","Snaauw, Gerard (); Gong, Dong (); Maicas, Gabriel (); Hengel, Anton van den (); Niessen, Wiro J. (); Verjans, Johan (); Carneiro, Gustavo ()",,"Snaauw, Gerard (); Gong, Dong (); Maicas, Gabriel (); Hengel, Anton van den (); Niessen, Wiro J. (); Verjans, Johan (); Carneiro, Gustavo ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119367573,46 Information and Computing Sciences, 4605 Data Management and Data Science, 4611 Machine Learning,,,,,,,,,
2789,pub.1107729612,10.1016/j.media.2018.10.004,30390512,,Fully convolutional multi-scale residual DenseNets for cardiac segmentation and automated cardiac diagnosis using ensemble of classifiers,"Deep fully convolutional neural network (FCN) based architectures have shown great potential in medical image segmentation. However, such architectures usually have millions of parameters and inadequate number of training samples leading to over-fitting and poor generalization. In this paper, we present a novel DenseNet based FCN architecture for cardiac segmentation which is parameter and memory efficient. We propose a novel up-sampling path which incorporates long skip and short-cut connections to overcome the feature map explosion in conventional FCN based architectures. In order to process the input images at multiple scales and view points simultaneously, we propose to incorporate Inception module's parallel structures. We propose a novel dual loss function whose weighting scheme allows to combine advantages of cross-entropy and Dice loss leading to qualitative improvements in segmentation. We demonstrate computational efficacy of incorporating conventional computer vision techniques for region of interest detection in an end-to-end deep learning based segmentation framework. From the segmentation maps we extract clinically relevant cardiac parameters and hand-craft features which reflect the clinical diagnostic analysis and train an ensemble system for cardiac disease classification. We validate our proposed network architecture on three publicly available datasets, namely: (i) Automated Cardiac Diagnosis Challenge (ACDC-2017), (ii) Left Ventricular segmentation challenge (LV-2011), (iii) 2015 Kaggle Data Science Bowl cardiac challenge data. Our approach in ACDC-2017 challenge stood second place for segmentation and first place in automated cardiac disease diagnosis tasks with an accuracy of 100% on a limited testing set (n=50). In the LV-2011 challenge our approach attained 0.74 Jaccard index, which is so far the highest published result in fully automated algorithms. In the Kaggle challenge our approach for LV volume gave a Continuous Ranked Probability Score (CRPS) of 0.0127, which would have placed us tenth in the original challenge. Our approach combined both cardiac segmentation and disease diagnosis into a fully automated framework which is computationally efficient and hence has the potential to be incorporated in computer-aided diagnosis (CAD) tools for clinical application.",,,Medical Image Analysis,,"Algorithms; Cardiovascular Diseases; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Neural Networks, Computer; Reproducibility of Results",2018-10-19,2018,2018-10-19,2019-01,51,,21-45,All OA, Green,Article,"Khened, Mahendra; Kollerathu, Varghese Alex; Krishnamurthi, Ganapathy","Khened, Mahendra (Department of Engineering Design, Indian Institute of Technology Madras, Chennai, India.); Kollerathu, Varghese Alex (Department of Engineering Design, Indian Institute of Technology Madras, Chennai, India.); Krishnamurthi, Ganapathy (Department of Engineering Design, Indian Institute of Technology Madras, Chennai, India. Electronic address: gankrish@iitm.ac.in.)","Krishnamurthi, Ganapathy (Indian Institute of Technology Madras)","Khened, Mahendra (Indian Institute of Technology Madras); Kollerathu, Varghese Alex (Indian Institute of Technology Madras); Krishnamurthi, Ganapathy (Indian Institute of Technology Madras)",228,128,10.01,,http://arxiv.org/pdf/1801.05173,https://app.dimensions.ai/details/publication/pub.1107729612,32 Biomedical and Clinical Sciences, 40 Engineering,,,,,,,,,,
1517,pub.1110350497,10.1109/snams.2018.8554962,,,Automated Segmentation on the Entire Cardiac Cycle Using a Deep Learning Work - Flow,"The segmentation of the left ventricle (LV) from CINE MRI images is essential to infer important clinical parameters. Typically, machine learning algorithms for automated LV segmentation use annotated contours from only two cardiac phases, diastole, and systole. In this work, we present an analysis work-flow for fully-automated LV segmentation that learns from images acquired through the cardiac cycle. The workflow consists of three components: first, for each image in the sequence, we perform an automated localization and subsequent cropping of the bounding box containing the cardiac silhouette. Second, we identify the LV contours using a Temporal Fully Convolutional Neural Network (T-FCNN), which extends Fully Convolutional Neural Networks (FCNN) through a recurrent mechanism enforcing temporal coherence across consecutive frames. Finally, we further defined the boundaries using either one of two components: fully-connected Conditional Random Fields (CRFs) with Gaussian edge potentials and Semantic Flow. Our initial experiments suggest that significant improvement in performance can potentially be achieved by using a recurrent neural network component that explicitly learns cardiac motion patterns whilst performing LV segmentation.",,,,"2018 Fifth International Conference on Social Networks Analysis, Management and Security (SNAMS)",,2018-10-15,2018,,2018-10-15,0,,153-158,All OA, Green,Proceeding,"Savioli, Nicolo; Vieira, Miguel Silva; Lamata, Pablo; Montana, Giovanni","Savioli, Nicolo (); Vieira, Miguel Silva (King's College London, Division of Imaging Sciences and Biomedical Engineering, UK); Lamata, Pablo (King's College London, Division of Imaging Sciences and Biomedical Engineering, UK); Montana, Giovanni (WMG, University of Warwick, UK)",,"Savioli, Nicolo (); Vieira, Miguel Silva (King's College London); Lamata, Pablo (King's College London); Montana, Giovanni (University of Warwick)",15,8,,4.73,http://arxiv.org/pdf/1809.01015,https://app.dimensions.ai/details/publication/pub.1110350497,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
1615,pub.1119306326,10.48550/arxiv.1809.10430,,,Towards increased trustworthiness of deep learning segmentation methods  on cardiac MRI,"Current state-of-the-art deep learning segmentation methods have not yet made
a broad entrance into the clinical setting in spite of high demand for such
automatic methods. One important reason is the lack of reliability caused by
models that fail unnoticed and often locally produce anatomically implausible
results that medical experts would not make. This paper presents an automatic
image segmentation method based on (Bayesian) dilated convolutional networks
(DCNN) that generate segmentation masks and spatial uncertainty maps for the
input image at hand. The method was trained and evaluated using segmentation of
the left ventricle (LV) cavity, right ventricle (RV) endocardium and myocardium
(Myo) at end-diastole (ED) and end-systole (ES) in 100 cardiac 2D MR scans from
the MICCAI 2017 Challenge (ACDC). Combining segmentations and uncertainty maps
and employing a human-in-the-loop setting, we provide evidence that image areas
indicated as highly uncertain regarding the obtained segmentation almost
entirely cover regions of incorrect segmentations. The fused information can be
harnessed to increase segmentation performance. Our results reveal that we can
obtain valuable spatial uncertainty maps with low computational effort using
DCNNs.",,,arXiv,,,2018-09-27,2018,,,,,,All OA, Green,Preprint,"Sander, Jörg; de Vos, Bob D.; Wolterink, Jelmer M.; Išgum, Ivana","Sander, Jörg (); de Vos, Bob D. (); Wolterink, Jelmer M. (); Išgum, Ivana ()",,"Sander, Jörg (); de Vos, Bob D. (); Wolterink, Jelmer M. (); Išgum, Ivana ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119306326,40 Engineering, 4003 Biomedical Engineering, 46 Information and Computing Sciences,,,,,,,,,
1617,pub.1107037506,10.1007/978-3-030-00919-9_32,,,Combining Heterogeneously Labeled Datasets For Training Segmentation Networks,"Accurate segmentation of medical images is an important step towards analyzing and tracking disease related morphological alterations in the anatomy. Convolutional neural networks (CNNs) have recently emerged as a powerful tool for many segmentation tasks in medical imaging. The performance of CNNs strongly depends on the size of the training data and combining data from different sources is an effective strategy for obtaining larger training datasets. However, this is often challenged by heterogeneous labeling of the datasets. For instance, one of the dataset may be missing labels or a number of labels may have been combined into a super label. In this work we propose a cost function which allows integration of multiple datasets with heterogeneous label subsets into a joint training. We evaluated the performance of this strategy on thigh MR and a cardiac MR datasets in which we artificially merged labels for half of the data. We found the proposed cost function substantially outperforms a naive masking approach, obtaining results very close to using the full annotations.",,,Lecture Notes in Computer Science,Machine Learning in Medical Imaging,,2018-09-15,2018,2018-09-15,2018,11046,,276-284,All OA, Green,Chapter,"Kemnitz, Jana; Baumgartner, Christian F.; Wirth, Wolfgang; Eckstein, Felix; Eder, Sebastian K.; Konukoglu, Ender","Kemnitz, Jana (Paracelsus Medical University Salzburg, Salzburg, Austria; Chondrometrics GmbH Ainring, Ainring, Germany; Computer Vision Lab, ETH Zurich, Zurich, Switzerland); Baumgartner, Christian F. (Computer Vision Lab, ETH Zurich, Zurich, Switzerland); Wirth, Wolfgang (Paracelsus Medical University Salzburg, Salzburg, Austria; Chondrometrics GmbH Ainring, Ainring, Germany); Eckstein, Felix (Paracelsus Medical University Salzburg, Salzburg, Austria; Chondrometrics GmbH Ainring, Ainring, Germany); Eder, Sebastian K. (Paracelsus Medical University Salzburg, Salzburg, Austria); Konukoglu, Ender (Computer Vision Lab, ETH Zurich, Zurich, Switzerland)","Kemnitz, Jana (Paracelsus Medical University; Chondrometrics (Germany); ETH Zurich)","Kemnitz, Jana (Paracelsus Medical University; Chondrometrics (Germany); ETH Zurich); Baumgartner, Christian F. (ETH Zurich); Wirth, Wolfgang (Paracelsus Medical University; Chondrometrics (Germany)); Eckstein, Felix (Paracelsus Medical University; Chondrometrics (Germany)); Eder, Sebastian K. (Paracelsus Medical University); Konukoglu, Ender (ETH Zurich)",5,3,,1.58,http://arxiv.org/pdf/1807.08935,https://app.dimensions.ai/details/publication/pub.1107037506,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
4281,pub.1106947579,10.1186/s12968-018-0471-x,30217194,PMC6138894,Automated cardiovascular magnetic resonance image analysis with fully convolutional networks,"BackgroundCardiovascular resonance (CMR) imaging is a standard imaging modality for assessing cardiovascular diseases (CVDs), the leading cause of death globally. CMR enables accurate quantification of the cardiac chamber volume, ejection fraction and myocardial mass, providing information for diagnosis and monitoring of CVDs. However, for years, clinicians have been relying on manual approaches for CMR image analysis, which is time consuming and prone to subjective errors. It is a major clinical challenge to automatically derive quantitative and clinically relevant information from CMR images.MethodsDeep neural networks have shown a great potential in image pattern recognition and segmentation for a variety of tasks. Here we demonstrate an automated analysis method for CMR images, which is based on a fully convolutional network (FCN). The network is trained and evaluated on a large-scale dataset from the UK Biobank, consisting of 4,875 subjects with 93,500 pixelwise annotated images. The performance of the method has been evaluated using a number of technical metrics, including the Dice metric, mean contour distance and Hausdorff distance, as well as clinically relevant measures, including left ventricle (LV) end-diastolic volume (LVEDV) and end-systolic volume (LVESV), LV mass (LVM); right ventricle (RV) end-diastolic volume (RVEDV) and end-systolic volume (RVESV).ResultsBy combining FCN with a large-scale annotated dataset, the proposed automated method achieves a high performance in segmenting the LV and RV on short-axis CMR images and the left atrium (LA) and right atrium (RA) on long-axis CMR images. On a short-axis image test set of 600 subjects, it achieves an average Dice metric of 0.94 for the LV cavity, 0.88 for the LV myocardium and 0.90 for the RV cavity. The mean absolute difference between automated measurement and manual measurement is 6.1 mL for LVEDV, 5.3 mL for LVESV, 6.9 gram for LVM, 8.5 mL for RVEDV and 7.2 mL for RVESV. On long-axis image test sets, the average Dice metric is 0.93 for the LA cavity (2-chamber view), 0.95 for the LA cavity (4-chamber view) and 0.96 for the RA cavity (4-chamber view). The performance is comparable to human inter-observer variability.ConclusionsWe show that an automated method achieves a performance on par with human experts in analysing CMR images and deriving clinically relevant measures.",This research has been conducted mainly using the UK Biobank Resource under Application Number 2946. The initial stage of the research was conducted using the UK Biobank Resource under Application Number 18545. The authors wish to thank all UK Biobank participants and staff.,"This work is supported by the SmartHeart EPSRC Programme Grant (EP/P001009/1). G.T. is supported by a Marie Skłodowska Curie European Fellowship. A.L. and S.E.P. acknowledge support from the NIHR Barts Biomedical Research Centre and from the MRC for the MRC eMedLab Medical Bioinformatics infrastructure (MR/L016311/1), which enables data access. N.A. is supported by a Wellcome Trust Research Training Fellowship (203553/Z/Z). S.N. and S.K.P. acknowledge support from the NIHR Oxford Biomedical Research Centre and the Oxford BHF Centre of Research Excellence. S.E.P., S.K.P. and S.N. acknowledge the British Heart Foundation (BHF) for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5000 CMR scans (PG/14/89/31194). H.S. is supported by a Research Fellowship from the Uehara Memorial Foundation. P.M.M. gratefully acknowledges support from the Edmond J. Safra Foundation and Lily Safra, the Imperial College Healthcare Trust Biomedical Research Centre, the EPSRC Centre for Mathematics in Precision Healthcare and the MRC.",Journal of Cardiovascular Magnetic Resonance,,"Aged; Automation; Databases, Factual; Deep Learning; Female; Heart Diseases; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Myocardial Contraction; Neural Networks, Computer; Observer Variation; Predictive Value of Tests; Reproducibility of Results; Stroke Volume; Ventricular Function, Left; Ventricular Function, Right",2018-09-14,2018,2018-09-14,2018-12,20,1,65,All OA, Gold,Article,"Bai, Wenjia; Sinclair, Matthew; Tarroni, Giacomo; Oktay, Ozan; Rajchl, Martin; Vaillant, Ghislain; Lee, Aaron M.; Aung, Nay; Lukaschuk, Elena; Sanghvi, Mihir M.; Zemrak, Filip; Fung, Kenneth; Paiva, Jose Miguel; Carapella, Valentina; Kim, Young Jin; Suzuki, Hideaki; Kainz, Bernhard; Matthews, Paul M.; Petersen, Steffen E.; Piechnik, Stefan K.; Neubauer, Stefan; Glocker, Ben; Rueckert, Daniel","Bai, Wenjia (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Sinclair, Matthew (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Tarroni, Giacomo (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Oktay, Ozan (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Rajchl, Martin (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Vaillant, Ghislain (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Lee, Aaron M. (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK); Aung, Nay (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK); Lukaschuk, Elena (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Sanghvi, Mihir M. (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK); Zemrak, Filip (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK); Fung, Kenneth (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK); Paiva, Jose Miguel (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK); Carapella, Valentina (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Kim, Young Jin (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Suzuki, Hideaki (Division of Brain Sciences, Department of Medicine, Imperial College London, London, UK); Kainz, Bernhard (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Matthews, Paul M. (Division of Brain Sciences, Department of Medicine, Imperial College London, London, UK); Petersen, Steffen E. (NIHR Biomedical Research Centre at Barts, Queen Mary University of London, London, UK); Piechnik, Stefan K. (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Neubauer, Stefan (Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, UK); Glocker, Ben (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK); Rueckert, Daniel (Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK)","Bai, Wenjia (Imperial College London)","Bai, Wenjia (Imperial College London); Sinclair, Matthew (Imperial College London); Tarroni, Giacomo (Imperial College London); Oktay, Ozan (Imperial College London); Rajchl, Martin (Imperial College London); Vaillant, Ghislain (Imperial College London); Lee, Aaron M. (Queen Mary University of London); Aung, Nay (Queen Mary University of London); Lukaschuk, Elena (University of Oxford); Sanghvi, Mihir M. (Queen Mary University of London); Zemrak, Filip (Queen Mary University of London); Fung, Kenneth (Queen Mary University of London); Paiva, Jose Miguel (Queen Mary University of London); Carapella, Valentina (University of Oxford); Kim, Young Jin (University of Oxford); Suzuki, Hideaki (Imperial College London); Kainz, Bernhard (Imperial College London); Matthews, Paul M. (Imperial College London); Petersen, Steffen E. (Queen Mary University of London); Piechnik, Stefan K. (University of Oxford); Neubauer, Stefan (University of Oxford); Glocker, Ben (Imperial College London); Rueckert, Daniel (Imperial College London)",419,249,18.77,144.29,https://doi.org/10.1186/s12968-018-0471-x,https://app.dimensions.ai/details/publication/pub.1106947579,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences,,,,,,,,,,
1545,pub.1119262979,10.48550/arxiv.1809.01015,,,Automated segmentation on the entire cardiac cycle using a deep learning  work-flow,"The segmentation of the left ventricle (LV) from CINE MRI images is essential
to infer important clinical parameters. Typically, machine learning algorithms
for automated LV segmentation use annotated contours from only two cardiac
phases, diastole, and systole. In this work, we present an analysis work-flow
for fully-automated LV segmentation that learns from images acquired through
the cardiac cycle. The workflow consists of three components: first, for each
image in the sequence, we perform an automated localization and subsequent
cropping of the bounding box containing the cardiac silhouette. Second, we
identify the LV contours using a Temporal Fully Convolutional Neural Network
(T-FCNN), which extends Fully Convolutional Neural Networks (FCNN) through a
recurrent mechanism enforcing temporal coherence across consecutive frames.
Finally, we further defined the boundaries using either one of two components:
fully-connected Conditional Random Fields (CRFs) with Gaussian edge potentials
and Semantic Flow. Our initial experiments suggest that significant improvement
in performance can potentially be achieved by using a recurrent neural network
component that explicitly learns cardiac motion patterns whilst performing LV
segmentation.",,,arXiv,,,2018-08-31,2018,,,,,,All OA, Green,Preprint,"Savioli, Nicoló; Vieira, Miguel Silva; Lamata, Pablo; Montana, Giovanni","Savioli, Nicoló (); Vieira, Miguel Silva (); Lamata, Pablo (); Montana, Giovanni ()",,"Savioli, Nicoló (); Vieira, Miguel Silva (); Lamata, Pablo (); Montana, Giovanni ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119262979,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
910,pub.1118176664,10.48550/arxiv.1808.08578,,,Automatic 3D bi-ventricular segmentation of cardiac images by a  shape-refined multi-task deep learning approach,"Deep learning approaches have achieved state-of-the-art performance in
cardiac magnetic resonance (CMR) image segmentation. However, most approaches
have focused on learning image intensity features for segmentation, whereas the
incorporation of anatomical shape priors has received less attention. In this
paper, we combine a multi-task deep learning approach with atlas propagation to
develop a shape-constrained bi-ventricular segmentation pipeline for short-axis
CMR volumetric images. The pipeline first employs a fully convolutional network
(FCN) that learns segmentation and landmark localisation tasks simultaneously.
The architecture of the proposed FCN uses a 2.5D representation, thus combining
the computational advantage of 2D FCNs networks and the capability of
addressing 3D spatial consistency without compromising segmentation accuracy.
Moreover, the refinement step is designed to explicitly enforce a shape
constraint and improve segmentation quality. This step is effective for
overcoming image artefacts (e.g. due to different breath-hold positions and
large slice thickness), which preclude the creation of anatomically meaningful
3D cardiac shapes. The proposed pipeline is fully automated, due to network's
ability to infer landmarks, which are then used downstream in the pipeline to
initialise atlas propagation. We validate the pipeline on 1831 healthy subjects
and 649 subjects with pulmonary hypertension. Extensive numerical experiments
on the two datasets demonstrate that our proposed method is robust and capable
of producing accurate, high-resolution and anatomically smooth bi-ventricular
3D models, despite the artefacts in input CMR volumes.",,,arXiv,,,2018-08-26,2018,,,,,,All OA, Green,Preprint,"Duan, Jinming; Bello, Ghalib; Schlemper, Jo; Bai, Wenjia; Dawes, Timothy J W; Biffi, Carlo; de Marvao, Antonio; Doumou, Georgia; O'Regan, Declan P; Rueckert, Daniel","Duan, Jinming (); Bello, Ghalib (); Schlemper, Jo (); Bai, Wenjia (); Dawes, Timothy J W (); Biffi, Carlo (); de Marvao, Antonio (); Doumou, Georgia (); O'Regan, Declan P (); Rueckert, Daniel ()",,"Duan, Jinming (); Bello, Ghalib (); Schlemper, Jo (); Bai, Wenjia (); Dawes, Timothy J W (); Biffi, Carlo (); de Marvao, Antonio (); Doumou, Georgia (); O'Regan, Declan P (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1118176664,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",,,,,,,,,,,
4547,pub.1106153147,10.1109/jbhi.2018.2865450,30113903,,Convolutional Neural Network With Shape Prior Applied to Cardiac MRI Segmentation,"In this paper, we present a novel convolutional neural network architecture to segment images from a series of short-axis cardiac magnetic resonance slices (CMRI). The proposed model is an extension of the U-net that embeds a cardiac shape prior and involves a loss function tailored to the cardiac anatomy. Since the shape prior is computed offline only once, the execution of our model is not limited by its calculation. Our system takes as input raw magnetic resonance images, requires no manual preprocessing or image cropping and is trained to segment the endocardium and epicardium of the left ventricle, the endocardium of the right ventricle, as well as the center of the left ventricle. With its multiresolution grid architecture, the network learns both high and low-level features useful to register the shape prior as well as accurately localize the borders of the cardiac regions. Experimental results obtained on the Automatic Cardiac Diagnostic Challenge - Medical Image Computing and Computer Assisted Intervention (ACDC-MICCAI) 2017 dataset show that our model segments multislices CMRI (left and right ventricle contours) in 0.18 s with an average Dice coefficient of [Formula: see text] and an average 3-D Hausdorff distance of [Formula: see text] mm.",,,IEEE Journal of Biomedical and Health Informatics,,"Cardiac Imaging Techniques; Databases, Factual; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer",2018-08-14,2018,2018-08-14,2019-05,23,3,1119-1128,Closed,Article,"Zotti, Clement; Luo, Zhiming; Lalande, Alain; Jodoin, Pierre-Marc","Zotti, Clement (Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, J1K 2R1, Canada); Luo, Zhiming (Department of Cognitive Science, Xiamen University, Xiamen, 361005, China; Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, J1K 2R1, Canada); Lalande, Alain (Le2i laboratory, CNRS FRE 2005, University of Burgundy, Dijon, 21079, France; MRI Department, University Hospital of Dijon, Dijon, 21079, France); Jodoin, Pierre-Marc (Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, J1K 2R1, Canada)","Zotti, Clement (Université de Sherbrooke)","Zotti, Clement (Université de Sherbrooke); Luo, Zhiming (Xiamen University; Université de Sherbrooke); Lalande, Alain (University of Burgundy; Centre Hospitalier Universitaire Dijon Bourgogne); Jodoin, Pierre-Marc (Université de Sherbrooke)",107,70,5.61,63.72,,https://app.dimensions.ai/details/publication/pub.1106153147,46 Information and Computing Sciences, 4601 Applied Computing,,,,,,,,,,,
1657,pub.1119181096,10.48550/arxiv.1807.08935,,,Combining Heterogeneously Labeled Datasets For Training Segmentation  Networks,"Accurate segmentation of medical images is an important step towards
analyzing and tracking disease related morphological alterations in the
anatomy. Convolutional neural networks (CNNs) have recently emerged as a
powerful tool for many segmentation tasks in medical imaging. The performance
of CNNs strongly depends on the size of the training data and combining data
from different sources is an effective strategy for obtaining larger training
datasets. However, this is often challenged by heterogeneous labeling of the
datasets. For instance, one of the dataset may be missing labels or a number of
labels may have been combined into a super label. In this work we propose a
cost function which allows integration of multiple datasets with heterogeneous
label subsets into a joint training. We evaluated the performance of this
strategy on thigh MR and a cardiac MR datasets in which we artificially merged
labels for half of the data. We found the proposed cost function substantially
outperforms a naive masking approach, obtaining results very close to using the
full annotations.",,,arXiv,,,2018-07-24,2018,,,,,,All OA, Green,Preprint,"Kemnitz, Jana; Baumgartner, Christian F.; Wirth, Wolfgang; Eckstein, Felix; Eder, Sebastian K.; Konukoglu, Ender","Kemnitz, Jana (); Baumgartner, Christian F. (); Wirth, Wolfgang (); Eckstein, Felix (); Eder, Sebastian K. (); Konukoglu, Ender ()",,"Kemnitz, Jana (); Baumgartner, Christian F. (); Wirth, Wolfgang (); Eckstein, Felix (); Eder, Sebastian K. (); Konukoglu, Ender ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119181096,46 Information and Computing Sciences, 4611 Machine Learning,,,,,,,,,,
5774,pub.1104047828,10.1109/tmi.2018.2837502,29994302,,Deep Learning Techniques for Automatic MRI Cardiac Multi-Structures Segmentation and Diagnosis: Is the Problem Solved?,"Delineation of the left ventricular cavity, myocardium, and right ventricle from cardiac magnetic resonance images (multi-slice 2-D cine MRI) is a common clinical task to establish diagnosis. The automation of the corresponding tasks has thus been the subject of intense research over the past decades. In this paper, we introduce the ""Automatic Cardiac Diagnosis Challenge"" dataset (ACDC), the largest publicly available and fully annotated dataset for the purpose of cardiac MRI (CMR) assessment. The dataset contains data from 150 multi-equipments CMRI recordings with reference measurements and classification from two medical experts. The overarching objective of this paper is to measure how far state-of-the-art deep learning methods can go at assessing CMRI, i.e., segmenting the myocardium and the two ventricles as well as classifying pathologies. In the wake of the 2017 MICCAI-ACDC challenge, we report results from deep learning methods provided by nine research groups for the segmentation task and four groups for the classification task. Results show that the best methods faithfully reproduce the expert analysis, leading to a mean value of 0.97 correlation score for the automatic extraction of clinical indices and an accuracy of 0.96 for automatic diagnosis. These results clearly open the door to highly accurate and fully automatic analysis of cardiac CMRI. We also identify scenarios for which deep learning methods are still failing. Both the dataset and detailed results are publicly available online, while the platform will remain open for new submissions.",,,IEEE Transactions on Medical Imaging,,"Cardiac Imaging Techniques; Databases, Factual; Deep Learning; Female; Heart; Heart Diseases; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male",2018-05-17,2018,2018-05-17,2018-11,37,11,2514-2525,All OA, Green,Article,"Bernard, Olivier; Lalande, Alain; Zotti, Clement; Cervenansky, Frederick; Yang, Xin; Heng, Pheng-Ann; Cetin, Irem; Lekadir, Karim; Camara, Oscar; Ballester, Miguel Angel Gonzalez; Sanroma, Gerard; Napel, Sandy; Petersen, Steffen; Tziritas, Georgios; Grinias, Elias; Khened, Mahendra; Kollerathu, Varghese Alex; Krishnamurthi, Ganapathy; Rohe, Marc-Michel; Pennec, Xavier; Sermesant, Maxime; Isensee, Fabian; Jager, Paul; Maier-Hein, Klaus H.; Full, Peter M.; Wolf, Ivo; Engelhardt, Sandy; Baumgartner, Christian F.; Koch, Lisa M.; Wolterink, Jelmer M.; Isgum, Ivana; Jang, Yeonggul; Hong, Yoonmi; Patravali, Jay; Jain, Shubham; Humbert, Olivier; Jodoin, Pierre-Marc","Bernard, Olivier (University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, Lyon, France); Lalande, Alain (Le2i Laboratory, CNRS FRE 2005, University of Burgundy, Dijon, France); Zotti, Clement (Computer Science Department, University of Sherbrooke, Sherbrooke, Canada); Cervenansky, Frederick (University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, Lyon, France); Yang, Xin (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong); Heng, Pheng-Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong); Cetin, Irem (Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain); Lekadir, Karim (Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain); Camara, Oscar (Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain); Ballester, Miguel Angel Gonzalez (Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain); Sanroma, Gerard (Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain); Napel, Sandy (Department of Radiology, Stanford University School of Medicine, Stanford, CA, USA); Petersen, Steffen (William Harvey Research Institute, Queen Mary University of London, London, U.K.); Tziritas, Georgios (Department of Computer Science, University of Crete, Heraklion, Greece); Grinias, Elias (Department of Computer Science, University of Crete, Heraklion, Greece); Khened, Mahendra (Department of Engineering Design, IIT Madras, Chennai, India); Kollerathu, Varghese Alex (Department of Engineering Design, IIT Madras, Chennai, India); Krishnamurthi, Ganapathy (Department of Engineering Design, IIT Madras, Chennai, India); Rohe, Marc-Michel (Inria-Asclepios Project, Sophia Antipolis, France); Pennec, Xavier (Inria-Asclepios Project, Sophia Antipolis, France); Sermesant, Maxime (Inria-Asclepios Project, Sophia Antipolis, France); Isensee, Fabian (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany); Jager, Paul (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany); Maier-Hein, Klaus H. (Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany); Full, Peter M. (Department of Computer Science, Mannheim University of Applied Sciences, Mannheim, Germany); Wolf, Ivo (Department of Computer Science, Mannheim University of Applied Sciences, Mannheim, Germany); Engelhardt, Sandy (Department of Computer Science, Mannheim University of Applied Sciences, Mannheim, Germany); Baumgartner, Christian F. (Computer Vision Laboratory, ETH Z&#x00FC;rich, Z&#x00FC;rich, Switzerland); Koch, Lisa M. (Computer Vision and Geometry Group, ETH Z&#x00FC;rich, Z&#x00FC;rich, Switzerland); Wolterink, Jelmer M. (Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands); Isgum, Ivana (Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands); Jang, Yeonggul (Integrative Cardiovascular Imaging Research Center, Yonsei University College of Medicine, Seoul, South Korea); Hong, Yoonmi (Integrative Cardiovascular Imaging Research Center, Yonsei University College of Medicine, Seoul, South Korea); Patravali, Jay (Qure.ai company, Mumbai, India); Jain, Shubham (Qure.ai company, Mumbai, India); Humbert, Olivier (TIRO-UMR E 4320 Laboratory, University of Nice, Nice, France); Jodoin, Pierre-Marc (Computer Science Department, University of Sherbrooke, Sherbrooke, Canada)",,"Bernard, Olivier (Institut National des Sciences Appliquées de Lyon); Lalande, Alain (University of Burgundy); Zotti, Clement (Université de Sherbrooke); Cervenansky, Frederick (Institut National des Sciences Appliquées de Lyon); Yang, Xin (Chinese University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong); Cetin, Irem (Pompeu Fabra University); Lekadir, Karim (Pompeu Fabra University); Camara, Oscar (Pompeu Fabra University); Ballester, Miguel Angel Gonzalez (Pompeu Fabra University); Sanroma, Gerard (Pompeu Fabra University); Napel, Sandy (Stanford University); Petersen, Steffen (Queen Mary University of London); Tziritas, Georgios (University of Crete); Grinias, Elias (University of Crete); Khened, Mahendra (Indian Institute of Technology Madras); Kollerathu, Varghese Alex (Indian Institute of Technology Madras); Krishnamurthi, Ganapathy (Indian Institute of Technology Madras); Rohe, Marc-Michel (); Pennec, Xavier (); Sermesant, Maxime (); Isensee, Fabian (German Cancer Research Center); Jager, Paul (German Cancer Research Center); Maier-Hein, Klaus H. (German Cancer Research Center); Full, Peter M. (Mannheim University of Applied Sciences); Wolf, Ivo (Mannheim University of Applied Sciences); Engelhardt, Sandy (Mannheim University of Applied Sciences); Baumgartner, Christian F. (); Koch, Lisa M. (); Wolterink, Jelmer M. (University Medical Center Utrecht); Isgum, Ivana (University Medical Center Utrecht); Jang, Yeonggul (Yonsei University); Hong, Yoonmi (Yonsei University); Patravali, Jay (); Jain, Shubham (); Humbert, Olivier (Université Côte d'Azur); Jodoin, Pierre-Marc (Université de Sherbrooke)",685,476,21.64,199.76,http://repositori.upf.edu/bitstream/10230/48000/1/Bernard_IEEETMI_deep.pdf,https://app.dimensions.ai/details/publication/pub.1104047828,46 Information and Computing Sciences, 4605 Data Management and Data Science,,,,,,,,,,
118,pub.1109700333,10.1007/978-3-030-00919-9,,,"Machine Learning in Medical Imaging, 9th International Workshop, MLMI 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings","This book constitutes the proceedings of the 9th International Workshop on Machine Learning in Medical Imaging, MLMI 2018, held in conjunction with MICCAI 2018 in Granada, Spain, in September 2018. The 45 papers presented in this volume were carefully reviewed and selected from 82 submissions. They focus on major trends and challenges in the area of machine learning in medical imaging and aim to identify new cutting-edge techniques and their use in medical imaging.",,,Lecture Notes in Computer Science,,,2018,2018,,2018,11046,,,Closed,Edited Book,,,,,9,3,,,,https://app.dimensions.ai/details/publication/pub.1109700333,46 Information and Computing Sciences,,,,,,,,,,,,
1137,pub.1118933615,10.48550/arxiv.1710.09289,,,Automated cardiovascular magnetic resonance image analysis with fully  convolutional networks,"Cardiovascular magnetic resonance (CMR) imaging is a standard imaging
modality for assessing cardiovascular diseases (CVDs), the leading cause of
death globally. CMR enables accurate quantification of the cardiac chamber
volume, ejection fraction and myocardial mass, providing information for
diagnosis and monitoring of CVDs. However, for years, clinicians have been
relying on manual approaches for CMR image analysis, which is time consuming
and prone to subjective errors. It is a major clinical challenge to
automatically derive quantitative and clinically relevant information from CMR
images. Deep neural networks have shown a great potential in image pattern
recognition and segmentation for a variety of tasks. Here we demonstrate an
automated analysis method for CMR images, which is based on a fully
convolutional network (FCN). The network is trained and evaluated on a
large-scale dataset from the UK Biobank, consisting of 4,875 subjects with
93,500 pixelwise annotated images. The performance of the method has been
evaluated using a number of technical metrics, including the Dice metric, mean
contour distance and Hausdorff distance, as well as clinically relevant
measures, including left ventricle (LV) end-diastolic volume (LVEDV) and
end-systolic volume (LVESV), LV mass (LVM); right ventricle (RV) end-diastolic
volume (RVEDV) and end-systolic volume (RVESV). By combining FCN with a
large-scale annotated dataset, the proposed automated method achieves a high
performance on par with human experts in segmenting the LV and RV on short-axis
CMR images and the left atrium (LA) and right atrium (RA) on long-axis CMR
images.",,,arXiv,,,2017-10-25,2017,,,,,,All OA, Green,Preprint,"Bai, Wenjia; Sinclair, Matthew; Tarroni, Giacomo; Oktay, Ozan; Rajchl, Martin; Vaillant, Ghislain; Lee, Aaron M.; Aung, Nay; Lukaschuk, Elena; Sanghvi, Mihir M.; Zemrak, Filip; Fung, Kenneth; Paiva, Jose Miguel; Carapella, Valentina; Kim, Young Jin; Suzuki, Hideaki; Kainz, Bernhard; Matthews, Paul M.; Petersen, Steffen E.; Piechnik, Stefan K.; Neubauer, Stefan; Glocker, Ben; Rueckert, Daniel","Bai, Wenjia (); Sinclair, Matthew (); Tarroni, Giacomo (); Oktay, Ozan (); Rajchl, Martin (); Vaillant, Ghislain (); Lee, Aaron M. (); Aung, Nay (); Lukaschuk, Elena (); Sanghvi, Mihir M. (); Zemrak, Filip (); Fung, Kenneth (); Paiva, Jose Miguel (); Carapella, Valentina (); Kim, Young Jin (); Suzuki, Hideaki (); Kainz, Bernhard (); Matthews, Paul M. (); Petersen, Steffen E. (); Piechnik, Stefan K. (); Neubauer, Stefan (); Glocker, Ben (); Rueckert, Daniel ()",,"Bai, Wenjia (); Sinclair, Matthew (); Tarroni, Giacomo (); Oktay, Ozan (); Rajchl, Martin (); Vaillant, Ghislain (); Lee, Aaron M. (); Aung, Nay (); Lukaschuk, Elena (); Sanghvi, Mihir M. (); Zemrak, Filip (); Fung, Kenneth (); Paiva, Jose Miguel (); Carapella, Valentina (); Kim, Young Jin (); Suzuki, Hideaki (); Kainz, Bernhard (); Matthews, Paul M. (); Petersen, Steffen E. (); Piechnik, Stefan K. (); Neubauer, Stefan (); Glocker, Ben (); Rueckert, Daniel ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1118933615,32 Biomedical and Clinical Sciences, 3202 Clinical Sciences, 46 Information and Computing Sciences,,,,,,,,,
