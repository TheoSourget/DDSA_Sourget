"About the data: Exported on Mar 06, 2023. Criteria: '""A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging""' in full data. Â© 2023 Digital Science &amp; Research Solutions Inc. All rights reserved. Parts of this work may also be protected by copyright of content providers and other third parties, which together with all rights of Digital Science, user agrees not to violate. Redistribution / external use of this work (or parts thereof) is prohibited without prior written approval. Please contact info@dimensions.ai for further information.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rank,Publication ID,DOI,PMID,PMCID,Title,Abstract,Acknowledgements,Funding,Source title,Anthology title,MeSH terms,Publication Date,PubYear,Publication Date (online),Publication Date (print),Volume,Issue,Pagination,Open Access,Publication Type,Authors,Authors (Raw Affiliation),Corresponding Authors,Authors Affiliations,Times cited,Recent citations,RCR,FCR,Source Linkout,Dimensions URL,Fields of Research (ANZSRC 2020),Sustainable Development Goals
12289,pub.1144567474,10.23919/cinc53138.2021.9662790,35662880,PMC9161679,A Deep Learning Framework for Image Super-Resolution for Late Gadolinium Enhanced Cardiac MRI,"Cardiac magnetic resonance imaging (MRI) provides 3D images with high-resolution in-plane information, however, they are known to have low through-plane resolution due to the trade-off between resolution, image acquisition time and signal-to-noise ratio. This results in anisotropic 3D images which could lead to difficulty in diagnosis, especially in late gadolinium enhanced (LGE) cardiac MRI, which is the reference imaging modality for locating the extent of myocardial fibrosis in various cardiovascular diseases like myocardial infarction and atrial fibrillation. To address this issue, we propose a self-supervised deep learning-based approach to enhance the through-plane resolution of the LGE MRI images. We train a convolutional neural network (CNN) model on randomly extracted patches of short-axis LGE MRI images and this trained CNN model is used to leverage the information learnt from the high-resolution in-plane data to improve the through-plane resolution. We conducted experiments on LGE MRI dataset made available through the 2018 atrial segmentation challenge. Our proposed method achieved a mean peak signal-to-noise-ratio (PSNR) of 36.99 and 35.92 and a mean structural similarity index measure (SSIM) of 0.9 and 0.84 on training the CNN model using low-resolution images downsampled by a scale factor of 2 and 4, respectively.",This work was supported by grants from the National Science Foundation (Award No. OAC 1808530) and the National Institutes of Health (Award No. R35GM128877). This work was supported by grants from the National Science Foundation (Award No. OAC 1808530) and the National Institutes of Health (Award No. R35GM128877).,,2016 Computing in Cardiology Conference (CinC),2021 Computing in Cardiology (CinC),,2021-09,2021,2022-01-10,2021-09,48,,1-4,All OA; Green,Proceeding,"Upendra, Roshan Reddy; Simon, Richard; Linte, Cristian A","Upendra, Roshan Reddy (Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA; RIT, Institute Hall (73) Rm 3130, Rochester, NY, 14623, USA); Simon, Richard (Biomedical Engineering, Rochester Institute of Technology, Rochester, NY, USA); Linte, Cristian A (Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA; Biomedical Engineering, Rochester Institute of Technology, Rochester, NY, USA)","Upendra, Roshan Reddy (Rochester Institute of Technology; Rochester Institute of Technology)","Upendra, Roshan Reddy (Rochester Institute of Technology; Rochester Institute of Technology); Simon, Richard (Rochester Institute of Technology); Linte, Cristian A (Rochester Institute of Technology; Rochester Institute of Technology)",1,1,0.36,0.56,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9161679,https://app.dimensions.ai/details/publication/pub.1144567474,40 Engineering; 4003 Biomedical Engineering; 46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
11448,pub.1150860475,10.1109/embc48229.2022.9871783,36086376,,A 3D Convolutional Neural Network with Gradient Guidance for Image Super-Resolution of Late Gadolinium Enhanced Cardiac MRI,"In this paper, we describe a 3D convolutional neural network (CNN) framework to compute and generate super-resolution late gadolinium enhanced (LGE) cardiac magnetic resonance imaging (MRI) images. The proposed CNN framework consists of two branches: a super-resolution branch with a 3D dense deep back-projection network (DBPN) as the backbone to learn the mapping of low-resolution LGE cardiac volumes to high-resolution LGE cardiac volumes, and a gradient branch that learns the mapping of the gradient map of low resolution LGE cardiac volumes to the gradient map of their high-resolution counterparts. The gradient branch of the CNN provides additional cardiac structure information to the super-resolution branch to generate structurally more accurate super-resolution LGE MRI images. We conducted our experiments on the 2018 atrial segmentation challenge dataset. The proposed CNN framework achieved a mean peak signal-to-noise ratio (PSNR) of 30.91 and 25.66 and a mean structural similarity index measure (SSIM) of 0.91 and 0.75 on training the model on low-resolution images downsamp led by a scale factor of 2 and 4, respectively.",,Research reported in this publication was supported by grants from the National Science Foundation (Award No. OAC 1808530) and the National Institutes of Health (Award No. R35GMI28877).,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Gadolinium; Heart Atria; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer",2022-07,2022,,2022-07,00,,1707-1710,Closed,Proceeding,"Upendra, Roshan Reddy; Linte, Cristian A.","Upendra, Roshan Reddy (Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA); Linte, Cristian A. (Department of Biomedical Engineering and Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA)",,"Upendra, Roshan Reddy (Rochester Institute of Technology); Linte, Cristian A. (Rochester Institute of Technology)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150860475,40 Engineering; 46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
11199,pub.1143755432,10.1109/embc46164.2021.9629941,34891968,,Hierarchical Consistency Regularized Mean Teacher for Semi-supervised 3D Left Atrium Segmentation,"Deep learning has achieved promising segmentation performance on 3D left atrium MR images. However, annotations for segmentation tasks are expensive, costly and difficult to obtain. In this paper, we introduce a novel hierarchical consistency regularized mean teacher framework for 3D left atrium segmentation. In each iteration, the student model is optimized by multi-scale deep supervision and hierarchical consistency regularization, concurrently. Extensive experiments have shown that our method achieves competitive performance as compared with full annotation, outperforming other state-of-the-art semi-supervised segmentation methods.","This research is supported by Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore. This research is supported by Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore.",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"Heart Atria; Humans; Imaging, Three-Dimensional; Students; Supervised Machine Learning",2021-11,2021,,2021-11,00,,3395-3398,All OA; Green,Proceeding,"Li, Shumeng; Zhao, Ziyuan; Xu, Kaixin; Zeng, Zeng; Guan, Cuntai","Li, Shumeng (Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore; Nanyang Technological University, Singapore); Zhao, Ziyuan (Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore; Nanyang Technological University, Singapore); Xu, Kaixin (Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore); Zeng, Zeng (Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore); Guan, Cuntai (Nanyang Technological University, Singapore)","Li, Shumeng (Institute for Infocomm Research; Nanyang Technological University)","Li, Shumeng (Institute for Infocomm Research; Nanyang Technological University); Zhao, Ziyuan (Institute for Infocomm Research; Nanyang Technological University); Xu, Kaixin (Institute for Infocomm Research); Zeng, Zeng (Institute for Infocomm Research); Guan, Cuntai (Nanyang Technological University)",13,13,1.92,10.64,http://arxiv.org/pdf/2105.10369,https://app.dimensions.ai/details/publication/pub.1143755432,46 Information and Computing Sciences; 4611 Machine Learning,
9230,pub.1147979681,10.3390/s22103820,35632229,PMC9145221,Multiresolution Aggregation Transformer UNet Based on Multiscale Input and Coordinate Attention for Medical Image Segmentation,"The latest medical image segmentation methods uses UNet and transformer structures with great success. Multiscale feature fusion is one of the important factors affecting the accuracy of medical image segmentation. Existing transformer-based UNet methods do not comprehensively explore multiscale feature fusion, and there is still much room for improvement. In this paper, we propose a novel multiresolution aggregation transformer UNet (MRA-TUNet) based on multiscale input and coordinate attention for medical image segmentation. It realizes multiresolution aggregation from the following two aspects: (1) On the input side, a multiresolution aggregation module is used to fuse the input image information of different resolutions, which enhances the input features of the network. (2) On the output side, an output feature selection module is used to fuse the output information of different scales to better extract coarse-grained information and fine-grained information. We try to introduce a coordinate attention structure for the first time to further improve the segmentation performance. We compare with state-of-the-art medical image segmentation methods on the automated cardiac diagnosis challenge and the 2018 atrial segmentation challenge. Our method achieved average dice score of 0.911 for right ventricle (RV), 0.890 for myocardium (Myo), 0.961 for left ventricle (LV), and 0.923 for left atrium (LA). The experimental results on two datasets show that our method outperforms eight state-of-the-art medical image segmentation methods in dice score, precision, and recall.","The author thanks the whole authors in the referred articles. In addition, the author would also like to thank Jiuying Chen and Ruiyang Guo. This study was supported by Sun Yat-sen University.",This work was supported in part by the Science and Technology Planning Project of Guangdong Science and Technology Department under Grant Guangdong Key Laboratory of Advanced IntelliSense Technology (2019B121203006).,Sensors,,"Attention; Heart; Heart Ventricles; Image Processing, Computer-Assisted",2022-05-18,2022,2022-05-18,,22,10,3820,All OA; Gold,Article,"Chen, Shaolong; Qiu, Changzhen; Yang, Weiping; Zhang, Zhiyong","Chen, Shaolong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.); Qiu, Changzhen (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.); Yang, Weiping (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.); Zhang, Zhiyong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen 518000, China.)","Zhang, Zhiyong (Sun Yat-sen University)","Chen, Shaolong (Sun Yat-sen University); Qiu, Changzhen (Sun Yat-sen University); Yang, Weiping (Sun Yat-sen University); Zhang, Zhiyong (Sun Yat-sen University)",3,3,,,https://www.mdpi.com/1424-8220/22/10/3820/pdf?version=1652860408,https://app.dimensions.ai/details/publication/pub.1147979681,46 Information and Computing Sciences; 4605 Data Management and Data Science,3 Good Health and Well Being
9177,pub.1147316264,10.1038/s41598-022-10464-w,35459270,PMC9033783,Introduction of Lazy Luna an automatic software-driven multilevel comparison of ventricular function quantification in cardiovascular magnetic resonance imaging,Cardiovascular magnetic resonance imaging is the gold standard for cardiac function assessment. Quantification of clinical results (CR) requires precise segmentation. Clinicians statistically compare CRs to ensure reproducibility. Convolutional Neural Network developers compare their results via metrics. Aim: Introducing software capable of automatic multilevel comparison. A multilevel analysis covering segmentations and CRs builds on a generic software backend. Metrics and CRs are calculated with geometric accuracy. Segmentations and CRs are connected to track errors and their effects. An interactive GUI makes the software accessible to different users. The softwareâs multilevel comparison was tested on a use case based on cardiac function assessment. The software shows good reader agreement in CRs and segmentation metrics (Diceâ>â90%). Decomposing differences by cardiac position revealed excellent agreement in midventricular slices:â>â90% but poorer segmentations in apical (>â71%) and basal slices (>â74%). Further decomposition by contour type locates the largest millilitre differences in the basal right cavity (>â3Â ml). Visual inspection shows these differences being caused by different basal slice choices. The software illuminated reader differences on several levels. Producing spreadsheets and figures concerning metric values and CR differences was automated. A multilevel reader comparison is feasible and extendable to other cardiac structures in the future.,"We wish to thank the members of the WG CMR for input at different steps. TH receives funding from the German Research Foundation (GRK2260, BIOQIC). At time of the softwareâs conception TH was a Masterâs student employee at Siemens Healthineers, Erlangen Germany.",Open Access funding enabled and organized by Projekt DEAL.,Scientific Reports,,"Magnetic Resonance Imaging; Neural Networks, Computer; Reproducibility of Results; Software; Ventricular Function",2022-04-22,2022,2022-04-22,,12,1,6629,All OA; Gold,Article,"Hadler, Thomas; Wetzl, Jens; Lange, Steffen; Geppert, Christian; Fenski, Max; Abazi, Endri; GrÃ¶schel, Jan; Ammann, Clemens; Wenson, Felix; TÃ¶pper, Agnieszka; DÃ¤uber, Sascha; Schulz-Menger, Jeanette","Hadler, Thomas (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-DelbrÃ¼ck-Center for Molecular Medicine in the Helmholtz Association and the CharitÃ© - UniversitÃ¤tsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany); Wetzl, Jens (Siemens Healthineers, Erlangen, Germany); Lange, Steffen (Department of Computer Sciences, Hochschule Darmstadt - University of Applied Sciences, Darmstadt, Germany); Geppert, Christian (Siemens Healthineers, Erlangen, Germany); Fenski, Max (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-DelbrÃ¼ck-Center for Molecular Medicine in the Helmholtz Association and the CharitÃ© - UniversitÃ¤tsmedizin Berlin, Berlin, Germany); Abazi, Endri (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-DelbrÃ¼ck-Center for Molecular Medicine in the Helmholtz Association and the CharitÃ© - UniversitÃ¤tsmedizin Berlin, Berlin, Germany); GrÃ¶schel, Jan (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-DelbrÃ¼ck-Center for Molecular Medicine in the Helmholtz Association and the CharitÃ© - UniversitÃ¤tsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany); Ammann, Clemens (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany); Wenson, Felix (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-DelbrÃ¼ck-Center for Molecular Medicine in the Helmholtz Association and the CharitÃ© - UniversitÃ¤tsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany); TÃ¶pper, Agnieszka (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-DelbrÃ¼ck-Center for Molecular Medicine in the Helmholtz Association and the CharitÃ© - UniversitÃ¤tsmedizin Berlin, Berlin, Germany; Department of Internal Medicine III, Cardiology, Lutherstadt Wittenberg, Evangelisches Krankenhaus Paul Gerhardt Stift, Wittenberg, Germany); DÃ¤uber, Sascha (Siemens Healthineers, Erlangen, Germany); Schulz-Menger, Jeanette (CharitÃ© â UniversitÃ¤tsmedizin Berlin, corporate member of Freie UniversitÃ¤t Berlin and Humboldt-UniversitÃ¤t Zu Berlin, Berlin, Germany; Working Group On CMR, Experimental and Clinical Research Center, a cooperation between the Max-DelbrÃ¼ck-Center for Molecular Medicine in the Helmholtz Association and the CharitÃ© - UniversitÃ¤tsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), partner site Berlin, Berlin, Germany; Department of Cardiology and Nephrology, HELIOS Hospital Berlin-Buch, Berlin, Germany)","Schulz-Menger, Jeanette (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine; German Centre for Cardiovascular Research; Helios Hospital Berlin-Buch)","Hadler, Thomas (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine; German Centre for Cardiovascular Research); Wetzl, Jens (Siemens Healthcare (Germany)); Lange, Steffen (Darmstadt University of Applied Sciences); Geppert, Christian (Siemens Healthcare (Germany)); Fenski, Max (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine); Abazi, Endri (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine); GrÃ¶schel, Jan (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine; German Centre for Cardiovascular Research); Ammann, Clemens (CharitÃ© - University Medicine Berlin); Wenson, Felix (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine; German Centre for Cardiovascular Research); TÃ¶pper, Agnieszka (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine); DÃ¤uber, Sascha (Siemens Healthcare (Germany)); Schulz-Menger, Jeanette (CharitÃ© - University Medicine Berlin; Max DelbrÃ¼ck Center for Molecular Medicine; German Centre for Cardiovascular Research; Helios Hospital Berlin-Buch)",1,1,,,https://www.nature.com/articles/s41598-022-10464-w.pdf,https://app.dimensions.ai/details/publication/pub.1147316264,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 46 Information and Computing Sciences; 4612 Software Engineering,
8880,pub.1153613587,10.1016/j.compbiomed.2022.106427,36543009,,Transformer-based multilevel region and edge aggregation network for magnetic resonance image segmentation,"To improve the quality of magnetic resonance (MR) image edge segmentation, some researchers applied additional edge labels to train the network to extract edge information and aggregate it with region information. They have made significant progress. However, due to the intrinsic locality of convolution operations, the convolution neural network-based region and edge aggregation has limitations in modeling long-range information. To solve this problem, we proposed a novel transformer-based multilevel region and edge aggregation network for MR image segmentation. To the best of our knowledge, this is the first literature on transformer-based region and edge aggregation. We first extract multilevel region and edge features using a dual-branch module. Then, the region and edge features at different levels are inferred and aggregated through multiple transformer-based inference modules to form multilevel complementary features. Finally, the attention feature selection module aggregates these complementary features with the corresponding level region and edge features to decode the region and edge features. We evaluated our method on a public MR dataset: Medical image computation and computer-assisted intervention atrial segmentation challenge (ASC). Meanwhile, the private MR dataset considered infrapatellar fat pad (IPFP). Our method achieved a dice score of 93.2% for ASC and 91.9% for IPFP. Compared with other 2D segmentation methods, our method improved a dice score by 0.6% for ASC and 3.0% for IPFP.",Shaolong Chen and Lijie Zhong contributed equally to this work. Zhiyong Zhang and Xiaodong Zhang are both corresponding authors. This work was supported in part by the Science and Technology Planning Project of the Guangdong Science and Technology Department under Grant Guangdong Key Laboratory of Advanced IntelliSense Technology (2019B121203006).,,Computers in Biology and Medicine,,"Heart Atria; Neural Networks, Computer; Image Processing, Computer-Assisted",2022-12-14,2022,2022-12-14,2023-01,152,,106427,Closed,Article,"Chen, Shaolong; Zhong, Lijie; Qiu, Changzhen; Zhang, Zhiyong; Zhang, Xiaodong","Chen, Shaolong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen, 518107, China.); Zhong, Lijie (Department of Medical Imaging, The Third Affiliated Hospital of Southern Medical University (Academy of OrthopedicsÂ·Guangdong Province), Guangzhou, 510630, China.); Qiu, Changzhen (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen, 518107, China.); Zhang, Zhiyong (School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen, 518107, China. Electronic address: zhangzhy99@mail.sysu.edu.cn.); Zhang, Xiaodong (Department of Medical Imaging, The Third Affiliated Hospital of Southern Medical University (Academy of OrthopedicsÂ·Guangdong Province), Guangzhou, 510630, China. Electronic address: ddautumn@126.com.)","Zhang, Zhiyong (Sun Yat-sen University); Zhang, Xiaodong (Third Affiliated Hospital of Southern Medical University)","Chen, Shaolong (Sun Yat-sen University); Zhong, Lijie (Third Affiliated Hospital of Southern Medical University); Qiu, Changzhen (Sun Yat-sen University); Zhang, Zhiyong (Sun Yat-sen University); Zhang, Xiaodong (Third Affiliated Hospital of Southern Medical University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153613587,46 Information and Computing Sciences; 4605 Data Management and Data Science,
8617,pub.1140629851,10.3389/fphys.2021.733139,34512401,PMC8424004,Reinforcement Learning to Improve Image-Guidance of Ablation Therapy for Atrial Fibrillation,"Atrial fibrillation (AF) is the most common cardiac arrhythmia and currently affects more than 650,000 people in the United Kingdom alone. Catheter ablation (CA) is the only AF treatment with a long-term curative effect as it involves destroying arrhythmogenic tissue in the atria. However, its success rate is suboptimal, approximately 50% after a 2-year follow-up, and this high AF recurrence rate warrants significant improvements. Image-guidance of CA procedures have shown clinical promise, enabling the identification of key patient anatomical and pathological (such as fibrosis) features of atrial tissue, which require ablation. However, the latter approach still suffers from a lack of functional information and the need to interpret structures in the images by a clinician. Deep learning plays an increasingly important role in biomedicine, facilitating efficient diagnosis and treatment of clinical problems. This study applies deep reinforcement learning in combination with patient imaging (to provide structural information of the atria) and image-based modelling (to provide functional information) to design patient-specific CA strategies to guide clinicians and improve treatment success rates. To achieve this, patient-specific 2D left atrial (LA) models were derived from late-gadolinium enhancement (LGE) MRI scans of AF patients and were used to simulate patient-specific AF scenarios. Then a reinforcement Q-learning algorithm was created, where an ablating agent moved around the 2D LA, applying CA lesions to terminate AF and learning through feedback imposed by a reward policy. The agent achieved 84% success rate in terminating AF during training and 72% success rate in testing. Finally, AF recurrence rate was measured by attempting to re-initiate AF in the 2D atrial models after CA with 11% recurrence showing a great improvement on the existing therapies. Thus, reinforcement Q-learning algorithms can predict successful CA strategies from patient MRI data and help to improve the patient-specific guidance of CA therapy.",,,Frontiers in Physiology,,,2021-08-25,2021,2021-08-25,,12,,733139,All OA; Gold,Article,"Muizniece, Laila; Bertagnoli, Adrian; Qureshi, Ahmed; Zeidan, Aya; Roy, Aditi; Muffoletto, Marica; Aslanidi, Oleg","Muizniece, Laila (School of Biomedical Engineering & Imaging Sciences, Kingâs College London, London, United Kingdom); Bertagnoli, Adrian (School of Biomedical Engineering & Imaging Sciences, Kingâs College London, London, United Kingdom; Department of Biomedical Engineering, ETH ZÃ¼rich, ZÃ¼rich, Switzerland); Qureshi, Ahmed (School of Biomedical Engineering & Imaging Sciences, Kingâs College London, London, United Kingdom); Zeidan, Aya (School of Biomedical Engineering & Imaging Sciences, Kingâs College London, London, United Kingdom); Roy, Aditi (School of Biomedical Engineering & Imaging Sciences, Kingâs College London, London, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom); Muffoletto, Marica (School of Biomedical Engineering & Imaging Sciences, Kingâs College London, London, United Kingdom); Aslanidi, Oleg (School of Biomedical Engineering & Imaging Sciences, Kingâs College London, London, United Kingdom)","Aslanidi, Oleg (King's College London)","Muizniece, Laila (King's College London); Bertagnoli, Adrian (King's College London; ETH Zurich); Qureshi, Ahmed (King's College London); Zeidan, Aya (King's College London); Roy, Aditi (King's College London; University of Oxford); Muffoletto, Marica (King's College London); Aslanidi, Oleg (King's College London)",2,2,0.22,1.37,https://www.frontiersin.org/articles/10.3389/fphys.2021.733139/pdf,https://app.dimensions.ai/details/publication/pub.1140629851,32 Biomedical and Clinical Sciences; 3208 Medical Physiology,
8563,pub.1148731846,10.1016/j.compmedimag.2022.102092,35777192,,A contrastive consistency semi-supervised left atrium segmentation model,"Accurate segmentation for the left atrium (LA) is a key process of clinical diagnosis and therapy for atrial fibrillation. In clinical, the semantic-level segmentation of LA consumes much time and labor. Although supervised deep learning methods can somewhat solve this problem, a high-efficient deep learning model requires abundant labeled data that is hard to acquire. Therefore, the research on automatic LA segmentation of leveraging unlabeled data is highly required. In this paper, we propose a semi-supervised LA segmentation framework including a segmentation model and a classification model. The segmentation model takes volumes from both labeled and unlabeled data as input and generates predictions of LAs. And then, a classification model maps these predictions to class-vectors for each input. Afterward, to leverage the class information, we construct a contrastive consistency loss function based on these class-vectors, so that the model can enlarge the discrepancy of the inter-class and compact the similarity of the intra-class for learning more distinguishable representation. Moreover, we set the class-vectors from the labeled data as references to the class-vectors from the unlabeled data to relieve the influence of the unreliable prediction for the unlabeled data. At last, we evaluate our semi-supervised LA segmentation framework on a public LA dataset using four universal metrics and compare it with recent state-of-the-art models. The proposed model achieves the best performance on all metrics with a Dice Score of 89.81Â %, Jaccard of 81.64Â %, 95Â % Hausdorff distance of 7.15Â mm, and Average Surface Distance of 1.82Â mm. The outstanding performance of the proposed framework shows that it may have a significant contribution to assisting the therapy of patients with atrial fibrillation. Code is available at: https://github.com/PerceptionComputingLab/SCC.",Thanks to the authors of Yu et al. (2019) and Ma et al. (2020). Their code repositories are the fundament of our work. Thanks to the organizers of the 2018 Atrial Segmentation Challenge to publish the LA segmentation dataset.,"This work was supported by the National Natural Science Foundation of China [grant numbers 62001141, 62001144]; and the Science and Technology Innovation Committee of Shenzhen Municipality [grant number JCYJ20210324131800002].",Computerized Medical Imaging and Graphics,,"Atrial Fibrillation; Heart Atria; Humans; Image Processing, Computer-Assisted; Supervised Machine Learning",2022-06-16,2022,2022-06-16,2022-07,99,,102092,Closed,Article,"Liu, Yashu; Wang, Wei; Luo, Gongning; Wang, Kuanquan; Li, Shuo","Liu, Yashu (School of Computer Science and Technology, Harbin Institute of Technology (HIT), China.); Wang, Wei (School of Computer Science and Technology, Harbin Institute of Technology (HIT), China. Electronic address: wangwei2019@hit.edu.cn.); Luo, Gongning (School of Computer Science and Technology, Harbin Institute of Technology (HIT), China.); Wang, Kuanquan (School of Computer Science and Technology, Harbin Institute of Technology (HIT), China.); Li, Shuo (Department of Medical Imaging, Western University, London, Canada.)","Wang, Wei (Harbin Institute of Technology)","Liu, Yashu (Harbin Institute of Technology); Wang, Wei (Harbin Institute of Technology); Luo, Gongning (Harbin Institute of Technology); Wang, Kuanquan (Harbin Institute of Technology); Li, Shuo (Western University)",3,3,,,,https://app.dimensions.ai/details/publication/pub.1148731846,46 Information and Computing Sciences; 4611 Machine Learning,
8563,pub.1134302251,10.3390/e23010064,33401695,PMC7824462,Bayesian Estimation of Geometric Morphometric Landmarks for Simultaneous Localization of Multiple Anatomies in Cardiac CT Images,"We propose a robust method to simultaneously localize multiple objects in cardiac computed tomography angiography (CTA) images. The relative prior distributions of the multiple objects in the three-dimensional (3D) space can be obtained through integrating the geometric morphological relationship of each target object to some reference objects. In cardiac CTA images, the cross-sections of ascending and descending aorta can play the role of the reference objects. We employed the maximum a posteriori (MAP) estimator that utilizes anatomic prior knowledge to address this problem of localizing multiple objects. We propose a new feature for each pixel using the relative distances, which can define any objects that have unclear boundaries. Our experimental results targeting four pulmonary veins (PVs) and the left atrial appendage (LAA) in cardiac CTA images demonstrate the robustness of the proposed method. The method could also be extended to localize other multiple objects in different applications.",,"This work was supported by the Korea Medical Device Development Fund grant funded by the Korea government (the Ministry of Science and ICT, the Ministry of Trade, Industry and Energy, the Ministry of Health & Welfare, Republic of Korea, the Ministry of Food and Drug Safety) (Project Number: 202016B02) and supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (1345322865).",Entropy,,,2021-01-02,2021,2021-01-02,,23,1,64,All OA; Gold,Article,"Jeon, Byunghwan; Jung, Sunghee; Shim, Hackjoon; Chang, Hyuk-Jae","Jeon, Byunghwan (School of Computer Science, Kyungil University, Gyeongsan 38428, Korea;, bhjeon@kiu.kr); Jung, Sunghee (CONNECT-AI R&D Center, Yonsei University College of Medicine, Seoul 03722,Korea;, sh.jung@yonsei.ac.kr, (S.J.);, hjshim@yuhs.ac, (H.S.)); Shim, Hackjoon (CONNECT-AI R&D Center, Yonsei University College of Medicine, Seoul 03722,Korea;, sh.jung@yonsei.ac.kr, (S.J.);, hjshim@yuhs.ac, (H.S.)); Chang, Hyuk-Jae (CONNECT-AI R&D Center, Yonsei University College of Medicine, Seoul 03722,Korea;, sh.jung@yonsei.ac.kr, (S.J.);, hjshim@yuhs.ac, (H.S.); Division of Cardiology Department of Internal Medicine, Yonsei University College of Medicine, Seoul 03722, Korea)","Chang, Hyuk-Jae (Yonsei University; ; Yonsei University)","Jeon, Byunghwan (Kyungil University); Jung, Sunghee (Yonsei University); Shim, Hackjoon (Yonsei University); Chang, Hyuk-Jae (Yonsei University; Yonsei University)",1,1,,,https://www.mdpi.com/1099-4300/23/1/64/pdf?version=1609577482,https://app.dimensions.ai/details/publication/pub.1134302251,49 Mathematical Sciences; 51 Physical Sciences,
8518,pub.1131793126,10.1016/j.media.2020.101832,33166776,,A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging,"Segmentation of medical images, particularly late gadolinium-enhanced magnetic resonance imaging (LGE-MRI) used for visualizing diseased atrial structures, is a crucial first step for ablation treatment of atrial fibrillation. However, direct segmentation of LGE-MRIs is challenging due to the varying intensities caused by contrast agents. Since most clinical studies have relied on manual, labor-intensive approaches, automatic methods are of high interest, particularly optimized machine learning approaches. To address this, we organized the 2018 Left Atrium Segmentation Challenge using 154 3D LGE-MRIs, currently the world's largest atrial LGE-MRI dataset, and associated labels of the left atrium segmented by three medical experts, ultimately attracting the participation of 27 international teams. In this paper, extensive analysis of the submitted algorithms using technical and biological metrics was performed by undergoing subgroup analysis and conducting hyper-parameter analysis, offering an overall picture of the major design choices of convolutional neural networks (CNNs) and practical considerations for achieving state-of-the-art left atrium segmentation. Results show that the top method achieved a Dice score of 93.2% and a mean surface to surface distance of 0.7â¯mm, significantly outperforming prior state-of-the-art. Particularly, our analysis demonstrated that double sequentially used CNNs, in which a first CNN is used for automatic region-of-interest localization and a subsequent CNN is used for refined regional segmentation, achieved superior results than traditional methods and machine learning approaches containing single CNNs. This large-scale benchmarking study makes a significant step towards much-improved segmentation methods for atrial LGE-MRIs, and will serve as an important benchmark for evaluating and comparing the future works in the field. Furthermore, the findings from this study can potentially be extended to other imaging datasets and modalities, having an impact on the wider medical imaging community.","The authors would like to thank Nvidia, MedTech CoRE New Zealand, and Arterys for providing prizes for the winners of the 2018 LA Segmentation Challenge. Z.X. and J.Z. are grateful for Nvidia for donating Titan-X Pascal GPU for algorithm development and testing, and the NIH/NIGMS Center for Integrative Biomedical Computing (CIBC) at the University of Utah for providing the LGE-MRI dataset. This work was funded by the Health Research Council of New Zealand [#16/385].",,Medical Image Analysis,,Algorithms; Benchmarking; Gadolinium; Heart Atria; Humans; Magnetic Resonance Imaging,2020-10-16,2020,2020-10-16,2021-01,67,,101832,All OA; Green,Article,"Xiong, Zhaohan; Xia, Qing; Hu, Zhiqiang; Huang, Ning; Bian, Cheng; Zheng, Yefeng; Vesal, Sulaiman; Ravikumar, Nishant; Maier, Andreas; Yang, Xin; Heng, Pheng-Ann; Ni, Dong; Li, Caizi; Tong, Qianqian; Si, Weixin; Puybareau, Elodie; Khoudli, Younes; GÃ©raud, Thierry; Chen, Chen; Bai, Wenjia; Rueckert, Daniel; Xu, Lingchao; Zhuang, Xiahai; Luo, Xinzhe; Jia, Shuman; Sermesant, Maxime; Liu, Yashu; Wang, Kuanquan; Borra, Davide; Masci, Alessandro; Corsi, Cristiana; de Vente, Coen; Veta, Mitko; Karim, Rashed; Preetha, Chandrakanth Jayachandran; Engelhardt, Sandy; Qiao, Menyun; Wang, Yuanyuan; Tao, Qian; NuÃ±ez-Garcia, Marta; Camara, Oscar; Savioli, Nicolo; Lamata, Pablo; Zhao, Jichao","Xiong, Zhaohan (Auckland Bioengineering Institute, University of Auckland, Auckland, New Zealand.); Xia, Qing (State Key Lab of Virtual Reality Technology and Systems, Beihang University, Beijing, China.); Hu, Zhiqiang (School of Electronics Engineering and Computer Science, Peking University, Beijing, China.); Huang, Ning (SenseTime Inc, Shenzhen, China.); Bian, Cheng (Tencent Jarvis Laboratory, Shenzhen, China.); Zheng, Yefeng (Tencent Jarvis Laboratory, Shenzhen, China.); Vesal, Sulaiman (Pattern Recognition Lab, Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg, Erlangen, Germany.); Ravikumar, Nishant (Pattern Recognition Lab, Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg, Erlangen, Germany.); Maier, Andreas (Pattern Recognition Lab, Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg, Erlangen, Germany.); Yang, Xin (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.); Heng, Pheng-Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.); Ni, Dong (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China.); Li, Caizi (School of Computer Science, Wuhan University, Wuhan, China.); Tong, Qianqian (School of Computer Science, Wuhan University, Wuhan, China.); Si, Weixin (Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China.); Puybareau, Elodie (EPITA Research and Development Laboratory, Paris, France.); Khoudli, Younes (EPITA Research and Development Laboratory, Paris, France.); GÃ©raud, Thierry (EPITA Research and Development Laboratory, Paris, France.); Chen, Chen (Department of Computing,Â Imperial College London, London, United Kingdom.); Bai, Wenjia (Department of Computing,Â Imperial College London, London, United Kingdom.); Rueckert, Daniel (Department of Computing,Â Imperial College London, London, United Kingdom.); Xu, Lingchao (School of Naval Architecture, Ocean & Civil Engineering, Shanghai Jiao Tong University, Shanghai, China.); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China.); Luo, Xinzhe (School of Data Science, Fudan University, Shanghai, China.); Jia, Shuman (Inria, UniversitÃ© CÃ´te d'Azur, Epione team, Sophia Antipolis, France.); Sermesant, Maxime (Inria, UniversitÃ© CÃ´te d'Azur, Epione team, Sophia Antipolis, France.); Liu, Yashu (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Wang, Kuanquan (School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.); Borra, Davide (Department of Electric, Electronic and Information Engineering, University of Bologna, Cesena, Italy.); Masci, Alessandro (Department of Electric, Electronic and Information Engineering, University of Bologna, Cesena, Italy.); Corsi, Cristiana (Department of Electric, Electronic and Information Engineering, University of Bologna, Cesena, Italy.); de Vente, Coen (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, the Netherlands.); Veta, Mitko (Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, the Netherlands.); Karim, Rashed (School of Biomedical Engineering & Imaging Sciences, Kings College London, London, United Kingdom.); Preetha, Chandrakanth Jayachandran (Faculty of Electrical Engineering and Information Technology, University of Magdeburg, Magdeburg, Germany.); Engelhardt, Sandy (Department of Internal Medicine III, Heidelberg University Hospital, Heidelberg, Germany.); Qiao, Menyun (Biomedical Engineering Center, Fudan University, Shanghai, China.); Wang, Yuanyuan (Biomedical Engineering Center, Fudan University, Shanghai, China.); Tao, Qian (Department of Radiology, Leiden University Medical Center, Leiden, the Netherlands.); NuÃ±ez-Garcia, Marta (Physense, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain.); Camara, Oscar (Physense, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain.); Savioli, Nicolo (Department of Bioengineering, Kings College London, London, United Kingdom.); Lamata, Pablo (Department of Bioengineering, Kings College London, London, United Kingdom.); Zhao, Jichao (Auckland Bioengineering Institute, University of Auckland, Auckland, New Zealand. Electronic address: j.zhao@auckland.ac.nz.)","Zhao, Jichao (University of Auckland)","Xiong, Zhaohan (University of Auckland); Xia, Qing (Beihang University); Hu, Zhiqiang (Peking University); Huang, Ning (); Bian, Cheng (); Zheng, Yefeng (); Vesal, Sulaiman (University of Erlangen-Nuremberg); Ravikumar, Nishant (University of Erlangen-Nuremberg); Maier, Andreas (University of Erlangen-Nuremberg); Yang, Xin (Chinese University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong); Ni, Dong (Shenzhen University); Li, Caizi (Wuhan University); Tong, Qianqian (Wuhan University); Si, Weixin (Shenzhen Institutes of Advanced Technology); Puybareau, Elodie (Graduate School of Computer Science and Advanced Technologies); Khoudli, Younes (Graduate School of Computer Science and Advanced Technologies); GÃ©raud, Thierry (Graduate School of Computer Science and Advanced Technologies); Chen, Chen (Imperial College London); Bai, Wenjia (Imperial College London); Rueckert, Daniel (Imperial College London); Xu, Lingchao (Shanghai Jiao Tong University); Zhuang, Xiahai (Fudan University); Luo, Xinzhe (Fudan University); Jia, Shuman (); Sermesant, Maxime (); Liu, Yashu (Harbin Institute of Technology); Wang, Kuanquan (Harbin Institute of Technology); Borra, Davide (University of Bologna); Masci, Alessandro (University of Bologna); Corsi, Cristiana (University of Bologna); de Vente, Coen (Eindhoven University of Technology); Veta, Mitko (Eindhoven University of Technology); Karim, Rashed (King's College London); Preetha, Chandrakanth Jayachandran (Otto-von-Guericke University Magdeburg); Engelhardt, Sandy (University Hospital Heidelberg); Qiao, Menyun (Fudan University); Wang, Yuanyuan (Fudan University); Tao, Qian (Leiden University Medical Center); NuÃ±ez-Garcia, Marta (Pompeu Fabra University); Camara, Oscar (Pompeu Fabra University); Savioli, Nicolo (King's College London); Lamata, Pablo (King's College London); Zhao, Jichao (University of Auckland)",77,76,11.17,37.75,https://scholarlypublications.universiteitleiden.nl/access/item%3A3307719/view,https://app.dimensions.ai/details/publication/pub.1131793126,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,
7563,pub.1149273495,10.1016/j.media.2022.102530,35839737,,Mutual consistency learning for semi-supervised medical image segmentation,"In this paper, we propose a novel mutual consistency network (MC-Net+) to effectively exploit the unlabeled data for semi-supervised medical image segmentation. The MC-Net+ model is motivated by the observation that deep models trained with limited annotations are prone to output highly uncertain and easily mis-classified predictions in the ambiguous regions (e.g., adhesive edges or thin branches) for medical image segmentation. Leveraging these challenging samples can make the semi-supervised segmentation model training more effective. Therefore, our proposed MC-Net+ model consists of two new designs. First, the model contains one shared encoder and multiple slightly different decoders (i.e., using different up-sampling strategies). The statistical discrepancy of multiple decoders' outputs is computed to denote the model's uncertainty, which indicates the unlabeled hard regions. Second, we apply a novel mutual consistency constraint between one decoder's probability output and other decoders' soft pseudo labels. In this way, we minimize the discrepancy of multiple outputs (i.e., the model uncertainty) during training and force the model to generate invariant results in such challenging regions, aiming at regularizing the model training. We compared the segmentation results of our MC-Net+ model with five state-of-the-art semi-supervised approaches on three public medical datasets. Extension experiments with two standard semi-supervised settings demonstrate the superior performance of our model over other methods, which sets a new state of the art for semi-supervised medical image segmentation. Our code is released publicly at https://github.com/ycwu1997/MC-Net.","This work was supported in part by the Monash FIT Start-up Grant, and in part by the National Natural Science Foundation of China under Grant 62171377, and in part by the Key Research and Development Program of Shaanxi Province under Grant 2022GY-084. We also appreciate the efforts to collect and share the datasets (Xiong et al., 2021; Clark et al., 2013; Bernard 485 et al., 2018) and several public benchmarks (Yu et al., 2019; Li et al., 2020b; Luo et al., 2021a,b; Luo, 2020).",,Medical Image Analysis,,"Deep Learning; Humans; Image Processing, Computer-Assisted; Supervised Machine Learning",2022-07-06,2022,2022-07-06,2022-10,81,,102530,All OA; Green,Article,"Wu, Yicheng; Ge, Zongyuan; Zhang, Donghao; Xu, Minfeng; Zhang, Lei; Xia, Yong; Cai, Jianfei","Wu, Yicheng (Department of Data Science & AI, Faculty of Information Technology, Monash University, Melbourne, VIC 3800, Australia. Electronic address: yicheng.wu@monash.edu.); Ge, Zongyuan (Monash-Airdoc Research, Monash University, Melbourne, VIC 3800, Australia; Monash Medical AI, Monash eResearch Centre, Melbourne, VIC 3800, Australia.); Zhang, Donghao (Monash Medical AI, Monash eResearch Centre, Melbourne, VIC 3800, Australia.); Xu, Minfeng (DAMO Academy, Alibaba Group, Hangzhou 311121, China.); Zhang, Lei (DAMO Academy, Alibaba Group, Hangzhou 311121, China.); Xia, Yong (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an 710072, China.); Cai, Jianfei (Department of Data Science & AI, Faculty of Information Technology, Monash University, Melbourne, VIC 3800, Australia.)","Wu, Yicheng (Monash University)","Wu, Yicheng (Monash University); Ge, Zongyuan (Monash University); Zhang, Donghao (); Xu, Minfeng (Alibaba Group (China)); Zhang, Lei (Alibaba Group (China)); Xia, Yong (Northwestern Polytechnical University); Cai, Jianfei (Monash University)",11,11,,,http://arxiv.org/pdf/2109.09960,https://app.dimensions.ai/details/publication/pub.1149273495,32 Biomedical and Clinical Sciences; 40 Engineering,
7552,pub.1144866538,10.1109/tcbb.2022.3144428,35061590,,Semi-supervised 3D Medical Image Segmentation Based on Dual-task Consistent joint Learning and Task-Level Regularization,"Semi-supervised learning has attracted wide attention from many researchers since its ability to utilize a few data with labels and relatively more data without labels to learn information. Some existing semi-supervised methods for medical image segmentation enforce the regularization of training by implicitly perturbing data or networks to perform the consistency. Most consistency regularization methods focus on data level or network structure level, and rarely of them focus on the task level. It may not directly lead to an improvement in task accuracy. To overcome the problem, this work proposes a semi-supervised dual-task consistent joint learning framework with task-level regularization for 3D medical image segmentation. Two branches are utilized to simultaneously predict the segmented and signed distance maps, and they can learn useful information from each other by constructing a consistency loss function between the two tasks. The segmentation branch learns rich information from both labeled and unlabeled data to strengthen the constraints on the geometric structure of the target. Experimental results on two benchmark datasets show that the proposed method can achieve better performance compared with other state-of-the-art works. It illustrates our method improves segmentation performance by utilizing unlabeled data and consistent regularization.",,,IEEE/ACM Transactions on Computational Biology and Bioinformatics,,,2022-01-21,2022,2022-01-21,2022-01-21,PP,99,1-1,Closed,Article,"Chen, Qi-Qi; Sun, Zhao-Hui; Wei, Chuan-Feng; Wu, Edmond Q.; Ming, Dong","Chen, Qi-Qi (Shanghai, Shanghai, China, (e-mail: 13297040055@163.com)); Sun, Zhao-Hui (Department of Industrial Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai, China, 200240 (e-mail: zh.sun@sjtu.edu.cn)); Wei, Chuan-Feng (Beijing, Beijing, China, (e-mail: 57410703@qq.com)); Wu, Edmond Q. (Key Laboratory of System Control and Information Processing, Ministry of Education, Shanghai Jiao Tong University, 12474 Shanghai, shanghai, China, 200240 (e-mail: edmondqwu@163.com)); Ming, Dong (Biomedical Engineering, Tianjin University, TianJin, Tianjin, China, (e-mail: richardming@tju.edu.cn))",,"Chen, Qi-Qi (); Sun, Zhao-Hui (Shanghai Jiao Tong University); Wei, Chuan-Feng (); Wu, Edmond Q. (Shanghai Jiao Tong University); Ming, Dong (Tianjin University)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1144866538,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
7186,pub.1154394105,10.3390/s23020690,36679487,PMC9865693,Cardiac Magnetic Resonance Image Segmentation Method Based on Multi-Scale Feature Fusion and Sequence Relationship Learning,"Accurate segmentation of the left atrial structure using magnetic resonance images provides an important basis for the diagnosis of atrial fibrillation (AF) and its treatment using robotic surgery. In this study, an image segmentation method based on sequence relationship learning and multi-scale feature fusion is proposed for 3D to 2D sequence conversion in cardiac magnetic resonance images and the varying scales of left atrial structures within different slices. Firstly, a convolutional neural network layer with an attention module was designed to extract and fuse contextual information at different scales in the image, to strengthen the target features using the correlation between features in different regions within the image, and to improve the network's ability to distinguish the left atrial structure. Secondly, a recurrent neural network layer oriented to two-dimensional images was designed to capture the correlation of left atrial structures in adjacent slices by simulating the continuous relationship between sequential image slices. Finally, a combined loss function was constructed to reduce the effect of positive and negative sample imbalance and improve model stability. The Dice, IoU, and Hausdorff distance values reached 90.73%, 89.37%, and 4.803 mm, respectively, based on the LASC2013 (left atrial segmentation challenge in 2013) dataset; the corresponding values reached 92.05%, 89.41% and 9.056 mm, respectively, based on the ASC2018 (atrial segmentation challenge at 2018) dataset.",,This research was funded by NSFC No.51905092.,Sensors,,"Humans; Atrial Fibrillation; Magnetic Resonance Imaging; Neural Networks, Computer; Heart Atria; Robotic Surgical Procedures; Image Processing, Computer-Assisted",2023-01-07,2023,2023-01-07,,23,2,690,All OA; Gold,Article,"Qi, Yushi; Hu, Chunhu; Zuo, Liling; Yang, Bo; Lv, Youlong","Qi, Yushi (College of Mechanical Engineering, Donghua University, Shanghai 201620, China); Hu, Chunhu (College of Mechanical Engineering, Donghua University, Shanghai 201620, China); Zuo, Liling (College of Mechanical Engineering, Donghua University, Shanghai 201620, China); Yang, Bo (College of Mechanical Engineering, Donghua University, Shanghai 201620, China); Lv, Youlong (Institute of Artificial Intelligence, Donghua University, Shanghai 201620, China)","Lv, Youlong (Donghua University)","Qi, Yushi (Donghua University); Hu, Chunhu (Donghua University); Zuo, Liling (Donghua University); Yang, Bo (Donghua University); Lv, Youlong (Donghua University)",0,0,,,https://www.mdpi.com/1424-8220/23/2/690/pdf?version=1673946099,https://app.dimensions.ai/details/publication/pub.1154394105,46 Information and Computing Sciences; 4611 Machine Learning,
7132,pub.1137750801,10.1109/jbhi.2021.3077469,33945491,,JAS-GAN: Generative Adversarial Network Based Joint Atrium and Scar Segmentations on Unbalanced Atrial Targets,"Automated and accurate segmentations of left atrium (LA) and atrial scars from late gadolinium-enhanced cardiac magnetic resonance (LGE CMR) images are in high demand for quantifying atrial scars. The previous quantification of atrial scars relies on a two-phase segmentation for LA and atrial scars due to their large volume difference (unbalanced atrial targets). In this paper, we propose an inter-cascade generative adversarial network, namely JAS-GAN, to segment the unbalanced atrial targets from LGE CMR images automatically and accurately in an end-to-end way. Firstly, JAS-GAN investigates an adaptive attention cascade to automatically correlate the segmentation tasks of the unbalanced atrial targets. The adaptive attention cascade mainly models the inclusion relationship of the two unbalanced atrial targets, where the estimated LA acts as the attention map to adaptively focus on the small atrial scars roughly. Then, an adversarial regularization is applied to the segmentation tasks of the unbalanced atrial targets for making a consistent optimization. It mainly forces the estimated joint distribution of LA and atrial scars to match the real ones. We evaluated the performance of our JAS-GAN on a 3D LGE CMR dataset with 192 scans. Compared with the state-of-the-art methods, our proposed approach yielded better segmentation performance (Average Dice Similarity Coefficient (DSC) values of 0.946 and 0.821 for LA and atrial scars, respectively), which indicated the effectiveness of our proposed approach for segmenting unbalanced atrial targets.",,"This work was supported in part by the Key-Area Research and Development Program of Guangdong Province under Grant 2019B010110001, in part by the National Natural Science Foundation of China under Grants 61771464 and U1801265, in part by the Key Program for International Cooperation Projects of Guangdong Province under Grant 2018A050506031, in part by the Guangdong Natural Science Funds for Distinguished Young Scholar under Grant 2019B151502031, in part by British Heart Foundation under Grants TG/18/5/34111 and PG/16/78/32402, in part by Innovative Medicines Initiative under Grant H2020-JTI-IMI2 101005122, and in part by ERC H2020 under Grant H2020-SC1-FA-DTS-2019-1952172.",IEEE Journal of Biomedical and Health Informatics,,"Cicatrix; Gadolinium; Heart Atria; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging",2022-01-17,2022,2022-01-17,2022-01,26,1,103-114,All OA; Green,Article,"Chen, Jun; Yang, Guang; Khan, Habib; Zhang, Heye; Zhang, Yanping; Zhao, Shu; Mohiaddin, Raad; Wong, Tom; Firmin, David; Keegan, Jennifer","Chen, Jun (School of Biomedical Engineering, Sun Yat-sen University, Guangzhou, 510275, China); Yang, Guang (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, U.K.); Khan, Habib (Cardiovascular Research Centre, Royal Brompton Hospital, SW3 6NP, London, U.K.); Zhang, Heye (School of Biomedical Engineering, Sun Yat-sen University, Guangzhou, 510275, China); Zhang, Yanping (School of Computer Science and Technology, Anhui University, Hefei, 230601, China); Zhao, Shu (School of Computer Science and Technology, Anhui University, Hefei, 230601, China); Mohiaddin, Raad (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, U.K.); Wong, Tom (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, U.K.); Firmin, David (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, U.K.); Keegan, Jennifer (Cardiovascular Research Centre, Royal Brompton Hospital, London, SW3 6NP, U.K.; National Heart and Lung Institute, Imperial College London, London, SW7 2AZ, U.K.)","Yang, Guang (Royal Brompton Hospital; Imperial College London)","Chen, Jun (Sun Yat-sen University); Yang, Guang (Royal Brompton Hospital; Imperial College London); Khan, Habib (Royal Brompton Hospital); Zhang, Heye (Sun Yat-sen University); Zhang, Yanping (Anhui University); Zhao, Shu (Anhui University); Mohiaddin, Raad (Royal Brompton Hospital; Imperial College London); Wong, Tom (Royal Brompton Hospital; Imperial College London); Firmin, David (Royal Brompton Hospital; Imperial College London); Keegan, Jennifer (Royal Brompton Hospital; Imperial College London)",31,31,,,http://arxiv.org/pdf/2105.00234,https://app.dimensions.ai/details/publication/pub.1137750801,46 Information and Computing Sciences; 4611 Machine Learning,
6775,pub.1147208859,10.1016/j.cmpb.2022.106821,35487181,,Deep learning-based automatic segmentation of images in cardiac radiography: A promising challenge,"BACKGROUND: Due to the advancement of medical imaging and computer technology, machine intelligence to analyze clinical image data increases the probability of disease prevention and successful treatment. When diagnosing and detecting heart disease, medical imaging can provide high-resolution scans of every organ or tissue in the heart. The diagnostic results obtained by the imaging method are less susceptible to human interference. They can process numerous patient information, assist doctors in early detection of heart disease, intervene and treat patients, and improve the understanding of heart disease symptoms and clinical diagnosis of great significance. In a computer-aided diagnosis system, accurate segmentation of cardiac scan images is the basis and premise of subsequent thoracic function analysis and 3D image reconstruction.
EXISTING TECHNIQUES: This paper systematically reviews automatic methods and some difficulties for cardiac segmentation in radiographic images. Combined with recent advanced deep learning techniques, the feasibility of using deep learning network models for image segmentation is discussed, and the commonly used deep learning frameworks are compared.
DEVELOPED INSIGHTS: There are many standard methods for medical image segmentation, such as traditional methods based on regions and edges and methods based on deep learning. Because of characteristics of non-uniform grayscale, individual differences, artifacts and noise of medical images, the above image segmentation methods have certain limitations. It is tough to obtain the needed results sensitivity and accuracy when performing heart segmentation. The deep learning model proposed has achieved good results in image segmentation. Accurate segmentation improves the accuracy of disease diagnosis and reduces subsequent irrelevant computations.
SUMMARY: There are two requirements for accurate segmentation of radiological images. One is to use image segmentation to improve the development of computer-aided diagnosis. The other is to achieve complete segmentation of the heart. When there are lesions or deformities in the heart, there will be some abnormalities in the radiographic images, and the segmentation algorithm needs to segment the heart altogether. The quantity of processing inside a certain range will no longer be a restriction for real-time detection with the advancement of deep learning and the enhancement of hardware device performance.","This work was funded by National Key RD Program of China (Grant numbers 2017YFC1703600, 2017YFC1703606), National Science Foundation of China (Grant Number 81771927), Natural Science Foundation of Top Talent of Shenzhen Technology University (Grant number 2019010801011), and Stable Support Project for Shenzhen Higher Education Institutions (Grant number SZWD2021011).",,Computer Methods and Programs in Biomedicine,,"Deep Learning; Heart Diseases; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Radiography",2022-04-19,2022,2022-04-19,2022-06,220,,106821,Closed,Article,"Song, Yucheng; Ren, Shengbing; Lu, Yu; Fu, Xianghua; Wong, Kelvin K L","Song, Yucheng (School of Computer Science and Engineering, Central South University, Changsha, China.); Ren, Shengbing (School of Computer Science and Engineering, Central South University, Changsha, China.); Lu, Yu (College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China. Electronic address: lvyu@sztu.edu.cn.); Fu, Xianghua (College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China.); Wong, Kelvin K L (School of Computer Science and Engineering, Central South University, Changsha, China. Electronic address: kelvin.wong@csu.edu.cn.)","Lu, Yu (Shenzhen Technology University); Wong, Kelvin K L (Central South University)","Song, Yucheng (Central South University); Ren, Shengbing (Central South University); Lu, Yu (Shenzhen Technology University); Fu, Xianghua (Shenzhen Technology University); Wong, Kelvin K L (Central South University)",5,5,,,,https://app.dimensions.ai/details/publication/pub.1147208859,40 Engineering; 4003 Biomedical Engineering; 46 Information and Computing Sciences,
6768,pub.1151790345,10.1109/tmi.2022.3213372,36219664,,Semi-supervised Unpaired Medical Image Segmentation Through Task-affinity Consistency,"Deep learning-based semi-supervised learning (SSL) algorithms are promising in reducing the cost of manual annotation of clinicians by using unlabelled data, when developing medical image segmentation tools. However, to date, most existing semi-supervised learning (SSL) algorithms treat the labelled images and unlabelled images separately and ignore the explicit connection between them; this disregards essential shared information and thus hinders further performance improvements. To mine the shared information between the labelled and unlabelled images, we introduce a class-specific representation extraction approach, in which a task-affinity module is specifically designed for representation extraction. We further cast the representation into two different views of feature maps; one is focusing on low-level context, while the other concentrates on structural information. The two views of feature maps are incorporated into the task-affinity module, which then extracts the class-specific representations to aid the knowledge transfer from the labelled images to the unlabelled images. In particular, a task-affinity consistency loss between the labelled images and unlabelled images based on the multi-scale class-specific representations is formulated, leading to a significant performance improvement. Experimental results on three datasets show that our method consistently outperforms existing state-of-the-art methods. Our findings highlight the potential of consistency between class-specific knowledge for semi-supervised medical image segmentation. The code and models are to be made publicly available at https://github.com/jingkunchen/TAC.",,,IEEE Transactions on Medical Imaging,,,2022-10-11,2022,2022-10-11,2022-10-11,PP,99,1-1,All OA; Green,Article,"Chen, Jingkun; Zhang, Jianguo; Debattista, Kurt; Han, Jungong","Chen, Jingkun (Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China); Zhang, Jianguo (Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China); Debattista, Kurt (Warwick Manufacturing Group, University of Warwick, Coventry, UK); Han, Jungong (Warwick Manufacturing Group, University of Warwick, Coventry, UK)",,"Chen, Jingkun (Southern University of Science and Technology); Zhang, Jianguo (Southern University of Science and Technology); Debattista, Kurt (University of Warwick); Han, Jungong (University of Warwick)",1,1,,,http://wrap.warwick.ac.uk/170166/1/WRAP-semi-supervised-unpaired-medical-image-segmentation-through-task-affinity-consistency-2022.pdf,https://app.dimensions.ai/details/publication/pub.1151790345,46 Information and Computing Sciences; 4602 Artificial Intelligence; 4603 Computer Vision and Multimedia Computation; 4605 Data Management and Data Science; 4611 Machine Learning,
6761,pub.1148084908,10.1109/tmi.2022.3176915,35604969,,Anti-Interference From Noisy Labels: Mean-Teacher-Assisted Confident Learning for Medical Image Segmentation,"Manually segmenting medical images is expertise-demanding, time-consuming and laborious. Acquiring massive high-quality labeled data from experts is often infeasible. Unfortunately, without sufficient high-quality pixel-level labels, the usual data-driven learning-based segmentation methods often struggle with deficient training. As a result, we are often forced to collect additional labeled data from multiple sources with varying label qualities. However, directly introducing additional data with low-quality noisy labels may mislead the network training and undesirably offset the efficacy provided by those high-quality labels. To address this issue, we propose a Mean-Teacher-assisted Confident Learning (MTCL) framework constructed by a teacher-student architecture and a label self-denoising process to robustly learn segmentation from a small set of high-quality labeled data and plentiful low-quality noisy labeled data. Particularly, such a synergistic framework is capable of simultaneously and robustly exploiting (i) the additional dark knowledge inside the images of low-quality labeled set via perturbation-based unsupervised consistency, and (ii) the productive information of their low-quality noisy labels via explicit label refinement. Comprehensive experiments on left atrium segmentation with simulated noisy labels and hepatic and retinal vessel segmentation with real-world noisy labels demonstrate the superior segmentation performance of our approach as well as its effectiveness on label denoising.",This research was done with Tencent Healthcare (Shenzhen) Company Ltd. and Tencent Jarvis Laboratory.,This work was supported in part by the Research Grant Council of Hong Kong under General Research Fund 14205419 and in part by the Scientific and Technical Innovation 2030-âNew Generation Artificial Intelligenceâ Project (2020AAA0104100).,IEEE Transactions on Medical Imaging,,,2022-10-27,2022,2022-10-27,2022-11,41,11,3062-3073,Closed,Article,"Xu, Zhe; Lu, Donghuan; Luo, Jie; Wang, Yixin; Yan, Jiangpeng; Ma, Kai; Zheng, Yefeng; Tong, Raymond Kai-Yu","Xu, Zhe (Department of Biomedical Engineering, The Chinese University of Hong Kong, Hong Kong, China); Lu, Donghuan (Tencent Healthcare (Shenzhen) Company Ltd., Shenzhen, 518057, China; Tencent Jarvis Laboratory, Shenzhen, 518057, China); Luo, Jie (Brigham and Womenâs Hospital, Harvard Medical School, Boston, MA, 02115, USA); Wang, Yixin (Department of Bioengineering, Stanford University, Stanford, CA, 94305, USA); Yan, Jiangpeng (Department of Automation, Tsinghua University, Beijing, 100190, China); Ma, Kai (Tencent Healthcare (Shenzhen) Company Ltd., Shenzhen, 518057, China; Tencent Jarvis Laboratory, Shenzhen, 518057, China); Zheng, Yefeng (Tencent Healthcare (Shenzhen) Company Ltd., Shenzhen, 518057, China; Tencent Jarvis Laboratory, Shenzhen, 518057, China); Tong, Raymond Kai-Yu (Department of Biomedical Engineering, The Chinese University of Hong Kong, Hong Kong, China)","Tong, Raymond Kai-Yu (Chinese University of Hong Kong)","Xu, Zhe (Chinese University of Hong Kong); Lu, Donghuan (Tencent Healthcare (China)); Luo, Jie (Harvard University; Brigham and Women's Hospital); Wang, Yixin (Stanford University); Yan, Jiangpeng (Tsinghua University); Ma, Kai (Tencent Healthcare (China)); Zheng, Yefeng (Tencent Healthcare (China)); Tong, Raymond Kai-Yu (Chinese University of Hong Kong)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1148084908,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4605 Data Management and Data Science; 4611 Machine Learning,
6755,pub.1153675288,10.1016/j.compbiomed.2022.106422,36535210,,TMS-Net: A segmentation network coupled with a run-time quality control method for robust cardiac image segmentation,"Recently, deep networks have shown impressive performance for the segmentation of cardiac Magnetic Resonance Imaging (MRI) images. However, their achievement is proving slow to transition to widespread use in medical clinics because of robustness issues leading to low trust of clinicians to their results. Predicting run-time quality of segmentation masks can be useful to warn clinicians against poor results. Despite its importance, there are few studies on this problem. To address this gap, we propose a quality control method based on the agreement across decoders of a multi-view network, TMS-Net, measured by the cosine similarity. The network takes three view inputs resliced from the same 3D image along different axes. Different from previous multi-view networks, TMS-Net has a single encoder and three decoders, leading to better noise robustness, segmentation performance and run-time quality estimation in our experiments on the segmentation of the left atrium on STACOM 2013 and STACOM 2018 challenge datasets. We also present a way to generate poor segmentation masks by using noisy images generated with engineered noise and Rician noise to simulate undertraining, high anisotropy and poor imaging settings problems. Our run-time quality estimation method show a good classification of poor and good quality segmentation masks with an AUC reaching to 0.97 on STACOM 2018. We believe that TMS-Net and our run-time quality estimation method has a high potential to increase the thrust of clinicians to automatic image analysis tools.","This work is financially supported by Bursa Technical University Scientific Research Projects Units , with the project number of 211N043.",,Computers in Biology and Medicine,,"Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Heart Atria; Anisotropy",2022-12-14,2022,2022-12-14,2023-01,152,,106422,All OA; Green,Article,"Uslu, FatmatÃ¼lzehra; Bharath, Anil A","Uslu, FatmatÃ¼lzehra (Bursa Technical University, Electrical and Electronics Engineering Department, Bursa, 16310, Turkey. Electronic address: fatmatulzehra.uslu@btu.edu.tr.); Bharath, Anil A (Imperial College London, Bioengineering Department, London, SW7 2AZ, UK. Electronic address: a.bharath@imperial.ac.uk.)","Uslu, FatmatÃ¼lzehra (Bursa Technical University)","Uslu, FatmatÃ¼lzehra (Bursa Technical University); Bharath, Anil A (Imperial College London)",0,0,,,http://arxiv.org/pdf/2212.10877,https://app.dimensions.ai/details/publication/pub.1153675288,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
6443,pub.1153241596,10.1109/tmi.2022.3225687,36449588,,Semi-supervised medical image segmentation using adversarial consistency learning and dynamic convolution network,"Popular semi-supervised medical image segmentation networks often suffer from error supervision from unlabeled data since they usually use consistency learning under different data perturbations to regularize model training. These networks ignore the relationship between labeled and unlabeled data, and only compute single pixel-level consistency leading to uncertain prediction results. Besides, these networks often require a large number of parameters since their backbone networks are designed depending on supervised image segmentation tasks. Moreover, these networks often face a high over-fitting risk since a small number of training samples are popular for semi-supervised image segmentation. To address the above problems, in this paper, we propose a novel adversarial self-ensembling network using dynamic convolution (ASE-Net) for semi-supervised medical image segmentation. First, we use an adversarial consistency training strategy (ACTS) that employs two discriminators based on consistency learning to obtain prior relationships between labeled and unlabeled data. The ACTS can simultaneously compute pixel-level and image-level consistency of unlabeled data under different data perturbations to improve the prediction quality of labels. Second, we design a dynamic convolution-based bidirectional attention component (DyBAC) that can be embedded in any segmentation network, aiming at adaptively adjusting the weights of ASE-Net based on the structural information of input samples. This component effectively improves the feature representation ability of ASE-Net and reduces the overfitting risk of the network. The proposed ASE-Net has been extensively tested on three publicly available datasets, and experiments indicate that ASE-Net is superior to state-of-the-art networks, and reduces computational costs and memory overhead. The code is available at: https://github.com/SUST-reynole/ASE-Net.",,,IEEE Transactions on Medical Imaging,,,2022-11-30,2022,2022-11-30,2022-11-30,PP,99,1-1,All OA; Hybrid,Article,"Lei, Tao; Zhang, Dong; Du, Xiaogang; Wang, Xuan; Wan, Yong; Nandi, Asoke K.","Lei, Tao (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi&#x2019;an, China); Zhang, Dong (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi&#x2019;an, China); Du, Xiaogang (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi&#x2019;an, China); Wang, Xuan (Department of Electrical and Computer Engineering, University of Wisconsin-Madison, Madison, WI, US); Wan, Yong (Department of Geriatric Surgery, First Affiliated Hospital, Xi&#x2019;an Jiaotong University, Xi&#x2019;an, China); Nandi, Asoke K. (Department of Electronic and Electrical Engineering, Brunel University London, Uxbridge, U.K.)",,"Lei, Tao (Shaanxi University of Science and Technology); Zhang, Dong (Shaanxi University of Science and Technology); Du, Xiaogang (Shaanxi University of Science and Technology); Wang, Xuan (University of WisconsinâMadison); Wan, Yong (Shanghai Jiao Tong University); Nandi, Asoke K. (Brunel University London)",0,0,,,https://ieeexplore.ieee.org/ielx7/42/4359023/09966841.pdf,https://app.dimensions.ai/details/publication/pub.1153241596,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
6117,pub.1139034715,10.1002/jmri.27732,34155715,PMC9292698,WholeâHeart HighâResolution Late Gadolinium Enhancement: Techniques and Clinical Applications,"In cardiovascular magnetic resonance, late gadolinium enhancement (LGE) has become the cornerstone of myocardial tissue characterization. It is widely used in clinical routine to diagnose and characterize the myocardial tissue in a wide range of ischemic and nonischemic cardiomyopathies. The recent growing interest in imaging left atrial fibrosis has led to the development of novel whole-heart high-resolution late gadolinium enhancement (HR-LGE) techniques. Indeed, conventional LGE is acquired in multiple breath-holds with limited spatial resolution: ~1.4-1.8âmm in plane and 6-8âmm slice thickness, according to the Society for Cardiovascular Magnetic Resonance standardized guidelines. Such large voxel size prevents its use in thin structures such as the atrial or right ventricular walls. Whole-heart 3D HR-LGE images are acquired in free breathing to increase the spatial resolution (up to 1.3Â Ãâ1.3Â Ãâ1.3âmm3 ) and offer a better detection and depiction of focal atrial fibrosis. The downside of this increased resolution is the extended scan time of around 10âmin, which hampers the spread of HR-LGE in clinical practice. Initially introduced for atrial fibrosis imaging, HR-LGE interest has evolved to be a tool to detect small scars in the ventricles and guide ablation procedures. Indeed, the detection of scars, nonvisible with conventional LGE, can be crucial in the diagnosis of myocardial infarction with nonobstructed coronary arteries, in the detection of the arrhythmogenic substrate triggering ventricular arrhythmia, and improve the confidence of clinicians in the challenging diagnoses such as the arrhythmogenic right ventricular cardiomyopathy. HR-LGE also offers a precise visualization of left ventricular scar morphology that is particularly useful in planning ablation procedures and guiding them through the fusion of HR-LGE images with electroanatomical mapping systems. In this narrative review, we attempt to summarize the technical particularities of whole-heart HR-LGE acquisition and provide an overview of its clinical applications with a particular focus on the ventricles. EVIDENCE LEVEL: 2 TECHNICAL EFFICACY STAGE: 2.","The research leading to these results has received funding from l&#x27;Agence Nationale de la Recherche (ANR) under Grant Agreements Equipex MUSIC ANRâ11âEQPXâ0030 and LIRYC ANRâ10âIAHUâ04, and the European Research Council under Grant Agreement ERC nÂ°715093.",,Journal of Magnetic Resonance Imaging,,Cicatrix; Contrast Media; Fibrosis; Gadolinium; Humans; Magnetic Resonance Imaging; Predictive Value of Tests,2021-06-21,2021,2021-06-21,2022-04,55,4,967-987,All OA; Hybrid,Article,"Toupin, Solenn; Pezel, ThÃ©o; Bustin, AurÃ©lien; Cochet, Hubert","Toupin, Solenn (Siemens Healthcare France, SaintâDenis, France; IHU Liryc, Electrophysiology and Heart Modeling Institute, Fondation Bordeaux UniversitÃ©, Bordeaux, France; UniversitÃ© de Bordeaux, Centre de recherche CardioâThoracique de Bordeaux, Bordeaux, France; INSERM, Centre de recherche CardioâThoracique de Bordeaux, Bordeaux, France); Pezel, ThÃ©o (Division of Cardiology, Johns Hopkins University, Baltimore, Maryland, USA; Department of Cardiology, Lariboisiere Hospital, APHP, University of Paris, Paris, France); Bustin, AurÃ©lien (IHU Liryc, Electrophysiology and Heart Modeling Institute, Fondation Bordeaux UniversitÃ©, Bordeaux, France; UniversitÃ© de Bordeaux, Centre de recherche CardioâThoracique de Bordeaux, Bordeaux, France; INSERM, Centre de recherche CardioâThoracique de Bordeaux, Bordeaux, France; Department of Diagnostic and Interventional Radiology, Lausanne University Hospital and University of Lausanne, Lausanne, Switzerland); Cochet, Hubert (IHU Liryc, Electrophysiology and Heart Modeling Institute, Fondation Bordeaux UniversitÃ©, Bordeaux, France; UniversitÃ© de Bordeaux, Centre de recherche CardioâThoracique de Bordeaux, Bordeaux, France; INSERM, Centre de recherche CardioâThoracique de Bordeaux, Bordeaux, France; Bordeaux University Hospital (CHU), Pessac, France)","Cochet, Hubert (Electrophysiology and Heart Modeling Institute; Centre de Recherche Cardio-Thoracique de Bordeaux; ; Centre Hospitalier Universitaire de Bordeaux)","Toupin, Solenn (Electrophysiology and Heart Modeling Institute; Centre de Recherche Cardio-Thoracique de Bordeaux); Pezel, ThÃ©o (Johns Hopkins University; HÃ´pital LariboisiÃ¨re); Bustin, AurÃ©lien (Electrophysiology and Heart Modeling Institute; Centre de Recherche Cardio-Thoracique de Bordeaux; University of Lausanne); Cochet, Hubert (Electrophysiology and Heart Modeling Institute; Centre de Recherche Cardio-Thoracique de Bordeaux; Centre Hospitalier Universitaire de Bordeaux)",7,7,,6.14,https://doi.org/10.1002/jmri.27732,https://app.dimensions.ai/details/publication/pub.1139034715,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,
5604,pub.1154982170,10.3390/jcdd10020056,36826552,PMC9968112,Comparative Analysis of Temperature Rise between Convective Heat Transfer Method and Computational Fluid Dynamics Method in an Anatomy-Based Left Atrium Model during Pulsed Field Ablation: A Computational Study,"The non-thermal effects are considered one of the prominent advantages of pulsed field ablation (PFA). However, at higher PFA doses, the temperature rise in the tissue during PFA may exceed the thermal damage threshold, at which time intracardiac pulsatile blood flow plays a crucial role in suppressing this temperature rise. This study aims to compare the effect of heat dissipation of the different methods in simulating the pulsatile blood flow during PFA. This study first constructed an anatomy-based left atrium (LA) model and then applied the convective heat transfer (CHT) method and the computational fluid dynamics (CFD) method to the model, respectively, and the thermal convective coefficients used in the CHT method are 984 (W/m2*K) (blood-myocardium interface) and 4372 (W/m2*K) (blood-catheter interface), respectively. Then, it compared the effect of the above two methods on the maximum temperature of myocardium and blood, as well as the myocardial ablation volumes caused by irreversible electroporation (IRE) and hyperthermia under different PFA parameters. Compared with the CFD method, the CHT method underestimates the maximum temperature of myocardium and blood; the differences in the maximum temperature of myocardium and blood between the two methods at the end of the last pulse are significant (>1 Â°C), and the differences in the maximum temperature of blood at the end of the last pulse interval are significant (>1 Â°C) only at a pulse amplitude greater than 1000 V or pulse number greater than 10. Under the same pulse amplitude and different heat dissipation methods, the IRE ablation volumes are the same. Compared with the CFD method, the CHT method underestimates the hyperthermia ablation volume; the differences in the hyperthermia ablation volume are significant (>1 mm3) only at a pulse amplitude greater than 1000 V, a pulse interval of 250 ms, or a pulse number greater than 10. Additionally, the hyperthermia ablation isosurfaces are completely wrapped by the IRE ablation isosurfaces in the myocardium. Thus, during PFA, compared with the CFD method, the CHT method cannot accurately simulate the maximum myocardial temperature; however, except at the above PFA parameters, the CHT method can accurately simulate the maximum blood temperature and the myocardial ablation volume caused by IRE and hyperthermia. Additionally, within the range of the PFA parameters used in this study, the temperature rise during PFA may not lead to the appearance of additional hyperthermia ablation areas beyond the IRE ablation area in the myocardium.",,"This study received financial support from the National Key R&D Program of China, grant No. 2022YFC2404904 & 2021YFC2400203, Shanghai Municipal Commission of Science and Technology, grant No. 21S31906900, Shanghai Municipal Commission of Economy and Information Technology, grant No. GYQJ-2018-2-05, and Medical Engineering Fund of Fudan University, grant No. yg2021-38.",Journal of Cardiovascular Development and Disease,,,2023-01-30,2023,2023-01-30,,10,2,56,All OA; Gold,Article,"Zang, Lianru; Gu, Kaihao; Ji, Xingkai; Zhang, Hao; Yan, Shengjie; Wu, Xiaomei","Zang, Lianru (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Gu, Kaihao (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Ji, Xingkai (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Zhang, Hao (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Yan, Shengjie (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Wu, Xiaomei (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.; Academy for Engineering and Technology, Fudan University, Shanghai 200433, China.; Key Laboratory of Medical Imaging Computing and Computer-Assisted Intervention (MICCAI) of Shanghai, Fudan University, Shanghai 200032, China.; Shanghai Engineering Research Center of Assistive Devices, Shanghai 200093, China.; Yiwu Research Institute, Fudan University, Yiwu 322000, China.)","Yan, Shengjie (Fudan University); Wu, Xiaomei (Fudan University; Fudan University; ; University of Shanghai for Science and Technology; Fudan University)","Zang, Lianru (Fudan University); Gu, Kaihao (Fudan University); Ji, Xingkai (Fudan University); Zhang, Hao (Fudan University); Yan, Shengjie (Fudan University); Wu, Xiaomei (Fudan University; Fudan University; University of Shanghai for Science and Technology; Fudan University)",0,0,,,https://www.mdpi.com/2308-3425/10/2/56/pdf?version=1675092705,https://app.dimensions.ai/details/publication/pub.1154982170,32 Biomedical and Clinical Sciences; 3201 Cardiovascular Medicine and Haematology,
5596,pub.1151244434,10.3390/jcdd9100319,36286271,PMC9604654,Effect of Anisotropic Electrical Conductivity Induced by Fiber Orientation on Ablation Characteristics of Pulsed Field Ablation in Atrial Fibrillation Treatment: A Computational Study,"Pulsed field ablation (PFA) is a promising new ablation modality for the treatment of atrial fibrillation (AF); however, the effect of fiber orientation on the ablation characteristics of PFA in AF treatment is still unclear, which is likely an essential factor in influencing the ablation characteristics. This study constructed an anatomy-based left atrium (LA) model incorporating fiber orientation and selected various electrical conductivity and ablation targets to investigate the effect of anisotropic electrical conductivity (AC), compared with isotropic electrical conductivity (IC), on the ablation characteristics of PFA in AF treatment. The results show that the percentage differences in the size of the surface ablation area between AC and IC are greater than 73.71%; the maximum difference in the size of the ablation isosurface between AC and IC at different locations in the atrial wall is 3.65 mm (X-axis), 3.65 mm (Z-axis), and 4.03 mm (X-axis), respectively; and the percentage differences in the size of the ablation volume are greater than 6.9%. Under the condition of the pulse, the amplitude is 1000 V, the total PFA duration is 1 s, and the pulse train interval is 198.4 ms; the differences in the temperature increase between AC and IC in LA are less than 2.46 Â°C. Hence, this study suggests that in further exploration of the computational study of PFA in AF treatment using the same or similar conditions as those used here (myocardial electrical conductivity, pulse parameters, and electric field intensity damage threshold), to obtain more accurate computational results, it is necessary to adopt AC rather than IC to investigate the size of the surface ablation area, the size of the ablation isosurface, or the size of the ablation volume generated by PFA in LA. Moreover, if only investigating the temperature increase generated by PFA in LA, adopting IC instead of AC for simplifying the model construction process is reasonable.",The author would like to express his sincere gratitude to Wachter for the email guidance on adding the âdata arrayâ to the LA model.,"This study received financial support from the National Key Research and Development Program, grant no.2021YFC2400203; Shanghai Municipal Commission of Economy and Information Technology, grant no.GYQJ-2018-2-05; and Medical Engineering Fund of Fudan University, grant no.yg2021-38.",Journal of Cardiovascular Development and Disease,,,2022-09-22,2022,2022-09-22,,9,10,319,All OA; Gold,Article,"Zang, Lianru; Gu, Kaihao; Ji, Xingkai; Zhang, Hao; Yan, Shengjie; Wu, Xiaomei","Zang, Lianru (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Gu, Kaihao (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Ji, Xingkai (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Zhang, Hao (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Yan, Shengjie (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.); Wu, Xiaomei (Center for Biomedical Engineering, School of Information Science and Technology, Fudan University, Shanghai 200438, China.; Academy for Engineering and Technology, Fudan University, Shanghai 200433, China.; Key Laboratory of Medical Imaging Computing and Computer-Assisted Intervention (MICCAI) of Shanghai, Fudan University, Shanghai 200032, China.; Shanghai Engineering Research Center of Assistive Devices, Shanghai 200093, China.; Yiwu Research Institute, Fudan University, Yiwu 322000, China.)","Yan, Shengjie (Fudan University); Wu, Xiaomei (Fudan University; Fudan University; ; University of Shanghai for Science and Technology; Fudan University)","Zang, Lianru (Fudan University); Gu, Kaihao (Fudan University); Ji, Xingkai (Fudan University); Zhang, Hao (Fudan University); Yan, Shengjie (Fudan University); Wu, Xiaomei (Fudan University; Fudan University; University of Shanghai for Science and Technology; Fudan University)",1,1,,,https://www.mdpi.com/2308-3425/9/10/319/pdf?version=1663932218,https://app.dimensions.ai/details/publication/pub.1151244434,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,
5585,pub.1139873734,10.3390/ijms22147681,34299303,PMC8307824,Understanding PITX2-Dependent Atrial Fibrillation Mechanisms through Computational Models,"Atrial fibrillation (AF) is a common arrhythmia. Better prevention and treatment of AF are needed to reduce AF-associated morbidity and mortality. Several major mechanisms cause AF in patients, including genetic predispositions to AF development. Genome-wide association studies have identified a number of genetic variants in association with AF populations, with the strongest hits clustering on chromosome 4q25, close to the gene for the homeobox transcription PITX2. Because of the inherent complexity of the human heart, experimental and basic research is insufficient for understanding the functional impacts of PITX2 variants on AF. Linking PITX2 properties to ion channels, cells, tissues, atriums and the whole heart, computational models provide a supplementary tool for achieving a quantitative understanding of the functional role of PITX2 in remodelling atrial structure and function to predispose to AF. It is hoped that computational approaches incorporating all we know about PITX2-related structural and electrical remodelling would provide better understanding into its proarrhythmic effects leading to development of improved anti-AF therapies. In the present review, we discuss advances in atrial modelling and focus on the mechanistic links between PITX2 and AF. Challenges in applying models for improving patient health are described, as well as a summary of future perspectives.",,"This research was funded by National Key Research and Development Project, grant number 2019YFC0120100 (H.W., J.B. and Y.L.) and 2019YFC0121907 (J.B. and Y.L.) and the National Natural Science Foundation of China, grant number 61901192 (J.B.).",International Journal of Molecular Sciences,,"Animals; Atrial Fibrillation; Atrial Remodeling; Body Patterning; Computer Simulation; Genes, Homeobox; Genetic Predisposition to Disease; Genetic Variation; Genome-Wide Association Study; Heart; Homeodomain Proteins; Humans; Ion Channels; MicroRNAs; Models, Cardiovascular; Mutation; Transcription Factors",2021-07-19,2021,2021-07-19,,22,14,7681,All OA; Gold,Article,"Bai, Jieyun; Lu, Yaosheng; Zhu, Yijie; Wang, Huijin; Yin, Dechun; Zhang, Henggui; Franco, Diego; Zhao, Jichao","Bai, Jieyun (College of Information Science and Technology, Jinan University, Guangzhou 510632, China;, tluys@jnu.edu.cn, (Y.L.);, zyj1934261010@stu2019.jnu.edu.cn, (Y.Z.); Auckland Bioengineering Institute, University of Auckland, Auckland 1010, New Zealand); Lu, Yaosheng (College of Information Science and Technology, Jinan University, Guangzhou 510632, China;, tluys@jnu.edu.cn, (Y.L.);, zyj1934261010@stu2019.jnu.edu.cn, (Y.Z.)); Zhu, Yijie (College of Information Science and Technology, Jinan University, Guangzhou 510632, China;, tluys@jnu.edu.cn, (Y.L.);, zyj1934261010@stu2019.jnu.edu.cn, (Y.Z.)); Wang, Huijin (College of Information Science and Technology, Jinan University, Guangzhou 510632, China;, tluys@jnu.edu.cn, (Y.L.);, zyj1934261010@stu2019.jnu.edu.cn, (Y.Z.)); Yin, Dechun (Department of Cardiology, First Affiliated Hospital of Harbin Medical University, Harbin 150000, China;, yindechun0429@163.com); Zhang, Henggui (Biological Physics Group, School of Physics & Astronomy, The University of Manchester, Manchester M13 9PL, UK;, henggui.zhang@manchester.ac.uk); Franco, Diego (Department of Experimental Biology, University of Jaen, 23071 Jaen, Spain;, dfranco@ujaen.es); Zhao, Jichao (Auckland Bioengineering Institute, University of Auckland, Auckland 1010, New Zealand)","Bai, Jieyun (Jinan University; ; University of Auckland); Wang, Huijin (Jinan University; ); Zhao, Jichao (University of Auckland)","Bai, Jieyun (Jinan University; University of Auckland); Lu, Yaosheng (Jinan University); Zhu, Yijie (Jinan University); Wang, Huijin (Jinan University); Yin, Dechun (First Affiliated Hospital of Harbin Medical University); Zhang, Henggui (University of Manchester); Franco, Diego (University of JaÃ©n); Zhao, Jichao (University of Auckland)",2,2,0.43,1.03,https://www.mdpi.com/1422-0067/22/14/7681/pdf?version=1626679225,https://app.dimensions.ai/details/publication/pub.1139873734,31 Biological Sciences; 3105 Genetics,3 Good Health and Well Being
3787,pub.1145093048,10.1016/j.media.2022.102360,35124370,PMC7614005,Medical image analysis on left atrial LGE MRI for atrial fibrillation studies: A review,"Late gadolinium enhancement magnetic resonance imaging (LGE MRI) is commonly used to visualize and quantify left atrial (LA) scars. The position and extent of LA scars provide important information on the pathophysiology and progression of atrial fibrillation (AF). Hence, LA LGE MRI computing and analysis are essential for computer-assisted diagnosis and treatment stratification of AF patients. Since manual delineations can be time-consuming and subject to intra- and inter-expert variability, automating this computing is highly desired, which nevertheless is still challenging and under-researched. This paper aims to provide a systematic review on computing methods for LA cavity, wall, scar, and ablation gap segmentation and quantification from LGE MRI, and the related literature for AF studies. Specifically, we first summarize AF-related imaging techniques, particularly LGE MRI. Then, we review the methodologies of the four computing tasks in detail and summarize the validation strategies applied in each task as well as state-of-the-art results on public datasets. Finally, the possible future developments are outlined, with a brief survey on the potential clinical applications of the aforementioned methods. The review indicates that the research into this topic is still in the early stages. Although several methods have been proposed, especially for the LA cavity segmentation, there is still a large scope for further algorithmic developments due to performance issues related to the high variability of enhancement appearance and differences in image acquisition.","This work was supported by the National Natural Science Foundation of China (61971142, 62111530195 and 62011540404) and the development fund for Shanghai talents (2020015). L Li was partially supported by the CSC Scholarship. JA Schnabel and VA Zimmer would like to acknowledge funding from a Wellcome Trust IEH Award (WT 102431), an EPSRC programme grant (EP/P001009/1), and the Wellcome/EPSRC Center for Medical Engineering (WT 203148/Z/16/Z). XH Zhuang and JA Schnabel would also like to acknowledge funding from the Royal Society Sino-British Fellowship Trust International Exchanges Award.",,Medical Image Analysis,,Atrial Fibrillation; Cicatrix; Contrast Media; Gadolinium; Heart Atria; Humans; Magnetic Resonance Imaging,2022-01-29,2022,2022-01-29,2022-04,77,,102360,All OA; Green,Article,"Li, Lei; Zimmer, Veronika A.; Schnabel, Julia A.; Zhuang, Xiahai","Li, Lei (School of Data Science, Fudan University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering and Imaging Sciences, Kingâs College London, London, UK); Zimmer, Veronika A. (School of Biomedical Engineering and Imaging Sciences, Kingâs College London, London, UK; Department of Informatics, Technical University of Munich, Germany); Schnabel, Julia A. (School of Biomedical Engineering and Imaging Sciences, Kingâs College London, London, UK; Department of Informatics, Technical University of Munich, Germany; Helmholtz Center Munich, Germany); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China)","Zhuang, Xiahai (Fudan University)","Li, Lei (Fudan University; Shanghai Jiao Tong University; King's College London); Zimmer, Veronika A. (King's College London; Technical University of Munich); Schnabel, Julia A. (King's College London; Technical University of Munich; Helmholtz Zentrum MÃ¼nchen); Zhuang, Xiahai (Fudan University)",4,4,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7614005,https://app.dimensions.ai/details/publication/pub.1145093048,40 Engineering; 4003 Biomedical Engineering,
2390,pub.1144683786,10.1007/978-3-030-93722-5_38,,,3D Right Ventricle Reconstruction from 2D U-Net Segmentation of Sparse Short-Axis and 4-Chamber Cardiac Cine MRI Views,"We reconstruct a 3D model of the right ventricle from short- and long-axis image data and evaluate the benefits compared to quantification based on the 2D image stack. Deep learning is used to extract short-axis contours. An initial surface representation based on the contours is refined using long-axis images. Using a deformable model, the surface around the basal plane is adapted to image data. The resulting models capture the shape of the right ventricle better than segmentation from short-axis images alone and allow for a more precise volumetry.",,,Lecture Notes in Computer Science,"Statistical Atlases and Computational Models of the Heart. Multi-Disease, Multi-View, and Multi-Center Right Ventricular Segmentation in Cardiac MRI Challenge",,2022-01-14,2022,2022-01-14,2022,13131,,352-359,Closed,Chapter,"Tautz, Lennart; Walczak, Lars; Manini, Chiara; Hennemuth, Anja; HÃ¼llebrand, Markus","Tautz, Lennart (CharitÃ© â UniversitÃ¤tsmedizin Berlin, Berlin, Germany; Fraunhofer MEVIS, Bremen, Germany); Walczak, Lars (CharitÃ© â UniversitÃ¤tsmedizin Berlin, Berlin, Germany; Fraunhofer MEVIS, Bremen, Germany); Manini, Chiara (CharitÃ© â UniversitÃ¤tsmedizin Berlin, Berlin, Germany); Hennemuth, Anja (CharitÃ© â UniversitÃ¤tsmedizin Berlin, Berlin, Germany; Fraunhofer MEVIS, Bremen, Germany); HÃ¼llebrand, Markus (CharitÃ© â UniversitÃ¤tsmedizin Berlin, Berlin, Germany; Fraunhofer MEVIS, Bremen, Germany)","Tautz, Lennart (CharitÃ© - University Medicine Berlin; Fraunhofer Institute for Digital Medicine)","Tautz, Lennart (CharitÃ© - University Medicine Berlin; Fraunhofer Institute for Digital Medicine); Walczak, Lars (CharitÃ© - University Medicine Berlin; Fraunhofer Institute for Digital Medicine); Manini, Chiara (CharitÃ© - University Medicine Berlin); Hennemuth, Anja (CharitÃ© - University Medicine Berlin; Fraunhofer Institute for Digital Medicine); HÃ¼llebrand, Markus (CharitÃ© - University Medicine Berlin; Fraunhofer Institute for Digital Medicine)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1144683786,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",
2390,pub.1134406127,10.22489/cinc.2020.306,,,Performance Comparison of Deep Learning Approaches for Left Atrium Segmentation From LGE-MRI Data,"Quantification of viable left atrial (LA) tissue is a reliable information which should be used to support therapy selection in atrial fibrillation (AF) patients. Late gadolinium-enhanced magnetic resonance imaging (LGE-MRI) is employed for the non-invasive assessment of LA fibrotic tissue. Unfortunately, the analysis of LGE-MRI relies on manual tracing of LA boundaries. This task is time-consuming and prone to high inter-observer variability. Therefore, an automatic approach for LA wall detection would be very helpful. In this study, we compared the performance of different deep architectures - U-Net and attention U-Net (AttnU-Net) - and different loss functions - Dice loss (DL) and focal Tversky loss (FTL) to automatically detect LA boundaries from LGE-MRI data. In addition, AttnU-Net was trained without deep supervision (DS) and multi-scale inputs (MI), with DS and with DS+MI. No statistically significant differences were found training the networks with DL or FTL. U-Net was the best-performing algorithm overall, outperforming significantly AttnU-Net with a Dice Coefficient of 0.9015Â±0.0308 (mean Â± standard deviation). However, no significant differences were found between U-Net and AttnU-Net DS/DS+MI. Based on these results, using a DL or FTL does not affect the performance and U-Net was the best-performing solution.",,,2016 Computing in Cardiology Conference (CinC),2020 Computing in Cardiology Conference (CinC),,2020-01-16,2020,2020-12-30,2020-01-16,00,,1-4,All OA; Bronze,Proceeding,"Borra, Davide; Portas, Daniela; AndalÃ³, Alice; Fabbri, Claudio; Corsi, Cristiana","Borra, Davide (DEI, Campus of Cesena, University of Bologna, Cesena, Italy); Portas, Daniela (DEI, Campus of Cesena, University of Bologna, Cesena, Italy); AndalÃ³, Alice (DEI, Campus of Cesena, University of Bologna, Cesena, Italy); Fabbri, Claudio (DEI, Campus of Cesena, University of Bologna, Cesena, Italy); Corsi, Cristiana (DEI, Campus of Cesena, University of Bologna, Cesena, Italy)","Borra, Davide (University of Bologna)","Borra, Davide (University of Bologna); Portas, Daniela (University of Bologna); AndalÃ³, Alice (University of Bologna); Fabbri, Claudio (University of Bologna); Corsi, Cristiana (University of Bologna)",1,1,,0.24,https://doi.org/10.22489/cinc.2020.306,https://app.dimensions.ai/details/publication/pub.1134406127,40 Engineering; 4003 Biomedical Engineering,
2239,pub.1138299548,10.48550/arxiv.2105.10369,,,Hierarchical Consistency Regularized Mean Teacher for Semi-supervised 3D  Left Atrium Segmentation,"Deep learning has achieved promising segmentation performance on 3D left
atrium MR images. However, annotations for segmentation tasks are expensive,
costly and difficult to obtain. In this paper, we introduce a novel
hierarchical consistency regularized mean teacher framework for 3D left atrium
segmentation. In each iteration, the student model is optimized by multi-scale
deep supervision and hierarchical consistency regularization, concurrently.
Extensive experiments have shown that our method achieves competitive
performance as compared with full annotation, outperforming other
state-of-the-art semi-supervised segmentation methods.",,,arXiv,,,2021-05-21,2021,,,,,,All OA; Green,Preprint,"Li, Shumeng; Zhao, Ziyuan; Xu, Kaixin; Zeng, Zeng; Guan, Cuntai","Li, Shumeng (); Zhao, Ziyuan (); Xu, Kaixin (); Zeng, Zeng (); Guan, Cuntai ()",,"Li, Shumeng (); Zhao, Ziyuan (); Xu, Kaixin (); Zeng, Zeng (); Guan, Cuntai ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138299548,46 Information and Computing Sciences; 4611 Machine Learning,
2197,pub.1138948226,10.48550/arxiv.2106.08727,,,AtrialGeneral: Domain Generalization for Left Atrial Segmentation of  Multi-Center LGE MRIs,"Left atrial (LA) segmentation from late gadolinium enhanced magnetic
resonance imaging (LGE MRI) is a crucial step needed for planning the treatment
of atrial fibrillation. However, automatic LA segmentation from LGE MRI is
still challenging, due to the poor image quality, high variability in LA
shapes, and unclear LA boundary. Though deep learning-based methods can provide
promising LA segmentation results, they often generalize poorly to unseen
domains, such as data from different scanners and/or sites. In this work, we
collect 210 LGE MRIs from different centers with different levels of image
quality. To evaluate the domain generalization ability of models on the LA
segmentation task, we employ four commonly used semantic segmentation networks
for the LA segmentation from multi-center LGE MRIs. Besides, we investigate
three domain generalization strategies, i.e., histogram matching, mutual
information based disentangled representation, and random style transfer, where
a simple histogram matching is proved to be most effective.",,,arXiv,,,2021-06-16,2021,,,,,,All OA; Green,Preprint,"Li, Lei; Zimmer, Veronika A.; Schnabel, Julia A.; Zhuang, Xiahai","Li, Lei (); Zimmer, Veronika A. (); Schnabel, Julia A. (); Zhuang, Xiahai ()",,"Li, Lei (); Zimmer, Veronika A. (); Schnabel, Julia A. (); Zhuang, Xiahai ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138948226,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 46 Information and Computing Sciences,
2187,pub.1141302120,10.1007/978-3-030-87231-1_54,,,AtrialGeneral: Domain Generalization for Left Atrial Segmentation of Multi-center LGE MRIs,"Left atrial (LA) segmentation from late gadolinium enhanced magnetic resonance imaging (LGE MRI) is a crucial step needed for planning the treatment of atrial fibrillation. However, automatic LA segmentation from LGE MRI is still challenging, due to the poor image quality, high variability in LA shapes, and unclear LA boundary. Though deep learning-based methods can provide promising LA segmentation results, they often generalize poorly to unseen domains, such as data from different scanners and/or sites. In this work, we collect 140 LGE MRIs from different centers with different levels of image quality. To evaluate the domain generalization ability of models on the LA segmentation task, we employ four commonly used semantic segmentation networks for the LA segmentation from multi-center LGE MRIs. Besides, we investigate three domain generalization strategies, i.e., histogram matching, mutual information based disentangled representation, and random style transfer, where a simple histogram matching is proved to be most effective.","This work was funded by the National Natural Science Foundation of China (grant no. 61971142, 62111530195 and 62011540404) and the development fund for Shanghai talents (no. 2020015). L. Li was partially supported by the CSC Scholarship. JA Schnabel and VA Zimmer would like to acknowledge funding from a Wellcome Trust IEH Award (WT 102431), an EPSRC programme grant (EP/P001009/1), and the Wellcome/EPSRC Center for Medical Engineering (WT 203148/Z/16/Z).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention â MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12906,,557-566,All OA; Green,Chapter,"Li, Lei; Zimmer, Veronika A.; Schnabel, Julia A.; Zhuang, Xiahai","Li, Lei (School of Data Science, Fudan University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering and Imaging Sciences, Kingâs College London, London, UK); Zimmer, Veronika A. (School of Biomedical Engineering and Imaging Sciences, Kingâs College London, London, UK); Schnabel, Julia A. (School of Biomedical Engineering and Imaging Sciences, Kingâs College London, London, UK); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China)","Zhuang, Xiahai (Fudan University)","Li, Lei (Fudan University; Shanghai Jiao Tong University; King's College London); Zimmer, Veronika A. (King's College London); Schnabel, Julia A. (King's College London); Zhuang, Xiahai (Fudan University)",4,4,,,http://arxiv.org/pdf/2106.08727,https://app.dimensions.ai/details/publication/pub.1141302120,46 Information and Computing Sciences,
2146,pub.1141326761,10.1007/978-3-030-87196-3_33,,,Reciprocal Learning for Semi-supervised Segmentation,"Semi-supervised learning has been recently employed to solve problems from medical image segmentation due to challenges in acquiring sufficient manual annotations, which is an important prerequisite for building high-performance deep learning methods. Since unlabeled data is generally abundant, most existing semi-supervised approaches focus on how to make full use of both limited labeled data and abundant unlabeled data. In this paper, we propose a novel semi-supervised strategy called reciprocal learning for medical image segmentation, which can be easily integrated into any CNN architecture. Concretely, the reciprocal learning works by having a pair of networks, one as a student and one as a teacher. The student model learns from pseudo label generated by the teacher. Furthermore, the teacher updates its parameters autonomously according to the reciprocal feedback signal of how well student performs on the labeled set. Extensive experiments on two public datasets show that our method outperforms current state-of-the-art semi-supervised segmentation methods, demonstrating the potential of our strategy for the challenging semi-supervised problems.Â The code is publicly available atÂ https://github.com/XYZach/RLSSS.","This work was supported in part by the National Key R&amp;D Program of China (No. 2019YFC0118300), in part by the National Natural Science Foundation of China under Grants 62071305, 61701312 and 81971631, in part by the Guangdong Basic and Applied Basic Research Foundation (2019A1515010847), in part by the Medical Science and Technology Foundation of Guangdong Province (B2019046), in part by the Natural Science Foundation of Shenzhen University (No. 860-000002110129), and in part by the Shenzhen Peacock Plan (No. KQTD2016053112051497).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention â MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12902,,352-361,Closed,Chapter,"Zeng, Xiangyun; Huang, Rian; Zhong, Yuming; Sun, Dong; Han, Chu; Lin, Di; Ni, Dong; Wang, Yi","Zeng, Xiangyun (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Medical UltraSound Image Computing (MUSIC) Lab, Shenzhen University, Shenzhen, China; Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China); Huang, Rian (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Medical UltraSound Image Computing (MUSIC) Lab, Shenzhen University, Shenzhen, China; Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China); Zhong, Yuming (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Medical UltraSound Image Computing (MUSIC) Lab, Shenzhen University, Shenzhen, China; Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China); Sun, Dong (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Medical UltraSound Image Computing (MUSIC) Lab, Shenzhen University, Shenzhen, China; Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China); Han, Chu (Department of Radiology, Guangdong Provincial Peopleâs Hospital, Guangdong Academy of Medical Sciences, Guangzhou, Guangdong, China); Lin, Di (College of Intelligence and Computing, Tianjin University, Tianjin, China); Ni, Dong (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Medical UltraSound Image Computing (MUSIC) Lab, Shenzhen University, Shenzhen, China; Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China); Wang, Yi (National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Medical UltraSound Image Computing (MUSIC) Lab, Shenzhen University, Shenzhen, China; Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China)","Wang, Yi (Shenzhen University; Shenzhen University; Shenzhen University)","Zeng, Xiangyun (Shenzhen University; Shenzhen University; Shenzhen University); Huang, Rian (Shenzhen University; Shenzhen University; Shenzhen University); Zhong, Yuming (Shenzhen University; Shenzhen University; Shenzhen University); Sun, Dong (Shenzhen University; Shenzhen University; Shenzhen University); Han, Chu (); Lin, Di (Tianjin University); Ni, Dong (Shenzhen University; Shenzhen University; Shenzhen University); Wang, Yi (Shenzhen University; Shenzhen University; Shenzhen University)",5,5,,4.09,,https://app.dimensions.ai/details/publication/pub.1141326761,46 Information and Computing Sciences; 4611 Machine Learning,
2146,pub.1139220044,10.48550/arxiv.2106.14178,,,Residual Moment Loss for Medical Image Segmentation,"Location information is proven to benefit the deep learning models on
capturing the manifold structure of target objects, and accordingly boosts the
accuracy of medical image segmentation. However, most existing methods encode
the location information in an implicit way, e.g. the distance transform maps,
which describe the relative distance from each pixel to the contour boundary,
for the network to learn. These implicit approaches do not fully exploit the
position information (i.e. absolute location) of targets. In this paper, we
propose a novel loss function, namely residual moment (RM) loss, to explicitly
embed the location information of segmentation targets during the training of
deep learning networks. Particularly, motivated by image moments, the
segmentation prediction map and ground-truth map are weighted by coordinate
information. Then our RM loss encourages the networks to maintain the
consistency between the two weighted maps, which promotes the segmentation
networks to easily locate the targets and extract manifold-structure-related
features. We validate the proposed RM loss by conducting extensive experiments
on two publicly available datasets, i.e., 2D optic cup and disk segmentation
and 3D left atrial segmentation. The experimental results demonstrate the
effectiveness of our RM loss, which significantly boosts the accuracy of
segmentation networks.",,,arXiv,,,2021-06-27,2021,,,,,,All OA; Green,Preprint,"Wang, Quanziang; Wang, Renzhen; Li, Yuexiang; Ma, Kai; Zheng, Yefeng; Meng, Deyu","Wang, Quanziang (); Wang, Renzhen (); Li, Yuexiang (); Ma, Kai (); Zheng, Yefeng (); Meng, Deyu ()",,"Wang, Quanziang (); Wang, Renzhen (); Li, Yuexiang (); Ma, Kai (); Zheng, Yefeng (); Meng, Deyu ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139220044,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4605 Data Management and Data Science; 4611 Machine Learning,
2145,pub.1151033012,10.1007/978-3-031-16443-9_4,,,Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation,"Semi-supervised segmentation remains challenging in medical imaging since the amount of annotated medical data is often scarce and there are many blurred pixels near the adhesive edges or in the low-contrast regions. To address the issues, we advocate to firstly constrain the consistency of pixels with and without strong perturbations to apply a sufficient smoothness constraint and further encourage the class-level separation to exploit the low-entropy regularization for the model training. Particularly, in this paper, we propose the SS-Net for semi-supervised medical image segmentation tasks, via exploring the pixel-level Smoothness and inter-class Separation at the same time. The pixel-level smoothness forces the model to generate invariant results under adversarial perturbations. Meanwhile, the inter-class separation encourages individual class features should approach their corresponding high-quality prototypes, in order to make each class distribution compact and separate different classes. We evaluated our SS-Net against five recent methods on the public LA and ACDC datasets. Extensive experimental results under two semi-supervised settings demonstrate the superiority of our proposed SS-Net model, achieving new state-of-the-art (SOTA) performance on both datasets. The code is available at https://github.com/ycwu1997/SS-Net.","This work was supported by Monash FIT Start-up Grant. We also appreciate the efforts to collect and share the LA and ACDC datasets [2, 26] and several public repositories [7, 10, 11, 21, 28].",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention â MICCAI 2022,,2022-09-16,2022,2022-09-16,2022,13435,,34-43,All OA; Green,Chapter,"Wu, Yicheng; Wu, Zhonghua; Wu, Qianyi; Ge, Zongyuan; Cai, Jianfei","Wu, Yicheng (Department of Data Science & AI, Faculty of Information Technology, Monash University, 3800, Melbourne, VIC, Australia); Wu, Zhonghua (School of Computer Science and Engineering, Nanyang Technological University, 639798, Singapore, Singapore); Wu, Qianyi (Department of Data Science & AI, Faculty of Information Technology, Monash University, 3800, Melbourne, VIC, Australia); Ge, Zongyuan (Monash-Airdoc Research, Monash University, 3800, Melbourne, VIC, Australia; Monash Medical AI, Monash eResearch Centre, 3800, Melbourne, VIC, Australia); Cai, Jianfei (Department of Data Science & AI, Faculty of Information Technology, Monash University, 3800, Melbourne, VIC, Australia)","Wu, Yicheng (Monash University)","Wu, Yicheng (Monash University); Wu, Zhonghua (Nanyang Technological University); Wu, Qianyi (Monash University); Ge, Zongyuan (Monash University); Cai, Jianfei (Monash University)",2,2,,,http://arxiv.org/pdf/2203.01324,https://app.dimensions.ai/details/publication/pub.1151033012,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
2145,pub.1141326755,10.1007/978-3-030-87196-3_28,,,Semi-supervised Left Atrium Segmentation with Mutual Consistency Training,"Semi-supervised learning has attracted great attention in the field of machine learning, especially for medical image segmentation tasks, since it alleviates the heavy burden of collecting abundant densely annotated data for training. However, most of existing methods underestimate the importance of challenging regions (e.g. small branches or blurred edges) during training. We believe that these unlabeled regions may contain more crucial information to minimize the uncertainty prediction for the model and should be emphasized in the training process. Therefore, in this paper, we propose a novel Mutual Consistency Network (MC-Net) for semi-supervised left atrium segmentation from 3D MR images. Particularly, our MC-Net consists of one encoder and two slightly different decoders, and the prediction discrepancies of two decoders are transformed as an unsupervised loss by our designed cycled pseudo label scheme to encourage mutual consistency. Such mutual consistency encourages the two decoders to have consistent and low-entropy predictions and enables the model to gradually capture generalized features from these unlabeled challenging regions. We evaluate our MC-Net on the public Left Atrium (LA) database and it obtains impressive performance gains by exploiting the unlabeled data effectively. Our MC-Net outperforms six recent semi-supervised methods for left atrium segmentation, and sets the new state-of-the-art performance on the LA database.","This work was done during an internship at Alibaba Group and was partially supported by Monash FIT Start-up Grant. We also appreciate the efforts devoted to collect and share the LA database [16] and several available repositories [6, 7, 17].",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention â MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12902,,297-306,All OA; Green,Chapter,"Wu, Yicheng; Xu, Minfeng; Ge, Zongyuan; Cai, Jianfei; Zhang, Lei","Wu, Yicheng (DAMO Academy, Alibaba Group, 311121, Hangzhou, China; Department of Data Science and AI, Faculty of Information Technology, Monash University, 3800, Melbourne, VIC, Australia); Xu, Minfeng (DAMO Academy, Alibaba Group, 311121, Hangzhou, China); Ge, Zongyuan (Monash-Airdoc Research, Monash University, 3800, Melbourne, VIC, Australia; Monash Medical AI, Monash eResearch Centre, 3800, Melbourne, VIC, Australia); Cai, Jianfei (Department of Data Science and AI, Faculty of Information Technology, Monash University, 3800, Melbourne, VIC, Australia); Zhang, Lei (DAMO Academy, Alibaba Group, 311121, Hangzhou, China)","Cai, Jianfei (Monash University)","Wu, Yicheng (Alibaba Group (China); Monash University); Xu, Minfeng (Alibaba Group (China)); Ge, Zongyuan (Monash University); Cai, Jianfei (Monash University); Zhang, Lei (Alibaba Group (China))",34,34,,27.83,http://arxiv.org/pdf/2103.02911,https://app.dimensions.ai/details/publication/pub.1141326755,46 Information and Computing Sciences; 4611 Machine Learning,
2142,pub.1153642093,10.1007/978-3-031-21014-3_15,,,Cross Task Temporal Consistency for Semi-supervised Medical Image Segmentation,"Semi-supervised deep learning for medical image segmentation is an intriguing area of research as far as the requirement for an adequate amount of labeled data is concerned. In this context, we propose Cross Task Temporal Consistency, a novel Semi-Supervised Learning framework that combines a self-ensembled learning strategy with cross-consistency constraints derived from the implicit perturbations between the incongruous tasks of multi-headed architectures. More specifically, the Signed Distance Map output of a teacher model is transformed to an approximate segmentation map which acts as a pseudo target for the student model. Simultaneously, the teacherâs segmentation task output is utilized as the objective for the studentâs Signed Distance Map derived segmentation output. Our proposed framework is intuitively simple and can be plugged into existing segmentation architectures with minimal computational overhead. Our work focuses on improving the segmentation performance in very low-labeled data proportions and has demonstrated marked superiority in performance and stability over existing SSL techniques, as evidenced through extensive evaluations on two standard datasets: ACDC and LA.",,,Lecture Notes in Computer Science,Machine Learning in Medical Imaging,,2022-12-16,2022,2022-12-16,2022,13583,,140-150,Closed,Chapter,"Jeevan, Govind; Pawan, S. J.; Rajan, Jeny","Jeevan, Govind (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangaluru, India); Pawan, S. J. (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangaluru, India); Rajan, Jeny (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangaluru, India)","Pawan, S. J. (National Institute of Technology Karnataka)","Jeevan, Govind (National Institute of Technology Karnataka); Pawan, S. J. (National Institute of Technology Karnataka); Rajan, Jeny (National Institute of Technology Karnataka)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153642093,46 Information and Computing Sciences; 4611 Machine Learning,
2066,pub.1148651738,10.48550/arxiv.2206.05284,,,Decoupling Predictions in Distributed Learning for Multi-Center Left  Atrial MRI Segmentation,"Distributed learning has shown great potential in medical image analysis. It
allows to use multi-center training data with privacy protection. However, data
distributions in local centers can vary from each other due to different
imaging vendors, and annotation protocols. Such variation degrades the
performance of learning-based methods. To mitigate the influence, two groups of
methods have been proposed for different aims, i.e., the global methods and the
personalized methods. The former are aimed to improve the performance of a
single global model for all test data from unseen centers (known as generic
data); while the latter target multiple models for each center (denoted as
local data). However, little has been researched to achieve both goals
simultaneously. In this work, we propose a new framework of distributed
learning that bridges the gap between two groups, and improves the performance
for both generic and local data. Specifically, our method decouples the
predictions for generic data and local data, via distribution-conditioned
adaptation matrices. Results on multi-center left atrial (LA) MRI segmentation
showed that our method demonstrated superior performance over existing methods
on both generic and local data. Our code is available at
https://github.com/key1589745/decouple_predict",,,arXiv,,,2022-06-10,2022,,,,,,All OA; Green,Preprint,"Gao, Zheyao; Li, Lei; Wu, Fuping; Wang, Sihan; Zhuang, Xiahai","Gao, Zheyao (); Li, Lei (); Wu, Fuping (); Wang, Sihan (); Zhuang, Xiahai ()",,"Gao, Zheyao (); Li, Lei (); Wu, Fuping (); Wang, Sihan (); Zhuang, Xiahai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148651738,46 Information and Computing Sciences; 4611 Machine Learning,
2066,pub.1147730336,10.48550/arxiv.2205.02847,,,Segmentation with Super Images: A New 2D Perspective on 3D Medical Image  Analysis,"Deep learning is showing an increasing number of audience in medical imaging
research. In the segmentation task of medical images, we oftentimes rely on
volumetric data, and thus require the use of 3D architectures which are praised
for their ability to capture more features from the depth dimension. Yet, these
architectures are generally more ineffective in time and compute compared to
their 2D counterpart on account of 3D convolutions, max pooling,
up-convolutions, and other operations used in these networks. Moreover, there
are limited to no 3D pretrained model weights, and pretraining is generally
challenging. To alleviate these issues, we propose to cast volumetric data to
2D super images and use 2D networks for the segmentation task. The method
processes the 3D image by stitching slices side-by-side to generate a super
resolution image. While the depth information is lost, we expect that deep
neural networks can still capture and learn these features. Our goal in this
work is to introduce a new perspective when dealing with volumetric data, and
test our hypothesis using vanilla networks. We hope that this approach, while
achieving close enough results to 3D networks using only 2D counterparts, can
attract more related research in the future, especially in medical image
analysis since volumetric data is comparably limited.",,,arXiv,,,2022-05-05,2022,,,,,,All OA; Green,Preprint,"Sobirov, Ikboljon; Saeed, Numan; Yaqub, Mohammad","Sobirov, Ikboljon (); Saeed, Numan (); Yaqub, Mohammad ()",,"Sobirov, Ikboljon (); Saeed, Numan (); Yaqub, Mohammad ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147730336,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games",
2066,pub.1146252408,10.48550/arxiv.2203.05682,,,Leveraging Labeling Representations in Uncertainty-based Semi-supervised  Segmentation,"Semi-supervised segmentation tackles the scarcity of annotations by
leveraging unlabeled data with a small amount of labeled data. A prominent way
to utilize the unlabeled data is by consistency training which commonly uses a
teacher-student network, where a teacher guides a student segmentation. The
predictions of unlabeled data are not reliable, therefore, uncertainty-aware
methods have been proposed to gradually learn from meaningful and reliable
predictions. Uncertainty estimation, however, relies on multiple inferences
from model predictions that need to be computed for each training step, which
is computationally expensive. This work proposes a novel method to estimate the
pixel-level uncertainty by leveraging the labeling representation of
segmentation masks. On the one hand, a labeling representation is learnt to
represent the available segmentation masks. The learnt labeling representation
is used to map the prediction of the segmentation into a set of plausible
masks. Such a reconstructed segmentation mask aids in estimating the
pixel-level uncertainty guiding the segmentation network. The proposed method
estimates the uncertainty with a single inference from the labeling
representation, thereby reducing the total computation. We evaluate our method
on the 3D segmentation of left atrium in MRI, and we show that our uncertainty
estimates from our labeling representation improve the segmentation accuracy
over state-of-the-art methods.",,,arXiv,,,2022-03-10,2022,,,,,,All OA; Green,Preprint,"Adiga, Sukesh; Dolz, Jose; Lombaert, Herve","Adiga, Sukesh (); Dolz, Jose (); Lombaert, Herve ()",,"Adiga, Sukesh (); Dolz, Jose (); Lombaert, Herve ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146252408,46 Information and Computing Sciences; 4611 Machine Learning,
2066,pub.1136235547,10.48550/arxiv.2103.04708,,,Dual-Task Mutual Learning for Semi-Supervised Medical Image Segmentation,"The success of deep learning methods in medical image segmentation tasks
usually requires a large amount of labeled data. However, obtaining reliable
annotations is expensive and time-consuming. Semi-supervised learning has
attracted much attention in medical image segmentation by taking the advantage
of unlabeled data which is much easier to acquire. In this paper, we propose a
novel dual-task mutual learning framework for semi-supervised medical image
segmentation. Our framework can be formulated as an integration of two
individual segmentation networks based on two tasks: learning region-based
shape constraint and learning boundary-based surface mismatch. Different from
the one-way transfer between teacher and student networks, an ensemble of
dual-task students can learn collaboratively and implicitly explore useful
knowledge from each other during the training process. By jointly learning the
segmentation probability maps and signed distance maps of targets, our
framework can enforce the geometric shape constraint and learn more reliable
information. Experimental results demonstrate that our method achieves
performance gains by leveraging unlabeled data and outperforms the
state-of-the-art semi-supervised segmentation methods.",,,arXiv,,,2021-03-08,2021,,,,,,All OA; Green,Preprint,"Zhang, Yichi; Zhang, Jicong","Zhang, Yichi (); Zhang, Jicong ()",,"Zhang, Yichi (); Zhang, Jicong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136235547,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
2066,pub.1136234878,10.48550/arxiv.2103.04020,,,NeRD: Neural Representation of Distribution for Medical Image  Segmentation,"We introduce Neural Representation of Distribution (NeRD) technique, a module
for convolutional neural networks (CNNs) that can estimate the feature
distribution by optimizing an underlying function mapping image coordinates to
the feature distribution. Using NeRD, we propose an end-to-end deep learning
model for medical image segmentation that can compensate the negative impact of
feature distribution shifting issue caused by commonly used network operations
such as padding and pooling. An implicit function is used to represent the
parameter space of the feature distribution by querying the image coordinate.
With NeRD, the impact of issues such as over-segmenting and missing have been
reduced, and experimental results on the challenging white matter lesion
segmentation and left atrial segmentation verify the effectiveness of the
proposed method. The code is available via https://github.com/tinymilky/NeRD.",,,arXiv,,,2021-03-05,2021,,,,,,All OA; Green,Preprint,"Zhang, Hang; Wang, Rongguang; Zhang, Jinwei; Li, Chao; Yang, Gufeng; Spincemaille, Pascal; Nguyen, Thanh; Wang, Yi","Zhang, Hang (); Wang, Rongguang (); Zhang, Jinwei (); Li, Chao (); Yang, Gufeng (); Spincemaille, Pascal (); Nguyen, Thanh (); Wang, Yi ()",,"Zhang, Hang (); Wang, Rongguang (); Zhang, Jinwei (); Li, Chao (); Yang, Gufeng (); Spincemaille, Pascal (); Nguyen, Thanh (); Wang, Yi ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136234878,46 Information and Computing Sciences; 4611 Machine Learning,
2066,pub.1136005784,10.48550/arxiv.2103.02911,,,Semi-supervised Left Atrium Segmentation with Mutual Consistency  Training,"Semi-supervised learning has attracted great attention in the field of
machine learning, especially for medical image segmentation tasks, since it
alleviates the heavy burden of collecting abundant densely annotated data for
training. However, most of existing methods underestimate the importance of
challenging regions (e.g. small branches or blurred edges) during training. We
believe that these unlabeled regions may contain more crucial information to
minimize the uncertainty prediction for the model and should be emphasized in
the training process. Therefore, in this paper, we propose a novel Mutual
Consistency Network (MC-Net) for semi-supervised left atrium segmentation from
3D MR images. Particularly, our MC-Net consists of one encoder and two slightly
different decoders, and the prediction discrepancies of two decoders are
transformed as an unsupervised loss by our designed cycled pseudo label scheme
to encourage mutual consistency. Such mutual consistency encourages the two
decoders to have consistent and low-entropy predictions and enables the model
to gradually capture generalized features from these unlabeled challenging
regions. We evaluate our MC-Net on the public Left Atrium (LA) database and it
obtains impressive performance gains by exploiting the unlabeled data
effectively. Our MC-Net outperforms six recent semi-supervised methods for left
atrium segmentation, and sets the new state-of-the-art performance on the LA
database.",,,arXiv,,,2021-03-04,2021,,,,,,All OA; Green,Preprint,"Wu, Yicheng; Xu, Minfeng; Ge, Zongyuan; Cai, Jianfei; Zhang, Lei","Wu, Yicheng (); Xu, Minfeng (); Ge, Zongyuan (); Cai, Jianfei (); Zhang, Lei ()",,"Wu, Yicheng (); Xu, Minfeng (); Ge, Zongyuan (); Cai, Jianfei (); Zhang, Lei ()",1,1,,0.82,,https://app.dimensions.ai/details/publication/pub.1136005784,46 Information and Computing Sciences; 4611 Machine Learning,
2060,pub.1154178478,10.1109/bibm55620.2022.9995371,,,DTSC-Net: Semi-supervised 3D Biomedical Image Segmentation through Dual-Teacher Simplified Consistency,"Although those deep learning networks have achieved remarkable performance in various biomedical image segmentation tasks, they rely on massive labeled data for training, which is time-consuming to acquire. To alleviate this challenging issue, semi-supervised learning (SSL) has shown the potential to simultaneously leverage between abundant unlabeled samples and limited labeled data. In this work, we propose a new SSL approach for left atrial and liver tumor segmentation called DTSC-Net. First, two teacher networks and one student network are optimized together through a supervised loss and two unsupervised consistency losses. Furthermore, pseudo labels are yielded by using the first teacher network on unlabeled data. In addition, the weights of the second teacher network are an exponential moving average of the student networkâs weights. Moreover, the student network learns from the two teacher networks by minimizing a supervised segmentation loss, a pseudo-labeling unsupervised consistency (PUC) loss, and a dual-teacher unsupervised consistency (DUC) loss with respect to the targets of the two teacher networks. Experiment results show that our approach achieves state-of-the-art semi-supervised segmentation performance on the LA2018 and LiTS2017 datasets.",,"This work was supported by the National Natural Science Foundation of China under Grant 61901120 and 62171133, in part by the Science and Technology Innovation Joint Fund Program of Fujian Province of China under Grant 2019Y9104, the Health Science and Technology Program of Fujian Province of China under Grant 2019-1-33.",,2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,2022-12-08,2022,,2022-12-08,00,,1429-1434,Closed,Proceeding,"Zhou, Xiaogen; Li, Zhiqiang; Tong, Tong","Zhou, Xiaogen (College of Physics and Information Engineering, Fuzhou University; Fujian Key Lab of Medical Instrumentation & Pharmaceutical Technology, Fuzhou University); Li, Zhiqiang (College of Physics and Information Engineering, Fuzhou University; Fujian Key Lab of Medical Instrumentation & Pharmaceutical Technology, Fuzhou University); Tong, Tong (College of Physics and Information Engineering, Fuzhou University; Fujian Key Lab of Medical Instrumentation & Pharmaceutical Technology, Fuzhou University; Imperial Vision Technology)","Tong, Tong (Fuzhou University; Fuzhou University; )","Zhou, Xiaogen (Fuzhou University; Fuzhou University); Li, Zhiqiang (Fuzhou University; Fuzhou University); Tong, Tong (Fuzhou University; Fuzhou University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1154178478,46 Information and Computing Sciences; 4611 Machine Learning,
2060,pub.1151856865,10.1007/978-3-031-18814-5_8,,,Gabor Filter-Embedded U-Net with Transformer-Based Encoding for Biomedical Image Segmentation,"Medical image segmentation involves a process of categorization of target regions that are typically varied in terms of shape, orientation and scales. This requires highly accurate algorithms as marginal segmentation errors in medical images may lead to inaccurate diagnosis in subsequent procedures. The U-Net framework has become one of the dominant deep neural network architectures for medical image segmentation. Due to complex and irregular shape of objects involved in medical images, robust feature representations that correspond to various spatial transformations are key to achieve successful results. Although U-Net-based deep architectures can perform feature extraction and localization, the design of specialized architectures or layer modifications is often an intricate task. In this paper, we propose an effective solution to this problem by introducing Gabor filter banks into the U-Net encoder, which has not yet been well explored in existing U-Net-based segmentation frameworks. In addition, global self-attention mechanisms and Transformer layers are also incorporated into the U-Net framework to capture global contexts. Through extensive testing on two benchmark datasets, we show that the Gabor filter-embedded U-Net with Transformer encoders can enhance the robustness of deep-learned features, and thus achieve a more competitive performance.",,,Lecture Notes in Computer Science,Multiscale Multimodal Medical Imaging,,2022-10-12,2022,2022-10-12,2022,13594,,76-88,Closed,Chapter,"Reyes, Abel A.; Paheding, Sidike; Deo, Makarand; Audette, Michel","Reyes, Abel A. (Michigan Technological University, 49931, Houghton, MI, USA); Paheding, Sidike (Michigan Technological University, 49931, Houghton, MI, USA); Deo, Makarand (Norfolk State University, 23504, Norfolk, VA, USA); Audette, Michel (Old Dominion University, 23529, Norfolk, VA, USA)","Paheding, Sidike (Michigan Technological University)","Reyes, Abel A. (Michigan Technological University); Paheding, Sidike (Michigan Technological University); Deo, Makarand (Norfolk State University); Audette, Michel (Old Dominion University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151856865,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
2060,pub.1150532726,10.1109/icme52920.2022.9859611,,,Semi-Supervised 3D Medical Image Segmentation Using Shape-Guided Dual Consistency Learning,"Popular semi-supervised image segmentation networks suf-fer from two problems: firstly, supervision is only performed on the last layer of the decoder, resulting in the network's weak generalization ability; secondly, the geometry shape constraints of targets are frequently disregarded in these net-works, leading to poor segmentation results. To address these issues, we propose a novel shape-guided dual consistency semi-supervised learning framework for 3D medical image segmentation. The proposed framework makes two contri-butions. Initially, we introduce a shape constraint to learn the shape representation, which converts the difference be-tween two networks into an unsupervised loss and lets the model learn the boundary information of targets. Addition-ally, we develop a deep-supervised knowledge transfer strat-egy that improves the generalization ability of the network without increasing extra computation costs. Experiments demonstrate that the proposed framework outperforms state-of-the-art semi-supervised methods due to the strong ability of knowledge mining on unlabeled data.",,,,2022 IEEE International Conference on Multimedia and Expo (ICME),,2022-07-22,2022,,2022-07-22,00,,01-06,Closed,Proceeding,"Lei, Tao; Liu, Hulin; Chen, Qi; Wang, Zexuan; Zhang, Dong; Wang, Xingwu; Du, Xiaogang; Lu, Bo","Lei, Tao (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China); Liu, Hulin (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China); Chen, Qi (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China); Wang, Zexuan (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China); Zhang, Dong (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China); Wang, Xingwu (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China); Du, Xiaogang (Shaanxi Joint Laboratory of Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Xi'an, 710021, P. R. China); Lu, Bo (ORCA DATA TECHNOLOGY (XI'AN) CO., LTD, Xi'an, 712000, P. R. China)",,"Lei, Tao (Shaanxi University of Science and Technology; Shaanxi University of Science and Technology); Liu, Hulin (Shaanxi University of Science and Technology; Shaanxi University of Science and Technology); Chen, Qi (Shaanxi University of Science and Technology; Shaanxi University of Science and Technology); Wang, Zexuan (Shaanxi University of Science and Technology; Shaanxi University of Science and Technology); Zhang, Dong (Shaanxi University of Science and Technology; Shaanxi University of Science and Technology); Wang, Xingwu (Shaanxi University of Science and Technology; Shaanxi University of Science and Technology); Du, Xiaogang (Shaanxi University of Science and Technology; Shaanxi University of Science and Technology); Lu, Bo ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150532726,46 Information and Computing Sciences; 4611 Machine Learning,
2058,pub.1142052783,10.1007/978-3-030-88010-1_46,,,Dual-Task Mutual Learning for Semi-supervised Medical Image Segmentation,"The success of deep learning methods in medical image segmentation tasks usually requires a large amount of labeled data. However, obtaining reliable annotations is expensive and time-consuming. Semi-supervised learning has attracted much attention in medical image segmentation by taking the advantage of unlabeled data which is much easier to acquire. In this paper, we propose a novel dual-task mutual learning framework for semi-supervised medical image segmentation. Our framework can be formulated as an integration of two individual segmentation networks based on two tasks: learning region-based shape constraint and learning boundary-based surface mismatch. Different from the one-way transfer between teacher and student networks, an ensemble of dual-task students can learn collaboratively and implicitly explore useful knowledge from each other during the training process. By jointly learning the segmentation probability maps and signed distance maps of targets, our framework can enforce the geometric shape constraint and learn more reliable information. Experimental results demonstrate that our method achieves performance gains by leveraging unlabeled data and outperforms the state-of-the-art semi-supervised segmentation methods.","This work is supported by the National Key Research and Development Program of China (2016YFF0201002), the University Synergy Innovation Program of Anhui Province (GXXT-2019-044), and the National Natural Science Foundation of China (61301005).",,Lecture Notes in Computer Science,Pattern Recognition and Computer Vision,,2021-10-22,2021,2021-10-22,2021,13021,,548-559,All OA; Green,Chapter,"Zhang, Yichi; Zhang, Jicong","Zhang, Yichi (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Zhang, Jicong (School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Hefei Innovation Research Institute, Beihang University, Hefei, China; Beijing Advanced Innovation Centre for Biomedical Engineering, Beijing, China; Beijing Advanced Innovation Centre for Big Data-Based Precision Medicine, Beijing, China)","Zhang, Jicong (Beihang University; Beihang University; ; )","Zhang, Yichi (Beihang University); Zhang, Jicong (Beihang University; Beihang University)",12,12,,9.55,http://arxiv.org/pdf/2103.04708,https://app.dimensions.ai/details/publication/pub.1142052783,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
2056,pub.1151033087,10.1007/978-3-031-16452-1_46,,,FUSSNet: Fusing Two Sources of Uncertainty for Semi-supervised Medical Image Segmentation,"In recent years, various semi-supervised learning (SSL) methods have been developed to deal with the scarcity of labeled data in medical image segmentation. Especially, many of them focus on the uncertainty caused by a lack of knowledge (about the best model), i.e. epistemic uncertainty (EU). Besides EU, another type of uncertainty, aleatoric uncertainty (AU), originated from irreducible errors or noise, also commonly exists in medical imaging data. While previous SSL approaches focus on only one of them (mostly EU), this study shows that SSL segmentation models can benefit more by considering both sources of uncertainty. The proposed FUSSNet framework is featured by a joint learning scheme, which combines the EU-guided unsupervised learning and AU-guided supervised learning. We assess the method on two benchmark datasets for the segmentation of left atrium (LA) and pancreas, respectively. The experimental results show that FUSSNet outperforms the state-of-the-art semi-supervised segmentation methods by over 2% on Dice score for pancreas data and almost reaches the accuracy obtained in fully supervised setting for LA data.","This work was supported by Clinical Research Program of 9th Peopleâs Hospital (JYLJ202010), Shanghai Science and Technology Innovation Action Plan (20Y11909600, 21S31904300), Clinical Research Plan of SHDC (SHDC2020CR6016-003), Shanghai Municipal Health Bureau Project (202040434). We thank the authors of [15] and [21] for sharing their datasets and [10, 13, 16] for their inspiring work and code repositories.",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention â MICCAI 2022,,2022-09-16,2022,2022-09-16,2022,13438,,481-491,Closed,Chapter,"Xiang, Jinyi; Qiu, Peng; Yang, Yang","Xiang, Jinyi (Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China); Qiu, Peng (Department of Vascular Surgery, Shanghai Ninth Peopleâs Hospital Affiliated to Shanghai Jiao Tong University, Shanghai, China); Yang, Yang (Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China)","Yang, Yang (Shanghai Jiao Tong University)","Xiang, Jinyi (Shanghai Jiao Tong University); Qiu, Peng (Shanghai Jiao Tong University); Yang, Yang (Shanghai Jiao Tong University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1151033087,46 Information and Computing Sciences; 4611 Machine Learning,
2056,pub.1151033066,10.1007/978-3-031-16452-1_26,,,Leveraging Labeling Representations in Uncertainty-Based Semi-supervised Segmentation,"Semi-supervised segmentation tackles the scarcity of annotations by leveraging unlabeled data with a small amount of labeled data. A prominent way to utilize the unlabeled data is by consistency training which commonly uses a teacher-student network, where a teacher guides a student segmentation. The predictions of unlabeled data are not reliable, therefore, uncertainty-aware methods have been proposed to gradually learn from meaningful and reliable predictions. Uncertainty estimation, however, relies on multiple inferences from model predictions that need to be computed for each training step, which is computationally expensive. This work proposes a novel method to estimate the pixel-level uncertainty by leveraging the labeling representation of segmentation masks. On the one hand, a labeling representation is learnt to represent the available segmentation masks. The learnt labeling representation is used to map the prediction of the segmentation into a set of plausible masks. Such a reconstructed segmentation mask aids in estimating the pixel-level uncertainty guiding the segmentation network. The proposed method estimates the uncertainty with a single inference from the labeling representation, thereby reducing the total computation. We evaluate our method on the 3D segmentation of left atrium in MRI, and we show that our uncertainty estimates from our labeling representation improve the segmentation accuracy over state-of-the-art methods. Code is released at GitHub.","This research work was partly funded by the Canada Research Chair on Shape Analysis in Medical Imaging, the Natural Sciences and Engineering Research Council of Canada (NSERC), and the Fonds de Recherche du Quebec (FQRNT).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention â MICCAI 2022,,2022-09-16,2022,2022-09-16,2022,13438,,265-275,All OA; Green,Chapter,"Adiga Vasudeva, Sukesh; Dolz, Jose; Lombaert, Herve","Adiga Vasudeva, Sukesh (ETS Montreal, Montreal, Canada); Dolz, Jose (ETS Montreal, Montreal, Canada); Lombaert, Herve (ETS Montreal, Montreal, Canada)","Adiga Vasudeva, Sukesh ","Adiga Vasudeva, Sukesh (); Dolz, Jose (); Lombaert, Herve ()",1,1,,,http://arxiv.org/pdf/2203.05682,https://app.dimensions.ai/details/publication/pub.1151033066,46 Information and Computing Sciences; 4611 Machine Learning,
2056,pub.1150997092,10.1007/978-3-031-16431-6_49,,,Decoupling Predictions in Distributed Learning for Multi-center Left Atrial MRI Segmentation,"Distributed learning has shown great potential in medical image analysis. It allows to use multi-center training data with privacy protection. However, data distributions in local centers can vary from each other due to different imaging vendors, and annotation protocols. Such variation degrades the performance of learning-based methods. To mitigate the influence, two groups of methods have been proposed for different aims, i.e., the global methods and the personalized methods. The former are aimed to improve the performance of a single global model for all test data from unseen centers (known as generic data); while the latter target multiple models for each center (denoted as local data). However, little has been researched to achieve both goals simultaneously. In this work, we propose a new framework of distributed learning that bridges the gap between two groups, and improves the performance for both generic and local data. Specifically, our method decouples the predictions for generic data and local data, via distribution-conditioned adaptation matrices. Results on multi-center left atrial (LA) MRI segmentation showed that our method demonstrated superior performance over existing methods on both generic and local data. Our code is available at https://github.com/key1589745/decouple_predict.",,,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention â MICCAI 2022,,2022-09-15,2022,2022-09-15,2022,13431,,517-527,Closed,Chapter,"Gao, Zheyao; Li, Lei; Wu, Fuping; Wang, Sihan; Zhuang, Xiahai","Gao, Zheyao (School of Data Science, Fudan University, Shanghai, China); Li, Lei (Department of Engineering Science, University of Oxford, Oxford, UK); Wu, Fuping (School of Data Science, Fudan University, Shanghai, China; Department of Statistics, Fudan University, Shanghai, China); Wang, Sihan (School of Data Science, Fudan University, Shanghai, China); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China)","Zhuang, Xiahai (Fudan University)","Gao, Zheyao (Fudan University); Li, Lei (University of Oxford); Wu, Fuping (Fudan University; Fudan University); Wang, Sihan (Fudan University); Zhuang, Xiahai (Fudan University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150997092,46 Information and Computing Sciences; 4611 Machine Learning,
2056,pub.1146046374,10.48550/arxiv.2203.01324,,,Exploring Smoothness and Class-Separation for Semi-supervised Medical  Image Segmentation,"Semi-supervised segmentation remains challenging in medical imaging since the
amount of annotated medical data is often scarce and there are many blurred
pixels near the adhesive edges or in the low-contrast regions. To address the
issues, we advocate to firstly constrain the consistency of pixels with and
without strong perturbations to apply a sufficient smoothness constraint and
further encourage the class-level separation to exploit the low-entropy
regularization for the model training. Particularly, in this paper, we propose
the SS-Net for semi-supervised medical image segmentation tasks, via exploring
the pixel-level smoothness and inter-class separation at the same time. The
pixel-level smoothness forces the model to generate invariant results under
adversarial perturbations. Meanwhile, the inter-class separation encourages
individual class features should approach their corresponding high-quality
prototypes, in order to make each class distribution compact and separate
different classes. We evaluated our SS-Net against five recent methods on the
public LA and ACDC datasets. Extensive experimental results under two
semi-supervised settings demonstrate the superiority of our proposed SS-Net
model, achieving new state-of-the-art (SOTA) performance on both datasets. The
code is available at https://github.com/ycwu1997/SS-Net.",,,arXiv,,,2022-03-02,2022,,,,,,All OA; Green,Preprint,"Wu, Yicheng; Wu, Zhonghua; Wu, Qianyi; Ge, Zongyuan; Cai, Jianfei","Wu, Yicheng (); Wu, Zhonghua (); Wu, Qianyi (); Ge, Zongyuan (); Cai, Jianfei ()",,"Wu, Yicheng (); Wu, Zhonghua (); Wu, Qianyi (); Ge, Zongyuan (); Cai, Jianfei ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146046374,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1846,pub.1154424344,10.48550/arxiv.2301.04401,,,An atrium segmentation network with location guidance and siamese  adjustment,"The segmentation of atrial scan images is of great significance for the
three-dimensional reconstruction of the atrium and the surgical positioning.
Most of the existing segmentation networks adopt a 2D structure and only take
original images as input, ignoring the context information of 3D images and the
role of prior information. In this paper, we propose an atrium segmentation
network LGSANet with location guidance and siamese adjustment, which takes
adjacent three slices of images as input and adopts an end-to-end approach to
achieve coarse-to-fine atrial segmentation. The location guidance(LG) block
uses the prior information of the localization map to guide the encoding
features of the fine segmentation stage, and the siamese adjustment(SA) block
uses the context information to adjust the segmentation edges. On the atrium
datasets of ACDC and ASC, sufficient experiments prove that our method can
adapt to many classic 2D segmentation networks, so that it can obtain
significant performance improvements.",,,arXiv,,,2023-01-11,2023,,,,,,All OA; Green,Preprint,"Xie, Yuhan; Zhang, Zhiyong; Chen, Shaolong; Qiu, Changzhen","Xie, Yuhan (); Zhang, Zhiyong (); Chen, Shaolong (); Qiu, Changzhen ()",,"Xie, Yuhan (); Zhang, Zhiyong (); Chen, Shaolong (); Qiu, Changzhen ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154424344,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1836,pub.1149760557,10.1016/j.bspc.2022.103960,,,Combining edge guidance and feature pyramid for medical image segmentation,"Automatic segmentation of medical images is very important for computer-aided diagnosis. The U-shaped and skip-connection based on convolution (UNet) has achieved the most advanced performance in the field of medical image segmentation. However, most existing UNet-based methods have the problem of coarse segmentation of tissue edges. We propose a novel edge guidance feature pyramid network (EGFPNet) for medical image segmentation with the following contributions. First, we synthesize local edge information and global location information to obtain tissue edge features. Second, in order to better utilize the edge information, we propose an edge guidance feature pyramid (EGFP). Edge features interact with area features of different scales to form complementary features of different scales. These complementary features of different scales also interact to represent the complete information of the tissue and improve the adaptability to different tissue scales. We compare with state-of-the-art medical image segmentation methods on the automated cardiac diagnosis challenge (ACDC) and the 2018 atrial segmentation challenge (2018 ASC). Our method achieved average dice score of 0.929 for right ventricle (RV), 0.886 for myocardium (Myo), 0.958 for left ventricle (LV), and 0.920 for left atrium (LA). Experimental results on two medical image segmentation datasets show that our method outperforms six state-of-the-art medical image segmentation methods. The code is available at https://github.com/jinancsl/EGFPNet.","The author thanks the whole authors in the referred articles. In addition, the author would also like to thank Jiuying Chen and Ruiyang Guo. This work was supported in part by the Science and Technology Planning Project of Guangdong Science and Technology Department under Grant Guangdong Key Laboratory of Advanced IntelliSense Technology (2019B121203006).",,Biomedical Signal Processing and Control,,,2022-09,2022,,2022-09,78,,103960,Closed,Article,"Chen, Shaolong; Qiu, Changzhen; Yang, Weiping; Zhang, Zhiyong","Chen, Shaolong (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China); Qiu, Changzhen (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China); Yang, Weiping (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China); Zhang, Zhiyong (School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China)","Zhang, Zhiyong (Sun Yat-sen University)","Chen, Shaolong (Sun Yat-sen University); Qiu, Changzhen (Sun Yat-sen University); Yang, Weiping (Sun Yat-sen University); Zhang, Zhiyong (Sun Yat-sen University)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1149760557,40 Engineering; 4003 Biomedical Engineering,3 Good Health and Well Being
1773,pub.1145527573,10.48550/arxiv.2202.06104,,,Semi-supervised Medical Image Segmentation via Geometry-aware  Consistency Training,"The performance of supervised deep learning methods for medical image
segmentation is often limited by the scarcity of labeled data. As a promising
research direction, semi-supervised learning addresses this dilemma by
leveraging unlabeled data information to assist the learning process. In this
paper, a novel geometry-aware semi-supervised learning framework is proposed
for medical image segmentation, which is a consistency-based method.
Considering that the hard-to-segment regions are mainly located around the
object boundary, we introduce an auxiliary prediction task to learn the global
geometric information. Based on the geometric constraint, the ambiguous
boundary regions are emphasized through an exponentially weighted strategy for
the model training to better exploit both labeled and unlabeled data. In
addition, a dual-view network is designed to perform segmentation from
different perspectives and reduce the prediction uncertainty. The proposed
method is evaluated on the public left atrium benchmark dataset and improves
fully supervised method by 8.7% in Dice with 10% labeled images, while 4.3%
with 20% labeled images. Meanwhile, our framework outperforms six
state-of-the-art semi-supervised segmentation methods.",,,arXiv,,,2022-02-12,2022,,,,,,All OA; Green,Preprint,"Liu, Zihang; Zhao, Chunhui","Liu, Zihang (); Zhao, Chunhui ()",,"Liu, Zihang (); Zhao, Chunhui ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145527573,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4605 Data Management and Data Science; 4611 Machine Learning,
1717,pub.1154742181,10.1080/20479700.2023.2166206,,,Left atrium MRI image segmentation using efficient Xception stochastic depth based generative adversarial network,"Globally, cardiovascular diseases are an important cause of death. The general underlying mechanism of the key cardiovascular diseases is thrombus formation inside the blood vessels. For these thrombi, the Left Atrial Appendage (LAA) is the significant repository. It is a residual appendix as of the Left Atrium (LA) embryonic development; in addition, thrombus formation in healthy patients is prevented by its high contractility. Hence, LA segmentation is required. Proposing an effectual technique to attain automatic segmentation of the LA of a Magnetic Resonance Imaging (MRI) input image is the goal. By employing a Bitwise Left and Right Shift-centric White Shark Optimizer (BLRSWSO), optimized boundary detection is conducted. To segment LA, the Xception Stochastic Depth-centric Generative Adversarial Network (XSDGAN) is developed. In the end, by deploying the Union Histogram Intersection Box filter (UHIBF), contrast enhancement is carried out. For proving the efficacy, the proposed methodologiesâ performance is weighed against the prevailing techniques. The proposed system segments the LA effectively as per the experimentation.",,The author(s) reported there is no funding associated with the work featured in this article.,International Journal of Healthcare Management,,,2023-01-21,2023,2023-01-21,,ahead-of-print,ahead-of-print,1-12,Closed,Article,"Bhan, Anupama; Mangipudi, Partha Sarathi; Goyal, Ayush","Bhan, Anupama (Department of Electronics and Communication Engineering, Amity School of Engineering and Technology, Amity University, Noida, India); Mangipudi, Partha Sarathi (Department of Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Noida, India); Goyal, Ayush (Department of Electrical Engineering and Computer Science, Frank H. Dotterweich College of Engineering, Texas A&M University â Kingsville, Kingsville, TX, USA)","Bhan, Anupama (Amity University)","Bhan, Anupama (Amity University); Mangipudi, Partha Sarathi (Amity University); Goyal, Ayush (Texas A&M University â Kingsville)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154742181,42 Health Sciences; 4203 Health Services and Systems; 4206 Public Health,
1714,pub.1148786291,10.1016/j.bspc.2022.103870,,,DC-net: Dual-Consistency semi-supervised learning for 3D left atrium segmentation from MRI,"Objective: Left atrial segmentation is very important for the treatment of atrial fibrillation. One factor limiting the automatic segmentation of the left atrium is that training network needs a large amount of labeled data, which is expensive and time-consuming. Using limited labeled data for accurate segmentation is our key concern. Methods: In this work, we propose a novel dual-consistency semi-supervised learning method for left atrium segmentation from 3D MR images. Our framework can effectively leverage limited labeled data and abundant unlabeled data by enforcing consistent predictions under model-level and structure-level perturbations. As for model-level perturbations, we employ a shared encoder and two slightly different decoders. Different decoders can output different predictions. As for structure-level spatial contextual perturbations, two sub-volumes with an overlapping region are randomly cropped, taking as inputs under different spatial contexts. Therefore, the proposed method can maintain the invariance of segmentation results when perturbed by different spatial contexts, and be robust to slight perturbations of networks. Results: Our method are evaluated on the public Atrial Segmentation Challenge dataset. The evaluation metrics of Dice, Jaccard, ASD and 95HD are 90.05%, 82.01%, 1.74 voxel and 7.03 voxel when we use 20% labeled data and 80% unlabeled data. The results show that the proposed method outperforms other exiting semi-supervised methods. Conclusion and Significance: The proposed semi-supervised method can achieve accurate segmentation of left atrium by utilizing limited labeled data and abundant unlabeled data, offering an effective way for doctors to diagnose and treat atrial fibrillation.","This work was supported partly by the Fundamental Research Funds for the Central Universities (Grant No. 2020XD-A04-2), partly by the National Natural Science Foundation of China (Grant No. 62173045, 61673192), and partly supported by BUPT Excellent Ph.D. Students Foundation (CX2021314), partially supported by the Research Grant Council (RGC) of Hong Kong under Grant 11212321 and Grant ECS-21212720, Basic and Applied Basic Research Foundation of Guangdong Province under Grant 2019A1515110175, and Science Technology and Innovation Committee of Shenzhen under Grant SGDX20210823104001011.",,Biomedical Signal Processing and Control,,,2022-09,2022,,2022-09,78,,103870,Closed,Article,"Wang, Junying; Liu, Xiaoli; Yin, Jianqin; Ding, Pengxiang","Wang, Junying (Beijing University of Posts and Telecommunications, Beijing, China); Liu, Xiaoli (Beijing University of Posts and Telecommunications, Beijing, China); Yin, Jianqin (Beijing University of Posts and Telecommunications, Beijing, China); Ding, Pengxiang (Beijing University of Posts and Telecommunications, Beijing, China)","Yin, Jianqin (Beijing University of Posts and Telecommunications)","Wang, Junying (Beijing University of Posts and Telecommunications); Liu, Xiaoli (Beijing University of Posts and Telecommunications); Yin, Jianqin (Beijing University of Posts and Telecommunications); Ding, Pengxiang (Beijing University of Posts and Telecommunications)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1148786291,"30 Agricultural, Veterinary and Food Sciences; 3006 Food Sciences; 40 Engineering; 4003 Biomedical Engineering",
1712,pub.1151600813,10.48550/arxiv.2210.01438,,,Complementary consistency semi-supervised learning for 3D left atrial  image segmentation,"A network (CC-Net) based on complementary consistency training is proposed
for semi-supervised left atrial image segmentation in this paper. From the
perspective of complementary information, CC-Net efficiently utilizes unlabeled
data and resolves the problem that semi-supervised segmentation algorithms
currently in use have limited capacity to extract information from unlabeled
data. A primary model and two complementary auxiliary models are part of the
complementary symmetric structure of the CC-Net. The inter-model perturbation
is formed between the main model and the auxiliary model to form complementary
consistency training. The complementary information between the two auxiliary
models helps the main model to focus on the fuzzy region effectively.
Additionally, forcing consistency between the main model and the auxiliary
models makes it easier to obtain decision boundaries with low uncertainty.
CC-Net was validated in the benchmark dataset of the 2018 Atrial Segmentation
Challenge. The Dice reached of 89.82% with 10% labeled data training and 91.27%
with 20% labeled data training. By comparing with current state-of-the-art
algorithms, CC-Net has the best segmentation performance and robustness. Our
code is publicly available at https://github.com/Cuthbert-Huang/CC-Net.",,,arXiv,,,2022-10-04,2022,,,,,,All OA; Green,Preprint,"Huang, Hejun; Chen, Zuguo; Chen, Chaoyang; Lu, Ming; Zou, Ying","Huang, Hejun (); Chen, Zuguo (); Chen, Chaoyang (); Lu, Ming (); Zou, Ying ()",,"Huang, Hejun (); Chen, Zuguo (); Chen, Chaoyang (); Lu, Ming (); Zou, Ying ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151600813,46 Information and Computing Sciences; 4611 Machine Learning,
1710,pub.1139284625,10.48550/arxiv.2106.15707,,,Recent Advances in Fibrosis and Scar Segmentation from Cardiac MRI: A  State-of-the-Art Review and Future Perspectives,"Segmentation of cardiac fibrosis and scar are essential for clinical
diagnosis and can provide invaluable guidance for the treatment of cardiac
diseases. Late Gadolinium enhancement (LGE) cardiovascular magnetic resonance
(CMR) has been successful for its efficacy in guiding the clinical diagnosis
and treatment reliably. For LGE CMR, many methods have demonstrated success in
accurately segmenting scarring regions. Co-registration with other
non-contrast-agent (non-CA) modalities, balanced steady-state free precession
(bSSFP) and cine magnetic resonance imaging (MRI) for example, can further
enhance the efficacy of automated segmentation of cardiac anatomies. Many
conventional methods have been proposed to provide automated or semi-automated
segmentation of scars. With the development of deep learning in recent years,
we can also see more advanced methods that are more efficient in providing more
accurate segmentations. This paper conducts a state-of-the-art review of
conventional and current state-of-the-art approaches utilising different
modalities for accurate cardiac fibrosis and scar segmentation.",,,arXiv,,,2021-06-28,2021,,,,,,All OA; Green,Preprint,"Wu, Yinzhe; Tang, Zeyu; Li, Binghuan; Firmin, David; Yang, Guang","Wu, Yinzhe (); Tang, Zeyu (); Li, Binghuan (); Firmin, David (); Yang, Guang ()",,"Wu, Yinzhe (); Tang, Zeyu (); Li, Binghuan (); Firmin, David (); Yang, Guang ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139284625,32 Biomedical and Clinical Sciences; 40 Engineering; 4003 Biomedical Engineering,
1616,pub.1153871538,10.1016/j.bspc.2022.104537,,,Comprehensive information integration network for left atrium segmentation on LGE CMR images,"Automatic and accurate segmentation of the left atrium (LA) is a prerequisite for quantifying the LA, and effective LA segmentation is helpful for the clinical diagnosis of patients with atrial fibrillation. The existing LA segmentation methods are prone to a lack of structural prediction of the pulmonary vein and mitral valve, and the structure of the LA is prone to over- and under-segmentation. To solve these problems, we propose a comprehensive information integration network (CII-Net) to segment the LA from late gadolinium-enhanced (LGE) cardiac magnetic resonance (CMR) images. The CII-Net integrates multiscale information from the input stage, high-level semantic information from the bottleneck stage, interaction information from the encoding and decoding stages, and information from the output stage, which can more completely capture the comprehensive image characteristics. We conducted experiments on 154 LGE CMR cases with atrial fibrillation proposed by the organizer of the 2018 atrial segmentation challenge. Compared with state-of-the-art methods, the proposed CII-Net obtains an average DICE score of 91.9%, average Jaccard score of 85.1%, average Hausdorff distance of 5.924Â mm, and average symmetric surface distance of 0.993Â mm without post-processing, demonstrating the potential for clinical application.","This work was supported by the National Key Research and Development Program of China [2019YFE0110800, 2016YFC1000307-3], National Natural Science Foundation of China [61972060, U1713213, 62027827], the Natural Science Foundation of Chongqing, China [cstc2020j cyj-zdxmX0025, cstc2019cxcyljrc-td0270, cstc2019jcyj-cxttX0002], Chongqing University of Posts and Telecommunications Ph.D. Innovative Talents Project, China [BYJS202110].",,Biomedical Signal Processing and Control,,,2023-03,2023,,2023-03,81,,104537,Closed,Article,"Li, Feiyan; Li, Weisheng; Gao, Xinbo; Liu, Rui; Xiao, Bin","Li, Feiyan (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Li, Weisheng (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Gao, Xinbo (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Liu, Rui (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China); Xiao, Bin (Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China)","Li, Weisheng (Chongqing University of Posts and Telecommunications)","Li, Feiyan (Chongqing University of Posts and Telecommunications); Li, Weisheng (Chongqing University of Posts and Telecommunications); Gao, Xinbo (Chongqing University of Posts and Telecommunications); Liu, Rui (Chongqing University of Posts and Telecommunications); Xiao, Bin (Chongqing University of Posts and Telecommunications)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153871538,"30 Agricultural, Veterinary and Food Sciences; 3006 Food Sciences; 40 Engineering; 4003 Biomedical Engineering",
1616,pub.1153624193,10.1016/j.artmed.2022.102476,,,Uncertainty-guided mutual consistency learning for semi-supervised medical image segmentation,"Medical image segmentation is a fundamental and critical step in many clinical approaches. Semi-supervised learning has been widely applied to medical image segmentation tasks since it alleviates the heavy burden of acquiring expert-examined annotations and takes the advantage of unlabeled data which is much easier to acquire. Although consistency learning has been proven to be an effective approach by enforcing an invariance of predictions under different distributions, existing approaches cannot make full use of region-level shape constraint and boundary-level distance information from unlabeled data. In this paper, we propose a novel uncertainty-guided mutual consistency learning framework to effectively exploit unlabeled data by integrating intra-task consistency learning from up-to-date predictions for self-ensembling and cross-task consistency learning from task-level regularization to exploit geometric shape information. The framework is guided by the estimated segmentation uncertainty of models to select out relatively certain predictions for consistency learning, so as to effectively exploit more reliable information from unlabeled data. Experiments on two publicly available benchmark datasets showed that: (1) Our proposed method can achieve significant performance improvement by leveraging unlabeled data, with up to 4.13% and 9.82% in Dice coefficient compared to supervised baseline on left atrium segmentation and brain tumor segmentation, respectively. (2) Compared with other semi-supervised segmentation methods, our proposed method achieve better segmentation performance under the same backbone network and task settings on both datasets, demonstrating the effectiveness and robustness of our method and potential transferability for other medical image segmentation tasks.","This work is supported in part by the National Key Research and Development Program of China (2016YFF0201002), and in part by the University Synergy Innovation Program of Anhui Province (GXXT-2019-044).",,Artificial Intelligence in Medicine,,,2023-04,2023,,2023-04,138,,102476,All OA; Green,Article,"Zhang, Yichi; Jiao, Rushi; Liao, Qingcheng; Li, Dongyang; Zhang, Jicong","Zhang, Yichi (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Jiao, Rushi (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Liao, Qingcheng (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Li, Dongyang (School of Biological Science and Medical Engineering, Beihang University, Beijing, China); Zhang, Jicong (School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Hefei Innovation Research Institute, Beihang University, Hefei, China; Beijing Advanced Innovation Centre for Biomedical Engineering, Beijing, China)","Zhang, Jicong (Beihang University; Beihang University; )","Zhang, Yichi (Beihang University); Jiao, Rushi (Beihang University); Liao, Qingcheng (Beihang University); Li, Dongyang (Beihang University); Zhang, Jicong (Beihang University; Beihang University)",0,0,,,http://arxiv.org/pdf/2112.02508,https://app.dimensions.ai/details/publication/pub.1153624193,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1609,pub.1154562615,10.48550/arxiv.2301.05500,,,RCPS: Rectified Contrastive Pseudo Supervision for Semi-Supervised  Medical Image Segmentation,"Medical image segmentation methods are generally designed as fully-supervised
to guarantee model performance, which require a significant amount of expert
annotated samples that are high-cost and laborious. Semi-supervised image
segmentation can alleviate the problem by utilizing a large number of unlabeled
images along with limited labeled images. However, learning a robust
representation from numerous unlabeled images remains challenging due to
potential noise in pseudo labels and insufficient class separability in feature
space, which undermines the performance of current semi-supervised segmentation
approaches. To address the issues above, we propose a novel semi-supervised
segmentation method named as Rectified Contrastive Pseudo Supervision (RCPS),
which combines a rectified pseudo supervision and voxel-level contrastive
learning to improve the effectiveness of semi-supervised segmentation.
Particularly, we design a novel rectification strategy for the pseudo
supervision method based on uncertainty estimation and consistency
regularization to reduce the noise influence in pseudo labels. Furthermore, we
introduce a bidirectional voxel contrastive loss to the network to ensure
intra-class consistency and inter-class contrast in feature space, which
increases class separability in the segmentation. The proposed RCPS
segmentation method has been validated on two public datasets and an in-house
clinical dataset. Experimental results reveal that the proposed method yields
better segmentation performance compared with the state-of-the-art methods in
semi-supervised medical image segmentation. The source code is available at
https://github.com/hsiangyuzhao/RCPS.",,,arXiv,,,2023-01-13,2023,,,,,,All OA; Green,Preprint,"Zhao, Xiangyu; Qi, Zengxin; Wang, Sheng; Wang, Qian; Wu, Xuehai; Mao, Ying; Zhang, Lichi","Zhao, Xiangyu (); Qi, Zengxin (); Wang, Sheng (); Wang, Qian (); Wu, Xuehai (); Mao, Ying (); Zhang, Lichi ()",,"Zhao, Xiangyu (); Qi, Zengxin (); Wang, Sheng (); Wang, Qian (); Wu, Xuehai (); Mao, Ying (); Zhang, Lichi ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154562615,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1607,pub.1143667336,10.48550/arxiv.2112.02508,,,Uncertainty-Guided Mutual Consistency Learning for Semi-Supervised  Medical Image Segmentation,"Medical image segmentation is a fundamental and critical step in many
clinical approaches. Semi-supervised learning has been widely applied to
medical image segmentation tasks since it alleviates the heavy burden of
acquiring expert-examined annotations and takes the advantage of unlabeled data
which is much easier to acquire. Although consistency learning has been proven
to be an effective approach by enforcing an invariance of predictions under
different distributions, existing approaches cannot make full use of
region-level shape constraint and boundary-level distance information from
unlabeled data. In this paper, we propose a novel uncertainty-guided mutual
consistency learning framework to effectively exploit unlabeled data by
integrating intra-task consistency learning from up-to-date predictions for
self-ensembling and cross-task consistency learning from task-level
regularization to exploit geometric shape information. The framework is guided
by the estimated segmentation uncertainty of models to select out relatively
certain predictions for consistency learning, so as to effectively exploit more
reliable information from unlabeled data. Experiments on two publicly available
benchmark datasets showed that: 1) Our proposed method can achieve significant
performance improvement by leveraging unlabeled data, with up to 4.13% and
9.82% in Dice coefficient compared to supervised baseline on left atrium
segmentation and brain tumor segmentation, respectively. 2) Compared with other
semi-supervised segmentation methods, our proposed method achieve better
segmentation performance under the same backbone network and task settings on
both datasets, demonstrating the effectiveness and robustness of our method and
potential transferability for other medical image segmentation tasks.",,,arXiv,,,2021-12-05,2021,,,,,,All OA; Green,Preprint,"Zhang, Yichi; Jiao, Rushi; Liao, Qingcheng; Li, Dongyang; Zhang, Jicong","Zhang, Yichi (); Jiao, Rushi (); Liao, Qingcheng (); Li, Dongyang (); Zhang, Jicong ()",,"Zhang, Yichi (); Jiao, Rushi (); Liao, Qingcheng (); Li, Dongyang (); Zhang, Jicong ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1143667336,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1521,pub.1151225069,10.1016/j.bspc.2022.104203,,,Uncertainty-aware pseudo-label and consistency for semi-supervised medical image segmentation,"In medical image segmentation tasks, fully-supervised learning has been a huge success by using abundant labeled data. However, it is time-consuming and expensive for technicians to label medical images. In this paper, we propose a novel framework for semi-supervised medical image segmentation, named Uncertainty-aware Pseudo-label and Consistency. Our framework is made up of the studentâteacher models. The supervised loss on labeled data and the consistency loss on both labeled and unlabeled data are weighted and combined to optimize the models. Our method combines the recent state-of-the-art semi-supervised methods, which are consistency regularization and pseudo-labeling. More importantly, we calculate the KullbackâLeibler variance between the student modelâs prediction and the teacher modelâs prediction as uncertainty estimation, and directly use the uncertainty to rectify the learning of noisy pseudo-labels, instead of setting a fixed threshold to filter the pseudo-labels. Experiments on the Left Atrium dataset show that our method can efficiently utilize unlabeled data to achieve high performance and outperform other state-of-the-art semi-supervised methods. In addition, we have also analyzed its difference from conventional methods of consistency regularization and pseudo-labeling in semi-supervised medical image segmentation. Code is available in https://github.com/GXU-GMU-MICCAI/UPC-Pytorch.","This work was partly supported by the National Natural Science Foundation of China (NSFC) (Grant No. : 61861004, 61862006).",,Biomedical Signal Processing and Control,,,2023-01,2023,,2023-01,79,,104203,Closed,Article,"Lu, Liyun; Yin, Mengxiao; Fu, Liyao; Yang, Feng","Lu, Liyun (School of Computer and Electronics and Information, Guangxi University, Nanning, Guangxi, 530004, China); Yin, Mengxiao (School of Computer and Electronics and Information, Guangxi University, Nanning, Guangxi, 530004, China; Guangxi Key Laboratory of Multimedia Communications Network Technology, Guangxi University, Nanning, Guangxi, 530004, China); Fu, Liyao (School of Computer and Electronics and Information, Guangxi University, Nanning, Guangxi, 530004, China); Yang, Feng (School of Computer and Electronics and Information, Guangxi University, Nanning, Guangxi, 530004, China; Guangxi Key Laboratory of Multimedia Communications Network Technology, Guangxi University, Nanning, Guangxi, 530004, China)","Yang, Feng (Guangxi University; Guangxi University)","Lu, Liyun (Guangxi University); Yin, Mengxiao (Guangxi University; Guangxi University); Fu, Liyao (Guangxi University); Yang, Feng (Guangxi University; Guangxi University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1151225069,"30 Agricultural, Veterinary and Food Sciences; 3006 Food Sciences; 40 Engineering; 4003 Biomedical Engineering",
1515,pub.1144167152,10.1016/j.jksuci.2021.12.005,,,An objective measure for assessing the quality of contrast enhancement on magnetic resonance images,"Post-processing algorithms like histogram equalization and its variants have been widely employed to enhance the contrast of Magnetic Resonance (MR) images. Objective metrics that can collectively reflect the improvement in contrast and inadvertent distortions are necessary to rate the quality of enhanced images. The objective of this paper is to formulate an objective statistic for rating the quality of contrast enhancement on MR images and to test the agreement of the proposed metric with the subjective fidelity ratings. An objective metric named Cumulative Quality of Contrast-Enhanced Images (CQCEI), for assessing the quality of contrast enhancement, especially the performance of the histogram equalization and its variants, on MR images is proposed. The CQCEI is formulated such that it collectively accounts for various aspects of image quality pertaining to the contrast enhancement, namely improvement in contrast, shift in mean brightness, saturation and noise-amplification. The CQCEI has shown good agreement with subjective fidelity ratings on contrast-enhanced MR images.",,,Journal of King Saud University - Computer and Information Sciences,,,2022-11,2022,,2022-11,34,10,9732-9744,All OA; Gold,Article,"Renuka, Simi Venuji; Edla, Damodar Reddy; Joseph, Justin","Renuka, Simi Venuji (Department of Computer Science and Engineering, National Institute of Technology, Goa 403401, India); Edla, Damodar Reddy (Department of Computer Science and Engineering, National Institute of Technology, Goa 403401, India); Joseph, Justin (School of Bioengineering, VIT University, Bhopal 466114, India)","Renuka, Simi Venuji (Maulana Azad National Institute of Technology)","Renuka, Simi Venuji (Maulana Azad National Institute of Technology); Edla, Damodar Reddy (Maulana Azad National Institute of Technology); Joseph, Justin ()",4,4,,,https://doi.org/10.1016/j.jksuci.2021.12.005,https://app.dimensions.ai/details/publication/pub.1144167152,46 Information and Computing Sciences,
1510,pub.1141300244,10.48550/arxiv.2109.09960,,,Mutual Consistency Learning for Semi-supervised Medical Image  Segmentation,"In this paper, we propose a novel mutual consistency network (MC-Net+) to
effectively exploit the unlabeled data for semi-supervised medical image
segmentation. The MC-Net+ model is motivated by the observation that deep
models trained with limited annotations are prone to output highly uncertain
and easily mis-classified predictions in the ambiguous regions (e.g., adhesive
edges or thin branches) for medical image segmentation. Leveraging these
challenging samples can make the semi-supervised segmentation model training
more effective. Therefore, our proposed MC-Net+ model consists of two new
designs. First, the model contains one shared encoder and multiple slightly
different decoders (i.e., using different up-sampling strategies). The
statistical discrepancy of multiple decoders' outputs is computed to denote the
model's uncertainty, which indicates the unlabeled hard regions. Second, we
apply a novel mutual consistency constraint between one decoder's probability
output and other decoders' soft pseudo labels. In this way, we minimize the
discrepancy of multiple outputs (i.e., the model uncertainty) during training
and force the model to generate invariant results in such challenging regions,
aiming at regularizing the model training. We compared the segmentation results
of our MC-Net+ model with five state-of-the-art semi-supervised approaches on
three public medical datasets. Extension experiments with two standard
semi-supervised settings demonstrate the superior performance of our model over
other methods, which sets a new state of the art for semi-supervised medical
image segmentation. Our code is released publicly at
https://github.com/ycwu1997/MC-Net.",,,arXiv,,,2021-09-21,2021,,,,,,All OA; Green,Preprint,"Wu, Yicheng; Ge, Zongyuan; Zhang, Donghao; Xu, Minfeng; Zhang, Lei; Xia, Yong; Cai, Jianfei","Wu, Yicheng (); Ge, Zongyuan (); Zhang, Donghao (); Xu, Minfeng (); Zhang, Lei (); Xia, Yong (); Cai, Jianfei ()",,"Wu, Yicheng (); Ge, Zongyuan (); Zhang, Donghao (); Xu, Minfeng (); Zhang, Lei (); Xia, Yong (); Cai, Jianfei ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1141300244,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1353,pub.1153897886,10.48550/arxiv.2212.10877,,,TMS-Net: A Segmentation Network Coupled With A Run-time Quality Control  Method For Robust Cardiac Image Segmentation,"Recently, deep networks have shown impressive performance for the
segmentation of cardiac Magnetic Resonance Imaging (MRI) images. However, their
achievement is proving slow to transition to widespread use in medical clinics
because of robustness issues leading to low trust of clinicians to their
results. Predicting run-time quality of segmentation masks can be useful to
warn clinicians against poor results. Despite its importance, there are few
studies on this problem. To address this gap, we propose a quality control
method based on the agreement across decoders of a multi-view network, TMS-Net,
measured by the cosine similarity. The network takes three view inputs resliced
from the same 3D image along different axes. Different from previous multi-view
networks, TMS-Net has a single encoder and three decoders, leading to better
noise robustness, segmentation performance and run-time quality estimation in
our experiments on the segmentation of the left atrium on STACOM 2013 and
STACOM 2018 challenge datasets. We also present a way to generate poor
segmentation masks by using noisy images generated with engineered noise and
Rician noise to simulate undertraining, high anisotropy and poor imaging
settings problems. Our run-time quality estimation method show a good
classification of poor and good quality segmentation masks with an AUC reaching
to 0.97 on STACOM 2018. We believe that TMS-Net and our run-time quality
estimation method has a high potential to increase the thrust of clinicians to
automatic image analysis tools.",,,arXiv,,,2022-12-21,2022,,,,,,All OA; Green,Preprint,"Uslu, Fatmatulzehra; Bharath, Anil A.","Uslu, Fatmatulzehra (); Bharath, Anil A. ()",,"Uslu, Fatmatulzehra (); Bharath, Anil A. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153897886,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1349,pub.1137748697,10.48550/arxiv.2105.00234,,,JAS-GAN: Generative Adversarial Network Based Joint Atrium and Scar  Segmentations on Unbalanced Atrial Targets,"Automated and accurate segmentations of left atrium (LA) and atrial scars
from late gadolinium-enhanced cardiac magnetic resonance (LGE CMR) images are
in high demand for quantifying atrial scars. The previous quantification of
atrial scars relies on a two-phase segmentation for LA and atrial scars due to
their large volume difference (unbalanced atrial targets). In this paper, we
propose an inter-cascade generative adversarial network, namely JAS-GAN, to
segment the unbalanced atrial targets from LGE CMR images automatically and
accurately in an end-to-end way. Firstly, JAS-GAN investigates an adaptive
attention cascade to automatically correlate the segmentation tasks of the
unbalanced atrial targets. The adaptive attention cascade mainly models the
inclusion relationship of the two unbalanced atrial targets, where the
estimated LA acts as the attention map to adaptively focus on the small atrial
scars roughly. Then, an adversarial regularization is applied to the
segmentation tasks of the unbalanced atrial targets for making a consistent
optimization. It mainly forces the estimated joint distribution of LA and
atrial scars to match the real ones. We evaluated the performance of our
JAS-GAN on a 3D LGE CMR dataset with 192 scans. Compared with the
state-of-the-art methods, our proposed approach yielded better segmentation
performance (Average Dice Similarity Coefficient (DSC) values of 0.946 and
0.821 for LA and atrial scars, respectively), which indicated the effectiveness
of our proposed approach for segmenting unbalanced atrial targets.",,,arXiv,,,2021-05-01,2021,,,,,,All OA; Green,Preprint,"Chen, Jun; Yang, Guang; Khan, Habib; Zhang, Heye; Zhang, Yanping; Zhao, Shu; Mohiaddin, Raad; Wong, Tom; Firmin, David; Keegan, Jennifer","Chen, Jun (); Yang, Guang (); Khan, Habib (); Zhang, Heye (); Zhang, Yanping (); Zhao, Shu (); Mohiaddin, Raad (); Wong, Tom (); Firmin, David (); Keegan, Jennifer ()",,"Chen, Jun (); Yang, Guang (); Khan, Habib (); Zhang, Heye (); Zhang, Yanping (); Zhao, Shu (); Mohiaddin, Raad (); Wong, Tom (); Firmin, David (); Keegan, Jennifer ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1137748697,46 Information and Computing Sciences; 4611 Machine Learning,
1283,pub.1144584935,10.48550/arxiv.2201.03186,,,MyoPS: A Benchmark of Myocardial Pathology Segmentation Combining  Three-Sequence Cardiac Magnetic Resonance Images,"Assessment of myocardial viability is essential in diagnosis and treatment
management of patients suffering from myocardial infarction, and classification
of pathology on myocardium is the key to this assessment. This work defines a
new task of medical image analysis, i.e., to perform myocardial pathology
segmentation (MyoPS) combining three-sequence cardiac magnetic resonance (CMR)
images, which was first proposed in the MyoPS challenge, in conjunction with
MICCAI 2020. The challenge provided 45 paired and pre-aligned CMR images,
allowing algorithms to combine the complementary information from the three CMR
sequences for pathology segmentation. In this article, we provide details of
the challenge, survey the works from fifteen participants and interpret their
methods according to five aspects, i.e., preprocessing, data augmentation,
learning strategy, model architecture and post-processing. In addition, we
analyze the results with respect to different factors, in order to examine the
key obstacles and explore potential of solutions, as well as to provide a
benchmark for future research. We conclude that while promising results have
been reported, the research is still in the early stage, and more in-depth
exploration is needed before a successful application to the clinics. Note that
MyoPS data and evaluation tool continue to be publicly available upon
registration via its homepage
(www.sdspeople.fudan.edu.cn/zhuangxiahai/0/myops20/).",,,arXiv,,,2022-01-10,2022,,,,,,All OA; Green,Preprint,"Li, Lei; Wu, Fuping; Wang, Sihan; Luo, Xinzhe; Martin-Isla, Carlos; Zhai, Shuwei; Zhang, Jianpeng; Liu7, Yanfei; Zhang, Zhen; Ankenbrand, Markus J.; Jiang, Haochuan; Zhang, Xiaoran; Wang, Linhong; Arega, Tewodros Weldebirhan; Altunok, Elif; Zhao, Zhou; Li, Feiyan; Ma, Jun; Yang, Xiaoping; Puybareau, Elodie; Oksuz, Ilkay; Bricq, Stephanie; Li, Weisheng; Punithakumar, Kumaradevan; Tsaftaris, Sotirios A.; Schreiber, Laura M.; Yang, Mingjing; Liu, Guocai; Xia, Yong; Wang, Guotai; Escalera, Sergio; Zhuang, Xiahai","Li, Lei (); Wu, Fuping (); Wang, Sihan (); Luo, Xinzhe (); Martin-Isla, Carlos (); Zhai, Shuwei (); Zhang, Jianpeng (); Liu7, Yanfei (); Zhang, Zhen (); Ankenbrand, Markus J. (); Jiang, Haochuan (); Zhang, Xiaoran (); Wang, Linhong (); Arega, Tewodros Weldebirhan (); Altunok, Elif (); Zhao, Zhou (); Li, Feiyan (); Ma, Jun (); Yang, Xiaoping (); Puybareau, Elodie (); Oksuz, Ilkay (); Bricq, Stephanie (); Li, Weisheng (); Punithakumar, Kumaradevan (); Tsaftaris, Sotirios A. (); Schreiber, Laura M. (); Yang, Mingjing (); Liu, Guocai (); Xia, Yong (); Wang, Guotai (); Escalera, Sergio (); Zhuang, Xiahai ()",,"Li, Lei (); Wu, Fuping (); Wang, Sihan (); Luo, Xinzhe (); Martin-Isla, Carlos (); Zhai, Shuwei (); Zhang, Jianpeng (); Liu7, Yanfei (); Zhang, Zhen (); Ankenbrand, Markus J. (); Jiang, Haochuan (); Zhang, Xiaoran (); Wang, Linhong (); Arega, Tewodros Weldebirhan (); Altunok, Elif (); Zhao, Zhou (); Li, Feiyan (); Ma, Jun (); Yang, Xiaoping (); Puybareau, Elodie (); Oksuz, Ilkay (); Bricq, Stephanie (); Li, Weisheng (); Punithakumar, Kumaradevan (); Tsaftaris, Sotirios A. (); Schreiber, Laura M. (); Yang, Mingjing (); Liu, Guocai (); Xia, Yong (); Wang, Guotai (); Escalera, Sergio (); Zhuang, Xiahai ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1144584935,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1170,pub.1140549294,10.48550/arxiv.2108.08467,,,Medical Image Segmentation with 3D Convolutional Neural Networks: A  Survey,"Computer-aided medical image analysis plays a significant role in assisting
medical practitioners for expert clinical diagnosis and deciding the optimal
treatment plan. At present, convolutional neural networks (CNN) are the
preferred choice for medical image analysis. In addition, with the rapid
advancements in three-dimensional (3D) imaging systems and the availability of
excellent hardware and software support to process large volumes of data, 3D
deep learning methods are gaining popularity in medical image analysis. Here,
we present an extensive review of the recently evolved 3D deep learning methods
in medical image segmentation. Furthermore, the research gaps and future
directions in 3D medical image segmentation are discussed.",,,arXiv,,,2021-08-18,2021,,,,,,All OA; Green,Preprint,"Niyas, S; Pawan, S J; Kumar, M Anand; Rajan, Jeny","Niyas, S (); Pawan, S J (); Kumar, M Anand (); Rajan, Jeny ()",,"Niyas, S (); Pawan, S J (); Kumar, M Anand (); Rajan, Jeny ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1140549294,46 Information and Computing Sciences; 51 Physical Sciences; 5105 Medical and Biological Physics,
1125,pub.1150264316,10.48550/arxiv.2208.06643,,,Medical image analysis based on transformer: A Review,"The transformer has dominated the natural language processing (NLP) field for
a long time. Recently, the transformer-based method has been adopted into the
computer vision (CV) field and shows promising results. As an important branch
of the CV field, medical image analysis joins the wave of the transformer-based
method rightfully. In this review, we illustrate the principle of the attention
mechanism, and the detailed structures of the transformer, and depict how the
transformer is adopted into medical image analysis. We organize the
transformer-based medical image analysis applications in a sequence of
different tasks, including classification, segmentation, synthesis,
registration, localization, detection, captioning, and denoising. For the
mainstream classification and segmentation tasks, we further divided the
corresponding works based on different medical imaging modalities. The datasets
corresponding to the related works are also organized. We include thirteen
modalities and more than twenty objects in our work.",,,arXiv,,,2022-08-13,2022,,,,,,All OA; Green,Preprint,"Liu, Zhaoshan; Lv, Qiujie; Lee, Chau Hung; Shen, Lei","Liu, Zhaoshan (); Lv, Qiujie (); Lee, Chau Hung (); Shen, Lei ()",,"Liu, Zhaoshan (); Lv, Qiujie (); Lee, Chau Hung (); Shen, Lei ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150264316,46 Information and Computing Sciences; 4605 Data Management and Data Science,
1119,pub.1147138021,10.1016/j.neucom.2022.04.065,,,Medical image segmentation with 3D convolutional neural networks: A survey,"Computer-aided medical image analysis plays a significant role in assisting medical practitioners for expert clinical diagnosis and deciding the optimal treatment plan. At present, convolutional neural networks (CNNs) are the preferred choice for medical image analysis. In addition, with the rapid advancements in three-dimensional (3D) imaging systems and the availability of excellent hardware and software support to process large volumes of data, 3D deep learning methods are gaining popularity in medical image analysis. Here, we present an extensive review of the recently proposed 3D deep learning methods for medical image segmentation. Furthermore, the research gaps and future directions in 3D medical image segmentation are discussed.",,,Neurocomputing,,,2022-07,2022,,2022-07,493,,397-413,All OA; Green,Article,"Niyas, S.; Pawan, S.J.; Kumar, M. Anand; Rajan, Jeny","Niyas, S. (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangalore â 575025, Karnataka, India); Pawan, S.J. (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangalore â 575025, Karnataka, India); Kumar, M. Anand (Department of Information Technology, National Institute of Technology Karnataka, Surathkal, Mangalore â 575025, Karnataka, India); Rajan, Jeny (Department of Computer Science and Engineering, National Institute of Technology Karnataka, Surathkal, Mangalore â 575025, Karnataka, India)","Niyas, S. (National Institute of Technology Karnataka)","Niyas, S. (National Institute of Technology Karnataka); Pawan, S.J. (National Institute of Technology Karnataka); Kumar, M. Anand (National Institute of Technology Karnataka); Rajan, Jeny (National Institute of Technology Karnataka)",10,10,,,http://arxiv.org/pdf/2108.08467,https://app.dimensions.ai/details/publication/pub.1147138021,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
989,pub.1141558241,10.48550/arxiv.2109.14956,,,Comparative Validation of Machine Learning Algorithms for Surgical  Workflow and Skill Analysis with the HeiChole Benchmark,"PURPOSE: Surgical workflow and skill analysis are key technologies for the
next generation of cognitive surgical assistance systems. These systems could
increase the safety of the operation through context-sensitive warnings and
semi-autonomous robotic assistance or improve training of surgeons via
data-driven feedback. In surgical workflow analysis up to 91% average precision
has been reported for phase recognition on an open data single-center dataset.
In this work we investigated the generalizability of phase recognition
algorithms in a multi-center setting including more difficult recognition tasks
such as surgical action and surgical skill. METHODS: To achieve this goal, a
dataset with 33 laparoscopic cholecystectomy videos from three surgical centers
with a total operation time of 22 hours was created. Labels included annotation
of seven surgical phases with 250 phase transitions, 5514 occurences of four
surgical actions, 6980 occurences of 21 surgical instruments from seven
instrument categories and 495 skill classifications in five skill dimensions.
The dataset was used in the 2019 Endoscopic Vision challenge, sub-challenge for
surgical workflow and skill analysis. Here, 12 teams submitted their machine
learning algorithms for recognition of phase, action, instrument and/or skill
assessment. RESULTS: F1-scores were achieved for phase recognition between
23.9% and 67.7% (n=9 teams), for instrument presence detection between 38.5%
and 63.8% (n=8 teams), but for action recognition only between 21.8% and 23.3%
(n=5 teams). The average absolute error for skill assessment was 0.78 (n=1
team). CONCLUSION: Surgical workflow and skill analysis are promising
technologies to support the surgical team, but are not solved yet, as shown by
our comparison of algorithms. This novel benchmark can be used for comparable
evaluation and validation of future work.",,,arXiv,,,2021-09-30,2021,,,,,,All OA; Green,Preprint,"Wagner, Martin; MÃ¼ller-Stich, Beat-Peter; Kisilenko, Anna; Tran, Duc; Heger, Patrick; MÃ¼ndermann, Lars; Lubotsky, David M; MÃ¼ller, Benjamin; Davitashvili, Tornike; Capek, Manuela; Reinke, Annika; Yu, Tong; Vardazaryan, Armine; Nwoye, Chinedu Innocent; Padoy, Nicolas; Liu, Xinyang; Lee, Eung-Joo; Disch, Constantin; Meine, Hans; Xia, Tong; Jia, Fucang; Kondo, Satoshi; Reiter, Wolfgang; Jin, Yueming; Long, Yonghao; Jiang, Meirui; Dou, Qi; Heng, Pheng Ann; Twick, Isabell; Kirtac, Kadir; Hosgor, Enes; Bolmgren, Jon LindstrÃ¶m; Stenzel, Michael; von Siemens, BjÃ¶rn; Kenngott, Hannes G.; Nickel, Felix; von Frankenberg, Moritz; Mathis-Ullrich, Franziska; Maier-Hein, Lena; Speidel, Stefanie; Bodenstedt, Sebastian","Wagner, Martin (); MÃ¼ller-Stich, Beat-Peter (); Kisilenko, Anna (); Tran, Duc (); Heger, Patrick (); MÃ¼ndermann, Lars (); Lubotsky, David M (); MÃ¼ller, Benjamin (); Davitashvili, Tornike (); Capek, Manuela (); Reinke, Annika (); Yu, Tong (); Vardazaryan, Armine (); Nwoye, Chinedu Innocent (); Padoy, Nicolas (); Liu, Xinyang (); Lee, Eung-Joo (); Disch, Constantin (); Meine, Hans (); Xia, Tong (); Jia, Fucang (); Kondo, Satoshi (); Reiter, Wolfgang (); Jin, Yueming (); Long, Yonghao (); Jiang, Meirui (); Dou, Qi (); Heng, Pheng Ann (); Twick, Isabell (); Kirtac, Kadir (); Hosgor, Enes (); Bolmgren, Jon LindstrÃ¶m (); Stenzel, Michael (); von Siemens, BjÃ¶rn (); Kenngott, Hannes G. (); Nickel, Felix (); von Frankenberg, Moritz (); Mathis-Ullrich, Franziska (); Maier-Hein, Lena (); Speidel, Stefanie (); Bodenstedt, Sebastian ()",,"Wagner, Martin (); MÃ¼ller-Stich, Beat-Peter (); Kisilenko, Anna (); Tran, Duc (); Heger, Patrick (); MÃ¼ndermann, Lars (); Lubotsky, David M (); MÃ¼ller, Benjamin (); Davitashvili, Tornike (); Capek, Manuela (); Reinke, Annika (); Yu, Tong (); Vardazaryan, Armine (); Nwoye, Chinedu Innocent (); Padoy, Nicolas (); Liu, Xinyang (); Lee, Eung-Joo (); Disch, Constantin (); Meine, Hans (); Xia, Tong (); Jia, Fucang (); Kondo, Satoshi (); Reiter, Wolfgang (); Jin, Yueming (); Long, Yonghao (); Jiang, Meirui (); Dou, Qi (); Heng, Pheng Ann (); Twick, Isabell (); Kirtac, Kadir (); Hosgor, Enes (); Bolmgren, Jon LindstrÃ¶m (); Stenzel, Michael (); von Siemens, BjÃ¶rn (); Kenngott, Hannes G. (); Nickel, Felix (); von Frankenberg, Moritz (); Mathis-Ullrich, Franziska (); Maier-Hein, Lena (); Speidel, Stefanie (); Bodenstedt, Sebastian ()",3,3,,2.72,,https://app.dimensions.ai/details/publication/pub.1141558241,46 Information and Computing Sciences; 4608 Human-Centred Computing,
919,pub.1151848478,10.48550/arxiv.2210.05952,,,3D Brain and Heart Volume Generative Models: A Survey,"Generative models such as generative adversarial networks and autoencoders
have gained a great deal of attention in the medical field due to their
excellent data generation capability. This paper provides a comprehensive
survey of generative models for three-dimensional (3D) volumes, focusing on the
brain and heart. A new and elaborate taxonomy of unconditional and conditional
generative models is proposed to cover diverse medical tasks for the brain and
heart: unconditional synthesis, classification, conditional synthesis,
segmentation, denoising, detection, and registration. We provide relevant
background, examine each task and also suggest potential future directions. A
list of the latest publications will be updated on Github to keep up with the
rapid influx of papers at
https://github.com/csyanbin/3D-Medical-Generative-Survey.",,,arXiv,,,2022-10-12,2022,,,,,,All OA; Green,Preprint,"Liu, Yanbin; Dwivedi, Girish; Boussaid, Farid; Bennamoun, Mohammed","Liu, Yanbin (); Dwivedi, Girish (); Boussaid, Farid (); Bennamoun, Mohammed ()",,"Liu, Yanbin (); Dwivedi, Girish (); Boussaid, Farid (); Bennamoun, Mohammed ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151848478,46 Information and Computing Sciences; 4611 Machine Learning,
754,pub.1139148412,10.48550/arxiv.2106.12864,,,A Systematic Collection of Medical Image Datasets for Deep Learning,"The astounding success made by artificial intelligence (AI) in healthcare and
other fields proves that AI can achieve human-like performance. However,
success always comes with challenges. Deep learning algorithms are
data-dependent and require large datasets for training. The lack of data in the
medical imaging field creates a bottleneck for the application of deep learning
to medical image analysis. Medical image acquisition, annotation, and analysis
are costly, and their usage is constrained by ethical restrictions. They also
require many resources, such as human expertise and funding. That makes it
difficult for non-medical researchers to have access to useful and large
medical data. Thus, as comprehensive as possible, this paper provides a
collection of medical image datasets with their associated challenges for deep
learning research. We have collected information of around three hundred
datasets and challenges mainly reported between 2013 and 2020 and categorized
them into four categories: head & neck, chest & abdomen, pathology & blood, and
``others''. Our paper has three purposes: 1) to provide a most up to date and
complete list that can be used as a universal reference to easily find the
datasets for clinical image analysis, 2) to guide researchers on the
methodology to test and evaluate their methods' performance and robustness on
relevant datasets, 3) to provide a ``route'' to relevant algorithms for the
relevant medical topics, and challenge leaderboards.",,,arXiv,,,2021-06-24,2021,,,,,,All OA; Green,Preprint,"Li, Johann; Zhu, Guangming; Hua, Cong; Feng, Mingtao; BasheerBennamoun; Li, Ping; Lu, Xiaoyuan; Song, Juan; Shen, Peiyi; Xu, Xu; Mei, Lin; Zhang, Liang; Shah, Syed Afaq Ali; Bennamoun, Mohammed","Li, Johann (); Zhu, Guangming (); Hua, Cong (); Feng, Mingtao (); BasheerBennamoun (); Li, Ping (); Lu, Xiaoyuan (); Song, Juan (); Shen, Peiyi (); Xu, Xu (); Mei, Lin (); Zhang, Liang (); Shah, Syed Afaq Ali (); Bennamoun, Mohammed ()",,"Li, Johann (); Zhu, Guangming (); Hua, Cong (); Feng, Mingtao (); BasheerBennamoun (); Li, Ping (); Lu, Xiaoyuan (); Song, Juan (); Shen, Peiyi (); Xu, Xu (); Mei, Lin (); Zhang, Liang (); Shah, Syed Afaq Ali (); Bennamoun, Mohammed ()",1,1,,0.83,,https://app.dimensions.ai/details/publication/pub.1139148412,46 Information and Computing Sciences; 4602 Artificial Intelligence,3 Good Health and Well Being
751,pub.1139041071,10.48550/arxiv.2106.09862,,,Medical Image Analysis on Left Atrial LGE MRI for Atrial Fibrillation  Studies: A Review,"Late gadolinium enhancement magnetic resonance imaging (LGE MRI) is commonly
used to visualize and quantify left atrial (LA) scars. The position and extent
of scars provide important information of the pathophysiology and progression
of atrial fibrillation (AF). Hence, LA scar segmentation and quantification
from LGE MRI can be useful in computer-assisted diagnosis and treatment
stratification of AF patients. Since manual delineation can be time-consuming
and subject to intra- and inter-expert variability, automating this computing
is highly desired, which nevertheless is still challenging and
under-researched.
  This paper aims to provide a systematic review on computing methods for LA
cavity, wall, scar and ablation gap segmentation and quantification from LGE
MRI, and the related literature for AF studies. Specifically, we first
summarize AF-related imaging techniques, particularly LGE MRI. Then, we review
the methodologies of the four computing tasks in detail, and summarize the
validation strategies applied in each task. Finally, the possible future
developments are outlined, with a brief survey on the potential clinical
applications of the aforementioned methods. The review shows that the research
into this topic is still in early stages. Although several methods have been
proposed, especially for LA segmentation, there is still large scope for
further algorithmic developments due to performance issues related to the high
variability of enhancement appearance and differences in image acquisition.",,,arXiv,,,2021-06-17,2021,,,,,,All OA; Green,Preprint,"Li, Lei; Zimmer, Veronika A.; Schnabel, Julia A.; Zhuang, Xiahai","Li, Lei (); Zimmer, Veronika A. (); Schnabel, Julia A. (); Zhuang, Xiahai ()",,"Li, Lei (); Zimmer, Veronika A. (); Schnabel, Julia A. (); Zhuang, Xiahai ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139041071,40 Engineering; 4003 Biomedical Engineering,
459,pub.1151856854,10.1007/978-3-031-18814-5,,,"Multiscale Multimodal Medical Imaging, Third International Workshop, MMMI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 22, 2022, Proceedings","This book constitutes the refereed proceedings of the Third International Workshop on Multiscale Multimodal Medical Imaging, MMMI 2022, held in conjunction with MICCAI 2022 in singapore, in September 2022. The 12 papers presented were carefully reviewed and selected from 18 submissions. The MMMI workshop aims to advance the state of the art in multi-scale multi-modal medical imaging, including algorithm development, implementation of methodology, and experimental studies. The papers focus on medical image analysis and machine learning, especially on machine learning methods for data fusion and multi-score learning.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13594,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1151856854,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
189,pub.1141326734,10.1007/978-3-030-87196-3,,,"Medical Image Computing and Computer Assisted Intervention â MICCAI 2021, 24th International Conference, Strasbourg, France, September 27âOctober 1, 2021, Proceedings, Part II","The eight-volume set LNCS 12901, 12902, 12903, 12904, 12905, 12906, 12907, and 12908 constitutes the refereed proceedings of the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2021, held in Strasbourg, France, in September/October 2021.* The 531 revised full papers presented were carefully reviewed and selected from 1630 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: image segmentation Part II: machine learning - self-supervised learning; machine learning - semi-supervised learning; and machine learning - weakly supervised learning Part III: machine learning - advances in machine learning theory; machine learning - attention models; machine learning - domain adaptation; machine learning - federated learning; machine learning - interpretability / explainability; and machine learning - uncertainty Part IV: image registration; image-guided interventions and surgery; surgical data science; surgical planning and simulation; surgical skill and work flow analysis; and surgical visualization and mixed, augmented and virtual reality Part V: computer aided diagnosis; integration of imaging with non-imaging biomarkers; and outcome/disease prediction Part VI: image reconstruction; clinical applications - cardiac; and clinical applications - vascular Part VII: clinical applications - abdomen; clinical applications - breast; clinical applications - dermatology; clinical applications - fetal imaging; clinical applications - lung; clinical applications - neuroimaging - brain development; clinical applications - neuroimaging - DWI and tractography; clinical applications - neuroimaging - functional brain networks; clinical applications - neuroimaging â others; and clinical applications - oncology Part VIII: clinical applications - ophthalmology; computational (integrative) pathology; modalities - microscopy; modalities - histopathology; and modalities - ultrasound *The conference was held virtually.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12902,,,All OA; Green,Edited Book,,,,,3,3,,2.46,https://link.springer.com/content/pdf/bfm%3A978-3-030-87196-3%2F1,https://app.dimensions.ai/details/publication/pub.1141326734,46 Information and Computing Sciences; 4611 Machine Learning,
140,pub.1153662504,10.1007/978-3-031-21014-3,,,"Machine Learning in Medical Imaging, 13th International Workshop, MLMI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Proceedings","This book constitutes the proceedings of the 13th International Workshop on Machine Learning in Medical Imaging, MLMI 2022, held in conjunction with MICCAI 2022, in Singapore, in September 2022. The 48 full papers presented in this volume were carefully reviewed and selected from 64 submissions. They focus on major trends and challenges in the above-mentioned area, aiming to identify new-cutting-edge techniques and their uses in medical imaging. Topics dealt with are: deep learning, generative adversarial learning, ensemble learning, sparse learning, multi-task learning, multi-view learning, manifold learning, and reinforcement learning, with their applications to medical image analysis, computer-aided detection and diagnosis, multi-modality fusion, image reconstruction, image retrieval, cellular image analysis, molecular imaging, digital pathology, etc.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13583,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1153662504,46 Information and Computing Sciences; 4611 Machine Learning,
111,pub.1142080756,10.1007/978-3-030-88010-1,,,"Pattern Recognition and Computer Vision, 4th Chinese Conference, PRCV 2021, Beijing, China, October 29 â November 1, 2021, Proceedings, Part III","The 4-volume set LNCS 13019, 13020, 13021 and 13022 constitutes the refereed proceedings of the 4th Chinese Conference on Pattern Recognition and Computer Vision, PRCV 2021, held in Beijing, China, in October-November 2021. The 201 full papers presented were carefully reviewed and selected from 513 submissions. The papers have been organized in the following topical sections: Object Detection, Tracking and Recognition; Computer Vision, Theories and Applications, Multimedia Processing and Analysis; Low-level Vision and Image Processing; Biomedical Image Processing and Analysis; Machine Learning, Neural Network and Deep Learning, and New Advances in Visual Perception and Understanding.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,13021,,,All OA; Green,Edited Book,,,,,1,1,,0.82,https://link.springer.com/content/pdf/bfm%3A978-3-030-88010-1%2F1,https://app.dimensions.ai/details/publication/pub.1142080756,46 Information and Computing Sciences; 4611 Machine Learning,
103,pub.1141302076,10.1007/978-3-030-87231-1,,,"Medical Image Computing and Computer Assisted Intervention â MICCAI 2021, 24th International Conference, Strasbourg, France, September 27âOctober 1, 2021, Proceedings, Part VI","The eight-volume set LNCS 12901, 12902, 12903, 12904, 12905, 12906, 12907, and 12908 constitutes the refereed proceedings of the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2021, held in Strasbourg, France, in September/October 2021.* The 531 revised full papers presented were carefully reviewed and selected from 1630 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: image segmentation Part II: machine learning - self-supervised learning; machine learning - semi-supervised learning; and machine learning - weakly supervised learning Part III: machine learning - advances in machine learning theory; machine learning - attention models; machine learning - domain adaptation; machine learning - federated learning; machine learning - interpretability / explainability; and machine learning - uncertainty Part IV: image registration; image-guided interventions and surgery; surgical data science; surgical planning and simulation; surgical skill and work flow analysis; and surgical visualization and mixed, augmented and virtual reality Part V: computer aided diagnosis; integration of imaging with non-imaging biomarkers; and outcome/disease prediction Part VI: image reconstruction; clinical applications - cardiac; and clinical applications - vascular Part VII: clinical applications - abdomen; clinical applications - breast; clinical applications - dermatology; clinical applications - fetal imaging; clinical applications - lung; clinical applications - neuroimaging - brain development; clinical applications - neuroimaging - DWI and tractography; clinical applications - neuroimaging - functional brain networks; clinical applications - neuroimaging â others; and clinical applications - oncology Part VIII: clinical applications - ophthalmology; computational (integrative) pathology; modalities - microscopy; modalities - histopathology; and modalities - ultrasound *The conference was held virtually.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12906,,,All OA; Green,Edited Book,,,,,1,1,,0.82,https://link.springer.com/content/pdf/bfm%3A978-3-030-87231-1%2F1,https://app.dimensions.ai/details/publication/pub.1141302076,46 Information and Computing Sciences; 4611 Machine Learning,
87,pub.1151032978,10.1007/978-3-031-16443-9,,,"Medical Image Computing and Computer Assisted Intervention â MICCAI 2022, 25th International Conference, Singapore, September 18â22, 2022, Proceedings, Part V","The eight-volume set LNCS 13431, 13432, 13433, 13434, 13435, 13436, 13437, and 13438 constitutes the refereed proceedings of the 25th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2022, which was held in Singapore in September 2022. The 574 revised full papers presented were carefully reviewed and selected from 1831 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: Brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; heart and lung imaging; dermatology; Part II: Computational (integrative) pathology; computational anatomy and physiology; ophthalmology; fetal imaging; Part III: Breast imaging; colonoscopy; computer aided diagnosis; Part IV: Microscopic image analysis; positron emission tomography; ultrasound imaging; video data analysis; image segmentation I; Part V: Image segmentation II; integration of imaging with non-imaging biomarkers; Part VI: Image registration; image reconstruction; Part VII: Image-Guided interventions and surgery; outcome and disease prediction; surgical data science; surgical planning and simulation; machine learning â domain adaptation and generalization; Part VIII: Machine learning â weakly-supervised learning; machine learning â model interpretation; machine learning â uncertainty; machine learning theory and methodologies.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13435,,,All OA; Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16443-9%2F1,https://app.dimensions.ai/details/publication/pub.1151032978,46 Information and Computing Sciences; 4611 Machine Learning,
86,pub.1150997048,10.1007/978-3-031-16431-6,,,"Medical Image Computing and Computer Assisted Intervention â MICCAI 2022, 25th International Conference, Singapore, September 18â22, 2022, Proceedings, Part I","The eight-volume set LNCS 13431, 13432, 13433, 13434, 13435, 13436, 13437, and 13438 constitutes the refereed proceedings of the 25th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2022, which was held in Singapore in September 2022. The 574 revised full papers presented were carefully reviewed and selected from 1831 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: Brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; heart and lung imaging; dermatology; Part II: Computational (integrative) pathology; computational anatomy and physiology; ophthalmology; fetal imaging; Part III: Breast imaging; colonoscopy; computer aided diagnosis; Part IV: Microscopic image analysis; positron emission tomography; ultrasound imaging; video data analysis; image segmentation I; Part V: Image segmentation II; integration of imaging with non-imaging biomarkers; Part VI: Image registration; image reconstruction; Part VII: Image-Guided interventions and surgery; outcome and disease prediction; surgical data science; surgical planning and simulation; machine learning â domain adaptation and generalization; Part VIII: Machine learning â weakly-supervised learning; machine learning â model interpretation; machine learning â uncertainty; machine learning theory and methodologies.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13431,,,All OA; Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16431-6%2F1,https://app.dimensions.ai/details/publication/pub.1150997048,46 Information and Computing Sciences; 4611 Machine Learning,
