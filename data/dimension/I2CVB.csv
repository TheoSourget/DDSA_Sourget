"About the data: Exported on Mar 06, 2023. Criteria: '""Computer-Aided Detection and diagnosis for prostate cancer based on mono and multi-parametric MRI: A review""' in full data. © 2023 Digital Science &amp; Research Solutions Inc. All rights reserved. Parts of this work may also be protected by copyright of content providers and other third parties, which together with all rights of Digital Science, user agrees not to violate. Redistribution / external use of this work (or parts thereof) is prohibited without prior written approval. Please contact info@dimensions.ai for further information.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rank,Publication ID,DOI,PMID,PMCID,Title,Abstract,Acknowledgements,Funding,Source title,Anthology title,MeSH terms,Publication Date,PubYear,Publication Date (online),Publication Date (print),Volume,Issue,Pagination,Open Access,Publication Type,Authors,Authors (Raw Affiliation),Corresponding Authors,Authors Affiliations,Times cited,Recent citations,RCR,FCR,Source Linkout,Dimensions URL,Fields of Research (ANZSRC 2020),Sustainable Development Goals
7589,pub.1135659711,10.1016/j.phro.2021.01.004,33898790,PMC8058024,Impact of neoadjuvant androgen deprivation therapy on magnetic resonance imaging features in prostate cancer before radiotherapy,"BACKGROUND AND PURPOSE: In locally advanced prostate cancer (PC), androgen deprivation therapy (ADT) in combination with whole prostate radiotherapy (RT) is the standard treatment. ADT affects the prostate as well as the tumour on multiparametric magnetic resonance imaging (MRI) with decreased PC conspicuity and impaired localisation of the prostate lesion. Image texture analysis has been suggested to be of aid in separating tumour from normal tissue. The aim of the study was to investigate the impact of ADT on baseline defined MRI features in prostate cancer with the goal to investigate if it might be of use in radiotherapy planning.
MATERIALS AND METHODS: Fifty PC patients were included. Multiparametric MRI was performed before, and three months after ADT. At baseline, a tumour volume was delineated on apparent diffusion coefficient (ADC) maps with suspected tumour content and a reference volume in normal prostatic tissue. These volumes were transferred to MRIs after ADT and were analysed with first-order -and invariant Haralick -features.
RESULTS: At baseline, the median value and several of the invariant Haralick features of ADC, showed a significant difference between tumour and reference volumes. After ADT, only ADC median value could significantly differentiate the two volumes.
CONCLUSIONS: Invariant Haralick -features could not distinguish between baseline MRI defined PC and normal tissue after ADT. First-order median value remained significantly different in tumour and reference volumes after ADT, but the difference was less pronounced than before ADT.",,,Physics and Imaging in Radiation Oncology,,,2021-01,2021,2021-02-24,2021-01,17,,117-123,All OA; Gold,Article,"Björeland, Ulrika; Nyholm, Tufve; Jonsson, Joakim; Skorpil, Mikael; Blomqvist, Lennart; Strandberg, Sara; Riklund, Katrine; Beckman, Lars; Thellenberg-Karlsson, Camilla","Björeland, Ulrika (Department of Radiation Sciences, Umeå University, Umeå, Sweden); Nyholm, Tufve (Department of Radiation Sciences, Umeå University, Umeå, Sweden); Jonsson, Joakim (Department of Radiation Sciences, Umeå University, Umeå, Sweden); Skorpil, Mikael (Department of Molecular Medicine and Surgery, Karolinska Institutet, Stockholm, Sweden); Blomqvist, Lennart (Department of Molecular Medicine and Surgery, Karolinska Institutet, Stockholm, Sweden); Strandberg, Sara (Department of Radiation Sciences, Umeå University, Umeå, Sweden); Riklund, Katrine (Department of Radiation Sciences, Umeå University, Umeå, Sweden); Beckman, Lars (Department of Radiation Sciences, Umeå University, Umeå, Sweden); Thellenberg-Karlsson, Camilla (Department of Radiation Sciences, Umeå University, Umeå, Sweden)","Björeland, Ulrika (Umeå University)","Björeland, Ulrika (Umeå University); Nyholm, Tufve (Umeå University); Jonsson, Joakim (Umeå University); Skorpil, Mikael (Karolinska Institute); Blomqvist, Lennart (Karolinska Institute); Strandberg, Sara (Umeå University); Riklund, Katrine (Umeå University); Beckman, Lars (Umeå University); Thellenberg-Karlsson, Camilla (Umeå University)",2,2,0.58,1.45,http://phiro.science/article/S240563162100004X/pdf,https://app.dimensions.ai/details/publication/pub.1135659711,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
7307,pub.1134835673,10.1097/md.0000000000023817,33545946,PMC7837946,Diagnostic accuracy of different computer-aided diagnostic systems for prostate cancer based on magnetic resonance imaging,"BACKGROUND: Computer-aided detection (CAD) system for accurate and automated prostate cancer (PCa) diagnosis have been developed, however, the diagnostic test accuracy of different CAD systems is still controversial. This systematic review aimed to assess the diagnostic accuracy of CAD systems based on magnetic resonance imaging for PCa.
METHODS: Cochrane library, PubMed, EMBASE and China Biology Medicine disc were systematically searched until March 2019 for original diagnostic studies. Two independent reviewers selected studies on CAD based on magnetic resonance imaging diagnosis of PCa and extracted the requisite data. Pooled sensitivity, specificity, and the area under the summary receiver operating characteristic curve were calculated to estimate the diagnostic accuracy of CAD system.
RESULTS: Fifteen studies involving 1945 patients were included in our analysis. The diagnostic meta-analysis showed that overall sensitivity of CAD system ranged from 0.47 to 1.00 and, specificity from 0.47 to 0.89. The pooled sensitivity of CAD system was 0.87 (95% CI: 0.76-0.94), pooled specificity 0.76 (95% CI: 0.62-0.85), and the area under curve (AUC) 0.89 (95% CI: 0.86-0.91). Subgroup analysis showed that the support vector machines produced the best AUC among the CAD classifiers, with sensitivity ranging from 0.87 to 0.92, and specificity from 0.47 to 0.95. Among different zones of prostate, CAD system produced the best AUC in the transitional zone than the peripheral zone and central gland; sensitivity ranged from 0.89 to 1.00, and specificity from 0.38 to 0.85.
CONCLUSIONS: CAD system can help improve the diagnostic accuracy of PCa especially using the support vector machines classifier. Whether the performance of the CAD system depends on the specific locations of the prostate needs further investigation.",,,Medicine,,"Diagnosis, Computer-Assisted; Humans; Magnetic Resonance Imaging; Male; Prostatic Neoplasms; Sensitivity and Specificity",2021-01-22,2021,2021-01-22,2021-01-22,100,3,e23817,All OA; Gold,Article,"Xing, Xiping; Zhao, Xinke; Wei, Huiping; Li, Yingdong","Xing, Xiping (Affiliated hospital of Gansu University of Chinese Medicine); Zhao, Xinke (Affiliated hospital of Gansu University of Chinese Medicine); Wei, Huiping (Affiliated hospital of Gansu University of Chinese Medicine); Li, Yingdong (Gansu University of Traditional Chinese Medicine, Lanzhou, China.)","Li, Yingdong (Gansu University of Traditional Chinese Medicine)","Xing, Xiping (); Zhao, Xinke (); Wei, Huiping (); Li, Yingdong (Gansu University of Traditional Chinese Medicine)",2,2,0.41,1.45,https://doi.org/10.1097/md.0000000000023817,https://app.dimensions.ai/details/publication/pub.1134835673,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
7019,pub.1092356840,10.1109/embc.2017.8037522,29060563,,Computer-Aided Detection for Prostate Cancer Detection Based on Multi-Parametric Magnetic Resonance Imaging,"Prostate cancer (CaP) is the second most diagnosed cancer in men all over the world. In the last decades, new imaging techniques based on magnetic resonance imaging (MRI) have been developed improving diagnosis. In practice, diagnosis is affected by multiple factors such as observer variability and visibility and complexity of the lesions. In this regard, computer-aided detection and diagnosis (CAD) systems are being designed to help radiologists in their clinical practice. We propose a CAD system taking advantage of all MRI modalities (i.e., T2-W-MRI, DCE-MRI, diffusion weighted (DW)-MRI, MRSI). The aim of this CAD system was to provide a probabilistic map of cancer location in the prostate. We extensively tested our proposed CAD using different fusion approaches to combine the features provided by each modality. The source code and the dataset have been released.",,,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),Contrast Media; Humans; Magnetic Resonance Imaging; Male; Prostatic Neoplasms,2017-07,2017,,2017-07,2017,,3138-3141,All OA; Green,Proceeding,"Lemaître, Guillaume; Martí, Robert; Rastgoo, Mojdeh; Mériaudeau, Fabrice","Lemaître, Guillaume (Parietal team, Inria, CEA, Université Paris-Saclay, 1 Rue Honoré d'Estienne d'Orves, 91120, Palaiseau); Martí, Robert (ViCOROB, Universitat de Girona, Campus Montilivi, Edifici P4, 17071, Girona); Rastgoo, Mojdeh (LE2I UMR6306, CNRS, Arts et Métiers, Univ. Bourgogne Franche-Comté, 12 rue de la Fonderie, 71200, Le Creusot); Mériaudeau, Fabrice (CISIR, Electrical & Electronic Engineering Department, Universiti Teknologi PETRONAS, 32610, Seri Iskandar, Perak)","Mériaudeau, Fabrice ","Lemaître, Guillaume (); Martí, Robert (University of Girona); Rastgoo, Mojdeh (Université Bourgogne Franche-Comté); Mériaudeau, Fabrice ()",30,14,0.59,7.54,https://hal.inria.fr/hal-01516245/file/root%20%281%29.pdf,https://app.dimensions.ai/details/publication/pub.1092356840,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
6864,pub.1084499028,10.1109/embc.2016.7591981,28269511,,Enhanced Dual-Stage Correlated Diffusion Imaging,"Prostate cancer is the most common form of cancer and third leading cause of cancer death in Canadian men. Multi-parametric magnetic resonance imaging (mpMRI) has become a powerful non-invasive diagnostic tool for the detection of prostate cancer. Among mpMRI imaging modalities, diffusion-weighed imaging has shown the most promising results in accurate detection of prostate cancer. Introduced recently, correlated diffusion imaging (CDI) is a new form of diffusion imaging which accounts for the joint correlation of diffusion signal attenuation across multiple gradient pulse strengths and timings to improve the separability of cancerous and healthy tissues. Dual-stage CDI (D-CDI) is a newer generation of CDI where in contrast to CDI that does not capture anatomical information, an additional signal mixing stage between the correlated diffusion signal from the first signal mixing stage (CDI) and an auxiliary diffusion signal is performed to incorporate anatomical context. The core of D-CDI is a signal mixing algorithm that combines diffusion images at different b values to construct a single image. In this paper, we enhance the signal mixing algorithm to optimize the contribution of each single b-value image to maximize the separability of cancerous and healthy tissues. We evaluated the enhanced D-CDI (eD-CDI) using area under the ROC curve for datasets of 17 patient cases with confirmed prostate cancer and the results show that eD-CDI outperforms the original D-CDI as well as T2 weighted images and diffusion-weighed images used in the form of apparent diffusion coefficient maps.","This work was partially supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) Ontario Institute of Cancer Research (OICR), and Cancer Care Ontario (CCO)-Imaging Network of Ontario (CINO).",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"Aged; Aged, 80 and over; Algorithms; Diffusion Magnetic Resonance Imaging; Humans; Image Interpretation, Computer-Assisted; Male; Middle Aged; Prostate; Prostatic Neoplasms; ROC Curve",2016-08,2016,,2016-08,2016,,5537-5540,Closed,Proceeding,"Khalvati, Farzad; Zhang, Junjie; Haider, Masoom A.; Wong, Alexander","Khalvati, Farzad (Department of Medical Imaging, University of Toronto, Sunnybrook Research Institute, Toronto, Ontario, Canada, M4N 3M5); Zhang, Junjie (Department of Medical Imaging, University of Toronto, Sunnybrook Research Institute, Toronto, Ontario, Canada, M4N 3M5); Haider, Masoom A. (Department of Medical Imaging, University of Toronto, Sunnybrook Research Institute, Toronto, Ontario, Canada, M4N 3M5); Wong, Alexander (Department of Medical Imaging, University of Toronto, Sunnybrook Research Institute, Toronto, Ontario, Canada, M4N 3M5)",,"Khalvati, Farzad (University of Toronto); Zhang, Junjie (University of Toronto); Haider, Masoom A. (University of Toronto); Wong, Alexander (University of Toronto)",3,1,0.11,0.7,,https://app.dimensions.ai/details/publication/pub.1084499028,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
6846,pub.1121562897,10.1109/embc.2019.8856927,31946451,,Differentiating Cancerous and Non-cancerous Prostate Tissue Using Multi-scale Texture Analysis on MRI,"Prostate cancer (PCa) diagnosis is established by pathological examination via biopsies, which are associated with significant complications and false negatives. Using MRIs to identify locations with high probability of containing cancer could instead be used to guide the biopsy procedure. The present investigation aims to identify target regions within different prostatic zones on MRI with high probability of being cancerous for assisting in the decision of where and how to perform biopsy. Our approach involved extracting multi-scale texture features for capturing local patterns to distinguish cancer and healthy tissue in different T2W-MRI prostate zones. Three different classification models were fed by the proposed strategy, namely support vector machine (SVM), Adaboost, and Random Forest. SVM with a linear kernel showed the best classification performance, with AUC scores of 0.91 in the anterior fibromuscular stroma area, 0.85 in the peripheral zone, and 0.87 when classification is performed independently of the prostate zone. The proposed method demonstrated that discriminant multi-scale texture features can accurately identify regions of prostate cancer in a zone-specific fashion, via MRI.","An special acknowledgement to SPIE, the AAPM, the NCI, and Radboud University for providing the data used in this work. Research reported in this publication was supported by the DOD Peer Reviewed Cancer Research Program W81XWH-16-1-0329, the National Cancer Institute of the National Institutes of Health under award number R01CA208236-01A1, the Cleveland Digestive Diseases Research Core Center, and the NIH/NIDDK 1P30DK097948 DDRCC Pilot/Feasibility Award Program. An special acknowledgement to SPIE, the AAPM, the NCI, and Radboud University for providing the data used in this work. Research reported in this publication was supported by the DOD Peer Reviewed Cancer Research Program W81XWH-16-1-0329, the National Cancer Institute of the National Institutes of Health under award number R01CA208236-01A1, the Cleveland Digestive Diseases Research Core Center, and the NIH/NIDDK 1P30DK097948 DDRCC Pilot/Feasibility Award Program.",,Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),Biopsy; Humans; Magnetic Resonance Imaging; Male; Prostatic Neoplasms; Support Vector Machine,2019-07,2019,,2019-07,00,,2695-2698,Closed,Proceeding,"Alvarez-Jimenez, Charlems; Barrera, Cristian; Munera, Nicolás; Viswanath, Satish E.; Romero, Eduardo","Alvarez-Jimenez, Charlems (Computer Imaging and Medical Applications Laboratory – CIM@LAB at Universidad Nacional de Colombia, Bogotá, Colombia); Barrera, Cristian (Computer Imaging and Medical Applications Laboratory – CIM@LAB at Universidad Nacional de Colombia, Bogotá, Colombia); Munera, Nicolás (Computer Imaging and Medical Applications Laboratory – CIM@LAB at Universidad Nacional de Colombia, Bogotá, Colombia); Viswanath, Satish E. (Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States of America); Romero, Eduardo (Computer Imaging and Medical Applications Laboratory – CIM@LAB at Universidad Nacional de Colombia, Bogotá, Colombia)","Romero, Eduardo (National University of Colombia)","Alvarez-Jimenez, Charlems (National University of Colombia); Barrera, Cristian (National University of Colombia); Munera, Nicolás (National University of Colombia); Viswanath, Satish E. (Case Western Reserve University); Romero, Eduardo (National University of Colombia)",3,3,0.15,1.06,,https://app.dimensions.ai/details/publication/pub.1121562897,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
6804,pub.1125858433,10.1109/tuffc.2020.2983099,32217475,,Synthetic Elastography Using B-Mode Ultrasound Through a Deep Fully Convolutional Neural Network,"Shear-wave elastography (SWE) permits local estimation of tissue elasticity, an important imaging marker in biomedicine. This recently developed, advanced technique assesses the speed of a laterally traveling shear wave after an acoustic radiation force ""push"" to estimate local Young's moduli in an operator-independent fashion. In this work, we show how synthetic SWE (sSWE) images can be generated based on conventional B-mode imaging through deep learning. Using side-by-side-view B-mode/SWE images collected in 50 patients with prostate cancer, we show that sSWE images with a pixel-wise mean absolute error of 4.5 ± 0.96 kPa with regard to the original SWE can be generated. Visualization of high-level feature levels through t -distributed stochastic neighbor embedding reveals substantial overlap between data from two different scanners. Qualitatively, we examined the use of the sSWE methodology for B-mode images obtained with a scanner without SWE functionality. We also examined the use of this type of network in elasticity imaging in the thyroid. Limitations of the technique reside in the fact that networks have to be retrained for different organs, and that the method requires standardization of the imaging settings and procedure. Future research will be aimed at the development of sSWE as an elasticity-related tissue typing strategy that is solely based on B-mode ultrasound acquisition, and the examination of its clinical utility.","This work was supported in part by the Dutch Cancer Society under Grant UVA2013-5941, in part by the European Research Council Starting Grant under Grant 280209, and in part by the framework of the IMPULS2-Program within the Eindhoven University of Technology in collaboration with Philips.",,IEEE Transactions on Ultrasonics Ferroelectrics and Frequency Control,,"Deep Learning; Elasticity Imaging Techniques; Humans; Image Processing, Computer-Assisted; Thyroid Gland",2020-11-24,2020,2020-11-24,2020-12,67,12,2640-2648,All OA; Green,Article,"Wildeboer, R. R.; van Sloun, R. J. G.; Mannaerts, C. K.; Moraes, P. H.; Salomon, G.; Chammas, M. C.; Wijkstra, H.; Mischi, M.","Wildeboer, R. R. (Laboratory of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, 5612, AZ Eindhoven, The Netherlands); van Sloun, R. J. G. (Laboratory of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, 5612, AZ Eindhoven, The Netherlands); Mannaerts, C. K. (Department of Urology, Academic University Medical Center, University of Amsterdam, 1105, AZ Amsterdam, The Netherlands); Moraes, P. H. (Department of Radiology, Hospital das Clínicas, Faculdade de Medicina, Universidade de São Paulo, São Paulo, 05403, Brazil); Salomon, G. (Department of Urology, University Hospital Hamburg-Eppendorf, 20246, Hamburg, Germany); Chammas, M. C. (Department of Radiology, Hospital das Clínicas, Faculdade de Medicina, Universidade de São Paulo, São Paulo, 05403, Brazil); Wijkstra, H. (Laboratory of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, 5612, AZ Eindhoven, The Netherlands; Department of Urology, Academic University Medical Center, University of Amsterdam, 1105, AZ Amsterdam, The Netherlands); Mischi, M. (Laboratory of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, 5612, AZ Eindhoven, The Netherlands)","Wildeboer, R. R. (Eindhoven University of Technology)","Wildeboer, R. R. (Eindhoven University of Technology); van Sloun, R. J. G. (Eindhoven University of Technology); Mannaerts, C. K. (University of Amsterdam); Moraes, P. H. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo); Salomon, G. (University Medical Center Hamburg-Eppendorf); Chammas, M. C. (Universidade de São Paulo; Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo); Wijkstra, H. (Eindhoven University of Technology; University of Amsterdam); Mischi, M. (Eindhoven University of Technology)",7,5,1.89,,https://pure.tue.nl/ws/files/191033800/Synthetic_Elastography_Using_B_Mode_Ultrasound_Through_a_Deep_Fully_Convolutional_Neural_Network.pdf,https://app.dimensions.ai/details/publication/pub.1125858433,40 Engineering,
6568,pub.1021380951,10.1007/s11307-016-1009-y,27734253,PMC5332060,A Novel Unsupervised Segmentation Approach Quantifies Tumor Tissue Populations Using Multiparametric MRI: First Results with Histological Validation,"PurposeWe aimed to precisely estimate intra-tumoral heterogeneity using spatially regularized spectral clustering (SRSC) on multiparametric MRI data and compare the efficacy of SRSC with the previously reported segmentation techniques in MRI studies.ProceduresSix NMRI nu/nu mice bearing subcutaneous human glioblastoma U87 MG tumors were scanned using a dedicated small animal 7T magnetic resonance imaging (MRI) scanner. The data consisted of T2 weighted images, apparent diffusion coefficient maps, and pre- and post-contrast T2 and T2* maps. Following each scan, the tumors were excised into 2–3-mm thin slices parallel to the axial field of view and processed for histological staining. The MRI data were segmented using SRSC, K-means, fuzzy C-means, and Gaussian mixture modeling to estimate the fractional population of necrotic, peri-necrotic, and viable regions and validated with the fractional population obtained from histology.ResultsWhile the aforementioned methods overestimated peri-necrotic and underestimated viable fractions, SRSC accurately predicted the fractional population of all three tumor tissue types and exhibited strong correlations (rnecrotic = 0.92, rperi-necrotic = 0.82 and rviable = 0.98) with the histology.ConclusionsThe precise identification of necrotic, peri-necrotic and viable areas using SRSC may greatly assist in cancer treatment planning and add a new dimension to MRI-guided tumor biopsy procedures.","The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under ERC grant agreement n°323196—ImageLink, German Ministry for Education and Research/Bundesministerium für Bildung und Forschung (BMBF), grant number 0316186E, and Eberhard Karls University Tuebingen (Evaluation of Tumor Heterogeneity Using Clustering of Multi-Modality Imaging Data, Fortuene 2131-0-0). We thank Dennis Thiele for the excellent histological work.",,Molecular Imaging and Biology,,"Algorithms; Animals; Biomarkers, Tumor; Cluster Analysis; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Mice, Nude; Neoplasms; Reproducibility of Results",2016-10-12,2016,2016-10-12,2017-06,19,3,391-397,All OA; Hybrid,Article,"Katiyar, Prateek; Divine, Mathew R.; Kohlhofer, Ursula; Quintanilla-Martinez, Leticia; Schölkopf, Bernhard; Pichler, Bernd J.; Disselhorst, Jonathan A.","Katiyar, Prateek (Werner Siemens Imaging Center, Department of Preclinical Imaging and Radiopharmacy, Eberhard Karls University Tuebingen, Roentgenweg 13, 72076, Tuebingen, Germany; Max Planck Institute for Intelligent Systems, Tuebingen, Germany); Divine, Mathew R. (Werner Siemens Imaging Center, Department of Preclinical Imaging and Radiopharmacy, Eberhard Karls University Tuebingen, Roentgenweg 13, 72076, Tuebingen, Germany); Kohlhofer, Ursula (Institute of Pathology and Neuropathology, Eberhard Karls University Tuebingen and Comprehensive Cancer Center, University Hospital Tuebingen, Tuebingen, Germany); Quintanilla-Martinez, Leticia (Institute of Pathology and Neuropathology, Eberhard Karls University Tuebingen and Comprehensive Cancer Center, University Hospital Tuebingen, Tuebingen, Germany); Schölkopf, Bernhard (Max Planck Institute for Intelligent Systems, Tuebingen, Germany); Pichler, Bernd J. (Werner Siemens Imaging Center, Department of Preclinical Imaging and Radiopharmacy, Eberhard Karls University Tuebingen, Roentgenweg 13, 72076, Tuebingen, Germany); Disselhorst, Jonathan A. (Werner Siemens Imaging Center, Department of Preclinical Imaging and Radiopharmacy, Eberhard Karls University Tuebingen, Roentgenweg 13, 72076, Tuebingen, Germany)","Katiyar, Prateek (University of Tübingen; Max Planck Institute for Intelligent Systems)","Katiyar, Prateek (University of Tübingen; Max Planck Institute for Intelligent Systems); Divine, Mathew R. (University of Tübingen); Kohlhofer, Ursula (Universitätsklinikum Tübingen); Quintanilla-Martinez, Leticia (Universitätsklinikum Tübingen); Schölkopf, Bernhard (Max Planck Institute for Intelligent Systems); Pichler, Bernd J. (University of Tübingen); Disselhorst, Jonathan A. (University of Tübingen)",12,2,0.62,2.42,https://link.springer.com/content/pdf/10.1007%2Fs11307-016-1009-y.pdf,https://app.dimensions.ai/details/publication/pub.1021380951,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis,
6394,pub.1125604701,10.3390/s20051539,32164378,PMC7085575,Radiomics Driven Diffusion Weighted Imaging Sensing Strategies for Zone-Level Prostate Cancer Sensing,"Prostate cancer is the most commonly diagnosed cancer in North American men; however, prognosis is relatively good given early diagnosis. This motivates the need for fast and reliable prostate cancer sensing. Diffusion weighted imaging (DWI) has gained traction in recent years as a fast non-invasive approach to cancer sensing. The most commonly used DWI sensing modality currently is apparent diffusion coefficient (ADC) imaging, with the recently introduced computed high-b value diffusion weighted imaging (CHB-DWI) showing considerable promise for cancer sensing. In this study, we investigate the efficacy of ADC and CHB-DWI sensing modalities when applied to zone-level prostate cancer sensing by introducing several radiomics driven zone-level prostate cancer sensing strategies geared around hand-engineered radiomic sequences from DWI sensing (which we term as Zone-X sensing strategies). Furthermore, we also propose Zone-DR, a discovery radiomics approach based on zone-level deep radiomic sequencer discovery that discover radiomic sequences directly for radiomics driven sensing. Experimental results using 12,466 pathology-verified zones obtained through the different DWI sensing modalities of 101 patients showed that: (i) the introduced Zone-X and Zone-DR radiomics driven sensing strategies significantly outperformed the traditional clinical heuristics driven strategy in terms of AUC, (ii) the introduced Zone-DR and Zone-SVM strategies achieved the highest sensitivity and specificity, respectively for ADC amongst the tested radiomics driven strategies, (iii) the introduced Zone-DR and Zone-LR strategies achieved the highest sensitivities for CHB-DWI amongst the tested radiomics driven strategies, and (iv) the introduced Zone-DR, Zone-LR, and Zone-SVM strategies achieved the highest specificities for CHB-DWI amongst the tested radiomics driven strategies. Furthermore, the results showed that the trade-off between sensitivity and specificity can be optimized based on the particular clinical scenario we wish to employ radiomic driven DWI prostate cancer sensing strategies for, such as clinical screening versus surgical planning. Finally, we investigate the critical regions within sensing data that led to a given radiomic sequence generated by a Zone-DR sequencer using an explainability method to get a deeper understanding on the biomarkers important for zone-level cancer sensing.","The authors would like to thank the Natural Sciences and Engineering Research Council of Canada (NSERC), the Canada Research Chairs program, and the Ontario Institute of Cancer Research (OICR).",This work is supported by Canada Research Chairs program and the Natural Sciences and Engineering Research Council of Canada (NSERC).,Sensors,,"Algorithms; Area Under Curve; Decision Trees; Diffusion Magnetic Resonance Imaging; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Male; Prostate; Prostatic Neoplasms; Regression Analysis; Sensitivity and Specificity; Support Vector Machine",2020-03-10,2020,2020-03-10,,20,5,1539,All OA; Gold,Article,"Dulhanty, Chris; Wang, Linda; Cheng, Maria; Gunraj, Hayden; Khalvati, Farzad; Haider, Masoom A.; Wong, Alexander","Dulhanty, Chris (Vision and Image Processing Research Group, University of Waterloo, Waterloo, ON N2L 3G1, Canada;, alexander.wong@uwaterloo.ca); Wang, Linda (Vision and Image Processing Research Group, University of Waterloo, Waterloo, ON N2L 3G1, Canada;, alexander.wong@uwaterloo.ca); Cheng, Maria (Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada;, maria.cheng@edu.uwaterloo.ca); Gunraj, Hayden (Department of Mechanical and Mechatronics Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada;, hayden.gunraj@uwaterloo.ca); Khalvati, Farzad (Lunenfeld-Tanenbaum Research Institute, Sinai Health System, Toronto, ON M5G 1X5, Canada;, farzad.khalvati@utoronto.ca, (F.K.);, m.haider@utoronto.ca, (M.A.H.)); Haider, Masoom A. (Lunenfeld-Tanenbaum Research Institute, Sinai Health System, Toronto, ON M5G 1X5, Canada;, farzad.khalvati@utoronto.ca, (F.K.);, m.haider@utoronto.ca, (M.A.H.)); Wong, Alexander (Vision and Image Processing Research Group, University of Waterloo, Waterloo, ON N2L 3G1, Canada;, alexander.wong@uwaterloo.ca; Waterloo Artificial Intelligence Institute, University of Waterloo, Waterloo, ON N2L 3G1, Canada)","Dulhanty, Chris (University of Waterloo); Wang, Linda (University of Waterloo)","Dulhanty, Chris (University of Waterloo); Wang, Linda (University of Waterloo); Cheng, Maria (University of Waterloo); Gunraj, Hayden (University of Waterloo); Khalvati, Farzad (Lunenfeld-Tanenbaum Research Institute); Haider, Masoom A. (Lunenfeld-Tanenbaum Research Institute); Wong, Alexander (University of Waterloo; University of Waterloo)",10,8,1.34,4.07,https://www.mdpi.com/1424-8220/20/5/1539/pdf?version=1583916034,https://app.dimensions.ai/details/publication/pub.1125604701,"40 Engineering; 4008 Electrical Engineering; 4009 Electronics, Sensors and Digital Hardware; 46 Information and Computing Sciences; 4606 Distributed Computing and Systems Software",3 Good Health and Well Being
6364,pub.1145408426,10.1136/bmjopen-2021-051274,35140147,PMC8830410,Detection of ISUP ≥2 prostate cancers using multiparametric MRI: prospective multicentre assessment of the non-inferiority of an artificial intelligence system as compared to the PI-RADS V.2.1 score (CHANGE study),"INTRODUCTION: Prostate multiparametric MRI (mpMRI) has shown good sensitivity in detecting cancers with an International Society of Urological Pathology (ISUP) grade of ≥2. However, it lacks specificity, and its inter-reader reproducibility remains moderate. Biomarkers, such as the Prostate Health Index (PHI), may help select patients for prostate biopsy. Computer-aided diagnosis/detection (CAD) systems may also improve mpMRI interpretation. Different prototypes of CAD systems are currently developed under the Recherche Hospitalo-Universitaire en Santé / Personalized Focused Ultrasound Surgery of Localized Prostate Cancer (RHU PERFUSE) research programme, tackling challenging issues such as robustness across imaging protocols and magnetic resonance (MR) vendors, and ability to characterise cancer aggressiveness. The study primary objective is to evaluate the non-inferiority of the area under the receiver operating characteristic curve of the final CAD system as compared with the Prostate Imaging-Reporting and Data System V.2.1 (PI-RADS V.2.1) in predicting the presence of ISUP ≥2 prostate cancer in patients undergoing prostate biopsy.
METHODS: This prospective, multicentre, non-inferiority trial will include 420 men with suspected prostate cancer, a prostate-specific antigen level of ≤30 ng/mL and a clinical stage ≤T2 c. Included men will undergo prostate mpMRI that will be interpreted using the PI-RADS V.2.1 score. Then, they will undergo systematic and targeted biopsy. PHI will be assessed before biopsy. At the end of patient inclusion, MR images will be assessed by the final version of the CAD system developed under the RHU PERFUSE programme. Key secondary outcomes include the prediction of ISUP grade ≥2 prostate cancer during a 3-year follow-up, and the number of biopsy procedures saved and ISUP grade ≥2 cancers missed by several diagnostic pathways combining PHI and MRI findings.
ETHICS AND DISSEMINATION: Ethical approval was obtained from the Comité de Protection des Personnes Nord Ouest III (ID-RCB: 2020-A02785-34). After publication of the results, access to MR images will be possible for testing other CAD systems.
TRIAL REGISTRATION NUMBER: NCT04732156.",,,BMJ Open,,Artificial Intelligence; Humans; Image-Guided Biopsy; Magnetic Resonance Imaging; Male; Multiparametric Magnetic Resonance Imaging; Prospective Studies; Prostatic Neoplasms; Reproducibility of Results; Retrospective Studies,2022-02-09,2022,2022-02-09,2022-02,12,2,e051274,All OA; Gold,Article,"Rouvière, Olivier; Souchon, Rémi; Lartizien, Carole; Mansuy, Adeline; Magaud, Laurent; Colom, Matthieu; Dubreuil-Chambardel, Marine; Debeer, Sabine; Jaouen, Tristan; Duran, Audrey; Rippert, Pascal; Riche, Benjamin; Monini, Caterina; Vlaeminck-Guillem, Virginie; Haesebaert, Julie; Rabilloud, Muriel; Crouzet, Sébastien","Rouvière, Olivier (Université Lyon 1, Université de Lyon, Lyon, France; Department of Urinary and Vascular Imaging, Hôpital Edouard Herriot, Hospices Civils de Lyon, Lyon, France; LabTau, INSERM U1032, Lyon, France); Souchon, Rémi (LabTau, INSERM U1032, Lyon, France); Lartizien, Carole (CREATIS, INSERM U1294, Villeurbanne, France; CNRS UMR 5220, INSA-Lyon, Villeurbanne, France); Mansuy, Adeline (Department of Urinary and Vascular Imaging, Hôpital Edouard Herriot, Hospices Civils de Lyon, Lyon, France); Magaud, Laurent (Service Recherche et Epidémiologie Cliniques, Pôle Santé Publique, Hospices Civils de Lyon, Lyon, France); Colom, Matthieu (Direction de la Recherche Clinique et de l'Innovation, Hospices Civils de Lyon, Lyon, France); Dubreuil-Chambardel, Marine (Department of Urinary and Vascular Imaging, Hôpital Edouard Herriot, Hospices Civils de Lyon, Lyon, France); Debeer, Sabine (Department of Urinary and Vascular Imaging, Hôpital Edouard Herriot, Hospices Civils de Lyon, Lyon, France); Jaouen, Tristan (LabTau, INSERM U1032, Lyon, France); Duran, Audrey (CREATIS, INSERM U1294, Villeurbanne, France; CNRS UMR 5220, INSA-Lyon, Villeurbanne, France); Rippert, Pascal (Service Recherche et Epidémiologie Cliniques, Pôle Santé Publique, Hospices Civils de Lyon, Lyon, France); Riche, Benjamin (Service de Biostatistique–Bioinformatique, Pôle Santé Publique, Hospices Civils de Lyon, Lyon, France; Laboratoire de Biométrie et Biologie Évolutive CNRS UMR 5558, Équipe Biostatistiques Santé, Université de Lyon, Lyon, France); Monini, Caterina (LabTau, INSERM U1032, Lyon, France); Vlaeminck-Guillem, Virginie (Université Lyon 1, Université de Lyon, Lyon, France; Service de Biochimie et Biologie Moléculaire Sud, Centre Hospitalier Lyon Sud, Hospices Civils de Lyon, Pierre Bénite, France); Haesebaert, Julie (Université Lyon 1, Université de Lyon, Lyon, France; Service Recherche et Epidémiologie Cliniques, Pôle Santé Publique, Hospices Civils de Lyon, Lyon, France; Research on Healthcare Performance (RESHAPE), INSERM U1290, Lyon, France); Rabilloud, Muriel (Université Lyon 1, Université de Lyon, Lyon, France; Service de Biostatistique–Bioinformatique, Pôle Santé Publique, Hospices Civils de Lyon, Lyon, France; Laboratoire de Biométrie et Biologie Évolutive CNRS UMR 5558, Équipe Biostatistiques Santé, Université de Lyon, Lyon, France); Crouzet, Sébastien (Université Lyon 1, Université de Lyon, Lyon, France; LabTau, INSERM U1032, Lyon, France; Department of Urology, Hôpital Edouard Herriot, Hospices Civils de Lyon, Lyon, France)","Rouvière, Olivier (University of Lyon System; Hôpital Édouard-Herriot; Laboratory of Therapeutic Applications of Ultrasound)","Rouvière, Olivier (University of Lyon System; Hôpital Édouard-Herriot; Laboratory of Therapeutic Applications of Ultrasound); Souchon, Rémi (Laboratory of Therapeutic Applications of Ultrasound); Lartizien, Carole (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé; Institut National des Sciences Appliquées de Lyon); Mansuy, Adeline (Hôpital Édouard-Herriot); Magaud, Laurent (Hospices Civils de Lyon); Colom, Matthieu (Hospices Civils de Lyon); Dubreuil-Chambardel, Marine (Hôpital Édouard-Herriot); Debeer, Sabine (Hôpital Édouard-Herriot); Jaouen, Tristan (Laboratory of Therapeutic Applications of Ultrasound); Duran, Audrey (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé; Institut National des Sciences Appliquées de Lyon); Rippert, Pascal (Hospices Civils de Lyon); Riche, Benjamin (Hospices Civils de Lyon; University of Lyon System); Monini, Caterina (Laboratory of Therapeutic Applications of Ultrasound); Vlaeminck-Guillem, Virginie (University of Lyon System; Centre Hospitalier Lyon Sud); Haesebaert, Julie (University of Lyon System; Hospices Civils de Lyon; Inserm); Rabilloud, Muriel (University of Lyon System; Hospices Civils de Lyon; University of Lyon System); Crouzet, Sébastien (University of Lyon System; Laboratory of Therapeutic Applications of Ultrasound; Hôpital Édouard-Herriot)",1,1,,,https://bmjopen.bmj.com/content/bmjopen/12/2/e051274.full.pdf,https://app.dimensions.ai/details/publication/pub.1145408426,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
6350,pub.1141632568,10.3390/diagnostics11101829,34679527,PMC8534893,Multiparametric MRI and Radiomics in Prostate Cancer: A Review of the Current Literature,"Prostate cancer (PCa) represents the fourth most common cancer and the fifth leading cause of cancer death of men worldwide. Multiparametric MRI (mp-MRI) has high sensitivity and specificity in the detection of PCa, and it is currently the most widely used imaging technique for tumor localization and cancer staging. mp-MRI plays a key role in risk stratification of naïve patients, in active surveillance for low-risk patients, and in monitoring recurrence after definitive therapy. Radiomics is an emerging and promising tool which allows a quantitative tumor evaluation from radiological images via conversion of digital images into mineable high-dimensional data. The purpose of radiomics is to increase the features available to detect PCa, to avoid unnecessary biopsies, to define tumor aggressiveness, and to monitor post-treatment recurrence of PCa. The integration of radiomics data, including different imaging modalities (such as PET-CT) and other clinical and histopathological data, could improve the prediction of tumor aggressiveness as well as guide clinical decisions and patient management. The purpose of this review is to describe the current research applications of radiomics in PCa on MR images.",We thank Sebastian Faby and Margherita Milite from Siemens Healthineers for their support with the radiomics research software.,,Diagnostics,,,2021-10-03,2021,2021-10-03,,11,10,1829,All OA; Gold,Article,"Midiri, Federico; Vernuccio, Federica; Purpura, Pierpaolo; Alongi, Pierpaolo; Bartolotta, Tommaso Vincenzo","Midiri, Federico (Section of Radiology—BiND, University Hospital “Paolo Giaccone”, 90127 Palermo, Italy;, federicavernuccio@gmail.com, (F.V.);, tommasovincenzo.bartolotta@unipa.it, (T.V.B.)); Vernuccio, Federica (Section of Radiology—BiND, University Hospital “Paolo Giaccone”, 90127 Palermo, Italy;, federicavernuccio@gmail.com, (F.V.);, tommasovincenzo.bartolotta@unipa.it, (T.V.B.)); Purpura, Pierpaolo (Department of Radiology, Fondazione Istituto “Giuseppe Giglio”, Ct.da Pietrapollastra, Via Pisciotto, Cefalù, 90015 Palermo, Italy;, pierpaolopurpura@gmail.com); Alongi, Pierpaolo (Nuclear Medicine Unit, Fondazione Istituto “Giuseppe Giglio”, Ct.da Pietrapollastra, Via Pisciotto, Cefalù, 90015 Palermo, Italy;, alongi.pierpaolo@gmail.com); Bartolotta, Tommaso Vincenzo (Section of Radiology—BiND, University Hospital “Paolo Giaccone”, 90127 Palermo, Italy;, federicavernuccio@gmail.com, (F.V.);, tommasovincenzo.bartolotta@unipa.it, (T.V.B.); Department of Radiology, Fondazione Istituto “Giuseppe Giglio”, Ct.da Pietrapollastra, Via Pisciotto, Cefalù, 90015 Palermo, Italy;, pierpaolopurpura@gmail.com)","Midiri, Federico ","Midiri, Federico (); Vernuccio, Federica (); Purpura, Pierpaolo (); Alongi, Pierpaolo (); Bartolotta, Tommaso Vincenzo ()",5,5,0.83,3.62,https://www.mdpi.com/2075-4418/11/10/1829/pdf?version=1633254031,https://app.dimensions.ai/details/publication/pub.1141632568,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
6346,pub.1144815053,10.3389/fonc.2021.792456,35127499,PMC8810653,MRI Based Radiomics Compared With the PI-RADS V2.1 in the Prediction of Clinically Significant Prostate Cancer: Biparametric vs Multiparametric MRI,"PURPOSE: To compare the performance of radiomics to that of the Prostate Imaging Reporting and Data System (PI-RADS) v2.1 scoring system in the detection of clinically significant prostate cancer (csPCa) based on biparametric magnetic resonance imaging (bpMRI) vs. multiparametric MRI (mpMRI).
METHODS: A total of 204 patients with pathological results were enrolled between January 2018 and December 2019, with 142 patients in the training cohort and 62 patients in the testing cohort. The radiomics model was compared with the PI-RADS v2.1 for the diagnosis of csPCa based on bpMRI and mpMRI by using receiver operating characteristic (ROC) curve analysis.
RESULTS: The radiomics model based on bpMRI and mpMRI signatures showed high predictive efficiency but with no significant differences (AUC = 0.975 vs 0.981, p=0.687 in the training cohort, and 0.953 vs 0.968, p=0.287 in the testing cohort, respectively). In addition, the radiomics model outperformed the PI-RADS v2.1 in the diagnosis of csPCa regardless of whether bpMRI (AUC = 0.975 vs. 0.871, p= 0.030 for the training cohort and AUC = 0.953 vs. 0.853, P = 0.024 for the testing cohort) or mpMRI (AUC = 0.981 vs. 0.880, p= 0.030 for the training cohort and AUC = 0.968 vs. 0.863, P = 0.016 for the testing cohort) was incorporated.
CONCLUSIONS: Our study suggests the performance of bpMRI- and mpMRI-based radiomics models show no significant difference, which indicates that omitting DCE imaging in radiomics can simplify the process of analysis. Adding radiomics to PI-RADS v2.1 may improve the performance to predict csPCa.",We thank AJE Editing Service for editing this manuscript.,,Frontiers in Oncology,,,2022-01-20,2022,2022-01-20,,11,,792456,All OA; Gold,Article,"Chen, Tong; Zhang, Zhiyuan; Tan, Shuangxiu; Zhang, Yueyue; Wei, Chaogang; Wang, Shan; Zhao, Wenlu; Qian, Xusheng; Zhou, Zhiyong; Shen, Junkang; Dai, Yakang; Hu, Jisu","Chen, Tong (Department of Radiology, The Second Affiliated Hospital of Soochow University, Suzhou, China); Zhang, Zhiyuan (School of Medical Imaging, Biomedical Engineering, Xuzhou Medical University, Xuzhou, China); Tan, Shuangxiu (Department of Radiology, The Second Affiliated Hospital of Soochow University, Suzhou, China; Department of Ultrasound, Nanjing Drum Tower Hospital, Nanjing Medical School, Nanjing, China); Zhang, Yueyue (Department of Radiology, The Second Affiliated Hospital of Soochow University, Suzhou, China); Wei, Chaogang (Department of Radiology, The Second Affiliated Hospital of Soochow University, Suzhou, China); Wang, Shan (Department of Radiology, Jiangsu Jiangyin People’s Hospital, Jiangyin, China); Zhao, Wenlu (Department of Radiology, The Second Affiliated Hospital of Soochow University, Suzhou, China); Qian, Xusheng (Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China; School of Biomedical Engineering (Suzhou), Division of Life Sciences and Medicine, University of Science and Technology of China, Suzhou, China); Zhou, Zhiyong (Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China); Shen, Junkang (Department of Radiology, The Second Affiliated Hospital of Soochow University, Suzhou, China; Institute of Imaging Medicine, Soochow University, Suzhou, China); Dai, Yakang (Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China); Hu, Jisu (Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China; School of Biomedical Engineering (Suzhou), Division of Life Sciences and Medicine, University of Science and Technology of China, Suzhou, China)","Shen, Junkang (Second Affiliated Hospital of Soochow University; Soochow University); Dai, Yakang (Suzhou Institute of Biomedical Engineering and Technology); Hu, Jisu (Suzhou Institute of Biomedical Engineering and Technology; University of Science and Technology of China)","Chen, Tong (Second Affiliated Hospital of Soochow University); Zhang, Zhiyuan (Xuzhou Medical College); Tan, Shuangxiu (Second Affiliated Hospital of Soochow University; Nanjing Drum Tower Hospital); Zhang, Yueyue (Second Affiliated Hospital of Soochow University); Wei, Chaogang (Second Affiliated Hospital of Soochow University); Wang, Shan (Jiangyin People's Hospital); Zhao, Wenlu (Second Affiliated Hospital of Soochow University); Qian, Xusheng (Suzhou Institute of Biomedical Engineering and Technology; University of Science and Technology of China); Zhou, Zhiyong (Suzhou Institute of Biomedical Engineering and Technology); Shen, Junkang (Second Affiliated Hospital of Soochow University; Soochow University); Dai, Yakang (Suzhou Institute of Biomedical Engineering and Technology); Hu, Jisu (Suzhou Institute of Biomedical Engineering and Technology; University of Science and Technology of China)",3,3,,,https://www.frontiersin.org/articles/10.3389/fonc.2021.792456/pdf,https://app.dimensions.ai/details/publication/pub.1144815053,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
6167,pub.1141180276,10.3390/diagnostics11091690,34574031,PMC8471645,The Reproducibility of Deep Learning-Based Segmentation of the Prostate Gland and Zones on T2-Weighted MR Images,"Volume of interest segmentation is an essential step in computer-aided detection and diagnosis (CAD) systems. Deep learning (DL)-based methods provide good performance for prostate segmentation, but little is known about the reproducibility of these methods. In this work, an in-house collected dataset from 244 patients was used to investigate the intra-patient reproducibility of 14 shape features for DL-based segmentation methods of the whole prostate gland (WP), peripheral zone (PZ), and the remaining prostate zones (non-PZ) on T2-weighted (T2W) magnetic resonance (MR) images compared to manual segmentations. The DL-based segmentation was performed using three different convolutional neural networks (CNNs): V-Net, nnU-Net-2D, and nnU-Net-3D. The two-way random, single score intra-class correlation coefficient (ICC) was used to measure the inter-scan reproducibility of each feature for each CNN and the manual segmentation. We found that the reproducibility of the investigated methods is comparable to manual for all CNNs (14/14 features), except for V-Net in PZ (7/14 features). The ICC score for segmentation volume was found to be 0.888, 0.607, 0.819, and 0.903 in PZ; 0.988, 0.967, 0.986, and 0.983 in non-PZ; 0.982, 0.975, 0.973, and 0.984 in WP for manual, V-Net, nnU-Net-2D, and nnU-Net-3D, respectively. The results of this work show the feasibility of embedding DL-based segmentation in CAD systems, based on multiple T2W MR scans of the prostate, which is an important step towards the clinical implementation.","We would like to thank Fausto Milletari from the Technical University of Munich (Munich, Germany) and Fabian Isensee from the German Cancer Research Center (Heidelberg, Germany) for making their segmentation methods publicly available.",,Diagnostics,,,2021-09-16,2021,2021-09-16,,11,9,1690,All OA; Gold,Article,"Sunoqrot, Mohammed R. S.; Selnæs, Kirsten M.; Sandsmark, Elise; Langørgen, Sverre; Bertilsson, Helena; Bathen, Tone F.; Elschot, Mattijs","Sunoqrot, Mohammed R. S. (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, kirsten.margrete.selnes@stolav.no, (K.M.S.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.)); Selnæs, Kirsten M. (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, kirsten.margrete.selnes@stolav.no, (K.M.S.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.); Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no, (E.S.);, sverre.langorgen@stolav.no, (S.L.)); Sandsmark, Elise (Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no, (E.S.);, sverre.langorgen@stolav.no, (S.L.)); Langørgen, Sverre (Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no, (E.S.);, sverre.langorgen@stolav.no, (S.L.)); Bertilsson, Helena (Department of Cancer Research and Molecular Medicine, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, helena.bertilsson@ntnu.no; Department of Urology, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway); Bathen, Tone F. (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, kirsten.margrete.selnes@stolav.no, (K.M.S.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.); Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no, (E.S.);, sverre.langorgen@stolav.no, (S.L.)); Elschot, Mattijs (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, kirsten.margrete.selnes@stolav.no, (K.M.S.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.); Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no, (E.S.);, sverre.langorgen@stolav.no, (S.L.))","Sunoqrot, Mohammed R. S. (Norwegian University of Science and Technology)","Sunoqrot, Mohammed R. S. (Norwegian University of Science and Technology); Selnæs, Kirsten M. (Norwegian University of Science and Technology; St Olav's University Hospital); Sandsmark, Elise (St Olav's University Hospital); Langørgen, Sverre (St Olav's University Hospital); Bertilsson, Helena (Norwegian University of Science and Technology; St Olav's University Hospital); Bathen, Tone F. (Norwegian University of Science and Technology; St Olav's University Hospital); Elschot, Mattijs (Norwegian University of Science and Technology; St Olav's University Hospital)",4,4,0.86,3.51,https://www.mdpi.com/2075-4418/11/9/1690/pdf?version=1631932080,https://app.dimensions.ai/details/publication/pub.1141180276,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,
6167,pub.1135783002,10.1002/nbm.4495,33638244,,Characterisation of prostate cancer using texture analysis for diagnostic and prognostic monitoring,"Automated classification of significant prostate cancer (PCa) using MRI plays a potential role in assisting in clinical decision-making. Multiparametric MRI using a machine-aided approach is a better step to improve the overall accuracy of diagnosis of PCa. The objective of this study was to develop and validate a framework for differentiating Prostate Imaging-Reporting and Data System version 2 (PI-RADS v2) grades (grade 2 to grade 5) of PCa using texture features and machine learning (ML) methods with diffusion-weighted imaging (DWI) and apparent diffusion coefficient (ADC). The study cohort included an MRI dataset of 59 patients with clinically proven PCa. Regions of interest (ROIs) for a total of 435 lesions were delineated from the segmented peripheral zones of DWI and ADC. Six texture methods comprising 98 texture features in total (49 each of DWI and ADC) were extracted from lesion ROIs. Random forest (RF) and correlation-based feature selection methods were applied on feature vectors to select the best features for classification. Two ML classifiers, support vector machine (SVM) and K-nearest neighbour, were used and validated by 10-fold cross-validation. The proposed framework achieved high diagnostic performance with a sensitivity of 85.25% ± 3.84%, specificity of 95.71% ± 1.96%, accuracy of 84.90% ± 3.37% and area under the receiver-operating characteristic curve of 0.98 for PI-RADS v2 grades (2 to 5) classification using the RF feature selection method and Gaussian SVM classifier with combined features of DWI + ADC. The proposed computer-assisted framework can distinguish between PCa lesions with different aggressiveness based on PI-RADS v2 standards using texture analysis to improve the efficiency of PCa diagnostic performance.","The authors would like to acknowledge the support staff of IIT Delhi, New Delhi, and AIIMS Delhi, New Delhi. D.S. was supported with a research fellowship, funded by the Ministry of Human Resource Development, Government of India. This research did not receive any specific grants from funding agencies in the public, commercial or not‐for‐profit sectors.",,NMR in Biomedicine,,"Adult; Aged; Algorithms; Diffusion Magnetic Resonance Imaging; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Neoplasm Grading; Prognosis; Prostatic Neoplasms",2021-02-27,2021,2021-02-27,2021-06,34,6,e4495,Closed,Article,"Singh, Dharmesh; Kumar, Virendra; Das, Chandan J.; Singh, Anup; Mehndiratta, Amit","Singh, Dharmesh (Centre for Biomedical Engineering, Indian Institute of Technology Delhi, New Delhi, India); Kumar, Virendra (Department of NMR, All India Institute of Medical Sciences, New Delhi, India); Das, Chandan J. (Department of Radiodiagnosis, All India Institute of Medical Sciences, New Delhi, India); Singh, Anup (Centre for Biomedical Engineering, Indian Institute of Technology Delhi, New Delhi, India; Department of Biomedical Engineering, All India Institute of Medical Sciences, New Delhi, India); Mehndiratta, Amit (Centre for Biomedical Engineering, Indian Institute of Technology Delhi, New Delhi, India; Department of Biomedical Engineering, All India Institute of Medical Sciences, New Delhi, India)","Mehndiratta, Amit (Indian Institute of Technology Delhi; All India Institute of Medical Sciences)","Singh, Dharmesh (Indian Institute of Technology Delhi); Kumar, Virendra (All India Institute of Medical Sciences); Das, Chandan J. (All India Institute of Medical Sciences); Singh, Anup (Indian Institute of Technology Delhi; All India Institute of Medical Sciences); Mehndiratta, Amit (Indian Institute of Technology Delhi; All India Institute of Medical Sciences)",1,1,0.43,0.72,,https://app.dimensions.ai/details/publication/pub.1135783002,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
6166,pub.1124224314,10.1002/mp.14038,31971614,,T2w‐MRI signal normalization affects radiomics features reproducibility,"PURPOSE: Despite its increasing application, radiomics has not yet demonstrated a solid reliability, due to the difficulty in replicating analyses. The extraction of radiomic features from clinical MRI (T1w/T2w) presents even more challenges because of the absence of well-defined units (e.g. HU). Some preprocessing steps are required before the estimation of radiomic features and one of this is the intensity normalization, that can be performed using different methods. The aim of this work was to evaluate the effect of three different normalization techniques, applied on T2w-MRI images of the pelvic region, on radiomic features reproducibility.
METHODS: T2w-MRI acquired before (MRI1) and 12 months after radiotherapy (MRI2) from 14 patients treated for prostate cancer were considered. Four different conditions were analyzed: (a) the original MRI (No_Norm); (b) MRI normalized by the mean image value (Norm_Mean); (c) MRI normalized by the mean value of the urine in the bladder (Norm_ROI); (d) MRI normalized by the histogram-matching method (Norm_HM). Ninety-one radiomic features were extracted from three organs of interest (prostate, internal obturator muscles and bulb) at both time-points and on each image discretized using a fixed bin-width approach and the difference between the two time-points was calculated (Δfeature). To estimate the effect of normalization methods on the reproducibility of radiomic features, ICC was calculated in three analyses: (a) considering the features extracted on MRI2 in the four conditions together and considering the influence of each method separately, with respect to No_Norm; (b) considering the features extracted on MRI2 in the four conditions with respect to the inter-observer variability in region of interest (ROI) contouring, considering also the effect of the discretization approach; (c) considering Δfeature to evaluate if some indices can recover some consistency when differences are calculated.
RESULTS: Nearly 60% of the features have shown poor reproducibility (ICC < 0.5) on MRI2 and the method that most affected features reliability was Norm_ROI (average ICC of 0.45). The other two methods were similar, except for first-order features, where Norm_HM outperformed Norm_Mean (average ICC = 0.33 and 0.76 for Norm_Mean and Norm_HM, respectively). In the inter-observer setting, the number of reproducible features varied in the three structures, being higher in the prostate than in the penile bulb and in the obturators. The analysis on Δfeature highlighted that more than 60% of the features were not consistent with respect to the normalization method and confirmed the high reproducibility of the features between Norm_Mean and Norm_HM, whereas Norm_ROI was the less reproducible method.
CONCLUSIONS: The normalization process impacts the reproducibility of radiomic features, both in terms of changes in the image information content and in the inter-observer setting. Among the considered methods, Norm_Mean and Norm_HM seem to provide the most reproducible features with respect to the original image and also between themselves, whereas Norm_ROI generates less reproducible features. Only a very small subset of feature remained reproducible and independent in any tested condition, regardless the ROI and the adopted algorithm: skewness or kurtosis, correlation and one among Imc2, Idmn and Idn from GLCM group.",The work was partially funded by Italo Monzino Foundation and by Italian Ministry of Health (MoH) and MIUR (5 x 1000 Funds – 2016).,,Medical Physics,,"Image Processing, Computer-Assisted; Magnetic Resonance Imaging",2020-02-14,2020,2020-02-14,2020-04,47,4,1680-1691,All OA; Green,Article,"Scalco, Elisa; Belfatto, Antonella; Mastropietro, Alfonso; Rancati, Tiziana; Avuzzi, Barbara; Messina, Antonella; Valdagni, Riccardo; Rizzo, Giovanna","Scalco, Elisa (CNR, Institute of Biomedical Technologies (ITB), Segrate, Italy; CNR, Institute of Molecular Bioimaging and Physiology (IBFM), Segrate, Italy); Belfatto, Antonella (CNR, Institute of Molecular Bioimaging and Physiology (IBFM), Segrate, Italy); Mastropietro, Alfonso (CNR, Institute of Biomedical Technologies (ITB), Segrate, Italy; CNR, Institute of Molecular Bioimaging and Physiology (IBFM), Segrate, Italy); Rancati, Tiziana (Fondazione IRCCS Istituto Nazionale dei Tumori, Prostate Cancer Program, Milano, Italy); Avuzzi, Barbara (Radiation Oncology 1, Fondazione IRCCS Istituto Nazionale dei Tumori, Milano, Italy); Messina, Antonella (Radiology, Fondazione IRCCS Istituto Nazionale dei Tumori, Milano, Italy); Valdagni, Riccardo (Fondazione IRCCS Istituto Nazionale dei Tumori, Prostate Cancer Program, Milano, Italy; Radiation Oncology 1, Fondazione IRCCS Istituto Nazionale dei Tumori, Milano, Italy; Department of Oncology and Hemato‐oncology, Università degli Studi di Milano, Milano, Italy); Rizzo, Giovanna (CNR, Institute of Biomedical Technologies (ITB), Segrate, Italy; CNR, Institute of Molecular Bioimaging and Physiology (IBFM), Segrate, Italy)","Scalco, Elisa (Institute of Biomedical Technologies; Institute of Molecular Bioimaging and Physiology)","Scalco, Elisa (Institute of Biomedical Technologies; Institute of Molecular Bioimaging and Physiology); Belfatto, Antonella (Institute of Molecular Bioimaging and Physiology); Mastropietro, Alfonso (Institute of Biomedical Technologies; Institute of Molecular Bioimaging and Physiology); Rancati, Tiziana (Fondazione IRCCS Istituto Nazionale dei Tumori); Avuzzi, Barbara (Fondazione IRCCS Istituto Nazionale dei Tumori); Messina, Antonella (Fondazione IRCCS Istituto Nazionale dei Tumori); Valdagni, Riccardo (Fondazione IRCCS Istituto Nazionale dei Tumori; Fondazione IRCCS Istituto Nazionale dei Tumori; University of Milan); Rizzo, Giovanna (Institute of Biomedical Technologies; Institute of Molecular Bioimaging and Physiology)",60,54,7.17,24.59,https://air.unimi.it/bitstream/2434/726673/2/Scalco.pdf,https://app.dimensions.ai/details/publication/pub.1124224314,40 Engineering; 4003 Biomedical Engineering; 51 Physical Sciences; 5105 Medical and Biological Physics,
6165,pub.1149407319,10.1016/j.compbiomed.2022.105817,35841780,,Prostate158 - An expert-annotated 3T MRI dataset and algorithm for prostate cancer detection,"BACKGROUND: The development of deep learning (DL) models for prostate segmentation on magnetic resonance imaging (MRI) depends on expert-annotated data and reliable baselines, which are often not publicly available. This limits both reproducibility and comparability.
METHODS: Prostate158 consists of 158 expert annotated biparametric 3T prostate MRIs comprising T2w sequences and diffusion-weighted sequences with apparent diffusion coefficient maps. Two U-ResNets trained for segmentation of anatomy (central gland, peripheral zone) and suspicious lesions for prostate cancer (PCa) with a PI-RADS score of ≥4 served as baseline algorithms. Segmentation performance was evaluated using the Dice similarity coefficient (DSC), the Hausdorff distance (HD), and the average surface distance (ASD). The Wilcoxon test with Bonferroni correction was used to evaluate differences in performance. The generalizability of the baseline model was assessed using the open datasets Medical Segmentation Decathlon and PROSTATEx.
RESULTS: Compared to Reader 1, the models achieved a DSC/HD/ASD of 0.88/18.3/2.2 for the central gland, 0.75/22.8/1.9 for the peripheral zone, and 0.45/36.7/17.4 for PCa. Compared with Reader 2, the DSC/HD/ASD were 0.88/17.5/2.6 for the central gland, 0.73/33.2/1.9 for the peripheral zone, and 0.4/39.5/19.1 for PCa. Interrater agreement measured in DSC/HD/ASD was 0.87/11.1/1.0 for the central gland, 0.75/15.8/0.74 for the peripheral zone, and 0.6/18.8/5.5 for PCa. Segmentation performances on the Medical Segmentation Decathlon and PROSTATEx were 0.82/22.5/3.4; 0.86/18.6/2.5 for the central gland, and 0.64/29.2/4.7; 0.71/26.3/2.2 for the peripheral zone.
CONCLUSIONS: We provide an openly accessible, expert-annotated 3T dataset of prostate MRI and a reproducible benchmark to foster the development of prostate segmentation algorithms.","LCA is grateful for her participation in the BIH Charité–Junior Clinician and Clinician Scientist Program and KKB is grateful for his participation in the BIH Charité Digital Clinician Scientist Program, all funded by the Charité–Universitätsmedizin Berlin and the Berlin Institute of Health.",,Computers in Biology and Medicine,,Algorithms; Humans; Magnetic Resonance Imaging; Male; Prostate; Prostatic Neoplasms; Reproducibility of Results; Retrospective Studies,2022-07-11,2022,2022-07-11,2022-09,148,,105817,Closed,Article,"Adams, Lisa C; Makowski, Marcus R; Engel, Günther; Rattunde, Maximilian; Busch, Felix; Asbach, Patrick; Niehues, Stefan M; Vinayahalingam, Shankeeth; van Ginneken, Bram; Litjens, Geert; Bressem, Keno K","Adams, Lisa C (Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Institute for Radiology, Luisenstraße 7, 10117, Hindenburgdamm 30, 12203, Berlin, Germany; Berlin Institute of Health at Charité - Universitätsmedizin Berlin, Charitéplatz 1, 10117, Berlin, Germany. Electronic address: lisa.christine.adams@gmail.com.); Makowski, Marcus R (Technical University of Munich, Department of Diagnostic and Interventional Radiology, Faculty of Medicine, Ismaninger Str. 22, 81675, Munich, Germany.); Engel, Günther (Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Institute for Radiology, Luisenstraße 7, 10117, Hindenburgdamm 30, 12203, Berlin, Germany; Institute for Diagnostic and Interventional Radiology, Georg-August University, Göttingen, Germany.); Rattunde, Maximilian (Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Institute for Radiology, Luisenstraße 7, 10117, Hindenburgdamm 30, 12203, Berlin, Germany.); Busch, Felix (Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Institute for Radiology, Luisenstraße 7, 10117, Hindenburgdamm 30, 12203, Berlin, Germany.); Asbach, Patrick (Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Institute for Radiology, Luisenstraße 7, 10117, Hindenburgdamm 30, 12203, Berlin, Germany.); Niehues, Stefan M (Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Institute for Radiology, Luisenstraße 7, 10117, Hindenburgdamm 30, 12203, Berlin, Germany.); Vinayahalingam, Shankeeth (Department of Oral and Maxillofacial Surgery, Radboud University Medical Center, Nijmegen, GA, the Netherlands.); van Ginneken, Bram (Radboud University Medical Center, Nijmegen, GA, the Netherlands.); Litjens, Geert (Radboud University Medical Center, Nijmegen, GA, the Netherlands.); Bressem, Keno K (Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Institute for Radiology, Luisenstraße 7, 10117, Hindenburgdamm 30, 12203, Berlin, Germany; Berlin Institute of Health at Charité - Universitätsmedizin Berlin, Charitéplatz 1, 10117, Berlin, Germany.)","Adams, Lisa C (Charité - University Medicine Berlin; Berlin Institute of Health at Charité - Universitätsmedizin Berlin)","Adams, Lisa C (Charité - University Medicine Berlin; Berlin Institute of Health at Charité - Universitätsmedizin Berlin); Makowski, Marcus R (Technical University of Munich); Engel, Günther (Charité - University Medicine Berlin; University of Göttingen); Rattunde, Maximilian (Charité - University Medicine Berlin); Busch, Felix (Charité - University Medicine Berlin); Asbach, Patrick (Charité - University Medicine Berlin); Niehues, Stefan M (Charité - University Medicine Berlin); Vinayahalingam, Shankeeth (Radboud University Nijmegen Medical Centre); van Ginneken, Bram (Radboud University Nijmegen Medical Centre); Litjens, Geert (Radboud University Nijmegen Medical Centre); Bressem, Keno K (Charité - University Medicine Berlin; Berlin Institute of Health at Charité - Universitätsmedizin Berlin)",3,3,,,,https://app.dimensions.ai/details/publication/pub.1149407319,31 Biological Sciences; 3102 Bioinformatics and Computational Biology; 42 Health Sciences; 4203 Health Services and Systems; 46 Information and Computing Sciences; 4601 Applied Computing,
6153,pub.1129958522,10.1002/acm2.12992,32770600,PMC7592985,Voxel‐based supervised machine learning of peripheral zone prostate cancer using noncontrast multiparametric MRI,"PURPOSE: The aim of this study was to develop and assess the performance of supervised machine learning technique to classify magnetic resonance imaging (MRI) voxels as cancerous or noncancerous using noncontrast multiparametric MRI (mp-MRI), comprised of T2-weighted imaging (T2WI), diffusion-weighted imaging (DWI), and advanced diffusion tensor imaging (DTI) parameters.
MATERIALS AND METHODS: In this work, 191 radiomic features were extracted from mp-MRI from prostate cancer patients. A comprehensive set of support vector machine (SVM) models for T2WI and mp-MRI (T2WI + DWI, T2WI + DTI, and T2WI + DWI + DTI) were developed based on novel Bayesian parameters optimization method and validated using leave-one-patient-out approach to eliminate any possible overfitting. The diagnostic performance of each model was evaluated using the area under the receiver operating characteristic curve (AUROC). The average sensitivity, specificity, and accuracy of the models were evaluated using the test data set and the corresponding binary maps generated. Finally, the SVM plus sigmoid function of the models with the highest performance were used to produce cancer probability maps.
RESULTS: The T2WI + DWI + DTI models using the optimal feature subset achieved the best performance in prostate cancer detection, with the average AUROC , sensitivity, specificity, and accuracy of 0.93 ± 0.03, 0.85 ± 0.05, 0.82 ± 0.07, and 0.83 ± 0.04, respectively. The average diagnostic performance of T2WI + DTI models was slightly higher than T2WI + DWI models (+3.52%) using the optimal radiomic features.
CONCLUSIONS: Combination of noncontrast mp-MRI (T2WI, DWI, and DTI) features with the framework of a supervised classification technique and Bayesian optimization method are able to differentiate cancer from noncancer voxels with high accuracy and without administration of contrast agent. The addition of cancer probability maps provides additional functionality for image interpretation, lesion heterogeneity evaluation, and treatment management.","This study was supported by the Hunter Cancer Research Alliance (HCRA), NSW, and Australia [Grant number: G1301098, 2015]. We would especially like to acknowledge the contribution of the Clinical Research and Statistical Support unit in Hunter Medical Research Institute (HMRI).",,Journal of Applied Clinical Medical Physics,,Bayes Theorem; Diffusion Tensor Imaging; Humans; Magnetic Resonance Imaging; Male; Multiparametric Magnetic Resonance Imaging; Prostatic Neoplasms; Retrospective Studies; Sensitivity and Specificity; Supervised Machine Learning,2020-08-08,2020,2020-08-08,2020-10,21,10,179-191,All OA; Gold,Article,"Gholizadeh, Neda; Simpson, John; Ramadan, Saadallah; Denham, Jim; Lau, Peter; Siddique, Sabbir; Dowling, Jason; Welsh, James; Chalup, Stephan; Greer, Peter B.","Gholizadeh, Neda (School of Mathematical and Physical Sciences, University of Newcastle, Callaghan, NSW, Australia); Simpson, John (School of Mathematical and Physical Sciences, University of Newcastle, Callaghan, NSW, Australia; Radiation Oncology Department, Calvary Mater Newcastle, Newcastle, NSW, Australia); Ramadan, Saadallah (School of Health Sciences, Faculty of Health and Medicine, University of Newcastle, Callaghan, NSW, 2308, Australia; Hunter Medical Research Institute (HMRI) Imaging Centre, New Lambton Heights, NSW, Australia); Denham, Jim (Radiation Oncology Department, Calvary Mater Newcastle, Newcastle, NSW, Australia); Lau, Peter (Hunter Medical Research Institute (HMRI) Imaging Centre, New Lambton Heights, NSW, Australia; Radiology Department, Calvary Mater Newcastle, Newcastle, NSW, Australia); Siddique, Sabbir (Radiology Department, Calvary Mater Newcastle, Newcastle, NSW, Australia); Dowling, Jason (CSIRO Australian e‐Health Research Centre, Herston, Queensland, Australia); Welsh, James (School of Electrical Engineering and Computing, University of Newcastle, Callaghan, NSW, Australia); Chalup, Stephan (School of Electrical Engineering and Computing, University of Newcastle, Callaghan, NSW, Australia); Greer, Peter B. (School of Mathematical and Physical Sciences, University of Newcastle, Callaghan, NSW, Australia; Radiation Oncology Department, Calvary Mater Newcastle, Newcastle, NSW, Australia)","Gholizadeh, Neda (University of Newcastle Australia)","Gholizadeh, Neda (University of Newcastle Australia); Simpson, John (University of Newcastle Australia; Calvary Mater Newcastle Hospital); Ramadan, Saadallah (University of Newcastle Australia; Hunter Medical Research Institute); Denham, Jim (Calvary Mater Newcastle Hospital); Lau, Peter (Hunter Medical Research Institute; Calvary Mater Newcastle Hospital); Siddique, Sabbir (Calvary Mater Newcastle Hospital); Dowling, Jason (Australian e-Health Research Centre); Welsh, James (University of Newcastle Australia); Chalup, Stephan (University of Newcastle Australia); Greer, Peter B. (University of Newcastle Australia; Calvary Mater Newcastle Hospital)",9,9,1.23,3.83,https://doi.org/10.1002/acm2.12992,https://app.dimensions.ai/details/publication/pub.1129958522,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
6151,pub.1146557624,10.1007/s13246-022-01118-2,35325377,,Multiple analyses suggests texture features can indicate the presence of tumor in the prostate tissue,"Several studies have demonstrated statistical and texture analysis abilities to differentiate cancerous from healthy tissue in magnetic resonance imaging. This study developed a method based on texture analysis and machine learning to differentiate prostate findings. Forty-eight male patients with PI-RADS classification and subsequent radical prostatectomy histopathological analysis were used as gold standard. Experienced radiologists delimited the regions of interest in magnetic resonance images. Six different groups of images were used to perform multiple analyses (seven analyses variations). Those analyses were outlined by specialists in urology as those of most significant importance for the classification. Forty texture features were extracted from each image and processed with Random Forest, Support Vector Machine, K-Nearest Neighbors, and Naive Bayes. Those seven analyses variation results were described in terms of area under the ROC curve (AUC), accuracy, F-score, precision and sensitivity. The highest AUC (93.7%) and accuracy (88.8%) were obtained when differentiating the group with both MRI and histopathology positive findings against the group with both negative MRI and histopathology. When differentiating the group with both MRI and histopathology positive findings versus the peripheral image zone group the AUC value was 86.6%. When differentiating the group with negative MRI/positive histopathology versus the group with both negative MRI and histopathology the AUC value was 80.7%. The evaluation of statistical and texture analysis promoted very suggestive indications for future work in prostate cancer suspicious regions. The method is fast for both region of interest selection and classification with machine learning and the result brings original contributions in the classification of different groups of patients. This tool is low-cost, and can be used to assist diagnostic decisions.","We would like to thank all the technicians of the Computed Tomography service at Botucatu Medical School, including urology and radiology experts that contributed to this study. The Coordination for the Improvement of Higher Education Personnel (CAPES 001), the National Council for Scientific and Technological Development (PQ/CNPq 303509/2019-8) and The São Paulo Research Foundation, (FAPESP 2020/05539-9) for the financial support throughout this study.",This research was funded by São Paulo Research Foundation (Process Number: 2020/05539-9) and by Brazilian National Council for Scientific and Technological Development (Process Number: 303509/2019-8). Ph.D. Student Sérgio Augusto Santana Souza received a scholarship from Coordination of Superior Level Staff Improvement (CAPES).,Physical and Engineering Sciences in Medicine,,Bayes Theorem; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Prostate; Prostatic Neoplasms,2022-03-24,2022,2022-03-24,2022-06,45,2,525-535,Closed,Article,"Souza, Sérgio Augusto Santana; Reis, Leonardo Oliveira; Alves, Allan Felipe Fattori; Silva, Letícia Cotinguiba; Medeiros, Maria Clara Korndorfer; Andrade, Danilo Leite; Billis, Athanase; Amaro, João Luiz; Martins, Daniel Lahan; Trindade, André Petean; Miranda, José Ricardo Arruda; Pina, Diana Rodrigues","Souza, Sérgio Augusto Santana (São Paulo State University Júlio de Mesquita Filho, R. Prof. Dr. Antônio Celso Wagner Zanin, 250 - Distrito de Rubião Junior, CEP: 18618-689, Botucatu, SP, Brazil); Reis, Leonardo Oliveira (Department of Urology, UroScience, State University of Campinas, Unicamp and Pontifical Catholic University of Campinas, PUC-Campinas, Av. John Boyd Dunlop-Jardim Ipaussurama, CEP: 13034-685, Campinas, SP, Brazil); Alves, Allan Felipe Fattori (Botucatu Medical School, Clinics Hospital, Medical Physics and Radioprotection Nucleus, Av. Prof. Mário Rubens Guimarães Montenegro, s/n - UNESP - Campus de Botucatu, CEP: 18618687, Botucatu, SP, Brazil); Silva, Letícia Cotinguiba (São Paulo State University Júlio de Mesquita Filho, R. Prof. Dr. Antônio Celso Wagner Zanin, 250 - Distrito de Rubião Junior, CEP: 18618-689, Botucatu, SP, Brazil); Medeiros, Maria Clara Korndorfer (Department of Radiology, Pontifical Catholic University of Campinas, Campinas, SP, Brazil); Andrade, Danilo Leite (Department of Urology, UroScience, State University of Campinas, Unicamp and Pontifical Catholic University of Campinas, PUC-Campinas, Av. John Boyd Dunlop-Jardim Ipaussurama, CEP: 13034-685, Campinas, SP, Brazil); Billis, Athanase (Department of Anatomic Pathology and Urology, School of Medical Sciences, State University of Campinas (Unicamp), Campinas, Brazil); Amaro, João Luiz (Department of Urology, Botucatu Medical School, São Paulo State University (UNESP), Botucatu, SP, Brazil); Martins, Daniel Lahan (Department of Radiology, University of Campinas (UNICAMP), Campinas, SP, Brazil); Trindade, André Petean (Botucatu Medical School, São Paulo State University Júlio de Mesquita Filho, Av. Prof. Mário Rubens Guimarães Montenegro, s/n - UNESP - Campus de Botucatu, CEP:18618687, Botucatu, SP, Brazil); Miranda, José Ricardo Arruda (Institute of Bioscience, São Paulo State University Júlio de Mesquita Filho, R. Prof. Dr. Antônio Celso Wagner Zanin, 250 - Distrito de Rubião Junior, CEP: 8618-689, Botucatu, SP, Brazil); Pina, Diana Rodrigues (Botucatu Medical School, São Paulo State University Júlio de Mesquita Filho, Av. Prof. Mário Rubens Guimarães Montenegro, s/n - UNESP - Campus de Botucatu, CEP:18618687, Botucatu, SP, Brazil)","Pina, Diana Rodrigues (São Paulo State University)","Souza, Sérgio Augusto Santana (São Paulo State University); Reis, Leonardo Oliveira (State University of Campinas); Alves, Allan Felipe Fattori (São Paulo State University); Silva, Letícia Cotinguiba (São Paulo State University); Medeiros, Maria Clara Korndorfer (State University of Campinas); Andrade, Danilo Leite (State University of Campinas); Billis, Athanase (State University of Campinas); Amaro, João Luiz (São Paulo State University); Martins, Daniel Lahan (State University of Campinas); Trindade, André Petean (São Paulo State University); Miranda, José Ricardo Arruda (São Paulo State University); Pina, Diana Rodrigues (São Paulo State University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146557624,40 Engineering; 4003 Biomedical Engineering; 51 Physical Sciences; 5105 Medical and Biological Physics,
5836,pub.1103658545,10.1080/0284186x.2018.1468084,29698083,,Voxel-wise prostate cell density prediction using multiparametric magnetic resonance imaging and machine learning,"BACKGROUND: There are currently no methods to estimate cell density in the prostate. This study aimed to develop predictive models to estimate prostate cell density from multiparametric magnetic resonance imaging (mpMRI) data at a voxel level using machine learning techniques.
MATERIAL AND METHODS: In vivo mpMRI data were collected from 30 patients before radical prostatectomy. Sequences included T2-weighted imaging, diffusion-weighted imaging and dynamic contrast-enhanced imaging. Ground truth cell density maps were computed from histology and co-registered with mpMRI. Feature extraction and selection were performed on mpMRI data. Final models were fitted using three regression algorithms including multivariate adaptive regression spline (MARS), polynomial regression (PR) and generalised additive model (GAM). Model parameters were optimised using leave-one-out cross-validation on the training data and model performance was evaluated on test data using root mean square error (RMSE) measurements.
RESULTS: Predictive models to estimate voxel-wise prostate cell density were successfully trained and tested using the three algorithms. The best model (GAM) achieved a RMSE of 1.06 (± 0.06) × 103 cells/mm2 and a relative deviation of 13.3 ± 0.8%.
CONCLUSION: Prostate cell density can be quantitatively estimated non-invasively from mpMRI data using high-quality co-registered data at a voxel level. These cell density predictions could be used for tissue classification, treatment response evaluation and personalised radiotherapy.",The authors would like to thank Courtney Savill and Lauren Caspersz for their contribution in specimen preparation and MRI acquisition.,"This study was supported by NHMRC grant 1126955, PdCCRS grant 628592 with funding partners: Prostate Cancer Foundation of Australia, and the Radiation Oncology Section of the Australian Government of Health and Aging and Cancer Australia. Yu Sun is funded by the Melbourne International Research Scholarship, the Movember Young Investigator Grant through Prostate Cancer Foundation of Australia (PCFA) and Cancer Therapeutics Top-up Funding. Dr Reynolds is funded by the Movember Young Investigator Grant through PCFA’s Research Program.",Acta Oncologica,,"Algorithms; Cell Count; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Prostate; Prostatic Neoplasms; Regression Analysis",2018-04-26,2018,2018-04-26,2018-11-02,57,11,1540-1546,All OA; Bronze,Article,"Sun, Yu; Reynolds, Hayley M.; Wraith, Darren; Williams, Scott; Finnegan, Mary E.; Mitchell, Catherine; Murphy, Declan; Haworth, Annette","Sun, Yu (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, Australia, ;; Department of Physical Sciences, Peter MacCallum Cancer Centre, Melbourne, Australia, ;); Reynolds, Hayley M. (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, Australia, ;; Department of Physical Sciences, Peter MacCallum Cancer Centre, Melbourne, Australia, ;); Wraith, Darren (Institute of Health and Biomedical Innovation Queensland University of Technology, Brisbane, Australia, ;); Williams, Scott (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, Australia, ;; Division of Radiation Oncology and Cancer Imaging, Peter MacCallum Cancer Centre, Melbourne, Australia, ;); Finnegan, Mary E. (Department of Imaging, Imperial College Healthcare NHS Trust, London, UK, ;; Department of Bioengineering, Imperial College London, London, UK, ;); Mitchell, Catherine (Department of Pathology, Peter MacCallum Cancer Centre, Melbourne, Australia, ;); Murphy, Declan (Division of Cancer Surgery, Peter MacCallum Cancer Centre, Melbourne, Australia, ;); Haworth, Annette (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, Australia, ;; School of Physics, The University of Sydney, Sydney, Australia)","Sun, Yu (University of Melbourne; Peter MacCallum Cancer Centre)","Sun, Yu (University of Melbourne; Peter MacCallum Cancer Centre); Reynolds, Hayley M. (University of Melbourne; Peter MacCallum Cancer Centre); Wraith, Darren (Queensland University of Technology); Williams, Scott (University of Melbourne; Peter MacCallum Cancer Centre); Finnegan, Mary E. (Imperial College Healthcare NHS Trust; Imperial College London); Mitchell, Catherine (Peter MacCallum Cancer Centre); Murphy, Declan (Peter MacCallum Cancer Centre); Haworth, Annette (University of Melbourne; The University of Sydney)",17,9,0.98,4.96,https://www.tandfonline.com/doi/pdf/10.1080/0284186X.2018.1468084?needAccess=true,https://app.dimensions.ai/details/publication/pub.1103658545,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
5830,pub.1103270391,10.1002/jmri.26047,29659067,,Computer‐aided diagnosis of prostate cancer using a deep convolutional neural network from multiparametric MRI,"BACKGROUND: Deep learning is the most promising methodology for automatic computer-aided diagnosis of prostate cancer (PCa) with multiparametric MRI (mp-MRI).
PURPOSE: To develop an automatic approach based on deep convolutional neural network (DCNN) to classify PCa and noncancerous tissues (NC) with mp-MRI.
STUDY TYPE: Retrospective.
SUBJECTS: In all, 195 patients with localized PCa were collected from a PROSTATEx database. In total, 159/17/19 patients with 444/48/55 observations (215/23/23 PCas and 229/25/32 NCs) were randomly selected for training/validation/testing, respectively.
SEQUENCE: T2 -weighted, diffusion-weighted, and apparent diffusion coefficient images.
ASSESSMENT: A radiologist manually labeled the regions of interest of PCas and NCs and estimated the Prostate Imaging Reporting and Data System (PI-RADS) scores for each region. Inspired by VGG-Net, we designed a patch-based DCNN model to distinguish between PCa and NCs based on a combination of mp-MRI data. Additionally, an enhanced prediction method was used to improve the prediction accuracy. The performance of DCNN prediction was tested using a receiver operating characteristic (ROC) curve, and the area under the ROC curve (AUC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were calculated. Moreover, the predicted result was compared with the PI-RADS score to evaluate its clinical value using decision curve analysis.
STATISTICAL TEST: Two-sided Wilcoxon signed-rank test with statistical significance set at 0.05.
RESULTS: The DCNN produced excellent diagnostic performance in distinguishing between PCa and NC for testing datasets with an AUC of 0.944 (95% confidence interval: 0.876-0.994), sensitivity of 87.0%, specificity of 90.6%, PPV of 87.0%, and NPV of 90.6%. The decision curve analysis revealed that the joint model of PI-RADS and DCNN provided additional net benefits compared with the DCNN model and the PI-RADS scheme.
DATA CONCLUSION: The proposed DCNN-based model with enhanced prediction yielded high performance in statistical analysis, suggesting that DCNN could be used in computer-aided diagnosis (CAD) for PCa classification.
LEVEL OF EVIDENCE: 3 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2018;48:1570-1577.",Contract grant sponsor: Key Project of the National Natural Science Foundation of China; contract grant number: 61731009 (to G.Y.); Contract grant sponsor: China Postdoctoral Fund; contract grant number: 2015M580453 (to Y.D.Z.); Contract grant sponsor: Key Social Development Program for the Ministry of Science and Technology of Jiangsu Province; contract grant number: BE2017756 (to Y.D.Z.),,Journal of Magnetic Resonance Imaging,,"Area Under Curve; Databases, Factual; Deep Learning; Diagnosis, Computer-Assisted; Diffusion Magnetic Resonance Imaging; Humans; Male; Neural Networks, Computer; Pattern Recognition, Automated; Predictive Value of Tests; Prostatic Neoplasms; ROC Curve; Reproducibility of Results; Retrospective Studies; Sensitivity and Specificity; Software",2018-04-16,2018,2018-04-16,2018-12,48,6,1570-1577,Closed,Article,"Song, Yang; Zhang, Yu‐Dong; Yan, Xu; Liu, Hui; Zhou, Minxiong; Hu, Bingwen; Yang, Guang","Song, Yang (Shanghai Key Laboratory of Magnetic Resonance, East China Normal University, Shanghai, China); Zhang, Yu‐Dong (Department of Radiology, First Affiliated Hospital with Nanjing Medical University, Nanjing, China); Yan, Xu (MR Scientific Marketing, Siemens Healthcare, Shanghai, China); Liu, Hui (Research Department, hImagingTek Ltd., Shanghai, China); Zhou, Minxiong (Shanghai University of Medicine & Health Sciences, Shanghai, China); Hu, Bingwen (Shanghai Key Laboratory of Magnetic Resonance, East China Normal University, Shanghai, China); Yang, Guang (Shanghai Key Laboratory of Magnetic Resonance, East China Normal University, Shanghai, China)","Zhang, Yu‐Dong (Jiangsu Province Hospital); Yang, Guang (East China Normal University)","Song, Yang (East China Normal University); Zhang, Yu‐Dong (Jiangsu Province Hospital); Yan, Xu (); Liu, Hui (); Zhou, Minxiong (Shanghai University of Medicine and Health Sciences); Hu, Bingwen (East China Normal University); Yang, Guang (East China Normal University)",113,63,5.76,32.98,,https://app.dimensions.ai/details/publication/pub.1103270391,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
5805,pub.1151335092,10.1109/tmi.2022.3210133,36155434,,Domain and Content Adaptive Convolution Based Multi-Source Domain Generalization for Medical Image Segmentation,"The domain gap caused mainly by variable medical image quality renders a major obstacle on the path between training a segmentation model in the lab and applying the trained model to unseen clinical data. To address this issue, domain generalization methods have been proposed, which however usually use static convolutions and are less flexible. In this paper, we propose a multi-source domain generalization model based on the domain and content adaptive convolution (DCAC) for the segmentation of medical images across different modalities. Specifically, we design the domain adaptive convolution (DAC) module and content adaptive convolution (CAC) module and incorporate both into an encoder-decoder backbone. In the DAC module, a dynamic convolutional head is conditioned on the predicted domain code of the input to make our model adapt to the unseen target domain. In the CAC module, a dynamic convolutional head is conditioned on the global image features to make our model adapt to the test image. We evaluated the DCAC model against the baseline and four state-of-the-art domain generalization methods on the prostate segmentation, COVID-19 lesion segmentation, and optic cup/optic disc segmentation tasks. Our results not only indicate that the proposed DCAC model outperforms all competing methods on each segmentation task but also demonstrate the effectiveness of the DAC and CAC modules. Code is available at https://git.io/DCAC.","The authors acknowledge the RSNA and Society of Thoracic Radiology (STR), the European Society of Medical Imaging Informatics, the American College of Radiology, and the American Association of Physicists in Medicine, and their critical role in the creation of the free publicly available RICORD dataset used for this study. They also appreciate the efforts devoted by the authors of [10] and [24] to collect and share the prostate MR and fundus imaging data for comparing generalizable medical image segmentation algorithms.","This work was supported in part by the National Natural Science Foundation of China under Grant 62171377, in part by the National Key Research and Development Program of China under Grant 2022YFC2009903/2022YFC2009900, and in part by the Key Research and Development Program of Shaanxi Province, China, under Grant 2022GY-084.",IEEE Transactions on Medical Imaging,,,2022-09-26,2022,2022-09-26,2022-09-26,42,1,233-244,All OA; Green,Article,"Hu, Shishuai; Liao, Zehui; Zhang, Jianpeng; Xia, Yong","Hu, Shishuai (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, China); Liao, Zehui (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, China); Zhang, Jianpeng (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, China); Xia, Yong (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, 710072, China)","Xia, Yong (Northwestern Polytechnical University)","Hu, Shishuai (Northwestern Polytechnical University); Liao, Zehui (Northwestern Polytechnical University); Zhang, Jianpeng (Northwestern Polytechnical University); Xia, Yong (Northwestern Polytechnical University)",1,1,,,http://arxiv.org/pdf/2109.05676,https://app.dimensions.ai/details/publication/pub.1151335092,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
5805,pub.1139066925,10.1016/j.compbiomed.2021.104600,34214938,,Investigation of the plaque morphology effect on changes of pulsatile blood flow in a stenosed curved artery induced by an external magnetic field,"In a new therapeutic technique, called magnetic drug targeting (MDT), magnetic particles carrying therapeutic agents are directed to the target tissue by applying an external magnetic field. Meanwhile, this magnetic field also affects the blood as a biomagnetic fluid. Therefore, it is necessary to select a magnetic field with an acceptable range of influence on the blood flow. This study investigates the effect of an external magnetic field on the pulsatile blood flow in a stenosed curved artery to identify a safe magnetic field. The effects of a number of parameters, including the magnetic susceptibility of blood in oxygenated and deoxygenated states and the magnetic field strength, were studied. Moreover, the effect of the plaque morphology, including the occlusion percentage and the chord length of the stenosis, on changes in blood flow induced by the magnetic field was investigated. The results show that applying a magnetic field increases the wall shear stress (WSS) and the pressure of the deoxygenated blood. Comparing the wall shear stresses of the deoxygenated and oxygenated blood shows that the effect of magnetic field on the deoxygenated blood is more significant than its effect on the oxygenated blood due to its higher magnetic susceptibility. The study of the stenosis geometry shows that the influence of magnetic field on the blood flow is increased by decreasing the occlusion percentage of the artery. Furthermore, among the evaluated lengths, the 50° chord length results in the highest variation under the influence of the magnetic field. Finally, the magnetic field of Mn = 2.5 can be utilized as a safe field for MDT purposes in such a stenosed curved artery.","This work was supported by the National Research Foundation of Korea grant, which is funded by the Korean government (MSIT) (No. 2020R1A5A8018822).",,Computers in Biology and Medicine,,"Arteries; Blood Flow Velocity; Computer Simulation; Constriction, Pathologic; Humans; Magnetic Fields; Models, Cardiovascular; Pulsatile Flow; Stress, Mechanical",2021-06-23,2021,2021-06-23,2021-08,135,,104600,Closed,Article,"Teimouri, Kowsar; Tavakoli, Mohammad Reza; Ghafari, Ashkan; Kim, Kyung Chun","Teimouri, Kowsar (Department of Mechanical Engineering, Isfahan University of Technology, Isfahan, 8415683111, Iran. Electronic address: k.teimouri@me.iut.ac.ir.); Tavakoli, Mohammad Reza (Department of Mechanical Engineering, Isfahan University of Technology, Isfahan, 8415683111, Iran. Electronic address: mrtavak@iut.ac.ir.); Ghafari, Ashkan (Department of Mechanical Engineering, Isfahan University of Technology, Isfahan, 8415683111, Iran. Electronic address: ashkan.ghafari92@gmail.com.); Kim, Kyung Chun (School of Mechanical Engineering, Pusan National University, Busan, 46241, Republic of Korea. Electronic address: kckim@pusan.ac.kr.)","Tavakoli, Mohammad Reza (Isfahan University of Technology); Kim, Kyung Chun (Pusan National University)","Teimouri, Kowsar (Isfahan University of Technology); Tavakoli, Mohammad Reza (Isfahan University of Technology); Ghafari, Ashkan (Isfahan University of Technology); Kim, Kyung Chun (Pusan National University)",5,5,,3.52,,https://app.dimensions.ai/details/publication/pub.1139066925,31 Biological Sciences; 3102 Bioinformatics and Computational Biology; 42 Health Sciences; 4203 Health Services and Systems; 46 Information and Computing Sciences; 4601 Applied Computing,
5803,pub.1149500948,10.1109/tmi.2022.3191535,35839185,,DLTTA: Dynamic Learning Rate for Test-Time Adaptation on Cross-Domain Medical Images,"Test-time adaptation (TTA) has increasingly been an important topic to efficiently tackle the cross-domain distribution shift at test time for medical images from different institutions. Previous TTA methods have a common limitation of using a fixed learning rate for all the test samples. Such a practice would be sub-optimal for TTA, because test data may arrive sequentially therefore the scale of distribution shift would change frequently. To address this problem, we propose a novel dynamic learning rate adjustment method for test-time adaptation, called DLTTA, which dynamically modulates the amount of weights update for each test image to account for the differences in their distribution shift. Specifically, our DLTTA is equipped with a memory bank based estimation scheme to effectively measure the discrepancy of a given test sample. Based on this estimated discrepancy, a dynamic learning rate adjustment strategy is then developed to achieve a suitable degree of adaptation for each test sample. The effectiveness and general applicability of our DLTTA is extensively demonstrated on three tasks including retinal optical coherence tomography (OCT) segmentation, histopathological image classification, and prostate 3D MRI segmentation. Our method achieves effective and fast test-time adaptation with consistent performance improvement over current state-of-the-art test-time adaptation methods. Code is available at https://github.com/med-air/DLTTA.",,"This work was supported in part by the Hong Kong Innovation and Technology Fund under Project ITS/238/21, Project ITS/170/20, and Project GHP/110/19SZ, in part by The Chinese University of Hong Kong Shun Hing Institute of Advanced Engineering under Project MMT-p5-20, and in part by the Shenzhen-Hong Kong Collaboration Development Zone.",IEEE Transactions on Medical Imaging,,"Male; Humans; Prostate; Tomography, Optical Coherence; Retina; Magnetic Resonance Imaging",2022-12-02,2022,2022-12-02,2022-12,41,12,3575-3586,All OA; Green,Article,"Yang, Hongzheng; Chen, Cheng; Jiang, Meirui; Liu, Quande; Cao, Jianfeng; Heng, Pheng Ann; Dou, Qi","Yang, Hongzheng (Department of Artificial Intelligence, Beihang University, Beijing, 100191, China); Chen, Cheng (Department of Computer Science and Engineering, Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, Shatin, Hong Kong, SAR); Jiang, Meirui (Department of Computer Science and Engineering, Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, Shatin, Hong Kong, SAR); Liu, Quande (Department of Computer Science and Engineering, Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, Shatin, Hong Kong, SAR); Cao, Jianfeng (Department of Computer Science and Engineering, Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, Shatin, Hong Kong, SAR); Heng, Pheng Ann (Department of Computer Science and Engineering, Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, Shatin, Hong Kong, SAR); Dou, Qi (Department of Computer Science and Engineering, Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, Shatin, Hong Kong, SAR)","Chen, Cheng (Chinese University of Hong Kong)","Yang, Hongzheng (Beihang University); Chen, Cheng (Chinese University of Hong Kong); Jiang, Meirui (Chinese University of Hong Kong); Liu, Quande (Chinese University of Hong Kong); Cao, Jianfeng (Chinese University of Hong Kong); Heng, Pheng Ann (Chinese University of Hong Kong); Dou, Qi (Chinese University of Hong Kong)",1,1,,,http://arxiv.org/pdf/2205.13723,https://app.dimensions.ai/details/publication/pub.1149500948,46 Information and Computing Sciences; 4611 Machine Learning,
5802,pub.1142607240,10.3389/fninf.2021.622951,34867254,PMC8635782,Magnetic Resonance Imaging Sequence Identification Using a Metadata Learning Approach,"Despite the wide application of the magnetic resonance imaging (MRI) technique, there are no widely used standards on naming and describing MRI sequences. The absence of consistent naming conventions presents a major challenge in automating image processing since most MRI software require a priori knowledge of the type of the MRI sequences to be processed. This issue becomes increasingly critical with the current efforts toward open-sharing of MRI data in the neuroscience community. This manuscript reports an MRI sequence detection method using imaging metadata and a supervised machine learning technique. Three datasets from the Brain Center for Ontario Data Exploration (Brain-CODE) data platform, each involving MRI data from multiple research institutes, are used to build and test our model. The preliminary results show that a random forest model can be trained to accurately identify MRI sequence types, and to recognize MRI scans that do not belong to any of the known sequence types. Therefore the proposed approach can be used to automate processing of MRI data that involves a large number of variations in sequence names, and to help standardize sequence naming in ongoing data collections. This study highlights the potential of the machine learning approaches in helping manage health data.","We would like to thank the individuals and organizations that have made data used in this research available including the Province of Ontario Neurodevelopmental Disorders Network, the Canadian Biomarker Integration Network in Depression, the Ontario Neurodegenerative Disease Research Initiative, the Ontario Brain Institute, the Brain-CODE platform, and the Government of Ontario. The authors would also like to acknowledge the CAN-BIND Investigator Team: www.canbind.ca/our-team.","This research was conducted with the support of the Ontario Brain Institute, an independent non-profit corporation, funded partially by the Ontario government. Additional funding was provided by the Canadian Institutes of Health Research (CIHR), the National Science and Engineering Council of Canada (NSERC), Lundbeck, Bristol-Myers Squibb, Pfizer, and Servier. Matching funds and/or in-kind support were provided by participant hospital and research institute foundations, including the Baycrest Foundation, Bruyére Research Institute, Centre for Addiction and Mental Health Foundation, London Health Sciences Foundation, McMaster University Faculty of Health Sciences, Ottawa Brain and Mind Research Institute, Queen’s University Faculty of Health Sciences, Sunnybrook Health Sciences Foundation, the Thunder Bay Regional Health Sciences Centre, the University of Ottawa Faculty of Medicine, the University of British Columbia, the University of Calgary, the Hospital for Sick Children, and the Windsor/Essex County ALS Association. The Temerty Family Foundation provided the major infrastructure matching funds. AT, MZ, and SRA were partially supported by a Canadian Institutes of Health Research (CIHR) grant (MOP201403) to SCS.",Frontiers in Neuroinformatics,,,2021-11-17,2021,2021-11-17,,15,,622951,All OA; Gold,Article,"Liang, Shuai; Beaton, Derek; Arnott, Stephen R.; Gee, Tom; Zamyadi, Mojdeh; Bartha, Robert; Symons, Sean; MacQueen, Glenda M.; Hassel, Stefanie; Lerch, Jason P.; Anagnostou, Evdokia; Lam, Raymond W.; Frey, Benicio N.; Milev, Roumen; Müller, Daniel J.; Kennedy, Sidney H.; Scott, Christopher J. M.; Strother, Stephen C.; Troyer, Angela; Lang, Anthony E.; Greenberg, Barry; Hudson, Chris; Corbett, Dale; Grimes, David A.; Munoz, David G.; Munoz, Douglas P.; Finger, Elizabeth; Orange, J. B.; Zinman, Lorne; Montero-Odasso, Manuel; Tartaglia, Maria Carmela; Masellis, Mario; Borrie, Michael; Strong, Michael J.; Freedman, Morris; McLaughlin, Paula M.; Swartz, Richard H.; Hegele, Robert A.; Bartha, Robert; Black, Sandra E.; Symons, Sean; Strother, Stephen C.; McIlroy, William E.","Liang, Shuai (Rotman Research Institute, Baycrest Health Center, Toronto, ON, Canada; Indoc Research, Toronto, ON, Canada); Beaton, Derek (Rotman Research Institute, Baycrest Health Center, Toronto, ON, Canada); Arnott, Stephen R. (Rotman Research Institute, Baycrest Health Center, Toronto, ON, Canada); Gee, Tom (Indoc Research, Toronto, ON, Canada); Zamyadi, Mojdeh (Rotman Research Institute, Baycrest Health Center, Toronto, ON, Canada); Bartha, Robert (); Symons, Sean (); MacQueen, Glenda M. (Department of Psychiatry, Cumming School of Medicine, University of Calgary, Calgary, AB, Canada); Hassel, Stefanie (Department of Psychiatry, Cumming School of Medicine, University of Calgary, Calgary, AB, Canada); Lerch, Jason P. (Mouse Imaging Centre, Hospital for Sick Children, Toronto, ON, Canada; Wellcome Centre for Integrative Neuroimaging, FMRIB, Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, United Kingdom); Anagnostou, Evdokia (Bloorview Research Institute, Holland Bloorview Kids Rehabilitation Hospital, Toronto, ON, Canada; Department of Pediatrics, University of Toronto, Toronto, ON, Canada); Lam, Raymond W. (Department of Psychiatry, University of British Columbia, Vancouver, BC, Canada); Frey, Benicio N. (Department of Psychiatry and Behavioral Neurosciences, McMaster University, Hamilton, ON, Canada; Mood Disorders Program, St. Joseph’s Healthcare, Hamilton, ON, Canada); Milev, Roumen (Departments of Psychiatry and Psychology, Providence Care Hospital, Queen’s University, Kingston, ON, Canada); Müller, Daniel J. (Molecular Brain Science, Centre for Addiction and Mental Health, Campbell Family Mental Health Research Institute, Toronto, ON, Canada; Department of Psychiatry, University of Toronto, Toronto, ON, Canada); Kennedy, Sidney H. (Department of Psychiatry, University of Toronto, Toronto, ON, Canada; Department of Psychiatry, Krembil Research Centre, University Health Network, Toronto, ON, Canada; Department of Psychiatry, St. Michael’s Hospital, University of Toronto, Toronto, ON, Canada; Keenan Research Centre for Biomedical Science, St. Michael’s Hospital, Li Ka Shing Knowledge Institute, Toronto, ON, Canada); Scott, Christopher J. M. (L.C. Campbell Cognitive Neurology Research Unit, Toronto, ON, Canada; Heart & Stroke Foundation Centre for Stroke Recovery, Toronto, ON, Canada; Sunnybrook Health Sciences Centre, Brain Sciences Research Program, Sunnybrook Research Institute, Toronto, ON, Canada); Strother, Stephen C. (); Troyer, Angela (); Lang, Anthony E. (); Greenberg, Barry (); Hudson, Chris (); Corbett, Dale (); Grimes, David A. (); Munoz, David G. (); Munoz, Douglas P. (); Finger, Elizabeth (); Orange, J. B. (); Zinman, Lorne (); Montero-Odasso, Manuel (); Tartaglia, Maria Carmela (); Masellis, Mario (); Borrie, Michael (); Strong, Michael J. (); Freedman, Morris (); McLaughlin, Paula M. (); Swartz, Richard H. (); Hegele, Robert A. (); Black, Sandra E. (); McIlroy, William E. ()","Liang, Shuai (University of Toronto; Indoc Research)","Liang, Shuai (University of Toronto; Indoc Research); Beaton, Derek (University of Toronto); Arnott, Stephen R. (University of Toronto); Gee, Tom (Indoc Research); Zamyadi, Mojdeh (University of Toronto); Bartha, Robert (); Symons, Sean (); MacQueen, Glenda M. (University of Calgary); Hassel, Stefanie (University of Calgary); Lerch, Jason P. (Hospital for Sick Children; Wellcome Centre for Integrative Neuroimaging); Anagnostou, Evdokia (Holland Bloorview Kids Rehabilitation Hospital; University of Toronto); Lam, Raymond W. (University of British Columbia); Frey, Benicio N. (McMaster University; St. Joseph’s Healthcare Hamilton); Milev, Roumen (Queen's University); Müller, Daniel J. (Centre for Addiction and Mental Health; University of Toronto); Kennedy, Sidney H. (University of Toronto; University Health Network; University of Toronto; St. Michael's Hospital; St. Michael's Hospital); Scott, Christopher J. M. (University of Toronto; Heart and Stroke Foundation; University of Toronto; Sunnybrook Health Science Centre); Strother, Stephen C. (); Troyer, Angela (); Lang, Anthony E. (); Greenberg, Barry (); Hudson, Chris (); Corbett, Dale (); Grimes, David A. (); Munoz, David G. (); Munoz, Douglas P. (); Finger, Elizabeth (); Orange, J. B. (); Zinman, Lorne (); Montero-Odasso, Manuel (); Tartaglia, Maria Carmela (); Masellis, Mario (); Borrie, Michael (); Strong, Michael J. (); Freedman, Morris (); McLaughlin, Paula M. (); Swartz, Richard H. (); Hegele, Robert A. (); Black, Sandra E. (); McIlroy, William E. ()",1,1,,0.91,https://www.frontiersin.org/articles/10.3389/fninf.2021.622951/pdf,https://app.dimensions.ai/details/publication/pub.1142607240,46 Information and Computing Sciences; 4601 Applied Computing; 4611 Machine Learning,
5788,pub.1130984905,10.3390/diagnostics10090714,32961895,PMC7555425,A Quality Control System for Automated Prostate Segmentation on T2-Weighted MRI,"Computer-aided detection and diagnosis (CAD) systems have the potential to improve robustness and efficiency compared to traditional radiological reading of magnetic resonance imaging (MRI). Fully automated segmentation of the prostate is a crucial step of CAD for prostate cancer, but visual inspection is still required to detect poorly segmented cases. The aim of this work was therefore to establish a fully automated quality control (QC) system for prostate segmentation based on T2-weighted MRI. Four different deep learning-based segmentation methods were used to segment the prostate for 585 patients. First order, shape and textural radiomics features were extracted from the segmented prostate masks. A reference quality score (QS) was calculated for each automated segmentation in comparison to a manual segmentation. A least absolute shrinkage and selection operator (LASSO) was trained and optimized on a randomly assigned training dataset (N = 1756, 439 cases from each segmentation method) to build a generalizable linear regression model based on the radiomics features that best estimated the reference QS. Subsequently, the model was used to estimate the QSs for an independent testing dataset (N = 584, 146 cases from each segmentation method). The mean ± standard deviation absolute error between the estimated and reference QSs was 5.47 ± 6.33 on a scale from 0 to 100. In addition, we found a strong correlation between the estimated and reference QSs (rho = 0.70). In conclusion, we developed an automated QC system that may be helpful for evaluating the quality of automated prostate segmentations.","We would like to thank SPIE, the AAPM, the NCI and Radboud University Nijmegen (Nijmegen, Netherlands) in addition to the organizers of the PROSTATEx and PROMISE12 challenges for making their datasets available. In addition, we would like to thank Inom Mirzaev from Ohio State University (Ohio, USA), Fausto Milletari from the Technical University of Munich (Munich, Germany) and Fabian Isensee from the German Cancer Research Center (Heidelberg, Germany) for making their segmentation methods publicly available. We would like to thank Sverre Langørgen from St. Olavs Hospital, Trondheim University Hospital (Trondheim, Norway), for supervising the prostate delineation process for the in-house collected dataset.","This research was funded by the Norwegian University of Science and Technology (NTNU) Biotechnology (grant number 81770928; M.R.S.S.), the Research Council of Norway (grant number 295013; T.F.B.) and the liaison committee between the Central Norway Regional Health Authority and the Norwegian University of Science and Technology (grant numbers 90368401; G.A.N. and 90265300; M.E.).",Diagnostics,,,2020-09-18,2020,2020-09-18,,10,9,714,All OA; Gold,Article,"Sunoqrot, Mohammed R. S.; Selnæs, Kirsten M.; Sandsmark, Elise; Nketiah, Gabriel A.; Zavala-Romero, Olmo; Stoyanova, Radka; Bathen, Tone F.; Elschot, Mattijs","Sunoqrot, Mohammed R. S. (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, Kirsten.Margrete.Selnes@stolav.no, (K.M.S.);, gabriel.a.nketiah@ntnu.no, (G.A.N.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.)); Selnæs, Kirsten M. (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, Kirsten.Margrete.Selnes@stolav.no, (K.M.S.);, gabriel.a.nketiah@ntnu.no, (G.A.N.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.); Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no); Sandsmark, Elise (Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no); Nketiah, Gabriel A. (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, Kirsten.Margrete.Selnes@stolav.no, (K.M.S.);, gabriel.a.nketiah@ntnu.no, (G.A.N.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.); Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no); Zavala-Romero, Olmo (Department of Radiation Oncology, University of Miami Miller School of Medicine, Miami, FL 33136, USA;, ozavala@coaps.fsu.edu, (O.Z.-R.);, rstoyanova@med.miami.edu, (R.S.); Center for Ocean-Atmospheric Prediction Studies, Florida State University, Tallahassee, FL 32306, USA); Stoyanova, Radka (Department of Radiation Oncology, University of Miami Miller School of Medicine, Miami, FL 33136, USA;, ozavala@coaps.fsu.edu, (O.Z.-R.);, rstoyanova@med.miami.edu, (R.S.)); Bathen, Tone F. (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, Kirsten.Margrete.Selnes@stolav.no, (K.M.S.);, gabriel.a.nketiah@ntnu.no, (G.A.N.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.); Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no); Elschot, Mattijs (Department of Circulation and Medical Imaging, NTNU—Norwegian University of Science and Technology, 7030 Trondheim, Norway;, Kirsten.Margrete.Selnes@stolav.no, (K.M.S.);, gabriel.a.nketiah@ntnu.no, (G.A.N.);, tone.f.bathen@ntnu.no, (T.F.B.);, mattijs.elschot@ntnu.no, (M.E.); Department of Radiology and Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 Trondheim, Norway;, elise.sandsmark@stolav.no)","Sunoqrot, Mohammed R. S. (Norwegian University of Science and Technology; )","Sunoqrot, Mohammed R. S. (Norwegian University of Science and Technology); Selnæs, Kirsten M. (Norwegian University of Science and Technology; St Olav's University Hospital); Sandsmark, Elise (St Olav's University Hospital); Nketiah, Gabriel A. (Norwegian University of Science and Technology; St Olav's University Hospital); Zavala-Romero, Olmo (University of Miami; Florida State University); Stoyanova, Radka (University of Miami); Bathen, Tone F. (Norwegian University of Science and Technology; St Olav's University Hospital); Elschot, Mattijs (Norwegian University of Science and Technology; St Olav's University Hospital)",12,12,1.52,5.11,https://www.mdpi.com/2075-4418/10/9/714/pdf?version=1600432487,https://app.dimensions.ai/details/publication/pub.1130984905,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
5788,pub.1130272721,10.3390/cancers12092366,32825612,PMC7565879,Computer-Aided Diagnosis in Multiparametric MRI of the Prostate: An Open-Access Online Tool for Lesion Classification with High Accuracy,"Computer-aided diagnosis (CADx) approaches could help to objectify reporting on prostate mpMRI, but their use in many cases is hampered due to common-built algorithms that are not publicly available. The aim of this study was to develop an open-access CADx algorithm with high accuracy for classification of suspicious lesions in mpMRI of the prostate. This retrospective study was approved by the local ethics commission, with waiver of informed consent. A total of 124 patients with 195 reported lesions were included. All patients received mpMRI of the prostate between 2014 and 2017, and transrectal ultrasound (TRUS)-guided and targeted biopsy within a time period of 30 days. Histopathology of the biopsy cores served as a standard of reference. Acquired imaging parameters included the size of the lesion, signal intensity (T2w images), diffusion restriction, prostate volume, and several dynamic parameters along with the clinical parameters patient age and serum PSA level. Inter-reader agreement of the imaging parameters was assessed by calculating intraclass correlation coefficients. The dataset was stratified into a train set and test set (156 and 39 lesions in 100 and 24 patients, respectively). Using the above parameters, a CADx based on an Extreme Gradient Boosting algorithm was developed on the train set, and tested on the test set. Performance optimization was focused on maximizing the area under the Receiver Operating Characteristic curve (ROCAUC). The algorithm was made publicly available on the internet. The CADx reached an ROCAUC of 0.908 during training, and 0.913 during testing (p = 0.93). Additionally, established rule-in and rule-out criteria allowed classifying 35.8% of the malignant and 49.4% of the benign lesions with error rates of <2%. All imaging parameters featured excellent inter-reader agreement. This study presents an open-access CADx for classification of suspicious lesions in mpMRI of the prostate with high accuracy. Applying the provided rule-in and rule-out criteria might facilitate to further stratify the management of patients at risk.",Michael Schlicht performed the present work in partial fulfilment of the requirements for obtaining the degree “Dr. med.”,This work was in part funded by the Collaborative Research Center 1181 of the German Research Foundation (Deutsche Forschungsgemeinschaft; CRC 1181; project Z02).,Cancers,,,2020-08-21,2020,2020-08-21,,12,9,2366,All OA; Gold,Article,"Ellmann, Stephan; Schlicht, Michael; Dietzel, Matthias; Janka, Rolf; Hammon, Matthias; Saake, Marc; Ganslandt, Thomas; Hartmann, Arndt; Kunath, Frank; Wullich, Bernd; Uder, Michael; Bäuerle, Tobias","Ellmann, Stephan (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.)); Schlicht, Michael (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.)); Dietzel, Matthias (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.)); Janka, Rolf (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.)); Hammon, Matthias (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.)); Saake, Marc (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.)); Ganslandt, Thomas (Department of Medical Informatics, Friedrich-Alexander-University Erlangen-Nuremberg, 91058 Erlangen, Germany;, thomas.ganslandt@medma.uni-heidelberg.de; Heinrich-Lanz-Center for Digital Health, Department of Biomedical Informatics, University Medicine Mannheim, Heidelberg University, 68177 Mannheim, Germany); Hartmann, Arndt (Institute of Pathology, University Hospital Erlangen, 91054 Erlangen, Germany;, arndt.hartmann@uk-erlangen.de); Kunath, Frank (Department of Urology and Paediatric Urology, University Hospital Erlangen, 91054 Erlangen, Germany;, frank.kunath@uk-erlangen.de, (F.K.);, bernd.wullich@uk-erlangen.de, (B.W.)); Wullich, Bernd (Department of Urology and Paediatric Urology, University Hospital Erlangen, 91054 Erlangen, Germany;, frank.kunath@uk-erlangen.de, (F.K.);, bernd.wullich@uk-erlangen.de, (B.W.)); Uder, Michael (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.)); Bäuerle, Tobias (Department of Radiology, University Hospital Erlangen, 91054 Erlangen, Germany;, michi.schlicht@googlemail.com, (M.S.);, dietzelmatthias2@hotmail.com, (M.D.);, rolf.janka@uk-erlangen.de, (R.J.);, matthias.hammon@gmail.com, (M.H.);, marc.saake@uk-erlangen.de, (M.S.);, michael.uder@uk-erlangen.de, (M.U.);, Tobias.Baeuerle@uk-erlangen.de, (T.B.))","Ellmann, Stephan (Universitätsklinikum Erlangen; )","Ellmann, Stephan (Universitätsklinikum Erlangen); Schlicht, Michael (Universitätsklinikum Erlangen); Dietzel, Matthias (Universitätsklinikum Erlangen); Janka, Rolf (Universitätsklinikum Erlangen); Hammon, Matthias (Universitätsklinikum Erlangen); Saake, Marc (Universitätsklinikum Erlangen); Ganslandt, Thomas (University of Erlangen-Nuremberg; University Medical Centre Mannheim); Hartmann, Arndt (Universitätsklinikum Erlangen); Kunath, Frank (Universitätsklinikum Erlangen); Wullich, Bernd (Universitätsklinikum Erlangen); Uder, Michael (Universitätsklinikum Erlangen); Bäuerle, Tobias (Universitätsklinikum Erlangen)",8,8,0.66,3.41,https://www.mdpi.com/2072-6694/12/9/2366/pdf?version=1598000393,https://app.dimensions.ai/details/publication/pub.1130272721,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
5784,pub.1124921558,10.1109/tmi.2020.2974574,32078543,,MS-Net: Multi-Site Network for Improving Prostate Segmentation With Heterogeneous MRI Data,"Automated prostate segmentation in MRI is highly demanded for computer-assisted diagnosis. Recently, a variety of deep learning methods have achieved remarkable progress in this task, usually relying on large amounts of training data. Due to the nature of scarcity for medical images, it is important to effectively aggregate data from multiple sites for robust model training, to alleviate the insufficiency of single-site samples. However, the prostate MRIs from different sites present heterogeneity due to the differences in scanners and imaging protocols, raising challenges for effective ways of aggregating multi-site data for network training. In this paper, we propose a novel multi-site network (MS-Net) for improving prostate segmentation by learning robust representations, leveraging multiple sources of data. To compensate for the inter-site heterogeneity of different MRI datasets, we develop Domain-Specific Batch Normalization layers in the network backbone, enabling the network to estimate statistics and perform feature normalization for each site separately. Considering the difficulty of capturing the shared knowledge from multiple datasets, a novel learning paradigm, i.e., Multi-site-guided Knowledge Transfer, is proposed to enhance the kernels to extract more generic representations from multi-site data. Extensive experiments on three heterogeneous prostate MRI datasets demonstrate that our MS-Net improves the performance across all datasets consistently, and outperforms state-of-the-art methods for multi-site learning.",This work was supported in part by the HongKong Research GrantsCouncil under ProjectCUHK14225616 and in part by the National Natural Science Foundation of China underProject U1813204.,,IEEE Transactions on Medical Imaging,,"Deep Learning; Diagnosis, Computer-Assisted; Humans; Magnetic Resonance Imaging; Male; Prostate",2020-02-17,2020,2020-02-17,2020-09,39,9,2713-2724,All OA; Green,Article,"Liu, Quande; Dou, Qi; Yu, Lequan; Heng, Pheng Ann","Liu, Quande (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong); Dou, Qi (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong); Yu, Lequan (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Radiation Oncology, Stanford University, Stanford, CA, 94305, USA); Heng, Pheng Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Beijing, 100864, China)","Dou, Qi (Chinese University of Hong Kong)","Liu, Quande (Chinese University of Hong Kong); Dou, Qi (Chinese University of Hong Kong); Yu, Lequan (Chinese University of Hong Kong; Stanford University); Heng, Pheng Ann (Chinese University of Hong Kong; Chinese Academy of Sciences)",99,89,6.4,51.02,http://arxiv.org/pdf/2002.03366,https://app.dimensions.ai/details/publication/pub.1124921558,46 Information and Computing Sciences; 4611 Machine Learning,
5637,pub.1101727496,10.1088/1361-6560/aab956,29570456,,Computer-aided diagnosis of prostate cancer using multi-parametric MRI: comparison between PUN and Tofts models,"Computer-aided diagnosis (CAD) systems are increasingly being used in clinical settings to report multi-parametric magnetic resonance imaging (mp-MRI) of the prostate. Usually, CAD systems automatically highlight cancer-suspicious regions to the radiologist, reducing reader variability and interpretation errors. Nevertheless, implementing this software requires the selection of which mp-MRI parameters can best discriminate between malignant and non-malignant regions. To exploit functional information, some parameters are derived from dynamic contrast-enhanced (DCE) acquisitions. In particular, much CAD software employs pharmacokinetic features, such as K trans and k ep, derived from the Tofts model, to estimate a likelihood map of malignancy. However, non-pharmacokinetic models can be also used to describe DCE-MRI curves, without any requirement for prior knowledge or measurement of the arterial input function, which could potentially lead to large errors in parameter estimation. In this work, we implemented an empirical function derived from the phenomenological universalities (PUN) class to fit DCE-MRI. The parameters of the PUN model are used in combination with T2-weighted and diffusion-weighted acquisitions to feed a support vector machine classifier to produce a voxel-wise malignancy likelihood map of the prostate. The results were all compared to those for a CAD system based on Tofts pharmacokinetic features to describe DCE-MRI curves, using different quality aspects of image segmentation, while also evaluating the number and size of false positive (FP) candidate regions. This study included 61 patients with 70 biopsy-proven prostate cancers (PCa). The metrics used to evaluate segmentation quality between the two CAD systems were not statistically different, although the PUN-based CAD reported a lower number of FP, with reduced size compared to the Tofts-based CAD. In conclusion, the CAD software based on PUN parameters is a feasible means with which to detect PCa, without affecting segmentation quality, and hence it could be successfully applied in clinical settings, improving the automated diagnosis process and reducing computational complexity.","This work was funded by Fondazione Piemontese per la Ricerca sul Cancro FPRC-onlus, 5 per Mille 2013 resources from the Italian Board of Health (grant Pro-Cure).",,Physics in Medicine and Biology,,"Aged; Algorithms; Contrast Media; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Prostatic Neoplasms; Retrospective Studies; Software",2018-05-01,2018,2018-05-01,2018-05-01,63,9,095004,Closed,Article,"Mazzetti, S; Giannini, V; Russo, F; Regge, D","Mazzetti, S (Department of Surgical Sciences, University of Torino, 10124 Turin, Italy; Department of Radiology, Candiolo Cancer Institute—FPO, IRCCS, 10060 Candiolo, Turin, Italy); Giannini, V (Department of Surgical Sciences, University of Torino, 10124 Turin, Italy; Department of Radiology, Candiolo Cancer Institute—FPO, IRCCS, 10060 Candiolo, Turin, Italy); Russo, F (Department of Radiology, Candiolo Cancer Institute—FPO, IRCCS, 10060 Candiolo, Turin, Italy); Regge, D (Department of Surgical Sciences, University of Torino, 10124 Turin, Italy; Department of Radiology, Candiolo Cancer Institute—FPO, IRCCS, 10060 Candiolo, Turin, Italy)",,"Mazzetti, S (University of Turin; Candiolo Cancer Institute); Giannini, V (University of Turin; Candiolo Cancer Institute); Russo, F (Candiolo Cancer Institute); Regge, D (University of Turin; Candiolo Cancer Institute)",7,4,0.36,4.26,,https://app.dimensions.ai/details/publication/pub.1101727496,51 Physical Sciences; 5105 Medical and Biological Physics,
5637,pub.1084517551,10.1007/s00330-017-4805-0,28386721,,Multiparametric magnetic resonance imaging of the prostate with computer-aided detection: experienced observer performance study,"ObjectivesTo compare the performance of experienced readers in detecting prostate cancer (PCa) using likelihood maps generated by a CAD system with that of unassisted interpretation of multiparametric magnetic resonance imaging (mp-MRI).MethodsThree experienced radiologists reviewed mp-MRI prostate cases twice. First, readers observed CAD marks on a likelihood map and classified as positive those suspicious for cancer. After 6 weeks, radiologists interpreted mp-MRI examinations unassisted, using their favourite protocol. Sensitivity, specificity, reading time and interobserver variability were compared for the two reading paradigms.ResultsThe dataset comprised 89 subjects of whom 35 with at least one significant PCa. Sensitivity was 80.9% (95% CI 72.1–88.0%) and 87.6% (95% CI 79.8–93.2; p = 0.105) for unassisted and CAD paradigm respectively. Sensitivity was higher with CAD for lesions with GS > 6 (91.3% vs 81.2%; p = 0.046) or diameter ≥10 mm (95.0% vs 80.0%; p = 0.006). Specificity was not affected by CAD. The average reading time with CAD was significantly lower (220 s vs 60 s; p < 0.001).ConclusionsExperienced readers using likelihood maps generated by a CAD scheme can detect more patients with ≥10 mm PCa lesions than unassisted MRI interpretation; overall reporting time is shorter. To gain more insight into CAD–human interaction, different reading paradigms should be investigated.Key points• With CAD, sensitivity increases in patients with prostate tumours ≥10 mm and/or GS > 6.• CAD significantly reduces reporting time of multiparametric MRI.• When using CAD, a marginal increase of inter-reader agreement was observed.",,,European Radiology,,"Aged; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Observer Variation; Prostate; Prostatic Neoplasms; Retrospective Studies; Sensitivity and Specificity",2017-04-06,2017,2017-04-06,2017-10,27,10,4200-4208,Closed,Article,"Giannini, Valentina; Mazzetti, Simone; Armando, Enrico; Carabalona, Silvia; Russo, Filippo; Giacobbe, Alessandro; Muto, Giovanni; Regge, Daniele","Giannini, Valentina (Department of Radiology at the Candiolo Cancer Institute, FPO, IRCCS, Strada Provinciale 142 km 3.95, 10060, Candiolo, Turin, Italy); Mazzetti, Simone (Department of Radiology at the Candiolo Cancer Institute, FPO, IRCCS, Strada Provinciale 142 km 3.95, 10060, Candiolo, Turin, Italy); Armando, Enrico (Department of Radiology at the Candiolo Cancer Institute, FPO, IRCCS, Strada Provinciale 142 km 3.95, 10060, Candiolo, Turin, Italy); Carabalona, Silvia (Department of Radiology at the Candiolo Cancer Institute, FPO, IRCCS, Strada Provinciale 142 km 3.95, 10060, Candiolo, Turin, Italy); Russo, Filippo (Department of Radiology at the Candiolo Cancer Institute, FPO, IRCCS, Strada Provinciale 142 km 3.95, 10060, Candiolo, Turin, Italy); Giacobbe, Alessandro (Department of Urology, San Giovanni Bosco Hospital, Turin, Italy); Muto, Giovanni (Department of Urology, University Campus Biomedico, Rome, Italy); Regge, Daniele (Department of Radiology at the Candiolo Cancer Institute, FPO, IRCCS, Strada Provinciale 142 km 3.95, 10060, Candiolo, Turin, Italy; Department of Surgical Sciences, University of Torino, A.O.U. Città della Salute e della Scienza, Via Genova 3, 10126, Turin, Italy)","Giannini, Valentina (Candiolo Cancer Institute)","Giannini, Valentina (Candiolo Cancer Institute); Mazzetti, Simone (Candiolo Cancer Institute); Armando, Enrico (Candiolo Cancer Institute); Carabalona, Silvia (Candiolo Cancer Institute); Russo, Filippo (Candiolo Cancer Institute); Giacobbe, Alessandro (Ospedale San Giovanni Bosco); Muto, Giovanni (Università Campus Bio-Medico); Regge, Daniele (Candiolo Cancer Institute; University of Turin)",44,25,2.01,11.06,,https://app.dimensions.ai/details/publication/pub.1084517551,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
5479,pub.1150454946,10.1016/j.media.2022.102596,36084564,PMC9400372,Distance-based detection of out-of-distribution silent failures for Covid-19 lung lesion segmentation,"Automatic segmentation of ground glass opacities and consolidations in chest computer tomography (CT) scans can potentially ease the burden of radiologists during times of high resource utilisation. However, deep learning models are not trusted in the clinical routine due to failing silently on out-of-distribution (OOD) data. We propose a lightweight OOD detection method that leverages the Mahalanobis distance in the feature space and seamlessly integrates into state-of-the-art segmentation pipelines. The simple approach can even augment pre-trained models with clinically relevant uncertainty quantification. We validate our method across four chest CT distribution shifts and two magnetic resonance imaging applications, namely segmentation of the hippocampus and the prostate. Our results show that the proposed method effectively detects far- and near-OOD samples across all explored scenarios.","This work was supported by the RACOON network under BMBF, Germany grant number [01KX2021]; and the Bundesministerium für Gesundheit (BMG), Germany with grant [ZMVI1-2520DAT03A].",,Medical Image Analysis,,"Humans; Male; COVID-19; Tomography, X-Ray Computed; Magnetic Resonance Imaging; Lung Diseases; Lung",2022-08-24,2022,2022-08-24,2022-11,82,,102596,All OA; Bronze,Article,"González, Camila; Gotkowski, Karol; Fuchs, Moritz; Bucher, Andreas; Dadras, Armin; Fischbach, Ricarda; Kaltenborn, Isabel Jasmin; Mukhopadhyay, Anirban","González, Camila (Darmstadt University of Technology, Karolinenplatz 5, 64289 Darmstadt, Germany. Electronic address: camila.gonzalez@gris.tu-darmstadt.de.); Gotkowski, Karol (Darmstadt University of Technology, Karolinenplatz 5, 64289 Darmstadt, Germany.); Fuchs, Moritz (Darmstadt University of Technology, Karolinenplatz 5, 64289 Darmstadt, Germany.); Bucher, Andreas (Uniklinik Frankfurt, Theodor-Stern-Kai 7, 60590 Frankfurt am Main, Germany.); Dadras, Armin (Uniklinik Frankfurt, Theodor-Stern-Kai 7, 60590 Frankfurt am Main, Germany.); Fischbach, Ricarda (Uniklinik Frankfurt, Theodor-Stern-Kai 7, 60590 Frankfurt am Main, Germany.); Kaltenborn, Isabel Jasmin (Uniklinik Frankfurt, Theodor-Stern-Kai 7, 60590 Frankfurt am Main, Germany.); Mukhopadhyay, Anirban (Darmstadt University of Technology, Karolinenplatz 5, 64289 Darmstadt, Germany.)","González, Camila (TU Darmstadt)","González, Camila (TU Darmstadt); Gotkowski, Karol (TU Darmstadt); Fuchs, Moritz (TU Darmstadt); Bucher, Andreas (); Dadras, Armin (); Fischbach, Ricarda (); Kaltenborn, Isabel Jasmin (); Mukhopadhyay, Anirban (TU Darmstadt)",1,1,,,https://doi.org/10.1016/j.media.2022.102596,https://app.dimensions.ai/details/publication/pub.1150454946,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,
5464,pub.1151831358,10.1088/1361-6560/ac99b4,36223780,,Effect of magnetic resonance imaging pre-processing on the performance of model-based prostate tumor probability mapping,"Objective. Multi-parametric magnetic resonance imaging (mpMRI) has become an important tool for the detection of prostate cancer in the past two decades. Despite the high sensitivity of MRI for tissue characterization, it often suffers from a lack of specificity. Several well-established pre-processing tools are publicly available for improving image quality and removing both intra- and inter-patient variability in order to increase the diagnostic accuracy of MRI. To date, most of these pre-processing tools have largely been assessed individually. In this study we present a systematic evaluation of a multi-step mpMRI pre-processing pipeline to automate tumor localization within the prostate using a previously trained model.Approach. The study was conducted on 31 treatment-naïve prostate cancer patients with a PI-RADS-v2 compliant mpMRI examination. Multiple methods were compared for each pre-processing step: (1) bias field correction, (2) normalization, and (3) deformable multi-modal registration. Optimal parameter values were estimated for each step on the basis of relevant individual metrics. Tumor localization was then carried out via a model-based approach that takes both mpMRI and prior clinical knowledge features as input. A sequential optimization approach was adopted for determining the optimal parameters and techniques in each step of the pipeline.Main results. The application of bias field correction alone increased the accuracy of tumor localization (area under the curve (AUC) = 0.77;p-value = 0.004) over unprocessed data (AUC = 0.74). Adding normalization to the pre-processing pipeline further improved diagnostic accuracy of the model to an AUC of 0.85 (p-value = 0.000 12). Multi-modal registration of apparent diffusion coefficient images to T2-weighted images improved the alignment of tumor locations in all but one patient, resulting in a slight decrease in accuracy (AUC = 0.84;p-value = 0.30).Significance. Overall, our findings suggest that the combined effect of multiple pre-processing steps with optimal values has the ability to improve the quantitative classification of prostate cancer using mpMRI. Clinical trials: NCT03378856 and NCT03367702.",This research was supported by the Réseau en Bio-Imagerie du Quebec (RBIQ 35450).,,Physics in Medicine and Biology,,Male; Humans; Prostatic Neoplasms; Magnetic Resonance Imaging; Multiparametric Magnetic Resonance Imaging; Prostate; Probability; Retrospective Studies,2022-12-13,2022,2022-12-13,2022-12-21,67,24,245018,All OA; Hybrid,Article,"Alley, Stephanie; Jackson, Edward; Olivié, Damien; Van der Heide, Uulke A; Ménard, Cynthia; Kadoury, Samuel","Alley, Stephanie (Polytechnique Montréal, Montréal, Québec, Canada); Jackson, Edward (The Netherlands Cancer Institute, Amsterdam, The Netherlands); Olivié, Damien (Centre Hospitalier de l’Université de Montréal, Montréal, Québec, Canada); Van der Heide, Uulke A (The Netherlands Cancer Institute, Amsterdam, The Netherlands); Ménard, Cynthia (Centre Hospitalier de l’Université de Montréal, Montréal, Québec, Canada); Kadoury, Samuel (Polytechnique Montréal, Montréal, Québec, Canada; Centre Hospitalier de l’Université de Montréal, Montréal, Québec, Canada)","Alley, Stephanie (Polytechnique Montréal)","Alley, Stephanie (Polytechnique Montréal); Jackson, Edward (Antoni van Leeuwenhoek Hospital); Olivié, Damien (Centre Hospitalier de l’Université de Montréal); Van der Heide, Uulke A (Antoni van Leeuwenhoek Hospital); Ménard, Cynthia (Centre Hospitalier de l’Université de Montréal); Kadoury, Samuel (Polytechnique Montréal; Centre Hospitalier de l’Université de Montréal)",0,0,,,https://doi.org/10.1088/1361-6560/ac99b4,https://app.dimensions.ai/details/publication/pub.1151831358,51 Physical Sciences; 5105 Medical and Biological Physics,
5443,pub.1091990029,10.1016/j.cobme.2017.09.009,29732440,PMC5931723,Computer-aided diagnosis of prostate cancer with MRI,"Multi-parametric magnetic resonance imaging (mp-MRI) has an increasingly important role in the diagnosis of prostate cancer. Due to the large amount of data and variations in mp-MRI, tumor detection can be affected by multiple factors, such as the observer's clinical experience, image quality, and appearance of the lesions. In order to improve the quantitative assessment of the disease and reduce the reporting time, various computer-aided diagnosis (CAD) systems have been designed to help radiologists identify lesions. This manuscript presents an overview of the literature regarding prostate CAD using mp-MRI, while focusing on the studies of the most recent five years. Current prostate CAD technologies and their utilization are discussed in this review.","This work was partially supported by NIH grants CA156775, CA176684, and CA204254, and by the Georgia Research Alliance Distinguished Scientists Award.",,Current Opinion in Biomedical Engineering,,,2017-09,2017,,2017-09,3,,20-27,All OA; Green,Article,"Fei, Baowei","Fei, Baowei (Department of Radiology and Imaging Sciences, Emory University School of Medicine, Atlanta, 1841 Clifton Road NE, GA 30329, USA; The Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, GA 30329, USA; Department of Mathematics and Computer Science, Emory College of Emory University, Atlanta, GA 30329, USA; Winship Cancer Institute of Emory University, Atlanta, GA 30329, USA)","Fei, Baowei (Emory University; The Wallace H. Coulter Department of Biomedical Engineering; Emory University; Winship Cancer Institute)","Fei, Baowei (Emory University; The Wallace H. Coulter Department of Biomedical Engineering; Emory University; Winship Cancer Institute)",21,10,0.77,3.15,https://europepmc.org/articles/pmc5931723?pdf=render,https://app.dimensions.ai/details/publication/pub.1091990029,40 Engineering; 4003 Biomedical Engineering,
5443,pub.1119769217,10.1016/j.diii.2019.06.012,31350218,,Computer-aided diagnosis system for characterizing ISUP grade≥2 prostate cancers at multiparametric MRI: A cross-vendor evaluation,"PURPOSE: To assess the performance of a computer-aided diagnosis (CADx) system trained at characterizing International Society of Urological Pathology (ISUP) grade≥2 peripheral zone (PZ) prostate cancers on multiparametric magnetic resonance imaging (mpMRI) examinations from a different institution and acquired on different scanners than those used for the training database.
PATIENTS AND METHODS: Preoperative mpMRIs of 74 men (median age, 65.7 years) treated by prostatectomy between 2014 and 2017 were retrospectively selected. One radiologist outlined suspicious lesions and scored them using Prostate Imaging-Reporting and Data System version 2 (PI-RADSv2); their CADx score was calculated using a classifier trained on an independent database of 106 patients treated by prostatectomy in another institution. The lesions' nature was assessed by comparison with prostatectomy whole-mounts. Diagnostic accuracy was estimated with areas under receiver operating characteristic curves (AUCs). Sensitivity and specificity were calculated using a CADx threshold (≥0.21) that yielded 95% sensitivity in the training database, and a PI-RADSv2≥3 threshold.
RESULTS: A total of 127 lesions (PZ, n=104; transition zone [TZ], n=23) were described. In PZ, CADx and PI-RADSv2 scores had similar AUCs for characterizing ISUP grade≥2 cancers (0.78 [95% confidence interval (CI): 0.69-0.87] vs. 0.74 [95%CI: 0.62-0.82], respectively) (P=0.59). Sensitivity and specificity were respectively 89% (95%CI: 82-97%) and 42% (95%CI: 26-58%) for the CADx score, and 97% (95%CI: 93-100%) and 37% (95%CI: 22-52%) for the PI-RADSv2 score. In TZ, both scores showed poor specificity.
CONCLUSION: In this external cohort, the CADx and PI-RADSv2 scores showed similar performances in characterizing ISUP grade≥2 cancers.",,"This work was supported by the RHU PERFUSE (ANR-17-RHUS-0006) of the Université Claude-Bernard Lyon 1 (UCBL), within the program “Investissements d’Avenir” operated by the French National Research Agency (ANR).",Diagnostic and Interventional Imaging,,"Aged; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Male; Multiparametric Magnetic Resonance Imaging; Prostatectomy; Prostatic Neoplasms; Retrospective Studies; Sensitivity and Specificity",2019-07-23,2019,2019-07-23,2019-12,100,12,801-811,All OA; Bronze,Article,"Transin, S.; Souchon, R.; Gonindard-Melodelima, C.; de Rozario, R.; Walker, P.; de la Vega, M. Funes; Loffroy, R.; Cormier, L.; Rouvière, O.","Transin, S. (Department of Radiology, University Hospital François-Mitterrand, 21000 Dijon, France); Souchon, R. (Inserm, U1032, LabTau, 69003 Lyon, France); Gonindard-Melodelima, C. (CNRS, UMR 5553, Laboratoire d’Ecologie Alpine, Université Grenoble-Alpes, 38041 Grenoble, France); de Rozario, R. (Inserm, U1032, LabTau, 69003 Lyon, France; Département Informatique, Faculté des Sciences et Technologies, Université Lyon 1, 69000 Lyon, France); Walker, P. (Medical Imaging Group, Laboratory of Electronics, Computer Science and Imaging (Le2I), CNRS 6306, University of Burgundy, 21000 Dijon, France; Department of MR Spectroscopy, University Hospital François-Mitterrand, 21000 Dijon, France); de la Vega, M. Funes (Department of Pathology, University Hospital François-Mitterrand, 21000 Dijon, France); Loffroy, R. (Department of Radiology, University Hospital François-Mitterrand, 21000 Dijon, France; Medical Imaging Group, Laboratory of Electronics, Computer Science and Imaging (Le2I), CNRS 6306, University of Burgundy, 21000 Dijon, France); Cormier, L. (Department of Urology, University Hospital François-Mitterrand, 21000 Dijon, France); Rouvière, O. (Inserm, U1032, LabTau, 69003 Lyon, France; Department of Urinary and Vascular Radiology, Hôpital Édouard-Herriot, Hospices Civils de Lyon, 69437 Lyon, France; Université de Lyon, Université Lyon 1, faculté de médecine Lyon Est, Lyon, France)","Rouvière, O. (Laboratory of Therapeutic Applications of Ultrasound; Hôpital Édouard-Herriot; University of Lyon System)","Transin, S. (); Souchon, R. (Laboratory of Therapeutic Applications of Ultrasound); Gonindard-Melodelima, C. (Laboratoire d'Écologie Alpine); de Rozario, R. (Laboratory of Therapeutic Applications of Ultrasound; Claude Bernard University Lyon 1); Walker, P. (University of Burgundy); de la Vega, M. Funes (); Loffroy, R. (University of Burgundy); Cormier, L. (); Rouvière, O. (Laboratory of Therapeutic Applications of Ultrasound; Hôpital Édouard-Herriot; University of Lyon System)",16,11,1.31,5.65,https://doi.org/10.1016/j.diii.2019.06.012,https://app.dimensions.ai/details/publication/pub.1119769217,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
5431,pub.1120692919,10.1007/s00330-019-06417-z,31468158,,Semi-automatic classification of prostate cancer on multi-parametric MR imaging using a multi-channel 3D convolutional neural network,"ObjectiveTo present a deep learning–based approach for semi-automatic prostate cancer classification based on multi-parametric magnetic resonance (MR) imaging using a 3D convolutional neural network (CNN).MethodsTwo hundred patients with a total of 318 lesions for which histological correlation was available were analyzed. A novel CNN was designed, trained, and validated using different combinations of distinct MRI sequences as input (e.g., T2-weighted, apparent diffusion coefficient (ADC), diffusion-weighted images, and K-trans) and the effect of different sequences on the network’s performance was tested and discussed. The particular choice of modeling approach was justified by testing all relevant data combinations. The model was trained and validated using eightfold cross-validation.ResultsIn terms of detection of significant prostate cancer defined by biopsy results as the reference standard, the 3D CNN achieved an area under the curve (AUC) of the receiver operating characteristics ranging from 0.89 (88.6% and 90.0% for sensitivity and specificity respectively) to 0.91 (81.2% and 90.5% for sensitivity and specificity respectively) with an average AUC of 0.897 for the ADC, DWI, and K-trans input combination. The other combinations scored less in terms of overall performance and average AUC, where the difference in performance was significant with a p value of 0.02 when using T2w and K-trans; and 0.00025 when using T2w, ADC, and DWI. Prostate cancer classification performance is thus comparable to that reported for experienced radiologists using the prostate imaging reporting and data system (PI-RADS). Lesion size and largest diameter had no effect on the network’s performance.ConclusionThe diagnostic performance of the 3D CNN in detecting clinically significant prostate cancer is characterized by a good AUC and sensitivity and high specificity.Key Points• Prostate cancer classification using a deep learning model is feasible and it allows direct processing of MR sequences without prior lesion segmentation.• Prostate cancer classification performance as measured by AUC is comparable to that of an experienced radiologist.• Perfusion MR images (K-trans), followed by DWI and ADC, have the highest effect on the overall performance; whereas T2w images show hardly any improvement.",,,European Radiology,,Area Under Curve; Biopsy; Deep Learning; Diffusion Magnetic Resonance Imaging; Humans; Male; Multiparametric Magnetic Resonance Imaging; Prostatic Neoplasms; ROC Curve; Sensitivity and Specificity,2019-08-29,2019,2019-08-29,2020-02,30,2,1243-1253,Closed,Article,"Aldoj, Nader; Lukas, Steffen; Dewey, Marc; Penzkofer, Tobias","Aldoj, Nader (Department of Radiology, Charité – Universitätsmedizin Berlin, Freie Universität Berlin, Humboldt-Universität zu Berlin, Charitéplatz 1, 10117, Berlin, Germany); Lukas, Steffen (Department of Radiology, Charité – Universitätsmedizin Berlin, Freie Universität Berlin, Humboldt-Universität zu Berlin, Charitéplatz 1, 10117, Berlin, Germany); Dewey, Marc (Department of Radiology, Charité – Universitätsmedizin Berlin, Freie Universität Berlin, Humboldt-Universität zu Berlin, Charitéplatz 1, 10117, Berlin, Germany; Berlin Institute of Health (BIH), Anna-Louisa-Karsch-Str. 2, 10178, Berlin, Germany); Penzkofer, Tobias (Department of Radiology, Charité – Universitätsmedizin Berlin, Freie Universität Berlin, Humboldt-Universität zu Berlin, Charitéplatz 1, 10117, Berlin, Germany; Berlin Institute of Health (BIH), Anna-Louisa-Karsch-Str. 2, 10178, Berlin, Germany)","Aldoj, Nader ; Dewey, Marc (; Berlin Institute of Health at Charité - Universitätsmedizin Berlin)","Aldoj, Nader (); Lukas, Steffen (); Dewey, Marc (Berlin Institute of Health at Charité - Universitätsmedizin Berlin); Penzkofer, Tobias (Berlin Institute of Health at Charité - Universitätsmedizin Berlin)",64,53,5.17,22.61,,https://app.dimensions.ai/details/publication/pub.1120692919,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
5427,pub.1112313855,10.1117/1.jmi.6.1.014501,30820440,PMC6384414,Prostate zonal segmentation in 1.5T and 3T T2W MRI using a convolutional neural network,"Zonal segmentation of the prostate gland using magnetic resonance imaging (MRI) is clinically important for prostate cancer (PCa) diagnosis and image-guided treatments. A two-dimensional convolutional neural network (CNN) based on the U-net architecture was evaluated for segmentation of the central gland (CG) and peripheral zone (PZ) using a dataset of 40 patients (34 PCa positive and 6 PCa negative) scanned on two different MRI scanners (1.5T GE and 3T Siemens). Images were cropped around the prostate gland to exclude surrounding tissues, resampled to 0.5 × 0.5 × 0.5    mm   voxels  and z  -score normalized before being propagated through the CNN. Performance was evaluated using the Dice similarity coefficient (DSC) and mean absolute distance (MAD) in a fivefold cross-validation setup. Overall performance showed DSC of 0.794 and 0.692, and MADs of 3.349 and 2.993 for CG and PZ, respectively. Dividing the gland into apex, mid, and base showed higher DSC for the midgland compared to apex and base for both CG and PZ. We found no significant difference in DSC between the two scanners. A larger dataset, preferably with multivendor scanners, is necessary for validation of the proposed algorithm; however, our results are promising and have clinical potential.",The authors of this paper would like to acknowledge Lemaître et al. for making the dataset publicly available.,,Journal of Medical Imaging,,,2019-01,2019,2019-02-22,2019-01,6,1,014501-014501,All OA; Green,Article,"Jensen, Carina; Sørensen, Kristine Storm; Jørgensen, Cecilia Klitgaard; Nielsen, Camilla Winther; Høy, Pia Christine; Langkilde, Niels Christian; Østergaard, Lasse Riis","Jensen, Carina (Aalborg University Hospital, Department of Medical Physics, Department of Oncology, Aalborg, Denmark); Sørensen, Kristine Storm (Aalborg University, Department of Health Science and Technology, Aalborg, Denmark); Jørgensen, Cecilia Klitgaard (Aalborg University, Department of Health Science and Technology, Aalborg, Denmark); Nielsen, Camilla Winther (Aalborg University, Department of Health Science and Technology, Aalborg, Denmark); Høy, Pia Christine (Aalborg University, Department of Health Science and Technology, Aalborg, Denmark); Langkilde, Niels Christian (Aalborg University Hospital, Department of Urology, Aalborg, Denmark); Østergaard, Lasse Riis (Aalborg University, Department of Health Science and Technology, Aalborg, Denmark)","Jensen, Carina (Aalborg University Hospital)","Jensen, Carina (Aalborg University Hospital); Sørensen, Kristine Storm (Aalborg University); Jørgensen, Cecilia Klitgaard (Aalborg University); Nielsen, Camilla Winther (Aalborg University); Høy, Pia Christine (Aalborg University); Langkilde, Niels Christian (Aalborg University Hospital); Østergaard, Lasse Riis (Aalborg University)",15,12,0.53,5.3,https://europepmc.org/articles/pmc6384414?pdf=render,https://app.dimensions.ai/details/publication/pub.1112313855,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
5262,pub.1106809642,10.1117/1.jmi.5.3.034502,30840719,PMC6126494,Classification of suspicious lesions on prostate multiparametric MRI using machine learning,"We present a radiomics-based approach developed for the SPIE-AAPM-NCI PROSTATEx challenge. The task was to classify clinically significant prostate cancer in multiparametric (mp) MRI. Data consisted of a ""training dataset"" (330 suspected lesions from 204 patients) and a ""test dataset"" (208 lesions/140 patients). All studies included T2-weighted (T2-W), proton density-weighted, dynamic contrast enhanced, and diffusion-weighted imaging. Analysis of the images was performed using the MIM imaging platform (MIM Software, Cleveland, Ohio). Prostate and peripheral zone contours were manually outlined on the T2-W images. A workflow for rigid fusion of the aforementioned images to T2-W was created in MIM. The suspicious lesion was outlined using the high b-value image. Intensity and texture features were extracted on four imaging modalities and characterized using nine histogram descriptors: 10%, 25%, 50%, 75%, 90%, mean, standard deviation, kurtosis, and skewness (216 features). Three classification methods were used: classification and regression trees (CART), random forests, and adaptive least absolute shrinkage and selection operator (LASSO). In the held out by the organizers test dataset, the areas under the curve (AUCs) were: 0.82 (random forests), 0.76 (CART), and 0.76 (adaptive LASSO). AUC of 0.82 was the fourth-highest score of 71 entries (32 teams) and the highest for feature-based methods.","This work was supported by National Cancer Institute [R01CA189295 and R01CA190105 to A.P.]. We would like to Harini Veeraraghavan, Ph.D., from Memorial Sloan Kettering Cancer Center for providing the initial version of the texture software. The prostate MR imaging was performed at the Radboud University Medical Centre (Radboudumc) in the Prostate MR Reference Center under supervision of prof. Dr. Barentsz. The Radboudumc is located in Nijmegen, The Netherlands. The dataset was collected and curated for research in computer aided diagnosis of prostate MR under supervision of Dr. Huisman, Radboudumc.",,Journal of Medical Imaging,,,2018-07,2018,2018-09-06,2018-07,5,3,034502-034502,All OA; Green,Article,"Kwon, Deukwoo; Reis, Isildinha M.; Breto, Adrian L.; Tschudi, Yohann; Gautney, Nicole; Zavala-Romero, Olmo; Lopez, Christopher; Ford, John C.; Punnen, Sanoj; Pollack, Alan; Stoyanova, Radka","Kwon, Deukwoo (University of Miami Miller School of Medicine, Sylvester Comprehensive Cancer Center, Biostatistics and Bioinformatics Shared Resource, Miami, Florida, United States); Reis, Isildinha M. (University of Miami Miller School of Medicine, Sylvester Comprehensive Cancer Center, Biostatistics and Bioinformatics Shared Resource, Miami, Florida, United States; University of Miami Miller School of Medicine, Department of Public Health Sciences, Miami, Florida, United States); Breto, Adrian L. (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States); Tschudi, Yohann (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States); Gautney, Nicole (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States); Zavala-Romero, Olmo (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States); Lopez, Christopher (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States); Ford, John C. (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States); Punnen, Sanoj (University of Miami Miller School of Medicine, Department of Urology, Miami, Florida, United States); Pollack, Alan (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States); Stoyanova, Radka (University of Miami Miller School of Medicine, Department of Radiation Oncology, Miami, Florida, United States)","Stoyanova, Radka (University of Miami)","Kwon, Deukwoo (Sylvester Comprehensive Cancer Center); Reis, Isildinha M. (Sylvester Comprehensive Cancer Center; University of Miami); Breto, Adrian L. (University of Miami); Tschudi, Yohann (University of Miami); Gautney, Nicole (University of Miami); Zavala-Romero, Olmo (University of Miami); Lopez, Christopher (University of Miami); Ford, John C. (University of Miami); Punnen, Sanoj (University of Miami); Pollack, Alan (University of Miami); Stoyanova, Radka (University of Miami)",27,17,1.4,7.88,https://europepmc.org/articles/pmc6126494?pdf=render,https://app.dimensions.ai/details/publication/pub.1106809642,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
5250,pub.1103840494,10.1002/jmri.26178,29734484,PMC6222024,Radiomic features from pretreatment biparametric MRI predict prostate cancer biochemical recurrence: Preliminary findings,"BACKGROUND: Radiomics or computer-extracted texture features derived from MRI have been shown to help quantitatively characterize prostate cancer (PCa). Radiomics have not been explored depth in the context of predicting biochemical recurrence (BCR) of PCa.
PURPOSE: To identify a set of radiomic features derived from pretreatment biparametric MRI (bpMRI) that may be predictive of PCa BCR.
STUDY TYPE: Retrospective.
SUBJECTS: In all, 120 PCa patients from two institutions, I1 and I2 , partitioned into training set D1 (N = 70) from I1 and independent validation set D2 (N = 50) from I2 . All patients were followed for ≥3 years.
SEQUENCE: 3T, T2 -weighted (T2 WI) and apparent diffusion coefficient (ADC) maps derived from diffusion-weighted sequences.
ASSESSMENT: PCa regions of interest (ROIs) on T2 WI were annotated by two experienced radiologists. Radiomic features from bpMRI (T2 WI and ADC maps) were extracted from the ROIs. A machine-learning classifier (CBCR ) was trained with the best discriminating set of radiomic features to predict BCR (pBCR ).
STATISTICAL TESTS: Wilcoxon rank-sum tests with P < 0.05 were considered statistically significant. Differences in BCR-free survival at 3 years using pBCR was assessed using the Kaplan-Meier method and compared with Gleason Score (GS), PSA, and PIRADS-v2.
RESULTS: Distribution statistics of co-occurrence of local anisotropic gradient orientation (CoLlAGe) and Haralick features from T2 WI and ADC were associated with BCR (P < 0.05) on D1 . CBCR predictions resulted in a mean AUC = 0.84 on D1 and AUC = 0.73 on D2 . A significant difference in BCR-free survival between the predicted classes (BCR + and BCR-) was observed (P = 0.02) on D2 compared to those obtained from GS (P = 0.8), PSA (P = 0.93) and PIRADS-v2 (P = 0.23).
DATA CONCLUSION: Radiomic features from pretreatment bpMRI can be predictive of PCa BCR after therapy and may help identify men who would benefit from adjuvant therapy.
LEVEL OF EVIDENCE: 4 Technical Efficacy: Stage 5 J. Magn. Reson. Imaging 2018;48:1626-1636.",Contract grant sponsor: National Cancer Institute of the National Institutes of Health; contract grant numbers: 1U24CA199374‐01; R01CA202752‐01A1; R01CA208236‐01A1; R01 CA216579‐01A1; R01 CA220581‐01A1; R21CA195152‐01; Contract grant sponsor: National Center for Research Resources; contract grant number: 1 C06 RR12463‐01; Contract grant sponsor: DOD Prostate Cancer Idea Development Award; DOD Peer Reviewed Cancer Research Program; contract grant number: W81XWH‐16‐1‐0329; Contract grant sponsor: Ohio Third Frontier Technology Validation Fund; Contract grant sponsor: Wallace H. Coulter Foundation Program in the Department of Biomedical Engineering and the Clinical and Translational Science Award Program (CTSA) at Case Western Reserve University.,,Journal of Magnetic Resonance Imaging,,"Aged; Aged, 80 and over; Algorithms; Diagnosis, Computer-Assisted; Diffusion Magnetic Resonance Imaging; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Neoplasm Grading; Neoplasm Recurrence, Local; Pattern Recognition, Automated; Prostatic Neoplasms; ROC Curve; Radiometry; Retrospective Studies",2018-05-07,2018,2018-05-07,2018-12,48,6,1626-1636,All OA; Green,Article,"Shiradkar, Rakesh; Ghose, Soumya; Jambor, Ivan; Taimen, Pekka; Ettala, Otto; Purysko, Andrei S.; Madabhushi, Anant","Shiradkar, Rakesh (Department of Biomedical Engineering, Case Western Reserve University, Cleveland, Ohio, USA); Ghose, Soumya (Department of Biomedical Engineering, Case Western Reserve University, Cleveland, Ohio, USA); Jambor, Ivan (Department of Diagnostic Radiology, University of Turku, Finland; Department of Radiology, Icahn School of Medicine at Mount Sinai, New York, New York, USA); Taimen, Pekka (Institute of Biomedicine, University of Turku, Turku, Finland; Department of Pathology, Turku University Hospital, Turku, Finland); Ettala, Otto (Department of Urology, Turku University Hospital, Turku, Finland); Purysko, Andrei S. (Section of Abdominal Imaging and Nuclear Radiology Department, Imaging Institute, Cleveland Clinic, Cleveland, Ohio, USA); Madabhushi, Anant (Department of Biomedical Engineering, Case Western Reserve University, Cleveland, Ohio, USA)","Shiradkar, Rakesh (Case Western Reserve University)","Shiradkar, Rakesh (Case Western Reserve University); Ghose, Soumya (Case Western Reserve University); Jambor, Ivan (University of Turku; Icahn School of Medicine at Mount Sinai); Taimen, Pekka (University of Turku; Turku University Hospital); Ettala, Otto (Turku University Hospital); Purysko, Andrei S. (Cleveland Clinic); Madabhushi, Anant (Case Western Reserve University)",88,41,5.56,25.68,https://europepmc.org/articles/pmc6222024?pdf=render,https://app.dimensions.ai/details/publication/pub.1103840494,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
5192,pub.1126095307,10.3390/cancers12040854,32244821,PMC7226478,"Progress towards Patient-Specific, Spatially-Continuous Radiobiological Dose Prescription and Planning in Prostate Cancer IMRT: An Overview","Advances in imaging have enabled the identification of prostate cancer foci with an initial application to focal dose escalation, with subvolumes created with image intensity thresholds. Through quantitative imaging techniques, correlations between image parameters and tumour characteristics have been identified. Mathematical functions are typically used to relate image parameters to prescription dose to improve the clinical relevance of the resulting dose distribution. However, these relationships have remained speculative or invalidated. In contrast, the use of radiobiological models during treatment planning optimisation, termed biological optimisation, has the advantage of directly considering the biological effect of the resulting dose distribution. This has led to an increased interest in the accurate derivation of radiobiological parameters from quantitative imaging to inform the models. This article reviews the progress in treatment planning using image-informed tumour biology, from focal dose escalation to the current trend of individualised biological treatment planning using image-derived radiobiological parameters, with the focus on prostate intensity-modulated radiotherapy (IMRT).",,This work was supported by Project Grant 1126955 from the Australian National Health and Medical Research Council.,Cancers,,,2020-04-01,2020,2020-04-01,,12,4,854,All OA; Gold,Article,"Her, Emily Jungmin; Haworth, Annette; Rowshanfarzad, Pejman; Ebert, Martin A.","Her, Emily Jungmin (Department of Physics, University of Western Australia, Crawley, WA 6009, Australia); Haworth, Annette (Institute of Medical Physics, University of Sydney, Camperdown, NSW 2050, Australia); Rowshanfarzad, Pejman (Department of Physics, University of Western Australia, Crawley, WA 6009, Australia); Ebert, Martin A. (Department of Physics, University of Western Australia, Crawley, WA 6009, Australia; Department of Radiation Oncology, Sir Charles Gairdner Hospital, Nedlands, WA 6009, Australia; D Clinics, Claremont, WA 6010, Australia)","Her, Emily Jungmin (University of Western Australia)","Her, Emily Jungmin (University of Western Australia); Haworth, Annette (The University of Sydney); Rowshanfarzad, Pejman (University of Western Australia); Ebert, Martin A. (University of Western Australia; Sir Charles Gairdner Hospital)",6,6,0.86,2.56,https://www.mdpi.com/2072-6694/12/4/854/pdf?version=1585896244,https://app.dimensions.ai/details/publication/pub.1126095307,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
5177,pub.1152613714,10.1109/tmi.2022.3220750,36350867,,A New Framework of Swarm Learning Consolidating Knowledge from Multi-Center Non-IID Data for Medical Image Segmentation,"Large training datasets are important for deep learning-based methods. For medical image segmentation, it could be however difficult to obtain large number of labeled training images solely from one center. Distributed learning, such as swarm learning, has the potential to use multi-center data without breaching data privacy. However, data distributions across centers can vary a lot due to the diverse imaging protocols and vendors (known as feature skew). Also, the regions of interest to be segmented could be different, leading to inhomogeneous label distributions (referred to as label skew). With such non-independently and identically distributed (Non-IID) data, the distributed learning could result in degraded models. In this work, we propose a novel swarm learning approach, which assembles local knowledge from each center while at the same time overcomes forgetting of global knowledge during local training. Specifically, the approach first leverages a label skew-awared loss to preserve the global label knowledge, and then aligns local feature distributions to consolidate global knowledge against local feature skew. We validated our method in three Non-IID scenarios using four public datasets, including the Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation (M&Ms) dataset, the Federated Tumor Segmentation (FeTS) dataset, the Multi-Modality Whole Heart Segmentation (MMWHS) dataset and the Multi-Site Prostate T2-weighted MRI segmentation (MSProsMRI) dataset. Results show that our method could achieve superior performance over existing methods. Code will be released via https://zmiclab.github.io/projects.html once the paper gets accepted.",,,IEEE Transactions on Medical Imaging,,,2022-11-09,2022,2022-11-09,2022-11-09,PP,99,1-1,Closed,Article,"Gao, Zheyao; Wu, Fuping; Gao, Weiguo; Zhuang, Xiahai","Gao, Zheyao (School of Data Science, Fudan University, Shanghai, China); Wu, Fuping (School of Data Science, Fudan University, Shanghai, China); Gao, Weiguo (School of Data Science, Fudan University, Shanghai, China); Zhuang, Xiahai (School of Data Science, Fudan University, Shanghai, China)",,"Gao, Zheyao (Fudan University); Wu, Fuping (Fudan University); Gao, Weiguo (Fudan University); Zhuang, Xiahai (Fudan University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152613714,46 Information and Computing Sciences; 4605 Data Management and Data Science; 4611 Machine Learning,
5176,pub.1142423458,10.1002/sim.9245,34747059,PMC9316890,Bayesian spatial models for voxel‐wise prostate cancer classification using multi‐parametric magnetic resonance imaging data,"Multi-parametric magnetic resonance imaging (mpMRI) has been playing an increasingly important role in the detection of prostate cancer (PCa). Various computer-aided detection algorithms were proposed for automated PCa detection by combining information in multiple mpMRI parameters. However, there are specific features of mpMRI, including between-voxel correlation within each prostate and heterogeneity across patients, that have not been fully explored but could potentially improve PCa detection if leveraged appropriately. This article proposes novel Bayesian approaches for voxel-wise PCa classification that accounts for spatial correlation and between-patient heterogeneity in the mpMRI data. Modeling the spatial correlation is challenging due to the extreme high dimensionality of the data, and we propose three scalable approaches based on Nearest Neighbor Gaussian Process (NNGP), reduced-rank approximation, and a conditional autoregressive (CAR) model that approximates a Gaussian Process with the Matérn covariance, respectively. Our simulation study shows that properly modeling the spatial correlation and between-patient heterogeneity can substantially improve PCa classification. Application to in vivo data illustrates that classification is improved by all three spatial modeling approaches considered, while modeling the between-patient heterogeneity does not further improve our classifiers. Among the proposed models, the NNGP-based model is recommended given its high classification accuracy and computational efficiency.","This work was supported by NCI R01 CA155268, NCI R01 CA241159, NCI P30 CA077598, NIBIB P41 EB027061, and the Assistant Secretary of Defense for Health affairs, through the Prostate Cancer Research Program under Award No. W81XWH‐15‐1‐0478. Opinions, interpretations, conclusions, and recommendations are those of the author and are not necessarily endorsed by the Department of Defense.","Funding information National Cancer Institute, P30 CA077598; R01 CA155268; R01 CA241159; National Institute of Biomedical Imaging and Bioengineering, P41 EB027061; the Assistant Secretary of Defense for Health affairs, Prostate Cancer Research Program, W81XWH‐15‐1‐0478",Statistics in Medicine,,Algorithms; Bayes Theorem; Humans; Magnetic Resonance Imaging; Male; Prostate; Prostatic Neoplasms,2021-11-07,2021,2021-11-07,2022-02-10,41,3,483-499,All OA; Green,Article,"Jin, Jin; Zhang, Lin; Leng, Ethan; Metzger, Gregory J.; Koopmeiners, Joseph S.","Jin, Jin (Division of Biostatistics, School of Public Health, University of Minnesota, Minneapolis, Minnesota, USA); Zhang, Lin (Division of Biostatistics, School of Public Health, University of Minnesota, Minneapolis, Minnesota, USA); Leng, Ethan (Department of Biomedical Engineering, University of Minnesota, Minneapolis, Minnesota, USA); Metzger, Gregory J. (Department of Radiology, Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, Minnesota, USA); Koopmeiners, Joseph S. (Division of Biostatistics, School of Public Health, University of Minnesota, Minneapolis, Minnesota, USA)","Jin, Jin (University of Minnesota)","Jin, Jin (University of Minnesota); Zhang, Lin (University of Minnesota); Leng, Ethan (University of Minnesota); Metzger, Gregory J. (University of Minnesota); Koopmeiners, Joseph S. (University of Minnesota)",2,2,,1.6,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9316890,https://app.dimensions.ai/details/publication/pub.1142423458,42 Health Sciences; 4202 Epidemiology; 49 Mathematical Sciences; 4905 Statistics,
5171,pub.1131090102,10.3390/s20185411,32967291,PMC7570598,Radiomics for Gleason Score Detection through Deep Learning,"Prostate cancer is classified into different stages, each stage is related to a different Gleason score. The labeling of a diagnosed prostate cancer is a task usually performed by radiologists. In this paper we propose a deep architecture, based on several convolutional layers, aimed to automatically assign the Gleason score to Magnetic Resonance Imaging (MRI) under analysis. We exploit a set of 71 radiomic features belonging to five categories: First Order, Shape, Gray Level Co-occurrence Matrix, Gray Level Run Length Matrix and Gray Level Size Zone Matrix. The radiomic features are gathered directly from segmented MRIs using two free-available dataset for research purpose obtained from different institutions. The results, obtained in terms of accuracy, are promising: they are ranging between 0.96 and 0.98 for Gleason score prediction.",,This research received no external funding.,Sensors,,Deep Learning; Humans; Magnetic Resonance Imaging; Male; Neoplasm Grading; Prostatic Neoplasms,2020-09-21,2020,2020-09-21,,20,18,5411,All OA; Gold,Article,"Brunese, Luca; Mercaldo, Francesco; Reginelli, Alfonso; Santone, Antonella","Brunese, Luca (Department of Medicine and Health Sciences “Vincenzo Tiberio”, University of Molise, 86100 Campobasso, Italy;, luca.brunese@unimol.it, (L.B.);, antonella.santone@unimol.it, (A.S.)); Mercaldo, Francesco (Department of Medicine and Health Sciences “Vincenzo Tiberio”, University of Molise, 86100 Campobasso, Italy;, luca.brunese@unimol.it, (L.B.);, antonella.santone@unimol.it, (A.S.); Institute for Informatics and Telematics, National Research Council of Italy, 56121 Pisa, Italy); Reginelli, Alfonso (Department of Precision Medicine, University of Campania “Luigi Vanvitelli”, 80100 Napoli, Italy;, alfonso.reginelli@unicampania.it); Santone, Antonella (Department of Medicine and Health Sciences “Vincenzo Tiberio”, University of Molise, 86100 Campobasso, Italy;, luca.brunese@unimol.it, (L.B.);, antonella.santone@unimol.it, (A.S.))","Mercaldo, Francesco (University of Molise; ; Institute of Informatics and Telematics)","Brunese, Luca (University of Molise); Mercaldo, Francesco (University of Molise; Institute of Informatics and Telematics); Reginelli, Alfonso (University of Campania ""Luigi Vanvitelli""); Santone, Antonella (University of Molise)",24,24,2.45,9.46,https://www.mdpi.com/1424-8220/20/18/5411/pdf?version=1600851319,https://app.dimensions.ai/details/publication/pub.1131090102,46 Information and Computing Sciences; 4606 Distributed Computing and Systems Software,3 Good Health and Well Being
5078,pub.1074203205,10.1007/s13246-016-0515-1,28120144,,Predicting prostate tumour location from multiparametric MRI using Gaussian kernel support vector machines: a preliminary study,"The performance of a support vector machine (SVM) algorithm was investigated to predict prostate tumour location using multi-parametric MRI (mpMRI) data. The purpose was to obtain information of prostate tumour location for the implementation of bio-focused radiotherapy. In vivo mpMRI data were collected from 16 patients prior to radical prostatectomy. Sequences included T2-weighted imaging, diffusion-weighted imaging and dynamic contrast enhanced imaging. In vivo mpMRI was registered with ‘ground truth’ histology, using ex vivo MRI as an intermediate registration step to improve accuracy. Prostate contours were delineated by a radiation oncologist and tumours were annotated on histology by a pathologist. Five patients with minimal imaging artefacts were selected for this study. A Gaussian kernel SVM was trained and tested on different patient data subsets. Parameters were optimised using leave-oneout cross validation. Signal intensities of mpMRI were used as features and histology annotations as true labels. Prediction accuracy, as well as area under the curve (AUC) of the receiver operating characteristics (ROC) curve, were used to assess performance. Results demonstrated the prediction accuracy ranged from 70.4 to 87.1% and AUC of ROC ranged from 0.81 to 0.94. Additional investigations showed the apparent diffusion coefficient map from diffusion weighted imaging was the most important imaging modality for predicting tumour location. Future work will incorporate additional patient data into the framework to increase the sensitivity and specificity of the model, and will be extended to incorporate predictions of biological characteristics of the tumour which will be used in bio-focused radiotherapy optimisation.","This research is supported by the Prostate Cancer Foundation of Australia, The University of Melbourne and Cancer Therapeutics CRC. The authors would also like to show their gratitude to Courtney Savill and Lauren Caspersz who have made substantial contributions during data collections.",,Physical and Engineering Sciences in Medicine,,Aged; Area Under Curve; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Prostatic Neoplasms; ROC Curve; Support Vector Machine,2017-01-24,2017,2017-01-24,2017-03,40,1,39-49,Closed,Article,"Sun, Yu; Reynolds, Hayley; Wraith, Darren; Williams, Scott; Finnegan, Mary E.; Mitchell, Catherine; Murphy, Declan; Ebert, Martin A.; Haworth, Annette","Sun, Yu (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, VIC, Australia; Department of Physical Sciences, Peter MacCallum Cancer Centre, Melbourne, VIC, Australia); Reynolds, Hayley (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, VIC, Australia; Department of Physical Sciences, Peter MacCallum Cancer Centre, Melbourne, VIC, Australia); Wraith, Darren (Institute of Health and Biomedical Innovation, Queensland University of Technology, Brisbane, QLD, Australia); Williams, Scott (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, VIC, Australia; Division of Radiation Oncology and Cancer Imaging, Peter MacCallum Cancer Centre, Melbourne, VIC, Australia); Finnegan, Mary E. (Department of Imaging, Imperial College Healthcare NHS Trust, London, UK; Department of Bioengineering, Imperial College London, London, UK); Mitchell, Catherine (Department of Pathology, Peter MacCallum Cancer Centre, Melbourne, VIC, Australia); Murphy, Declan (Division of Cancer Surgery, Peter MacCallum Cancer Centre, Melbourne, VIC, Australia); Ebert, Martin A. (Department of Radiation Oncology, Sir Charles Gairdner Hospital, Perth, WA, Australia; School of Physics, University of Western Australia, Perth, WA, Australia); Haworth, Annette (The Sir Peter MacCallum Department of Oncology, The University of Melbourne, Melbourne, VIC, Australia; Department of Physical Sciences, Peter MacCallum Cancer Centre, Melbourne, VIC, Australia)","Sun, Yu (University of Melbourne; Peter MacCallum Cancer Centre)","Sun, Yu (University of Melbourne; Peter MacCallum Cancer Centre); Reynolds, Hayley (University of Melbourne; Peter MacCallum Cancer Centre); Wraith, Darren (Queensland University of Technology); Williams, Scott (University of Melbourne; Peter MacCallum Cancer Centre); Finnegan, Mary E. (Imperial College Healthcare NHS Trust; Imperial College London); Mitchell, Catherine (Peter MacCallum Cancer Centre); Murphy, Declan (Peter MacCallum Cancer Centre); Ebert, Martin A. (Sir Charles Gairdner Hospital; University of Western Australia); Haworth, Annette (University of Melbourne; Peter MacCallum Cancer Centre)",27,12,1.17,12.62,,https://app.dimensions.ai/details/publication/pub.1074203205,51 Physical Sciences; 5105 Medical and Biological Physics,
5077,pub.1110507602,10.1016/j.ajur.2018.12.001,31061799,PMC6488694,The current role of prostate multiparametric magnetic resonance imaging,"Prostate multi-parametric magnetic resonance imaging (mpMRI) has shown excellent sensitivity for Gleason ≥7 cancers, especially when their volume is ≥0.5 mL. As a result, performing an mpMRI before prostate biopsy could improve the detection of clinically significant prostate cancer (csPCa) by adding targeted biopsies to systematic biopsies. Currently, there is a consensus that targeted biopsies improve the detection of csPCa in the repeat biopsy setting and at confirmatory biopsy in patients considering active surveillance. Several prospective multicentric controlled trials recently showed that targeted biopsy also improved csPCa detection in biopsy-naïve patients. The role of mpMRI and targeted biopsy during the follow-up of active surveillance remains unclear. Whether systematic biopsy could be omitted in case of negative mpMRI is also a matter of controversy. mpMRI did show excellent negative predictive values (NPV) in the literature, however, since NPV depends on the prevalence of the disease, negative mpMRI findings should be interpreted in the light of a priori risk for csPCa of the patient. Nomograms combining mpMRI findings and classical risk predictors (age, prostate-specific antigen density, digital rectal examination, etc.) will probably be developed in the future to decide whether a prostate biopsy should be obtained. mpMRI has a good specificity for detecting T3 stage cancers, but its sensitivity is low. It should therefore not be used routinely for staging purposes in low-risk patients. Nomograms combining mpMRI findings and other clinical and biochemical data will also probably be used in the future to better assess the risk of T3 stage disease.",,,Asian Journal of Urology,,,2018-12-11,2018,2018-12-11,2019-04,6,2,137-145,All OA; Gold,Article,"Rouviere, Olivier; Moldovan, Paul Cezar","Rouviere, Olivier (Hospices Civils de Lyon, Department of Urinary and Vascular Imaging, Hôpital Edouard Herriot, Lyon, France; Université de Lyon, Lyon, France; Université Lyon 1, faculté de médecine Lyon Est, Lyon, France); Moldovan, Paul Cezar (Hospices Civils de Lyon, Department of Urinary and Vascular Imaging, Hôpital Edouard Herriot, Lyon, France; Université de Lyon, Lyon, France; Université Lyon 1, faculté de médecine Lyon Est, Lyon, France)","Rouviere, Olivier (Hôpital Édouard-Herriot; University of Lyon System; Claude Bernard University Lyon 1)","Rouviere, Olivier (Hôpital Édouard-Herriot; University of Lyon System; Claude Bernard University Lyon 1); Moldovan, Paul Cezar (Hôpital Édouard-Herriot; University of Lyon System; Claude Bernard University Lyon 1)",13,6,0.78,3.79,https://doi.org/10.1016/j.ajur.2018.12.001,https://app.dimensions.ai/details/publication/pub.1110507602,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
5077,pub.1037008614,10.1016/j.compbiomed.2016.04.010,27107675,,A novel approach for quantification of time–intensity curves in a DCE-MRI image series with an application to prostate cancer,"This paper considers the problem of an automatic quantification of DCE-MRI curve shape patterns. In particular, the semi-quantitative approach which classifies DCE time-intensity curves into clusters representing the tree main shape patterns is proposed. The approach combines heuristic rules with the naive Bayes classifier. In particular, the descriptive parameters are firstly derived from pixel-by-pixel analysis of the DCE time intensity curves and then used to recognise the curves which without a doubt represent the three main shape patterns. These curves are next used to train the naive Bayes classifier intended to classify the remaining curves within the dataset. Results of applying the proposed approach to the DCE-MRI scans of patients with prostate cancer are presented and discussed. Additionally, the overall performance of the approach is estimated through the comparison with the ground truth results provided by the expert.",,,Computers in Biology and Medicine,,"Databases, Factual; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Prostatic Neoplasms",2016-04-16,2016,2016-04-16,2016-06,73,,119-130,Closed,Article,"Fabijańska, Anna","Fabijańska, Anna (Institute of Applied Computer Science, Lodz University of Technology, 18/22 Stefanowskiego Str., 90-924 Lodz, Poland)",,"Fabijańska, Anna (Lodz University of Technology)",16,6,0.31,3.78,,https://app.dimensions.ai/details/publication/pub.1037008614,31 Biological Sciences; 3102 Bioinformatics and Computational Biology; 42 Health Sciences; 4203 Health Services and Systems; 46 Information and Computing Sciences; 4601 Applied Computing,
4932,pub.1092341731,10.1007/s11934-017-0747-y,29064054,,HistoScanningTM to Detect and Characterize Prostate Cancer—a Review of Existing Literature,"Purpose of ReviewThe widely acknowledged limitations of the standard prostate cancer (PCa) diagnostic paradigm have provided an impetus to explore novel imaging modalities to diagnose, localize, and risk stratify PCa. As the body of literature focused on HistoScanning™(HS) grows, there is need for a comprehensive review of the clinical efficacy of this technology.Recent FindingsEighteen original, English language articles were found to adequately study the use of HistoScanning™ for prostate cancer diagnosis in the clinical setting. The articles were found by conducting a bibliographic search of PubMed in April 2017 in addition to utilizing references. The studies are divided into four groups based on study design. Study methods and quantitative data are summarized for each of the relevant articles. The results are synthesized to evaluate the utility of HistoScanning™ for the purpose of diagnosing PCa.SummaryDespite the promise of early pilot studies, there is a lack of consistent results across a number of further investigations of HistoScanning™. This becomes increasingly evident as study size increases. As various other modern diagnostic modalities continue to develop, the future of HistoScanning™, both alone and in conjunction with these technologies, remains unclear.",,,Current Urology Reports,,Humans; Image-Guided Biopsy; Male; Prostate; Prostatic Neoplasms; Ultrasonography,2017-10-24,2017,2017-10-24,2017-12,18,12,97,All OA; Green,Article,"Wysock, James S.; Xu, Alex; Orczyk, Clement; Taneja, Samir S.","Wysock, James S. (Division of Urologic Oncology, Department of Urology, New York University Langone Medical Center, New York, NY, USA); Xu, Alex (New York University School of Medicine, New York, NY, USA); Orczyk, Clement (Department of Urology, University College London Hospital, London, UK; Division of Surgery and Interventional Sciences, University College London, London, UK); Taneja, Samir S. (Division of Urologic Oncology, Department of Urology, New York University Langone Medical Center, New York, NY, USA)","Wysock, James S. (New York University Langone Medical Center)","Wysock, James S. (New York University Langone Medical Center); Xu, Alex (New York University); Orczyk, Clement (University College Hospital; University College London); Taneja, Samir S. (New York University Langone Medical Center)",6,3,0.37,1.51,https://discovery.ucl.ac.uk/10061438/1/Histoscanning%20manuscript%20final%20word%20file.pdf,https://app.dimensions.ai/details/publication/pub.1092341731,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4918,pub.1120636311,10.1002/jmri.26913,31456317,,Fully automated localization of prostate peripheral zone tumors on apparent diffusion coefficient map MR images using an ensemble learning method,"BACKGROUND: Accurate detection and localization of prostate cancer (PCa) in men undergoing prostate MRI is a fundamental step for future targeted prostate biopsies and treatment planning. Fully automated localization of peripheral zone (PZ) PCa using the apparent diffusion coefficient (ADC) map might be clinically useful.
PURPOSE/HYPOTHESIS: To describe automated localization of PCa in the PZ on ADC map MR images using an ensemble U-Net-based model.
STUDY TYPE: Retrospective, case-control.
POPULATION: In all, 226 patients (154 and 72 patients with and without clinically significant PZ PCa, respectively), training, and testing was performed using dataset images of 146 and 80 patients, respectively.
FIELD STRENGTH: 3T, ADC maps.
SEQUENCE: ADC map.
ASSESSMENT: The ground truth was established by manual delineation of the prostate and prostate PZ tumors on ADC maps by dedicated radiologists using MRI-radical prostatectomy maps as a reference standard. Statistical Tests: Performance of the ensemble model was evaluated using Dice similarity coefficient (DSC), sensitivity, and specificity metrics on a per-slice basis. Receiver operating characteristic (ROC) curve and area under the curve (AUC) were employed as well. The paired t-test was used to test the differences between the performances of constituent networks of the ensemble model.
RESULTS: Our developed algorithm yielded DSC, sensitivity, and specificity of 86.72% ± 9.93%, 85.76% ± 23.33%, and 76.44% ± 23.70%, respectively (mean ± standard deviation) on 80 test cases consisting of 41 and 39 instances from patients with and without clinically significant tumors including 660 extracted 2D slices. AUC was reported as 0.779.
DATA CONCLUSION: An ensemble U-Net-based approach can accurately detect and segment PCa in the PZ from ADC map MR prostate images.
LEVEL OF EVIDENCE: 4 Technical Efficacy: Stage 1 J. Magn. Reson. Imaging 2020;51:1223-1234.","We thank Drs. Steven Currin, Alayed Abdullah, and Sabarish Narayanasamy for their contribution towards segmentation of prostate MR images and Dr. Trevor A. Flood for his contribution in creating the prostate MRI‐Radical Prostatectomy database.",,Journal of Magnetic Resonance Imaging,,Diffusion Magnetic Resonance Imaging; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Prostatic Neoplasms; Retrospective Studies,2019-08-28,2019,2019-08-28,2020-04,51,4,1223-1234,Closed,Article,"Zabihollahy, Fatemeh; Ukwatta, Eranga; Krishna, Satheesh; Schieda, Nicola","Zabihollahy, Fatemeh (Department of Systems and Computer Engineering, Carleton University, Ottawa, Ontario, Canada); Ukwatta, Eranga (School of Engineering, University of Guelph, Guelph, Ontario, Canada); Krishna, Satheesh (Department of Medical Imaging, University of Toronto, Toronto, Ontario, Canada); Schieda, Nicola (Department of Radiology, University of Ottawa, Ottawa, Ontario, Canada)","Zabihollahy, Fatemeh (Carleton University)","Zabihollahy, Fatemeh (Carleton University); Ukwatta, Eranga (University of Guelph); Krishna, Satheesh (University of Toronto); Schieda, Nicola (University of Ottawa)",10,7,1.48,3.53,,https://app.dimensions.ai/details/publication/pub.1120636311,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4917,pub.1153574938,10.1016/j.diii.2022.11.005,36517398,,Artificial intelligence algorithms aimed at characterizing or detecting prostate cancer on MRI: How accurate are they when tested on independent cohorts? – A systematic review,"PURPOSE: The purpose of this study was to perform a systematic review of the literature on the diagnostic performance, in independent test cohorts, of artificial intelligence (AI)-based algorithms aimed at characterizing/detecting prostate cancer on magnetic resonance imaging (MRI).
MATERIALS AND METHODS: Medline, Embase and Web of Science were searched for studies published between January 2018 and September 2022, using a histological reference standard, and assessing prostate cancer characterization/detection by AI-based MRI algorithms in test cohorts composed of more than 40 patients and with at least one of the following independency criteria as compared to the training cohort: different institution, different population type, different MRI vendor, different magnetic field strength or strict temporal splitting.
RESULTS: Thirty-five studies were selected. The overall risk of bias was low. However, 23 studies did not use predefined diagnostic thresholds, which may have optimistically biased the results. Test cohorts fulfilled one to three of the five independency criteria. The diagnostic performance of the algorithms used as standalones was good, challenging that of human reading. In the 12 studies with predefined diagnostic thresholds, radiomics-based computer-aided diagnosis systems (assessing regions-of-interest drawn by the radiologist) tended to provide more robust results than deep learning-based computer-aided detection systems (providing probability maps). Two of the six studies comparing unassisted and assisted reading showed significant improvement due to the algorithm, mostly by reducing false positive findings.
CONCLUSION: Prostate MRI AI-based algorithms showed promising results, especially for the relatively simple task of characterizing predefined lesions. The best management of discrepancies between human reading and algorithm findings still needs to be defined.","The authors thank Florence Bouriot, from the central documentation of the Hospices Civils de Lyon, for her assistance with the computerized search of the Medline/PubMed, Embase and Web of Science databases. They also thank Heinrich von Busch and Robert Grimm, from Siemens Healthineers, for providing clarifications on the training cohorts of the vendor&#x27;s Prostate AI software.","This work was supported by the RHU PERFUSE (ANR-17-RHUS-0006) of the Université Claude-Bernard Lyon 1 (UCBL), within the program ‘‘Investissements d'Avenir’’ operated by the French National Research Agency (Agence Nationale de la Recherche) (Sébastien Crouzet, recipient).",Diagnostic and Interventional Imaging,,,2022-12-12,2022,2022-12-12,2022-12,,,,Closed,Article,"Rouvière, Olivier; Jaouen, Tristan; Baseilhac, Pierre; Benomar, Mohammed Lamine; Escande, Raphael; Crouzet, Sébastien; Souchon, Rémi","Rouvière, Olivier (Hospices Civils de Lyon, Hôpital Edouard Herriot, Department of Vascular and Urinary Imaging, Lyon 69003, France; Université Lyon 1, Faculté de médecine Lyon Est, Lyon 69003, France; LabTAU, INSERM, U1032, Lyon 69003, France. Electronic address: olivier.rouviere@netcourrier.com.); Jaouen, Tristan (LabTAU, INSERM, U1032, Lyon 69003, France.); Baseilhac, Pierre (Hospices Civils de Lyon, Hôpital Edouard Herriot, Department of Vascular and Urinary Imaging, Lyon 69003, France.); Benomar, Mohammed Lamine (LabTAU, INSERM, U1032, Lyon 69003, France; University of Ain Temouchent, Faculty of Science and Technology, Algeria.); Escande, Raphael (Hospices Civils de Lyon, Hôpital Edouard Herriot, Department of Vascular and Urinary Imaging, Lyon 69003, France.); Crouzet, Sébastien (Université Lyon 1, Faculté de médecine Lyon Est, Lyon 69003, France; LabTAU, INSERM, U1032, Lyon 69003, France; Hospices Civils de Lyon, Hôpital Edouard Herriot, Department of Urology, Lyon 69003, France.); Souchon, Rémi (LabTAU, INSERM, U1032, Lyon 69003, France.)","Rouvière, Olivier (Hôpital Édouard-Herriot; Claude Bernard University Lyon 1; Laboratory of Therapeutic Applications of Ultrasound)","Rouvière, Olivier (Hôpital Édouard-Herriot; Claude Bernard University Lyon 1; Laboratory of Therapeutic Applications of Ultrasound); Jaouen, Tristan (Laboratory of Therapeutic Applications of Ultrasound); Baseilhac, Pierre (Hôpital Édouard-Herriot); Benomar, Mohammed Lamine (Laboratory of Therapeutic Applications of Ultrasound); Escande, Raphael (Hôpital Édouard-Herriot); Crouzet, Sébastien (Claude Bernard University Lyon 1; Laboratory of Therapeutic Applications of Ultrasound; Hôpital Édouard-Herriot); Souchon, Rémi (Laboratory of Therapeutic Applications of Ultrasound)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153574938,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4911,pub.1153013167,10.1109/tmi.2022.3224067,36417741,,Causality-inspired Single-source Domain Generalization for Medical Image Segmentation,"Deep learning models usually suffer from the domain shift issue, where models trained on one source domain do not generalize well to other unseen domains. In this work, we investigate the single-source domain generalization problem: training a deep network that is robust to unseen domains, under the condition that training data are only available from one source domain, which is common in medical imaging applications. We tackle this problem in the context of cross-domain medical image segmentation. In this scenario, domain shifts are mainly caused by different acquisition processes. We propose a simple causality-inspired data augmentation approach to expose a segmentation model to synthesized domain-shifted training examples. Specifically, 1) to make the deep model robust to discrepancies in image intensities and textures, we employ a family of randomly-weighted shallow networks. They augment training images using diverse appearance transformations. 2) Further we show that spurious correlations among objects in an image are detrimental to domain robustness. These correlations might be taken by the network as domain-specific clues for making predictions, and they may break on unseen domains. We remove these spurious correlations via causal intervention. This is achieved by resampling the appearances of potentially correlated objects independently. The proposed approach is validated on three cross-domain segmentation scenarios: cross-modality (CT-MRI) abdominal image segmentation, cross-sequence (bSSFP-LGE) cardiac MRI segmentation, and cross-site prostate MRI segmentation. The proposed approach yields consistent performance gains compared with competitive methods when tested on unseen domains.",,,IEEE Transactions on Medical Imaging,,,2022-11-23,2022,2022-11-23,2022-11-23,PP,99,1-1,All OA; Green,Article,"Ouyang, Cheng; Chen, Chen; Li, Surui; Li, Zeju; Qin, Chen; Bai, Wenjia; Rueckert, Daniel","Ouyang, Cheng (Department of Computing, Imperial College London, UK); Chen, Chen (Department of Computing, Imperial College London, UK); Li, Surui (Department of Computing, Imperial College London, UK); Li, Zeju (Department of Computing, Imperial College London, UK); Qin, Chen (Department of Electrical and Electronic Engineering, Imperial College London, UK); Bai, Wenjia (Department of Computing, Imperial College London, UK); Rueckert, Daniel (Department of Computing, Imperial College London, UK)",,"Ouyang, Cheng (Imperial College London); Chen, Chen (Imperial College London); Li, Surui (Imperial College London); Li, Zeju (Imperial College London); Qin, Chen (Imperial College London); Bai, Wenjia (Imperial College London); Rueckert, Daniel (Imperial College London)",5,5,,,http://arxiv.org/pdf/2111.12525,https://app.dimensions.ai/details/publication/pub.1153013167,46 Information and Computing Sciences; 4611 Machine Learning,
4665,pub.1112457717,10.1186/s12880-019-0308-6,30819131,PMC6396464,Comparing radiomic classifiers and classifier ensembles for detection of peripheral zone prostate tumors on T2-weighted MRI: a multi-site study,"BackgroundFor most computer-aided diagnosis (CAD) problems involving prostate cancer detection via medical imaging data, the choice of classifier has been largely ad hoc, or been motivated by classifier comparison studies that have involved large synthetic datasets. More significantly, it is currently unknown how classifier choices and trends generalize across multiple institutions, due to heterogeneous acquisition and intensity characteristics (especially when considering MR imaging data). In this work, we empirically evaluate and compare a number of different classifiers and classifier ensembles in a multi-site setting, for voxel-wise detection of prostate cancer (PCa) using radiomic texture features derived from high-resolution in vivo T2-weighted (T2w) MRI.MethodsTwelve different supervised classifier schemes: Quadratic Discriminant Analysis (QDA), Support Vector Machines (SVMs), naïve Bayes, Decision Trees (DTs), and their ensemble variants (bagging, boosting), were compared in terms of classification accuracy as well as execution time. Our study utilized 85 prostate cancer T2w MRI datasets acquired from across 3 different institutions (1 for discovery, 2 for independent validation), from patients who later underwent radical prostatectomy. Surrogate ground truth for disease extent on MRI was established by expert annotation of pre-operative MRI through spatial correlation with corresponding ex vivo whole-mount histology sections. Classifier accuracy in detecting PCa extent on MRI on a per-voxel basis was evaluated via area under the ROC curve.ResultsThe boosted DT classifier yielded the highest cross-validated AUC (= 0.744) for detecting PCa in the discovery cohort. However, in independent validation, the boosted QDA classifier was identified as the most accurate and robust for voxel-wise detection of PCa extent (AUCs of 0.735, 0.683, 0.768 across the 3 sites). The next most accurate and robust classifier was the single QDA classifier, which also enjoyed the advantage of significantly lower computation times compared to any of the other methods.ConclusionsOur results therefore suggest that simpler classifiers (such as QDA and its ensemble variants) may be more robust, accurate, and efficient for prostate cancer CAD problems, especially in the context of multi-site validation.","Funding
        Research reported in this publication was supported by the NIH/NCI under award numbers 1U24CA199374-01, R01CA202752-01A1, R01CA208236-01A1, R01 CA216579-01A1, R01 CA220581-01A1, the National Center for Research Resources under award number 1 C06 RR12463-01,the DOD Prostate Cancer Idea Development Award (W81XWH-15-1-0558), the DOD Lung Cancer Investigator-Initiated Translational Research Award (W81XWH-18-1-0440), the DOD Peer Reviewed Cancer Research Program (W81XWH-16-1-0329), the Ohio Third Frontier Technology Validation Fund, the Cleveland Digestive Diseases Research Core Center, the NIH/NIDDK 1P30DK097948 DDRCC Pilot/Feasibility Award Program, the NIH/NIBIB CWRU Interdisciplinary Biomedical Imaging Training Program under award number 5T32EB00750912, Wallace H. Coulter Foundation Program in the Department of Biomedical Engineering, and the Clinical and Translational Science Award Program (CTSA) at Case Western Reserve University.
        The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. This work was also supported by the Office of the Assistant Secretary of Defense for Health Affairs, through different Peer Reviewed Research Programs. The U.S. Army Medical Research Acquisition Activity, 820 Chandler Street, Fort Detrick MD 21702-5014 is the awarding and administering acquisition office for these Programs. Opinions, interpretations, conclusions and recommendations are those of the authors and are not necessarily endorsed by the Department of Defense.
      
      
        Availability of data and materials
        All multi-site radiomic features used in the experiments conducted in this manuscript have been made publicly available at 10.5061/dryad.026cj63.",,BMC Medical Imaging,,"Diagnosis, Computer-Assisted; Discriminant Analysis; Humans; Interatrial Block; Magnetic Resonance Imaging; Male; Pattern Recognition, Automated; Prostate; Prostatic Neoplasms; ROC Curve; Sensitivity and Specificity; Support Vector Machine",2019-02-28,2019,2019-02-28,2019-12,19,1,22,All OA; Gold,Article,"Viswanath, Satish E.; Chirra, Prathyush V.; Yim, Michael C.; Rofsky, Neil M.; Purysko, Andrei S.; Rosen, Mark A.; Bloch, B Nicolas; Madabhushi, Anant","Viswanath, Satish E. (Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, USA); Chirra, Prathyush V. (Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, USA); Yim, Michael C. (College of Medicine, Northeast Ohio Medical University, Rootstown, OH, USA); Rofsky, Neil M. (Department of Radiology, UT Southwestern Medical Center, Dallas, TX, USA); Purysko, Andrei S. (Department of Radiology, Cleveland Clinic, Cleveland, OH, USA); Rosen, Mark A. (Department of Radiology, Hospital of the University of Pennsylvania, Philadelphia, PA, USA); Bloch, B Nicolas (Department of Radiology, Boston University School of Medicine, Boston, MA, USA); Madabhushi, Anant (Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, USA)","Viswanath, Satish E. (Case Western Reserve University)","Viswanath, Satish E. (Case Western Reserve University); Chirra, Prathyush V. (Case Western Reserve University); Yim, Michael C. (Northeast Ohio Medical University); Rofsky, Neil M. (The University of Texas Southwestern Medical Center); Purysko, Andrei S. (Cleveland Clinic); Rosen, Mark A. (Hospital of the University of Pennsylvania); Bloch, B Nicolas (Boston University); Madabhushi, Anant (Case Western Reserve University)",26,18,2.04,9.18,https://doi.org/10.1186/s12880-019-0308-6,https://app.dimensions.ai/details/publication/pub.1112457717,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4643,pub.1049972050,10.1186/s13014-016-0718-3,27829431,PMC5103611,Radiomics based targeted radiotherapy planning (Rad-TRaP): a computational framework for prostate cancer treatment planning with MRI,"BackgroundRadiomics or computer – extracted texture features have been shown to achieve superior performance than multiparametric MRI (mpMRI) signal intensities alone in targeting prostate cancer (PCa) lesions. Radiomics along with deformable co-registration tools can be used to develop a framework to generate targeted focal radiotherapy treatment plans.MethodsThe Rad-TRaP framework comprises three distinct modules. Firstly, a module for radiomics based detection of PCa lesions on mpMRI via a feature enabled machine learning classifier. The second module comprises a multi-modal deformable co-registration scheme to map tissue, organ, and delineated target volumes from MRI onto CT. Finally, the third module involves generation of a radiomics based dose plan on MRI for brachytherapy and on CT for EBRT using the target delineations transferred from the MRI to the CT.ResultsRad-TRaP framework was evaluated using a retrospective cohort of 23 patient studies from two different institutions. 11 patients from the first institution were used to train a radiomics classifier, which was used to detect tumor regions in 12 patients from the second institution. The ground truth cancer delineations for training the machine learning classifier were made by an experienced radiation oncologist using mpMRI, knowledge of biopsy location and radiology reports. The detected tumor regions were used to generate treatment plans for brachytherapy using mpMRI, and tumor regions mapped from MRI to CT to generate corresponding treatment plans for EBRT. For each of EBRT and brachytherapy, 3 dose plans were generated - whole gland homogeneous (PWH\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {WH}}$\end{document}) which is the current clinical standard, radiomics based focal (PRF\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {RF}}$\end{document}), and whole gland with a radiomics based focal boost (PWF\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {WF}}$\end{document}). Comparison of PRF\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {RF}}$\end{document} against conventional PWH\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {WH}}$\end{document} revealed that targeted focal brachytherapy would result in a marked reduction in dosage to the OARs while ensuring that the prescribed dose is delivered to the lesions. PWF\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {WF}}$\end{document} resulted in only a marginal increase in dosage to the OARs compared to PWH\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {WH}}$\end{document}. A similar trend was observed in case of EBRT with PRF\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {RF}}$\end{document} and PWF\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {WF}}$\end{document} compared to PWH\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {P}^{\text {WH}}$\end{document}.ConclusionsA radiotherapy planning framework to generate targeted focal treatment plans has been presented. The focal treatment plans generated using the framework showed reduction in dosage to the organs at risk and a boosted dose delivered to the cancerous lesions.",Not applicable.,,Radiation Oncology,,"Humans; Machine Learning; Magnetic Resonance Imaging; Male; Organs at Risk; Prostatic Neoplasms; Radiotherapy Dosage; Radiotherapy Planning, Computer-Assisted; Radiotherapy, Image-Guided; Retrospective Studies",2016-11-10,2016,2016-11-10,2016-12,11,1,148,All OA; Gold,Article,"Shiradkar, Rakesh; Podder, Tarun K; Algohary, Ahmad; Viswanath, Satish; Ellis, Rodney J.; Madabhushi, Anant","Shiradkar, Rakesh (Department of Biomedical Engineering, Case Western Reserve University, 44106, Cleveland, USA); Podder, Tarun K (Department of Radiation Oncology, Case School of Medicine, 44106, Cleveland, USA); Algohary, Ahmad (Department of Biomedical Engineering, Case Western Reserve University, 44106, Cleveland, USA); Viswanath, Satish (Department of Biomedical Engineering, Case Western Reserve University, 44106, Cleveland, USA); Ellis, Rodney J. (Department of Radiation Oncology, Case School of Medicine, 44106, Cleveland, USA); Madabhushi, Anant (Department of Biomedical Engineering, Case Western Reserve University, 44106, Cleveland, USA)","Shiradkar, Rakesh (Case Western Reserve University)","Shiradkar, Rakesh (Case Western Reserve University); Podder, Tarun K (Case Western Reserve University); Algohary, Ahmad (Case Western Reserve University); Viswanath, Satish (Case Western Reserve University); Ellis, Rodney J. (Case Western Reserve University); Madabhushi, Anant (Case Western Reserve University)",66,21,3.19,15.38,https://doi.org/10.1186/s13014-016-0718-3,https://app.dimensions.ai/details/publication/pub.1049972050,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4642,pub.1122908693,10.3389/fonc.2019.01313,31850209,PMC6901911,Detection of Dominant Intra-prostatic Lesions in Patients With Prostate Cancer Using an Artificial Neural Network and MR Multi-modal Radiomics Analysis,"Purpose: The aim of this study was to identify and rank discriminant radiomics features extracted from MR multi-modal images to construct an adaptive model for characterization of Dominant Intra-prostatic Lesions (DILs) from normal prostatic gland tissues (NT). Methods and Materials: Two cohorts were retrospectively studied: Group A consisted of 98 patients and Group B 19 patients. Two image modalities were acquired using a 3.0T MR scanner: Axial T2 Weighted (T2W) and axial diffusion weighted (DW) imaging. A linear regression method was used to construct apparent diffusion coefficient (ADC) maps from DW images. DILs and the NT in the mirrored location were drawn on each modality. One hundred and sixty-eight radiomics features were extracted from DILs and NT. A Partial-Least-Squares-Correlation (PLSC) with one-way ANOVA along with bootstrapping ratio techniques were recruited to identify and rank the most discriminant latent variables. An artificial neural network (ANN) was constructed based on the optimal latent variable feature to classify the DILs and NTs. Nineteen patients were randomly chosen to test the contour variability effect on the radiomics analysis and the performance of the ANN. Finally, the trained ANN and a two dimension (2D) convolutional sampling method were combined and used to estimate DIL-NT probability map for two test cases. Results: Among 168 radiomics-based latent variables, only the first four variables of each modality in the PLSC space were found to be significantly different between the DILs and NTs. Area Under Receiver Operating Characteristic (AUROC), Positive Predictive and Negative Predictive values (PPV and NPV) for the conventional method were 94%, 0.95, and 0.92, respectively. When the feature vector was randomly permuted 10,000 times, a very strong permutation-invariant efficiency (p < 0.0001) was achieved. The radiomic-based latent variables of the NTs and DILs showed no statistically significant differences (Fstatistic < Fc = 4.11 with Confidence Level of 95% for all 8 variables) against contour variability. Dice coefficients between DIL-NT probability map and physician contours for the two test cases were 0.82 and 0.71, respectively. Conclusion: This study demonstrates the high performance of combining radiomics information extracted from multimodal MR information such as T2WI and ADC maps, and adaptive models to detect DILs in patients with PCa.","Authors would also like to thank The Cancer Imaging Archive (TCIA) sponsored by the SPIE, NCI/NIH, AAPM, and Radboud University for sharing the MRI and clinical information of PCa patients that were used in this study.",,Frontiers in Oncology,,,2019-11-26,2019,2019-11-26,,9,,1313,All OA; Gold,Article,"Bagher-Ebadian, Hassan; Janic, Branislava; Liu, Chang; Pantelic, Milan; Hearshen, David; Elshaikh, Mohamed; Movsas, Benjamin; Chetty, Indrin J.; Wen, Ning","Bagher-Ebadian, Hassan (Department of Radiation Oncology, Henry Ford Health System, Detroit, MI, United States); Janic, Branislava (Department of Radiation Oncology, Henry Ford Health System, Detroit, MI, United States); Liu, Chang (Department of Radiation Oncology, Henry Ford Health System, Detroit, MI, United States); Pantelic, Milan (Department of Radiology, Henry Ford Health System, Detroit, MI, United States); Hearshen, David (Department of Radiology, Henry Ford Health System, Detroit, MI, United States); Elshaikh, Mohamed (Department of Radiation Oncology, Henry Ford Health System, Detroit, MI, United States); Movsas, Benjamin (Department of Radiation Oncology, Henry Ford Health System, Detroit, MI, United States); Chetty, Indrin J. (Department of Radiation Oncology, Henry Ford Health System, Detroit, MI, United States); Wen, Ning (Department of Radiation Oncology, Henry Ford Health System, Detroit, MI, United States)","Wen, Ning (Henry Ford Health System)","Bagher-Ebadian, Hassan (Henry Ford Health System); Janic, Branislava (Henry Ford Health System); Liu, Chang (Henry Ford Health System); Pantelic, Milan (Henry Ford Health System); Hearshen, David (Henry Ford Health System); Elshaikh, Mohamed (Henry Ford Health System); Movsas, Benjamin (Henry Ford Health System); Chetty, Indrin J. (Henry Ford Health System); Wen, Ning (Henry Ford Health System)",18,16,1.23,5.39,https://www.frontiersin.org/articles/10.3389/fonc.2019.01313/pdf,https://app.dimensions.ai/details/publication/pub.1122908693,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis,
4383,pub.1117165259,10.1117/1.jmi.6.2.024502,31259199,PMC6566001,Multisite evaluation of radiomic feature reproducibility and discriminability for identifying peripheral zone prostate tumors on MRI,"Recent advances in the field of radiomics have enabled the development of a number of prognostic and predictive imaging-based tools for a variety of diseases. However, wider clinical adoption of these tools is contingent on their generalizability across multiple sites and scanners. This may be particularly relevant in the context of radiomic features derived from T1- or T2-weighted magnetic resonance images (MRIs), where signal intensity values are known to lack tissue-specific meaning and vary based on differing acquisition protocols between institutions. We present the first empirical study of benchmarking five different radiomic feature families in terms of both reproducibility and discriminability in a multisite setting, specifically, for identifying prostate tumors in the peripheral zone on MRI. Our cohort comprised 147 patient T2-weighted MRI datasets from four different sites, all of which are first preprocessed to correct for acquisition-related artifacts such as bias field, differing voxel resolutions, and intensity drift (nonstandardness). About 406 three-dimensional voxel-wise radiomic features from five different families (gray, Haralick, gradient, Laws, and Gabor) were evaluated in a cross-site setting to determine (a) how reproducible they are within a relatively homogeneous nontumor tissue region and (b) how well they could discriminate tumor regions from nontumor regions. Our results demonstrate that a majority of the popular Haralick features are reproducible in over 99% of all cross-site comparisons, as well as achieve excellent cross-site discriminability (classification accuracy of ≈ 0.8  ). By contrast, a majority of Laws features are highly variable across sites (reproducible in < 75 %  of all cross-site comparisons) as well as resulting in low cross-site classifier accuracies ( < 0.6  ), likely due to a large number of noisy filter responses that can be extracted. These trends suggest that only a subset of radiomic features and associated parameters may be both reproducible and discriminable enough for use within machine learning classifier schemes.","Research reported in this publication was supported by the National Cancer Institute of the National Institutes of Health under Award Nos. 1U24CA199374-01, R01CA202752-01A1, R01CA208236-01A1, R01CA216579-01A1, R01CA220581-01A1, 1U01CA239055-01; National Center for Research Resources under Award No. 1 C06 RR12463-01; VA Merit Review Award IBX004121A from the United States Department of Veterans Affairs Biomedical Laboratory Research and Development Service; the DOD Prostate Cancer Idea Development Award (W81XWH-15-1-0558); the DOD Lung Cancer Investigator-Initiated Translational Research Award (W81XWH-18-1-0440); the DOD Peer Reviewed Cancer Research Program (W81XWH-16-1-0329); the Ohio Third Frontier Technology Validation Fund; the Wallace H. Coulter Foundation Program in the Department of Biomedical Engineering, and the Clinical and Translational Science Award Program (CTSA) at Case Western Reserve University. Initial finding of this research were published in the 2018 SPIE Proceedings along with an oral presentation, though significant changes and additions have been made since that time.51 The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health, the U.S. Department of Veterans Affairs, the Department of Defense, the United States Government, or SPIE.",,Journal of Medical Imaging,,,2019-04,2019,2019-06-14,2019-04,6,2,024502-024502,All OA; Bronze,Article,"Chirra, Prathyush; Leo, Patrick; Yim, Michael; Bloch, B. Nicolas; Rastinehad, Ardeshir R.; Purysko, Andrei; Rosen, Mark; Madabhushi, Anant; Viswanath, Satish E.","Chirra, Prathyush (Case Western Reserve University, Department of Biomedical Engineering, Cleveland, Ohio, United States); Leo, Patrick (Case Western Reserve University, Department of Biomedical Engineering, Cleveland, Ohio, United States); Yim, Michael (Northeast Ohio Medical University, College of Medicine, Rootstown, Ohio, United States); Bloch, B. Nicolas (Boston University School of Medicine, Department of Radiology, Boston, Massachusetts, United States); Rastinehad, Ardeshir R. (Icahn School of Medicine at Mount Sinai, Department of Urology, New York, New York, United States); Purysko, Andrei (Cleveland Clinic, Department of Radiology, Cleveland, Ohio, United States); Rosen, Mark (Hospital of the University of Pennsylvania, Department of Radiology, Philadelphia, Pennsylvania, United States); Madabhushi, Anant (Case Western Reserve University, Department of Biomedical Engineering, Cleveland, Ohio, United States; Louis Stokes Cleveland Veterans Administration Medical Center, Cleveland, Ohio, United States); Viswanath, Satish E. (Case Western Reserve University, Department of Biomedical Engineering, Cleveland, Ohio, United States)","Chirra, Prathyush (Case Western Reserve University)","Chirra, Prathyush (Case Western Reserve University); Leo, Patrick (Case Western Reserve University); Yim, Michael (Northeast Ohio Medical University); Bloch, B. Nicolas (Boston University); Rastinehad, Ardeshir R. (Icahn School of Medicine at Mount Sinai); Purysko, Andrei (Cleveland Clinic); Rosen, Mark (Hospital of the University of Pennsylvania); Madabhushi, Anant (Case Western Reserve University; Louis Stokes Cleveland VA Medical Center); Viswanath, Satish E. (Case Western Reserve University)",26,18,1.98,10.91,https://www.spiedigitallibrary.org/journals/Journal-of-Medical-Imaging/volume-6/issue-2/024502/Multisite-evaluation-of-radiomic-feature-reproducibility-and-discriminability-for-identifying/10.1117/1.JMI.6.2.024502.pdf,https://app.dimensions.ai/details/publication/pub.1117165259,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,3 Good Health and Well Being
4376,pub.1112445197,10.1109/tmi.2019.2901928,30835218,,Joint Prostate Cancer Detection and Gleason Score Prediction in mp-MRI via FocalNet,"Multi-parametric MRI (mp-MRI) is considered the best non-invasive imaging modality for diagnosing prostate cancer (PCa). However, mp-MRI for PCa diagnosis is currently limited by the qualitative or semi-quantitative interpretation criteria, leading to inter-reader variability and a suboptimal ability to assess lesion aggressiveness. Convolutional neural networks (CNNs) are a powerful method to automatically learn the discriminative features for various tasks, including cancer detection. We propose a novel multi-class CNN, FocalNet, to jointly detect PCa lesions and predict their aggressiveness using Gleason score (GS). FocalNet characterizes lesion aggressiveness and fully utilizes distinctive knowledge from mp-MRI. We collected a prostate mp-MRI dataset from 417 patients who underwent 3T mp-MRI exams prior to robotic-assisted laparoscopic prostatectomy. FocalNet was trained and evaluated in this large study cohort with fivefold cross validation. In the free-response receiver operating characteristics (FROC) analysis for lesion detection, FocalNet achieved 89.7% and 87.9% sensitivity for index lesions and clinically significant lesions at one false positive per patient, respectively. For the GS classification, evaluated by the receiver operating characteristics (ROC) analysis, FocalNet received the area under the curve of 0.81 and 0.79 for the classifications of clinically significant PCa (GS ≥ 3 + 4) and PCa with GS ≥ 4 + 3, respectively. With the comparison to the prospective performance of radiologists using the current diagnostic guideline, FocalNet demonstrated comparable detection sensitivity for index lesions and clinically significant lesions, only 3.4% and 1.5% lower than highly experienced radiologists without statistical significance.","This work was supported by the Integrated Diagnostics Program, Department of Radiological Sciences and Pathology, David Geffen School of Medicine, UCLA.",,IEEE Transactions on Medical Imaging,,"Humans; Image Interpretation, Computer-Assisted; Male; Multiparametric Magnetic Resonance Imaging; Neoplasm Grading; Neural Networks, Computer; Prostate; Prostatic Neoplasms",2019-02-27,2019,2019-02-27,2019-11,38,11,2496-2506,All OA; Green,Article,"Cao, Ruiming; Bajgiran, Amirhossein Mohammadian; Mirak, Sohrab Afshari; Shakeri, Sepideh; Zhong, Xinran; Enzmann, Dieter; Raman, Steven; Sung, Kyunghyun","Cao, Ruiming (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA; Department of Computer Science, University of California at Los Angeles, Los Angeles, CA, 90095, USA); Bajgiran, Amirhossein Mohammadian (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA); Mirak, Sohrab Afshari (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA); Shakeri, Sepideh (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA); Zhong, Xinran (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA); Enzmann, Dieter (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA); Raman, Steven (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA); Sung, Kyunghyun (Department of Radiology, University of California at Los Angeles, Los Angeles, CA, 90095, USA)","Cao, Ruiming (University of California, Los Angeles; University of California, Los Angeles)","Cao, Ruiming (University of California, Los Angeles; University of California, Los Angeles); Bajgiran, Amirhossein Mohammadian (University of California, Los Angeles); Mirak, Sohrab Afshari (University of California, Los Angeles); Shakeri, Sepideh (University of California, Los Angeles); Zhong, Xinran (University of California, Los Angeles); Enzmann, Dieter (University of California, Los Angeles); Raman, Steven (University of California, Los Angeles); Sung, Kyunghyun (University of California, Los Angeles)",114,94,6.43,,https://escholarship.org/content/qt9zt9g3wt/qt9zt9g3wt.pdf?t=pq5vml,https://app.dimensions.ai/details/publication/pub.1112445197,40 Engineering; 46 Information and Computing Sciences,
4372,pub.1111223831,10.1073/pnas.1815735116,30617074,PMC6347698,Computer simulations suggest that prostate enlargement due to benign prostatic hyperplasia mechanically impedes prostate cancer growth,"Prostate cancer and benign prostatic hyperplasia are common genitourinary diseases in aging men. Both pathologies may coexist and share numerous similarities, which have suggested several connections or some interplay between them. However, solid evidence confirming their existence is lacking. Recent studies on extensive series of prostatectomy specimens have shown that tumors originating in larger prostates present favorable pathological features. Hence, large prostates may exert a protective effect against prostate cancer. In this work, we propose a mechanical explanation for this phenomenon. The mechanical stress fields that originate as tumors enlarge have been shown to slow down their dynamics. Benign prostatic hyperplasia contributes to these mechanical stress fields, hence further restraining prostate cancer growth. We derived a tissue-scale, patient-specific mechanically coupled mathematical model to qualitatively investigate the mechanical interaction of prostate cancer and benign prostatic hyperplasia. This model was calibrated by studying the deformation caused by each disease independently. Our simulations show that a history of benign prostatic hyperplasia creates mechanical stress fields in the prostate that impede prostatic tumor growth and limit its invasiveness. The technology presented herein may assist physicians in the clinical management of benign prostate hyperplasia and prostate cancer by predicting pathological outcomes on a tissue-scale, patient-specific basis.","We thank Pablo Orosa-Iglesias (Universidade da Coruña, Spain) for his valuable help in the construction of the prostate mesh. We acknowledge the Centro de Supercomputación de Galicia (Santiago de Compostela, Spain) for providing high-performance computing resources that contributed to the results presented in this paper. G.L., P.D.-F., and H.G. were partially supported by the European Research Council (Contract 307201) and Xunta de Galicia (Consellería de Cultura, Educación e Ordenación Universitaria). G.L. and A.R. were partially supported by Fondazione Cariplo–Regione Lombardia through the project “Verso nuovi strumenti di simulazione super veloci ed accurati basati sull’analisi isogeometrica,” within the program RST–rafforzamento.",,Proceedings of the National Academy of Sciences of the United States of America,,Computer Simulation; Electric Impedance; Humans; Hypertrophy; Male; Prostate; Prostatic Hyperplasia; Prostatic Neoplasms,2019-01-07,2019,2019-01-07,2019-01-22,116,4,1152-1161,All OA; Bronze,Article,"Lorenzo, Guillermo; Hughes, Thomas J R; Dominguez-Frojan, Pablo; Reali, Alessandro; Gomez, Hector","Lorenzo, Guillermo (Departamento de Matemáticas, Universidade da Coruña, 15071 A Coruña, Spain; hughes@ices.utexas.edu guillermo.lorenzo@unipv.it.; Department of Civil Engineering and Architecture, University of Pavia, 27100 Pavia, Italy.); Hughes, Thomas J R (Institute for Computational Engineering and Sciences, The University of Texas at Austin, Austin, TX 78712-1229; hughes@ices.utexas.edu guillermo.lorenzo@unipv.it.); Dominguez-Frojan, Pablo (School of Mechanical Engineering, Purdue University, West Lafayette, IN 47907.); Reali, Alessandro (Department of Civil Engineering and Architecture, University of Pavia, 27100 Pavia, Italy.); Gomez, Hector (School of Mechanical Engineering, Purdue University, West Lafayette, IN 47907.)","Lorenzo, Guillermo (University of A Coruña; University of Pavia); Hughes, Thomas J R (The University of Texas at Austin)","Lorenzo, Guillermo (University of A Coruña; University of Pavia); Hughes, Thomas J R (The University of Texas at Austin); Dominguez-Frojan, Pablo (Purdue University West Lafayette); Reali, Alessandro (University of Pavia); Gomez, Hector (Purdue University West Lafayette)",66,51,2.67,23.31,https://www.pnas.org/content/pnas/116/4/1152.full.pdf,https://app.dimensions.ai/details/publication/pub.1111223831,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4371,pub.1032306523,10.1016/j.compbiomed.2015.02.009,25747341,,Computer-Aided Detection and diagnosis for prostate cancer based on mono and multi-parametric MRI: A review,"Prostate cancer is the second most diagnosed cancer of men all over the world. In the last few decades, new imaging techniques based on Magnetic Resonance Imaging (MRI) have been developed to improve diagnosis. In practise, diagnosis can be affected by multiple factors such as observer variability and visibility and complexity of the lesions. In this regard, computer-aided detection and computer-aided diagnosis systems have been designed to help radiologists in their clinical practice. Research on computer-aided systems specifically focused for prostate cancer is a young technology and has been part of a dynamic field of research for the last 10 years. This survey aims to provide a comprehensive review of the state-of-the-art in this lapse of time, focusing on the different stages composing the work-flow of a computer-aided system. We also provide a comparison between studies and a discussion about the potential avenues for future research. In addition, this paper presents a new public online dataset which is made available to the research community with the aim of providing a common evaluation framework to overcome some of the current limitations identified in this survey.",G. Lemaître was supported by the Generalitat de Catalunya (Grant no. FI-DGR2012) and partly by the Mediterranean Office for Youth (Grant no. 2011/018/06). We would like to acknowledge Sharad Nagappa for all the discussions involved and his precious advices and corrections regarding the reduction of this entire manuscript.,,Computers in Biology and Medicine,,"Carcinoma; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Mass Screening; Medical Informatics; Neoplasm Grading; Neural Networks, Computer; Observer Variation; Prostatic Neoplasms; Reproducibility of Results; Research Design; Software; Time Factors",2015-02-20,2015,2015-02-20,2015-05,60,,8-31,All OA; Green,Article,"Lemaître, Guillaume; Martí, Robert; Freixenet, Jordi; Vilanova, Joan C.; Walker, Paul M.; Meriaudeau, Fabrice","Lemaître, Guillaume (LE2I-UMR CNRS 6306, Université de Bourgogne, 12 rue de la Fonderie, 71200 Le Creusot, France; ViCOROB, Universitat de Girona, Campus Montilivi, Edifici P4, 17071 Girona, Spain); Martí, Robert (ViCOROB, Universitat de Girona, Campus Montilivi, Edifici P4, 17071 Girona, Spain); Freixenet, Jordi (ViCOROB, Universitat de Girona, Campus Montilivi, Edifici P4, 17071 Girona, Spain); Vilanova, Joan C. (Department of Magnetic Resonance, Clínica Girona, Lorenzana 36, 17002 Girona, Spain); Walker, Paul M. (LE2I-UMR CNRS 6306, Université de Bourgogne, Avenue Alain Savary, 21000 Dijon, France); Meriaudeau, Fabrice (LE2I-UMR CNRS 6306, Université de Bourgogne, 12 rue de la Fonderie, 71200 Le Creusot, France)","Lemaître, Guillaume (University of Burgundy; University of Girona)","Lemaître, Guillaume (University of Burgundy; University of Girona); Martí, Robert (University of Girona); Freixenet, Jordi (University of Girona); Vilanova, Joan C. (Clínica Girona); Walker, Paul M. (University of Burgundy); Meriaudeau, Fabrice (University of Burgundy)",182,63,4.53,38.79,https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01235868/file/g_lemaitre_state_of_the_art.pdf,https://app.dimensions.ai/details/publication/pub.1032306523,31 Biological Sciences; 3102 Bioinformatics and Computational Biology; 42 Health Sciences; 4203 Health Services and Systems; 46 Information and Computing Sciences; 4601 Applied Computing,
4371,pub.1100087854,10.1016/j.ebiom.2017.12.026,29292031,PMC5828543,Deep Convolutional Neural Networks Enable Discrimination of Heterogeneous Digital Pathology Images,"Pathological evaluation of tumor tissue is pivotal for diagnosis in cancer patients and automated image analysis approaches have great potential to increase precision of diagnosis and help reduce human error. In this study, we utilize several computational methods based on convolutional neural networks (CNN) and build a stand-alone pipeline to effectively classify different histopathology images across different types of cancer. In particular, we demonstrate the utility of our pipeline to discriminate between two subtypes of lung cancer, four biomarkers of bladder cancer, and five biomarkers of breast cancer. In addition, we apply our pipeline to discriminate among four immunohistochemistry (IHC) staining scores of bladder and breast cancers. Our classification pipeline includes a basic CNN architecture, Google's Inceptions with three training strategies, and an ensemble of two state-of-the-art algorithms, Inception and ResNet. Training strategies include training the last layer of Google's Inceptions, training the network from scratch, and fine-tunning the parameters for our data using two pre-trained version of Google's Inception architectures, Inception-V1 and Inception-V3. We demonstrate the power of deep learning approaches for identifying cancer subtypes, and the robustness of Google's Inceptions even in presence of extensive tumor heterogeneity. On average, our pipeline achieved accuracies of 100%, 92%, 95%, and 69% for discrimination of various cancer tissues, subtypes, biomarkers, and scores, respectively. Our pipeline and related documentation is freely available at https://github.com/ih-_lab/CNN_Smoothie.","Ehsan Kazemi is supported by Swiss National Science Foundation under grant number 168574. This work was supported by start up funds (Weill Cornell Medicine) to Iman Hajirasouliha. We would also like to thank Mehdi Totonchi, Mehdi Habibzadeh-Motlagh and Ali Sharifi for valuable related discussions to this project.",,EBioMedicine,,"Algorithms; Humans; Image Processing, Computer-Assisted; Neoplasms; Neural Networks, Computer; ROC Curve",2017-12-28,2017,2017-12-28,2018-01,27,,317-328,All OA; Gold,Article,"Khosravi, Pegah; Kazemi, Ehsan; Imielinski, Marcin; Elemento, Olivier; Hajirasouliha, Iman","Khosravi, Pegah (Institute for Computational Biomedicine, Weill Cornell Medical College, NY, USA; Department of Physiology and Biophysics, Weill Cornell Medicine, New York, NY, USA.); Kazemi, Ehsan (Yale Institute for Network Science, Yale University, New Haven, CT, USA.); Imielinski, Marcin (Caryl and Israel Englander Institute for Precision Medicine, Weill Cornell Medical College, NY, USA; Department of Pathology and Laboratory Medicine, Weill Cornell Medical College, NY, USA; The New York Genome Center, NY, USA; The Meyer Cancer Center, Weill Cornell Medicine, New York, NY, USA.); Elemento, Olivier (Institute for Computational Biomedicine, Weill Cornell Medical College, NY, USA; Department of Physiology and Biophysics, Weill Cornell Medicine, New York, NY, USA; Caryl and Israel Englander Institute for Precision Medicine, Weill Cornell Medical College, NY, USA; The Meyer Cancer Center, Weill Cornell Medicine, New York, NY, USA.); Hajirasouliha, Iman (Institute for Computational Biomedicine, Weill Cornell Medical College, NY, USA; Department of Physiology and Biophysics, Weill Cornell Medicine, New York, NY, USA; Caryl and Israel Englander Institute for Precision Medicine, Weill Cornell Medical College, NY, USA; The Meyer Cancer Center, Weill Cornell Medicine, New York, NY, USA.)","Elemento, Olivier (Cornell University); Hajirasouliha, Iman (Cornell University)","Khosravi, Pegah (Cornell University); Kazemi, Ehsan (Yale University); Imielinski, Marcin (New York Genome Center; Cornell University); Elemento, Olivier (Cornell University); Hajirasouliha, Iman (Cornell University)",210,104,6.6,44.17,http://www.thelancet.com/article/S2352396417305078/pdf,https://app.dimensions.ai/details/publication/pub.1100087854,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
4368,pub.1110280965,10.1007/s10278-018-0160-1,30506124,PMC6737129,A Deep Learning-Based Approach for the Detection and Localization of Prostate Cancer in T2 Magnetic Resonance Images,"We address the problem of prostate lesion detection, localization, and segmentation in T2W magnetic resonance (MR) images. We train a deep convolutional encoder-decoder architecture to simultaneously segment the prostate, its anatomical structure, and the malignant lesions. To incorporate the 3D contextual spatial information provided by the MRI series, we propose a novel 3D sliding window approach, which preserves the 2D domain complexity while exploiting 3D information. Experiments on data from 19 patients provided for the public by the Initiative for Collaborative Computer Vision Benchmarking (I2CVB) show that our approach outperforms traditional pattern recognition and machine learning approaches by a significant margin. Particularly, for the task of cancer detection and localization, the system achieves an average AUC of 0.995, an accuracy of 0.894, and a recall of 0.928. The proposed mono-modal deep learning-based system performs comparably to other multi-modal MR-based systems. It could improve the performance of a radiologist in prostate cancer diagnosis and treatment planning.","The authors would also like to thank Dr. Waleed Hassen and Dr. Eric Vens from Cleveland Clinic, Abu Dhabi, and Dr. Salah El-Rai from Sheikh Khalifa General Hospital for their support and collaboration.",This work is support by a research grant from Al-Jalila foundation ref. AJF-201616.,Journal of Digital Imaging,,"Adult; Aged; Aged, 80 and over; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Prostate; Prostatic Neoplasms",2018-11-30,2018,2018-11-30,2019-10,32,5,793-807,Closed,Article,"Alkadi, Ruba; Taher, Fatma; El-baz, Ayman; Werghi, Naoufel","Alkadi, Ruba (Khalifa University of Science and Technology, PO Box 127788, Abu Dhabi, United Arab Emirates); Taher, Fatma (Khalifa University of Science and Technology, PO Box 127788, Abu Dhabi, United Arab Emirates); El-baz, Ayman (University of Louisville, 40292, Louisville, KY, USA); Werghi, Naoufel (Khalifa University of Science and Technology, PO Box 127788, Abu Dhabi, United Arab Emirates)","Alkadi, Ruba (Khalifa University of Science and Technology)","Alkadi, Ruba (Khalifa University of Science and Technology); Taher, Fatma (Khalifa University of Science and Technology); El-baz, Ayman (University of Louisville); Werghi, Naoufel (Khalifa University of Science and Technology)",66,46,3.56,19.26,,https://app.dimensions.ai/details/publication/pub.1110280965,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4368,pub.1104988304,10.1002/sim.7810,29923345,PMC6123293,Detection of prostate cancer with multiparametric MRI utilizing the anatomic structure of the prostate,"Multiparametric magnetic resonance imaging (mpMRI), which combines traditional anatomic and newer quantitative MRI methods, has been shown to result in improved voxel-wise classification of prostate cancer as compared with any single MRI parameter. While these results are promising, substantial heterogeneity in the mpMRI parameter values and voxel-wise prostate cancer risk has been observed both between and within regions of the prostate. This suggests that classification of prostate cancer can potentially be improved by incorporating structural information into the classifier. In this paper, we propose a novel voxel-wise classifier of prostate cancer that accounts for the anatomic structure of the prostate by Bayesian hierarchical modeling, which can be combined with post hoc spatial Gaussian kernel smoothing to account for residual spatial correlation. Our proposed classifier results in significantly improved area under the ROC curve (0.822 vs 0.729, P < .001) and sensitivity corresponding to 90% specificity (0.599 vs 0.429, P < .001), compared with a baseline model that does not account for the anatomic structure of the prostate. Furthermore, the classifier can also be applied on voxels with missing mpMRI parameters, resulting in similar performance, which is an important practical consideration that cannot be easily accommodated using regression-based classifiers. In addition, our classifier achieved high computational efficiency with a closed-form solution for the posterior predictive cancer probability.","This work was supported by NCIR01 CA155268, NCIP30 CA077598, NIBIBP41 EB015894, and the Assistant Secretary of Defense for Health affairs, through the Prostate Cancer Research Program under Award No. W81XWH‐15‐1‐0478. Opinions, interpretations, conclusions, and recommendations are those of the author and are not necessarily endorsed by the Department of Defense.",,Statistics in Medicine,,Algorithms; Bayes Theorem; Humans; Magnetic Resonance Imaging; Male; Prostate; Prostatic Neoplasms; ROC Curve; Sensitivity and Specificity,2018-06-19,2018,2018-06-19,2018-09-30,37,22,3214-3229,All OA; Green,Article,"Jin, Jin; Zhang, Lin; Leng, Ethan; Metzger, Gregory J.; Koopmeiners, Joseph S.","Jin, Jin (Division of Biostatistics, School of Public Health, University of Minnesota, Minneapolis, MN 55455, USA); Zhang, Lin (Division of Biostatistics, School of Public Health, University of Minnesota, Minneapolis, MN 55455, USA); Leng, Ethan (Center for Magnetic Resonance Research, Department of Radiology, University of Minnesota, Minneapolis, MN 55455, USA); Metzger, Gregory J. (Center for Magnetic Resonance Research, Department of Radiology, University of Minnesota, Minneapolis, MN 55455, USA); Koopmeiners, Joseph S. (Division of Biostatistics, School of Public Health, University of Minnesota, Minneapolis, MN 55455, USA)","Koopmeiners, Joseph S. (University of Minnesota)","Jin, Jin (University of Minnesota); Zhang, Lin (University of Minnesota); Leng, Ethan (University of Minnesota); Metzger, Gregory J. (University of Minnesota); Koopmeiners, Joseph S. (University of Minnesota)",7,6,0.41,2.82,https://europepmc.org/articles/pmc6123293?pdf=render,https://app.dimensions.ai/details/publication/pub.1104988304,42 Health Sciences; 4202 Epidemiology; 49 Mathematical Sciences; 4905 Statistics,
4288,pub.1152680879,10.1016/j.zemedi.2022.10.005,36376203,,The use of deep learning in interventional radiotherapy (brachytherapy): A review with a focus on open source and open data,"Deep learning advanced to one of the most important technologies in almost all medical fields. Especially in areas, related to medical imaging it plays a big role. However, in interventional radiotherapy (brachytherapy) deep learning is still in an early phase. In this review, first, we investigated and scrutinised the role of deep learning in all processes of interventional radiotherapy and directly related fields. Additionally, we summarised the most recent developments. For better understanding, we provide explanations of key terms and approaches to solving common deep learning problems. To reproduce results of deep learning algorithms both source code and training data must be available. Therefore, a second focus of this work is on the analysis of the availability of open source, open data and open models. In our analysis, we were able to show that deep learning plays already a major role in some areas of interventional radiotherapy, but is still hardly present in others. Nevertheless, its impact is increasing with the years, partly self-propelled but also influenced by closely related fields. Open source, data and models are growing in number but are still scarce and unevenly distributed among different research groups. The reluctance in publishing code, data and models limits reproducibility and restricts evaluation to mono-institutional datasets. The conclusion of our analysis is that deep learning can positively change the workflow of interventional radiotherapy but there is still room for improvements when it comes to reproducible results and standardised evaluation methods.",,,Zeitschrift für Medizinische Physik,,,2022-11-11,2022,2022-11-11,2022-11,,,,All OA; Hybrid,Article,"Fechter, Tobias; Sachpazidis, Ilias; Baltas, Dimos","Fechter, Tobias (Division of Medical Physics, Department of Radiation Oncology, Medical Center University of Freiburg, Germany; Faculty of Medicine, University of Freiburg, Germany; German Cancer Consortium (DKTK), Partner Site Freiburg, Germany. Electronic address: tobias.fechter@uniklinik-freiburg.de.); Sachpazidis, Ilias (Division of Medical Physics, Department of Radiation Oncology, Medical Center University of Freiburg, Germany; Faculty of Medicine, University of Freiburg, Germany; German Cancer Consortium (DKTK), Partner Site Freiburg, Germany.); Baltas, Dimos (Division of Medical Physics, Department of Radiation Oncology, Medical Center University of Freiburg, Germany; Faculty of Medicine, University of Freiburg, Germany; German Cancer Consortium (DKTK), Partner Site Freiburg, Germany.)","Fechter, Tobias (University Medical Center Freiburg; University of Freiburg; German Cancer Research Center)","Fechter, Tobias (University Medical Center Freiburg; University of Freiburg; German Cancer Research Center); Sachpazidis, Ilias (University Medical Center Freiburg; University of Freiburg; German Cancer Research Center); Baltas, Dimos (University Medical Center Freiburg; University of Freiburg; German Cancer Research Center)",0,0,,,https://doi.org/10.1016/j.zemedi.2022.10.005,https://app.dimensions.ai/details/publication/pub.1152680879,32 Biomedical and Clinical Sciences; 51 Physical Sciences; 5105 Medical and Biological Physics,
4274,pub.1138384250,10.3390/diagnostics11060959,34073627,PMC8229869,Artificial Intelligence Based Algorithms for Prostate Cancer Classification and Detection on Magnetic Resonance Imaging: A Narrative Review,"Due to the upfront role of magnetic resonance imaging (MRI) for prostate cancer (PCa) diagnosis, a multitude of artificial intelligence (AI) applications have been suggested to aid in the diagnosis and detection of PCa. In this review, we provide an overview of the current field, including studies between 2018 and February 2021, describing AI algorithms for (1) lesion classification and (2) lesion detection for PCa. Our evaluation of 59 included studies showed that most research has been conducted for the task of PCa lesion classification (66%) followed by PCa lesion detection (34%). Studies showed large heterogeneity in cohort sizes, ranging between 18 to 499 patients (median = 162) combined with different approaches for performance validation. Furthermore, 85% of the studies reported on the stand-alone diagnostic accuracy, whereas 15% demonstrated the impact of AI on diagnostic thinking efficacy, indicating limited proof for the clinical utility of PCa AI applications. In order to introduce AI within the clinical workflow of PCa assessment, robustness and generalizability of AI applications need to be further validated utilizing external validation and clinical workflow experiments.",,"This research was funded by the European Union’s Horizon 2020 research and innovation program, grant number 952159.",Diagnostics,,,2021-05-26,2021,2021-05-26,,11,6,959,All OA; Gold,Article,"Twilt, Jasper J; van Leeuwen, Kicky G; Huisman, Henkjan J; Fütterer, Jurgen J; de Rooij, Maarten","Twilt, Jasper J (Department of Medical Imaging, Radboud University Medical Center, P.O. Box 9101, 6500 HB Nijmegen, The Netherlands.); van Leeuwen, Kicky G (Department of Medical Imaging, Radboud University Medical Center, P.O. Box 9101, 6500 HB Nijmegen, The Netherlands.); Huisman, Henkjan J (Department of Medical Imaging, Radboud University Medical Center, P.O. Box 9101, 6500 HB Nijmegen, The Netherlands.); Fütterer, Jurgen J (Department of Medical Imaging, Radboud University Medical Center, P.O. Box 9101, 6500 HB Nijmegen, The Netherlands.); de Rooij, Maarten (Department of Medical Imaging, Radboud University Medical Center, P.O. Box 9101, 6500 HB Nijmegen, The Netherlands.)","Twilt, Jasper J (Radboud University Nijmegen Medical Centre)","Twilt, Jasper J (Radboud University Nijmegen Medical Centre); van Leeuwen, Kicky G (Radboud University Nijmegen Medical Centre); Huisman, Henkjan J (Radboud University Nijmegen Medical Centre); Fütterer, Jurgen J (Radboud University Nijmegen Medical Centre); de Rooij, Maarten (Radboud University Nijmegen Medical Centre)",23,23,4.46,16.65,https://www.mdpi.com/2075-4418/11/6/959/pdf?version=1622101037,https://app.dimensions.ai/details/publication/pub.1138384250,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4146,pub.1114311936,10.1038/s41585-019-0193-3,31092914,,A new era: artificial intelligence and machine learning in prostate cancer,"Artificial intelligence (AI) — the ability of a machine to perform cognitive tasks to achieve a particular goal based on provided data — is revolutionizing and reshaping our health-care systems. The current availability of ever-increasing computational power, highly developed pattern recognition algorithms and advanced image processing software working at very high speeds has led to the emergence of computer-based systems that are trained to perform complex tasks in bioinformatics, medical imaging and medical robotics. Accessibility to ‘big data’ enables the ‘cognitive’ computer to scan billions of bits of unstructured information, extract the relevant information and recognize complex patterns with increasing confidence. Computer-based decision-support systems based on machine learning (ML) have the potential to revolutionize medicine by performing complex tasks that are currently assigned to specialists to improve diagnostic accuracy, increase efficiency of throughputs, improve clinical workflow, decrease human resource costs and improve treatment choices. These characteristics could be especially helpful in the management of prostate cancer, with growing applications in diagnostic imaging, surgical interventions, skills training and assessment, digital pathology and genomics. Medicine must adapt to this changing world, and urologists, oncologists, radiologists and pathologists, as high-volume users of imaging and pathology, need to understand this burgeoning science and acknowledge that the development of highly accurate AI-based decision-support applications of ML will require collaboration between data scientists, computer researchers and engineers.",,,Nature Reviews Urology,,Artificial Intelligence; Humans; Machine Learning; Male; Prostatic Neoplasms,2019-05-15,2019,2019-05-15,2019-07,16,7,391-403,Closed,Article,"Goldenberg, S. Larry; Nir, Guy; Salcudean, Septimiu E.","Goldenberg, S. Larry (Department of Urologic Sciences and the Vancouver Prostate Centre, University of British Columbia, Vancouver, British Columbia, Canada); Nir, Guy (Department of Urologic Sciences and the Vancouver Prostate Centre, University of British Columbia, Vancouver, British Columbia, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, British Columbia, Canada); Salcudean, Septimiu E. (Department of Urologic Sciences and the Vancouver Prostate Centre, University of British Columbia, Vancouver, British Columbia, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, British Columbia, Canada)","Goldenberg, S. Larry (University of British Columbia)","Goldenberg, S. Larry (University of British Columbia); Nir, Guy (University of British Columbia; University of British Columbia); Salcudean, Septimiu E. (University of British Columbia; University of British Columbia)",206,161,11.02,72.77,,https://app.dimensions.ai/details/publication/pub.1114311936,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
4141,pub.1100191368,10.1109/tmi.2017.2789181,29727276,,Automated Detection of Clinically Significant Prostate Cancer in mp-MRI Images Based on an End-to-End Deep Neural Network,"Automated methods for detecting clinically significant (CS) prostate cancer (PCa) in multi-parameter magnetic resonance images (mp-MRI) are of high demand. Existing methods typically employ several separate steps, each of which is optimized individually without considering the error tolerance of other steps. As a result, they could either involve unnecessary computational cost or suffer from errors accumulated over steps. In this paper, we present an automated CS PCa detection system, where all steps are optimized jointly in an end-to-end trainable deep neural network. The proposed neural network consists of concatenated subnets: 1) a novel tissue deformation network (TDN) for automated prostate detection and multimodal registration and 2) a dual-path convolutional neural network (CNN) for CS PCa detection. Three types of loss functions, i.e., classification loss, inconsistency loss, and overlap loss, are employed for optimizing all parameters of the proposed TDN and CNN. In the training phase, the two nets mutually affect each other and effectively guide registration and extraction of representative CS PCa-relevant features to achieve results with sufficient accuracy. The entire network is trained in a weakly supervised manner by providing only image-level annotations (i.e., presence/absence of PCa) without exact priors of lesions' locations. Compared with most existing systems which require supervised labels, e.g., manual delineation of PCa lesions, it is much more convenient for clinical usage. Comprehensive evaluation based on fivefold cross validation using 360 patient data demonstrates that our system achieves a high accuracy for CS PCa detection, i.e., a sensitivity of 0.6374 and 0.8978 at 0.1 and 1 false positives per normal/benign patient.","This work was supported in part by the National Natural Science Foundation of China under Grant 61502188, the Wuhan Science and Technology Bureau under Award 2017010201010111, and the Program for HUST Acadamic Frontier Youth Team.",,IEEE Transactions on Medical Imaging,,"Algorithms; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Prostate; Prostatic Neoplasms; ROC Curve",2018-01-03,2018,2018-01-03,2018-05,37,5,1127-1139,Closed,Article,"Wang, Zhiwei; Liu, Chaoyue; Cheng, Danpeng; Wang, Liang; Yang, Xin; Cheng, Kwang-Ting","Wang, Zhiwei (School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China); Liu, Chaoyue (School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China); Cheng, Danpeng (University of Bridgeport, CT, 06604, USA); Wang, Liang (Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Wuhan, 430030, China); Yang, Xin (School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China); Cheng, Kwang-Ting (School of Engineering, Hong Kong University of Science and Technology, Hong Kong)","Yang, Xin (Huazhong University of Science and Technology)","Wang, Zhiwei (Huazhong University of Science and Technology); Liu, Chaoyue (Huazhong University of Science and Technology); Cheng, Danpeng (University of Bridgeport); Wang, Liang (Tongji Hospital; Huazhong University of Science and Technology); Yang, Xin (Huazhong University of Science and Technology); Cheng, Kwang-Ting (Hong Kong University of Science and Technology)",96,51,3.36,30.3,,https://app.dimensions.ai/details/publication/pub.1100191368,46 Information and Computing Sciences; 4611 Machine Learning,
4141,pub.1107889499,10.1016/j.media.2018.10.010,30399507,PMC6407631,"A collaborative computer aided diagnosis (C-CAD) system with eye-tracking, sparse attentional model, and deep learning","Computer aided diagnosis (CAD) tools help radiologists to reduce diagnostic errors such as missing tumors and misdiagnosis. Vision researchers have been analyzing behaviors of radiologists during screening to understand how and why they miss tumors or misdiagnose. In this regard, eye-trackers have been instrumental in understanding visual search processes of radiologists. However, most relevant studies in this aspect are not compatible with realistic radiology reading rooms. In this study, we aim to develop a paradigm shifting CAD system, called collaborative CAD (C-CAD), that unifies CAD and eye-tracking systems in realistic radiology room settings. We first developed an eye-tracking interface providing radiologists with a real radiology reading room experience. Second, we propose a novel algorithm that unifies eye-tracking data and a CAD system. Specifically, we present a new graph based clustering and sparsification algorithm to transform eye-tracking data (gaze) into a graph model to interpret gaze patterns quantitatively and qualitatively. The proposed C-CAD collaborates with radiologists via eye-tracking technology and helps them to improve their diagnostic decisions. The C-CAD uses radiologists' search efficiency by processing their gaze patterns. Furthermore, the C-CAD incorporates a deep learning algorithm in a newly designed multi-task learning platform to segment and diagnose suspicious areas simultaneously. The proposed C-CAD system has been tested in a lung cancer screening experiment with multiple radiologists, reading low dose chest CTs. Promising results support the efficiency, accuracy and applicability of the proposed C-CAD system in a real radiology room setting. We have also shown that our framework is generalizable to more complex applications such as prostate cancer screening with multi-parametric magnetic resonance imaging (mp-MRI).","We would like to thank Nancy Terry, NIH Library Editing Service, for reviewing the manuscript.",,Medical Image Analysis,,"Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Diagnostic Errors; Early Detection of Cancer; Eye Movements; Female; Humans; Lung Neoplasms; Magnetic Resonance Imaging; Male; Prostatic Neoplasms; Tomography, X-Ray Computed",2018-10-28,2018,2018-10-28,2019-01,51,,101-115,All OA; Green,Article,"Khosravan, Naji; Celik, Haydar; Turkbey, Baris; Jones, Elizabeth C; Wood, Bradford; Bagci, Ulas","Khosravan, Naji (Center for Research in Computer Vision, University of Central Florida, FL, United States.); Celik, Haydar (Clinical Center, National Institutes of Health, Bethesda, MD, United States.); Turkbey, Baris (Clinical Center, National Institutes of Health, Bethesda, MD, United States.); Jones, Elizabeth C (Clinical Center, National Institutes of Health, Bethesda, MD, United States.); Wood, Bradford (Clinical Center, National Institutes of Health, Bethesda, MD, United States.); Bagci, Ulas (Center for Research in Computer Vision, University of Central Florida, FL, United States. Electronic address: ulasbagci@gmail.com.)","Bagci, Ulas (University of Central Florida)","Khosravan, Naji (University of Central Florida); Celik, Haydar (National Institutes of Health Clinical Center); Turkbey, Baris (National Institutes of Health Clinical Center); Jones, Elizabeth C (National Institutes of Health Clinical Center); Wood, Bradford (National Institutes of Health Clinical Center); Bagci, Ulas (University of Central Florida)",47,28,1.87,,https://europepmc.org/articles/pmc6407631?pdf=render,https://app.dimensions.ai/details/publication/pub.1107889499,32 Biomedical and Clinical Sciences; 40 Engineering,
4136,pub.1024308260,10.1118/1.4962031,27782724,PMC5035312,Computer aided diagnosis of prostate cancer: A texton based approach,"PURPOSE: In this paper the authors propose a texton based prostate computer aided diagnosis approach which bypasses the typical feature extraction process such as filtering and convolution which can be computationally expensive. The study focuses the peripheral zone because 75% of prostate cancers start within this region and the majority of prostate cancers arising within this region are more aggressive than those arising in the transitional zone.
METHODS: For the model development, square patches were extracted at random locations from malignant and benign regions. Subsequently, extracted patches were aggregated and clustered using k-means clustering to generate textons that represent both regions. All textons together form a texton dictionary, which was used to construct a texton map for every peripheral zone in the training images. Based on the texton map, histogram models for each malignant and benign tissue samples were constructed and used as a feature vector to train our classifiers. In the testing phase, four machine learning algorithms were employed to classify each unknown sample tissue based on its corresponding feature vector.
RESULTS: The proposed method was tested on 418 T2-W MR images taken from 45 patients. Evaluation results show that the best three classifiers were Bayesian network (Az = 92.8% ± 5.9%), random forest (89.5% ± 7.1%), and k-NN (86.9% ± 7.5%). These results are comparable to the state-of-the-art in the literature.
CONCLUSIONS: The authors have developed a prostate computer aided diagnosis method based on textons using a single modality of T2-W MRI without the need for the typical feature extraction methods, such as filtering and convolution. The proposed method could form a solid basis for a multimodality magnetic resonance imaging based systems.",,,Medical Physics,,"Aged; Algorithms; Bayes Theorem; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Prostatic Neoplasms",2016-09-13,2016,2016-09-13,2016-09-13,43,10,5412-5425,All OA; Green,Article,"Rampun, Andrik; Tiddeman, Bernie; Zwiggelaar, Reyer; Malcolm, Paul","Rampun, Andrik (Department of Computer Science, Aberystwyth University, Aberystwyth, Ceredigion SY23 3DB, United Kingdom.); Tiddeman, Bernie (Department of Computer Science, Aberystwyth University, Aberystwyth, Ceredigion SY23 3DB, United Kingdom.); Zwiggelaar, Reyer (Department of Computer Science, Aberystwyth University, Aberystwyth, Ceredigion SY23 3DB, United Kingdom.); Malcolm, Paul (Department of Radiology, Norfolk & Norwich University Hospital, Norwich NR4 7UY, United Kingdom.)",,"Rampun, Andrik (Aberystwyth University); Tiddeman, Bernie (Aberystwyth University); Zwiggelaar, Reyer (Aberystwyth University); Malcolm, Paul (Norfolk and Norwich University Hospital)",15,1,0.26,5.13,https://europepmc.org/articles/pmc5035312?pdf=render,https://app.dimensions.ai/details/publication/pub.1024308260,40 Engineering; 4003 Biomedical Engineering; 51 Physical Sciences; 5105 Medical and Biological Physics,
4114,pub.1123928639,10.1016/j.cmpb.2020.105316,31951873,,Artificial intelligence in multiparametric prostate cancer imaging with focus on deep-learning methods,"Prostate cancer represents today the most typical example of a pathology whose diagnosis requires multiparametric imaging, a strategy where multiple imaging techniques are combined to reach an acceptable diagnostic performance. However, the reviewing, weighing and coupling of multiple images not only places additional burden on the radiologist, it also complicates the reviewing process. Prostate cancer imaging has therefore been an important target for the development of computer-aided diagnostic (CAD) tools. In this survey, we discuss the advances in CAD for prostate cancer over the last decades with special attention to the deep-learning techniques that have been designed in the last few years. Moreover, we elaborate and compare the methods employed to deliver the CAD output to the operator for further medical decision making.","This study has received funding from the Dutch Cancer Society (#UVA2013-5941) and a European Research Council Starting Grant (#280209), and was performed within the framework of the IMPULS2-program within the Eindhoven University of Technology in collaboration with Philips.",,Computer Methods and Programs in Biomedicine,,"Artificial Intelligence; Deep Learning; Diagnosis, Computer-Assisted; Humans; Magnetic Resonance Imaging; Male; Prostatic Neoplasms",2020-01-07,2020,2020-01-07,2020-06,189,,105316,All OA; Green,Article,"Wildeboer, Rogier R.; van Sloun, Ruud J.G.; Wijkstra, Hessel; Mischi, Massimo","Wildeboer, Rogier R. (Lab of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, De Zaale, 5600 MB, Eindhoven, the Netherlands); van Sloun, Ruud J.G. (Lab of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, De Zaale, 5600 MB, Eindhoven, the Netherlands); Wijkstra, Hessel (Lab of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, De Zaale, 5600 MB, Eindhoven, the Netherlands; Department of Urology, Amsterdam University Medical Centers, University of Amsterdam, Meibergdreef 9, 1105 AZ, Amsterdam, the Netherlands); Mischi, Massimo (Lab of Biomedical Diagnostics, Department of Electrical Engineering, Eindhoven University of Technology, De Zaale, 5600 MB, Eindhoven, the Netherlands)","Wildeboer, Rogier R. (Eindhoven University of Technology); van Sloun, Ruud J.G. (Eindhoven University of Technology)","Wildeboer, Rogier R. (Eindhoven University of Technology); van Sloun, Ruud J.G. (Eindhoven University of Technology); Wijkstra, Hessel (Eindhoven University of Technology; University of Amsterdam); Mischi, Massimo (Eindhoven University of Technology)",32,29,2.95,13.82,https://pure.tue.nl/ws/files/145677416/1_s2.0_S0169260719310442_main.pdf,https://app.dimensions.ai/details/publication/pub.1123928639,40 Engineering; 4003 Biomedical Engineering; 46 Information and Computing Sciences; 4601 Applied Computing; 4603 Computer Vision and Multimedia Computation,
4097,pub.1142805592,10.3390/diagnostics11111964,34829310,PMC8625809,Automatic Segmentation of Pelvic Cancers Using Deep Learning: State-of-the-Art Approaches and Challenges,"The recent rise of deep learning (DL) and its promising capabilities in capturing non-explicit detail from large datasets have attracted substantial research attention in the field of medical image processing. DL provides grounds for technological development of computer-aided diagnosis and segmentation in radiology and radiation oncology. Amongst the anatomical locations where recent auto-segmentation algorithms have been employed, the pelvis remains one of the most challenging due to large intra- and inter-patient soft-tissue variabilities. This review provides a comprehensive, non-systematic and clinically-oriented overview of 74 DL-based segmentation studies, published between January 2016 and December 2020, for bladder, prostate, cervical and rectal cancers on computed tomography (CT) and magnetic resonance imaging (MRI), highlighting the key findings, challenges and limitations.",,,Diagnostics,,,2021-10-22,2021,2021-10-22,,11,11,1964,All OA; Gold,Article,"Kalantar, Reza; Lin, Gigin; Winfield, Jessica M.; Messiou, Christina; Lalondrelle, Susan; Blackledge, Matthew D.; Koh, Dow-Mu","Kalantar, Reza (Division of Radiotherapy and Imaging, The Institute of Cancer Research, London SM2 5NG, UK;, reza.kalantar@icr.ac.uk, (R.K.);, jessica.winfield@icr.ac.uk, (J.M.W.);, christina.messiou@icr.ac.uk, (C.M.);, susan.lalondrelle@rmh.nhs.uk, (S.L.);, mu.koh@icr.ac.uk, (D.-M.K.)); Lin, Gigin (Department of Medical Imaging and Intervention, Chang Gung Memorial Hospital at Linkou and Chang Gung University, 5 Fuhsing St., Guishan, Taoyuan 333, Taiwan;, giginlin@cgmh.org.tw); Winfield, Jessica M. (Division of Radiotherapy and Imaging, The Institute of Cancer Research, London SM2 5NG, UK;, reza.kalantar@icr.ac.uk, (R.K.);, jessica.winfield@icr.ac.uk, (J.M.W.);, christina.messiou@icr.ac.uk, (C.M.);, susan.lalondrelle@rmh.nhs.uk, (S.L.);, mu.koh@icr.ac.uk, (D.-M.K.); Department of Radiology, The Royal Marsden Hospital, London SW3 6JJ, UK); Messiou, Christina (Division of Radiotherapy and Imaging, The Institute of Cancer Research, London SM2 5NG, UK;, reza.kalantar@icr.ac.uk, (R.K.);, jessica.winfield@icr.ac.uk, (J.M.W.);, christina.messiou@icr.ac.uk, (C.M.);, susan.lalondrelle@rmh.nhs.uk, (S.L.);, mu.koh@icr.ac.uk, (D.-M.K.); Department of Radiology, The Royal Marsden Hospital, London SW3 6JJ, UK); Lalondrelle, Susan (Division of Radiotherapy and Imaging, The Institute of Cancer Research, London SM2 5NG, UK;, reza.kalantar@icr.ac.uk, (R.K.);, jessica.winfield@icr.ac.uk, (J.M.W.);, christina.messiou@icr.ac.uk, (C.M.);, susan.lalondrelle@rmh.nhs.uk, (S.L.);, mu.koh@icr.ac.uk, (D.-M.K.); Department of Radiology, The Royal Marsden Hospital, London SW3 6JJ, UK); Blackledge, Matthew D. (Division of Radiotherapy and Imaging, The Institute of Cancer Research, London SM2 5NG, UK;, reza.kalantar@icr.ac.uk, (R.K.);, jessica.winfield@icr.ac.uk, (J.M.W.);, christina.messiou@icr.ac.uk, (C.M.);, susan.lalondrelle@rmh.nhs.uk, (S.L.);, mu.koh@icr.ac.uk, (D.-M.K.)); Koh, Dow-Mu (Division of Radiotherapy and Imaging, The Institute of Cancer Research, London SM2 5NG, UK;, reza.kalantar@icr.ac.uk, (R.K.);, jessica.winfield@icr.ac.uk, (J.M.W.);, christina.messiou@icr.ac.uk, (C.M.);, susan.lalondrelle@rmh.nhs.uk, (S.L.);, mu.koh@icr.ac.uk, (D.-M.K.); Department of Radiology, The Royal Marsden Hospital, London SW3 6JJ, UK)","Blackledge, Matthew D. (Institute of Cancer Research)","Kalantar, Reza (Institute of Cancer Research); Lin, Gigin (Chang Gung University); Winfield, Jessica M. (Institute of Cancer Research; Royal Marsden Hospital); Messiou, Christina (Institute of Cancer Research; Royal Marsden Hospital); Lalondrelle, Susan (Institute of Cancer Research; Royal Marsden Hospital); Blackledge, Matthew D. (Institute of Cancer Research); Koh, Dow-Mu (Institute of Cancer Research; Royal Marsden Hospital)",12,12,2.22,8.69,https://www.mdpi.com/2075-4418/11/11/1964/pdf?version=1634902331,https://app.dimensions.ai/details/publication/pub.1142805592,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4088,pub.1144609812,10.1016/j.media.2021.102347,35085952,,ProstAttention-Net: A deep attention model for prostate cancer segmentation by aggressiveness in MRI scans,"Multiparametric magnetic resonance imaging (mp-MRI) has shown excellent results in the detection of prostate cancer (PCa). However, characterizing prostate lesions aggressiveness in mp-MRI sequences is impossible in clinical practice, and biopsy remains the reference to determine the Gleason score (GS). In this work, we propose a novel end-to-end multi-class network that jointly segments the prostate gland and cancer lesions with GS group grading. After encoding the information on a latent space, the network is separated in two branches: 1) the first branch performs prostate segmentation 2) the second branch uses this zonal prior as an attention gate for the detection and grading of prostate lesions. The model was trained and validated with a 5-fold cross-validation on a heterogeneous series of 219 MRI exams acquired on three different scanners prior prostatectomy. In the free-response receiver operating characteristics (FROC) analysis for clinically significant lesions (defined as GS >6) detection, our model achieves 69.0%±14.5% sensitivity at 2.9 false positive per patient on the whole prostate and  70.8%±14.4% sensitivity at 1.5 false positive when considering the peripheral zone (PZ) only. Regarding the automatic GS group grading, Cohen's quadratic weighted kappa coefficient (κ) is 0.418±0.138, which is the best reported lesion-wise kappa for GS segmentation to our knowledge. The model has encouraging generalization capacities with κ=0.120±0.092 on the PROSTATEx-2 public dataset and achieves state-of-the-art performance for the segmentation of the whole prostate gland with a Dice of 0.875±0.013. Finally, we show that ProstAttention-Net improves performance in comparison to reference segmentation models, including U-Net, DeepLabv3+ and E-Net. The proposed attention mechanism is also shown to outperform Attention U-Net.","This work was supported by the RHU PERFUSE (ANR-17-RHUS-0006) of Université Claude Bernard Lyon 1 (UCBL), within the program “Investissements d’Avenir” operated by the French National Research Agency (ANR). It was performed within the framework of the Discovery grant RGPIN-2018-05401 awarded to P-M Jodoin by the Natural Sciences and Engineering Research Council of Canada (CA) and the LABEX PRIMES (ANR-11-LABX-0063) of Université de Lyon operated by the French National Research Agency (ANR).",,Medical Image Analysis,,Humans; Magnetic Resonance Imaging; Male; Multiparametric Magnetic Resonance Imaging; Neoplasm Grading; Prostate; Prostatic Neoplasms,2022-01-12,2022,2022-01-12,2022-04,77,,102347,All OA; Green,Article,"Duran, Audrey; Dussert, Gaspard; Rouvière, Olivier; Jaouen, Tristan; Jodoin, Pierre-Marc; Lartizien, Carole","Duran, Audrey (Univ Lyon, CNRS, Inserm, INSA Lyon, UCBL, CREATIS, UMR5220, U1206, F-69621, Villeurbanne, France.); Dussert, Gaspard (Univ Lyon, CNRS, Inserm, INSA Lyon, UCBL, CREATIS, UMR5220, U1206, F-69621, Villeurbanne, France.); Rouvière, Olivier (Department of Urinary and Vascular Imaging, Hospices Civils de Lyon, Hôpital Edouard Herriot, Lyon, France.); Jaouen, Tristan (Department of Urinary and Vascular Imaging, Hospices Civils de Lyon, Hôpital Edouard Herriot, Lyon, France.); Jodoin, Pierre-Marc (Computer Science Department, University of Sherbrooke, 2500 Boulevard de l'Université, Sherbrooke QC J1K 2R1, Canada.); Lartizien, Carole (Univ Lyon, CNRS, Inserm, INSA Lyon, UCBL, CREATIS, UMR5220, U1206, F-69621, Villeurbanne, France. Electronic address: carole.lartizien@creatis.insa-lyon.fr.)","Lartizien, Carole (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé)","Duran, Audrey (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé); Dussert, Gaspard (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé); Rouvière, Olivier (Hôpital Édouard-Herriot); Jaouen, Tristan (Hôpital Édouard-Herriot); Jodoin, Pierre-Marc (Université de Sherbrooke); Lartizien, Carole (Centre de Recherche en Acquisition et Traitement de l'Image pour la Santé)",11,11,,,http://arxiv.org/pdf/2211.13238,https://app.dimensions.ai/details/publication/pub.1144609812,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
4088,pub.1125683192,10.1016/j.euo.2020.02.005,32192942,PMC8942295,Factors Influencing Variability in the Performance of Multiparametric Magnetic Resonance Imaging in Detecting Clinically Significant Prostate Cancer: A Systematic Literature Review,"CONTEXT: There is a lack of comprehensive data regarding the factors that influence the diagnostic accuracy of multiparametric magnetic resonance imaging (mpMRI) to detect and localize clinically significant prostate cancer (csPCa).
OBJECTIVE: To systematically review the current literature assessing the factors influencing the variability of mpMRI performance in csPCa diagnosis.
EVIDENCE ACQUISITION: A computerized bibliographic search of Medline/PubMed database was performed for all studies assessing magnetic field strength, use of an endorectal coil, assessment system used by radiologists and inter-reader variability, experience of radiologists and urologists, use of a contrast agent, and use of computer-aided diagnosis (CAD) tools in relation to mpMRI diagnostic accuracy.
EVIDENCE SYNTHESIS: A total of 77 articles were included. Both radiologists' reading experience and urologists'/radiologists' biopsy experience were the main factors that influenced diagnostic accuracy. Therefore, it is mandatory to indicate the experience of the interpreting radiologists and biopsy-performing urologists to support the reliability of the findings. The most recent Prostate Imaging Reporting and Data System (PI-RADS) guidelines are recommended for use as the main assessment system for csPCa, given the simplified and standardized approach as well as its particular added value for less experienced radiologists. Biparametric MRI had similar accuracy to mpMRI; however, biparametric MRI performed better with experienced readers. The limited data available suggest that the combination of CAD and radiologist readings may influence diagnostic accuracy positively.
CONCLUSIONS: Multiple factors affect the accuracy of mpMRI and MRI-targeted biopsy to detect and localize csPCa. The high heterogeneity across the studies underlines the need to define the experience of radiologists and urologists, implement quality control, and adhere to the most recent PI-RADS assessment guidelines. Further research is needed to clarify which factors impact the accuracy of the MRI pathway and how.
PATIENT SUMMARY: We systematically reported the factors influencing the accuracy of multiparametric magnetic resonance imaging (mpMRI) in detecting clinically significant prostate cancer (csPCa). These factors are significantly related to each other, with the experience of the radiologists being the dominating factor. In order to deliver the benefits of mpMRI to diagnose csPCa, it is necessary to develop expertise for both radiologists and urologists, implement quality control, and adhere to the most recent Prostate Imaging Reporting and Data System assessment guidelines.",,,European Urology Oncology,,Humans; Male; Multiparametric Magnetic Resonance Imaging; Prostatic Neoplasms,2020-03-17,2020,2020-03-17,2020-04,3,2,145-167,All OA; Green,Article,"Stabile, Armando; Giganti, Francesco; Kasivisvanathan, Veeru; Giannarini, Gianluca; Moore, Caroline M; Padhani, Anwar R; Panebianco, Valeria; Rosenkrantz, Andrew B; Salomon, Georg; Turkbey, Baris; Villeirs, Geert; Barentsz, Jelle O","Stabile, Armando (Department of Urology and Division of Experimental Oncology, URI, Urological Research Institute, Vita-Salute San Raffaele University, IRCCS San Raffaele Scientific Institute, Milan, Italy. Electronic address: armando.stabile88@gmail.com.); Giganti, Francesco (Division of Surgery and Interventional Science, University College London, London, UK; Department of Radiology, University College London Hospitals NHS Foundation Trust, London, UK.); Kasivisvanathan, Veeru (Division of Surgery and Interventional Science, University College London, London, UK; Department of Urology, University College London Hospitals NHS Foundation Trust, London, UK.); Giannarini, Gianluca (Urology Unit, Academic Medical Centre, Santa Maria della Misericordia Hospital, Udine, Italy.); Moore, Caroline M (Division of Surgery and Interventional Science, University College London, London, UK; Department of Urology, University College London Hospitals NHS Foundation Trust, London, UK.); Padhani, Anwar R (Paul Strickland Scanner Centre, Mount Vernon Cancer Centre, Northwood, UK.); Panebianco, Valeria (Department of Radiology, Sapienza Rome University, Policlinico Umberto I, Rome, Italy.); Rosenkrantz, Andrew B (Department of Radiology, NYU Langone Health, New York, NY, USA.); Salomon, Georg (Prostate Cancer Center, Martini-Klinik Hamburg, University Hospital Hamburg-Eppendorf, Hamburg, Germany.); Turkbey, Baris (Molecular Imaging Program, National Cancer Institute, NIH, Bethesda, MD, USA.); Villeirs, Geert (Department of Radiology, Ghent University Hospital, Ghent, Belgium.); Barentsz, Jelle O (Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands.)","Stabile, Armando (Vita-Salute San Raffaele University)","Stabile, Armando (Vita-Salute San Raffaele University); Giganti, Francesco (University College London; University College London Hospitals NHS Foundation Trust); Kasivisvanathan, Veeru (University College London; University College London Hospitals NHS Foundation Trust); Giannarini, Gianluca (Ospedale Santa Maria della Misericordia di Udine); Moore, Caroline M (University College London; University College London Hospitals NHS Foundation Trust); Padhani, Anwar R (Mount Vernon Cancer Centre); Panebianco, Valeria (Sapienza University of Rome; Policlinico Umberto I); Rosenkrantz, Andrew B (New York University Langone Medical Center); Salomon, Georg (University Medical Center Hamburg-Eppendorf); Turkbey, Baris (National Cancer Institute); Villeirs, Geert (Ghent University Hospital); Barentsz, Jelle O (Radboud University Nijmegen Medical Centre)",60,48,6.46,25.56,https://iris.uniroma1.it/bitstream/11573/1381853/1/Panebianco_Factors-influencing-variability.pdf,https://app.dimensions.ai/details/publication/pub.1125683192,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
3946,pub.1121429986,10.1016/j.media.2019.101565,31630010,,Semi-supervised mp-MRI data synthesis with StitchLayer and auxiliary distance maximization,"The availability of a large amount of annotated data is critical for many medical image analysis applications, in particular for those relying on deep learning methods which are known to be data-hungry. However, annotated medical data, especially multimodal data, is often scarce and costly to obtain. In this paper, we address the problem of synthesizing multi-parameter magnetic resonance imaging data (i.e. mp-MRI), which typically consists of Apparent Diffusion Coefficient (ADC) and T2-weighted (T2w) images, containing clinically significant (CS) prostate cancer (PCa) via semi-supervised learning and adversarial learning. Specifically, our synthesizer generates mp-MRI data in a sequential manner: first utilizing a decoder to generate an ADC map from a 128-d latent vector, followed by translating the ADC to the T2w image via U-Net. The synthesizer is trained in a semi-supervised manner. In the supervised training process, a limited amount of paired ADC-T2w images and the corresponding ADC encodings are provided and the synthesizer learns the paired relationship by explicitly minimizing the reconstruction losses between synthetic and real images. To avoid overfitting limited ADC encodings, an unlimited amount of random latent vectors and unpaired ADC-T2w Images are utilized in the unsupervised training process for learning the marginal image distributions of real images. To improve the robustness for training the synthesizer, we decompose the difficult task of generating full-size images into several simpler tasks which generate sub-images only. A StitchLayer is then employed to seamlessly fuse sub-images together in an interlaced manner into a full-size image. In addition, to enforce the synthetic images to indeed contain distinguishable CS PCa lesions, we propose to also maximize an auxiliary distance of Jensen-Shannon divergence (JSD) between CS and nonCS images. Experimental results show that our method can effectively synthesize a large variety of mp-MRI images which contain meaningful CS PCa lesions, display a good visual quality and have the correct paired relationship between the two modalities of a pair. Compared to the state-of-the-art methods based on adversarial learning (Liu and Tuzel, 2016; Costa et al., 2017), our method achieves a significant improvement in terms of both visual quality and several popular quantitative evaluation metrics.","This work was supported by the National Key Research and Development Program of China (2017YFA0700402), the National Natural Science Foundation of China (61872417), the Wuhan Science and Technology Bureau under Award (2017010201010111), the Fundamental Research Funds for the Central Universities (2019kfyRCPY118) and the Program for HUST Acadamic Frontier Youth Team.",,Medical Image Analysis,,"Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Multiparametric Magnetic Resonance Imaging; Prostatic Neoplasms",2019-10-01,2019,2019-10-01,2020-01,59,,101565,All OA; Green,Article,"Wang, Zhiwei; Lin, Yi; Cheng, Kwang-Ting Tim; Yang, Xin","Wang, Zhiwei (Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China.); Lin, Yi (Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China.); Cheng, Kwang-Ting Tim (School of Engineering, Hong Kong University of Science and Technology, Hong Kong.); Yang, Xin (Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China. Electronic address: xinyang2014@hust.edu.cn.)","Yang, Xin (Huazhong University of Science and Technology)","Wang, Zhiwei (Huazhong University of Science and Technology); Lin, Yi (Huazhong University of Science and Technology); Cheng, Kwang-Ting Tim (Hong Kong University of Science and Technology); Yang, Xin (Huazhong University of Science and Technology)",15,13,1.86,,http://arxiv.org/pdf/1812.06625,https://app.dimensions.ai/details/publication/pub.1121429986,32 Biomedical and Clinical Sciences; 40 Engineering,
3757,pub.1121393504,10.1109/jbhi.2019.2944643,31567104,,Deep Learning-Based Gleason Grading of Prostate Cancer From Histopathology ImagesRole of Multiscale Decision Aggregation and Data Augmentation,"Visual inspection of histopathology images of stained biopsy tissue by expert pathologists is the standard method for grading of prostate cancer (PCa). However, this process is time-consuming and subject to high inter-observer variability. Machine learning-based methods have the potential to improve efficient throughput of large volumes of slides while decreasing variability, but they are not easy to develop because they require substantial amounts of labeled training data. In this paper, we propose a deep learning-based classification technique and data augmentation methods for accurate grading of PCa in histopathology images in the presence of limited data. Our method combines the predictions of three separate convolutional neural networks (CNNs) that work with different patch sizes. This enables our method to take advantage of the greater amount of contextual information in larger patches as well as greater quantity of smaller patches in the labeled training data. The predictions produced by the three CNNs are combined using a logistic regression model, which is trained separately after the CNN training. To effectively train our models, we propose new data augmentation methods and empirically study their effects on the classification accuracy. The proposed method achieves an accuracy of [Formula: see text] in classifying cancerous patches versus benign patches and an accuracy of [Formula: see text] in classifying low-grade (i.e., Gleason grade 3) from high-grade (i.e., Gleason grades 4 and 5) patches. The agreement level of our automatic grading method with expert pathologists is within the range of agreement between pathologists. Our experiments indicate that data augmentation is necessary for achieving expert-level performance with deep learning-based methods. A combination of image-space augmentation and feature-space augmentation leads to the best results. Our study shows that well-designed and properly trained deep learning models can achieve PCa Gleason grading accuracy that is comparable to an expert pathologist.",This work was supported by the Canadian Institutes of Health Research (CIHR) and the Prostate Cancer Canada (PCC). The authors would like to thank the support from the Charles Laszlo Chair in Biomedical Engineering held by Prof. S. Salcudean. L. Goldenberg and S. E. Salcudean are joint senior authors.,,IEEE Journal of Biomedical and Health Informatics,,"Deep Learning; Histological Techniques; Humans; Image Interpretation, Computer-Assisted; Male; Neoplasm Grading; Prostate; Prostatic Neoplasms",2019-09-30,2019,2019-09-30,2020-05,24,5,1413-1426,Closed,Article,"Karimi, Davood; Nir, Guy; Fazli, Ladan; Black, Peter C.; Goldenberg, Larry; Salcudean, Septimiu E.","Karimi, Davood (Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, V6T 1Z4, Canada); Nir, Guy (Department of Urologic Sciences, University of British Columbia, Vancouver, BC, V6T 1Z4, Canada); Fazli, Ladan (Department of Urologic Sciences, University of British Columbia, Vancouver, BC, V6T 1Z4, Canada); Black, Peter C. (Department of Urologic Sciences, University of British Columbia, Vancouver, BC, V6T 1Z4, Canada); Goldenberg, Larry (Department of Urologic Sciences, University of British Columbia, Vancouver, BC, V6T 1Z4, Canada); Salcudean, Septimiu E. (Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, V6T 1Z4, Canada)","Karimi, Davood (University of British Columbia)","Karimi, Davood (University of British Columbia); Nir, Guy (University of British Columbia); Fazli, Ladan (University of British Columbia); Black, Peter C. (University of British Columbia); Goldenberg, Larry (University of British Columbia); Salcudean, Septimiu E. (University of British Columbia)",72,60,3.93,27.59,,https://app.dimensions.ai/details/publication/pub.1121393504,46 Information and Computing Sciences; 4611 Machine Learning,
3757,pub.1117843705,10.1371/journal.pone.0217702,31283771,PMC6613688,Radiomics and machine learning of multisequence multiparametric prostate MRI: Towards improved non-invasive prostate cancer characterization,"PURPOSE: To develop and validate a classifier system for prediction of prostate cancer (PCa) Gleason score (GS) using radiomics and texture features of T2-weighted imaging (T2w), diffusion weighted imaging (DWI) acquired using high b values, and T2-mapping (T2).
METHODS: T2w, DWI (12 b values, 0-2000 s/mm2), and T2 data sets of 62 patients with histologically confirmed PCa were acquired at 3T using surface array coils. The DWI data sets were post-processed using monoexponential and kurtosis models, while T2w was standardized to a common scale. Local statistics and 8 different radiomics/texture descriptors were utilized at different configurations to extract a total of 7105 unique per-tumor features. Regularized logistic regression with implicit feature selection and leave pair out cross validation was used to discriminate tumors with 3+3 vs >3+3 GS.
RESULTS: In total, 100 PCa lesions were analysed, of those 20 and 80 had GS of 3+3 and >3+3, respectively. The best model performance was obtained by selecting the top 1% features of T2w, ADCm and K with ROC AUC of 0.88 (95% CI of 0.82-0.95). Features from T2 mapping provided little added value. The most useful texture features were based on the gray-level co-occurrence matrix, Gabor transform, and Zernike moments.
CONCLUSION: Texture feature analysis of DWI, post-processed using monoexponential and kurtosis models, and T2w demonstrated good classification performance for GS of PCa. In multisequence setting, the optimal radiomics based texture extraction methods and parameters differed between different image types.","This study was financially supported by grants from Instrumentarium Research Foundation, Sigrid Jusélius Foundation, Turku University Hospital, TYKS-SAPA research fund, Finnish Cancer Society, Finnish Cultural Foundation, and Orion Research Foundation. PT was supported by Clinical Researcher Funding from the Academy of Finland. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. This study was financially supported by grants from Instrumentarium Research Foundation, Sigrid Jusélius Foundation, Turku University Hospital, TYKS-SAPA research fund, Finnish Cancer Society, Finnish Cultural Foundation, and Orion Research Foundation. PT was supported by Clinical Researcher Funding from the Academy of Finland. We thank Jaakko Liippo (Turku University Hospital, Turku, Finland) for his help in scanning the histological slides, and Anitta Entonen (Turku University Hospital, Turku, Finland) for her help with patient enrollment and assistance during MRI examinations. No funding bodies had any role in the study design, data collection and analysis, decision to publish, or preparation of this manuscript.","This study was financially supported by grants from Instrumentarium Research Foundation, Sigrid Jusélius Foundation, Turku University Hospital, TYKS-SAPA research fund, Finnish Cancer Society, Finnish Cultural Foundation, and Orion Research Foundation. PT was supported by Clinical Researcher Funding from the Academy of Finland. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.",PLOS ONE,,"Aged; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Middle Aged; Multiparametric Magnetic Resonance Imaging; Prostatic Neoplasms",2019-07-08,2019,2019-07-08,,14,7,e0217702,All OA; Gold,Article,"Toivonen, Jussi; Perez, Ileana Montoya; Movahedi, Parisa; Merisaari, Harri; Pesola, Marko; Taimen, Pekka; Boström, Peter J.; Pohjankukka, Jonne; Kiviniemi, Aida; Pahikkala, Tapio; Aronen, Hannu J.; Jambor, Ivan","Toivonen, Jussi (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland; Dept. of Future Technologies, University of Turku, Turku, Finland); Perez, Ileana Montoya (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland; Dept. of Future Technologies, University of Turku, Turku, Finland); Movahedi, Parisa (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland; Dept. of Future Technologies, University of Turku, Turku, Finland); Merisaari, Harri (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland; Dept. of Future Technologies, University of Turku, Turku, Finland; Turku PET Centre, University of Turku, Turku, Finland); Pesola, Marko (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland); Taimen, Pekka (Institute of Biomedicine, University of Turku and Dept. of Pathology, Turku University Hospital, Turku, Finland); Boström, Peter J. (Dept. of Urology, Turku University Hospital, Turku, Finland); Pohjankukka, Jonne (Dept. of Future Technologies, University of Turku, Turku, Finland); Kiviniemi, Aida (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland; Medical Imaging Centre of Southwest Finland, Turku University Hospital, Turku, Finland); Pahikkala, Tapio (Dept. of Future Technologies, University of Turku, Turku, Finland); Aronen, Hannu J. (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland; Medical Imaging Centre of Southwest Finland, Turku University Hospital, Turku, Finland); Jambor, Ivan (Dept. of Diagnostic Radiology, University of Turku, Turku, Finland; Department of Radiology, Icahn School of Medicine at Mount Sinai, New York, NY, United States of America)","Toivonen, Jussi (University of Turku; University of Turku)","Toivonen, Jussi (University of Turku; University of Turku); Perez, Ileana Montoya (University of Turku; University of Turku); Movahedi, Parisa (University of Turku; University of Turku); Merisaari, Harri (University of Turku; University of Turku; Turku PET Centre); Pesola, Marko (University of Turku); Taimen, Pekka (Turku University Hospital); Boström, Peter J. (Turku University Hospital); Pohjankukka, Jonne (University of Turku); Kiviniemi, Aida (University of Turku; Turku University Hospital); Pahikkala, Tapio (University of Turku); Aronen, Hannu J. (University of Turku; Turku University Hospital); Jambor, Ivan (University of Turku; Icahn School of Medicine at Mount Sinai)",65,48,5.02,19.48,https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0217702&type=printable,https://app.dimensions.ai/details/publication/pub.1117843705,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis,
3431,pub.1091322966,10.1016/j.media.2017.08.006,28850876,,Co-trained convolutional neural networks for automated detection of prostate cancer in multi-parametric MRI,"Multi-parameter magnetic resonance imaging (mp-MRI) is increasingly popular for prostate cancer (PCa) detection and diagnosis. However, interpreting mp-MRI data which typically contains multiple unregistered 3D sequences, e.g. apparent diffusion coefficient (ADC) and T2-weighted (T2w) images, is time-consuming and demands special expertise, limiting its usage for large-scale PCa screening. Therefore, solutions to computer-aided detection of PCa in mp-MRI images are highly desirable. Most recent advances in automated methods for PCa detection employ a handcrafted feature based two-stage classification flow, i.e. voxel-level classification followed by a region-level classification. This work presents an automated PCa detection system which can concurrently identify the presence of PCa in an image and localize lesions based on deep convolutional neural network (CNN) features and a single-stage SVM classifier. Specifically, the developed co-trained CNNs consist of two parallel convolutional networks for ADC and T2w images respectively. Each network is trained using images of a single modality in a weakly-supervised manner by providing a set of prostate images with image-level labels indicating only the presence of PCa without priors of lesions' locations. Discriminative visual patterns of lesions can be learned effectively from clutters of prostate and surrounding tissues. A cancer response map with each pixel indicating the likelihood to be cancerous is explicitly generated at the last convolutional layer of the network for each modality. A new back-propagated error E is defined to enforce both optimized classification results and consistent cancer response maps for different modalities, which help capture highly representative PCa-relevant features during the CNN feature learning process. The CNN features of each modality are concatenated and fed into a SVM classifier. For images which are classified to contain cancers, non-maximum suppression and adaptive thresholding are applied to the corresponding cancer response maps for PCa foci localization. Evaluation based on 160 patient data with 12-core systematic TRUS-guided prostate biopsy as the reference standard demonstrates that our system achieves a sensitivity of 0.46, 0.92 and 0.97 at 0.1, 1 and 10 false positives per normal/benign patient which is significantly superior to two state-of-the-art CNN-based methods (Oquab et al., 2015; Zhou et al., 2015) and 6-core systematic prostate biopsies.",This work was supported by the National Natural Science Foundation of China grant 61502188.,,Medical Image Analysis,,"Algorithms; Automation; Humans; Image Interpretation, Computer-Assisted; Image-Guided Biopsy; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Prostatic Neoplasms; Reproducibility of Results; Sensitivity and Specificity",2017-08-24,2017,2017-08-24,2017-12,42,,212-227,Closed,Article,"Yang, Xin; Liu, Chaoyue; Wang, Zhiwei; Yang, Jun; Le Min, Hung; Wang, Liang; Cheng, Kwang-Ting","Yang, Xin (Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China); Liu, Chaoyue (Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China); Wang, Zhiwei (Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China); Yang, Jun (Department of Organ transplantation, Tongji Hospital, Huazhong University of Science and Technology, 430022, Wuhan, China); Le Min, Hung (Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China); Wang, Liang (Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, 430030, Wuhan, China); Cheng, Kwang-Ting (School of Engineering, Hong Kong University of Science and Technology, Hong Kong)","Wang, Zhiwei (Huazhong University of Science and Technology)","Yang, Xin (Huazhong University of Science and Technology); Liu, Chaoyue (Huazhong University of Science and Technology); Wang, Zhiwei (Huazhong University of Science and Technology); Yang, Jun (Huazhong University of Science and Technology; Tongji Hospital); Le Min, Hung (Huazhong University of Science and Technology); Wang, Liang (Huazhong University of Science and Technology; Tongji Hospital); Cheng, Kwang-Ting (Hong Kong University of Science and Technology)",101,48,3.63,25.39,,https://app.dimensions.ai/details/publication/pub.1091322966,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
3430,pub.1059031425,10.1088/0031-9155/61/13/4796,27272935,,Computer-aided detection of prostate cancer in T2-weighted MRI within the peripheral zone,"In this paper we propose a prostate cancer computer-aided diagnosis (CAD) system and suggest a set of discriminant texture descriptors extracted from T2-weighted MRI data which can be used as a good basis for a multimodality system. For this purpose, 215 texture descriptors were extracted and eleven different classifiers were employed to achieve the best possible results. The proposed method was tested based on 418 T2-weighted MR images taken from 45 patients and evaluated using 9-fold cross validation with five patients in each fold. The results demonstrated comparable results to existing CAD systems using multimodality MRI. We achieved an area under the receiver operating curve (A z ) values equal to [Formula: see text], [Formula: see text], [Formula: see text] and [Formula: see text] for Bayesian networks, ADTree, random forest and multilayer perceptron classifiers, respectively, while a meta-voting classifier using average probability as a combination rule achieved [Formula: see text].",A Rampun is grateful for the awards given by Aberystwyth University under the Departmental Overseas Scholarship (DOS) and Doctoral Career Development Scholarships (DCDS). This work was funded in part by the NISCHR Biomedical Research Unit for Advanced Medical Imaging and Visualization.,,Physics in Medicine and Biology,,"Algorithms; Bayes Theorem; Diagnosis, Computer-Assisted; Humans; Magnetic Resonance Imaging; Male; Probability; Prostatic Neoplasms; ROC Curve",2016-06-08,2016,2016-06-08,2016-07-07,61,13,4796-4825,All OA; Green,Article,"Rampun, Andrik; Zheng, Ling; Malcolm, Paul; Tiddeman, Bernie; Zwiggelaar, Reyer","Rampun, Andrik (Department of Computer Science, Aberystwyth University, Aberystwyth SY23 3DB, UK); Zheng, Ling (Department of Computer Science, Aberystwyth University, Aberystwyth SY23 3DB, UK); Malcolm, Paul (Department of Radiology, Norfolk Norwich University Hospital, Norwich NR4 7UY, UK); Tiddeman, Bernie (Department of Computer Science, Aberystwyth University, Aberystwyth SY23 3DB, UK); Zwiggelaar, Reyer (Department of Computer Science, Aberystwyth University, Aberystwyth SY23 3DB, UK)",,"Rampun, Andrik (Aberystwyth University); Zheng, Ling (Aberystwyth University); Malcolm, Paul (Norfolk and Norwich University Hospital); Tiddeman, Bernie (Aberystwyth University); Zwiggelaar, Reyer (Aberystwyth University)",32,7,0.98,25.03,https://pure.aber.ac.uk/portal/files/9271217/PMB.pdf,https://app.dimensions.ai/details/publication/pub.1059031425,51 Physical Sciences; 5105 Medical and Biological Physics,
3030,pub.1112098321,10.1007/s13246-019-00730-z,30762223,,Multiparametric MRI and radiomics in prostate cancer: a review,"Multiparametric MRI (mpMRI) is an imaging modality that combines anatomical MR imaging with one or more functional MRI sequences. It has become a versatile tool for detecting and characterising prostate cancer (PCa). The traditional role of mpMRI was confined to PCa staging, but due to the advanced imaging techniques, its role has expanded to various stages in clinical practises including tumour detection, disease monitor during active surveillance and sequential imaging for patient follow-up. Meanwhile, with the growing speed of data generation and the increasing volume of imaging data, it is highly demanded to apply computerised methods to process mpMRI data and extract useful information. Hence quantitative analysis for imaging data using radiomics has become an emerging paradigm. The application of radiomics approaches in prostate cancer has not only enabled automatic localisation of the disease but also provided a non-invasive solution to assess tumour biology (e.g. aggressiveness and the presence of hypoxia). This article reviews mpMRI and its expanding role in PCa detection, staging and patient management. Following that, an overview of prostate radiomics will be provided, with a special focus on its current applications as well as its future directions.","The authors would like to acknowledge Peter MacCallum Cancer Centre, The University of Melbourne and Cancer Therapeutics CRC for providing the resources to perform the literature survey. The authors would also like to show their gratitude to Courtney Savill and Lauren Caspersz for their contributions in data collection.","This study is supported by PdCCRS grant 628592 with funding partners: Prostate Cancer Foundation of Australia, and the Radiation Oncology Section of the Australian Government of Health and Aging and Cancer Australia. Yu Sun is funded by the Melbourne International Research Scholarship, a Movember Young Investigator Grant through Prostate Cancer Foundation of Australia (PCFA) and Cancer Therapeutics Top-up Funding. Hayley Reynolds is funded by a Movember Young Investigator Grant through PCFA’s Research Program.",Physical and Engineering Sciences in Medicine,,"Algorithms; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Prostatic Neoplasms",2019-02-14,2019,2019-02-14,2019-03,42,1,3-25,Closed,Article,"Sun, Yu; Reynolds, Hayley M.; Parameswaran, Bimal; Wraith, Darren; Finnegan, Mary E.; Williams, Scott; Haworth, Annette","Sun, Yu (University of Sydney, Sydney, Australia; Peter MacCallum Cancer Centre, Melbourne, Australia); Reynolds, Hayley M. (Peter MacCallum Cancer Centre, Melbourne, Australia); Parameswaran, Bimal (Imaging Associates, Melbourne, Australia); Wraith, Darren (Queensland University of Technology, Brisbane, Australia); Finnegan, Mary E. (Imperial College Healthcare NHS Trust, London, UK; Imperial College London, London, UK); Williams, Scott (Peter MacCallum Cancer Centre, Melbourne, Australia); Haworth, Annette (University of Sydney, Sydney, Australia)","Sun, Yu (The University of Sydney; Peter MacCallum Cancer Centre)","Sun, Yu (The University of Sydney; Peter MacCallum Cancer Centre); Reynolds, Hayley M. (Peter MacCallum Cancer Centre); Parameswaran, Bimal (); Wraith, Darren (Queensland University of Technology); Finnegan, Mary E. (Imperial College Healthcare NHS Trust; Imperial College London); Williams, Scott (Peter MacCallum Cancer Centre); Haworth, Annette (The University of Sydney)",68,51,6.12,23.74,,https://app.dimensions.ai/details/publication/pub.1112098321,40 Engineering; 4003 Biomedical Engineering; 51 Physical Sciences; 5105 Medical and Biological Physics,3 Good Health and Well Being
1928,pub.1111703469,10.1007/978-3-030-11018-5_66,,,A 2.5D Deep Learning-Based Approach for Prostate Cancer Detection on T2-Weighted Magnetic Resonance Imaging,"In this paper, we propose a fully automatic magnetic resonance image (MRI)-based computer aided diagnosis (CAD) system which simultaneously performs both prostate segmentation and prostate cancer diagnosis. The system utilizes a deep-learning approach to extract high-level features from raw T2-weighted MR volumes. Features are then remapped to the original input to assign a predicted label to each pixel. In the same context, we propose a 2.5D approach which exploits 3D spatial information without a compromise in computational cost. The system is evaluated on a public dataset. Preliminary results demonstrate that our approach outperforms current state-of-the-art in both prostate segmentation and cancer diagnosis.",This work is supported by a research grant from Al-Jalila foundation Ref: AJF-201616.,,Lecture Notes in Computer Science,Computer Vision – ECCV 2018 Workshops,,2019-01-23,2019,2019-01-23,2019,11132,,734-739,Closed,Chapter,"Alkadi, Ruba; El-Baz, Ayman; Taher, Fatma; Werghi, Naoufel","Alkadi, Ruba (Khalifa University of Science and Technology, Abu Dhabi, UAE); El-Baz, Ayman (Department of Bioengineering, University of Louisville, Louisville, KY, USA); Taher, Fatma (Khalifa University of Science and Technology, Abu Dhabi, UAE); Werghi, Naoufel (Khalifa University of Science and Technology, Abu Dhabi, UAE)","Alkadi, Ruba (Khalifa University of Science and Technology)","Alkadi, Ruba (Khalifa University of Science and Technology); El-Baz, Ayman (University of Louisville); Taher, Fatma (Khalifa University of Science and Technology); Werghi, Naoufel (Khalifa University of Science and Technology)",11,8,,,,https://app.dimensions.ai/details/publication/pub.1111703469,46 Information and Computing Sciences,
1754,pub.1093425323,10.1109/iceei.2015.7352585,,,Multi-Scoring Feature Selection Method Based on SVM-RFE for Prostate Cancer Diagnosis,"Prostate cancer diagnosis is based mainly by microscopic evaluation of prostate tissue biopsy which includes assigning cancer grading. The latter is crucial in evaluating the prognosis or cancer progression and treatment. The common grading system used is Gleason grading system that classifies the prostate cancer into five basic grades based on the architecture and pattern of glandular proliferation. However, this process may be subjected to inter and intra observer variation. Therefore, the main aim of this paper is to develop a computer aided diagnosis (CAD) utilizing supervised machine learning techniques for Gleason grading of prostate histology. The proposed procedure utilizes the main tissue components of the images in an ensemble style to correctly classify the input histopathological image into benign or malignant. Moreover, the texture features of the benign and malignant images can be used to build the proposed ensemble framework. However, not all extracted texture features contribute to the improvement of the classification performance of the proposed ensemble framework. Therefore, to select the more informative features from a set is a critical issue. In this study, a new multi-scoring features selection method based on SVM-RFE and conditional mutual information (CMI) is proposed.",,,,2015 International Conference on Electrical Engineering and Informatics (ICEEI),,2015-08-01,2015,,2015-08-01,,,682-686,Closed,Proceeding,"Albashish, Dheeb; Sahran, Shahnorbanun; Abdullah, Azizi.; Adam, Afzan; Shukor, Nordashima Abd; Pauzi, Suria Hayati Md","Albashish, Dheeb (Pattern Recognition Research Group, Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, University Kebangsaan Malaysia, 43600, Bangi, Malaysia’); Sahran, Shahnorbanun (Pattern Recognition Research Group, Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, University Kebangsaan Malaysia, 43600, Bangi, Malaysia’); Abdullah, Azizi. (Pattern Recognition Research Group, Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, University Kebangsaan Malaysia, 43600, Bangi, Malaysia’); Adam, Afzan (Pattern Recognition Research Group, Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, University Kebangsaan Malaysia, 43600, Bangi, Malaysia’); Shukor, Nordashima Abd (Department of Pathology, University Kebangsaan Malaysia Medical Center); Pauzi, Suria Hayati Md (Department of Pathology, University Kebangsaan Malaysia Medical Center)",,"Albashish, Dheeb (); Sahran, Shahnorbanun (); Abdullah, Azizi. (); Adam, Afzan (); Shukor, Nordashima Abd (); Pauzi, Suria Hayati Md ()",6,4,,1.04,,https://app.dimensions.ai/details/publication/pub.1093425323,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences,
1754,pub.1006319888,10.1117/12.2216072,,,Normalization of T2W-MRI prostate images using Rician a priori,,,,Proceedings of SPIE,Medical Imaging 2016: Computer-Aided Diagnosis,,2016-03-24,2016,2016-03-24,2016-03-24,9785,,978529-978529-7,All OA; Green,Proceeding,"Lemaitre, Guillaume; Dastjerdi, Mojdeh Rastgo; Massich, Joan; Vilanova, Joan C.; Walker, Paul M.; Freixenet, Jordi; Meyer-Baese, Anke; Mériaudeau, Fabrice; Marti, Robert","Lemaitre, Guillaume (Univ. Bourgogne Franche-Comté (France)); Dastjerdi, Mojdeh Rastgo (Univ. Bourgogne Franche-Comté (France)); Massich, Joan (Univ. Bourgogne Franche-Comté (France)); Vilanova, Joan C. (Univ. de Girona (Spain)); Walker, Paul M. (Univ. Bourgogne Franche-Comté (France)); Freixenet, Jordi (Univ. de Girona (Spain)); Meyer-Baese, Anke (Florida State Univ. (United States)); Mériaudeau, Fabrice (Univ. Bourgogne Franche-Comté (France)); Marti, Robert (Univ. de Girona (Spain))",,"Lemaitre, Guillaume (Université Bourgogne Franche-Comté); Dastjerdi, Mojdeh Rastgo (Université Bourgogne Franche-Comté); Massich, Joan (Université Bourgogne Franche-Comté); Vilanova, Joan C. (University of Girona); Walker, Paul M. (Université Bourgogne Franche-Comté); Freixenet, Jordi (University of Girona); Meyer-Baese, Anke (Florida State University); Mériaudeau, Fabrice (Université Bourgogne Franche-Comté); Marti, Robert (University of Girona)",10,4,,3.27,https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01265774/file/master.pdf,https://app.dimensions.ai/details/publication/pub.1006319888,"40 Engineering; 4006 Communications Engineering; 4009 Electronics, Sensors and Digital Hardware; 51 Physical Sciences; 5102 Atomic, Molecular and Optical Physics",
1754,pub.1122590702,10.1109/scored.2019.8896248,,,Zonal Segmentation of Prostate T2W-MRI using Atrous Convolutional Neural Network,"The number of prostate cancer cases is steadily increasing especially with rising number of ageing population. It is reported that 5-year relative survival rate for man with stage 1 prostate cancer is almost 99% hence, early detection will significantly improve treatment planning and increase survival rate. Magnetic resonance imaging (MRI) technique is a common imaging modality for diagnosis of prostate cancer. MRI provide good visualization of soft tissue and enable better lesion detection and staging of prostate cancer. The main challenge of prostate whole gland segmentation is due to blurry boundary of central gland (CG) and peripheral zone (PZ) which lead to differential diagnosis. Since there is substantial difference in occurance and characteristic of cancer in both zones. So to enhance the diagnosis of prostate gland, we implemented DeeplabV3+ semantic segmentation approach to segment the prostate into zones. DeepLabV3+ achieved significant results in segmentation of prostate MRI by applying several parallel atrous convolution with different rates. The CNN-based semantic segmentation approach is trained and tested on NCI-ISBI 1.5T and 3T MRI dataset consist of 40 patients. Performance evaluation based on Dice similarity coefficient (DSC) of the Deeplab-based segmentation is compared with two other CNN-based semantic segmentation techniques: FCN and PSNet. Results shows that prostate segmentation using DeepLabV3+ can perform better than FCN and PSNet with average DSC of 70.3% in PZ and 88% in CG zone. This indicates the significant contribution made by the atrous convolution layer, in producing better prostate segmentation result.",This work has been supported by the international collaborative research fund between UTP-UMP under Grant 015ME0-098. This work has been supported by the international collaborative research fund between UTP-UMP under Grant 015ME0-098.,,,2019 IEEE Student Conference on Research and Development (SCOReD),,2019-10-15,2019,,2019-10-15,00,,95-99,Closed,Proceeding,"Khan, Zia; Yahya, Norashikin; Alsaih, Khaled; Meriaudeau, Fabrice","Khan, Zia (Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS (UTP), Malaysia); Yahya, Norashikin (Centre for Intelligent Signal and Imaging Research (CISIR); Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS (UTP), Malaysia); Alsaih, Khaled (Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS (UTP), Malaysia); Meriaudeau, Fabrice (ImViA/ITFIM, University of Burgundy, France)",,"Khan, Zia (Universiti Teknologi Petronas); Yahya, Norashikin (Universiti Teknologi Petronas); Alsaih, Khaled (Universiti Teknologi Petronas); Meriaudeau, Fabrice (University of Burgundy)",9,7,,3.18,,https://app.dimensions.ai/details/publication/pub.1122590702,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1752,pub.1121613880,10.1007/978-3-030-32486-5_6,,,A Two-Stage Approach for Automated Prostate Lesion Detection and Classification with Mask R-CNN and Weakly Supervised Deep Neural Network,"Early diagnosis of prostate cancer is very crucial to reduce the mortality rate. Multi-parametric magnetic resonance imaging (MRI) can provide detailed visualization of prostate tissues and lesions. Their malignancy can be diagnosed before any necessary invasive approaches, such as needle biopsy, at the risk of damage to or inflammation of the periprostatic nerves, prostate and bladder neck. However, the prostate tissue malignancy on magnetic resonance (MR) images can also be difficult to determine, with often inconclusive results among the clinicians. With the progress in artificial intelligence (AI), research on MR image-based lesion classification with AI tools are being explored increasingly. So far, existing classification approaches heavily rely on manually labelling of lesion areas, which is a labor-intensive and time-consuming process. In this paper, we present a novel two-stage method for fully-automated prostate lesion detection and classification, using input sequences of T2-weighted images, apparent diffusion coefficient (ADC) maps and high b-value diffusion-weighted images. In the first stage, a Mask R-CNN model is trained to automatically segment prostate structures. In the second stage, a weakly supervised deep neural network is developed to detect and classify lesions in a single run. To validate the accuracy of our system, we tested our method on two datasets, one from the PROSTATEx Challenge and the other from our local cohort. Our method can achieve average area-under-the-curve (AUC) of 0.912 and 0.882 on the two datasets respectively. The proposed approach present a promising tool for radiologists in their clinical practices.","This work is supported by the Research Grants Council (RGC) of HK (Ref. No.: 17202317, 17227616, 17206818, 27209515), and Innovation and Technology Commission (Ref. No.: UIM/353).",,Lecture Notes in Computer Science,Artificial Intelligence in Radiation Therapy,,2019-10-10,2019,2019-10-10,2019,11850,,43-51,Closed,Chapter,"Liu, Zhiyu; Jiang, Wenhao; Lee, Kit-Hang; Lo, Yat-Long; Ng, Yui-Lun; Dou, Qi; Vardhanabhuti, Varut; Kwok, Ka-Wai","Liu, Zhiyu (Department of Mechanical Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong); Jiang, Wenhao (Department of Mechanical Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong); Lee, Kit-Hang (Department of Mechanical Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong); Lo, Yat-Long (Department of Mechanical Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong); Ng, Yui-Lun (Department of Mechanical Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong); Dou, Qi (Department of Computing, Imperial College London, London, UK); Vardhanabhuti, Varut (Department of Diagnostic Radiology, Li Ka Shing Faculty of Medicine, The University of Hong Kong, Pok Fu Lam, Hong Kong); Kwok, Ka-Wai (Department of Mechanical Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong)","Kwok, Ka-Wai (University of Hong Kong)","Liu, Zhiyu (University of Hong Kong); Jiang, Wenhao (University of Hong Kong); Lee, Kit-Hang (University of Hong Kong); Lo, Yat-Long (University of Hong Kong); Ng, Yui-Lun (University of Hong Kong); Dou, Qi (Imperial College London); Vardhanabhuti, Varut (University of Hong Kong); Kwok, Ka-Wai (University of Hong Kong)",7,7,,,,https://app.dimensions.ai/details/publication/pub.1121613880,46 Information and Computing Sciences,
1749,pub.1112089790,10.1016/j.ijleo.2019.02.036,,,Feasibility of fast non-local means noise reduction algorithm in magnetic resonance imaging using 1.5 and 3.0 T with diffusion-weighted image technique,"Magnetic resonance imaging (MRI) has many advantages and has developed various pulse sequences. In particular, the diffusion weighted image (DWI) technique is widely used because it can acquire images quickly during examination of stroke, through a proper adjustment of the diffusion-weighted gradient b-value. However, a setting with inappropriate b-value causes loss of image signal that increases the influence of noise. Therefore, in this study, we quantitatively evaluated image quality after applying a variety of algorithms to the image acquired by changing the b-value and the main magnetic field in the MRI device. To acquire the image, the phantom was self-produced with an acrylic panel and chicken breast. Wiener filter, total variation (TV), and our proposed fast non-local means (FNLM) noise reduction algorithms were applied to the image. Consequently, the signal intensity at a 3.0 T magnetic field increased by a factor 4.8 compared to a 1.5 T magnetic field. Moreover, the signal-to-noise ratio and contrast-to-noise ratio were highest with the FNLM algorithm, and the values increased by factors of 9.5 and 9.9 with a 1.5 T magnetic field and by factors of 9.9 and 5.0 with a 3.0 T magnetic field compared to the noise image, respectively. The result of time resolution, the Wiener filter appeared the finest value, but had no significant difference compared to FNLM algorithm. In conclusion, our results confirmed that the proposed FNLM noise reduction algorithm can acquire both improved image quality and high processing time in MRI imaging with the DWI technique.",This research was supported by the Gachon University research fund of 2018 (GCU-2018-0289) and the National Research Foundation of Korea (NRF-2016R1D1A1B03930357).,,Optik,,,2019-04,2019,,2019-04,183,,241-246,Closed,Article,"Choi, Won Ho; Choi, Hye Ran; Seo, Eunsoo; Hwang, Jeewoo; Oh, Heekyung; Kim, Myeong Rae; Han, Su Rin; Kim, Min Seok; Kang, Seong-Hyeon; Lee, Youngjin","Choi, Won Ho (Department of Radiology, Asan Medical Center, 88, Olympic-ro 43-gil, Songpa-gu, Seoul, Republic of Korea); Choi, Hye Ran (Department of Radiological Science, Eulji University, 553, Sanseong-daero, Sujeong-gu, Seongnam-si, Gyeonggi-do, Republic of Korea); Seo, Eunsoo (Department of Radiological Science, Gachon University, 191, Hambakmoero, Yeonsu-gu, Incheon, Republic of Korea); Hwang, Jeewoo (Department of Radiological Science, Gachon University, 191, Hambakmoero, Yeonsu-gu, Incheon, Republic of Korea); Oh, Heekyung (Department of Radiological Science, Gachon University, 191, Hambakmoero, Yeonsu-gu, Incheon, Republic of Korea); Kim, Myeong Rae (Department of Radiological Science, Eulji University, 553, Sanseong-daero, Sujeong-gu, Seongnam-si, Gyeonggi-do, Republic of Korea); Han, Su Rin (Department of Radiological Science, Eulji University, 553, Sanseong-daero, Sujeong-gu, Seongnam-si, Gyeonggi-do, Republic of Korea); Kim, Min Seok (Department of Radiology, Seoul National University Boramae Medical Center, 20, Boramae-ro 5-gil, Dongjak-gu, Seoul, Republic of Korea); Kang, Seong-Hyeon (Department of Radiological Science, Gachon University, 191, Hambakmoero, Yeonsu-gu, Incheon, Republic of Korea); Lee, Youngjin (Department of Radiological Science, Gachon University, 191, Hambakmoero, Yeonsu-gu, Incheon, Republic of Korea)","Lee, Youngjin (Gachon University)","Choi, Won Ho (Asan Medical Center); Choi, Hye Ran (Eulji University); Seo, Eunsoo (Gachon University); Hwang, Jeewoo (Gachon University); Oh, Heekyung (Gachon University); Kim, Myeong Rae (Eulji University); Han, Su Rin (Eulji University); Kim, Min Seok (Boramae Medical Center); Kang, Seong-Hyeon (Gachon University); Lee, Youngjin (Gachon University)",2,1,,0.71,,https://app.dimensions.ai/details/publication/pub.1112089790,"51 Physical Sciences; 5102 Atomic, Molecular and Optical Physics; 5108 Quantum Physics",
1749,pub.1085997059,10.1007/978-981-10-5122-7_207,,,MRI imaging texture features in prostate lesions classification,"Prostate cancer (PCa) is the most common diagnosed cancer and cause of cancer-related death among men. Computer Aided Diagnosis (CAD) systems are used to support radiologists in multiparametric Magnetic Resonance (mpMR) image-based analysis in order to avoid unnecessary biopsis and increase radiologist’s specificity. CAD systems have been reported in many papers for the last decade. The reported results have been obtained on small, private data sets and are impossible to reproduce or verify concluded remarks. PROSTATEx challenge organizers provided database that contains approximately 350 MRI cases, each from a distinct patient, allowing benchmarking of various CAD systems. This paper describes novel, deep learning based PCa CAD system that uses statistical central moments and Haralick features extracted from MR images, integrated with anamnestic data. Developed system has been trained on the dataset consisting of 330 lesions and evaluated on the challenge dataset using area under curve (AUC) related to estimated receiver operating characteristic (ROC). Two configurations of our method, based on statistical and Haralick features, scored 0.63 and 0.73 of AUC values. We draw conclusions from the challenge participation and discussed further improvements that could be made to the model to improve prostate classification.",,,IFMBE Proceedings,EMBEC & NBC 2017,,2017-06-13,2017,2017-06-13,2018,65,,827-830,Closed,Chapter,"Sobecki, Piotr; Życka-Malesa, Dominika; Mykhalevych, Ihor; Sklinda, Katarzyna; Przelaskowski, Artur","Sobecki, Piotr (Faculty of Mathematics and Information Science, Warsaw University of Technology, Warsaw, Poland; Information Processing Centre, Polish Research Institute, Warsaw, Poland); Życka-Malesa, Dominika (Faculty of Mathematics and Information Science, Warsaw University of Technology, Warsaw, Poland); Mykhalevych, Ihor (Faculty of Mathematics and Information Science, Warsaw University of Technology, Warsaw, Poland); Sklinda, Katarzyna (Department of Radiology, Central Clinical Hospital of the Ministry of the Interior and Administration, Warsaw, Poland); Przelaskowski, Artur (Faculty of Mathematics and Information Science, Warsaw University of Technology, Warsaw, Poland)","Sobecki, Piotr (Warsaw University of Technology; )","Sobecki, Piotr (Warsaw University of Technology); Życka-Malesa, Dominika (Warsaw University of Technology); Mykhalevych, Ihor (Warsaw University of Technology); Sklinda, Katarzyna (Ministry of Interior and Administration); Przelaskowski, Artur (Warsaw University of Technology)",6,2,,1.26,,https://app.dimensions.ai/details/publication/pub.1085997059,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis,
1716,pub.1123304792,10.1109/ultsym.2019.8925823,,,"Machine Learning for Multiparametric Ultrasound Classification of Prostate Cancer using B-mode, Shear-Wave Elastography, and Contrast-Enhanced Ultrasound Radiomics","The diagnosis of prostate cancer (PCa) is still based on systematic biopsy, but is increasingly developing towards an imaging-driven approach. In particular, multiparametric magnetic resonance imaging (MRI) is receiving increasing attention over the last few years. In light of MRI-related issues concerning costs, practicality, and availability, we investigate a multiparametric ultrasound (mpUS) approach. We propose and test a machine-learning-based strategy that automatically combines B-mode ultrasound, shear-wave elastography (SWE), and dynamic contrast-enhanced ultrasound (DCE-US) features. To this end, automatic zonal segmentation by deep learning, model-based feature estimation (related to contrast-agent perfusion and dispersion), radiomic feature extraction, and a random-forest-based pixel-wise classification were combined. The method was trained and validated against histopathologically-confirmed benign and malignant regions of interest in 48 PCa patients, in a leave-one-patient-out cross-correlation fashion. The mpUS classification algorithm yielded a region-wise area under the Receiver Operating Characteristics (ROC) curve of 0.75 and 0.90 for PCa and significant (i.e., Gleason ≥4+3) PCa, respectively. In comparison, the best-performing single parameter (i.e., DCE-US-based contrast velocity) reached a performance of 0.69 and 0.76 in terms of the ROC curve area. In particular the combination of perfusion-, dispersion-, and elasticity-related features were favored in the classification. Even though validation on a larger patient group is required, we have demonstrated the technical feasibility of automatic mpUS for PCa localization. Further development of mpUS might lead to a valuable clinical option for robust, ultrasound-driven PCa diagnosis.","This research was conducted in the framework of the IMPULS2 program within the Eindhoven University in collaboration with Philips. It also received funding from the Dutch Cancer Society (#UVA2013-5941) and a European Research Council Starting Grant (#280209). Furthermore, the authors would like to acknowledge SuperSonic Imagine (Aix-en-Provence, France) for providing the Aixplorer ultrasound scanner as well as NVIDIA Corporation for granting the Titan XP graphics processing unit. This research was conducted in the framework of the IMPULS2 program within the Eindhoven University in collaboration with Philips. It also received funding from the Dutch Cancer Society (#UVA2013-5941) and a European Research Council Starting Grant (#280209). Furthermore, the authors would like to acknowledge SuperSonic Imagine (Aix-en-Provence, France) for providing the Aixplorer ultrasound scanner as well as NVIDIA Corporation for granting the Titan XP graphics processing unit.",,,2019 IEEE International Ultrasonics Symposium (IUS),,2019-10-09,2019,,2019-10-09,00,,1902-1905,Closed,Proceeding,"Wildeboer, R.R.; Mannaerts, Christophe K.; van Sloun, R.J.G.; Wijkstra, H.; Salomon, G.; Mischi, M.","Wildeboer, R.R. (Dept. of Electrical Engineering, Eindhoven University of Technology, The Netherlands); Mannaerts, Christophe K. (Dept. of Electrical Engineering, Eindhoven University of Technology, The Netherlands; Dept. of Urology, Amsterdam University Medical Centers, University of Amsterdam, Amsterdam, The Netherlands); van Sloun, R.J.G. (Dept. of Electrical Engineering, Eindhoven University of Technology, The Netherlands); Wijkstra, H. (Dept. of Electrical Engineering, Eindhoven University of Technology, The Netherlands; Dept. of Urology, Amsterdam University Medical Centers, University of Amsterdam, Amsterdam, The Netherlands); Salomon, G. (Martini Clinic, University Hospital Hamburg-Eppendorf, Germany); Mischi, M. (Dept. of Electrical Engineering, Eindhoven University of Technology, The Netherlands)","Wildeboer, R.R. (Eindhoven University of Technology)","Wildeboer, R.R. (Eindhoven University of Technology); Mannaerts, Christophe K. (Eindhoven University of Technology; University of Amsterdam); van Sloun, R.J.G. (Eindhoven University of Technology); Wijkstra, H. (Eindhoven University of Technology; University of Amsterdam); Salomon, G. (University Medical Center Hamburg-Eppendorf); Mischi, M. (Eindhoven University of Technology)",1,1,,0.35,,https://app.dimensions.ai/details/publication/pub.1123304792,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1716,pub.1006676588,10.1117/12.2182772,,,A boosting approach for prostate cancer detection using multi-parametric MRI,,,,Proceedings of SPIE,Twelfth International Conference on Quality Control by Artificial Vision 2015,,2015-04-30,2015,2015-04-30,2015-04-30,9534,,95340a-95340a-7,All OA; Green,Proceeding,"Lemaitre, Guillaume; Massich, Joan; Martí, Robert; Freixenet, Jordi; Vilanova, Joan C.; Walker, Paul M.; Sidibé, Désiré; Mériaudeau, Fabrice","Lemaitre, Guillaume (Le2i, CNRS, Univ. de Bourgogne (France)); Massich, Joan (Le2i, CNRS, Univ. de Bourgogne (France)); Martí, Robert (Univ. de Girona (Spain)); Freixenet, Jordi (Univ. de Girona (Spain)); Vilanova, Joan C. (Clínica Girona (Spain)); Walker, Paul M. (Le2i, CNRS, Univ. de Bourgogne (France)); Sidibé, Désiré (Le2i, CNRS, Univ. de Bourgogne (France)); Mériaudeau, Fabrice (Le2i, CNRS, Univ. de Bourgogne (France))",,"Lemaitre, Guillaume (University of Burgundy); Massich, Joan (University of Burgundy); Martí, Robert (University of Girona); Freixenet, Jordi (University of Girona); Vilanova, Joan C. (Clínica Girona); Walker, Paul M. (University of Burgundy); Sidibé, Désiré (University of Burgundy); Mériaudeau, Fabrice (University of Burgundy)",13,7,,4.3,https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01235890/file/glemaitre_qcav_2015.pdf,https://app.dimensions.ai/details/publication/pub.1006676588,"40 Engineering; 4006 Communications Engineering; 4009 Electronics, Sensors and Digital Hardware; 51 Physical Sciences; 5102 Atomic, Molecular and Optical Physics",
1715,pub.1091428682,10.1007/978-3-319-66179-7_45,,,Synergistic Combination of Learned and Hand-Crafted Features for Prostate Lesion Classification in Multiparametric Magnetic Resonance Imaging,"In this paper, we propose and evaluate a new method for classifying between malignant and benign prostate cancer lesions in multiparametric magnetic resonance imaging (MRI). We show that synergistically combining automatically-learned and handcrafted features can significantly improve the classification performance. Our method utilizes features extracted from convolutional neural networks (CNNs), texture features learned via a discriminative sparsity-regularized approach, and hand-crafted statistical features. To assess the efficacy of different feature sets, we use AdaBoost with decision trees to classify prostate cancer lesions using different sets of features. CNN-derived, texture, and statistical features achieved area under the receiver operating characteristic curve (AUC) of 0.75, 0.68, and 0.70, respectively. Augmenting CNN features with texture and statistical features increased the AUC to 0.84 and 0.82, respectively. Combining all three feature types led to an AUC of 0.87. Our results indicate that in medical applications where training data is scarce, the classification performance achieved by CNNs or sparsity-regularized classification methods alone can be sub-optimal. Alternatively, one can treat these methods as implicit feature extraction mechanisms and combine their learned features with hand-crafted features using meta-classifiers to obtain superior classification performance.",,,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention − MICCAI 2017,,2017-09-04,2017,2017-09-04,2017,10435,,391-398,Closed,Chapter,"Karimi, Davood; Ruan, Dan","Karimi, Davood (Department of Radiation Oncology, University of California, Los Angeles, USA); Ruan, Dan (Department of Radiation Oncology, University of California, Los Angeles, USA)","Karimi, Davood (University of California, Los Angeles)","Karimi, Davood (University of California, Los Angeles); Ruan, Dan (University of California, Los Angeles)",8,4,,,,https://app.dimensions.ai/details/publication/pub.1091428682,46 Information and Computing Sciences,
1711,pub.1117944561,10.1109/isbi.2019.8759314,,,Deep Learning for Volumetric Segmentation in Spatio-Temporal Data: Application to Segmentation of Prostate in DCE-MRI,"Segmentation of the prostate in MR images is an essential step that underpins the success of subsequent analysis methods, such as cancer lesion detection inside the tumour and registration between different modalities. This work focuses on leveraging deep learning for analysis of longitudinal volumetric datasets, particularly for the task of segmentation, and presents proof-of-concept for segmentation of the prostate in 3D+T DCE-MRI sequences. A two-stream processing pipeline is proposed for this task, comprising a spatial stream modelled using a volumetric fully convolutional network and a temporal stream modeled using recurrent neural networks with Long-Short-term Memory (LSTM) units. The predictions of the two streams are fused using deep neural networks. The proposed method has been validated on a public benchmark dataset of 17 patients, each with 40 temporal volumes. When averaged over three experiments, a highly competitive Dice overlap score of 0.8688 and sensitivity of 0.8694 were achieved. As a spatiotemporal segmentation method, it can easily migrate to other datasets.",,,,2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019),,2019-04-11,2019,,2019-04-11,00,,61-65,Closed,Proceeding,"Kang, Jian; Samarasinghe, Gihan; Senanayake, Upul; Conjeti, Sailesh; Sowmya, Arcot","Kang, Jian (School of Computer Science and Engineering, University of New South Wales, Sydney, Australia); Samarasinghe, Gihan (School of Computer Science and Engineering, University of New South Wales, Sydney, Australia); Senanayake, Upul (School of Computer Science and Engineering, University of New South Wales, Sydney, Australia); Conjeti, Sailesh (German Center for Neurodegenerative Diseases, Bonn, Germany 3; Computer Aided Medical Procedures, Technische Universität München, Munich, Germany); Sowmya, Arcot (School of Computer Science and Engineering, University of New South Wales, Sydney, Australia)","Sowmya, Arcot (UNSW Sydney)","Kang, Jian (UNSW Sydney); Samarasinghe, Gihan (UNSW Sydney); Senanayake, Upul (UNSW Sydney); Conjeti, Sailesh (German Center for Neurodegenerative Diseases; Technical University of Munich); Sowmya, Arcot (UNSW Sydney)",3,2,,1.15,,https://app.dimensions.ai/details/publication/pub.1117944561,46 Information and Computing Sciences; 4611 Machine Learning,
1711,pub.1093365247,10.1109/isbi.2016.7493420,,,Semi-Quantitative Analysis of Prostate Perfusion MRI by Clustering of Pre and Post Contrast Enhancement Phases,"Computer-based analysis is highly effective in information retrieval from Dynamic Contrast Enhance Magnetic Resonance Images (DCE-MRI) for prostate cancer recognition. Quantification and modelling of perfusion curves to extract higher order informative features for use in classification algorithms, is a major step in DCE-MRI analysis where inter-scan independent semi-quantitative models are highly desirable. This paper presents a semi-quantitative analysis model for prostate DCE-MRI, that is independent of inter-scan intensity variations, where the significance of the derived features is maximised by preserving the original shape of the perfusion curve to a maximum degree. The proposed model is evaluated on three different classifiers and 82 annotated prostate peripheral zone lesions in 3T DCE-MRI datasets of 40 patients. Random Forest Classifier yields a promising accuracy of 97.6% and a sensitivity of 92.3%.",,,,2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI),,2016-04-01,2016,,2016-04-01,,,943-947,Closed,Proceeding,"Samarasinghe, Gihan; Sowmya, Arcot; Moses, Daniel Aaron","Samarasinghe, Gihan (School of Computer Science and Engineering, The University of New South Wales (UNSW), NSW, 2052, Australia); Sowmya, Arcot (School of Computer Science and Engineering, The University of New South Wales (UNSW), NSW, 2052, Australia); Moses, Daniel Aaron (Department of Medical Imaging, Prince of Wales Hospital, Randwick, NSW, 2031, Australia)",,"Samarasinghe, Gihan (UNSW Sydney); Sowmya, Arcot (UNSW Sydney); Moses, Daniel Aaron (Prince of Wales Hospital)",2,2,,0.47,,https://app.dimensions.ai/details/publication/pub.1093365247,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences,
1679,pub.1125698866,10.1117/12.2551248,,,Radiomic features derived from periprostatic fat on pre-surgical T2w MRI predict extraprostatic extension of prostate cancer identified on post-surgical pathology: preliminary results,"Periprostatic fat composition on T2-weighted (T2w) MRI has been shown to be associated with aggressive prostate cancer and may influence extraprostatic extension (EPE). In this study, we interrogate the periprostatic fat (PPF) region adjacent to cancer lesion on prostate T2w MRI. Patients with pathologic stage pT3a are considered to experience EPE (EPE+) and those with stage T2c are without EPE (EPE-) post radical prostatectomy (RP). We use a cohort of N = 45 prostate cancer patients retrospectively acquired from a single institution who underwent 3T multi-parametric MRI prior to RP. Radiomic features including 1st and 2nd order statistics, Haralick, Gabor, CoLlAGe features are extracted from a region of interest (ROI) in the PPF on pre-surgical T2w MRI delineated by an experienced radiologist. Haralick, gradient and CoLlAGe features were observed to be significantly different (p<0.05) in PPF ROIs between EPE+ and EPE- and were significantly over expressed in EPE+ patients compared to EPE- patients, suggesting a higher heterogeneity within the PPF region for EPE+ patients. These features were used to train machine learning classifiers using a 3-fold cross validation approach in conjunction with feature selection methods to predict EPE. The best classification performance was obtained with Support Vector Machine (SVM) classifiers resulting in an AUC = 0.88 (0.04). On univariable and multivariable analysis, we observed that radiomic classifier predictions resulted in significant separation between EPE+ and EPE- while none of the routinely used clinical parameters including prostate specific antigen (PSA), Gleason Grade Groups (GGG), age, race and prostate imaging reporting and data system (PI-RADS v2) scores showed significant differences. Our results suggest that radiomic features may quantify the underlying heterogeneity in periprostatic fat and predict patients who are likely to experience extraprostatic extension of disease post RP.",,,Progress in Biomedical Optics and Imaging,Medical Imaging 2020: Computer-Aided Diagnosis,,2020-03-16,2020,,,11314,,113143g-113143g-7,Closed,Proceeding,"Shiradkar, Rakesh; Zuo, Ruyuan; Mahran, Amr; Ponsky, Lee; Tirumani, Sree Harsha; Madabhushi, Anant","Shiradkar, Rakesh (Case Western Reserve Univ. (United States)); Zuo, Ruyuan (Case Western Reserve Univ. (United States)); Mahran, Amr (Univ. Hospitals of Cleveland (United States)); Ponsky, Lee (Case Western Reserve Univ. (United States)); Tirumani, Sree Harsha (Univ. Hospitals of Cleveland (United States)); Madabhushi, Anant (Case Western Reserve Univ. (United States))",,"Shiradkar, Rakesh (Case Western Reserve University); Zuo, Ruyuan (Case Western Reserve University); Mahran, Amr (University Hospitals of Cleveland); Ponsky, Lee (Case Western Reserve University); Tirumani, Sree Harsha (University Hospitals of Cleveland); Madabhushi, Anant (Case Western Reserve University)",1,1,,0.43,,https://app.dimensions.ai/details/publication/pub.1125698866,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1675,pub.1135163898,10.1007/978-3-030-68449-5_14,,,Segmentation of Prostate in MRI Images Using Depth Separable Convolution Operations,"The segmentation of the prostate gland into two sub-regions, namely, the central gland (CG) and the peripheral zone (PZ) is crucial for the prostate cancer (PCa) diagnosis. The nature and occurrence of cancer occurred in the prostate is substantially different in both zones. Magnetic resonance imaging modality (MRI) is a clinically primary tool for computer-based assessment and remediation of various cancer types such as PCa. In this paper, we evaluated DeeplabV3+ model on T2W MRI scans using the I2CVB dataset, which is designed in an encoder-decoder style for the zonal segmentation of prostate regions. An important feature of DeeplabV3+ is the depth-wise separable convolutions, which allow more information to be extracted from images as it uses filters with different dilation rates. Prior to being fed to the deep neural network, image pre-processing techniques are applied, including image resizing, cropping, and denoising. The DeeplabV3+ model performance is evaluated using the Dice similarity coefficient (DSC) metric and compared with the vanilla U-Net architecture. Results show that the encoder-decoder network having depth-wise separable convolutions performed better prostate segmentation than the network with standard convolution operations with the DSC value of 70.1% in PZ and 81.5% in CG zone.",This project is supported by the Yayasan Universiti Teknologi PETRONAS (YUTP) research fund under grant number 015LC0-292.,,Lecture Notes in Computer Science,Intelligent Human Computer Interaction,,2021-02-06,2021,2021-02-06,2021,12615,,132-141,Closed,Chapter,"Khan, Zia; Yahya, Norashikin; Alsaih, Khaled; Meriaudeau, Fabrice","Khan, Zia (Centre for Intelligent and Imaging Research (CISIR), Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Malaysia); Yahya, Norashikin (Centre for Intelligent and Imaging Research (CISIR), Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Malaysia); Alsaih, Khaled (Centre for Intelligent and Imaging Research (CISIR), Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Malaysia); Meriaudeau, Fabrice (ImViA/IFTIM, University of Bourgogne Franche-Comté, Besançon, France)","Yahya, Norashikin (Universiti Teknologi Petronas)","Khan, Zia (Universiti Teknologi Petronas); Yahya, Norashikin (Universiti Teknologi Petronas); Alsaih, Khaled (Universiti Teknologi Petronas); Meriaudeau, Fabrice (Université Bourgogne Franche-Comté)",2,2,,,,https://app.dimensions.ai/details/publication/pub.1135163898,46 Information and Computing Sciences,
1675,pub.1084900082,10.1007/978-3-319-46720-7_71,,,Image-Based Computer-Aided Diagnostic System for Early Diagnosis of Prostate Cancer,"The goal of this paper is to develop a computer-aided diagnostic (CAD) system for early detection of prostate cancer from diffusion-weighted magnetic resonance imaging (DW-MRI) acquired at different b-values. The proposed system consists of three main steps. First, the prostate is segmented using a hybrid framework that integrates geometric deformable model (level-sets) and nonnegative matrix factorization (NMF). Secondly, the apparent diffusion coefficient (ADC) of the segmented prostate volume is first estimated at different b-values and is then normalized and refined using a generalized Gauss-Markov random field (GGMRF) image model. Then, the cumulative distribution function (CDF) of the refined ADCs at different b-values are constructed. Finally, a two-stage structure of stacked non-negativity constraint auto-encoder (SNCAE) is trained to classify the prostate tumor as benign or malignant based on the constructed CDFs. In the first stage, classification probabilities are estimated at each b-value and in the second stage, those probabilities are fused and fed into the prediction stage SNCAE to calculate the final classification. Preliminary experiments on 53 clinical DW-MRI datasets resulted in \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$98.11\,\%$$\end{document} correct classification (sensitivity \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$=96.15\,\%$$\end{document} and specificity = \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$100\,\%$$\end{document}), indicating the high performance of the proposed CAD system and holding promise of the proposed system as a reliable non-invasive diagnostic tool.",,,Lecture Notes in Computer Science,Medical Image Computing and Computer-Assisted Intervention – MICCAI 2016,,2016-10-02,2016,2016-10-02,2016,9900,,610-618,Closed,Chapter,"Reda, Islam; Shalaby, Ahmed; Elmogy, Mohammed; Aboulfotouh, Ahmed; Khalifa, Fahmi; El-Ghar, Mohamed Abou; Gimelfarb, Georgy; El-Baz, Ayman","Reda, Islam (Faculty of Computers and Information, Mansoura University, Mansoura, Egypt; Bioengineering Department, University of Louisville, 40292, Louisville, KY, USA); Shalaby, Ahmed (Bioengineering Department, University of Louisville, 40292, Louisville, KY, USA); Elmogy, Mohammed (Faculty of Computers and Information, Mansoura University, Mansoura, Egypt); Aboulfotouh, Ahmed (Faculty of Computers and Information, Mansoura University, Mansoura, Egypt); Khalifa, Fahmi (Bioengineering Department, University of Louisville, 40292, Louisville, KY, USA); El-Ghar, Mohamed Abou (Radiology Department, Urology and Nephrology Center, University of Mansoura, Mansoura, Egypt); Gimelfarb, Georgy (Department of Computer Science, University of Auckland, Auckland, New Zealand); El-Baz, Ayman (Bioengineering Department, University of Louisville, 40292, Louisville, KY, USA)","El-Baz, Ayman (University of Louisville)","Reda, Islam (Mansoura University; University of Louisville); Shalaby, Ahmed (University of Louisville); Elmogy, Mohammed (Mansoura University); Aboulfotouh, Ahmed (Mansoura University); Khalifa, Fahmi (University of Louisville); El-Ghar, Mohamed Abou (Mansoura University); Gimelfarb, Georgy (University of Auckland); El-Baz, Ayman (University of Louisville)",8,0,,,,https://app.dimensions.ai/details/publication/pub.1084900082,46 Information and Computing Sciences,
1649,pub.1092014987,10.1007/978-3-319-61786-2_4,,,PI-RADS v2: Reading Model,"Multiparametric MRI (mpMRI) is the method of choice to evaluate the prostate for clinically significant adenocarcinoma. The widespread implementation and acceptance of mpMRI requires a standardization of image acquisition, interpretation, and reporting to achieve an optimal test for daily practice on the work-up of prostate cancer (PCa).",,,,Atlas of Multiparametric Prostate MRI,,2017-07-13,2017,2017-07-13,2018,,,53-76,Closed,Chapter,"Vilanova, Joan C.; Catalá, Violeta; García-Figueiras, Roberto; Boada, Maria","Vilanova, Joan C. (Department of Radiology, Clínica Girona, Institute Catalan of Health-IDI, University of Girona, Lorenzana 36, 17002, Girona, Spain); Catalá, Violeta (Department of Radiology, Fundació Puigvert, Cartagena 340, 08005, Barcelona, Spain); García-Figueiras, Roberto (Department of Radiology, Hospital Clínico Universitario de Santiago de Compostela (CHUS), 15706, Santiago de Compostela, A Coruña, Spain); Boada, Maria (Department of Radiology, Clínica Girona, Lorenzana 36, 17002, Girona, Spain)","Vilanova, Joan C. (University of Girona)","Vilanova, Joan C. (University of Girona); Catalá, Violeta (Puigvert Foundation); García-Figueiras, Roberto (USC University Hospital Complex); Boada, Maria (Clínica Girona)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1092014987,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1644,pub.1095087116,10.1109/icmla.2016.0032,,,Bag of Bags: Nested Multi Instance Classification for Prostate Cancer Detection,"Computer-aided detection (CAD) algorithms have been proposed for auto-detection of different types of cancer. CAD algorithms rely on machine learning methods to classify regions of interest in images into cancerous and healthy regions. In cancer screening, the foremost problem to solve is whether a patient has cancer, regardless of the location of cancerous regions in the organ. This allows early detection of the disease leading to a right course of action in terms of treatment to be taken. In machine learning, this problem has been formulated as multi-instance learning (MIL) where bags of instances are classified rather than the individual instances. In this paper, we propose a bag of bags (BoB) nested MIL algorithm where high-level bags (or parent bags), each contains multiple smaller bags of instances. We applied the proposed BoB MIL algorithm to prostate cancer detection problem using magnetic resonance imaging data to first detect which patients have cancer and consequently, to detect which slices in the 3D volume imaging data of the detected patients contain cancerous regions. Experimental results obtained from the imaging data of 30 patients with ground-truth data based on biopsy results show that the proposed algorithm is not only capable of detecting prostate cancer at patient level, it is also able to detect the cancerous regions at slice level of imaging data with high accuracy.",,,,2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA),,2016-12-01,2016,,2016-12-01,,,146-151,Closed,Proceeding,"Khalvati, Farzad; Zhang, Junjie; Wong, Alexander; Haider, Masoom A.","Khalvati, Farzad (Department of Medical Imaging, University of Toronto and Sunnybrook Research Institute, Toronto, Ontario, Canada, M4N 3M5); Zhang, Junjie (Department of Medical Imaging, University of Toronto and Sunnybrook Research Institute, Toronto, Ontario, Canada, M4N 3M5); Wong, Alexander (Department of Systems Design Engineering, University of Waterloo, Waterloo, Ontario, Canada, N2L 3G1); Haider, Masoom A. (Department of Medical Imaging, University of Toronto and Sunnybrook Research Institute, Toronto, Ontario, Canada, M4N 3M5)",,"Khalvati, Farzad (University of Toronto); Zhang, Junjie (University of Toronto); Wong, Alexander (University of Waterloo); Haider, Masoom A. (University of Toronto)",3,2,,0.7,,https://app.dimensions.ai/details/publication/pub.1095087116,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences,
1643,pub.1151124918,10.1007/978-3-031-16852-9_6,,,Unsupervised Site Adaptation by Intra-site Variability Alignment,"A medical imaging network that was trained on a particular source domain usually suffers significant performance degradation when transferred to a different target domain. This is known as the domain-shift problem. In this study, we propose a general method for transfer knowledge from a source site with labeled data to a target site where only unlabeled data is available. We leverage the variability that is often present within each site, the intra-site variability, and propose an unsupervised site adaptation method that jointly aligns the intra-site data variability in the source and target sites while training the network on the labeled source site data. We applied our method to several medical MRI image segmentation tasks and show that it consistently outperforms state-of-the-art methods.",,,Lecture Notes in Computer Science,Domain Adaptation and Representation Transfer,,2022-09-15,2022,2022-09-15,2022,13542,,56-65,Closed,Chapter,"Goodman, Shaya; Kasten Serlin, Shira; Greenspan, Hayit; Goldberger, Jacob","Goodman, Shaya (Tel-Aviv University, Tel-Aviv, Israel); Kasten Serlin, Shira (Tel-Aviv University, Tel-Aviv, Israel); Greenspan, Hayit (Tel-Aviv University, Tel-Aviv, Israel); Goldberger, Jacob (Bar-Ilan University, Ramat-Gan, Israel)","Goldberger, Jacob (Bar-Ilan University)","Goodman, Shaya (Tel Aviv University); Kasten Serlin, Shira (Tel Aviv University); Greenspan, Hayit (Tel Aviv University); Goldberger, Jacob (Bar-Ilan University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1151124918,46 Information and Computing Sciences; 4611 Machine Learning,
1642,pub.1151124915,10.1007/978-3-031-16852-9_3,,,Supervised Domain Adaptation Using Gradients Transfer for Improved Medical Image Analysis,"A well known problem in medical imaging is the performance degradation that occurs when using a model learned on source data, in a new site. Supervised Domain Adaptation (SDA) strategies that focus on this challenge, assume the availability of a limited number of annotated samples from the new site. A typical SDA approach is to pre-train the model on the source site and then fine-tune on the target site. Current research has thus mainly focused on which layers should be fine-tuned. Our approach is based on transferring also the gradients history of the pre-training phase to the fine-tuning phase. We present two schemes to transfer the gradients information to improve the generalization achieved during pre-training while fine-tuning the model. We show that our methods outperform the state-of-the-art with different levels of data scarcity from the target site, on multiple datasets and tasks.",,,Lecture Notes in Computer Science,Domain Adaptation and Representation Transfer,,2022-09-15,2022,2022-09-15,2022,13542,,23-32,Closed,Chapter,"Goodman, Shaya; Greenspan, Hayit; Goldberger, Jacob","Goodman, Shaya (Tel-Aviv University, Tel-Aviv, Israel); Greenspan, Hayit (Tel-Aviv University, Tel-Aviv, Israel); Goldberger, Jacob (Bar-Ilan University, Ramat-Gan, Israel)","Goldberger, Jacob (Bar-Ilan University)","Goodman, Shaya (Tel Aviv University); Greenspan, Hayit (Tel Aviv University); Goldberger, Jacob (Bar-Ilan University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1151124915,46 Information and Computing Sciences; 4611 Machine Learning,
1642,pub.1086149794,10.1007/978-3-319-60964-5_27,,,3D Texton Based Prostate Cancer Detection Using Multiparametric Magnetic Resonance Imaging,"Multiparametric magnetic resonance imaging (mp-MRI) has shown its potential in prostate cancer detection. In this study, we investigate the application of 3D texton based prostate cancer detection using T2-weighted (T2W) MRI, dynamic contrast-enhanced (DCE) MRI and apparent diffusion coefficient (ADC) maps. For the T2W and ADC modalities, the traditional texton based approach is adopted, i.e., for each voxel, a texton histogram is extracted as the feature to perform the classification. For the DCE data, we present a new method, where the textons are extracted from each series and for each voxel, the corresponding textons across all series are used as features. A random forest classifier is applied for classifying all voxels into benign or malignant. The evaluation is conducted by performing a receiver operating characteristics (ROC) analysis and computing the area under the curve (AUC). The experiments on the Initiative for Collaborative Computer Vision Benchmarking (I2CVB) database demonstrate that the texton based approach using mp-MRI data obtains excellent performance in prostate cancer detection and produces \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$88.3\%$$\end{document} accuracy, whereas the accuracy produced by an intensity based approach is \documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$79.8\%$$\end{document}.",,,Communications in Computer and Information Science,Medical Image Understanding and Analysis,,2017-06-22,2017,2017-06-22,2017,723,,309-319,Closed,Chapter,"Wang, Liping; Zwiggelaar, Reyer","Wang, Liping (Department of Computer Science, Aberystwyth University, SY23 3DB, Aberystwyth, UK); Zwiggelaar, Reyer (Department of Computer Science, Aberystwyth University, SY23 3DB, Aberystwyth, UK)","Wang, Liping (Aberystwyth University)","Wang, Liping (Aberystwyth University); Zwiggelaar, Reyer (Aberystwyth University)",3,1,,0.75,,https://app.dimensions.ai/details/publication/pub.1086149794,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences,
1640,pub.1151072657,10.1007/978-3-031-16446-0_46,,,Weakly Supervised MR-TRUS Image Synthesis for Brachytherapy of Prostate Cancer,"Prostate magnetic resonance imaging (MRI) offers accurate details of structures and tumors for prostate cancer brachytherapy. However, it is unsuitable for routine treatment since MR images differ significantly from trans-rectal ultrasound (TRUS) images conventionally used for radioactive seed implants in brachytherapy. TRUS imaging is fast, convenient, and widely available in the operation room but is known for its low soft-tissue contrast and tumor visualization capability in the prostate area. Conventionally, practitioners usually rely on prostate segmentation to fuse the two imaging modalities with non-rigid registration. However, prostate delineation is often not available on diagnostic MR images. Besides, the high non-linear intensity relationship between two imaging modalities poses a challenge to non-rigid registration. Hence, we propose a method to generate a TRUS-styled image from a prostate MR image to replace the role of the TRUS image in radiation therapy dose pre-planning. We propose a structural constraint to handle non-linear projections of anatomical structures between MR and TRUS images. We further include an adversarial mechanism to enforce the model to preserve anatomical features in an MR image (such as prostate boundary and dominant intraprostatic lesion (DIL)) while synthesizing the TRUS-styled counterpart image. The proposed method is compared with other state-of-art methods with real TRUS images as the reference. The results demonstrate that the TRUS images synthesized by our method can be used for brachytherapy treatment planning for prostate cancer.",This work was supported in part by NIH grant CA206100. Yunzhi Huang was in part supported by the National Natural Science Foundation of China under Grant No. 62101365 and the startup foundation of Nanjing University of Information Science and Technology.,,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2022,,2022-09-17,2022,2022-09-17,2022,13436,,485-494,Closed,Chapter,"Pang, Yunkui; Chen, Xu; Huang, Yunzhi; Yap, Pew-Thian; Lian, Jun","Pang, Yunkui (University of North Carolina, 27599, Chapel Hill, NC, USA); Chen, Xu (College of Computer Science and Technology, Huaqiao University, 361021, Xiamen, China); Huang, Yunzhi (School of Automation, Nanjing University of Information Science and Technology, 210044, Nanjing, China); Yap, Pew-Thian (University of North Carolina, 27599, Chapel Hill, NC, USA); Lian, Jun (University of North Carolina, 27599, Chapel Hill, NC, USA)","Lian, Jun (University of North Carolina System)","Pang, Yunkui (University of North Carolina System); Chen, Xu (Huaqiao University); Huang, Yunzhi (Nanjing University of Information Science and Technology); Yap, Pew-Thian (University of North Carolina System); Lian, Jun (University of North Carolina System)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151072657,46 Information and Computing Sciences,
1640,pub.1112234854,10.1109/isspit.2018.8642689,,,A Computer-Aided System for Prostate Cancer Diagnosis,"In this paper, a computer-aided diagnosis (CAD) system for early diagnosis of prostate cancer from diffusion weighted magnetic resonance imaging (DWI) is proposed. The proposed system begins with defining a region of interest that contains the prostate across the various slices of the input volume. Then, the apparent diffusion coefficient (ADC) of the defined region is calculated, normalized and refined. Finally, the classification of prostate into either benign or malignant is performed through two stages. In the first stage, seven convolutional neural networks (CNNs) are utilized to get initial probabilities for each case. Then, a random forest (RF) classifier uses these probabilities as input to decide the final diagnosis. The proposed system is a novel system in the sense that it has the ability to detect prostate cancer without any prior processing (e.g., the segmentation of the prostate region). Evaluation of the developed system is done using DWI datasets collected at seven different b-values from 32 patients (16 benign and 16 malignant). The acquisition of these DWI datasets is performed using two different scanners with different magnetic field strengths (1.5 Tesla and 3 Tesla). The resulting accuracy of the proposed system after the second stage of classification shows a good performance close to the performance of up-to-date systems.",,,,2018 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT),,2018-12-08,2018,,2018-12-08,00,,465-469,Closed,Proceeding,"Reda, Islam; Ghazal, Mohammed; Shalaby, Ahmed; Elmogy, Mohammed; Aboulfotouh, Ahmed; El-Ghar, Mohamed Abou; Elmaghraby, Adel; Keynton, Robert; El-Baz, Ayman","Reda, Islam (Bioengineering Department, University of Louisville, KY, USA); Ghazal, Mohammed (Electrical and Computer Engineering Department, Abu Dhabi University, UAE); Shalaby, Ahmed (Bioengineering Department, University of Louisville, KY, USA); Elmogy, Mohammed (Bioengineering Department, University of Louisville, KY, USA); Aboulfotouh, Ahmed (Faculty of Computers and Information, Mansoura University, Egypt); El-Ghar, Mohamed Abou (Radiology Department, Urology and Nephrology Center, University of Mansoura, Egypt); Elmaghraby, Adel (Department of Computer Engineering and Computer Science, University of Louisville, KY, USA); Keynton, Robert (Bioengineering Department, University of Louisville, KY, USA); El-Baz, Ayman (Bioengineering Department, University of Louisville, KY, USA)","Reda, Islam (University of Louisville)","Reda, Islam (University of Louisville); Ghazal, Mohammed (Abu Dhabi University); Shalaby, Ahmed (University of Louisville); Elmogy, Mohammed (University of Louisville); Aboulfotouh, Ahmed (Mansoura University); El-Ghar, Mohamed Abou (Mansoura University); Elmaghraby, Adel (University of Louisville); Keynton, Robert (University of Louisville); El-Baz, Ayman (University of Louisville)",1,0,,0.29,,https://app.dimensions.ai/details/publication/pub.1112234854,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences,
1584,pub.1150816281,10.48550/arxiv.2209.01300,,,Source-Free Unsupervised Domain Adaptation with Norm and Shape  Constraints for Medical Image Segmentation,"Unsupervised domain adaptation (UDA) is one of the key technologies to solve
a problem where it is hard to obtain ground truth labels needed for supervised
learning. In general, UDA assumes that all samples from source and target
domains are available during the training process. However, this is not a
realistic assumption under applications where data privacy issues are
concerned. To overcome this limitation, UDA without source data, referred to
source-free unsupervised domain adaptation (SFUDA) has been recently proposed.
Here, we propose a SFUDA method for medical image segmentation. In addition to
the entropy minimization method, which is commonly used in UDA, we introduce a
loss function for avoiding feature norms in the target domain small and a prior
to preserve shape constraints of the target organ. We conduct experiments using
datasets including multiple types of source-target domain combinations in order
to show the versatility and robustness of our method. We confirm that our
method outperforms the state-of-the-art in all datasets.",,,arXiv,,,2022-09-02,2022,,,,,,All OA; Green,Preprint,"Kondo, Satoshi","Kondo, Satoshi ()",,"Kondo, Satoshi ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150816281,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1578,pub.1128417664,10.1016/j.matpr.2020.05.023,,,Survey of denoising and segmentation techniques for MRI images of prostate for improving diagnostic tools in medical applications,"Prostate cancer (PCa) is one of the deadliest cancers in men after lung cancer, thus its early detection remains a great concern to reduce the rate of mortality. Thetraditional approaches used for detection were manual, time consuming and prone to subjective errors. Magnetic resonance imaging (MRI) is the commonly used imaging modality for PCa, as it produces detailed and smooth images of the prostate gland in comparison to other modalities using a large magnet and radio waves in the MRI scanner. Computer aided diagnosis (CAD) systems can increase the overall accuracy of traditional approaches by detecting the cancer in the prostate gland using MRI. CADs mainly consist of three stages i.e. denoising, segmentation, and classification. Denoising is an approach to remove the noise present in MRI for better performance of segmentation and classification. Whereas, segmentation is the extraction of desired regions of interest i.e. prostate for further classification as malignant or benign. This paper presents a survey of various denoising and segmentation approaches used for detection of prostate cancer using MRI and the analysis presented in this study could be used for improving performance of diagnostic tools for medical purposes.",,,Materials Today Proceedings,,,2020,2020,,2020,28,,1667-1672,Closed,Article,"Gupta, Jatin; Saini, Sumindar Kaur; Juneja, Mamta","Gupta, Jatin (Computer Science and Engineering. University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Saini, Sumindar Kaur (Computer Science and Engineering. University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Juneja, Mamta (Computer Science and Engineering. University Institute of Engineering and Technology, Panjab University, Chandigarh, India)","Juneja, Mamta (Panjab University)","Gupta, Jatin (Panjab University); Saini, Sumindar Kaur (Panjab University); Juneja, Mamta (Panjab University)",5,5,,0.84,,https://app.dimensions.ai/details/publication/pub.1128417664,40 Engineering; 4016 Materials Engineering,
1578,pub.1086115224,10.1007/978-3-319-59126-1_14,,,Computer Aided Detection of Prostate Cancer on Biparametric MRI Using a Quadratic Discriminant Model,"This paper presents a computer-aided detection (CAD) algorithm for detection of prostate cancer (PCa) in biparametric magnetic resonance imaging (bpMRI). Using image intensity, gradient and gradient direction from T2-weighted (T2W), diffusion weighted imaging (DWI) and apparent diffusion coefficient (ADC) MRI series, together with a distance feature, a quadratic discriminant analysis (QDA) model was evaluated in 18 patients. A 3D probability map was created for each patient and the number of true- and false positive tumors was determined. Visual assessment showed that for the majority of patients, highest tumor probability was found within the expert annotated volume. The algorithm successfully located 21 of 22 tumors with 0 to 4 false positive per patient. However, the algorithm had a tendency of under-estimating the tumor volume compared to the expert. The study suggests that features extracted from bpMRI can be used for automatic detection of PCa with performance comparable to existing CAD algorithms.",,,Lecture Notes in Computer Science,Image Analysis,,2017-05-19,2017,2017-05-19,2017,10269,,161-171,Closed,Chapter,"Jensen, Carina; Korsager, Anne Sofie; Boesen, Lars; Østergaard, Lasse Riis; Carl, Jesper","Jensen, Carina (Department of Medical Physics, Oncology, Aalborg Hospital, 9000, Aalborg, Denmark); Korsager, Anne Sofie (Department of Health Science and Technology, Aalborg University, 9000, Aalborg, Denmark); Boesen, Lars (Department of Urology, Herlev University Hospital, 2730, Herlev, Denmark); Østergaard, Lasse Riis (Department of Health Science and Technology, Aalborg University, 9000, Aalborg, Denmark); Carl, Jesper (Department of Medical Physics, Oncology, Aalborg Hospital, 9000, Aalborg, Denmark; Department of Clinical Medicine, Aalborg University, 9000, Aalborg, Denmark)","Jensen, Carina (Aalborg University Hospital)","Jensen, Carina (Aalborg University Hospital); Korsager, Anne Sofie (Aalborg University); Boesen, Lars (Herlev Hospital); Østergaard, Lasse Riis (Aalborg University); Carl, Jesper (Aalborg University Hospital; Aalborg University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1086115224,46 Information and Computing Sciences,
1578,pub.1154886846,10.1109/bigdata55660.2022.10020468,,,ACL-Net: Adaptive and Collaborative Learning Network for Multi-Site Prostate MRI Segmentation,"High-performance deep learning models require large amounts of data with high quality annotations for model training, while the labeling work usually takes a lot of time for the experts. Meanwhile, the inter-observer variability al-ways exist between annotations from different experts and the distribution shift between the data acquired from different medical institutions. To address these challenges, we propose an end-to-end domain adaptive collaborative learning network for multi-institutional prostate MRI segmentation. Specifically, we introduce an unpaired image translation module to match the image domains between different institutions, which can alleviate the heterogeneity between 1.5T and 3T prostate MR images during model training. Moreover, we design a self-taught strategy to transfer domain-aware knowledge to jointly learn generic and unique representations. Furthermore, we evaluate our approach in scenarios with limited or without annotations, experimental results show that our approach has better adaptation performance than traditional supervised learning approaches, and has the potential to extend to unsupervised domain adaptation scenario. We also evaluate our approach with prostate MRI segmentation benchmark datasets, experimental results show that our approach outperforms several state-of-the-art methods.",,,,2022 IEEE International Conference on Big Data (Big Data),,2022-12-20,2022,,2022-12-20,00,,3112-3117,Closed,Proceeding,"Ma, Zibo; Zhang, Bo; Zhang, Zheng; Wang, Wendong; Mi, Yue; Huang, Haiwen; Wu, Jingyun","Ma, Zibo (Beijing University of Posts and Telecommunications, Beijing, 100876, China; State Key Laboratory of Networking and Switching Technology, School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications); Zhang, Bo (Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Modern Post, Beijing University of Posts and Telecommunications); Zhang, Zheng (Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Modern Post, Beijing University of Posts and Telecommunications); Wang, Wendong (State Key Laboratory of Networking and Switching Technology, School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications, Beijing, 100876, China); Mi, Yue (Peking University First Hospital, Beijing, 100034, China; Department of Urology, Peking University First Hospital); Huang, Haiwen (Department of Urology, Peking University First Hospital; Peking University First Hospital, Beijing, 100034, China); Wu, Jingyun (Peking University First Hospital, Beijing, 100034, China; Department of Radiology, Peking University First Hospital)","Ma, Zibo (Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications); Zhang, Bo (Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications)","Ma, Zibo (Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications); Zhang, Bo (Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications); Zhang, Zheng (Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications); Wang, Wendong (Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications); Mi, Yue (Peking University First Hospital); Huang, Haiwen (Peking University First Hospital); Wu, Jingyun (Peking University First Hospital)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154886846,46 Information and Computing Sciences; 4611 Machine Learning,
1578,pub.1141301972,10.1007/978-3-030-87193-2_37,,,Comprehensive Importance-Based Selective Regularization for Continual Segmentation Across Multiple Sites,"In clinical practice, a desirable medical image segmentation model should be able to learn from sequential training data from multiple sites, as collecting these data together could be difficult due to the storage cost and privacy restriction. However, existing methods often suffer from catastrophic forgetting problem for previous sites when learning from images from a new site. In this paper, we propose a novel comprehensive importance-based selective regularization method for continual segmentation, aiming to mitigate model forgetting by maintaining both shape and reliable semantic knowledge for previous sites. Specifically, we define a comprehensive importance weight for each model parameter, which consists of shape-aware importance and uncertainty-guided semantics-aware importance, by measuring how a segmentation’s shape and reliable semantic information is sensitive to the parameter. When training model on a new site, we adopt a selective regularization scheme that penalizes changes of parameters with high comprehensive importance, avoiding the shape knowledge and reliable semantics related to previous sites being forgotten. We evaluate our method on prostate MRI data sequentially acquired from six institutes. Results show that our method outperforms many continual learning methods for relieving model forgetting issue. Code is available at https://github.com/jingyzhang/CISR.","This research is partially supported by the National Key research and development program (No. 2016YFC0106200), Beijing Natural Science Foundation-Haidian Original Innovation Collaborative Fund (No. L192006), and the funding from Institute of Medical Robotics of Shanghai Jiao Tong University as well as the 863 national research fund (No. 2015AA043203).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2021,,2021-09-21,2021,2021-09-21,2021,12901,,389-399,Closed,Chapter,"Zhang, Jingyang; Gu, Ran; Wang, Guotai; Gu, Lixu","Zhang, Jingyang (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; SenseTime Research, Shanghai, China); Gu, Ran (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; SenseTime Research, Shanghai, China); Wang, Guotai (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China); Gu, Lixu (School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; SenseTime Research, Shanghai, China)","Gu, Lixu (Shanghai Jiao Tong University; Shanghai Jiao Tong University; )","Zhang, Jingyang (Shanghai Jiao Tong University; Shanghai Jiao Tong University); Gu, Ran (University of Electronic Science and Technology of China); Wang, Guotai (University of Electronic Science and Technology of China); Gu, Lixu (Shanghai Jiao Tong University; Shanghai Jiao Tong University)",10,10,,8.18,,https://app.dimensions.ai/details/publication/pub.1141301972,46 Information and Computing Sciences; 4611 Machine Learning,
1577,pub.1149408186,10.1016/j.fpurol.2022.06.002,,,Utilisation de l’intelligence artificielle pour l’interprétation de l’IRM prostatique : où en sommes-nous ?,"Bien que l’IRM se soit imposée dans le diagnostic précoce du cancer de prostate, ses performances restent limitées par sa faible spécificité et sa variabilité interlecteur substantielle. Les progrès récents des techniques d’Intelligence Artificielle en imagerie médicale font espérer que l’analyse automatique des IRM de prostate puisse améliorer la fiabilité et la robustesse de la détection des foyers tumoraux. Cependant, malgré une recherche très active, peu d’algorithmes ont pour l’instant montré des résultats robustes sur des cohortes externes, que ce soit en solution indépendante ou en tant que « second lecteur ». Les principaux défis à résoudre avant le développement clinique de ces algorithmes sont la relative petite taille des bases d’apprentissages et la variabilité des paramètres image en fonction des protocoles d’acquisition, des machines et des constructeurs. Although MRI is widely used for prostate cancer early diagnosis, its performance remains limited by its low specificity and substantial inter-reader variability. Recent advances in Artificial Intelligence techniques in medical imaging give hope that automatic analysis of prostate MRI can improve the reliability and robustness of tumor foci detection. However, despite intensive research, few algorithms have so far shown robust results in external cohorts, either as standalone solutions or as second opinion readers. The main challenges to be solved before the clinical development of these algorithms are the relatively small size of the learning databases and the lack of robustness of image parameters across acquisition protocols, scanners and manufacturers.",,,Progrès en Urologie - FMC,,,2022-09,2022,,2022-09,32,3,f70-f75,Closed,Article,"Rouvière, O.","Rouvière, O. (Hospices civils de Lyon, hôpital Edouard Herriot, service d’imagerie urinaire et vasculaire, Pavillon B, 5, place d’Arsonval, 69003 Lyon, France; Université de Lyon, université Lyon 1, faculté de médecine Lyon Est, Lyon 69003, France)",,"Rouvière, O. (Hôpital Édouard-Herriot; University of Lyon System)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149408186,,
1577,pub.1119394934,10.48550/arxiv.1903.12571,,,CNN-based Prostate Zonal Segmentation on T2-weighted MR Images: A  Cross-dataset Study,"Prostate cancer is the most common cancer among US men. However, prostate
imaging is still challenging despite the advances in multi-parametric Magnetic
Resonance Imaging (MRI), which provides both morphologic and functional
information pertaining to the pathological regions. Along with whole prostate
gland segmentation, distinguishing between the Central Gland (CG) and
Peripheral Zone (PZ) can guide towards differential diagnosis, since the
frequency and severity of tumors differ in these regions; however, their
boundary is often weak and fuzzy. This work presents a preliminary study on
Deep Learning to automatically delineate the CG and PZ, aiming at evaluating
the generalization ability of Convolutional Neural Networks (CNNs) on two
multi-centric MRI prostate datasets. Especially, we compared three CNN-based
architectures: SegNet, U-Net, and pix2pix. In such a context, the segmentation
performances achieved with/without pre-training were compared in 4-fold
cross-validation. In general, U-Net outperforms the other methods, especially
when training and testing are performed on multiple datasets.",,,arXiv,,,2019-03-29,2019,,,,,,All OA; Green,Preprint,"Rundo, Leonardo; Han, Changhee; Zhang, Jin; Hataya, Ryuichiro; Nagano, Yudai; Militello, Carmelo; Ferretti, Claudio; Nobile, Marco S.; Tangherloni, Andrea; Gilardi, Maria Carla; Vitabile, Salvatore; Nakayama, Hideki; Mauri, Giancarlo","Rundo, Leonardo (); Han, Changhee (); Zhang, Jin (); Hataya, Ryuichiro (); Nagano, Yudai (); Militello, Carmelo (); Ferretti, Claudio (); Nobile, Marco S. (); Tangherloni, Andrea (); Gilardi, Maria Carla (); Vitabile, Salvatore (); Nakayama, Hideki (); Mauri, Giancarlo ()",,"Rundo, Leonardo (); Han, Changhee (); Zhang, Jin (); Hataya, Ryuichiro (); Nagano, Yudai (); Militello, Carmelo (); Ferretti, Claudio (); Nobile, Marco S. (); Tangherloni, Andrea (); Gilardi, Maria Carla (); Vitabile, Salvatore (); Nakayama, Hideki (); Mauri, Giancarlo ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119394934,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1576,pub.1151032985,10.1007/978-3-031-16443-9_15,,,MaxStyle: Adversarial Style Composition for Robust Medical Image Segmentation,"Convolutional neural networks (CNNs) have achieved remarkable segmentation accuracy on benchmark datasets where training and test sets are from the same domain, yet their performance can degrade significantly on unseen domains, which hinders the deployment of CNNs in many clinical scenarios. Most existing works improve model out-of-domain (OOD) robustness by collecting multi-domain datasets for training, which is expensive and may not always be feasible due to privacy and logistical issues. In this work, we focus on improving model robustness using a single-domain dataset only. We propose a novel data augmentation framework called MaxStyle, which maximizes the effectiveness of style augmentation for model OOD performance. It attaches an auxiliary style-augmented image decoder to a segmentation network for robust feature learning and data augmentation. Importantly, MaxStyle augments data with improved image style diversity and hardness, by expanding the style space with noise and searching for the worst-case style composition of latent features via adversarial training. With extensive experiments on multiple public cardiac and prostate MR datasets, we demonstrate that MaxStyle leads to significantly improved out-of-distribution robustness against unseen corruptions as well as common distribution shifts across multiple, different, unseen sites and unknown image sequences under both low- and high-training data settings. The code can be found at https://github.com/cherise215/MaxStyle.","This work was supported by two EPSRC Programme Grants (EP/P001009/1, EP/W01842X/1) and the UKRI Innovate UK Grant (No.104691).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2022,,2022-09-16,2022,2022-09-16,2022,13435,,151-161,All OA; Green,Chapter,"Chen, Chen; Li, Zeju; Ouyang, Cheng; Sinclair, Matthew; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Li, Zeju (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Ouyang, Cheng (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Sinclair, Matthew (BioMedIA Group, Department of Computing, Imperial College London, London, UK; HeartFlow, Mountain View, USA); Bai, Wenjia (BioMedIA Group, Department of Computing, Imperial College London, London, UK; Data Science Institute, Imperial College London, London, UK; Department of Brain Sciences, Imperial College London, London, UK); Rueckert, Daniel (BioMedIA Group, Department of Computing, Imperial College London, London, UK; Klinikum rechts der Isar, Technical University of Munich, Munich, Germany)","Chen, Chen (Imperial College London)","Chen, Chen (Imperial College London); Li, Zeju (Imperial College London); Ouyang, Cheng (Imperial College London); Sinclair, Matthew (Imperial College London; HeartFlow (United States)); Bai, Wenjia (Imperial College London; Imperial College London; Imperial College London); Rueckert, Daniel (Imperial College London; Rechts der Isar Hospital; Technical University of Munich)",0,0,,,http://arxiv.org/pdf/2206.01737,https://app.dimensions.ai/details/publication/pub.1151032985,46 Information and Computing Sciences; 4611 Machine Learning,
1576,pub.1094331756,10.1109/memea.2016.7533734,,,Dataset Homogeneity Assessment for a Prostate Cancer CAD System,"Current research in radiology field is increasingly focusing on developing computer aided detection (CAD) systems able to support radiologists in the detection of suspicious regions, reducing oversight, errors and working time. Prostate cancer (PCa) is the most common cancer afflicting men in USA. Multiparametric Magnetic Resonance (mp-MR) imaging is recently emerging as a powerful tool for PCa diagnosis. The development of CAD systems for its automatic processing and elaboration is growing but they can be affected by the variation of the imaging characteristics of PCa depending on its aggressiveness and location. The aim of this study is to characterize the homogeneity of a large set of data derived from mp-MR images, in order to assess the effect on the performances of a CAD system for PCa detection. Firstly, 15 semiquantitative and quantitative features were extracted from malignant and normal region of interest in 60 patients, who underwent mp-MR exam before prostatectomy. Then, we used a clustering procedure based on a Self-Organizing Map (SOM) for grouping patients with similar characteristics from the features point of view. Finally, we evaluated the impact of this partition on the malignant voxel detection by means of a classifier based on a set of SOMs trained and tested using only those patient belonging to the same cluster. We compared these results with those obtained using a unique classifier for all patients. From our analysis it emerged that the image partition in homogeneous groups can effectively improve the final detection performances.","This work was funded by Fondazione Piemontese per la Ricerca sul Cancro FPRC-onlus, grant Pro-Cure, 5 per Mille 2009 Ministero della Salute. This work was funded by Fondazione Piemontese per la Ricerca sul Cancro FPRC-onlus, grant Pro-Cure, 5 per Mille 2009 Ministero della Salute.",,,2016 IEEE International Symposium on Medical Measurements and Applications (MeMeA),,2016-05-01,2016,,2016-05-01,,,1-7,Closed,Proceeding,"Rosati, S.; Giannini, V.; Castagneri, C.; Regge, D.; Balestra, G.","Rosati, S. (Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy); Giannini, V. (Radiology Department, Candiolo Cancer Institute–FPO, IRCCS, Candiolo (To), Italy); Castagneri, C. (Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy); Regge, D. (Radiology Department, Candiolo Cancer Institute–FPO, IRCCS, Candiolo (To), Italy; Department of Surgical Science, University of Torino, A.O.U. Città della Salute e della Scienza, Torino, Italy); Balestra, G. (Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy)",,"Rosati, S. (Polytechnic University of Turin); Giannini, V. (Istituti di Ricovero e Cura a Carattere Scientifico); Castagneri, C. (Polytechnic University of Turin); Regge, D. (Istituti di Ricovero e Cura a Carattere Scientifico; University of Turin); Balestra, G. (Polytechnic University of Turin)",5,1,,1.16,,https://app.dimensions.ai/details/publication/pub.1094331756,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1574,pub.1129039446,10.48550/arxiv.2007.02035,,,Shape-aware Meta-learning for Generalizing Prostate MRI Segmentation to  Unseen Domains,"Model generalization capacity at domain shift (e.g., various imaging
protocols and scanners) is crucial for deep learning methods in real-world
clinical deployment. This paper tackles the challenging problem of domain
generalization, i.e., learning a model from multi-domain source data such that
it can directly generalize to an unseen target domain. We present a novel
shape-aware meta-learning scheme to improve the model generalization in
prostate MRI segmentation. Our learning scheme roots in the gradient-based
meta-learning, by explicitly simulating domain shift with virtual meta-train
and meta-test during training. Importantly, considering the deficiencies
encountered when applying a segmentation model to unseen domains (i.e.,
incomplete shape and ambiguous boundary of the prediction masks), we further
introduce two complementary loss objectives to enhance the meta-optimization,
by particularly encouraging the shape compactness and shape smoothness of the
segmentations under simulated domain shift. We evaluate our method on prostate
MRI data from six different institutions with distribution shifts acquired from
public datasets. Experimental results show that our approach outperforms many
state-of-the-art generalization methods consistently across all six settings of
unseen domains.",,,arXiv,,,2020-07-04,2020,,,,,,All OA; Green,Preprint,"Liu, Quande; Dou, Qi; Heng, Pheng-Ann","Liu, Quande (); Dou, Qi (); Heng, Pheng-Ann ()",,"Liu, Quande (); Dou, Qi (); Heng, Pheng-Ann ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1129039446,"46 Information and Computing Sciences; 4607 Graphics, Augmented Reality and Games; 4611 Machine Learning",
1574,pub.1110721860,10.1109/ist.2018.8577162,,,A New Fast Framework for Early Detection of Prostate Cancer Without Prostate Segmentation,"This paper presents a computer-aided diagnosis (CAD) system for early detection of prostate cancer from diffusion-weighted magnetic resonance imaging (DWI) acquired at six different b-values. Our system starts by defining a region of interest (ROI) that includes the prostate across the different slices of the input DWI volume. Then, the apparent diffusion coefficient (ADC) of the defined ROI is calculated, normalized and refined. Then, the probability density functions (PDFs) of the refined ADC volumes at the distinct b-values are constructed. Finally, the classification of prostate into either benign or malignant is achieved using a classification system of two stages. The proposed system is the first system of its type that has the ability to detect prostate cancer without any prior processing (e.g., the segmentation of the prostate region). Evaluation of the proposed system is done using DWI datasets acquired from 45 patients (20 benign and 25 malignant) at six distinct b-values. The acquisition of these DWI datasets is performed using two different scanners with distinct magnetic field strengths (1.5 Tesla and 3 Tesla). The resulting area under curve (AUC) is 0.77, which shows that the proposed system approaches the state-of-the-art performance without any prior processing.",,,,2018 IEEE International Conference on Imaging Systems and Techniques (IST),,2018-10-18,2018,,2018-10-18,00,,1-5,Closed,Proceeding,"Reda, Islam; Shalaby, Ahmed; Elmogy, Mohammed; Ghazal, Mohammed; Aboulfotouh, Ahmed; El-Ghar, Mohamed Abou; Elmaghraby, Adel; Keynton, Robert; El-Baz, Ayman","Reda, Islam (Faculty of Computers and Information, Mansoura University, Egypt; Bioengineering Department, University of Louisville, KY, USA); Shalaby, Ahmed (Bioengineering Department, University of Louisville, KY, USA); Elmogy, Mohammed (Bioengineering Department, University of Louisville, KY, USA); Ghazal, Mohammed (Electrical and Computer Engineering Department, Abu Dhabi University, UAE); Aboulfotouh, Ahmed (Faculty of Computers and Information, Mansoura University, Egypt); El-Ghar, Mohamed Abou (Radiology Department, Urology and Nephrology Center, University of Mansoura, Mansoura, 35516, Egypt); Elmaghraby, Adel (Department of Computer Engineering and Computer Science, University of Louisville, KY, USA); Keynton, Robert (Bioengineering Department, University of Louisville, KY, USA); El-Baz, Ayman (Faculty of Computers and Information, Mansoura University, Egypt)","Reda, Islam (Mansoura University; University of Louisville)","Reda, Islam (Mansoura University; University of Louisville); Shalaby, Ahmed (University of Louisville); Elmogy, Mohammed (University of Louisville); Ghazal, Mohammed (Abu Dhabi University); Aboulfotouh, Ahmed (Mansoura University); El-Ghar, Mohamed Abou (Mansoura University); Elmaghraby, Adel (University of Louisville); Keynton, Robert (University of Louisville); El-Baz, Ayman (Mansoura University)",5,0,,1.46,,https://app.dimensions.ai/details/publication/pub.1110721860,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1517,pub.1151033009,10.1007/978-3-031-16443-9_37,,,Learning Towards Synchronous Network Memorizability and Generalizability for Continual Segmentation Across Multiple Sites,"In clinical practice, a segmentation network is often required to continually learn on a sequential data stream from multiple sites rather than a consolidated set, due to the storage cost and privacy restriction. However, during the continual learning process, existing methods are usually restricted in either network memorizability on previous sites or generalizability on unseen sites. This paper aims to tackle the challenging problem of Synchronous Memorizability and Generalizability (SMG) and to simultaneously improve performance on both previous and unseen sites, with a novel proposed SMG-learning framework. First, we propose a Synchronous Gradient Alignment (SGA) objective, which not only promotes the network memorizability by enforcing coordinated optimization for a small exemplar set from previous sites (called replay buffer), but also enhances the generalizability by facilitating site-invariance under simulated domain shift. Second, to simplify the optimization of SGA objective, we design a Dual-Meta algorithm that approximates the SGA objective as dual meta-objectives for optimization without expensive computation overhead. Third, for efficient rehearsal, we configure the replay buffer comprehensively considering additional inter-site diversity to reduce redundancy. Experiments on prostate MRI data sequentially acquired from six institutes demonstrate that our method can simultaneously achieve higher memorizability and generalizability over state-of-the-art methods. Code is available at https://github.com/jingyzhang/SMG-Learning.","This work was supported in part by National Natural Science Foundation of China (grant number 62131015), and Science and Technology Commission of Shanghai Municipality (STCSM) (grant number 21010502600).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2022,,2022-09-16,2022,2022-09-16,2022,13435,,380-390,All OA; Green,Chapter,"Zhang, Jingyang; Xue, Peng; Gu, Ran; Gu, Yuning; Liu, Mianxin; Pan, Yongsheng; Cui, Zhiming; Huang, Jiawei; Ma, Lei; Shen, Dinggang","Zhang, Jingyang (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China); Xue, Peng (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China); Gu, Ran (School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China); Gu, Yuning (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China); Liu, Mianxin (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China); Pan, Yongsheng (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China); Cui, Zhiming (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China; Department of Computer Science, The University of Hong Kong, Hong Kong, China); Huang, Jiawei (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China); Ma, Lei (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China); Shen, Dinggang (School of Biomedical Engineering, ShanghaiTech University, Shanghai, China; Shanghai United Imaging Intelligence Co., Ltd., Shanghai, China)","Shen, Dinggang (ShanghaiTech University; )","Zhang, Jingyang (ShanghaiTech University); Xue, Peng (ShanghaiTech University); Gu, Ran (University of Electronic Science and Technology of China); Gu, Yuning (ShanghaiTech University); Liu, Mianxin (ShanghaiTech University); Pan, Yongsheng (ShanghaiTech University); Cui, Zhiming (ShanghaiTech University; University of Hong Kong); Huang, Jiawei (ShanghaiTech University); Ma, Lei (ShanghaiTech University); Shen, Dinggang (ShanghaiTech University)",0,0,,,http://arxiv.org/pdf/2206.06813,https://app.dimensions.ai/details/publication/pub.1151033009,46 Information and Computing Sciences; 4611 Machine Learning,
1517,pub.1148488878,10.48550/arxiv.2206.01737,,,MaxStyle: Adversarial Style Composition for Robust Medical Image  Segmentation,"Convolutional neural networks (CNNs) have achieved remarkable segmentation
accuracy on benchmark datasets where training and test sets are from the same
domain, yet their performance can degrade significantly on unseen domains,
which hinders the deployment of CNNs in many clinical scenarios. Most existing
works improve model out-of-domain (OOD) robustness by collecting multi-domain
datasets for training, which is expensive and may not always be feasible due to
privacy and logistical issues. In this work, we focus on improving model
robustness using a single-domain dataset only. We propose a novel data
augmentation framework called MaxStyle, which maximizes the effectiveness of
style augmentation for model OOD performance. It attaches an auxiliary
style-augmented image decoder to a segmentation network for robust feature
learning and data augmentation. Importantly, MaxStyle augments data with
improved image style diversity and hardness, by expanding the style space with
noise and searching for the worst-case style composition of latent features via
adversarial training. With extensive experiments on multiple public cardiac and
prostate MR datasets, we demonstrate that MaxStyle leads to significantly
improved out-of-distribution robustness against unseen corruptions as well as
common distribution shifts across multiple, different, unseen sites and unknown
image sequences under both low- and high-training data settings. The code can
be found at https://github.com/cherise215/MaxStyle.",,,arXiv,,,2022-06-02,2022,,,,,,All OA; Green,Preprint,"Chen, Chen; Li, Zeju; Ouyang, Cheng; Sinclair, Matt; Bai, Wenjia; Rueckert, Daniel","Chen, Chen (); Li, Zeju (); Ouyang, Cheng (); Sinclair, Matt (); Bai, Wenjia (); Rueckert, Daniel ()",,"Chen, Chen (); Li, Zeju (); Ouyang, Cheng (); Sinclair, Matt (); Bai, Wenjia (); Rueckert, Daniel ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148488878,46 Information and Computing Sciences; 4611 Machine Learning,
1515,pub.1151072754,10.1007/978-3-031-16449-1_66,,,Estimating Model Performance Under Domain Shifts with Class-Specific Confidence Scores,"Machine learning models are typically deployed in a test setting that differs from the training setting, potentially leading to decreased model performance because of domain shift. If we could estimate the performance that a pre-trained model would achieve on data from a specific deployment setting, for example a certain clinic, we could judge whether the model could safely be deployed or if its performance degrades unacceptably on the specific data. Existing approaches estimate this based on the confidence of predictions made on unlabeled test data from the deployment’s domain. We find existing methods struggle with data that present class imbalance, because the methods used to calibrate confidence do not account for bias induced by class imbalance, consequently failing to estimate class-wise accuracy. Here, we introduce class-wise calibration within the framework of performance estimation for imbalanced datasets. Specifically, we derive class-specific modifications of state-of-the-art confidence-based model evaluation methods including temperature scaling (TS), difference of confidences (DoC), and average thresholded confidence (ATC). We also extend the methods to estimate Dice similarity coefficient (DSC) in image segmentation. We conduct experiments on four tasks and find the proposed modifications consistently improve the estimation accuracy for imbalanced datasets. Our methods improve accuracy estimation by 18% in classification under natural domain shifts, and double the estimation accuracy on segmentation tasks, when compared with prior methods (Code is available at https://github.com/ZerojumpLine/ModelEvaluationUnderClassImbalance).","ZL is grateful for a China Scholarship Council (CSC) Imperial Scholarship. This project has received funding from the ERC under the EU’s Horizon 2020 research and innovation programme (grant No 757173) and the UKRI London Medical Imaging &amp; Artificial Intelligence Centre for Value Based Healthcare, and a EPSRC Programme Grant (EP/P001009/1).",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2022,,2022-09-17,2022,2022-09-17,2022,13437,,693-703,All OA; Green,Chapter,"Li, Zeju; Kamnitsas, Konstantinos; Islam, Mobarakol; Chen, Chen; Glocker, Ben","Li, Zeju (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Kamnitsas, Konstantinos (BioMedIA Group, Department of Computing, Imperial College London, London, UK; Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, UK; School of Computer Science, University of Birmingham, Birmingham, UK); Islam, Mobarakol (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Chen, Chen (BioMedIA Group, Department of Computing, Imperial College London, London, UK); Glocker, Ben (BioMedIA Group, Department of Computing, Imperial College London, London, UK)","Li, Zeju (Imperial College London)","Li, Zeju (Imperial College London); Kamnitsas, Konstantinos (Imperial College London; University of Oxford; University of Birmingham); Islam, Mobarakol (Imperial College London); Chen, Chen (Imperial College London); Glocker, Ben (Imperial College London)",0,0,,,http://arxiv.org/pdf/2207.09957,https://app.dimensions.ai/details/publication/pub.1151072754,46 Information and Computing Sciences; 4611 Machine Learning,
1515,pub.1148688697,10.48550/arxiv.2206.06813,,,Learning towards Synchronous Network Memorizability and Generalizability  for Continual Segmentation across Multiple Sites,"In clinical practice, a segmentation network is often required to continually
learn on a sequential data stream from multiple sites rather than a
consolidated set, due to the storage cost and privacy restriction. However,
during the continual learning process, existing methods are usually restricted
in either network memorizability on previous sites or generalizability on
unseen sites. This paper aims to tackle the challenging problem of Synchronous
Memorizability and Generalizability (SMG) and to simultaneously improve
performance on both previous and unseen sites, with a novel proposed
SMG-learning framework. First, we propose a Synchronous Gradient Alignment
(SGA) objective, which not only promotes the network memorizability by
enforcing coordinated optimization for a small exemplar set from previous sites
(called replay buffer), but also enhances the generalizability by facilitating
site-invariance under simulated domain shift. Second, to simplify the
optimization of SGA objective, we design a Dual-Meta algorithm that
approximates the SGA objective as dual meta-objectives for optimization without
expensive computation overhead. Third, for efficient rehearsal, we configure
the replay buffer comprehensively considering additional inter-site diversity
to reduce redundancy. Experiments on prostate MRI data sequentially acquired
from six institutes demonstrate that our method can simultaneously achieve
higher memorizability and generalizability over state-of-the-art methods. Code
is available at https://github.com/jingyzhang/SMG-Learning.",,,arXiv,,,2022-06-14,2022,,,,,,All OA; Green,Preprint,"Zhang, Jingyang; Xue, Peng; Gu, Ran; Gu, Yuning; Liu, Mianxin; Pan, Yongsheng; Cui, Zhiming; Huang, Jiawei; Ma, Lei; Shen, Dinggang","Zhang, Jingyang (); Xue, Peng (); Gu, Ran (); Gu, Yuning (); Liu, Mianxin (); Pan, Yongsheng (); Cui, Zhiming (); Huang, Jiawei (); Ma, Lei (); Shen, Dinggang ()",,"Zhang, Jingyang (); Xue, Peng (); Gu, Ran (); Gu, Yuning (); Liu, Mianxin (); Pan, Yongsheng (); Cui, Zhiming (); Huang, Jiawei (); Ma, Lei (); Shen, Dinggang ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148688697,46 Information and Computing Sciences; 4611 Machine Learning,
1513,pub.1152233846,10.1007/978-3-031-18910-4_12,,,Gradient-Rebalanced Uncertainty Minimization for Cross-Site Adaptation of Medical Image Segmentation,"Automatically adapting image segmentation across data sites benefits to reduce the data annotation burden in medical image analysis. Due to variations in image collection procedures, there usually exists moderate domain gap between medical image datasets from different sites. Increasing the prediction certainty is beneficial for gradually reducing the category-wise domain shift. However, uncertainty minimization naturally leads to bias towards major classes since the target object usually occupies a small portion of pixels in the input image. In this paper, we propose a gradient-rebalanced uncertainty minimization scheme which is capable of eliminating the learning bias. First, the foreground pixels and background pixels are reweighted according to the total gradient amplitude of every class. Furthermore, we devise a feature-level adaptation scheme to reduce the overall domain gap between source and target datasets, based on feature norm regularization and adversarial learning. Experiments on CT pancreas segmentation and MRI prostate segmentation validate that, our method outperforms existing cross-site adaptation algorithms by around 3% on the DICE similarity coefficient.",,,Lecture Notes in Computer Science,Pattern Recognition and Computer Vision,,2022-10-27,2022,2022-10-27,2022,13535,,138-151,Closed,Chapter,"Li, Jiaming; Fang, Chaowei; Li, Guanbin","Li, Jiaming (School of Data and Computer Science, Sun Yet-Sen University, 510006, Guangzhou, China); Fang, Chaowei (School of Artificial Intelligence, Xidian University, 710071, Xi’an, China); Li, Guanbin (School of Data and Computer Science, Sun Yet-Sen University, 510006, Guangzhou, China)","Fang, Chaowei (Xidian University)","Li, Jiaming (Sun Yat-sen University); Fang, Chaowei (Xidian University); Li, Guanbin (Sun Yat-sen University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152233846,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1513,pub.1131399173,10.1007/978-3-030-59713-9_46,,,Shape-Aware Meta-learning for Generalizing Prostate MRI Segmentation to Unseen Domains,"Model generalization capacity at domain shift (e.g., various imaging protocols and scanners) is crucial for deep learning methods in real-world clinical deployment. This paper tackles the challenging problem of domain generalization, i.e., learning a model from multi-domain source data such that it can directly generalize to an unseen target domain. We present a novel shape-aware meta-learning scheme to improve the model generalization in prostate MRI segmentation. Our learning scheme roots in the gradient-based meta-learning, by explicitly simulating domain shift with virtual meta-train and meta-test during training. Importantly, considering the deficiencies encountered when applying a segmentation model to unseen domains (i.e., incomplete shape and ambiguous boundary of the prediction masks), we further introduce two complementary loss objectives to enhance the meta-optimization, by particularly encouraging the shape compactness and shape smoothness of the segmentations under simulated domain shift. We evaluate our method on prostate MRI data from six different institutions with distribution shifts acquired from public datasets. Experimental results show that our approach outperforms many state-of-the-art generalization methods consistently across all six settings of unseen domains (Code and dataset are available at https://github.com/liuquande/SAML).","This work was supported in parts by the following grants: Key-Area Research and Development Program of Guangdong Province, China (2020B010165004), Hong Kong Innovation and Technology Fund (Project No. ITS/426/17FP), Hong Kong RGC TRS Project T42-409/18-R, and National Natural Science Foundation of China with Project No. U1813204.",,Lecture Notes in Computer Science,Medical Image Computing and Computer Assisted Intervention – MICCAI 2020,,2020-09-29,2020,2020-09-29,2020,12262,,475-485,All OA; Green,Chapter,"Liu, Quande; Dou, Qi; Heng, Pheng-Ann","Liu, Quande (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong SAR, China); Dou, Qi (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong SAR, China; T Stone Robotics Institute, The Chinese University of Hong Kong, Shatin, Hong Kong SAR, China); Heng, Pheng-Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong SAR, China; Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China)","Dou, Qi (Chinese University of Hong Kong; Chinese University of Hong Kong)","Liu, Quande (Chinese University of Hong Kong); Dou, Qi (Chinese University of Hong Kong; Chinese University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong; Shenzhen Institutes of Advanced Technology)",67,67,,34.53,http://arxiv.org/pdf/2007.02035,https://app.dimensions.ai/details/publication/pub.1131399173,46 Information and Computing Sciences; 4611 Machine Learning,
1461,pub.1110303625,10.1109/icpr.2018.8546029,,,A Novel ADCs-Based CNN Classification System for Precise Diagnosis of Prostate Cancer,"This paper addresses the issue of early diagnosis of prostate cancer from diffusion-weighted magnetic resonance imaging (DWI) using a convolutional neural network (CNN) based computer-aided diagnosis (CAD) system. The proposed CNN-based CAD system first segments the prostate using a geometric deformable model. The evolution of this model is guided by a stochastic speed function that exploits first-and second-order appearance models besides shape prior. The fusion of these guiding criteria is accomplished using a nonnegative matrix factorization (NMF) model. Then, the apparent diffusion coefficients (ADCs) within the segmented prostate are calculated at each b-value. They are used as imaging markers for the blood diffusion of the scanned prostate. For the purpose of classification/diagnosis, a three dimensional CNN has been trained to extract the most discriminatory features of these ADC maps for distinguishing malignant from benign prostate tumors. The performance of the proposed CNN-based CAD system is evaluated using DWI datasets acquired from 45 patients (20 benign and 25 malignant) at seven different b-values. The acquisition of these DWI datasets is performed using two different scanners with different magnetic field strengths (1.5 Tesla and 3 Tesla). The conducted experiments on in-vivo data confirm that the use of ADCs makes the proposed system nonsensitive to the magnetic field strength.",,,,2018 24th International Conference on Pattern Recognition (ICPR),,2018-08-20,2018,,2018-08-20,00,,3923-3928,Closed,Proceeding,"Reda, Islam; Ghazal, Mohammed; Shalaby, Ahmed; Elmogy, Mohammed; AbouEl-Fetouh, Ahmed; Ayinde, Babajide O.; AbouEl-Ghar, Mohamed; Elmaghraby, Adel; Keynton, Robert; El-Baz, Ayman","Reda, Islam (Faculty of Computers and Information, Mansoura University, Egypt; Bioengineering Department, University of Louisville, KY, USA); Ghazal, Mohammed (Electrical and Computer Engineering Department, Abu Dhabi University, UAE; Bioengineering Department, University of Louisville, KY, USA); Shalaby, Ahmed (Bioengineering Department, University of Louisville, KY, USA); Elmogy, Mohammed (Bioengineering Department, University of Louisville, KY, USA); AbouEl-Fetouh, Ahmed (Faculty of Computers and Information, Mansoura University, Egypt); Ayinde, Babajide O. (Department of Electrical and Computer Engineering, University of Louisville, KY, USA); AbouEl-Ghar, Mohamed (Department of Computer Engineering and Computer Science, University of Louisville, KY, USA); Elmaghraby, Adel (Radiology Department, Urology and Nephrology Center, University of Mansoura, Egypt); Keynton, Robert (Bioengineering Department, University of Louisville, KY, USA); El-Baz, Ayman (Bioengineering Department, University of Louisville, KY, USA)",,"Reda, Islam (Mansoura University; University of Louisville); Ghazal, Mohammed (Abu Dhabi University; University of Louisville); Shalaby, Ahmed (University of Louisville); Elmogy, Mohammed (University of Louisville); AbouEl-Fetouh, Ahmed (Mansoura University); Ayinde, Babajide O. (University of Louisville); AbouEl-Ghar, Mohamed (University of Louisville); Elmaghraby, Adel (Mansoura University); Keynton, Robert (University of Louisville); El-Baz, Ayman (University of Louisville)",16,10,,4.67,,https://app.dimensions.ai/details/publication/pub.1110303625,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
1461,pub.1145276077,10.1007/s11042-022-12102-z,,,Improving classification accuracy for prostate cancer using noise removal filter and deep learning technique,"Prostate Cancer (PCa) can be considered as the second cause of death among men all over the world. Different techniques based on deep learning have been proposed for accurate PCa detection using Magnetic Resonance Imaging (MRI) images. In this research work, an accurate 2d CNN-based Convolutional Neural Network (CNN) model is developed and implemented for PCa binary classification (0 for Benign and 1 for Malignant).The paper is aimed at improving the classification accuracy in two phases. The first one is to use image pre-processing algorithms such as (DICOM to jpg format, image resizing and labeling, adding noise, and noise removal by median filter). The second improvement is achieved by increasing the dataset size. The dataset of 20 patients were used which consist of 15 patients (3249 MRI slices) with cancerous tumor and 3 patients without cancer (1751 MRI slices). To evaluate the performance accuracy of the proposed approach, 30% of the dataset is used for the test and validation while 70% used for the training. The accuracy is found based on the Area under Curve (AUC) of Receiver Operating Characteristic (ROC). Test results indicate that the AUC is 0.98 without pre-processing whereas its value increased to 0.9993 with pre-processing using epoch iteration = 60 and the total dataset images.",,,Multimedia Tools and Applications,,,2022-02-04,2022,2022-02-04,2022-03,81,6,8653-8669,Closed,Article,"Ali, Ari M.; Mohammed, Aree A.","Ali, Ari M. (Department of Information Technology, Technical College of Informatics, Sulaimani Polytechnic University, KRG, Sulaimani, Iraq); Mohammed, Aree A. (Computer Science Department, College of Science, University of Sulaimani, Sulaimani, KRG, Iraq; Computer Science Department, College of Science, University of Halabja, Halabja, KRG, Iraq)","Mohammed, Aree A. (University of Sulaymaniyah; University of Halabja)","Ali, Ari M. (); Mohammed, Aree A. (University of Sulaymaniyah; University of Halabja)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1145276077,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1459,pub.1091380853,10.1007/978-3-319-56904-8_3,,,Fully Automatic Multispectral MR Image Segmentation of Prostate Gland Based on the Fuzzy C-Means Clustering Algorithm,"Prostate imaging is a very critical issue in the clinical practice, especially for diagnosis, therapy, and staging of prostate cancer. Magnetic Resonance Imaging (MRI) can provide both morphologic and complementary functional information of tumor region. Manual detection and segmentation of prostate gland and carcinoma on multispectral MRI data is not easily practicable in the clinical routine because of the long times required by experienced radiologists to analyze several types of imaging data. In this paper, a fully automatic image segmentation method, exploiting an unsupervised Fuzzy C-Means (FCM) clustering technique for multispectral T1-weighted and T2-weighted MRI data processing, is proposed. This approach enables prostate segmentation and automatic gland volume calculation. Segmentation trials have been performed on a dataset composed of 7 patients affected by prostate cancer, using both area-based and distance-based metrics for its evaluation. The achieved experimental results are encouraging, showing good segmentation accuracy.",,,"Smart Innovation, Systems and Technologies",Multidisciplinary Approaches to Neural Computing,,2017-08-30,2017,2017-08-30,2018,69,,23-37,All OA; Green,Chapter,"Rundo, Leonardo; Militello, Carmelo; Russo, Giorgio; D’Urso, Davide; Valastro, Lucia Maria; Garufi, Antonio; Mauri, Giancarlo; Vitabile, Salvatore; Gilardi, Maria Carla","Rundo, Leonardo (Dipartimento di Informatica, Sistemistica e Comunicazione (DISCo), Università degli Studi di Milano-Bicocca, Milan, Italy; Istituto di Bioimmagini e Fisiologia Molecolare - Consiglio Nazionale delle Ricerche (IBFM-CNR), Cefalù (PA), Italy); Militello, Carmelo (Istituto di Bioimmagini e Fisiologia Molecolare - Consiglio Nazionale delle Ricerche (IBFM-CNR), Cefalù (PA), Italy); Russo, Giorgio (Istituto di Bioimmagini e Fisiologia Molecolare - Consiglio Nazionale delle Ricerche (IBFM-CNR), Cefalù (PA), Italy; Azienda Ospedaliera per l’Emergenza Cannizzaro, Catania, Italy; Laboratori Nazionali del Sud (LNS), Istituto Nazionale di Fisica Nucleare (INFN), Catania, Italy); D’Urso, Davide (Istituto di Bioimmagini e Fisiologia Molecolare - Consiglio Nazionale delle Ricerche (IBFM-CNR), Cefalù (PA), Italy; Università degli Studi di Catania, Catania, Italy); Valastro, Lucia Maria (Azienda Ospedaliera per l’Emergenza Cannizzaro, Catania, Italy; Laboratori Nazionali del Sud (LNS), Istituto Nazionale di Fisica Nucleare (INFN), Catania, Italy); Garufi, Antonio (Azienda Ospedaliera per l’Emergenza Cannizzaro, Catania, Italy); Mauri, Giancarlo (Dipartimento di Informatica, Sistemistica e Comunicazione (DISCo), Università degli Studi di Milano-Bicocca, Milan, Italy); Vitabile, Salvatore (Dipartimento di Biopatologia e Biotecnologie Mediche (DIBIMED), Università degli Studi di Palermo, Palermo, Italy); Gilardi, Maria Carla (Istituto di Bioimmagini e Fisiologia Molecolare - Consiglio Nazionale delle Ricerche (IBFM-CNR), Cefalù (PA), Italy)","Rundo, Leonardo (University of Milano-Bicocca; Institute of Molecular Bioimaging and Physiology)","Rundo, Leonardo (University of Milano-Bicocca; Institute of Molecular Bioimaging and Physiology); Militello, Carmelo (Institute of Molecular Bioimaging and Physiology); Russo, Giorgio (Institute of Molecular Bioimaging and Physiology; Laboratori Nazionali del Sud); D’Urso, Davide (Institute of Molecular Bioimaging and Physiology; University of Catania); Valastro, Lucia Maria (Laboratori Nazionali del Sud); Garufi, Antonio (); Mauri, Giancarlo (University of Milano-Bicocca); Vitabile, Salvatore (University of Palermo); Gilardi, Maria Carla (Institute of Molecular Bioimaging and Physiology)",9,3,,2.37,https://media.springer.com/full/springer-instructions-for-authors-assets/pdf/SN_BPF_EN.pdf,https://app.dimensions.ai/details/publication/pub.1091380853,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4605 Data Management and Data Science,
1457,pub.1148451315,10.48550/arxiv.2206.01369,,,Incremental Learning Meets Transfer Learning: Application to Multi-site  Prostate MRI Segmentation,"Many medical datasets have recently been created for medical image
segmentation tasks, and it is natural to question whether we can use them to
sequentially train a single model that (1) performs better on all these
datasets, and (2) generalizes well and transfers better to the unknown target
site domain. Prior works have achieved this goal by jointly training one model
on multi-site datasets, which achieve competitive performance on average but
such methods rely on the assumption about the availability of all training
data, thus limiting its effectiveness in practical deployment. In this paper,
we propose a novel multi-site segmentation framework called
incremental-transfer learning (ITL), which learns a model from multi-site
datasets in an end-to-end sequential fashion. Specifically, ""incremental""
refers to training sequentially constructed datasets, and ""transfer"" is
achieved by leveraging useful information from the linear combination of
embedding features on each dataset. In addition, we introduce our ITL
framework, where we train the network including a site-agnostic encoder with
pre-trained weights and at most two segmentation decoder heads. We also design
a novel site-level incremental loss in order to generalize well on the target
domain. Second, we show for the first time that leveraging our ITL training
scheme is able to alleviate challenging catastrophic forgetting problems in
incremental learning. We conduct experiments using five challenging benchmark
datasets to validate the effectiveness of our incremental-transfer learning
approach. Our approach makes minimal assumptions on computation resources and
domain-specific expertise, and hence constitutes a strong starting point in
multi-site medical image segmentation.",,,arXiv,,,2022-06-02,2022,,,,,,All OA; Green,Preprint,"You, Chenyu; Xiang, Jinlin; Su, Kun; Zhang, Xiaoran; Dong, Siyuan; Onofrey, John; Staib, Lawrence; Duncan, James S.","You, Chenyu (); Xiang, Jinlin (); Su, Kun (); Zhang, Xiaoran (); Dong, Siyuan (); Onofrey, John (); Staib, Lawrence (); Duncan, James S. ()",,"You, Chenyu (); Xiang, Jinlin (); Su, Kun (); Zhang, Xiaoran (); Dong, Siyuan (); Onofrey, John (); Staib, Lawrence (); Duncan, James S. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148451315,46 Information and Computing Sciences; 4611 Machine Learning,
1409,pub.1154178222,10.1109/bibm55620.2022.9995034,,,Invariant Content Synergistic Learning for Domain Generalization on Medical Image Segmentation,"Although deep convolution neural networks (DC-NNs) can achieve remarkable success on medical image segmentation, their performance might significantly deteriorate when confronting testing data with the new distribution. Recent studies suggest that one major cause of this issue is the strong inductive bias of DCNNs, which towards image styles (e.g., superficial texture) that are sensitive to change, instead of the invariant content (e.g., object shapes). Inspired by this, we propose a novel method, named Invariant Content Synergistic Learning (ICSL), to improve the generalization ability of DCNNs on unseen data by controlling the inductive bias. Specifically, ICSL first mixes the style of training instances to perturb the training distribution, so that more diverse domains or styles would be made available for training DCNNs. Then, based on the perturbed distribution, we carefully design a dual-branches invariant content synergistic learning strategy to prevent style-biased predictions and maintain the invariant content. Extensive experimental results demonstrate the superior performance of the proposed method over state-of-the-art domain generalization methods on two typical medical segmentation tasks.","This work is supported by the National Natural Science Foundation of China (NSFC Grant No.62073260 and No.62106198), the Natural Science Foundation of Shaanxi Province of China (2021JQ-461), and the project of Xi’an Science and Technology Bureau (21RGZN0019).","This work is supported by the National Natural Science Foundation of China (NSFC Grant No.62073260 and No.62106198), the Natural Science Foundation of Shaanxi Province of China (2021JQ-461), and the project of Xi’an Science and Technology Bureau (21RGZN0019).",,2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,2022-12-08,2022,,2022-12-08,00,,450-456,All OA; Green,Proceeding,"Kang, Yuxin; Li, Hansheng; Zhao, Xuan; Shi, Xiaoshuang; Liu, Feihong; Yan, Qingguo; Guo, Ying; Cui, Lei; Feng, Jun; Yang, Lin","Kang, Yuxin (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China); Li, Hansheng (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China); Zhao, Xuan (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China); Shi, Xiaoshuang (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China); Liu, Feihong (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China); Yan, Qingguo (School of Medicine, Northwest University, Xi’an, 710069, Shaanxi, China); Guo, Ying (School of Medicine, Northwest University, Xi’an, 710069, Shaanxi, China; Department of Pathology, Xi’an Daxing Hospital, Xi’an, 710082, Shaanxi, China); Cui, Lei (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China); Feng, Jun (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China); Yang, Lin (School of Information Science and Technology, Northwest University, Xi’an, 710127, Shaanxi, China)","Cui, Lei (Northwest University)","Kang, Yuxin (Northwest University); Li, Hansheng (Northwest University); Zhao, Xuan (Northwest University); Shi, Xiaoshuang (Northwest University); Liu, Feihong (Northwest University); Yan, Qingguo (Northwest University); Guo, Ying (Northwest University); Cui, Lei (Northwest University); Feng, Jun (Northwest University); Yang, Lin (Northwest University)",0,0,,,http://arxiv.org/pdf/2205.02845,https://app.dimensions.ai/details/publication/pub.1154178222,46 Information and Computing Sciences; 4611 Machine Learning,
1409,pub.1151694517,10.1007/978-3-031-18523-6_1,,,Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation,"Many medical datasets have recently been created for medical image segmentation tasks, and it is natural to question whether we can use them to sequentially train a single model that (1) performs better on all these datasets, and (2) generalizes well and transfers better to the unknown target site domain. Prior works have achieved this goal by jointly training one model on multi-site datasets, which achieve competitive performance on average but such methods rely on the assumption about the availability of all training data, thus limiting its effectiveness in practical deployment. In this paper, we propose a novel multi-site segmentation framework called incremental-transfer learning (ITL), which learns a model from multi-site datasets in an end-to-end sequential fashion. Specifically, “incremental” refers to training sequentially constructed datasets, and “transfer” is achieved by leveraging useful information from the linear combination of embedding features on each dataset. In addition, we introduce our ITL framework, where we train the network including a site-agnostic encoder with pretrained weights and at most two segmentation decoder heads. We also design a novel site-level incremental loss in order to generalize well on the target domain. Second, we show for the first time that leveraging our ITL training scheme is able to alleviate challenging catastrophic forgetting problems in incremental learning. We conduct experiments using five challenging benchmark datasets to validate the effectiveness of our incremental-transfer learning approach. Our approach makes minimal assumptions on computation resources and domain-specific expertise, and hence constitutes a strong starting point in multi-site medical image segmentation.",,,Lecture Notes in Computer Science,"Distributed, Collaborative, and Federated Learning, and Affordable AI and Healthcare for Resource Diverse Global Health",,2022-10-07,2022,2022-10-07,2022,13573,,3-16,All OA; Green,Chapter,"You, Chenyu; Xiang, Jinlin; Su, Kun; Zhang, Xiaoran; Dong, Siyuan; Onofrey, John; Staib, Lawrence; Duncan, James S.","You, Chenyu (Electrical Engineering, Yale University, New Haven, CT, USA); Xiang, Jinlin (Electrical and Computer Engineering, The University of Washington, WA, USA); Su, Kun (Electrical and Computer Engineering, The University of Washington, WA, USA); Zhang, Xiaoran (Biomedical Engineering, Yale University, New Haven, CT, USA); Dong, Siyuan (Electrical Engineering, Yale University, New Haven, CT, USA); Onofrey, John (Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, CT, USA); Staib, Lawrence (Electrical Engineering, Yale University, New Haven, CT, USA; Biomedical Engineering, Yale University, New Haven, CT, USA; Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, CT, USA); Duncan, James S. (Electrical Engineering, Yale University, New Haven, CT, USA; Biomedical Engineering, Yale University, New Haven, CT, USA; Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, CT, USA)","You, Chenyu (Yale University)","You, Chenyu (Yale University); Xiang, Jinlin (University of Washington); Su, Kun (University of Washington); Zhang, Xiaoran (Yale University); Dong, Siyuan (Yale University); Onofrey, John (Yale University); Staib, Lawrence (Yale University; Yale University; Yale University); Duncan, James S. (Yale University; Yale University; Yale University)",6,6,,,http://arxiv.org/pdf/2206.01369,https://app.dimensions.ai/details/publication/pub.1151694517,46 Information and Computing Sciences; 4611 Machine Learning,
1409,pub.1151124913,10.1007/978-3-031-16852-9_13,,,CateNorm: Categorical Normalization for Robust Medical Image Segmentation,"Batch normalization (BN) uniformly shifts and scales the activations based on the statistics of a batch of images. However, the intensity distribution of the background pixels often dominates the BN statistics because the background accounts for a large proportion of the entire image. This paper focuses on enhancing BN with the intensity distribution of foreground pixels, the one that really matters for image segmentation. We propose a new normalization strategy, named categorical normalization (CateNorm), to normalize the activations according to categorical statistics. The categorical statistics are obtained by dynamically modulating specific regions in an image that belong to the foreground. CateNorm demonstrates both precise and robust segmentation results across five public datasets obtained from different domains, covering complex and variable data distributions. It is attributable to the ability of CateNorm to capture domain-invariant information from multiple domains (institutions) of medical data.Code is available at https://github.com/lambert-x/CateNorm.",This work was supported by the Lustgarten Foundation for Pancreatic Cancer Research. We also thank Quande Liu for the discussion.,,Lecture Notes in Computer Science,Domain Adaptation and Representation Transfer,,2022-09-15,2022,2022-09-15,2022,13542,,129-146,All OA; Green,Chapter,"Xiao, Junfei; Yu, Lequan; Zhou, Zongwei; Bai, Yutong; Xing, Lei; Yuille, Alan; Zhou, Yuyin","Xiao, Junfei (Johns Hopkins University, Baltimore, USA); Yu, Lequan (The University of Hong Kong, Pok Fu Lam, Hong Kong); Zhou, Zongwei (Johns Hopkins University, Baltimore, USA); Bai, Yutong (Johns Hopkins University, Baltimore, USA); Xing, Lei (Stanford University, Stanford, USA); Yuille, Alan (Johns Hopkins University, Baltimore, USA); Zhou, Yuyin (UC Santa Cruz, Santa Cruz, USA)","Xiao, Junfei (Johns Hopkins University)","Xiao, Junfei (Johns Hopkins University); Yu, Lequan (University of Hong Kong); Zhou, Zongwei (Johns Hopkins University); Bai, Yutong (Johns Hopkins University); Xing, Lei (Stanford University); Yuille, Alan (Johns Hopkins University); Zhou, Yuyin (University of California, Santa Cruz)",1,1,,,http://arxiv.org/pdf/2103.15858,https://app.dimensions.ai/details/publication/pub.1151124913,46 Information and Computing Sciences,
1409,pub.1149637704,10.48550/arxiv.2207.09957,,,Estimating Model Performance under Domain Shifts with Class-Specific  Confidence Scores,"Machine learning models are typically deployed in a test setting that differs
from the training setting, potentially leading to decreased model performance
because of domain shift. If we could estimate the performance that a
pre-trained model would achieve on data from a specific deployment setting, for
example a certain clinic, we could judge whether the model could safely be
deployed or if its performance degrades unacceptably on the specific data.
Existing approaches estimate this based on the confidence of predictions made
on unlabeled test data from the deployment's domain. We find existing methods
struggle with data that present class imbalance, because the methods used to
calibrate confidence do not account for bias induced by class imbalance,
consequently failing to estimate class-wise accuracy. Here, we introduce
class-wise calibration within the framework of performance estimation for
imbalanced datasets. Specifically, we derive class-specific modifications of
state-of-the-art confidence-based model evaluation methods including
temperature scaling (TS), difference of confidences (DoC), and average
thresholded confidence (ATC). We also extend the methods to estimate Dice
similarity coefficient (DSC) in image segmentation. We conduct experiments on
four tasks and find the proposed modifications consistently improve the
estimation accuracy for imbalanced datasets. Our methods improve accuracy
estimation by 18\% in classification under natural domain shifts, and double
the estimation accuracy on segmentation tasks, when compared with prior
methods.",,,arXiv,,,2022-07-20,2022,,,,,,All OA; Green,Preprint,"Li, Zeju; Kamnitsas, Konstantinos; Islam, Mobarakol; Chen, Chen; Glocker, Ben","Li, Zeju (); Kamnitsas, Konstantinos (); Islam, Mobarakol (); Chen, Chen (); Glocker, Ben ()",,"Li, Zeju (); Kamnitsas, Konstantinos (); Islam, Mobarakol (); Chen, Chen (); Glocker, Ben ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1149637704,46 Information and Computing Sciences; 4611 Machine Learning,
1406,pub.1144978224,10.1007/s11042-022-11906-3,,,Automatic prostate cancer detection model based on ensemble VGGNet feature generation and NCA feature selection using magnetic resonance images,"Prostate cancer is one of the most common types of cancer in men and its frequency is 28 per hundred thousand in the world. This cancer is detected using Magnetic Resonance Imaging (MRI). By using these images, an automatic prostate cancer diagnosis model must be introduced to simplify diagnosis process. A new MRI image dataset were collected from Firat University Hospital retrospectively. This image corpus contains malign and benign prostate cancer images. A novel transfer learning based model is presented for this dataset. Deep feature generation, feature selection with neighborhood component analysis (NCA) and classification are the primary phases of these model. (i) Deep features of the used prostate MRI images are extracted using VGG16 and VGG19 networks. These networks are pre-trained and they were trained on ImageNet dataset. Three fully connected layers (fc6, fc7 and fc8) of these networks are used to generate features and the generated features are merged. (ii) NCA selects top 500 features and (iii) the features chosen are classified using Cubic k nearest neighbors (kNN) algorithm. By deploying the presented ensemble VGG feature generator and NCA selector based technique, 98.01% accuracy was calculated. Moreover, other widely used performance evaluation metrics and confusion matrices were given to evaluate this model comprehensively. Results and findings obviously denoted the success of the recommended ensemble VGG feature generator and NCA selector based prostate cancer classification model.",,,Multimedia Tools and Applications,,,2022-01-25,2022,2022-01-25,2022-02,81,5,7125-7144,Closed,Article,"Koc, Mustafa; Sut, Suat Kamil; Serhatlioglu, Ihsan; Baygin, Mehmet; Tuncer, Turker","Koc, Mustafa (Department of Radiology, Medical Faculty, Firat University, Elazig, Turkey); Sut, Suat Kamil (Department of Radiology, Medical Faculty, Firat University, Elazig, Turkey); Serhatlioglu, Ihsan (Department of Biophysics, Medical Faculty, Firat University, Elazig, Turkey); Baygin, Mehmet (Department of Computer Engineering, College of Engineering, Ardahan University, Ardahan, Turkey); Tuncer, Turker (Department of Digital Forensics Engineering, College of Technology, Firat University, Elazig, Turkey)","Baygin, Mehmet (Ardahan University)","Koc, Mustafa (Fırat University); Sut, Suat Kamil (Fırat University); Serhatlioglu, Ihsan (Fırat University); Baygin, Mehmet (Ardahan University); Tuncer, Turker (Fırat University)",4,4,,,,https://app.dimensions.ai/details/publication/pub.1144978224,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1405,pub.1142423526,10.1155/2021/5868501,,,NECScanNet: Novel Method for Cervical Neuroendocrine Cancer Screening from Whole Slide Images,"As a rare malignant tumor, cervical neuroendocrine cancer (NEC) is difficult in diagnosis even for experienced pathologists. A computer-assisted diagnosis may be helpful for the improvement of diagnostic accuracy. Nevertheless, the computer-aided pathological diagnosis has to face a great challenge that the hundred-million-pixels or even gig-pixels whole slide images (WSIs) cannot be applied directly in the existing deep convolution network for training and analysis. Therefore, the construction of a neural network to realize the automatic screening of cervical NEC is challenging; meanwhile, as far as we know, little attention has been paid to this field. In order to address this problem, here we present a multiple-instance learning method for automatic recognition of cervical NEC on pathological WSI, which consists of the Sliding Detector module and Lesion Analyzer module. A pathological WSI dataset, which is composed of 84 NEC cases and 216 NEC-free cases from the Pathological Department of West China Second University Hospital, is applied to evaluate the performance of the method. The experimental results show that the recall rate, accuracy rate, and precision rate of our method for automatic recognition are 92.9%, 92.7%, and 83.0%, respectively, demonstrating the effectiveness and the potential in clinical practice. The application of this method in computer-assisted pathological diagnosis is expected to decrease the misdiagnosis as well as the false diagnosis of rare cervical NEC, and, consequently, improve the therapeutic effect of cervical cancers.",This study was supported by the Research on Expert Knowledge Base for Automatic Diagnosis of Cervical Pathology Based on Big Data Deep Learning (2017LF3008). This research was supported by the grants from Key Laboratory Open Foundation of Sichuan Province .,,Security and Communication Networks,,,2021-10-31,2021,,2021-10-31,2021,,1-12,All OA; Gold,Article,"Liao, Xin; Huang, Qin; Zheng, Xin","Liao, Xin (Department of Pathology, Key Laboratory of Birth Defects and Related Diseases of Women and Children (Sichuan University) Ministry of Education, West China Second University Hospital of Sichuan University, Chengdu, China, scu.edu.cn); Huang, Qin (Department of Pathology, Key Laboratory of Birth Defects and Related Diseases of Women and Children (Sichuan University) Ministry of Education, West China Second University Hospital of Sichuan University, Chengdu, China, scu.edu.cn); Zheng, Xin (College of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, uestc.edu.cn)","Huang, Qin (West China Second University Hospital of Sichuan University); Zheng, Xin (University of Electronic Science and Technology of China)","Liao, Xin (West China Second University Hospital of Sichuan University); Huang, Qin (West China Second University Hospital of Sichuan University); Zheng, Xin (University of Electronic Science and Technology of China)",1,1,,0.82,https://downloads.hindawi.com/journals/scn/2021/5868501.pdf,https://app.dimensions.ai/details/publication/pub.1142423526,46 Information and Computing Sciences; 4611 Machine Learning,
1405,pub.1120518213,10.1007/s12652-019-01426-8,,,Electromyogram prediction during anesthesia by using a hybrid intelligent model,"In the search for new and more efficient ways to administer drugs, clinicians are turning to engineering tools. The availability of these models to predict physiological variables are a significant factor. A model is set out in this research to predict the EMG (electromyogram) signal during surgery, in patients under general anaesthesia. This prediction hinges on the Bispectral Index™ (BIS) and the infusion rate of the drug propofol. The results of the research are very satisfactory, with error values of less than 0.67 (for a Normalized Mean Squared Error). A hybrid intelligent model is used which combines both clustering and regression algorithms. The resulting model is validated and trained using real data.","This study was conducted under the auspices of Research Project DPI2010-18278, supported by the Spanish Ministry of Innovation and Science.",,Journal of Ambient Intelligence and Humanized Computing,,,2019-08-23,2019,2019-08-23,2020-11,11,11,4467-4476,All OA; Green,Article,"Casteleiro-Roca, José-Luis; Gomes, Marco; Méndez-Pérez, Juan Albino; Alaiz-Moretón, Héctor; Meizoso-López, María del Carmen; Rodríguez-Gómez, Benigno Antonio; Calvo-Rolle, José Luis","Casteleiro-Roca, José-Luis (Dpto. de Ingeniería Industrial, University of A Coruña, A Coruña, Spain); Gomes, Marco (ALGORITMI Centre, University of Minho, Braga, Portugal); Méndez-Pérez, Juan Albino (Dpto. de Ingeniería de Sistemas y Automática y Arquitectura y Tecnología de Computadores, University of La Laguna, San Cristóbal de La Laguna, Spain); Alaiz-Moretón, Héctor (Dpto. de Ingeniería Eléctrica y de Sistemas y Automática, University of León, León, Spain); Meizoso-López, María del Carmen (Dpto. de Ingeniería Industrial, University of A Coruña, A Coruña, Spain); Rodríguez-Gómez, Benigno Antonio (Dpto. de Ingeniería Industrial, University of A Coruña, A Coruña, Spain); Calvo-Rolle, José Luis (Dpto. de Ingeniería Industrial, University of A Coruña, A Coruña, Spain)","Alaiz-Moretón, Héctor (University of Leon)","Casteleiro-Roca, José-Luis (University of A Coruña); Gomes, Marco (University of Minho); Méndez-Pérez, Juan Albino (University of La Laguna); Alaiz-Moretón, Héctor (University of Leon); Meizoso-López, María del Carmen (University of A Coruña); Rodríguez-Gómez, Benigno Antonio (University of A Coruña); Calvo-Rolle, José Luis (University of A Coruña)",4,1,,,https://ruc.udc.es/dspace/bitstream/2183/31879/2/2020_Casteleiro_Roca_Electromyogram_prediction_during_anesthesia_by_using_a_hybrid_intelligent_model.pdf,https://app.dimensions.ai/details/publication/pub.1120518213,46 Information and Computing Sciences,
1398,pub.1007971086,10.1016/j.imu.2016.06.003,,,Computer-aided detection system for nerve identification using ultrasound images: A comparative study,"Ultrasound-Guided Regional Anesthesia (UGRA) has been gaining importance in the last few years, offering numerous advantages over alternative methods of nerve localization (neurostimulation or paraesthesia). However, nerve detection is one of the most difficult tasks that anesthetists can encounter in the UGRA procedure. The context of the present work is to provide practitioners with a computer-aided system to facilitate the practice of UGRA. However, automatic detection and segmentation in US images is still a challenging problem in many medical applications. This paper addresses two main issues, first proposing an efficient framework for nerve detection and segmentation, and second, reviewing literature methods and evaluating their performance for this new application. The proposed system consists of four main stages: (1) despeckling filter, (2) feature extraction, (3) feature selection, (4) classification and segmentation. A comparative study was performed in each of these stages to measure their influence over the whole system. Sonographic videos were acquired with the same ultrasound machine in real conditions from 19 volunteer patients. Evaluation was designed to cover two important aspects: measure the effect of training set size, and evaluate consistency using a cross-validation technique. The results obtained were significant and indicated which method was better for a nerve detection system. The proposed scheme achieved high scores (i.e. 80% on average of 1900 tested images), demonstrating its validity.",This work is part of the DANIEAL project supported by a Region Centre-Val de Loire (France) grant 13067HPR-2013. We gratefully acknowledge Region Centre-Val de Loire for its support.,,Informatics in Medicine Unlocked,,,2016,2016,,2016,3,,29-43,All OA; Gold,Article,"Hadjerci, Oussama; Hafiane, Adel; Conte, Donatello; Makris, Pascal; Vieyres, Pierre; Delbos, Alain","Hadjerci, Oussama (INSA CVL, Université d′Orléans, Laboratoire PRISME EA 4229, Bourges, France); Hafiane, Adel (INSA CVL, Université d′Orléans, Laboratoire PRISME EA 4229, Bourges, France); Conte, Donatello (Université de Francois Rabelais, Laboratoire LI EA 6300, Tours, France); Makris, Pascal (Université de Francois Rabelais, Laboratoire LI EA 6300, Tours, France); Vieyres, Pierre (Université d′Orléans, Laboratoire PRISME EA 4229, Bourges, France); Delbos, Alain (Clinique Medipôle Garonne, Toulouse, France)","Hadjerci, Oussama ","Hadjerci, Oussama (); Hafiane, Adel (); Conte, Donatello (François Rabelais University); Makris, Pascal (François Rabelais University); Vieyres, Pierre (University of Orléans); Delbos, Alain (Médipole Garonne)",24,9,,6.17,https://doi.org/10.1016/j.imu.2016.06.003,https://app.dimensions.ai/details/publication/pub.1007971086,42 Health Sciences; 4203 Health Services and Systems,
1360,pub.1130165149,10.1007/978-3-030-52190-5_3,,,A Survey of Modern Gene Expression Based Techniques for Cancer Detection and Diagnosis,"Cancer is a leading cause of death and majority of cancer patients are diagnosed in the late stages of cancer by using conventional methods. The gene expression microarray technology is applied to detect and diagnose most types of cancers in their early stages. Furthermore, it allows researchers to analyze thousands of genes simultaneously. To acquire knowledge from gene expression data, data mining methods are needed. Due to the rapid evolution of cancer detection and diagnosis techniques, a survey of modern techniques is desirable. This study reviews and provide a detailed description of these techniques. As a result, it helps to enhance existing techniques for cancer detection and diagnosis as well as guiding researchers to develop new approaches.",,,Advances in Intelligent Systems and Computing,Soft Computing Applications,,2020-08-18,2020,2020-08-18,2021,1222,,35-50,Closed,Chapter,"Rahman, Hafiz ur; Arif, Muhammad; Al-Azani, Sadam; Ramadan, Emad; Wang, Guojun; Chen, Jianer; Olariu, Teodora; Olariu, Iustin","Rahman, Hafiz ur (School of Computer Science, Guangzhou University, 510006, Guangzhou, China); Arif, Muhammad (School of Computer Science, Guangzhou University, 510006, Guangzhou, China); Al-Azani, Sadam (Department of Information and Computer Science, King Fahd University of Petroleum and Minerals, Dhahran, Kingdom of Saudi Arabia); Ramadan, Emad (Department of Information and Computer Science, King Fahd University of Petroleum and Minerals, Dhahran, Kingdom of Saudi Arabia); Wang, Guojun (School of Computer Science, Guangzhou University, 510006, Guangzhou, China); Chen, Jianer (School of Computer Science, Guangzhou University, 510006, Guangzhou, China); Olariu, Teodora (Faculty of Medicine, Vasile Goldis Western University of Arad, Arad, Romania); Olariu, Iustin (Faculty of Medicine, Vasile Goldis Western University of Arad, Arad, Romania)","Wang, Guojun (Guangzhou University)","Rahman, Hafiz ur (Guangzhou University); Arif, Muhammad (Guangzhou University); Al-Azani, Sadam (King Fahd University of Petroleum and Minerals); Ramadan, Emad (King Fahd University of Petroleum and Minerals); Wang, Guojun (Guangzhou University); Chen, Jianer (Guangzhou University); Olariu, Teodora (Vasile Goldis Western University of Arad); Olariu, Iustin (Vasile Goldis Western University of Arad)",1,1,,0.26,,https://app.dimensions.ai/details/publication/pub.1130165149,31 Biological Sciences; 3102 Bioinformatics and Computational Biology,
1360,pub.1101319325,10.1007/s10586-018-2236-6,,,RETRACTED ARTICLE: A voxel based morphometry approach for identifying Alzheimer from MRI images,"A voxel based morphometry (VBM) which makes use of a structural brain magnetic resonance imaging (MRI) is now being employed widely for the purpose of assessing the various normal ageing of Alzheimer’s diseases (AD). VBM of the MRI data will contain segmentation within the grey and white matter, the cerebrospinal fluid and its partitions along with that of their anatomical image and its standardization inside the analogous stereotactic region. It further includes the affine transformation with a non-linear warping of the smoothing as well as a statistical investigation. In case there is a cognitive failure that is related to age called Dementia that has been indicated with that of a degeneration of the cortical and the sub-cortical structures. The characterization of such types of morphological changes will help in the understanding of the development of these diseases and the modelling will tend to capture the structural variability of brain which is a valid classification for this disease and its interpretation is found to be quite challenging. Here such features have also been extracted by means of using a curvelet transform along with a principal component analysis (PCA) for this technique of reduction of dimensionality. The Bagging as well as the boosting classifiers have been duly evaluated for their efficiency in classifying dementia. The work will further evaluate the framework by using images from that of the Alzheimer’s disease neuroimaging initiative (ADNI) for identifying dementia. Such results have shown that this classifier proposed has now achieved better accuracy.",,,Cluster Computing,,,2018-03-02,2018,2018-03-02,2019-11,22,Suppl 6,14081-14089,Closed,Article,"Saravanakumar, S.; Thangaraj, P.","Saravanakumar, S. (Department of Computer Science and Engineering, Adithya Institute of Technology, Coimbatore, Tamil Nadu, India); Thangaraj, P. (Department of Computer Science and Engineering, Bannari Amman Institute of Technology, Sathyamangalam, Tamil Nadu, India)","Saravanakumar, S. ","Saravanakumar, S. (); Thangaraj, P. (Anna University, Chennai)",7,5,,1.91,,https://app.dimensions.ai/details/publication/pub.1101319325,46 Information and Computing Sciences; 4606 Distributed Computing and Systems Software,
1358,pub.1120314056,10.48550/arxiv.1908.03573,,,Synthetic Elastography using B-mode Ultrasound through a Deep  Fully-Convolutional Neural Network,"Shear-wave elastography (SWE) permits local estimation of tissue elasticity,
an important imaging marker in biomedicine. This recently-developed, advanced
technique assesses the speed of a laterally-travelling shear wave after an
acoustic radiation force ""push"" to estimate local Young's moduli in an
operator-independent fashion. In this work, we show how synthetic SWE (sSWE)
images can be generated based on conventional B-mode imaging through deep
learning. Using side-by-side-view B-mode/SWE images collected in 50 patients
with prostate cancer, we show that sSWE images with a pixel-wise mean absolute
error of 4.5+/-0.96 kPa with regard to the original SWE can be generated.
Visualization of high-level feature levels through t-Distributed Stochastic
Neighbor Embedding reveals substantial overlap between data from two different
scanners. Qualitatively, we examined the use of the sSWE methodology for B-mode
images obtained with a scanner without SWE functionality. We also examined the
use of this type of network in elasticity imaging in the thyroid. Limitations
of the technique reside in the fact that networks have to be retrained for
different organs, and that the method requires standardization of the imaging
settings and procedure. Future research will be aimed at development of sSWE as
an elasticity-related tissue typing strategy that is solely based on B-mode
ultrasound acquisition, and the examination of its clinical utility.",,,arXiv,,,2019-08-09,2019,,,,,,All OA; Green,Preprint,"Wildeboer, R. R.; van Sloun, R. J. G.; Mannaerts, C. K.; Moraes, P. H.; Salomon, G.; Chammas, M. C.; Wijkstra, H.; Mischi, M.","Wildeboer, R. R. (); van Sloun, R. J. G. (); Mannaerts, C. K. (); Moraes, P. H. (); Salomon, G. (); Chammas, M. C. (); Wijkstra, H. (); Mischi, M. ()",,"Wildeboer, R. R. (); van Sloun, R. J. G. (); Mannaerts, C. K. (); Moraes, P. H. (); Salomon, G. (); Chammas, M. C. (); Wijkstra, H. (); Mischi, M. ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1120314056,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis; 40 Engineering,
1312,pub.1118451567,10.48550/arxiv.1509.00111,,,Discovery Radiomics for Multi-Parametric MRI Prostate Cancer Detection,"Prostate cancer is the most diagnosed form of cancer in Canadian men, and is
the third leading cause of cancer death. Despite these statistics, prognosis is
relatively good with a sufficiently early diagnosis, making fast and reliable
prostate cancer detection crucial. As imaging-based prostate cancer screening,
such as magnetic resonance imaging (MRI), requires an experienced medical
professional to extensively review the data and perform a diagnosis,
radiomics-driven methods help streamline the process and has the potential to
significantly improve diagnostic accuracy and efficiency, and thus improving
patient survival rates. These radiomics-driven methods currently rely on
hand-crafted sets of quantitative imaging-based features, which are selected
manually and can limit their ability to fully characterize unique prostate
cancer tumour phenotype. In this study, we propose a novel \textit{discovery
radiomics} framework for generating custom radiomic sequences tailored for
prostate cancer detection. Discovery radiomics aims to uncover abstract
imaging-based features that capture highly unique tumour traits and
characteristics beyond what can be captured using predefined feature models. In
this paper, we discover new custom radiomic sequencers for generating new
prostate radiomic sequences using multi-parametric MRI data. We evaluated the
performance of the discovered radiomic sequencer against a state-of-the-art
hand-crafted radiomic sequencer for computer-aided prostate cancer detection
with a feedforward neural network using real clinical prostate multi-parametric
MRI data. Results for the discovered radiomic sequencer demonstrate good
performance in prostate cancer detection and clinical decision support relative
to the hand-crafted radiomic sequencer. The use of discovery radiomics shows
potential for more efficient and reliable automatic prostate cancer detection.",,,arXiv,,,2015-08-31,2015,,,,,,All OA; Green,Preprint,"Chung, Audrey G.; Shafiee, Mohammad Javad; Kumar, Devinder; Khalvati, Farzad; Haider, Masoom A.; Wong, Alexander","Chung, Audrey G. (); Shafiee, Mohammad Javad (); Kumar, Devinder (); Khalvati, Farzad (); Haider, Masoom A. (); Wong, Alexander ()",,"Chung, Audrey G. (); Shafiee, Mohammad Javad (); Kumar, Devinder (); Khalvati, Farzad (); Haider, Masoom A. (); Wong, Alexander ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1118451567,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
1312,pub.1117925936,10.1145/3319619.3326864,,,Semantic learning machine improves the CNN-Based detection of prostate cancer in non-contrast-enhanced MRI,"Considering that Prostate Cancer (PCa) is the most frequently diagnosed tumor in Western men, considerable attention has been devoted in computer-assisted PCa detection approaches. However, this task still represents an open research question. In the clinical practice, multiparametric Magnetic Resonance Imaging (MRI) is becoming the most used modality, aiming at defining biomarkers for PCa. In the latest years, deep learning techniques have boosted the performance in prostate MR image analysis and classification. This work explores the use of the Semantic Learning Machine (SLM) neuroevolution algorithm to replace the backpropagation algorithm commonly used in the last fully-connected layers of Convolutional Neural Networks (CNNs). We analyzed the non-contrast-enhanced multispectral MRI sequences included in the PROSTATEx dataset, namely: T2-weighted, Proton Density weighted, Diffusion Weighted Imaging. The experimental results show that the SLM significantly outperforms XmasNet, a state-of-the-art CNN. In particular, with respect to XmasNet, the SLM achieves higher classification accuracy (without neither pre-training the underlying CNN nor relying on backprogation) as well as a speed-up of one order of magnitude.",,,,Proceedings of the Genetic and Evolutionary Computation Conference Companion,,2019-07-13,2019,2019-07-13,2019-07-13,,,1837-1845,All OA; Green,Proceeding,"Lapa, Paulo; Gonçalves, Ivo; Rundo, Leonardo; Castelli, Mauro","Lapa, Paulo (Universidade Nova de Lisboa, Lisboa, Portugal); Gonçalves, Ivo (University of Coimbra, Coimbra, Portugal); Rundo, Leonardo (University of Cambridge, Cambridge, UK); Castelli, Mauro (Universidade Nova de Lisboa, Lisboa, Portugal)",,"Lapa, Paulo (Universidade Nova de Lisboa); Gonçalves, Ivo (University of Coimbra); Rundo, Leonardo (University of Cambridge); Castelli, Mauro (Universidade Nova de Lisboa)",8,5,,2.83,https://www.repository.cam.ac.uk/bitstream/1810/310567/1/GECCO_2019_MedGEC_Workshop.pdf,https://app.dimensions.ai/details/publication/pub.1117925936,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences,
1273,pub.1136816488,10.48550/arxiv.2103.15858,,,CateNorm: Categorical Normalization for Robust Medical Image  Segmentation,"Batch normalization (BN) uniformly shifts and scales the activations based on
the statistics of a batch of images. However, the intensity distribution of the
background pixels often dominates the BN statistics because the background
accounts for a large proportion of the entire image. This paper focuses on
enhancing BN with the intensity distribution of foreground pixels, the one that
really matters for image segmentation. We propose a new normalization strategy,
named categorical normalization (CateNorm), to normalize the activations
according to categorical statistics. The categorical statistics are obtained by
dynamically modulating specific regions in an image that belong to the
foreground. CateNorm demonstrates both precise and robust segmentation results
across five public datasets obtained from different domains, covering complex
and variable data distributions. It is attributable to the ability of CateNorm
to capture domain-invariant information from multiple domains (institutions) of
medical data. Code is available at https://github.com/lambert-x/CateNorm.",,,arXiv,,,2021-03-29,2021,,,,,,All OA; Green,Preprint,"Xiao, Junfei; Yu, Lequan; Zhou, Zongwei; Bai, Yutong; Xing, Lei; Yuille, Alan; Zhou, Yuyin","Xiao, Junfei (); Yu, Lequan (); Zhou, Zongwei (); Bai, Yutong (); Xing, Lei (); Yuille, Alan (); Zhou, Yuyin ()",,"Xiao, Junfei (); Yu, Lequan (); Zhou, Zongwei (); Bai, Yutong (); Xing, Lei (); Yuille, Alan (); Zhou, Yuyin ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136816488,46 Information and Computing Sciences; 49 Mathematical Sciences; 4905 Statistics,
1270,pub.1006035199,10.1016/j.bspc.2016.07.015,,,Automatic classification and localization of prostate cancer using multi-parametric MRI/MRS,"Prostate cancer is considered to be the third and sixth leading cause of death from cancer in men in developed and developing countries, respectively. As Multiparametric Magnetic Resonance Imaging (mp-MRI) and Magnetic Resonance Spectroscopic Imaging (MRSI) play an important role in the detection and the localization of cancerous tissues, in this paper, we propose a SVM and Random Forest based supervised classification schema, based on three classes (Healthy, Benign, Malignant) and on an MRI/MRSI data base of 34 patients. A total of 7711 spectroscopy voxels were exploited. The first contribution of this paper is to present improvements of the automatic classification results compared with those of Parfait, thanks to an improvement in the quality of spectra. We also improved the global detection by introducing mp-MRI based features in the classification process. We selected the most discriminative features by evaluating several combinations of MRI modalities. Moreover, we have extended the analysis to the entire prostate gland (peripheral zone (PZ) and central gland (CG)). We evaluated the SVM classifier's ability to discriminate healthy and malignant voxels and the proposed method produces a global error rate of 1%, sensitivity of 99.1% and specificity of 98.4%. The three classes, including benign voxels data were then evaluated. An error rate of 18.2%, a sensitivity of 72% and a specificity of 88% were obtained when associating Random Forest classifier, MRSI, Dynamic Contrast-Enhanced MRI and Diffusion-Weighted MRI. We finally present classification results in the form of color-coded maps, which are a computer aided diagnosis tool which could help in the evaluation of the results and could also provide an estimation of tumor shape and volume.",We would like to thank the University Hospital of Dijon (France) for providing MRI data set used in our experiments.,,Biomedical Signal Processing and Control,,,2017-01,2017,,2017-01,31,,189-198,Closed,Article,"Trigui, R.; Mitéran, J.; Walker, P.M.; Sellami, L.; Hamida, A. Ben","Trigui, R. (Laboratoire Electronique Informatique et Image (LE2I), UMR 6309 CNRS, Univ. Bourgogne Franche-Comté, Faculté Mirande, 21000 Dijon, France; Advanced Technologies for Medicine and Signals (ATMS), ENIS, Université de Sfax, Tunisia); Mitéran, J. (Laboratoire Electronique Informatique et Image (LE2I), UMR 6309 CNRS, Univ. Bourgogne Franche-Comté, Faculté Mirande, 21000 Dijon, France); Walker, P.M. (Laboratoire Electronique Informatique et Image (LE2I), UMR 6309 CNRS, Univ. Bourgogne Franche-Comté, Faculté Mirande, 21000 Dijon, France; Centre Hospitalier Universitaire de Dijon, 21033 Dijon, France); Sellami, L. (Advanced Technologies for Medicine and Signals (ATMS), ENIS, Université de Sfax, Tunisia); Hamida, A. Ben (Advanced Technologies for Medicine and Signals (ATMS), ENIS, Université de Sfax, Tunisia)","Trigui, R. (Laboratoire d’Électronique, Informatique et Image; University of Sfax); Mitéran, J. (Laboratoire d’Électronique, Informatique et Image)","Trigui, R. (Laboratoire d’Électronique, Informatique et Image; University of Sfax); Mitéran, J. (Laboratoire d’Électronique, Informatique et Image); Walker, P.M. (Laboratoire d’Électronique, Informatique et Image; Centre Hospitalier Universitaire Dijon Bourgogne); Sellami, L. (University of Sfax); Hamida, A. Ben (University of Sfax)",24,10,,3.57,,https://app.dimensions.ai/details/publication/pub.1006035199,"30 Agricultural, Veterinary and Food Sciences; 3006 Food Sciences; 40 Engineering; 4003 Biomedical Engineering",
1270,pub.1121899749,10.1109/icecct.2019.8869533,,,On Computer-Aided Diagnosis of Prostate Cancer from MRI using Machine Intelligence Techniques,"Prostate cancer is one of the major cause of cancer death among men. Mortality rate due to prostate cancer can be reduced significantly by early diagnosis and treatment planning. Magnetic Resonance Imaging (MRI) is a major modality for early detection of prostate cancer. Recent studies have proven that MRI can be used for grading of prostate cancer also. In this paper, a survey on computer-aided detection and grading of prostate cancer is done exploring the state-of-the-art techniques. The paper examines various stages of computer-aided diagnosis of prostate cancer including detection of cancer, estimation of clinical significance of cancer and grading of cancer. The survey compares the performance of different techniques available in the lliteraure and provides directions for further research.",,,,"2019 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)",,2019-02-22,2019,,2019-02-22,00,,1-8,Closed,Proceeding,"Abraham, Bejoy; Nair, Madhu S.","Abraham, Bejoy (Department of Computer Science, University of Kerala, Kariavattom, Thiruvananthapuram, 695581, Kerala, India; Department of Computer Science and Engineering, College of Engineering Perumon, Perinad, Kollam, 691601, Kerala, India); Nair, Madhu S. (Department of Computer Science, Cochin University of Science and Technology, Kochi, 682022, Kerala, India)","Abraham, Bejoy (University of Kerala; )","Abraham, Bejoy (University of Kerala); Nair, Madhu S. (Cochin University of Science and Technology)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1121899749,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,3 Good Health and Well Being
1269,pub.1151381626,10.1109/cvpr52688.2022.02020,,,Closing the Generalization Gap of Cross-silo Federated Medical Image Segmentation,"Cross-silo federated learning (FL) has attracted much attention in medical imaging analysis with deep learning in recent years as it can resolve the critical issues of insufficient data, data privacy, and training efficiency. However, there can be a generalization gap between the model trained from FL and the one from centralized training. This important issue comes from the non-iid data distribution of the local data in the participating clients and is well-known as client drift. In this work, we propose a novel training frame-work FedSM to avoid the client drift issue and successfully close the generalization gap compared with the centralized training for medical image segmentation tasks for the first time. We also propose a novel personalized FL objective formulation and a new method SoftPull to solve it in our proposed framework FedSM. We conduct rigorous theoretical analysis to guarantee its convergence for optimizing the non-convex smooth objective function. Real-world medical image segmentation experiments using deep FL validate the motivations and effectiveness of our proposed method.",,"A.X. and H.H. were partially supported by NSF IIS 1845666, 1852606, 1838627, 1837956, 1956002, IIA 2040588. Implementation of this work is available at https://github.com/NVIDIA/NVFlare/examples/FedSM",,2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),,2022-06-24,2022,,2022-06-24,00,,20834-20843,All OA; Green,Proceeding,"Xu, An; Li, Wenqi; Guo, Pengfei; Yang, Dong; Roth, Holger; Hatamizadeh, Ali; Zhao, Can; Xu, Daguang; Huang, Heng; Xu, Ziyue","Xu, An (Univ. of Pittsburgh); Li, Wenqi (NVIDIA); Guo, Pengfei (Johns Hopkins University); Yang, Dong (NVIDIA); Roth, Holger (NVIDIA); Hatamizadeh, Ali (NVIDIA); Zhao, Can (NVIDIA); Xu, Daguang (NVIDIA); Huang, Heng (Univ. of Pittsburgh); Xu, Ziyue (NVIDIA)",,"Xu, An (University of Pittsburgh); Li, Wenqi (Nvidia (United States)); Guo, Pengfei (Johns Hopkins University); Yang, Dong (Nvidia (United States)); Roth, Holger (Nvidia (United States)); Hatamizadeh, Ali (Nvidia (United States)); Zhao, Can (Nvidia (United States)); Xu, Daguang (Nvidia (United States)); Huang, Heng (University of Pittsburgh); Xu, Ziyue (Nvidia (United States))",4,4,,,http://arxiv.org/pdf/2203.10144,https://app.dimensions.ai/details/publication/pub.1151381626,46 Information and Computing Sciences; 4611 Machine Learning,
1269,pub.1105427299,10.1016/j.bbe.2018.06.009,,,Computer-aided diagnosis of clinically significant prostate cancer from MRI images using sparse autoencoder and random forest classifier,"A novel method to diagnose clinically significant prostate cancer (PCa) using Multi-parametric Magnetic Resonance Imaging (mpMRI) biomarkers in a highly imbalanced dataset is investigated in this paper. Transaxial T2 Weighted (T2W), Apparent Diffusion Coefficient (ADC) and high B-Value (BVAL) Diffusion-Weighted (DW) images obtained from PROSTATEx 2016 challenge dataset publicly available in TCIA (The Cancer Imaging Archive) is used for this study. High-level features are extracted using a single layer Sparse Autoencoder (SAE). Synthetic Minority Oversampling Technique (SMOTE), Weka Resample algorithm and Adaptive Synthetic (ADASYN) sampling approach are explored to solve the class-imbalance problem. The performance of various classifiers are also investigated and it was found that the data augmented using ADASYN followed by classification using random forest classifier achieved the best performance. It achieved an area under ROC curve of 0.979. It also reached a Cohen's kappa score of 0.873, an accuracy of 93.65% and F-Measure of 0.94 in distinguishing clinically significant PCa from indolent PCa.","We thank American Association of Physicists in Medicine (AAPM), SPIE (The International Society for Optics and Photonics) and the National Cancer Institute (NCI) and TCIA (The Cancer Imaging Archive) and Radboud University for providing the dataset. We are grateful to Dr. Anil Prahladan, Assistant Professor of Radiology, Regional Cancer Centre, Thiruvananthapuram, Kerala, India for suggesting Computer Aided Prostate Cancer Detection as our research area. Bejoy Abraham is thankful to University of Kerala for providing him University Junior Research Fellowship.",,Journal of Applied Biomedicine,,,2018,2018,,2018,38,3,733-744,Closed,Article,"Abraham, Bejoy; Nair, Madhu S.","Abraham, Bejoy (Department of Computer Science, University of Kerala, Kariavattom, Thiruvananthapuram 695581, Kerala, India); Nair, Madhu S. (Department of Computer Science, Cochin University of Science and Technology, Kochi 682022, Kerala, India)","Abraham, Bejoy (University of Kerala)","Abraham, Bejoy (University of Kerala); Nair, Madhu S. (Cochin University of Science and Technology)",23,9,,3.74,,https://app.dimensions.ai/details/publication/pub.1105427299,40 Engineering; 4003 Biomedical Engineering,
1233,pub.1142385794,10.1109/cvpr46437.2021.00107,,,FedDG: Federated Domain Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency Space,"Federated learning allows distributed medical institutions to collaboratively learn a shared prediction model with privacy protection. While at clinical deployment, the models trained in federated learning can still suffer from performance drop when applied to completely unseen hospitals outside the federation. In this paper, we point out and solve a novel problem setting of federated domain generalization (FedDG), which aims to learn a federated model from multiple distributed source domains such that it can directly generalize to unseen target domains. We present a novel approach, named as Episodic Learning in Continuous Frequency Space (ELCFS), for this problem by enabling each client to exploit multi-source data distributions under the challenging constraint of data decentralization. Our approach transmits the distribution information across clients in a privacy-protecting way through an effective continuous frequency space interpolation mechanism. With the transferred multi-source distributions, we further carefully design a boundary-oriented episodic learning paradigm to expose the local learning to domain distribution shifts and particularly meet the challenges of model generalization in medical image segmentation scenario. The effectiveness of our method is demonstrated with superior performance over state-of-the-arts and in-depth ablation experiments on two medical image segmentation tasks. The code is available at https://github.com/liuquande/FedDG-ELCFS.","This work was supported by Key-Area Research and Development Program of Guangdong Province, China (2020B010165004); National Natural Science Foundation of China with Project No. U1813204; Hong Kong Innovation and Technology Fund (Project No. ITS/311/18FP and GHP/110/19SZ). This work was supported by Key-Area Research and Development Program of Guangdong Province, China (2020B010165004); National Natural Science Foundation of China with Project No. U1813204; Hong Kong Innovation and Technology Fund (Project No. ITS/311/18FP and GHP/110/19SZ).",,,2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),,2021-06-25,2021,,2021-06-25,00,,1013-1023,All OA; Green,Proceeding,"Liu, Quande; Chen, Cheng; Qin, Jing; Dou, Qi; Heng, Pheng-Ann","Liu, Quande (Department of Computer Science and Engineering, The Chinese University of Hong Kong); Chen, Cheng (Department of Computer Science and Engineering, The Chinese University of Hong Kong); Qin, Jing (School of Nursing, The Hong Kong Polytechnic University); Dou, Qi (Department of Computer Science and Engineering, The Chinese University of Hong Kong); Heng, Pheng-Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong)","Dou, Qi (Chinese University of Hong Kong)","Liu, Quande (Chinese University of Hong Kong); Chen, Cheng (Chinese University of Hong Kong); Qin, Jing (Hong Kong Polytechnic University); Dou, Qi (Chinese University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong)",72,72,,58.93,http://arxiv.org/pdf/2103.06030,https://app.dimensions.ai/details/publication/pub.1142385794,46 Information and Computing Sciences; 4611 Machine Learning,
1233,pub.1061252187,10.1109/access.2015.2502220,,,Prostate Cancer Detection via a Quantitative Radiomics-Driven Conditional Random Field Framework,"The use of high-volume quantitative radiomics features extracted from multi-parametric magnetic resonance imaging (MP-MRI) is gaining attraction for the autodetection of prostate tumors, since it provides a plethora of mineable data, which can be used for both detection and prognosis of prostate cancer. While current voxel-resolution radiomics-driven prostate tumor detection approaches utilize quantitative radiomics features associated with individual voxels on an independent basis, the incorporation of additional information regarding the spatial and radiomics feature relationships between voxels has significant potential for achieving a more reliable detection performance. Motivated by this, we present a novel approach for automatic prostate cancer detection using a radiomics-driven conditional random field (RD-CRF) framework. In addition to the high-throughput extraction and utilization of a comprehensive set of voxel-level quantitative radiomics features, the proposed RD-CRF framework leverages inter-voxel spatial and radiomics feature relationships to ensure that the autodetected tumor candidates exhibit interconnected tissue characteristics reflective of cancerous tumors. We evaluated the performance of the proposed framework using clinical prostate MP-MRI data of 20 patients, and the results of RD-CRF framework demonstrated a clear improvement with respect to the state-of-the-art in quantitative radiomics for automatic voxel-resolution prostate cancer detection.","This work was supported in part by the Ontario Institute of Cancer Research, Canada Research Chairs Program, Natural Sciences and Engineering Research Council of Canada, and the Ministry of Research and Innovation of Ontario.",,IEEE Access,,,2015-01-01,2015,2015-11-19,2015-01-01,3,,2531-2541,All OA; Gold,Article,"Chung, Audrey G.; Khalvati, Farzad; Shafiee, Mohammad Javad; Haider, Masoom A.; Wong, Alexander","Chung, Audrey G. (Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, N2L 3G1, Canada); Khalvati, Farzad (Department of Medical Imaging, Sunnybrook Research Institute, University of Toronto, Toronto, ON, M4N 3M5, Canada); Shafiee, Mohammad Javad (Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, N2L 3G1, Canada); Haider, Masoom A. (Department of Medical Imaging, Sunnybrook Research Institute, University of Toronto, Toronto, ON, M4N 3M5, Canada); Wong, Alexander (Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, N2L 3G1, Canada)","Khalvati, Farzad (University of Toronto)","Chung, Audrey G. (University of Waterloo); Khalvati, Farzad (University of Toronto); Shafiee, Mohammad Javad (University of Waterloo); Haider, Masoom A. (University of Toronto); Wong, Alexander (University of Waterloo)",28,12,,,https://ieeexplore.ieee.org/ielx7/6287639/7042252/07332243.pdf,https://app.dimensions.ai/details/publication/pub.1061252187,40 Engineering; 46 Information and Computing Sciences,3 Good Health and Well Being
1233,pub.1141111933,10.48550/arxiv.2109.05742,,,Domain Generalization for Medical Image Segmentation via Hierarchical  Consistency Regularization,"Modern deep neural networks struggle to transfer knowledge and generalize
across diverse domains when deployed to real-world applications. Currently,
domain generalization (DG) is introduced to learn a universal representation
from multiple domains to improve the network generalization ability on unseen
domains. However, previous DG methods only focus on the data-level consistency
scheme without considering the synergistic regularization among different
consistency schemes. In this paper, we present a novel Hierarchical Consistency
framework for Domain Generalization (HCDG) by integrating Extrinsic Consistency
and Intrinsic Consistency synergistically. Particularly, for the Extrinsic
Consistency, we leverage the knowledge across multiple source domains to
enforce data-level consistency. To better enhance such consistency, we design a
novel Amplitude Gaussian-mixing strategy into Fourier-based data augmentation
called DomainUp. For the Intrinsic Consistency, we perform task-level
consistency for the same instance under the dual-task scenario. We evaluate the
proposed HCDG framework on two medical image segmentation tasks, i.e., optic
cup/disc segmentation on fundus images and prostate MRI segmentation. Extensive
experimental results manifest the effectiveness and versatility of our HCDG
framework.",,,arXiv,,,2021-09-13,2021,,,,,,All OA; Green,Preprint,"Yang, Yijun; Wang, Shujun; Zhu, Lei; Heng, Pheng-Ann; Yu, Lequan","Yang, Yijun (); Wang, Shujun (); Zhu, Lei (); Heng, Pheng-Ann (); Yu, Lequan ()",,"Yang, Yijun (); Wang, Shujun (); Zhu, Lei (); Heng, Pheng-Ann (); Yu, Lequan ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1141111933,46 Information and Computing Sciences; 4602 Artificial Intelligence; 4605 Data Management and Data Science; 4611 Machine Learning,
1230,pub.1147563313,10.1002/ima.22744,,,PC‐SNet for automated detection of prostate cancer in multiparametric‐magnetic resonance imaging,"Prostate cancer (PCa) is responsible for the maximum deaths of men across the world after lung cancer; hence, it should be diagnosed in the initial stages. Magnetic resonance imaging (MRI) commonly diagnoses PCa due to better visibility of desired organ and cancerous region over other modalities. Therefore, development of MRI‐based computer‐aided diagnosis (CAD) systems for PCa has become a recent area of research. Conventional methodologies used by researchers and radiologists were time consuming and prone to subjective errors due to manual interpretation. Thus, the CAD system helps in the early detection of PCa by reducing the computational complexity and increasing the detection accuracy with less chances of subjective errors. This article proposes a deep learning–based methodology named prostate cancer segmentation network (PC‐SNet) for the segmentation of the region of interest (ROI) from the MRI sub‐modalities T2‐weighted (T2W) and dynamic contrast enhanced (DCE). Further, the performance is analyzed using parameters such as accuracy, Mathews correlation coefficient (MCC), dice similarity coefficient (DSC), Jaccard Index (JI) or intersection over union (IOU), F‐score, and Hausdorff distance (HD). Finally, the performance of PC‐SNet is found to outperform fully convolutional network (FCN), semantic pixel wise segmentation (SegNet), residual network (ResNet), UNet, and ENet architectures.","The authors are very obliged to the Ministry of Human Resource Development (MHRD), Government of India (GOI) for providing funds to this project (17‐11/2015‐PN‐1) under sub‐ theme Medical Devices and Restorative Technologies of Design Innovation Centre (DIC).","Funding information Ministry of Human Resource Development (MHRD), Grant/Award Number: 17‐11/2015‐PN‐1",International Journal of Imaging Systems and Technology,,,2022-05-03,2022,2022-05-03,2022-11,32,6,1861-1879,Closed,Article,"Juneja, Mamta; Saini, Sumindar Kaur; Acharjee, Rajarshi; Kaul, Sambhav; Thakur, Niharika; Jindal, Prashant","Juneja, Mamta (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Saini, Sumindar Kaur (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Acharjee, Rajarshi (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Kaul, Sambhav (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Thakur, Niharika (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Jindal, Prashant (University Institute of Engineering and Technology, Panjab University, Chandigarh, India)","Jindal, Prashant (Panjab University)","Juneja, Mamta (Panjab University); Saini, Sumindar Kaur (Panjab University); Acharjee, Rajarshi (Panjab University); Kaul, Sambhav (Panjab University); Thakur, Niharika (Panjab University); Jindal, Prashant (Panjab University)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147563313,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1161,pub.1154911271,10.1016/b978-0-12-819872-8.00011-2,,,Chapter 4 An accurate deep learning-based computer-aided diagnosis system for early diagnosis of prostate cancer,"This chapter introduces a system for early diagnosis of prostate cancer using a convolutional neural network (CNN) from diffusion-weighted imaging (DWI) acquired at seven b-values (100, 200, …, 700s/mm2). The proposed system has three main steps. First, prostate segmentation is performed to separate the region of interest from the background. Prostate segmentation is done using a level-set model that depends on three features for enhanced accuracy. These features are intensity, shape prior, and spatial features. These three features are fused using a nonnegative matrix factorization approach. Second, the apparent diffusion coefficients (ADCs) of the segmented regions at each b-value are computed and used to train the classification model of the final step. Finally, a CNN is trained using the ADC maps to distinguish malignant subjects from benign ones. The DWI datasets used to evaluate the performance of the proposed system were collected from 45 subjects (20 benign and 25 malignant) at two different magnetic field strengths which are 1.5 and 3 Tesla (T). An average accuracy of 93.7%±3% is achieved.",,,,State of the Art in Neural Networks and Their Applications,,2023,2023,,2023,,,83-104,Closed,Chapter,"Abdelmaksoud, Islam R.; Shalaby, Ahmed; Ghazal, Mohammed; Elmogy, Mohammed; AbouElfetouh, Ahmed; Mahmoud, Ali; El-Baz, Ayman S.","Abdelmaksoud, Islam R. (University of Louisville, Louisville, KY, United States; Faculty of Computers and Information, Mansoura University, Mansoura, Egypt); Shalaby, Ahmed (University of Louisville, Louisville, KY, United States); Ghazal, Mohammed (Electrical, Computer and Biomedical Engineering Department, Abu Dhabi University, Abu Dhabi, United Arab Emirates); Elmogy, Mohammed (Faculty of Computers and Information, Mansoura University, Mansoura, Egypt); AbouElfetouh, Ahmed (Faculty of Computers and Information, Mansoura University, Mansoura, Egypt); Mahmoud, Ali (University of Louisville, Louisville, KY, United States); El-Baz, Ayman S. (University of Louisville, Louisville, KY, United States; University of Louisville at Alamein International University (UofL-AIU), New Alamein City, Egypt)",,"Abdelmaksoud, Islam R. (University of Louisville; Mansoura University); Shalaby, Ahmed (University of Louisville); Ghazal, Mohammed (Abu Dhabi University); Elmogy, Mohammed (Mansoura University); AbouElfetouh, Ahmed (Mansoura University); Mahmoud, Ali (University of Louisville); El-Baz, Ayman S. (University of Louisville)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154911271,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis,
1161,pub.1141306350,10.1109/access.2021.3114733,,,ProCDet: A New Method for Prostate Cancer Detection Based on MR Images,"Prostate cancer is a malignant tumor that occurs in the male prostate. Prostate cancer lesions have the characteristics of small size and blurry outline, which is a challenge to design a robust prostate cancer detection method. At present, clinical diagnosis of prostate cancer is mainly based on magnetic resonance (MR) imaging. However, it is difficult to obtain prostate cancer data, and the data with true values is also very limited, which further increases the difficulty of prostate cancer detection methods based on MR images. To solve these problems, this paper designs a new method of prostate cancer detection based on MR images, which is recorded as ProCDet. The method consists of three modules: registration of prostate MR images, segmentation of prostate, and segmentation of prostate cancer lesions. First, the registration between different sequences of MR images is performed to find the spatial relationship between the different sequences. Then, the designed prostate segmentation network based on the attention mechanism is used to segment the prostate to remove the interference of background information. Finally, a 3D prostate cancer lesion segmentation network based on Focal Tversky Loss is applied to determine the specific location of prostate cancer. Moreover, in order to take full advantage of unlabeled prostate data, this paper designs a self-supervised learning method to improve the accuracy of prostate cancer detection. The proposed ProCDet has been experimentally verified on the ProstateX dataset. When the average number of false-positive lesions per patient is 0.6275, the true-positive rate is 91.82%. Experimental results show that the ProCDet can obtain competitive detection performance.","This work was supported by the Natural Science Foundation of Zhejiang Province under Grant LGF19F020004, and in part by Wenzhou Science and Technology Project under Grant G20190022.",,IEEE Access,,,2021-01-01,2021,2021-09-22,2021-01-01,9,,143495-143505,All OA; Gold,Article,"Qian, Yuejing; Zhang, Zengyou; Wang, Bo","Qian, Yuejing (Zhejiang Industry and Trade Vocational College, Wenzhou, Zhejiang, 313103, China); Zhang, Zengyou (Zhejiang Industry and Trade Vocational College, Wenzhou, Zhejiang, 313103, China); Wang, Bo (Zhejiang College of Security Technology, Wenzhou, Zhejiang, 325000, China)","Wang, Bo ","Qian, Yuejing (); Zhang, Zengyou (); Wang, Bo ()",1,1,,,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09546769.pdf,https://app.dimensions.ai/details/publication/pub.1141306350,46 Information and Computing Sciences,
1158,pub.1119352397,10.48550/arxiv.1812.06625,,,Semi-supervised mp-MRI Data Synthesis with StitchLayer and Auxiliary  Distance Maximization,"In this paper, we address the problem of synthesizing multi-parameter
magnetic resonance imaging (mp-MRI) data, i.e. Apparent Diffusion Coefficients
(ADC) and T2-weighted (T2w), containing clinically significant (CS) prostate
cancer (PCa) via semi-supervised adversarial learning. Specifically, our
synthesizer generates mp-MRI data in a sequential manner: first generating ADC
maps from 128-d latent vectors, followed by translating them to the T2w images.
The synthesizer is trained in a semisupervised manner. In the supervised
training process, a limited amount of paired ADC-T2w images and the
corresponding ADC encodings are provided and the synthesizer learns the paired
relationship by explicitly minimizing the reconstruction losses between
synthetic and real images. To avoid overfitting limited ADC encodings, an
unlimited amount of random latent vectors and unpaired ADC-T2w Images are
utilized in the unsupervised training process for learning the marginal image
distributions of real images. To improve the robustness of synthesizing, we
decompose the difficult task of generating full-size images into several
simpler tasks which generate sub-images only. A StitchLayer is then employed to
fuse sub-images together in an interlaced manner into a full-size image. To
enforce the synthetic images to indeed contain distinguishable CS PCa lesions,
we propose to also maximize an auxiliary distance of Jensen-Shannon divergence
(JSD) between CS and nonCS images. Experimental results show that our method
can effectively synthesize a large variety of mpMRI images which contain
meaningful CS PCa lesions, display a good visual quality and have the correct
paired relationship. Compared to the state-of-the-art synthesis methods, our
method achieves a significant improvement in terms of both visual and
quantitative evaluation metrics.",,,arXiv,,,2018-12-17,2018,,,,,,All OA; Green,Preprint,"Wang, Zhiwei; Lin, Yi; Cheng, Kwang-Ting; Yang, Xin","Wang, Zhiwei (); Lin, Yi (); Cheng, Kwang-Ting (); Yang, Xin ()",,"Wang, Zhiwei (); Lin, Yi (); Cheng, Kwang-Ting (); Yang, Xin ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1119352397,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1157,pub.1136305385,10.48550/arxiv.2103.06030,,,FedDG: Federated Domain Generalization on Medical Image Segmentation via  Episodic Learning in Continuous Frequency Space,"Federated learning allows distributed medical institutions to collaboratively
learn a shared prediction model with privacy protection. While at clinical
deployment, the models trained in federated learning can still suffer from
performance drop when applied to completely unseen hospitals outside the
federation. In this paper, we point out and solve a novel problem setting of
federated domain generalization (FedDG), which aims to learn a federated model
from multiple distributed source domains such that it can directly generalize
to unseen target domains. We present a novel approach, named as Episodic
Learning in Continuous Frequency Space (ELCFS), for this problem by enabling
each client to exploit multi-source data distributions under the challenging
constraint of data decentralization. Our approach transmits the distribution
information across clients in a privacy-protecting way through an effective
continuous frequency space interpolation mechanism. With the transferred
multi-source distributions, we further carefully design a boundary-oriented
episodic learning paradigm to expose the local learning to domain distribution
shifts and particularly meet the challenges of model generalization in medical
image segmentation scenario. The effectiveness of our method is demonstrated
with superior performance over state-of-the-arts and in-depth ablation
experiments on two medical image segmentation tasks. The code is available at
""https://github.com/liuquande/FedDG-ELCFS"".",,,arXiv,,,2021-03-10,2021,,,,,,All OA; Green,Preprint,"Liu, Quande; Chen, Cheng; Qin, Jing; Dou, Qi; Heng, Pheng-Ann","Liu, Quande (); Chen, Cheng (); Qin, Jing (); Dou, Qi (); Heng, Pheng-Ann ()",,"Liu, Quande (); Chen, Cheng (); Qin, Jing (); Dou, Qi (); Heng, Pheng-Ann ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1136305385,46 Information and Computing Sciences; 4611 Machine Learning,
1157,pub.1132685852,10.48550/arxiv.2011.07795,,,Deep learning in magnetic resonance prostate segmentation: A review and  a new perspective,"Prostate radiotherapy is a well established curative oncology modality, which
in future will use Magnetic Resonance Imaging (MRI)-based radiotherapy for
daily adaptive radiotherapy target definition. However the time needed to
delineate the prostate from MRI data accurately is a time consuming process.
Deep learning has been identified as a potential new technology for the
delivery of precision radiotherapy in prostate cancer, where accurate prostate
segmentation helps in cancer detection and therapy. However, the trained models
can be limited in their application to clinical setting due to different
acquisition protocols, limited publicly available datasets, where the size of
the datasets are relatively small. Therefore, to explore the field of prostate
segmentation and to discover a generalisable solution, we review the
state-of-the-art deep learning algorithms in MR prostate segmentation; provide
insights to the field by discussing their limitations and strengths; and
propose an optimised 2D U-Net for MR prostate segmentation. We evaluate the
performance on four publicly available datasets using Dice Similarity
Coefficient (DSC) as performance metric. Our experiments include within dataset
evaluation and cross-dataset evaluation. The best result is achieved by
composite evaluation (DSC of 0.9427 on Decathlon test set) and the poorest
result is achieved by cross-dataset evaluation (DSC of 0.5892, Prostate X
training set, Promise 12 testing set). We outline the challenges and provide
recommendations for future work. Our research provides a new perspective to MR
prostate segmentation and more importantly, we provide standardised experiment
settings for researchers to evaluate their algorithms. Our code is available at
https://github.com/AIEMMU/MRI\_Prostate.",,,arXiv,,,2020-11-16,2020,,,,,,All OA; Green,Preprint,"Gillespie, David; Kendrick, Connah; Boon, Ian; Boon, Cheng; Rattay, Tim; Yap, Moi Hoon","Gillespie, David (); Kendrick, Connah (); Boon, Ian (); Boon, Cheng (); Rattay, Tim (); Yap, Moi Hoon ()",,"Gillespie, David (); Kendrick, Connah (); Boon, Ian (); Boon, Cheng (); Rattay, Tim (); Yap, Moi Hoon ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1132685852,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 51 Physical Sciences; 5105 Medical and Biological Physics,
1156,pub.1147253873,10.48550/arxiv.2204.08467,,,IOP-FL: Inside-Outside Personalization for Federated Medical Image  Segmentation,"Federated learning (FL) allows multiple medical institutions to
collaboratively learn a global model without centralizing all clients data. It
is difficult, if possible at all, for such a global model to commonly achieve
optimal performance for each individual client, due to the heterogeneity of
medical data from various scanners and patient demographics. This problem
becomes even more significant when deploying the global model to unseen clients
outside the FL with new distributions not presented during federated training.
To optimize the prediction accuracy of each individual client for critical
medical tasks, we propose a novel unified framework for both Inside and Outside
model Personalization in FL (IOP-FL). Our inside personalization is achieved by
a lightweight gradient-based approach that exploits the local adapted model for
each client, by accumulating both the global gradients for common knowledge and
local gradients for client-specific optimization. Moreover, and importantly,
the obtained local personalized models and the global model can form a diverse
and informative routing space to personalize a new model for outside FL
clients. Hence, we design a new test-time routing scheme inspired by the
consistency loss with a shape constraint to dynamically incorporate the models,
given the distribution information conveyed by the test data. Our extensive
experimental results on two medical image segmentation tasks present
significant improvements over SOTA methods on both inside and outside
personalization, demonstrating the great potential of our IOP-FL scheme for
clinical practice. Code will be released at https://github.com/med-air/IOP-FL.",,,arXiv,,,2022-04-16,2022,,,,,,All OA; Green,Preprint,"Jiang, Meirui; Yang, Hongzheng; Cheng, Chen; Dou, Qi","Jiang, Meirui (); Yang, Hongzheng (); Cheng, Chen (); Dou, Qi ()",,"Jiang, Meirui (); Yang, Hongzheng (); Cheng, Chen (); Dou, Qi ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147253873,40 Engineering; 46 Information and Computing Sciences; 4611 Machine Learning,
1156,pub.1134724456,10.3390/app11020844,,,Robust Resolution-Enhanced Prostate Segmentation in Magnetic Resonance and Ultrasound Images through Convolutional Neural Networks,"Prostate segmentations are required for an ever-increasing number of medical applications, such as image-based lesion detection, fusion-guided biopsy and focal therapies. However, obtaining accurate segmentations is laborious, requires expertise and, even then, the inter-observer variability remains high. In this paper, a robust, accurate and generalizable model for Magnetic Resonance (MR) and three-dimensional (3D) Ultrasound (US) prostate image segmentation is proposed. It uses a densenet-resnet-based Convolutional Neural Network (CNN) combined with techniques such as deep supervision, checkpoint ensembling and Neural Resolution Enhancement. The MR prostate segmentation model was trained with five challenging and heterogeneous MR prostate datasets (and two US datasets), with segmentations from many different experts with varying segmentation criteria. The model achieves a consistently strong performance in all datasets independently (mean Dice Similarity Coefficient -DSC- above 0.91 for all datasets except for one), outperforming the inter-expert variability significantly in MR (mean DSC of 0.9099 vs. 0.8794). When evaluated on the publicly available Promise12 challenge dataset, it attains a similar performance to the best entries. In summary, the model has the potential of having a significant impact on current prostate procedures, undercutting, and even eliminating, the need of manual segmentations through improvements in terms of robustness, generalizability and output resolution.",,"This work has been partially supported by a doctoral grant of the Spanish Ministry of Innovation and Science, with reference FPU17/01993.",Applied Sciences,,,2021-01-18,2021,2021-01-18,,11,2,844,All OA; Gold,Article,"Pellicer-Valero, Oscar J.; Gonzalez-Perez, Victor; Ramón-Borja, Juan Luis Casanova; García, Isabel Martín; Benito, María Barrios; Gómez, Paula Pelechano; Rubio-Briones, José; Rupérez, María José; Martín-Guerrero, José D.","Pellicer-Valero, Oscar J. (Intelligent Data Analysis Laboratory, Department of Electronic Engineering, ETSE (Engineering School), Universitat de València (UV), Av. Universitat, sn, 46100 Bujassot, Valencia, Spain;, jose.d.martin@uv.es); Gonzalez-Perez, Victor (Department of Radiodiagnosis, Fundación Instituto Valenciano de Oncología (FIVO), Beltrán Báguena, 8, 46009 Valencia, Spain;, vgonzalez@fivo.org, (V.G.-P.);, mismaga99@gmail.com, (I.M.G.);, mar7esc@gmail.com, (M.B.B.);, ppelechano@hotmail.com, (P.P.G.)); Ramón-Borja, Juan Luis Casanova (Department of Medical Physics, Fundación Instituto Valenciano de Oncología (FIVO), Beltrán Báguena, 8, 46009 Valencia, Spain;, jcasanova@fivo.org, (J.L.C.R.-B.);, jrubio@fivo.org, (J.R.-B.)); García, Isabel Martín (Department of Radiodiagnosis, Fundación Instituto Valenciano de Oncología (FIVO), Beltrán Báguena, 8, 46009 Valencia, Spain;, vgonzalez@fivo.org, (V.G.-P.);, mismaga99@gmail.com, (I.M.G.);, mar7esc@gmail.com, (M.B.B.);, ppelechano@hotmail.com, (P.P.G.)); Benito, María Barrios (Department of Radiodiagnosis, Fundación Instituto Valenciano de Oncología (FIVO), Beltrán Báguena, 8, 46009 Valencia, Spain;, vgonzalez@fivo.org, (V.G.-P.);, mismaga99@gmail.com, (I.M.G.);, mar7esc@gmail.com, (M.B.B.);, ppelechano@hotmail.com, (P.P.G.)); Gómez, Paula Pelechano (Department of Radiodiagnosis, Fundación Instituto Valenciano de Oncología (FIVO), Beltrán Báguena, 8, 46009 Valencia, Spain;, vgonzalez@fivo.org, (V.G.-P.);, mismaga99@gmail.com, (I.M.G.);, mar7esc@gmail.com, (M.B.B.);, ppelechano@hotmail.com, (P.P.G.)); Rubio-Briones, José (Department of Medical Physics, Fundación Instituto Valenciano de Oncología (FIVO), Beltrán Báguena, 8, 46009 Valencia, Spain;, jcasanova@fivo.org, (J.L.C.R.-B.);, jrubio@fivo.org, (J.R.-B.)); Rupérez, María José (Centro de Investigación en Ingeniería Mecánica (CIIM), Universitat Politècnica de València (UPV), Camino de Vera, sn, 46022 Valencia, Spain;, mjrupere@upvnet.upv.es); Martín-Guerrero, José D. (Intelligent Data Analysis Laboratory, Department of Electronic Engineering, ETSE (Engineering School), Universitat de València (UV), Av. Universitat, sn, 46100 Bujassot, Valencia, Spain;, jose.d.martin@uv.es)","Pellicer-Valero, Oscar J. (University of Valencia)","Pellicer-Valero, Oscar J. (University of Valencia); Gonzalez-Perez, Victor (Fundación Instituto Valenciano de Oncología); Ramón-Borja, Juan Luis Casanova (Fundación Instituto Valenciano de Oncología); García, Isabel Martín (Fundación Instituto Valenciano de Oncología); Benito, María Barrios (Fundación Instituto Valenciano de Oncología); Gómez, Paula Pelechano (Fundación Instituto Valenciano de Oncología); Rubio-Briones, José (Fundación Instituto Valenciano de Oncología); Rupérez, María José (Universitat Politècnica de València); Martín-Guerrero, José D. (University of Valencia)",3,3,,2.63,https://www.mdpi.com/2076-3417/11/2/844/pdf?version=1611035136,https://app.dimensions.ai/details/publication/pub.1134724456,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 46 Information and Computing Sciences; 51 Physical Sciences,
1096,pub.1145203833,10.1016/j.patcog.2022.108556,,,Learning multi-scale synergic discriminative features for prostate image segmentation,"Although deep convolutional neural networks (DCNNs) have been proposed for prostate MR image segmentation, the effectiveness of these methods is often limited by inadequate semantic discrimination and spatial context modeling. To address these issues, we propose a Multi-scale Synergic Discriminative Network (MSD-Net), which includes a shared encoder, a segmentation decoder, and a boundary detection decoder. We further design the cascaded pyramid convolutional block and residual refinement block, and incorporate them and the channel attention block into MSD-Net to exploit the multi-scale spatial contextual information and semantically consistent features of the gland. We also fuse the features from two decoders to boost the segmentation performance, and introduce the synergic multi-task loss to impose the consistence constraint on the joint segmentation and boundary detection. We evaluated MSD-Net against several prostate segmentation methods on three public datasets and achieved an improved accuracy. Our results indicate that the proposed MSD-Net outperforms existing methods with setting the new state-of-the-art for prostate segmentation in magnetic resonance images.","H. Jia and Y. Xia were supported in part by the National Natural Science Foundation of China under Grants 62171377, in part by the Natural Science Foundation of Ningbo City, China, under Grant 2021J052, in part by the Science and Technology Innovation Committee of Shenzhen Municipality, China, under Grants JCYJ20180306171334997, in part by the CAAI-Huawei MindSpore Open Fund under Grants CAAIXSJLJJ-2020-005B, and in part by the Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University, under Grant CX202042. W. Cai, H. Huang, and their employers received no financial support for the research, authorship, and/or publication of this article. The authors would like to appreciate the efforts devoted to collect and share the PROMISE12, NCI-ISBI13, and 12CVB datasets for comparing interactive and (semi)-automatic segmentation algorithms for MRI of the prostate.",,Pattern Recognition,,,2022-06,2022,,2022-06,126,,108556,Closed,Article,"Jia, Haozhe; Cai, Weidong; Huang, Heng; Xia, Yong","Jia, Haozhe (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an 710072, China; Research Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen 518057, China; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA 15261, USA); Cai, Weidong (School of Computer Science, University of Sydney, Sydney, NSW 2006, Australia); Huang, Heng (Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA 15261, USA; JD Finance America Corporation, Mountain View, California, CA 94043, USA); Xia, Yong (National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an 710072, China; Research Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen 518057, China)","Xia, Yong (Northwestern Polytechnical University; Northwestern Polytechnical University)","Jia, Haozhe (Northwestern Polytechnical University; Northwestern Polytechnical University; University of Pittsburgh); Cai, Weidong (The University of Sydney); Huang, Heng (University of Pittsburgh); Xia, Yong (Northwestern Polytechnical University; Northwestern Polytechnical University)",1,1,,,,https://app.dimensions.ai/details/publication/pub.1145203833,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation; 4611 Machine Learning,
1096,pub.1144118799,10.48550/arxiv.2112.10775,,,HarmoFL: Harmonizing Local and Global Drifts in Federated Learning on  Heterogeneous Medical Images,"Multiple medical institutions collaboratively training a model using
federated learning (FL) has become a promising solution for maximizing the
potential of data-driven models, yet the non-independent and identically
distributed (non-iid) data in medical images is still an outstanding challenge
in real-world practice. The feature heterogeneity caused by diverse scanners or
protocols introduces a drift in the learning process, in both local (client)
and global (server) optimizations, which harms the convergence as well as model
performance. Many previous works have attempted to address the non-iid issue by
tackling the drift locally or globally, but how to jointly solve the two
essentially coupled drifts is still unclear. In this work, we concentrate on
handling both local and global drifts and introduce a new harmonizing framework
called HarmoFL. First, we propose to mitigate the local update drift by
normalizing amplitudes of images transformed into the frequency domain to mimic
a unified imaging setting, in order to generate a harmonized feature space
across local clients. Second, based on harmonized features, we design a client
weight perturbation guiding each local model to reach a flat optimum, where a
neighborhood area of the local optimal solution has a uniformly low loss.
Without any extra communication cost, the perturbation assists the global model
to optimize towards a converged optimal solution by aggregating several local
flat optima. We have theoretically analyzed the proposed method and empirically
conducted extensive experiments on three medical image classification and
segmentation tasks, showing that HarmoFL outperforms a set of recent
state-of-the-art methods with promising convergence behavior. Code is available
at https://github.com/med-air/HarmoFL.",,,arXiv,,,2021-12-20,2021,,,,,,All OA; Green,Preprint,"Jiang, Meirui; Wang, Zirui; Dou, Qi","Jiang, Meirui (); Wang, Zirui (); Dou, Qi ()",,"Jiang, Meirui (); Wang, Zirui (); Dou, Qi ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1144118799,46 Information and Computing Sciences; 4611 Machine Learning,
1096,pub.1124801595,10.48550/arxiv.2002.03366,,,MS-Net: Multi-Site Network for Improving Prostate Segmentation with  Heterogeneous MRI Data,"Automated prostate segmentation in MRI is highly demanded for
computer-assisted diagnosis. Recently, a variety of deep learning methods have
achieved remarkable progress in this task, usually relying on large amounts of
training data. Due to the nature of scarcity for medical images, it is
important to effectively aggregate data from multiple sites for robust model
training, to alleviate the insufficiency of single-site samples. However, the
prostate MRIs from different sites present heterogeneity due to the differences
in scanners and imaging protocols, raising challenges for effective ways of
aggregating multi-site data for network training. In this paper, we propose a
novel multi-site network (MS-Net) for improving prostate segmentation by
learning robust representations, leveraging multiple sources of data. To
compensate for the inter-site heterogeneity of different MRI datasets, we
develop Domain-Specific Batch Normalization layers in the network backbone,
enabling the network to estimate statistics and perform feature normalization
for each site separately. Considering the difficulty of capturing the shared
knowledge from multiple datasets, a novel learning paradigm, i.e.,
Multi-site-guided Knowledge Transfer, is proposed to enhance the kernels to
extract more generic representations from multi-site data. Extensive
experiments on three heterogeneous prostate MRI datasets demonstrate that our
MS-Net improves the performance across all datasets consistently, and
outperforms state-of-the-art methods for multi-site learning.",,,arXiv,,,2020-02-09,2020,,,,,,All OA; Green,Preprint,"Liu, Quande; Dou, Qi; Yu, Lequan; Heng, Pheng Ann","Liu, Quande (); Dou, Qi (); Yu, Lequan (); Heng, Pheng Ann ()",,"Liu, Quande (); Dou, Qi (); Yu, Lequan (); Heng, Pheng Ann ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1124801595,46 Information and Computing Sciences; 4611 Machine Learning,
1096,pub.1118989309,10.48550/arxiv.1802.06260,,,"A Collaborative Computer Aided Diagnosis (C-CAD) System with  Eye-Tracking, Sparse Attentional Model, and Deep Learning","There are at least two categories of errors in radiology screening that can
lead to suboptimal diagnostic decisions and interventions:(i)human fallibility
and (ii)complexity of visual search. Computer aided diagnostic (CAD) tools are
developed to help radiologists to compensate for some of these errors. However,
despite their significant improvements over conventional screening strategies,
most CAD systems do not go beyond their use as second opinion tools due to
producing a high number of false positives, which human interpreters need to
correct. In parallel with efforts in computerized analysis of radiology scans,
several researchers have examined behaviors of radiologists while screening
medical images to better understand how and why they miss tumors, how they
interact with the information in an image, and how they search for unknown
pathology in the images. Eye-tracking tools have been instrumental in exploring
answers to these fundamental questions. In this paper, we aim to develop a
paradigm shift CAD system, called collaborative CAD (C-CAD), that unifies both
of the above mentioned research lines: CAD and eye-tracking. We design an
eye-tracking interface providing radiologists with a real radiology reading
room experience. Then, we propose a novel algorithm that unifies eye-tracking
data and a CAD system. Specifically, we present a new graph based clustering
and sparsification algorithm to transform eye-tracking data (gaze) into a
signal model to interpret gaze patterns quantitatively and qualitatively. The
proposed C-CAD collaborates with radiologists via eye-tracking technology and
helps them to improve diagnostic decisions. The C-CAD learns radiologists'
search efficiency by processing their gaze patterns. To do this, the C-CAD uses
a deep learning algorithm in a newly designed multi-task learning platform to
segment and diagnose cancers simultaneously.",,,arXiv,,,2018-02-17,2018,,,,,,All OA; Green,Preprint,"Khosravan, Naji; Celik, Haydar; Turkbey, Baris; Jones, Elizabeth; Wood, Bradford; Bagci, Ulas","Khosravan, Naji (); Celik, Haydar (); Turkbey, Baris (); Jones, Elizabeth (); Wood, Bradford (); Bagci, Ulas ()",,"Khosravan, Naji (); Celik, Haydar (); Turkbey, Baris (); Jones, Elizabeth (); Wood, Bradford (); Bagci, Ulas ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1118989309,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
1096,pub.1092060928,10.1101/197517,,,Deep Convolutional Neural Networks Enable Discrimination of Heterogeneous Digital Pathology Images,"Pathological evaluation of tumor tissue is pivotal for diagnosis in cancer patients and automated image analysis approaches have great potential to increase precision of diagnosis and help reduce human error. In this study, we utilize various computational methods based on convolutional neural networks (CNN) and build a stand-alone pipeline to effectively classify different histopathology images across different types of cancer. In particular, we demonstrate the utility of our pipeline to discriminate between two subtypes of lung cancer, four biomarkers of bladder cancer, and five biomarkers of breast cancer. In addition, we apply our pipeline to discriminate among four immunohistochemistry (IHC) staining scores of bladder and breast cancers.
Our classification pipeline utilizes a basic architecture of CNN, Google's Inceptions within three training strategies, and an ensemble of two state-of-the-art algorithms, Inception and ResNet. These strategies include training the last layer of Google's Inceptions, training the network from scratch, and fine-tunning the parameters for our data using two pre-trained version of Google's Inception architectures, Inception-V1 and Inception-V3.
We demonstrate the power of deep learning approaches for identifying cancer subtypes, and the robustness of Google's Inceptions even in presence of extensive tumor heterogeneity. Our pipeline on average achieved accuracies of 100% , 92%, 95%, and 69% for discrimination of various cancer types, subtypes, biomarkers, and scores, respectively. Our pipeline and related documentation is freely available at https://github.com/ih-lab/CNN_Smoothie",,,bioRxiv,,,2017-10-02,2017,2017-10-02,,,,197517,All OA; Green,Preprint,"Khosravi, Pegah; Kazemi, Ehsan; Imielinski, Marcin; Elemento, Olivier; Hajirasouliha, Iman","Khosravi, Pegah (Institute for Computational Biomedicine, Weill Cornell Medical College, NY, USA; Department of Physiology and Biophysics, Weill Cornell Medicine, New York, NY, USA); Kazemi, Ehsan (Yale Institute for Network Science, Yale University, New Haven, CT, USA); Imielinski, Marcin (Englander Institute for Precision Medicine, Weill Cornell Medical College, NY, USA; Department of Pathology and Laboratory Medicine, Weill Cornell Medical College, NY, USA; The New York Genome Center, NY, USA; The Meyer Cancer Center, Weill Cornell Medicine, New York, NY, USA); Elemento, Olivier (Institute for Computational Biomedicine, Weill Cornell Medical College, NY, USA; Department of Physiology and Biophysics, Weill Cornell Medicine, New York, NY, USA; Englander Institute for Precision Medicine, Weill Cornell Medical College, NY, USA; The Meyer Cancer Center, Weill Cornell Medicine, New York, NY, USA); Hajirasouliha, Iman (Institute for Computational Biomedicine, Weill Cornell Medical College, NY, USA; Department of Physiology and Biophysics, Weill Cornell Medicine, New York, NY, USA; Englander Institute for Precision Medicine, Weill Cornell Medical College, NY, USA; The Meyer Cancer Center, Weill Cornell Medicine, New York, NY, USA)","Elemento, Olivier (Cornell University; Cornell University; Cornell University; Cornell University); Hajirasouliha, Iman (Cornell University; Cornell University; Cornell University; Cornell University)","Khosravi, Pegah (Cornell University; Cornell University); Kazemi, Ehsan (Yale University); Imielinski, Marcin (Cornell University; Cornell University; New York Genome Center; Cornell University); Elemento, Olivier (Cornell University; Cornell University; Cornell University; Cornell University); Hajirasouliha, Iman (Cornell University; Cornell University; Cornell University; Cornell University)",3,0,,0.71,http://www.thelancet.com/article/S2352396417305078/pdf,https://app.dimensions.ai/details/publication/pub.1092060928,32 Biomedical and Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences; 4611 Machine Learning,3 Good Health and Well Being
1095,pub.1148282795,10.48550/arxiv.2205.13723,,,DLTTA: Dynamic Learning Rate for Test-time Adaptation on Cross-domain  Medical Images,"Test-time adaptation (TTA) has increasingly been an important topic to
efficiently tackle the cross-domain distribution shift at test time for medical
images from different institutions. Previous TTA methods have a common
limitation of using a fixed learning rate for all the test samples. Such a
practice would be sub-optimal for TTA, because test data may arrive
sequentially therefore the scale of distribution shift would change frequently.
To address this problem, we propose a novel dynamic learning rate adjustment
method for test-time adaptation, called DLTTA, which dynamically modulates the
amount of weights update for each test image to account for the differences in
their distribution shift. Specifically, our DLTTA is equipped with a memory
bank based estimation scheme to effectively measure the discrepancy of a given
test sample. Based on this estimated discrepancy, a dynamic learning rate
adjustment strategy is then developed to achieve a suitable degree of
adaptation for each test sample. The effectiveness and general applicability of
our DLTTA is extensively demonstrated on three tasks including retinal optical
coherence tomography (OCT) segmentation, histopathological image
classification, and prostate 3D MRI segmentation. Our method achieves effective
and fast test-time adaptation with consistent performance improvement over
current state-of-the-art test-time adaptation methods. Code is available at:
https://github.com/med-air/DLTTA.",,,arXiv,,,2022-05-26,2022,,,,,,All OA; Green,Preprint,"Yang, Hongzheng; Chen, Cheng; Jiang, Meirui; Liu, Quande; Cao, Jianfeng; Heng, Pheng Ann; Dou, Qi","Yang, Hongzheng (); Chen, Cheng (); Jiang, Meirui (); Liu, Quande (); Cao, Jianfeng (); Heng, Pheng Ann (); Dou, Qi ()",,"Yang, Hongzheng (); Chen, Cheng (); Jiang, Meirui (); Liu, Quande (); Cao, Jianfeng (); Heng, Pheng Ann (); Dou, Qi ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1148282795,46 Information and Computing Sciences; 4611 Machine Learning,
1095,pub.1118174195,10.48550/arxiv.1904.08254,,,USE-Net: incorporating Squeeze-and-Excitation blocks into U-Net for  prostate zonal segmentation of multi-institutional MRI datasets,"Prostate cancer is the most common malignant tumors in men but prostate
Magnetic Resonance Imaging (MRI) analysis remains challenging. Besides whole
prostate gland segmentation, the capability to differentiate between the blurry
boundary of the Central Gland (CG) and Peripheral Zone (PZ) can lead to
differential diagnosis, since tumor's frequency and severity differ in these
regions. To tackle the prostate zonal segmentation task, we propose a novel
Convolutional Neural Network (CNN), called USE-Net, which incorporates
Squeeze-and-Excitation (SE) blocks into U-Net. Especially, the SE blocks are
added after every Encoder (Enc USE-Net) or Encoder-Decoder block (Enc-Dec
USE-Net). This study evaluates the generalization ability of CNN-based
architectures on three T2-weighted MRI datasets, each one consisting of a
different number of patients and heterogeneous image characteristics, collected
by different institutions. The following mixed scheme is used for
training/testing: (i) training on either each individual dataset or multiple
prostate MRI datasets and (ii) testing on all three datasets with all possible
training/testing combinations. USE-Net is compared against three
state-of-the-art CNN-based architectures (i.e., U-Net, pix2pix, and Mixed-Scale
Dense Network), along with a semi-automatic continuous max-flow model. The
results show that training on the union of the datasets generally outperforms
training on each dataset separately, allowing for both intra-/cross-dataset
generalization. Enc USE-Net shows good overall generalization under any
training condition, while Enc-Dec USE-Net remarkably outperforms the other
methods when trained on all datasets. These findings reveal that the SE blocks'
adaptive feature recalibration provides excellent cross-dataset generalization
when testing is performed on samples of the datasets used during training.",,,arXiv,,,2019-04-17,2019,,,,,,All OA; Green,Preprint,"Rundo, Leonardo; Han, Changhee; Nagano, Yudai; Zhang, Jin; Hataya, Ryuichiro; Militello, Carmelo; Tangherloni, Andrea; Nobile, Marco S.; Ferretti, Claudio; Besozzi, Daniela; Gilardi, Maria Carla; Vitabile, Salvatore; Mauri, Giancarlo; Nakayama, Hideki; Cazzaniga, Paolo","Rundo, Leonardo (); Han, Changhee (); Nagano, Yudai (); Zhang, Jin (); Hataya, Ryuichiro (); Militello, Carmelo (); Tangherloni, Andrea (); Nobile, Marco S. (); Ferretti, Claudio (); Besozzi, Daniela (); Gilardi, Maria Carla (); Vitabile, Salvatore (); Mauri, Giancarlo (); Nakayama, Hideki (); Cazzaniga, Paolo ()",,"Rundo, Leonardo (); Han, Changhee (); Nagano, Yudai (); Zhang, Jin (); Hataya, Ryuichiro (); Militello, Carmelo (); Tangherloni, Andrea (); Nobile, Marco S. (); Ferretti, Claudio (); Besozzi, Daniela (); Gilardi, Maria Carla (); Vitabile, Salvatore (); Mauri, Giancarlo (); Nakayama, Hideki (); Cazzaniga, Paolo ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1118174195,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences,
1094,pub.1151488479,10.1016/b978-0-32-399851-2.00016-8,,,Chapter 8 Domain generalization of deep networks for medical image segmentation via meta learning,"The generalization capacity of deep models is crucial for real-world clinical deployment, where domain shifts usually exist due to changes of image acquisition conditions. This chapter presents domain generalization methods for medical image segmentation with meta learning technique, aiming to generalize the deep models learned from multiple source domains to unseen target domains. We present solutions under two realistic scenarios, i.e., centralized training and decentralized federated training. For the first scenario, we establish meta learning with multidomain data to construct virtual training and testing domains and enhance the model optimization towards simulated domain shifts with two shape-aware metaobjectives. Under the second scenario, a frequency-space interpolation mechanism is devised to enable each client access the multisource distributions under the constraint of data decentralization. The meta learning scheme is then established locally with explicit feature regularization imposed around the ambiguous regions to promote generalizable model parameters for segmentation problems. Experimental results on two medical image segmentation tasks have validated the effectiveness of our methods on the generalization problems under the two realistic training scenarios.",,,,Meta Learning With Medical Imaging and Health Informatics Applications,,2023,2023,,2023,,,117-139,Closed,Chapter,"Liu, Quande; Dou, Qi; Chen, Cheng; Heng, Pheng-Ann","Liu, Quande (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China); Dou, Qi (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China); Chen, Cheng (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China); Heng, Pheng-Ann (Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China)",,"Liu, Quande (Chinese University of Hong Kong); Dou, Qi (Chinese University of Hong Kong); Chen, Cheng (Chinese University of Hong Kong); Heng, Pheng-Ann (Chinese University of Hong Kong)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1151488479,46 Information and Computing Sciences; 4611 Machine Learning,
1094,pub.1101405492,10.1016/j.imu.2018.03.002,,,Documenting and predicting topic changes in Computers in Biology and Medicine: A bibliometric keyword analysis from 1990 to 2017,"The Computers in Biology and Medicine (CBM) journal promotes the use of computing machinery in the fields of bioscience and medicine. Since the first volume in 1970, the importance of computers in these fields has grown dramatically, this is evident in the diversification of topics and an increase in the publication rate. In this study, we quantify both change and diversification of topics covered in. This is done by analysing the author supplied keywords, since they were electronically captured in 1990. The analysis starts by selecting 40 keywords, related to Medical (M) (7), Data (D) (10), Feature (F) (17) and (AI) (6) methods. Automated keyword clustering shows the statistical connection between the selected keywords. We found that the three most popular topics in CBM are: Support Vector Machine (SVM), Electroencephalography (EEG) and IMAGE PROCESSING. In a separate analysis step, we bagged the selected keywords into sequential one year time slices and calculated the normalized appearance. The results were visualised with graphs that indicate the CBM topic changes. These graphs show that there was a transition from Artificial Neural Network (ANN) to SVM. In 2006 SVM replaced ANN as the most important AI algorithm. Our investigation helps the editorial board to manage and embrace topic change. Furthermore, our analysis is interesting for the general reader, as the results can help them to adjust their research directions.",,,Informatics in Medicine Unlocked,,,2018,2018,,2018,11,,15-27,All OA; Gold,Article,"Faust, Oliver","Faust, Oliver (Department of Engineering and Mathematics, Sheffield Hallam University, UK)",,"Faust, Oliver (Sheffield Hallam University)",15,6,,5.19,https://doi.org/10.1016/j.imu.2018.03.002,https://app.dimensions.ai/details/publication/pub.1101405492,42 Health Sciences; 4203 Health Services and Systems,
1092,pub.1142635552,10.1007/978-3-030-73565-4_4,,,Image Fusion Principles: Theory,"Imaging is an integral component in the investigation of urologic disease. Continued advancement in both hardware and software tools have given rise to novel image modalities and innovative approaches for diagnosis and intervention. An appreciation of the fundamentals of imaging techniques is essential to enable Urologists to employ them in routine clinical practice. The objective of this chapter is to review the current state of the art regarding techniques in imaging and their applications in urologic interventions, with special attention to registration, image fusion, and tracking in diagnostic and therapeutic implementation.",,,,Interventional Urology,,2021-11-18,2021,2021-11-18,2021,,,67-80,Closed,Chapter,"Alameddine, Mitchell B.; Rastinehad, Ardeshir R.; George, Arvin K.","Alameddine, Mitchell B. (University of Michigan Medical School, Ann Arbor, MI, USA); Rastinehad, Ardeshir R. (Barbara and Donald Zucker School of Medicine at Hofstra-Northwell, New York, NY, USA; Smith Institute for Urology at Lenox Hill, New York, NY, USA; Northwell Health System, New York, NY, USA); George, Arvin K. (Prostate Cancer Programs, Division of Urologic Oncology, Department of Urology, Michigan Urological Surgery Improvement Collaborative, Michigan Medicine, Ann Arbor, MI, USA)","George, Arvin K. (Michigan Medicine)","Alameddine, Mitchell B. (University of Michigan–Ann Arbor); Rastinehad, Ardeshir R. (Donald & Barbara Zucker School of Medicine at Hofstra/Northwell; Northwell Health; Northwell Health); George, Arvin K. (Michigan Medicine)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1142635552,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,
1039,pub.1123972048,10.3390/app10010338,,,A Hybrid End-to-End Approach Integrating Conditional Random Fields into CNNs for Prostate Cancer Detection on MRI,"Prostate Cancer (PCa) is the most common oncological disease in Western men. Even though a growing effort has been carried out by the scientific community in recent years, accurate and reliable automated PCa detection methods on multiparametric Magnetic Resonance Imaging (mpMRI) are still a compelling issue. In this work, a Deep Neural Network architecture is developed for the task of classifying clinically significant PCa on non-contrast-enhanced MR images. In particular, we propose the use of Conditional Random Fields as a Recurrent Neural Network (CRF-RNN) to enhance the classification performance of XmasNet, a Convolutional Neural Network (CNN) architecture specifically tailored to the PROSTATEx17 Challenge. The devised approach builds a hybrid end-to-end trainable network, CRF-XmasNet, composed of an initial CNN component performing feature extraction and a CRF-based probabilistic graphical model component for structured prediction, without the need for two separate training procedures. Experimental results show the suitability of this method in terms of classification accuracy and training time, even though the high-variability of the observed results must be reduced before transferring the resulting architecture to a clinical environment. Interestingly, the use of CRFs as a separate postprocessing method achieves significantly lower performance with respect to the proposed hybrid end-to-end approach. The proposed hybrid end-to-end CRF-RNN approach yields excellent peak performance for all the CNN architectures taken into account, but it shows a high-variability, thus requiring future investigation on the integration of CRFs into a CNN.",,"This work was partially supported by projects UID/MULTI/00308/2019 and by the European Regional Development Fund through the COMPETE 2020 Programme, FCT—Portuguese Foundation for Science and Technology and Regional Operational Program of the Center Region (CENTRO2020) within project MAnAGER (POCI-01-0145-FEDER-028040). This work was also partially supported by national funds through FCT (Fundação para a Ciência e a Tecnologia) under project DSAIPA/DS/0022/2018 (GADgET) and by the financial support from the Slovenian Research Agency (research core funding No. P5-0410). This work was partially supported by The Mark Foundation for Cancer Research and Cancer Research UK Cambridge Centre [C9685/A25177]. Additional support has been provided by the National Institute of Health Research (NIHR) Cambridge Biomedical Research Centre. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health and Social Care.",Applied Sciences,,,2020-01-02,2020,2020-01-02,,10,1,338,All OA; Gold,Article,"Lapa, Paulo; Castelli, Mauro; Gonçalves, Ivo; Sala, Evis; Rundo, Leonardo","Lapa, Paulo (Nova Information Management School (NOVA IMS), Campus de Campolide, Universidade Nova de Lisboa, 1070-332 Lisboa, Portugal;, plapa@novaims.unl.pt); Castelli, Mauro (Nova Information Management School (NOVA IMS), Campus de Campolide, Universidade Nova de Lisboa, 1070-332 Lisboa, Portugal;, plapa@novaims.unl.pt); Gonçalves, Ivo (INESC Coimbra, DEEC, University of Coimbra, Pólo 2, 3030-290 Coimbra, Portugal;, ivogoncalves77@gmail.com); Sala, Evis (Department of Radiology, University of Cambridge, Cambridge CB2 0QQ, UK;, es220@cam.ac.uk, (E.S.);, lr495@cam.ac.uk, (L.R.); Cancer Research UK Cambridge Centre, Cambridge CB2 0RE, UK); Rundo, Leonardo (Department of Radiology, University of Cambridge, Cambridge CB2 0QQ, UK;, es220@cam.ac.uk, (E.S.);, lr495@cam.ac.uk, (L.R.); Cancer Research UK Cambridge Centre, Cambridge CB2 0RE, UK)","Castelli, Mauro (Universidade Nova de Lisboa)","Lapa, Paulo (Universidade Nova de Lisboa); Castelli, Mauro (Universidade Nova de Lisboa); Gonçalves, Ivo (University of Coimbra); Sala, Evis (University of Cambridge; Cancer Research UK Cambridge Center); Rundo, Leonardo (University of Cambridge; Cancer Research UK Cambridge Center)",14,12,,6.35,https://www.mdpi.com/2076-3417/10/1/338/pdf?version=1578465829,https://app.dimensions.ai/details/publication/pub.1123972048,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis; 46 Information and Computing Sciences; 4611 Machine Learning,
1038,pub.1101019158,10.1016/j.matcom.2018.02.001,,,Hybrid intelligent approach for diagnosis of the lung nodule from CT images using spatial kernelized fuzzy c-means and ensemble learning,"Lung cancer is one of the most common forms of cancer leading to over a million deaths per year throughout the world. The aim of this paper is to identify the pulmonary nodules in computed tomography (CT) images of the lung using a hybrid intelligent approach. At first, the proposed approach utilizes a type-II fuzzy algorithm to improve the quality of raw CT images. Then, a novel segmentation algorithm based on fuzzy c-means clustering, called modified spatial kernelized fuzzy c-means (MSFCM) clustering, is offered in order to achieve another representation of lung regions through an optimization methodology. Next, nodule candidates are detected among all available objects in the lung regions by a morphological procedure. This is followed by extracting significant statistical and morphological features from such nodule candidates and finally, an ensemble of three classifiers comprising Multilayer Perceptron (MLP), K-Nearest Neighbor (KNN), and Support Vector Machine (SVM) is employed for the actual diagnosis and determining whether the nodule candidate is nodule (cancerous) or non-nodule (healthy). The effectiveness of the hybrid intelligent approach is evaluated using a public dataset for lung CT images, viz.: Lung Image Database Consortium (LIDC). The experimental results positively demonstrate that the modified spatial kernelized FCM segmentation is superior to the other techniques existing in the literature. More importantly, a number of useful performance measurements in medical applications including accuracy, sensitivity, specificity, confusion matrix, as well as the area under the Receiver Operating Characteristic (ROC) curve are computed. The obtained results confirm the promising performance of the proposed hybrid approach in undertaking pulmonary nodules diagnosis.",,,Mathematics and Computers in Simulation,,,2018-07,2018,,2018-07,149,,48-68,Closed,Article,"Farahani, Farzad Vasheghani; Ahmadi, Abbas; Zarandi, Mohammad Hossein Fazel","Farahani, Farzad Vasheghani (Department of Industrial Engineering and Management Systems, Amirkabir University of Technology, Tehran, Iran); Ahmadi, Abbas (Department of Industrial Engineering and Management Systems, Amirkabir University of Technology, Tehran, Iran); Zarandi, Mohammad Hossein Fazel (Department of Industrial Engineering and Management Systems, Amirkabir University of Technology, Tehran, Iran)","Ahmadi, Abbas (Amirkabir University of Technology)","Farahani, Farzad Vasheghani (Amirkabir University of Technology); Ahmadi, Abbas (Amirkabir University of Technology); Zarandi, Mohammad Hossein Fazel (Amirkabir University of Technology)",41,24,,12.95,,https://app.dimensions.ai/details/publication/pub.1101019158,46 Information and Computing Sciences; 4602 Artificial Intelligence; 4603 Computer Vision and Multimedia Computation; 4605 Data Management and Data Science,
1035,pub.1150069389,10.48550/arxiv.2208.03217,,,Distance-based detection of out-of-distribution silent failures for  Covid-19 lung lesion segmentation,"Automatic segmentation of ground glass opacities and consolidations in chest
computer tomography (CT) scans can potentially ease the burden of radiologists
during times of high resource utilisation. However, deep learning models are
not trusted in the clinical routine due to failing silently on
out-of-distribution (OOD) data. We propose a lightweight OOD detection method
that leverages the Mahalanobis distance in the feature space and seamlessly
integrates into state-of-the-art segmentation pipelines. The simple approach
can even augment pre-trained models with clinically relevant uncertainty
quantification. We validate our method across four chest CT distribution shifts
and two magnetic resonance imaging applications, namely segmentation of the
hippocampus and the prostate. Our results show that the proposed method
effectively detects far- and near-OOD samples across all explored scenarios.",,,arXiv,,,2022-08-05,2022,,,,,,All OA; Green,Preprint,"Gonzalez, Camila; Gotkowski, Karol; Fuchs, Moritz; Bucher, Andreas; Dadras, Armin; Fischbach, Ricarda; Kaltenborn, Isabel; Mukhopadhyay, Anirban","Gonzalez, Camila (); Gotkowski, Karol (); Fuchs, Moritz (); Bucher, Andreas (); Dadras, Armin (); Fischbach, Ricarda (); Kaltenborn, Isabel (); Mukhopadhyay, Anirban ()",,"Gonzalez, Camila (); Gotkowski, Karol (); Fuchs, Moritz (); Bucher, Andreas (); Dadras, Armin (); Fischbach, Ricarda (); Kaltenborn, Isabel (); Mukhopadhyay, Anirban ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1150069389,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 46 Information and Computing Sciences,
1034,pub.1146477071,10.48550/arxiv.2203.10144,,,Closing the Generalization Gap of Cross-silo Federated Medical Image  Segmentation,"Cross-silo federated learning (FL) has attracted much attention in medical
imaging analysis with deep learning in recent years as it can resolve the
critical issues of insufficient data, data privacy, and training efficiency.
However, there can be a generalization gap between the model trained from FL
and the one from centralized training. This important issue comes from the
non-iid data distribution of the local data in the participating clients and is
well-known as client drift. In this work, we propose a novel training framework
FedSM to avoid the client drift issue and successfully close the generalization
gap compared with the centralized training for medical image segmentation tasks
for the first time. We also propose a novel personalized FL objective
formulation and a new method SoftPull to solve it in our proposed framework
FedSM. We conduct rigorous theoretical analysis to guarantee its convergence
for optimizing the non-convex smooth objective function. Real-world medical
image segmentation experiments using deep FL validate the motivations and
effectiveness of our proposed method.",,,arXiv,,,2022-03-18,2022,,,,,,All OA; Green,Preprint,"Xu, An; Li, Wenqi; Guo, Pengfei; Yang, Dong; Roth, Holger; Hatamizadeh, Ali; Zhao, Can; Xu, Daguang; Huang, Heng; Xu, Ziyue","Xu, An (); Li, Wenqi (); Guo, Pengfei (); Yang, Dong (); Roth, Holger (); Hatamizadeh, Ali (); Zhao, Can (); Xu, Daguang (); Huang, Heng (); Xu, Ziyue ()",,"Xu, An (); Li, Wenqi (); Guo, Pengfei (); Yang, Dong (); Roth, Holger (); Hatamizadeh, Ali (); Zhao, Can (); Xu, Daguang (); Huang, Heng (); Xu, Ziyue ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1146477071,46 Information and Computing Sciences; 4611 Machine Learning,
986,pub.1119737542,10.1016/j.neucom.2019.07.006,,,USE-Net: Incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets,"Prostate cancer is the most common malignant tumors in men but prostate Magnetic Resonance Imaging (MRI) analysis remains challenging. Besides whole prostate gland segmentation, the capability to differentiate between the blurry boundary of the Central Gland (CG) and Peripheral Zone (PZ) can lead to differential diagnosis, since the frequency and severity of tumors differ in these regions. To tackle the prostate zonal segmentation task, we propose a novel Convolutional Neural Network (CNN), called USE-Net, which incorporates Squeeze-and-Excitation (SE) blocks into U-Net, i.e., one of the most effective CNNs in biomedical image segmentation. Especially, the SE blocks are added after every Encoder (Enc USE-Net) or Encoder-Decoder block (Enc-Dec USE-Net). This study evaluates the generalization ability of CNN-based architectures on three T2-weighted MRI datasets, each one consisting of a different number of patients and heterogeneous image characteristics, collected by different institutions. The following mixed scheme is used for training/testing: (i) training on either each individual dataset or multiple prostate MRI datasets and (ii) testing on all three datasets with all possible training/testing combinations. USE-Net is compared against three state-of-the-art CNN-based architectures (i.e., U-Net, pix2pix, and Mixed-Scale Dense Network), along with a semi-automatic continuous max-flow model. The results show that training on the union of the datasets generally outperforms training on each dataset separately, allowing for both intra-/cross-dataset generalization. Enc USE-Net shows good overall generalization under any training condition, while Enc-Dec USE-Net remarkably outperforms the other methods when trained on all datasets. These findings reveal that the SE blocks’ adaptive feature recalibration provides excellent cross-dataset generalization when testing is performed on samples of the datasets used during training. Therefore, we should consider multi-dataset training and SE blocks together as mutually indispensable methods to draw out each other’s full potential. In conclusion, adaptive mechanisms (e.g., feature recalibration) may be a valuable solution in medical imaging applications involving multi-institutional settings.",,,Neurocomputing,,,2019-11,2019,,2019-11,365,,31-43,All OA; Green,Article,"Rundo, Leonardo; Han, Changhee; Nagano, Yudai; Zhang, Jin; Hataya, Ryuichiro; Militello, Carmelo; Tangherloni, Andrea; Nobile, Marco S.; Ferretti, Claudio; Besozzi, Daniela; Gilardi, Maria Carla; Vitabile, Salvatore; Mauri, Giancarlo; Nakayama, Hideki; Cazzaniga, Paolo","Rundo, Leonardo (Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan 20126, Italy; Institute of Molecular Bioimaging and Physiology, Italian National Research Council, Cefalú (PA) 90015, Italy; Department of Radiology, University of Cambridge, Cambridge CB2 0QQ, UK; Cancer Research UK Cambridge Centre, Cambridge CB2 0RE, UK); Han, Changhee (Graduate School of Information Science and Technology, The University of Tokyo, Tokyo 113-8656, Japan); Nagano, Yudai (Graduate School of Information Science and Technology, The University of Tokyo, Tokyo 113-8656, Japan); Zhang, Jin (Graduate School of Information Science and Technology, The University of Tokyo, Tokyo 113-8656, Japan); Hataya, Ryuichiro (Graduate School of Information Science and Technology, The University of Tokyo, Tokyo 113-8656, Japan); Militello, Carmelo (Institute of Molecular Bioimaging and Physiology, Italian National Research Council, Cefalú (PA) 90015, Italy); Tangherloni, Andrea (Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan 20126, Italy; Department of Haematology, University of Cambridge, Cambridge CB2 0XY, UK; Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Hinxton CB10 1SA, UK); Nobile, Marco S. (Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan 20126, Italy; SYSBIO.IT Centre of Systems Biology, Milan 20126 Italy); Ferretti, Claudio (Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan 20126, Italy); Besozzi, Daniela (Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan 20126, Italy); Gilardi, Maria Carla (Institute of Molecular Bioimaging and Physiology, Italian National Research Council, Cefalú (PA) 90015, Italy); Vitabile, Salvatore (Department of Biomedicine, Neuroscience and Advanced Diagnostics, University of Palermo, Palermo 90127 Italy); Mauri, Giancarlo (Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan 20126, Italy; SYSBIO.IT Centre of Systems Biology, Milan 20126 Italy); Nakayama, Hideki (Graduate School of Information Science and Technology, The University of Tokyo, Tokyo 113-8656, Japan); Cazzaniga, Paolo (Department of Human and Social Sciences, University of Bergamo, Bergamo 24129, Italy; SYSBIO.IT Centre of Systems Biology, Milan 20126 Italy)","Rundo, Leonardo (University of Milano-Bicocca; Institute of Molecular Bioimaging and Physiology; University of Cambridge; Cancer Research UK Cambridge Center)","Rundo, Leonardo (University of Milano-Bicocca; Institute of Molecular Bioimaging and Physiology; University of Cambridge; Cancer Research UK Cambridge Center); Han, Changhee (University of Tokyo); Nagano, Yudai (University of Tokyo); Zhang, Jin (University of Tokyo); Hataya, Ryuichiro (University of Tokyo); Militello, Carmelo (Institute of Molecular Bioimaging and Physiology); Tangherloni, Andrea (University of Milano-Bicocca; University of Cambridge; Wellcome Sanger Institute); Nobile, Marco S. (University of Milano-Bicocca); Ferretti, Claudio (University of Milano-Bicocca); Besozzi, Daniela (University of Milano-Bicocca); Gilardi, Maria Carla (Institute of Molecular Bioimaging and Physiology); Vitabile, Salvatore (University of Palermo); Mauri, Giancarlo (University of Milano-Bicocca); Nakayama, Hideki (University of Tokyo); Cazzaniga, Paolo (University of Bergamo)",156,123,,,http://arxiv.org/pdf/1904.08254,https://app.dimensions.ai/details/publication/pub.1119737542,46 Information and Computing Sciences,
983,pub.1154404820,10.1109/tmi.2023.3235757,,,FedDM: Federated Weakly Supervised Segmentation via Annotation Calibration and Gradient De-conflicting,"Weakly supervised segmentation (WSS) aims to exploit weak forms of annotations to achieve the segmentation training, thereby reducing the burden on annotation. However, existing methods rely on large-scale centralized datasets, which are difficult to construct due to privacy concerns on medical data. Federated learning (FL) provides a cross-site training paradigm and shows great potential to address this problem. In this work, we represent the first effort to formulate federated weakly supervised segmentation (FedWSS) and propose a novel Federated Drift Mitigation (FedDM) framework to learn segmentation models across multiple sites without sharing their raw data. FedDM is devoted to solving two main challenges (i.e., local drift on client-side optimization and global drift on server-side aggregation) caused by weak supervision signals in FL setting via Collaborative Annotation Calibration (CAC) and Hierarchical Gradient De-conflicting (HGD). To mitigate the local drift, CAC customizes a distal peer and a proximal peer for each client via a Monte Carlo sampling strategy, and then employs inter-client knowledge agreement and disagreement to recognize clean labels and correct noisy labels, respectively. Moreover, in order to alleviate the global drift, HGD online builds a client hierarchy under the guidance of history gradient of the global model in each communication round. Through de-conflicting clients under the same parent nodes from bottom layers to top layers, HGD achieves robust gradient aggregation at the server side. Furthermore, we theoretically analyze FedDM and conduct extensive experiments on public datasets. The experimental results demonstrate the superior performance of our method compared with state-of-the-art approaches. The source code is available at https://github.com/CityU-AIM-Group/FedDM.",,,IEEE Transactions on Medical Imaging,,,2023-01-10,2023,2023-01-10,,PP,99,1-1,Closed,Article,"Zhu, Meilu; Chen, Zhen; Yuan, Yixuan","Zhu, Meilu (Department of Mechanical Engineering, City University of Hong Kong, China); Chen, Zhen (Centre for Artificial Intelligence and Robotics (CAIR), HKISI, CAS, China); Yuan, Yixuan (Department of Electronic Engineering, Chinese University of Hong Kong, China)",,"Zhu, Meilu (City University of Hong Kong); Chen, Zhen (Chinese Academy of Sciences); Yuan, Yixuan (Chinese University of Hong Kong)",0,0,,,,https://app.dimensions.ai/details/publication/pub.1154404820,46 Information and Computing Sciences; 4611 Machine Learning,
983,pub.1111990223,10.1201/9780429434334-16,,,Computer-Aided Diagnosis of Prostate Magnetic Resonance Imaging,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,295-316,Closed,Chapter,"Giannini, Valentina; Mazzetti, Simone; Russo, Filippo; Regge, Daniele","Giannini, Valentina (); Mazzetti, Simone (); Russo, Filippo (); Regge, Daniele ()",,"Giannini, Valentina (); Mazzetti, Simone (); Russo, Filippo (); Regge, Daniele ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1111990223,,
983,pub.1106330140,10.1007/s11042-018-6487-2,,,A survey of denoising techniques for multi-parametric prostate MRI,"Denoising is one of active area of research in the image-processing domain since last decade. Internal and external conditions of acquisition device are the main source of noise in an image during the procurement process, which is often impossible to avoid in practical situations. Since many different image denoising algorithms have been recommended till date, but the issue of noise elimination remains an undefended challenge. The main objective of this paper is to study and analyze the behavior of different denoising filters for multi-parametric (mp) prostate MRI so that the appropriate filter can be selected unanimously. This study evaluates the performance of fifteen denoising filters (Anisotropic, Median, Wiener, Gaussian, Mean, Wavelet, Contourlet, Bilateral, Curvelet, WHMT, NLM, GFOE, LMMSE, CURE-LET and ARF) w.r.t mp-prostate MRI i.e. T2w, DCE and DWI images in the presence of Gaussian and Rician noise. Evaluation is done in both variable and fixed level of noise. Both subjective and objective quality assessment parameters are considered for determining the final rating of filters executed over 300 mp-MRI images. This study concludes that anisotropic and NLM filter should be opted for denoising task because of their structural and other crucial details preserving capability.",,,Multimedia Tools and Applications,,,2018-08-24,2018,2018-08-24,2019-05,78,10,12689-12722,Closed,Article,"Garg, Gaurav; Juneja, Mamta","Garg, Gaurav (Department of Computer Science and Engineering, University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Juneja, Mamta (Department of Computer Science and Engineering, University Institute of Engineering and Technology, Panjab University, Chandigarh, India)","Garg, Gaurav (Panjab University)","Garg, Gaurav (Panjab University); Juneja, Mamta (Panjab University)",16,11,,5.4,,https://app.dimensions.ai/details/publication/pub.1106330140,40 Engineering; 4006 Communications Engineering; 46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
936,pub.1111990218,10.1201/9780429434334-11,,,Early Diagnosis and Staging of Prostate Cancer Using Magnetic Resonance Imaging,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,165-188,Closed,Chapter,"Alkadi, Ruba; Taher, Fatma; El-Baz, Ayman; Werghi, Naoufel","Alkadi, Ruba (); Taher, Fatma (); El-Baz, Ayman (); Werghi, Naoufel ()",,"Alkadi, Ruba (); Taher, Fatma (); El-Baz, Ayman (); Werghi, Naoufel ()",5,1,,,,https://app.dimensions.ai/details/publication/pub.1111990218,,
893,pub.1138866949,10.1016/j.bspc.2021.102844,,,Denoising of magnetic resonance imaging using Bayes shrinkage based fused wavelet transform and autoencoder based deep learning approach,"Denoising of medical images is of great concern as it plays a significant role in performance of computer aided diagnosis (CAD) systems. In real life scenarios, various conditions like vibration of magnetic coils due to rapid pulses of electricity contribute to noise during the procurement of medical images such as magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound. The use of imaging modality depends on the type of disease and its severity, and MRI is the commonly employed imaging modality for diagnosis of second most common dreadful cancers in men known as prostate cancer. However, MRI is prone to certain noises as Gaussian and Rician making denoising one of the important steps in the CAD system. Traditional approaches used for denoising of MRI were prone to certain issues such as loss of data due to compression and preservation of edge details. Hence, this paper presents Bayes shrinkage based fused wavelet transform (BSbFWT) and Block based autoencoder network (BBAuto-Net) for removal of noise from MRI. Further, the performance analysis of the denoising approaches are performed using different metrics. Thus, the values of peak signal to noise ratio (PSNR), mean squared error (MSE), structural similarity index metric (SSIM) and mean absolute error (MAE) for proposed BB-Autonet is found to be 28.029, 89.354, 0.581 and 21.802 for combined Gaussian and Rician noise. Whereas, the values of PSNR, MSE, SSIM and MAE for proposed BSbFWT are found to be 29.028, 81.33, 0.747 and 21.962 for combined Gaussian and Rician noise.","The authors are also grateful to the Ministry of Human Resource Development (MHRD), Govt. of India for funding this project(17-11/2015-PN-1) under Design Innovation Centre (DIC) sub-theme Medical Devices Restorative Technologies.",,Biomedical Signal Processing and Control,,,2021-08,2021,,2021-08,69,,102844,Closed,Article,"Juneja, Mamta; Saini, Sumindar Kaur; Kaul, Sambhav; Acharjee, Rajarshi; Thakur, Niharika; Jindal, Prashant","Juneja, Mamta (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Saini, Sumindar Kaur (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Kaul, Sambhav (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Acharjee, Rajarshi (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Thakur, Niharika (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Jindal, Prashant (University Institute of Engineering and Technology, Panjab University, Chandigarh, India)","Jindal, Prashant (Panjab University)","Juneja, Mamta (Panjab University); Saini, Sumindar Kaur (Panjab University); Kaul, Sambhav (Panjab University); Acharjee, Rajarshi (Panjab University); Thakur, Niharika (Panjab University); Jindal, Prashant (Panjab University)",9,9,,7.94,,https://app.dimensions.ai/details/publication/pub.1138866949,40 Engineering; 4006 Communications Engineering,
893,pub.1147931821,10.48550/arxiv.2205.07516,,,The use of deep learning in interventional radiotherapy (brachytherapy):  a review with a focus on open source and open data,"Deep learning advanced to one of the most important technologies in almost
all medical fields. Especially in areas, related to medical imaging it plays a
big role. However, in interventional radiotherapy (brachytherapy) deep learning
is still in an early phase. In this review, first, we investigated and
scrutinised the role of deep learning in all processes of interventional
radiotherapy and directly related fields. Additionally we summarised the most
recent developments. To reproduce results of deep learning algorithms both
source code and training data must be available. Therefore, a second focus of
this work was on the analysis of the availability of open source, open data and
open models. In our analysis, we were able to show that deep learning plays
already a major role in some areas of interventional radiotherapy, but is still
hardly presented in others. Nevertheless, its impact is increasing with the
years, partly self-propelled but also influenced by closely related fields.
Open source, data and models are growing in number but are still scarce and
unevenly distributed among different research groups. The reluctance in
publishing code, data and models limits reproducibility and restricts
evaluation to mono-institutional datasets. Summarised, deep learning will
change positively the workflow of interventional radiotherapy but there is room
for improvement when it comes to reproducible results and standardised
evaluation methods.",,,arXiv,,,2022-05-16,2022,,,,,,All OA; Green,Preprint,"Fechter, Tobias; Sachpazidis, Ilias; Baltas, Dimos","Fechter, Tobias (); Sachpazidis, Ilias (); Baltas, Dimos ()",,"Fechter, Tobias (); Sachpazidis, Ilias (); Baltas, Dimos ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1147931821,32 Biomedical and Clinical Sciences; 51 Physical Sciences; 5105 Medical and Biological Physics,
857,pub.1124291875,10.1016/j.cma.2020.112843,,,A numerical simulation study of the dual role of 5 α -reductase inhibitors on tumor growth in prostates enlarged by benign prostatic hyperplasia via stress relaxation and apoptosis upregulation,"5 α -reductase inhibitors are regarded as a promising chemoprevention strategy to reduce the incidence and delay the progression of prostate cancer. Landmark clinical trials have shown the chemopreventive potential of these drugs, but they appear to be mostly effective in mild tumors and have also been correlated with a higher prevalence of advanced prostate cancer. Hence, the use of 5 α -reductase inhibitors for prostate cancer chemoprevention has become a controversial issue. The effects of these drugs on prostate cancer growth remain incompletely understood, but they are thought to promote apoptosis in the tumor. Additionally, 5 α -reductase inhibitors induce global prostate shrinkage, which decreases the tumor-inhibiting effect of the mechanical stress accumulated in prostatic tissue due to common prostate enlargement with age. Thus, the competition between this mechanical effect and apoptotic upregulation may explain the controversial outcomes of 5 α -reductase inhibitors on prostate cancer. Here, we extend our mechanically-coupled model of prostate cancer growth by including the mechanical and apoptotic action of 5 α -reductase inhibitors and explore their combined effect on an aggressive tumor in silico. Our simulations show that the apoptotic boost dominates in the first months of therapy but the long-term outcome of 5 α -reductase inhibitors depends on its competition with a decrease in hydrostatic stress caused by prostate shrinkage, which favors tumor growth. By combining moderate or strong prostate shrinkage with mild or intense apoptotic upregulation, our simulations show different tumor growth dynamics ranging from long-term inhibition of prostate cancer growth to rapidly growing large tumors, which may evolve towards advanced disease. Thus, our proposed mechanism for the action of 5 α -reductase inhibitors may contribute to resolve the controversy around the use of these drugs for chemoprevention and to gain insight on prostate cancer dynamics during its use. The computational technology used herein could also assist physicians to monitor prostatic tumors during 5 α -reductase inhibitor therapy and enable the early identification of responders from non-responders in a patient-specific manner.",G.L. and A.R. were partially supported by the MIUR-PRIN project XFAST-SIMS (no. 20173C478N). The authors acknowledge the Rosen Center for Advanced Computing at Purdue University (USA) for providing HPC resources that contributed to the results presented in this paper.,,Computer Methods in Applied Mechanics and Engineering,,,2020-04,2020,,2020-04,362,,112843,Closed,Article,"Lorenzo, G.; Hughes, T.J.R.; Reali, A.; Gomez, H.","Lorenzo, G. (Dipartimento di Ingegneria Civile e Architettura, Università degli Studi di Pavia, Via Ferrata 3, 27100 Pavia, Italy); Hughes, T.J.R. (Institute for Computational Engineering and Sciences, The University of Texas at Austin, 201 East 24th Street, C0200, Austin, TX 78712-1229, USA); Reali, A. (Dipartimento di Ingegneria Civile e Architettura, Università degli Studi di Pavia, Via Ferrata 3, 27100 Pavia, Italy); Gomez, H. (School of Mechanical Engineering, Purdue University, 516 Northwestern Avenue, West Lafayette, IN 47907, USA; Weldon School of Biomedical Engineering, Purdue University, 206 S. Martin Jischke Drive, West Lafayette, IN 47907, USA; Purdue Center for Cancer Research, Purdue University, 201 S. University Street, West Lafayette, IN 47907, USA)","Lorenzo, G. (University of Pavia)","Lorenzo, G. (University of Pavia); Hughes, T.J.R. (The University of Texas at Austin); Reali, A. (University of Pavia); Gomez, H. (Purdue University West Lafayette; Purdue University West Lafayette; Purdue University West Lafayette)",7,6,,,,https://app.dimensions.ai/details/publication/pub.1124291875,40 Engineering; 49 Mathematical Sciences,
855,pub.1153158005,10.48550/arxiv.2211.13238,,,ProstAttention-Net: A deep attention model for prostate cancer  segmentation by aggressiveness in MRI scans,"Multiparametric magnetic resonance imaging (mp-MRI) has shown excellent
results in the detection of prostate cancer (PCa). However, characterizing
prostate lesions aggressiveness in mp-MRI sequences is impossible in clinical
practice, and biopsy remains the reference to determine the Gleason score (GS).
In this work, we propose a novel end-to-end multi-class network that jointly
segments the prostate gland and cancer lesions with GS group grading. After
encoding the information on a latent space, the network is separated in two
branches: 1) the first branch performs prostate segmentation 2) the second
branch uses this zonal prior as an attention gate for the detection and grading
of prostate lesions. The model was trained and validated with a 5-fold
cross-validation on an heterogeneous series of 219 MRI exams acquired on three
different scanners prior prostatectomy. In the free-response receiver operating
characteristics (FROC) analysis for clinically significant lesions (defined as
GS > 6) detection, our model achieves 69.0% $\pm$14.5% sensitivity at 2.9 false
positive per patient on the whole prostate and 70.8% $\pm$14.4% sensitivity at
1.5 false positive when considering the peripheral zone (PZ) only. Regarding
the automatic GS group",,,arXiv,,,2022-11-23,2022,,,,,,All OA; Green,Preprint,"Duran, Audrey; Dussert, Gaspard; Rouvière, Olivier; Jaouen, Tristan; Jodoin, Pierre-Marc; Lartizien, Carole","Duran, Audrey (MYRIAD); Dussert, Gaspard (MYRIAD); Rouvière, Olivier (MYRIAD); Jaouen, Tristan (MYRIAD); Jodoin, Pierre-Marc (MYRIAD); Lartizien, Carole (MYRIAD)",,"Duran, Audrey (); Dussert, Gaspard (); Rouvière, Olivier (); Jaouen, Tristan (); Jodoin, Pierre-Marc (); Lartizien, Carole ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1153158005,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
827,pub.1085079328,10.3390/info8020049,,,Automated Prostate Gland Segmentation Based on an Unsupervised Fuzzy C-Means Clustering Technique Using Multispectral T1w and T2w MR Imaging,"Prostate imaging analysis is difficult in diagnosis, therapy, and staging of prostate cancer. In clinical practice, Magnetic Resonance Imaging (MRI) is increasingly used thanks to its morphologic and functional capabilities. However, manual detection and delineation of prostate gland on multispectral MRI data is currently a time-expensive and operator-dependent procedure. Efficient computer-assisted segmentation approaches are not yet able to address these issues, but rather have the potential to do so. In this paper, a novel automatic prostate MR image segmentation method based on the Fuzzy C-Means (FCM) clustering algorithm, which enables multispectral T1-weighted (T1w) and T2-weighted (T2w) MRI anatomical data processing, is proposed. This approach, using an unsupervised Machine Learning technique, helps to segment the prostate gland effectively. A total of 21 patients with suspicion of prostate cancer were enrolled in this study. Volume-based metrics, spatial overlap-based metrics and spatial distance-based metrics were used to quantitatively evaluate the accuracy of the obtained segmentation results with respect to the gold-standard boundaries delineated manually by an expert radiologist. The proposed multispectral segmentation method was compared with the same processing pipeline applied on either T2w or T1w MR images alone. The multispectral approach considerably outperforms the monoparametric ones, achieving an average Dice Similarity Coefficient 90.77 ± 1.75, with respect to 81.90 ± 6.49 and 82.55 ± 4.93 by processing T2w and T1w imaging alone, respectively. Combining T2w and T1w MR image structural information significantly enhances prostate gland segmentation by exploiting the uniform gray appearance of the prostate on T1w MRI.","This research work was supported by funds from the University of Milano-Bicocca. We would like to thank Lucia Maria Valastro, Maria Gabriella Sabini and Davide D’Urso at Medical Physics Unit of the Cannizzaro Hospital, Catania, Italy, for supplying all the images analyzed in this study.",,Information,,,2017-04-28,2017,2017-04-28,,8,2,49,All OA; Gold,Article,"Rundo, Leonardo; Militello, Carmelo; Russo, Giorgio; Garufi, Antonio; Vitabile, Salvatore; Gilardi, Maria Carla; Mauri, Giancarlo","Rundo, Leonardo (Dipartimento di Informatica, Sistemistica e Comunicazione (DISCo), Università degli Studi di Milano-Bicocca, Viale Sarca 336, Milano 20126, Italy;, mauri@disco.unimib.it; Istituto di Bioimmagini e Fisiologia Molecolare-Consiglio Nazionale delle Ricerche (IBFM-CNR), Contrada Pietrapollastra-Pisciotto, Cefalù (PA) 90015, Italy;, carmelo.militello@ibfm.cnr.it, (C.M.);, giorgio.russo@ibfm.cnr.it, (G.R.);, mariacarla.gilardi@ibfm.cnr.it, (M.C.G.)); Militello, Carmelo (Istituto di Bioimmagini e Fisiologia Molecolare-Consiglio Nazionale delle Ricerche (IBFM-CNR), Contrada Pietrapollastra-Pisciotto, Cefalù (PA) 90015, Italy;, carmelo.militello@ibfm.cnr.it, (C.M.);, giorgio.russo@ibfm.cnr.it, (G.R.);, mariacarla.gilardi@ibfm.cnr.it, (M.C.G.)); Russo, Giorgio (Istituto di Bioimmagini e Fisiologia Molecolare-Consiglio Nazionale delle Ricerche (IBFM-CNR), Contrada Pietrapollastra-Pisciotto, Cefalù (PA) 90015, Italy;, carmelo.militello@ibfm.cnr.it, (C.M.);, giorgio.russo@ibfm.cnr.it, (G.R.);, mariacarla.gilardi@ibfm.cnr.it, (M.C.G.); Azienda Ospedaliera per l’Emergenza Cannizzaro, Via Messina 829, Catania 95126, Italy;, antoniogarufi@alice.it); Garufi, Antonio (Azienda Ospedaliera per l’Emergenza Cannizzaro, Via Messina 829, Catania 95126, Italy;, antoniogarufi@alice.it); Vitabile, Salvatore (Dipartimento di Biopatologia e Biotecnologie Mediche (DIBIMED), Università degli Studi di Palermo, Via del Vespro 129, Palermo 90127, Italy;, salvatore.vitabile@unipa.it); Gilardi, Maria Carla (Istituto di Bioimmagini e Fisiologia Molecolare-Consiglio Nazionale delle Ricerche (IBFM-CNR), Contrada Pietrapollastra-Pisciotto, Cefalù (PA) 90015, Italy;, carmelo.militello@ibfm.cnr.it, (C.M.);, giorgio.russo@ibfm.cnr.it, (G.R.);, mariacarla.gilardi@ibfm.cnr.it, (M.C.G.)); Mauri, Giancarlo (Dipartimento di Informatica, Sistemistica e Comunicazione (DISCo), Università degli Studi di Milano-Bicocca, Viale Sarca 336, Milano 20126, Italy;, mauri@disco.unimib.it)","Rundo, Leonardo (University of Milano-Bicocca; Institute of Molecular Bioimaging and Physiology; )","Rundo, Leonardo (University of Milano-Bicocca; Institute of Molecular Bioimaging and Physiology); Militello, Carmelo (Institute of Molecular Bioimaging and Physiology); Russo, Giorgio (Institute of Molecular Bioimaging and Physiology); Garufi, Antonio (); Vitabile, Salvatore (University of Palermo); Gilardi, Maria Carla (Institute of Molecular Bioimaging and Physiology); Mauri, Giancarlo (University of Milano-Bicocca)",45,16,,12.7,https://www.mdpi.com/2078-2489/8/2/49/pdf,https://app.dimensions.ai/details/publication/pub.1085079328,46 Information and Computing Sciences; 4602 Artificial Intelligence; 4605 Data Management and Data Science,
777,pub.1151124908,10.1007/978-3-031-16852-9,,,"Domain Adaptation and Representation Transfer, 4th MICCAI Workshop, DART 2022, Held in Conjunction with MICCAI 2022, Singapore, September 22, 2022, Proceedings","This book constitutes the refereed proceedings of the 4th MICCAI Workshop on Domain Adaptation and Representation Transfer, DART 2022, held in conjunction with MICCAI 2022, in September 2022. DART 2022 accepted 13 papers from the 25 submissions received. The workshop aims at creating a discussion forum to compare, evaluate, and discuss methodological advancements and ideas that can improve the applicability of machine learning (ML)/deep learning (DL) approaches to clinical setting by making them robust and consistent across different domains.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13542,,,All OA; Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16852-9%2F1,https://app.dimensions.ai/details/publication/pub.1151124908,46 Information and Computing Sciences; 4611 Machine Learning,
662,pub.1149100873,10.1016/bs.aams.2022.05.003,,,Chapter Six Oncology and mechanics: Landmark studies and promising clinical applications,"Clinical management of cancer has continuously evolved for several decades. Biochemical, molecular, and genomics approaches have brought and still bring numerous insights into cancerous diseases. It is now accepted that some phenomena, allowed by favorable biological conditions, emerge via mechanical signaling at the cellular scale and via mechanical forces at the macroscale. Mechanical phenomena in cancer have been studied in-depth over the last decades, and their clinical applications are starting to be understood. If numerous models and experimental setups have been proposed, only a few have led to clinical applications. The objective of this contribution is to review a large scope of mechanical findings which have consequences on the clinical management of cancer. This review is mainly addressed to doctoral candidates in mechanics and applied mathematics who are faced with the challenge of the mechanics-based modeling of cancer with the aim of clinical applications. We show that the collaboration of the biological and mechanical approaches has led to promising advances in terms of modeling, experimental design, and therapeutic targets. Additionally, a specific focus is placed on imaging-informed mechanics-based models, which we believe can further the development of new therapeutic targets and the advent of personalized medicine. We study in detail several successful workflows on patient-specific targeted therapies based on mechanistic modeling.",,,Advances in Applied Mechanics,,,2022,2022,,2022,55,,513-571,All OA; Green,Chapter,"Urcun, Stéphane; Lorenzo, Guillermo; Baroli, Davide; Rohan, Pierre-Yves; Sciumè, Giuseppe; Skalli, Wafa; Lubrano, Vincent; Bordas, Stéphane P.A.","Urcun, Stéphane (Institute for Computational Engineering Sciences, Department of Engineering Sciences, Faculté des Sciences, de la Technologie et de Médecine, Université du Luxembourg, Campus Kirchberg, Luxembourg, Luxembourg; Institut de Biomécanique Humaine Georges Charpak, Paris,France; Université de Bordeaux, Bordeaux, France); Lorenzo, Guillermo (Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin, Austin, TX, United States; Department of Civil Engineering and Architecture, University of Pavia, Pavia, Italy); Baroli, Davide (Università della Svizzera Italiana, Euler Institute, Lugano, Switzerland; Aachen Institute for Advanced Study in Computational Engineering Science, Rheinisch-Westfälische Technische Hochschule Aachen, Aachen, Germany); Rohan, Pierre-Yves (Institut de Biomécanique Humaine Georges Charpak, Paris,France); Sciumè, Giuseppe (Université de Bordeaux, Bordeaux, France); Skalli, Wafa (Institut de Biomécanique Humaine Georges Charpak, Paris,France); Lubrano, Vincent (Hôpital Pierre-Paul Riquet, Toulouse, France); Bordas, Stéphane P.A. (Institute for Computational Engineering Sciences, Department of Engineering Sciences, Faculté des Sciences, de la Technologie et de Médecine, Université du Luxembourg, Campus Kirchberg, Luxembourg, Luxembourg; Department of Medical Research, China Medical University Hospital, China Medical University, Taichung, Taiwan)","Bordas, Stéphane P.A. (University of Luxembourg; )","Urcun, Stéphane (University of Luxembourg; Institut de Biomécanique Humaine Georges Charpak; University of Bordeaux); Lorenzo, Guillermo (The University of Texas at Austin; University of Pavia); Baroli, Davide (Università della Svizzera Italiana; RWTH Aachen University); Rohan, Pierre-Yves (Institut de Biomécanique Humaine Georges Charpak); Sciumè, Giuseppe (University of Bordeaux); Skalli, Wafa (Institut de Biomécanique Humaine Georges Charpak); Lubrano, Vincent (); Bordas, Stéphane P.A. (University of Luxembourg)",2,2,,,http://arxiv.org/pdf/2211.09186,https://app.dimensions.ai/details/publication/pub.1149100873,31 Biological Sciences; 40 Engineering; 4003 Biomedical Engineering,3 Good Health and Well Being
662,pub.1139044380,10.1109/access.2021.3090825,,,Recent Automatic Segmentation Algorithms of MRI Prostate Regions: A Review,"World-wide incidence rate of prostate cancer has progressively increased with time especially with the increased proportion of elderly population. Early detection of prostate cancer when it is confined to the prostate gland has the best chance of successful treatment and increase in surviving rate. Prostate cancer occurrence rate varies over the three prostate regions, peripheral zone (PZ), transitional zone (TZ), and central zone (CZ) and this characteristic is one of the important considerations is development of segmentation algorithm. In fact, the occurrence rate of cancer PZ, TZ and CZ regions is respectively. at 70-80%, 10-20%, 5% or less. In general application of medical imaging, segmentation tasks can be time consuming for the expert to delineate the region of interest, especially when involving large numbers of images. In addition, the manual segmentation is subjective depending on the expert’s experience. Hence, the need to develop automatic segmentation algorithms has rapidly increased along with the increased need of diagnostic tools for assisting medical practitioners, especially in the absence of radiologists. The prostate gland segmentation is challenging due to its shape variability in each zone from patient to patient and different tumor levels in each zone. This survey reviewed 22 machine learning and 88 deep learning-based segmentation of prostate MRI papers, including all MRI modalities. The review coverage includes the initial screening and imaging techniques, image pre-processing, segmentation techniques based on machine learning and deep learning techniques. Particular attention is given to different loss functions used for training segmentation based on deep learning techniques. Besides, a summary of publicly available prostate MRI image datasets is also provided. Finally, the future challenges and limitations of current deep learning-based approaches and suggestions of potential future research are also discussed.","This work was supported in part by the Yayasan Universiti Teknologi Petronas under Grant YUTP-FRG 015LC0-292, and in part by the Imagerie et Vision Artificielle (ImViA) / Imagerie Fonctionnelle et moléculaire et Traitement des Images Médicales (IFTIM) Research Grant.",,IEEE Access,,,2021-01-01,2021,2021-06-21,2021-01-01,9,,97878-97905,All OA; Gold,Article,"Khan, Zia; Yahya, Norashikin; Alsaih, Khaled; Al-Hiyali, Mohammed Isam; Meriaudeau, Fabrice","Khan, Zia (Centre for Intelligent Signal and Imaging Research, Electrical and Electronic Engineering Department, Universiti Teknologi PETRONAS, Seri Iskandar, 32610, Malaysia); Yahya, Norashikin (Centre for Intelligent Signal and Imaging Research, Electrical and Electronic Engineering Department, Universiti Teknologi PETRONAS, Seri Iskandar, 32610, Malaysia); Alsaih, Khaled (CNRS, IOGS, Université de Lyon, UJM-Saint-Etienne, Laboratoire Hubert Curien, UMR5516, 42023, Saint-Etienne, France); Al-Hiyali, Mohammed Isam (Centre for Intelligent Signal and Imaging Research, Electrical and Electronic Engineering Department, Universiti Teknologi PETRONAS, Seri Iskandar, 32610, Malaysia); Meriaudeau, Fabrice (ImViA/IFTIM, Universite Bourgogne Franche-Comté, 21000, Dijon, France)","Yahya, Norashikin (Universiti Teknologi Petronas)","Khan, Zia (Universiti Teknologi Petronas); Yahya, Norashikin (Universiti Teknologi Petronas); Alsaih, Khaled (Laboratoire Hubert Curien); Al-Hiyali, Mohammed Isam (Universiti Teknologi Petronas); Meriaudeau, Fabrice (Université Bourgogne Franche-Comté)",9,9,,,https://ieeexplore.ieee.org/ielx7/6287639/9312710/09461197.pdf,https://app.dimensions.ai/details/publication/pub.1139044380,40 Engineering; 46 Information and Computing Sciences,
658,pub.1118044745,10.1016/j.eswa.2019.112821,,,A systematic survey of computer-aided diagnosis in medicine: Past and present developments,"Computer-aided diagnosis (CAD) in medicine is the result of a large amount of effort expended in the interface of medicine and computer science. As some CAD systems in medicine try to emulate the diagnostic decision-making process of medical experts, they can be considered as expert systems in medicine. Furthermore, CAD systems in medicine may process clinical data that can be complex and/or massive in size. They do so in order to infer new knowledge from data and use that knowledge to improve their diagnostic performance over time. Therefore, such systems can also be viewed as intelligent systems because they use a feedback mechanism to improve their performance over time. The main aim of the literature survey described in this paper is to provide a comprehensive overview of past and current CAD developments. This survey/review can be of significant value to researchers and professionals in medicine and computer science. There are already some reviews about specific aspects of CAD in medicine. However, this paper focuses on the entire spectrum of the capabilities of CAD systems in medicine. It also identifies the key developments that have led to today's state-of-the-art in this area. It presents an extensive and systematic literature review of CAD in medicine, based on 251 carefully selected publications. While medicine and computer science have advanced dramatically in recent years, each area has also become profoundly more complex. This paper advocates that in order to further develop and improve CAD, it is required to have well-coordinated work among researchers and professionals in these two constituent fields. Finally, this survey helps to highlight areas where there are opportunities to make significant new contributions. This may profoundly impact future research in medicine and in select areas of computer science.",The authors of this paper would like to thank the Editor-in-Chief; Dr. Binshan Lin for all his help during the reviewing process. They are also very appreciative to the two anonymous reviewers the comments of which were valuable in clarifying and strengthening the original version of this paper.,"This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.",Expert Systems with Applications,,,2019-12,2019,,2019-12,138,,112821,Closed,Article,"Yanase, Juri; Triantaphyllou, Evangelos","Yanase, Juri (Complete Decisions, LLC, Baton Rouge, LA 70810, United States); Triantaphyllou, Evangelos (Division of Computer Science Engineering, School of Electrical Engineering and Computer Science, Louisiana State University, Baton Rouge, LA 70803, United States)","Triantaphyllou, Evangelos (Louisiana State University)","Yanase, Juri (); Triantaphyllou, Evangelos (Louisiana State University)",122,102,,48.22,,https://app.dimensions.ai/details/publication/pub.1118044745,46 Information and Computing Sciences; 4602 Artificial Intelligence,
655,pub.1152860298,10.48550/arxiv.2211.09186,,,Oncology and mechanics: landmark studies and promising clinical  applications,"Clinical management of cancer has continuously evolved for several decades.
Biochemical, molecular and genomics approaches have brought and still bring
numerous insights into cancerous diseases. It is now accepted that some
phenomena, allowed by favorable biological conditions, emerge via mechanical
signaling at the cellular scale and via mechanical forces at the macroscale.
Mechanical phenomena in cancer have been studied in-depth over the last
decades, and their clinical applications are starting to be understood. If
numerous models and experimental setups have been proposed, only a few have led
to clinical applications. The objective of this contribution is to propose to
review a large scope of mechanical findings which have consequences on the
clinical management of cancer. This review is mainly addressed to doctoral
candidates in mechanics and applied mathematics who are faced with the
challenge of the mechanics-based modeling of cancer with the aim of clinical
applications. We show that the collaboration of the biological and mechanical
approaches has led to promising advances in terms of modeling, experimental
design and therapeutic targets. Additionally, a specific focus is brought on
imaging-informed mechanics-based models, which we believe can further the
development of new therapeutic targets and the advent of personalized medicine.
We study in detail several successful workflows on patient-specific targeted
therapies based on mechanistic modeling.",,,arXiv,,,2022-11-16,2022,,,,,,All OA; Green,Preprint,"Urcun, Stéphane; Lorenzo, Guillermo; Baroli, Davide; Rohan, Pierre-Yves; Sciumè, Giuseppe; Skalli, Wafa; Lubrano, Vincent; Bordas, Stéphane P. A.","Urcun, Stéphane (); Lorenzo, Guillermo (); Baroli, Davide (); Rohan, Pierre-Yves (); Sciumè, Giuseppe (); Skalli, Wafa (); Lubrano, Vincent (); Bordas, Stéphane P. A. ()",,"Urcun, Stéphane (); Lorenzo, Guillermo (); Baroli, Davide (); Rohan, Pierre-Yves (); Sciumè, Giuseppe (); Skalli, Wafa (); Lubrano, Vincent (); Bordas, Stéphane P. A. ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1152860298,31 Biological Sciences; 40 Engineering; 4003 Biomedical Engineering,3 Good Health and Well Being
615,pub.1139063354,10.1007/s11042-021-11044-2,,,"Survey of denoising, segmentation and classification of magnetic resonance imaging for prostate cancer","Prostate cancer (PCa) has become the second most dreadful cancer in men after lung cancer. Traditional approaches used for treatment of PCa were manual, time consuming and prone to subjective errors. Thus, there is a need for a Computer aided diagnosis system (CADs) consisting of denoising, segmentation, and classification approaches for diagnosis of PCa. CADs may act as a second opinion for the medical experts and save their precious time used in manual analysis. Magnetic resonance imaging (MRI) is the commonly used modality, as it produces detailed and fine contrast images of internal organs for diagnosis of PCa, but it may contain a certain amount of rician and gaussian noise which is necessary to be denoising before segmentation and classification. Denoising offers several challenges such as suppressing of significance image details leading in inaccurate segmentation and classification for prediction of abnormality. Thus, improved denoising, segmentation, and classification approaches can overcome the challenges by analyzing the pitfalls in the state of the art. This paper presents the experimental analysis state of the art denoising and segmentation approaches to analyse their performance based on the values of Peak signal to noise ratio (PSNR), Mean squared error (MSE), Structured similarity index (SSIM), dice metric, area overlap and accuracy. Based on the experimental analysis it was analysed that anisotropic filter outperforms other filters for gaussian noise with PSNR of 28.29, MSE of 96.22 and SSIM of 0.64. Also, for the rician noise anisotropic filter outperforms others with PSNR of 28.06, MSE of 101.52 and SSIM of 0.01. Similarly, for the combined gaussian and rician noise, anisotropic filter outperform others with PSNR of 28.34, MSE of 95.13 and SSIM of 0.652. Further, the analysis of segmentation approaches such as contour and shape-based, region/atlas based, thresholding based, clustering based and deep learning based was performed. Amongst these approaches deep learning based segmentation was found to outperform with dice metric of 0.89 and area overlap of 0.80. Also, CNN based classification outperformed machine learning based Support vector machine (SVM), K nearest neighbour (K-NN) and Random forest (RF) with 94.55% sensitivity, 93.34% specificity, 95.45% accuracy. Finally, the paper discusses challenges and future scope based on analysis in the concerned field for diagnosis of PCa.","The authors are also grateful to the Ministry of Human Resource Development (MHRD), Govt. of India for funding this project(17-11/2015-PN-1) under Design Innovation Centre (DIC) sub-theme Medical Devices &amp; Restorative Technologies.",,Multimedia Tools and Applications,,,2021-06-22,2021,2021-06-22,2021-08,80,19,29199-29249,Closed,Article,"Juneja, Mamta; Saini, Sumindar Kaur; Gupta, Jatin; Garg, Poojita; Thakur, Niharika; Sharma, Aviral; Mehta, Manan; Jindal, Prashant","Juneja, Mamta (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Saini, Sumindar Kaur (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Gupta, Jatin (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Garg, Poojita (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Thakur, Niharika (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Sharma, Aviral (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Mehta, Manan (University Institute of Engineering and Technology, Panjab University, Chandigarh, India); Jindal, Prashant (University Institute of Engineering and Technology, Panjab University, Chandigarh, India)","Jindal, Prashant (Panjab University)","Juneja, Mamta (Panjab University); Saini, Sumindar Kaur (Panjab University); Gupta, Jatin (Panjab University); Garg, Poojita (Panjab University); Thakur, Niharika (Panjab University); Sharma, Aviral (Panjab University); Mehta, Manan (Panjab University); Jindal, Prashant (Panjab University)",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1139063354,40 Engineering; 46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
533,pub.1111990231,10.1201/9780429434334-6,,,Current Role of Focal Therapy for Prostate Cancer,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,53-62,Closed,Chapter,"Chiang, H Abraham; Haleblian, George E","Chiang, H Abraham (); Haleblian, George E ()",,"Chiang, H Abraham (); Haleblian, George E ()",1,1,,,,https://app.dimensions.ai/details/publication/pub.1111990231,,
533,pub.1111990229,10.1201/9780429434334-4,,,Prostate MRI,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,33-42,Closed,Chapter,"Pereira, J; Pareek, Gyan; Grand, D","Pereira, J (); Pareek, Gyan (); Grand, D ()",,"Pereira, J (); Pareek, Gyan (); Grand, D ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1111990229,,
533,pub.1111990227,10.1201/9780429434334-2,,,Transrectal Ultrasound (TRUS)-Guided Prostate Biopsy,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,9-21,Closed,Chapter,"Fantasia, Jennifer; Golijanin, Dragan; Gershman, Boris","Fantasia, Jennifer (); Golijanin, Dragan (); Gershman, Boris ()",,"Fantasia, Jennifer (); Golijanin, Dragan (); Gershman, Boris ()",1,0,,,,https://app.dimensions.ai/details/publication/pub.1111990227,,
533,pub.1111990217,10.1201/9780429434334-10,,,Computer-Aided Diagnosis Systems for Prostate Cancer Detection,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,87-163,Closed,Chapter,"Lemaître, Guillaume; Martí, Robert; Meriaudeau, Fabrice","Lemaître, Guillaume (); Martí, Robert (); Meriaudeau, Fabrice ()",,"Lemaître, Guillaume (); Martí, Robert (); Meriaudeau, Fabrice ()",3,0,,,,https://app.dimensions.ai/details/publication/pub.1111990217,,
532,pub.1111990230,10.1201/9780429434334-5,,,Current Role and Evolution of MRI Fusion Biopsy for Prostate Cancer,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,43-51,Closed,Chapter,"Velez, Danielle; Brito, Joseph; Renzulli, Joseph","Velez, Danielle (); Brito, Joseph (); Renzulli, Joseph ()",,"Velez, Danielle (); Brito, Joseph (); Renzulli, Joseph ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1111990230,,
532,pub.1111990225,10.1201/9780429434334-18,,,Diagnosing Prostate Cancer Based on Deep Learning with a Stacked Nonnegativity Constraint Autoencoder,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,325-347,Closed,Chapter,"Reda, Islam; Shalaby, Ahmed; Elmogy, Mohammed; Aboulfotouh, Ahmed; El-Ghar, Mohamed Abou; Elmagharaby, Adel; El-Baz, Ayman","Reda, Islam (); Shalaby, Ahmed (); Elmogy, Mohammed (); Aboulfotouh, Ahmed (); El-Ghar, Mohamed Abou (); Elmagharaby, Adel (); El-Baz, Ayman ()",,"Reda, Islam (); Shalaby, Ahmed (); Elmogy, Mohammed (); Aboulfotouh, Ahmed (); El-Ghar, Mohamed Abou (); Elmagharaby, Adel (); El-Baz, Ayman ()",2,0,,,,https://app.dimensions.ai/details/publication/pub.1111990225,,
532,pub.1111990224,10.1201/9780429434334-17,,,Magnetic Resonance Imaging in the Detection of Prostate Cancer,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,317-324,Closed,Chapter,"McClure, Timothy D; Margolis, Daniel; Schlegel, Peter N","McClure, Timothy D (); Margolis, Daniel (); Schlegel, Peter N ()",,"McClure, Timothy D (); Margolis, Daniel (); Schlegel, Peter N ()",3,0,,,,https://app.dimensions.ai/details/publication/pub.1111990224,,
532,pub.1111990222,10.1201/9780429434334-15,,,Precision Imaging of Prostate Cancer,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,259-293,Closed,Chapter,"Fei, Baowei","Fei, Baowei ()",,"Fei, Baowei ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1111990222,,
531,pub.1111990228,10.1201/9780429434334-3,,,Current Active Surveillance Protocol for Prostate Cancer,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,23-31,Closed,Chapter,"Greenberg, Scott; Yates, Jennifer","Greenberg, Scott (); Yates, Jennifer ()",,"Greenberg, Scott (); Yates, Jennifer ()",0,0,,,,https://app.dimensions.ai/details/publication/pub.1111990228,,
529,pub.1111990226,10.1201/9780429434334-19,,,MRI Imaging of Seminal Vesicle Invasion (SVI) in Prostate Adenocarcinoma,,,,,Prostate Cancer Imaging,,2018-10-31,2018,2018-10-31,,,,349-370,Closed,Chapter,"Gold, Samuel A; Hale, Graham R; Rayn, Kareem N; Valera, Vladimir; Bloom, Jonathan B; Pinto, Peter A","Gold, Samuel A (); Hale, Graham R (); Rayn, Kareem N (); Valera, Vladimir (); Bloom, Jonathan B (); Pinto, Peter A ()",,"Gold, Samuel A (); Hale, Graham R (); Rayn, Kareem N (); Valera, Vladimir (); Bloom, Jonathan B (); Pinto, Peter A ()",3,0,,,,https://app.dimensions.ai/details/publication/pub.1111990226,,
444,pub.1108900652,10.1007/978-3-319-61786-2,,,"Atlas of Multiparametric Prostate MRI, With PI-RADS Approach and Anatomic-MRI-Pathological Correlation","This atlas provides a comprehensive, state of the art review of the use of multiparametric MRI (mpMRI) for the imaging of prostate cancer, covering aspects from diagnosis and loco-regional staging through to the role of the technique after treatment and follow-up. The book contains a wealth of high-resolution images, many of them in color, and displays the anatomical-MRI–pathological correlation whenever appropriate. Readers will find a helpful overview on the current standardized method for reading and reporting on mpMRI, the Prostate Imaging Reporting and Data System (PI-RADS), version 2. Dedicated chapters focus on differential diagnosis and imaging pitfalls, and the inclusion of helpful diagrams and algorithms will further assist in image interpretation, enabling readers to ease and improve their use of mpMRI. Edited and written by very experienced radiologists, pathologists, and urologists; the Atlas of Multiparametric Prostate MRI will serve as a unique source of clinically relevant information and an aid to disease management for radiologists, urologists, pathologists, radiotherapists, and oncologists.",,,,,,2018,2018,,2018,,,,All OA; Green,Edited Book,,,,,8,4,,2.33,https://link.springer.com/content/pdf/bfm:978-3-319-61786-2/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1108900652,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences; 3211 Oncology and Carcinogenesis,
290,pub.1121615375,10.1007/978-3-030-32486-5,,,"Artificial Intelligence in Radiation Therapy, First International Workshop, AIRT 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 17, 2019, Proceedings","This book constitutes the refereed proceedings of the First International Workshop on Connectomics in Artificial Intelligence in Radiation Therapy, AIRT 2019, held in conjunction with MICCAI 2019 in Shenzhen, China, in October 2019. The 20 full papers presented were carefully reviewed and selected from 24 submissions. The papers discuss the state of radiation therapy, the state of AI and related technologies, and hope to find a pathway to revolutionizing the field to ultimately improve cancer patient outcome and quality of life.",,,Lecture Notes in Computer Science,,,2019,2019,,2019,11850,,,All OA; Green,Edited Book,,,,,2,2,,,https://link.springer.com/content/pdf/bfm:978-3-030-32486-5/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1121615375,46 Information and Computing Sciences,3 Good Health and Well Being
273,pub.1085439045,10.1007/s11548-017-1588-3,28527024,,"CARS 2017—Computer Assisted Radiology and Surgery Proceedings of the 31st International Congress and Exhibition Barcelona, Spain, June 20–24, 2017",,,,International Journal of Computer Assisted Radiology and Surgery,,,2017-05-19,2017,2017-05-19,2017-06,12,Suppl 1,1-286,All OA; Green,Article,,,,,15,6,0.65,4.54,https://boris.unibe.ch/106176/1/2017_Article_CARS2017ComputerAssistedRadiol_Paolucci.pdf,https://app.dimensions.ai/details/publication/pub.1085439045,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,3 Good Health and Well Being
246,pub.1151694516,10.1007/978-3-031-18523-6,,,"Distributed, Collaborative, and Federated Learning, and Affordable AI and Healthcare for Resource Diverse Global Health, Third MICCAI Workshop, DeCaF 2022, and Second MICCAI Workshop, FAIR 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18 and 22, 2022, Proceedings","This book constitutes the refereed proceedings of the Third MICCAI Workshop on Distributed, Collaborative, and Federated Learning, DeCaF 2022, and the Second MICCAI Workshop on Affordable AI and Healthcare, FAIR 2022, held in conjunction with MICCAI 2022, in Singapore in September 2022. FAIR 2022 was held as a hybrid event. DeCaF 2022 accepted 14 papers from the 18 submissions received. The workshop aims at creating a scientific discussion focusing on the comparison, evaluation, and discussion of methodological advancement and practical ideas about machine learning applied to problems where data cannot be stored in centralized databases or where information privacy is a priority. For FAIR 2022, 4 papers from 9 submissions were accepted for publication. The topics of the accepted submissions focus on deep ultrasound segmentation, portable OCT image quality enhancement, self-attention deep networks and knowledge distillation in low-regime setting.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13573,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1151694516,46 Information and Computing Sciences; 4606 Distributed Computing and Systems Software,3 Good Health and Well Being
190,pub.1111444832,10.1201/9780429434334,,,"Prostate Cancer Imaging, An Engineering and Clinical Perspective",,,,,,,2018-10-31,2018,2018-10-31,,,,,Closed,Edited Book,,,,,1,0,,,,https://app.dimensions.ai/details/publication/pub.1111444832,,
155,pub.1138729672,10.48550/arxiv.2106.04381,,,Computer-Assisted Analysis of Biomedical Images,"Nowadays, the amount of heterogeneous biomedical data is increasing more and
more thanks to novel sensing techniques and high-throughput technologies. In
reference to biomedical image analysis, the advances in image acquisition
modalities and high-throughput imaging experiments are creating new challenges.
This huge information ensemble could overwhelm the analytic capabilities needed
by physicians in their daily decision-making tasks as well as by biologists
investigating complex biochemical systems. In particular, quantitative imaging
methods convey scientifically and clinically relevant information in
prediction, prognosis or treatment response assessment, by also considering
radiomics approaches. Therefore, the computational analysis of medical and
biological images plays a key role in radiology and laboratory applications. In
this regard, frameworks based on advanced Machine Learning and Computational
Intelligence can significantly improve traditional Image Processing and Pattern
Recognition approaches. However, conventional Artificial Intelligence
techniques must be tailored to address the unique challenges concerning
biomedical imaging data. This thesis aims at proposing novel and advanced
computer-assisted methods for biomedical image analysis, also as an instrument
in the development of Clinical Decision Support Systems, by always keeping in
mind the clinical feasibility of the developed solutions. In conclusion, the
ultimate goal of these research studies is to gain clinically and biologically
useful insights that can guide differential diagnosis and therapies, leading
towards biomedical data integration for personalized medicine. As a matter of
fact, the proposed computer-assisted bioimage analysis methods can be
beneficial for the definition of imaging biomarkers, as well as for
quantitative medicine and biology.",,,arXiv,,,2021-06-04,2021,,,,,,All OA; Green,Preprint,"Rundo, Leonardo","Rundo, Leonardo ()",,"Rundo, Leonardo ()",0,0,,0.0,,https://app.dimensions.ai/details/publication/pub.1138729672,46 Information and Computing Sciences; 4605 Data Management and Data Science,3 Good Health and Well Being
146,pub.1091382400,10.1007/978-3-319-56904-8,,,Multidisciplinary Approaches to Neural Computing,"This book presents a collection of contributions in the field of Artificial Neural Networks (ANNs). The themes addressed are multidisciplinary in nature, and closely connected in their ultimate aim to identify features from dynamic realistic signal exchanges and invariant machine representations that can be exploited to improve the quality of life of their end users. Mathematical tools like ANNs are currently exploited in many scientific domains because of their solid theoretical background and effectiveness in providing solutions to many demanding tasks such as appropriately processing (both for extracting features and recognizing) mono- and bi-dimensional dynamic signals, solving strong nonlinearities in the data and providing general solutions for deep and fully connected architectures. Given the multidisciplinary nature of their use and the interdisciplinary characterization of the problems they are applied to – which range from medicine to psychology, industrial and social robotics, computer vision, and signal processing (among many others) – ANNs may provide a basis for redefining the concept of information processing. These reflections are supported by theoretical models and applications presented in the chapters of this book. This book is of primary importance for: (a) the academic research community, (b) the ICT market, (c) PhD students and early-stage researchers, (d) schools, hospitals, rehabilitation and assisted-living centers, and (e) representatives of multimedia industries and standardization bodies.",,,"Smart Innovation, Systems and Technologies",,,2018,2018,,2018,69,,,All OA; Green,Edited Book,,,,,4,3,,1.26,https://link.springer.com/content/pdf/bfm:978-3-319-56904-8/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1091382400,40 Engineering; 46 Information and Computing Sciences; 4611 Machine Learning,
130,pub.1151032978,10.1007/978-3-031-16443-9,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2022, 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part V","The eight-volume set LNCS 13431, 13432, 13433, 13434, 13435, 13436, 13437, and 13438 constitutes the refereed proceedings of the 25th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2022, which was held in Singapore in September 2022. The 574 revised full papers presented were carefully reviewed and selected from 1831 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: Brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; heart and lung imaging; dermatology; Part II: Computational (integrative) pathology; computational anatomy and physiology; ophthalmology; fetal imaging; Part III: Breast imaging; colonoscopy; computer aided diagnosis; Part IV: Microscopic image analysis; positron emission tomography; ultrasound imaging; video data analysis; image segmentation I; Part V: Image segmentation II; integration of imaging with non-imaging biomarkers; Part VI: Image registration; image reconstruction; Part VII: Image-Guided interventions and surgery; outcome and disease prediction; surgical data science; surgical planning and simulation; machine learning – domain adaptation and generalization; Part VIII: Machine learning – weakly-supervised learning; machine learning – model interpretation; machine learning – uncertainty; machine learning theory and methodologies.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13435,,,All OA; Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16443-9%2F1,https://app.dimensions.ai/details/publication/pub.1151032978,46 Information and Computing Sciences; 4611 Machine Learning,
118,pub.1135164904,10.1007/978-3-030-68449-5,,,"Intelligent Human Computer Interaction, 12th International Conference, IHCI 2020, Daegu, South Korea, November 24–26, 2020, Proceedings, Part I","The two-volume set LNCS 12615 + 12616 constitutes the refereed proceedings of the 12th International Conference on Intelligent Human Computer Interaction, IHCI 2020, which took place in Daegu, South Korea, during November 24-26, 2020. The 75 full and 18 short papers included in these proceedings were carefully reviewed and selected from a total of 185 submissions. The papers were organized in topical sections named: cognitive modeling and system; biomedical signal processing and complex problem solving; natural language, speech, voice and study; algorithm and related applications; crowd sourcing and information analysis; intelligent usability and test system; assistive living; image processing and deep learning; and human-centered AI applications.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12615,,,All OA; Green,Edited Book,,,,,1,1,,0.91,https://link.springer.com/content/pdf/bfm%3A978-3-030-68449-5%2F1,https://app.dimensions.ai/details/publication/pub.1135164904,46 Information and Computing Sciences; 4608 Human-Centred Computing,
90,pub.1120235212,10.1201/9781351208277,,,"Radiomics and Radiogenomics, Technical Basis and Clinical Applications",,,,,,,2019-07-09,2019,2019-07-09,,,,,All OA; Green,Edited Book,,,,,14,9,,,https://hrcak.srce.hr/file/384134,https://app.dimensions.ai/details/publication/pub.1120235212,,
90,pub.1086114210,10.1007/978-3-319-59126-1,,,"Image Analysis, 20th Scandinavian Conference, SCIA 2017, Tromsø, Norway, June 12–14, 2017, Proceedings, Part I","The two-volume set LNCS 10269 and 10270 constitutes the refereed proceedings of the 20th Scandinavian Conference on Image Analysis, SCIA 2017, held in Tromsø, Norway, in June 2017. The 87 revised papers presented were carefully reviewed and selected from 133 submissions. The contributions are structured in topical sections on history of SCIA; motion analysis and 3D vision; pattern detection and recognition; machine learning; image processing and applications; feature extraction and segmentation; remote sensing; medical and biomedical image analysis; faces, gestures and multispectral analysis.",,,Lecture Notes in Computer Science,,,2017,2017,,2017,10269,,,All OA; Green,Edited Book,,,,,4,0,,1.15,https://link.springer.com/content/pdf/bfm%3A978-3-319-59126-1%2F1,https://app.dimensions.ai/details/publication/pub.1086114210,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,
75,pub.1152224322,10.1007/978-3-031-18910-4,,,"Pattern Recognition and Computer Vision, 5th Chinese Conference, PRCV 2022, Shenzhen, China, November 4–7, 2022, Proceedings, Part II","The 4-volume set LNCS 13534, 13535, 13536 and 13537 constitutes the refereed proceedings of the 5th Chinese Conference on Pattern Recognition and Computer Vision, PRCV 2022, held in Shenzhen, China, in November 2022. The 233 full papers presented were carefully reviewed and selected from 564 submissions. The papers have been organized in the following topical sections: Theories and Feature Extraction; Machine learning, Multimedia and Multimodal; Optimization and Neural Network and Deep Learning; Biomedical Image Processing and Analysis; Pattern Classification and Clustering; 3D Computer Vision and Reconstruction, Robots and Autonomous Driving; Recognition, Remote Sensing; Vision Analysis and Understanding; Image Processing and Low-level Vision; Object Detection, Segmentation and Tracking.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13535,,,Closed,Edited Book,,,,,0,0,,,,https://app.dimensions.ai/details/publication/pub.1152224322,46 Information and Computing Sciences; 4611 Machine Learning,
74,pub.1084912607,10.1007/978-3-319-46720-7,,,"Medical Image Computing and Computer-Assisted Intervention – MICCAI 2016, 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings, Part I","The three-volume set LNCS 9900, 9901, and 9902 constitutes the refereed proceedings of the 19th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2016, held in Athens, Greece, in October 2016. Based on rigorous peer reviews, the program committee carefully selected 228 revised regular papers from 756 submissions for presentation in three volumes. The papers have been organized in the following topical sections: Part I: brain analysis; brain analysis - connectivity; brain analysis - cortical morphology; Alzheimer disease; surgical guidance and tracking; computer aided interventions; ultrasound image analysis; cancer image analysis; Part II: machine learning and feature selection; deep learning in medical imaging; applications of machine learning; segmentation; cell image analysis; Part III: registration and deformation estimation; shape modeling; cardiac and vascular image analysis; image reconstruction; and MR image analysis.",,,Lecture Notes in Computer Science,,,2016,2016,,2016,9900,,,All OA; Green,Edited Book,,,,,20,3,,,https://link.springer.com/content/pdf/bfm:978-3-319-46720-7/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1084912607,46 Information and Computing Sciences,
74,pub.1091427313,10.1007/978-3-319-66179-7,,,"Medical Image Computing and Computer Assisted Intervention − MICCAI 2017, 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part III","The three-volume set LNCS 10433, 10434, and 10435 constitutes the refereed proceedings of the 20th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017, held inQuebec City, Canada, in September 2017. The 255 revised full papers presented were carefully reviewed and selected from 800 submissions in a two-phase review process. The papers have been organized in the following topical sections: Part I: atlas and surface-based techniques; shape and patch-based techniques; registration techniques, functional imaging, connectivity, and brain parcellation; diffusion magnetic resonance imaging (dMRI) and tensor/fiber processing; and image segmentation and modelling. Part II: optical imaging; airway and vessel analysis; motion and cardiac analysis; tumor processing; planning and simulation for medical interventions; interventional imaging and navigation; and medical image computing. Part III: feature extraction and classification techniques; and machine learning in medical image computing.",,,Lecture Notes in Computer Science,,,2017,2017,,2017,10435,,,Closed,Edited Book,,,,,22,8,,,,https://app.dimensions.ai/details/publication/pub.1091427313,46 Information and Computing Sciences,
73,pub.1111703406,10.1007/978-3-030-11018-5,,,"Computer Vision – ECCV 2018 Workshops, Munich, Germany, September 8-14, 2018, Proceedings, Part IV","The six-volume set comprising the LNCS volumes 11129-11134 constitutes the refereed proceedings of the workshops that took place in conjunction with the 15th European Conference on Computer Vision, ECCV 2018, held in Munich, Germany, in September 2018. 43 workshops from 74 workshops proposals were selected for inclusion in the proceedings. The workshop topics present a good orchestration of new trends and traditional issues, built bridges into neighboring fields, and discuss fundamental technologies and novel applications.",,,Lecture Notes in Computer Science,,,2019,2019,,2019,11132,,,All OA; Green,Edited Book,,,,,2,1,,0.81,https://link.springer.com/content/pdf/bfm:978-3-030-11018-5/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1111703406,46 Information and Computing Sciences; 4608 Human-Centred Computing,
67,pub.1131394427,10.1007/978-3-030-59713-9,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2020, 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part II","The seven-volume set LNCS 12261, 12262, 12263, 12264, 12265, 12266, and 12267 constitutes the refereed proceedings of the 23rd International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2020, held in Lima, Peru, in October 2020. The conference was held virtually due to the COVID-19 pandemic. The 542 revised full papers presented were carefully reviewed and selected from 1809 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: machine learning methodologies Part II: image reconstruction; prediction and diagnosis; cross-domain methods and reconstruction; domain adaptation; machine learning applications; generative adversarial networks Part III: CAI applications; image registration; instrumentation and surgical phase detection; navigation and visualization; ultrasound imaging; video image analysis Part IV: segmentation; shape models and landmark detection Part V: biological, optical, microscopic imaging; cell segmentation and stain normalization; histopathology image analysis; opthalmology Part VI: angiography and vessel analysis; breast imaging; colonoscopy; dermatology; fetal imaging; heart and lung imaging; musculoskeletal imaging Part VI: brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; positron emission tomography",,,Lecture Notes in Computer Science,,,2020,2020,,2020,12262,,,All OA; Green,Edited Book,,,,,4,4,,2.06,https://link.springer.com/content/pdf/bfm:978-3-030-59713-9/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1131394427,46 Information and Computing Sciences; 4611 Machine Learning,
66,pub.1141301941,10.1007/978-3-030-87193-2,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2021, 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part I","The eight-volume set LNCS 12901, 12902, 12903, 12904, 12905, 12906, 12907, and 12908 constitutes the refereed proceedings of the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2021, held in Strasbourg, France, in September/October 2021.* The 531 revised full papers presented were carefully reviewed and selected from 1630 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: image segmentation Part II: machine learning - self-supervised learning; machine learning - semi-supervised learning; and machine learning - weakly supervised learning Part III: machine learning - advances in machine learning theory; machine learning - attention models; machine learning - domain adaptation; machine learning - federated learning; machine learning - interpretability / explainability; and machine learning - uncertainty Part IV: image registration; image-guided interventions and surgery; surgical data science; surgical planning and simulation; surgical skill and work flow analysis; and surgical visualization and mixed, augmented and virtual reality Part V: computer aided diagnosis; integration of imaging with non-imaging biomarkers; and outcome/disease prediction Part VI: image reconstruction; clinical applications - cardiac; and clinical applications - vascular Part VII: clinical applications - abdomen; clinical applications - breast; clinical applications - dermatology; clinical applications - fetal imaging; clinical applications - lung; clinical applications - neuroimaging - brain development; clinical applications - neuroimaging - DWI and tractography; clinical applications - neuroimaging - functional brain networks; clinical applications - neuroimaging – others; and clinical applications - oncology Part VIII: clinical applications - ophthalmology; computational (integrative) pathology; modalities - microscopy; modalities - histopathology; and modalities - ultrasound *The conference was held virtually.",,,Lecture Notes in Computer Science,,,2021,2021,,2021,12901,,,All OA; Green,Edited Book,,,,,4,4,,3.27,https://link.springer.com/content/pdf/bfm%3A978-3-030-87193-2%2F1,https://app.dimensions.ai/details/publication/pub.1141301941,46 Information and Computing Sciences; 4611 Machine Learning,
66,pub.1151072692,10.1007/978-3-031-16449-1,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2022, 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part VII","The eight-volume set LNCS 13431, 13432, 13433, 13434, 13435, 13436, 13437, and 13438 constitutes the refereed proceedings of the 25th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2022, which was held in Singapore in September 2022. The 574 revised full papers presented were carefully reviewed and selected from 1831 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: Brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; heart and lung imaging; dermatology; Part II: Computational (integrative) pathology; computational anatomy and physiology; ophthalmology; fetal imaging; Part III: Breast imaging; colonoscopy; computer aided diagnosis; Part IV: Microscopic image analysis; positron emission tomography; ultrasound imaging; video data analysis; image segmentation I; Part V: Image segmentation II; integration of imaging with non-imaging biomarkers; Part VI: Image registration; image reconstruction; Part VII: Image-Guided interventions and surgery; outcome and disease prediction; surgical data science; surgical planning and simulation; machine learning – domain adaptation and generalization; Part VIII: Machine learning – weakly-supervised learning; machine learning – model interpretation; machine learning – uncertainty; machine learning theory and methodologies.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13437,,,All OA; Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16449-1%2F1,https://app.dimensions.ai/details/publication/pub.1151072692,46 Information and Computing Sciences; 4611 Machine Learning,
60,pub.1151072616,10.1007/978-3-031-16446-0,,,"Medical Image Computing and Computer Assisted Intervention – MICCAI 2022, 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part VI","The eight-volume set LNCS 13431, 13432, 13433, 13434, 13435, 13436, 13437, and 13438 constitutes the refereed proceedings of the 25th International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2022, which was held in Singapore in September 2022. The 574 revised full papers presented were carefully reviewed and selected from 1831 submissions in a double-blind review process. The papers are organized in the following topical sections: Part I: Brain development and atlases; DWI and tractography; functional brain networks; neuroimaging; heart and lung imaging; dermatology; Part II: Computational (integrative) pathology; computational anatomy and physiology; ophthalmology; fetal imaging; Part III: Breast imaging; colonoscopy; computer aided diagnosis; Part IV: Microscopic image analysis; positron emission tomography; ultrasound imaging; video data analysis; image segmentation I; Part V: Image segmentation II; integration of imaging with non-imaging biomarkers; Part VI: Image registration; image reconstruction; Part VII: Image-Guided interventions and surgery; outcome and disease prediction; surgical data science; surgical planning and simulation; machine learning – domain adaptation and generalization; Part VIII: Machine learning – weakly-supervised learning; machine learning – model interpretation; machine learning – uncertainty; machine learning theory and methodologies.",,,Lecture Notes in Computer Science,,,2022,2022,,2022,13436,,,All OA; Green,Edited Book,,,,,0,0,,,https://link.springer.com/content/pdf/bfm%3A978-3-031-16446-0%2F1,https://app.dimensions.ai/details/publication/pub.1151072616,46 Information and Computing Sciences; 4611 Machine Learning,
60,pub.1142657609,10.1007/978-3-030-73565-4,,,Interventional Urology,"This updated text provides a concise yet comprehensive and state-of-the-art review of evolving techniques in the new and exciting subspecialty of interventional urology. Significant advances in imaging technologies, diagnostic tools, fusion navigation, and minimally invasive image-guided therapies such as focal ablative therapies have expanded the interventional urologists’ clinical toolkit over the past decade. Organized by organ system with subtopics covering imaging technologies, interventional techniques, recipes for successful practice, pitfalls to shorten the learning curves for new technologies, and clinical outcomes for the vast variety of interventional urologic procedures, this second edition includes many more medical images as well as helpful graphics and reference illustrations. The second edition of Interventional Urology serves as a valuable resource for clinicians, interventional urologists, interventional radiologists, interventional oncologists, urologic oncologists, as well as scientists, researchers, students, and residents with an interest in interventional urology.",,,,,,2021,2021,,2021,,,,All OA; Green,Edited Book,,,,,0,0,,0.0,https://link.springer.com/content/pdf/bfm%3A978-3-030-73565-4%2F1,https://app.dimensions.ai/details/publication/pub.1142657609,32 Biomedical and Clinical Sciences; 3202 Clinical Sciences,
60,pub.1086144283,10.1007/978-3-319-60964-5,,,"Medical Image Understanding and Analysis, 21st Annual Conference, MIUA 2017, Edinburgh, UK, July 11–13, 2017, Proceedings",The chapters 'Model-Based Correction of Segmentation Errors in Digitised Histological Images' and 'Unsupervised Superpixel-Based Segmentation of Histopathological Images with Consensus Clustering' are open access under a CC BY 4.0 license.,,,Communications in Computer and Information Science,,,2017,2017,,2017,723,,,All OA; Green,Edited Book,,,,,13,6,,3.74,https://link.springer.com/content/pdf/bfm:978-3-319-60964-5/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1086144283,46 Information and Computing Sciences; 4603 Computer Vision and Multimedia Computation,3 Good Health and Well Being
27,pub.1085989701,10.1007/978-981-10-5122-7,,,"EMBEC & NBC 2017, Joint Conference of the European Medical and Biological Engineering Conference (EMBEC) and the Nordic-Baltic Conference on Biomedical Engineering and Medical Physics (NBC), Tampere, Finland, June 2017","This volume presents the proceedings of the joint conference of the European Medical and Biological Engineering Conference (EMBEC) and the Nordic-Baltic Conference on Biomedical Engineering and Medical Physics (NBC), held in Tampere, Finland, in June 2017. The proceedings present all traditional biomedical engineering areas, but also highlight new emerging fields, such as tissue engineering, bioinformatics, biosensing, neurotechnology, additive manufacturing technologies for medicine and biology, and bioimaging, to name a few. Moreover, it emphasizes the role of education, translational research, and commercialization.",,,IFMBE Proceedings,,,2018,2018,,2018,65,,,All OA; Green,Edited Book,,,,,20,9,,3.25,https://link.springer.com/content/pdf/bfm:978-981-10-5122-7/1?pdf=chapter%20toc,https://app.dimensions.ai/details/publication/pub.1085989701,40 Engineering; 4003 Biomedical Engineering,4 Quality Education
