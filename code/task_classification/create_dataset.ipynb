{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "Aim to create the dataset of abstract for task classification.\n",
    "From OpenAlex inverted_abstract will create a reconstructed string version of the abstract and classify this task in regard of the dataset the paper references"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using list of paper that references a dataset with OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "datasets_context = {}\n",
    "ds_reader = csv.DictReader(open('../../data/datasets.csv'))\n",
    "for ds in ds_reader:\n",
    "    datasets_context[ds[\"name\"]] = ds[\"context\"]\n",
    "    \n",
    "df = pd.read_csv(\"../../results/extracted_csv/paper_openalex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_url = \"https://api.openalex.org/works/doi\"\n",
    "\n",
    "paper_abstract = {}\n",
    "with open(\"../../results/extracted_csv/paper_openalex.csv\",\"r\") as paper_csv:\n",
    "    with open(\"../../data/abstract_dataset.csv\",\"w\") as abstract_file:\n",
    "        abstract_file.write(\"title,doi,abstract,task\")\n",
    "        text = csv.reader(paper_csv,)\n",
    "        header=next(text)\n",
    "        for i,l in enumerate(text):\n",
    "            ds = datasets_context[l[-1]]\n",
    "            if not paper_abstract.get(l[1],None):\n",
    "                r = requests.get(query_url+l[1])\n",
    "                if r.status_code == 200:\n",
    "                    r_json = r.json()\n",
    "                    if r_json[\"abstract_inverted_index\"]:\n",
    "                        abstract = np.full(1000,\"\",dtype=object)\n",
    "                        for w in r_json[\"abstract_inverted_index\"]:\n",
    "                            for indices in r_json[\"abstract_inverted_index\"][w]:\n",
    "                                abstract[indices] = ''.join(filter(str.isalnum, w)).lower()\n",
    "                        abstract = abstract[abstract != \"\"]\n",
    "                        str_abstract = ' '.join(abstract)\n",
    "                        paper_abstract[l[1]] = (str_abstract,ds)\n",
    "                        abstract_file.write(f'\\n{l[0]},{l[1]},\"{paper_abstract[l[1]][0]}\",{ds}')\n",
    "            elif ds != paper_abstract[l[1]][1]:\n",
    "                abstract_file.write(f'\\n{l[0]},{l[1]},\"{paper_abstract[l[1]][0]}\",{ds}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using list of papers that cite a dataset or an organ in the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict = {\n",
    "    'acdc':'Cardiac',\n",
    "    'mscmr':\"Cardiac\",\n",
    "    'cardiac':'Cardiac',\n",
    "    'brats':\"Brain\",\n",
    "    'brain':\"Brain\",\n",
    "    'i2cvb':'Prostate',\n",
    "    'prostatex':'Prostate',\n",
    "    'promise12':'Prostate',\n",
    "    'prostate':'Prostate'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict = {}\n",
    "with open(\"../../data/keywords.csv\",'r') as f:\n",
    "    for l in csv.DictReader(f):\n",
    "        keyword_dict[l[\"keyword\"]] = l[\"organ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acdc': 'Cardiac',\n",
       " 'mscmr': 'Cardiac',\n",
       " 'cardiac': 'Cardiac',\n",
       " 'brats': 'Brain',\n",
       " 'brain': 'Brain',\n",
       " 'i2cvb': 'Prostate',\n",
       " 'prostatex': 'Prostate',\n",
       " 'promise12': 'Prostate',\n",
       " 'prostate': 'Prostate',\n",
       " 'lung': 'Lung',\n",
       " 'lungs': 'Lung'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    }
   ],
   "source": [
    "query_url = \"https://api.openalex.org/works\"\n",
    "with open('../../results/classification/raw_abstract.csv',\"w\") as test_file:\n",
    "    test_file.write(f'title,doi,publication_year,abstract,task')\n",
    "    for year in range(2023,2024):\n",
    "        print(year)\n",
    "        next_page = True\n",
    "        page_number = 1\n",
    "        while next_page:\n",
    "            query_param = {\n",
    "                'page':page_number,\n",
    "                'filter':f\"concepts.id:C89600930,concepts.id:C154945302,has_abstract:true,publication_year:{year}\"\n",
    "            }\n",
    "            r_year = requests.get(query_url,params=query_param)\n",
    "            if r_year.status_code == 200:\n",
    "                r_json = r_year.json()\n",
    "                if not r_json[\"results\"]:\n",
    "                    next_page = False\n",
    "                else:\n",
    "                    for paper in r_json[\"results\"]:\n",
    "                        abstract = np.full(2500,\"\",dtype=object)\n",
    "                        for w in paper[\"abstract_inverted_index\"]:\n",
    "                            for indices in paper[\"abstract_inverted_index\"][w]:\n",
    "                                if indices < 2500:\n",
    "                                    abstract[indices] = ''.join(filter(str.isalnum, w)).lower()\n",
    "                        abstract = abstract[abstract != \"\"]\n",
    "                        str_abstract = ' '.join(abstract)\n",
    "                        title = paper[\"title\"]\n",
    "                        if title:\n",
    "                            title = title.replace(\",\",\"\")\n",
    "                            title = title.replace(\"\\n\",\"\")\n",
    "                        for k in keyword_dict:\n",
    "                            if k in str_abstract:\n",
    "                                test_file.write(f'\\n{title},{paper[\"doi\"]},{paper[\"publication_year\"]},\"{str_abstract}\",{keyword_dict[k]}')\n",
    "                    page_number += 1\n",
    "            else:\n",
    "                next_page=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../results/classification/raw_abstract.csv\")\n",
    "df = df.drop_duplicates(subset=['title','task'])\n",
    "df.to_csv(\"../../data/abstract_dataset_clean2.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of non-relevant papers selected manually to add to the dataset to make the model able to detect non related papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_url = \"https://api.openalex.org/works/doi\"\n",
    "\n",
    "with open(\"../../data/paper_other.csv\",\"r\") as paper_csv:\n",
    "    with open(\"../../data/abstract_dataset_nonrelevant.csv\",\"w\") as abstract_file:\n",
    "        abstract_file.write(\"title,doi,publication_year,abstract,task\")\n",
    "        text = csv.reader(paper_csv,)\n",
    "        for i,l in enumerate(text):\n",
    "            r = requests.get(query_url+l[0])\n",
    "            if r.status_code == 200:\n",
    "                r_json = r.json()\n",
    "                if r_json[\"abstract_inverted_index\"]:\n",
    "                    abstract = np.full(1000,\"\",dtype=object)\n",
    "                    for w in r_json[\"abstract_inverted_index\"]:\n",
    "                        for indices in r_json[\"abstract_inverted_index\"][w]:\n",
    "                            abstract[indices] = ''.join(filter(str.isalnum, w)).lower()\n",
    "                    abstract = abstract[abstract != \"\"]\n",
    "                    str_abstract = ' '.join(abstract)\n",
    "                    title = r_json[\"title\"]\n",
    "                    title = title.replace(\",\",\"\")\n",
    "                    title = title.replace(\"\\n\",\"\")\n",
    "                    abstract_file.write(f'\\n{title},{l[0]},\"{str_abstract}\",Other')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
