{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this file is to merge the information extracted with the different sources such as OpenAlex or OpenCitation together to generate the final output of the process which contains all the association paper-dataset-task to allow further analysis after."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this proceed ?\n",
    "1. Load every generated csv present in extracted_csv folder\n",
    "2. For each line in a csv:\n",
    "    1. Test if the association DOI-Dataset has already been seen\n",
    "    2. If not create a new line in merged.csv with the addition of the information about the task find in dataset.csv \"context\" field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionnary with dataset's name as key and task as value (e.g ACDC:cardiac)\n",
    "datasets_context = {}\n",
    "ds_reader = csv.DictReader(open('../data/datasets.csv'))\n",
    "for ds in ds_reader:\n",
    "    datasets_context[ds[\"name\"]] = ds[\"context\"]\n",
    "\n",
    "doi_using_dataset = {ds:[] for ds in datasets_context}\n",
    "title_using_dataset = {ds:[] for ds in datasets_context}\n",
    "\n",
    "#Get the list of csv from different sources\n",
    "extracted_csv = glob.glob(\"../extracted_csv/*.csv\")\n",
    "\n",
    "#Dictionnary with paper DOI as key and list of sources that give back that paper as value\n",
    "sources_coverage = {}\n",
    "\n",
    "#title of papers as keys and DOI as value, use for papers with multiple DOI to do the coverage analysis\n",
    "name_doi = {}\n",
    "\n",
    "# /!\\ WARNING /!\\: If merged.csv already exist, the previous content will be removed !\n",
    "with open(\"../processed_csv/merged.csv\",\"w\") as merged :\n",
    "    merged.write(f\"name,DOI,publication_year,dataset_used,task\")\n",
    "    for i,csv_path in enumerate(extracted_csv):\n",
    "        csv_reader = csv.DictReader(open(csv_path))\n",
    "        for line in csv_reader:\n",
    "            doi_encountered = line['DOI'] not in doi_using_dataset[line['dataset_used']]\n",
    "            title_encountered = line['name'] not in title_using_dataset[line['dataset_used']]\n",
    "\n",
    "            if doi_encountered and title_encountered:\n",
    "                doi_using_dataset[line['dataset_used']].append(line['DOI'])\n",
    "                title_using_dataset[line['dataset_used']].append(line['name'])\n",
    "                \n",
    "                merged.write(f\"\\n{line['name']},{line['DOI']},{line['publication_year']},{line['dataset_used']},{datasets_context[line['dataset_used']]}\")\n",
    "                sources_coverage[line['DOI']] = [False for _ in range(len(extracted_csv))]\n",
    "                sources_coverage[line['DOI']][i] = True\n",
    "                name_doi[line[\"name\"]] = line['DOI']\n",
    "                \n",
    "            elif line['name'] in name_doi:\n",
    "                sources_coverage[name_doi[line['name']]][i] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of coverage\n",
    "Analysis the result from the different sources and compare them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame.from_dict(sources_coverage).transpose()\n",
    "df.columns = extracted_csv\n",
    "df.index.name = 'DOI'\n",
    "df.to_csv(\"../processed_csv/coverage.csv\")\n",
    "\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    name='test', \n",
    "    colors=['red','green']\n",
    ")\n",
    "plt.figure(figsize=(10,650))\n",
    "plt.title(\"Presence of a paper in the API's response\")\n",
    "sns.heatmap(df,cbar=False,cmap=cmap,xticklabels = 1,yticklabels = 5)\n",
    "sns.set(font_scale=2)\n",
    "plt.savefig('../res/coverage.png',bbox_inches='tight')\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
