{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of papers from venue that cites a dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load list of datasets and list of venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionnary with dataset's name as key and context/segmented organ as value\n",
    "datasets_doi = {}\n",
    "ds_reader = csv.DictReader(open('../../data/datasets.csv'))\n",
    "for ds in ds_reader:\n",
    "    datasets_doi[ds[\"name\"]] = ds[\"DOI\"]\n",
    "\n",
    "#Dictionnary with venues name as key and openalex id as value\n",
    "venue_id = {}\n",
    "ds_reader = csv.DictReader(open('../../data/venues.csv'))\n",
    "for ds in ds_reader:\n",
    "    venue_id[ds[\"name\"]] = ds[\"openalex_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "{'ACDC': '10.1109/TMI.2018.2837502',\n",
      " 'BRATS': '10.1109/tmi.2014.2377694',\n",
      " 'I2CVB': '10.1016/j.compbiomed.2015.02.009',\n",
      " 'LA': '10.1016/j.media.2020.101832',\n",
      " 'M&Ms': '10.1109/tmi.2021.3090082',\n",
      " 'MSCMRSeg': '10.48550/arxiv.2006.12434',\n",
      " 'Medical Decathlon': '10.1038/s41467-022-30695-9',\n",
      " 'PROMISE12': '10.1016/j.media.2013.12.002',\n",
      " 'Synapse': '10.7303/syn3193805'}\n",
      "\n",
      "Venues:\n",
      "{'LNCS': 'S106296714'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets:\")\n",
    "pprint(datasets_doi)\n",
    "print(\"\\nVenues:\")\n",
    "pprint(venue_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to convert DOI to OpenAlex ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't convert DOI for Synapse into OpenAlex ID\n"
     ]
    }
   ],
   "source": [
    "def doi_to_OpenAlexId(doi):\n",
    "    base_url = f\"https://api.openalex.org/works/doi:{doi}\"\n",
    "    r = requests.get(base_url)\n",
    "    if r.status_code == 200:\n",
    "        r_json = r.json()\n",
    "        return r_json[\"id\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#Dictionnary with dataset names as key and openalex id as value. We associate an openalex ID because it's the value in the \"referenced_works\" field given by the API.\n",
    "#To save a request, I use directly the OpenAlex ID otherwise you need to make a request with the ID to get the DOI or the name.\n",
    "datasets_id = {}\n",
    "#Convert DOI to OpenAlexID\n",
    "for ds  in datasets_doi:\n",
    "    openalex_id = doi_to_OpenAlexId(datasets_doi[ds])\n",
    "    if not openalex_id:\n",
    "        print(f\"Couldn't convert DOI for {ds} into OpenAlex ID\")\n",
    "    datasets_id[ds]=openalex_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACDC': 'https://openalex.org/W2804047627',\n",
      " 'BRATS': 'https://openalex.org/W1641498739',\n",
      " 'I2CVB': 'https://openalex.org/W2049522781',\n",
      " 'LA': 'https://openalex.org/W3093394156',\n",
      " 'M&Ms': 'https://openalex.org/W4226199676',\n",
      " 'MSCMRSeg': 'https://openalex.org/W4312016581',\n",
      " 'Medical Decathlon': 'https://openalex.org/W3172681723',\n",
      " 'PROMISE12': 'https://openalex.org/W2106033751',\n",
      " 'Synapse': None}\n"
     ]
    }
   ],
   "source": [
    "pprint(datasets_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of papers from each venues citing at least one of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n",
      "yo\n"
     ]
    }
   ],
   "source": [
    "#Dictionnary containing with dataset as key and a list of papers\n",
    "paper_using = {ds:[] for ds in datasets_id}\n",
    "\n",
    "\n",
    "for ds in datasets_id:\n",
    "    for venue in venue_id:\n",
    "        #The list of paper referencing the dataset is decomposed in multiple pages so we have to iterate with the query parameter \"page\" to get them all.\n",
    "        next_page = True\n",
    "        page_number = 1\n",
    "        while next_page:\n",
    "            #Definition of the request\n",
    "            base_url = \"https://api.openalex.org/works\"\n",
    "            query_param = {\n",
    "                \"filter\":f\"cites:{datasets_id[ds]},locations.source.id:{venue_id[venue]}\",\n",
    "                \"page\":page_number\n",
    "            }\n",
    "            request = requests.get(base_url,params=query_param)\n",
    "\n",
    "            if request.status_code == 200:\n",
    "                request_json = request.json()\n",
    "                \n",
    "                #For each paper referencing the dataset we get the title (with a little transformation to remove \",\" and \"\\n\" inside of them), doi and publication year\n",
    "                for res in request_json[\"results\"]:\n",
    "                    title = res[\"title\"]\n",
    "                    title = title.replace(\",\",\"\")\n",
    "                    title = title.replace(\"\\n\",\"\")\n",
    "\n",
    "                    #Remove review paper\n",
    "                    if \"review\" in title.lower():\n",
    "                        continue\n",
    "                    \n",
    "                    doi = res[\"doi\"]\n",
    "                    if doi is not None:\n",
    "                        doi = doi[16:] #Remove the https://doi.org/\n",
    "                        paper_using[ds].append((title,doi,res[\"publication_year\"]))\n",
    "\n",
    "                #If the results field is empty that mean we are at the last page so we can continue to the next dataset\n",
    "                #otherwise we need to go to next page of the current dataset\n",
    "                if not request_json[\"results\"]:\n",
    "                    next_page = False\n",
    "                else:\n",
    "                    page_number += 1\n",
    "            else:\n",
    "                next_page = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of citations for ACDC: 120\n",
      "Number of citations for LA: 10\n",
      "Number of citations for MSCMRSeg: 0\n",
      "Number of citations for M&Ms: 34\n",
      "Number of citations for PROMISE12: 29\n",
      "Number of citations for Medical Decathlon: 4\n",
      "Number of citations for I2CVB: 13\n",
      "Number of citations for BRATS: 494\n",
      "Number of citations for Synapse: 0\n"
     ]
    }
   ],
   "source": [
    "for d in paper_using:\n",
    "    print(f\"Number of citations for {d}: {len(paper_using[d])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check fulltext of paper for either figures or tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To download fulltext\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#To filter invalid pdf\n",
    "from pypdf import PdfReader\n",
    "from pypdf.errors import PdfReadError\n",
    "\n",
    "#To handle files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#To extract images from pdf\n",
    "import fitz\n",
    "\n",
    "#To extract tables from pdf\n",
    "import camelot\n",
    "import ghostscript"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download papers full text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter paper to get for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only get paper from 2023 referencing ACDC paper\n",
    "df = pd.read_csv(\"../../results/extracted_csv/paper_openalex.csv\")\n",
    "df_2023 = df[df[\"publication_year\"] == 2023]\n",
    "df_acdc = df_2023[df_2023[\"dataset_used\"] == \"ACDC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1016/b978-0-32-385773-4.00023-x\n",
      "10.1016/b978-0-32-385773-4.00025-3\n",
      "10.1016/b978-0-32-385773-4.00009-5\n",
      "https://doi.org/10.1016/b978-0-32-385773-4.00009-5\n",
      "10.1016/j.compbiomed.2022.106439\n",
      "10.1371/journal.pdig.0000159\n",
      "https://journals.plos.org/digitalhealth/article/file?id=10.1371/journal.pdig.0000159&type=printable\n",
      "10.1109/access.2023.3234241\n",
      "10.1016/j.compmedimag.2022.102174\n",
      "10.1088/1361-6560/acb19a\n",
      "https://iopscience.iop.org/article/10.1088/1361-6560/acb19a/pdf\n",
      "10.1007/s00740-022-00474-9\n",
      "10.1016/j.patcog.2023.109318\n",
      "https://doi.org/10.1016/j.patcog.2023.109318\n",
      "10.1109/access.2023.3238058\n",
      "10.1038/s41598-023-28348-y\n",
      "https://www.nature.com/articles/s41598-023-28348-y.pdf\n",
      "10.3389/fphys.2023.1027076\n",
      "https://www.frontiersin.org/articles/10.3389/fphys.2023.1027076/pdf\n",
      "10.1016/b978-0-12-821983-6.00008-4\n",
      "10.3390/bioengineering10020166\n",
      "https://www.mdpi.com/2306-5354/10/2/166/pdf?version=1674889337\n",
      "10.1016/j.media.2023.102762\n",
      "http://arxiv.org/pdf/2206.01136\n",
      "10.1016/j.bspc.2023.104631\n",
      "10.1109/wacv56688.2023.00365\n",
      "https://eprints.gla.ac.uk/282738/2/282738.pdf\n"
     ]
    }
   ],
   "source": [
    "url_base = \"https://api.openalex.org/works/https://doi.org/\"\n",
    "paper_id = 1\n",
    "for doi in df_acdc[\"DOI\"]:\n",
    "    url = url_base + doi \n",
    "    r_paper = requests.get(url)\n",
    "    if r_paper.status_code == 200:\n",
    "        r_paper_json = r_paper.json()\n",
    "        fulltext_url = r_paper_json[\"open_access\"][\"oa_url\"]\n",
    "        if fulltext_url:\n",
    "            r_fulltext = requests.get(fulltext_url,allow_redirects=True)\n",
    "            if r_fulltext.status_code == 200:\n",
    "                print(fulltext_url)\n",
    "                open(f\"../../results/papers_fulltext/{paper_id}.pdf\",\"wb\").write(r_fulltext.content)\n",
    "                paper_id += 1\n",
    "        #Stop after 10th download, only to test and maybe not get block by some site\n",
    "        if paper_id == 10:\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Error {r_paper.status_code} for {doi}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invalid pdf obtain from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get every downloaded pdf path\n",
    "pdf_path = glob.glob(\"../../results/papers_fulltext/*.pdf\")\n",
    "\n",
    "#Create folder where valid pdf will be moved\n",
    "if not os.path.exists(\"../../results/papers_fulltext/valid_pdf\"):\n",
    "    os.makedirs(\"../../results/papers_fulltext/valid_pdf\")\n",
    "\n",
    "#Create folder where invalid pdf will be moved\n",
    "if not os.path.exists(\"../../results/papers_fulltext/removed_pdf\"):\n",
    "    os.makedirs(\"../../results/papers_fulltext/removed_pdf\")\n",
    "\n",
    "#For each downloaded pdf\n",
    "for file in pdf_path:\n",
    "    try:\n",
    "        #Try to read the pdf (Raise an error if the file is an invalid pdf)\n",
    "        PdfReader(file,strict=True)\n",
    "        #If valid, move the file to valid folder\n",
    "        os.rename(file, file.replace(\"papers_fulltext/\",\"papers_fulltext/valid_pdf/\"))\n",
    "    except PdfReadError:\n",
    "        #If a PdfReadError is raised, the pdf is invalid and therefor moved to removed_pdf folder\n",
    "        os.rename(file, file.replace(\"papers_fulltext/\",\"papers_fulltext/removed_pdf/\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract images from valid pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get every valid pdf path\n",
    "valid_pdf_path = glob.glob(\"../../results/papers_fulltext/valid_pdf/*.pdf\")\n",
    "\n",
    "#path of folder where images will be stored\n",
    "images_path = \"../../results/papers_fulltext/images\"\n",
    "#Create this folder if it does not exist\n",
    "if not os.path.exists(images_path):\n",
    "    os.makedirs(images_path)\n",
    "\n",
    "#For each pdf file\n",
    "for file in valid_pdf_path:\n",
    "    #Open the file\n",
    "    pdf_file = fitz.open(file)\n",
    "\n",
    "    #Get the number of pages in PDF file\n",
    "    page_nums = len(pdf_file)\n",
    "\n",
    "    #Create empty list to store images information\n",
    "    images_list = []\n",
    "\n",
    "    #Extract all images information from each page\n",
    "    for page_num in range(page_nums):\n",
    "        page_content = pdf_file[page_num]\n",
    "        images_list.extend(page_content.get_images())\n",
    "\n",
    "    #If there is at least one image in the pdf\n",
    "    if len(images_list)!=0:\n",
    "        #Create a subfolder for the article, this way we easily know from which paper the images is coming from\n",
    "        if not os.path.exists(os.path.join(images_path, os.path.basename(file.replace(\".pdf\",\"\")))):\n",
    "            os.makedirs(os.path.join(images_path, os.path.basename(file.replace(\".pdf\",\"\"))))\n",
    "\n",
    "        #Save all the extracted images\n",
    "        for i, img in enumerate(images_list, start=1):\n",
    "            #Extract the image object number\n",
    "            xref = img[0]\n",
    "            #Extract image\n",
    "            base_image = pdf_file.extract_image(xref)\n",
    "            #Store image bytes\n",
    "            image_bytes = base_image['image']\n",
    "            #Store image extension\n",
    "            image_ext = base_image['ext']\n",
    "            #Generate image file name\n",
    "            image_name = str(i) + '.' + image_ext\n",
    "            #Save image\n",
    "            with open(os.path.join(images_path, os.path.basename(file.replace(\".pdf\",\"\")),image_name) , 'wb') as image_file:\n",
    "                image_file.write(image_bytes)\n",
    "                image_file.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract tables from valid PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pdf_path = glob.glob(\"../../results/papers_fulltext/valid_pdf/*.pdf\")\n",
    "for pdf in valid_pdf_path:\n",
    "    tables = camelot.read_pdf(pdf,\"all\",flavor=\"stream\",suppress_stdout=True)\n",
    "    for t in tables:\n",
    "        t_str = t.df.to_string()\n",
    "        if \"ACDC\" in t_str:\n",
    "            print(\"ACDC IN\",pdf)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACDC IN ../../results/papers_fulltext/valid_pdf/5.pdf\n",
      "ACDC IN ../../results/papers_fulltext/valid_pdf/9.pdf\n",
      "ACDC IN ../../results/papers_fulltext/valid_pdf/6.pdf\n",
      "ACDC IN ../../results/papers_fulltext/valid_pdf/7.pdf\n",
      "ACDC IN ../../results/papers_fulltext/valid_pdf/8.pdf\n"
     ]
    }
   ],
   "source": [
    "for pdf in valid_pdf_path:\n",
    "    tables = camelot.read_pdf(pdf,\"all\",flavor=\"stream\",suppress_stdout=True)\n",
    "    for t in tables:\n",
    "        t_str = t.df.to_string()\n",
    "        if \"ACDC\" in t_str:\n",
    "            print(\"ACDC IN\",pdf)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
